{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"themes/fluid/source/css/gitalk.css","path":"css/gitalk.css","modified":0,"renderable":1},{"_id":"themes/fluid/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/avatar.png","path":"img/avatar.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/bg.jpg","path":"img/bg.jpg","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/bg2.jpg","path":"img/bg2.jpg","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/bg_in.jpg","path":"img/bg_in.jpg","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/default.png","path":"img/default.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/favicon.png","path":"img/favicon.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/loading.gif","path":"img/loading.gif","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/police_beian.png","path":"img/police_beian.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/boot.js","path":"js/boot.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/color-schema.js","path":"js/color-schema.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/debouncer.js","path":"js/debouncer.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/duration.js","path":"js/duration.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/events.js","path":"js/events.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/lazyload.js","path":"js/lazyload.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/leancloud.js","path":"js/leancloud.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/local-search.js","path":"js/local-search.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/plugins.js","path":"js/plugins.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/xml/local-search.xml","path":"xml/local-search.xml","modified":0,"renderable":1},{"_id":"themes/fluid/source/lib/hint/hint.min.css","path":"lib/hint/hint.min.css","modified":0,"renderable":1},{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"source/pdf/NER.pdf","path":"pdf/NER.pdf","modified":0,"renderable":0},{"_id":"source/img/AI.png","path":"img/AI.png","modified":0,"renderable":0},{"_id":"source/img/PNP.webp","path":"img/PNP.webp","modified":0,"renderable":0},{"_id":"source/img/TODO.png","path":"img/TODO.png","modified":0,"renderable":0},{"_id":"source/img/tcp.jpeg","path":"img/tcp.jpeg","modified":0,"renderable":0},{"_id":"source/img/Cs231n/top.jpg","path":"img/Cs231n/top.jpg","modified":0,"renderable":0},{"_id":"source/img/DS/tree_差分2.png","path":"img/DS/tree_差分2.png","modified":0,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_016df1440f7044a54fb4ced529595b58.png","path":"img/ICS_Lab2/upload_016df1440f7044a54fb4ced529595b58.png","modified":0,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_244e1f55d2823d58f65eabab9478d7ce.png","path":"img/ICS_Lab2/upload_244e1f55d2823d58f65eabab9478d7ce.png","modified":0,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_27148224f8cf2be48266eaa52f50b2f8.png","path":"img/ICS_Lab2/upload_27148224f8cf2be48266eaa52f50b2f8.png","modified":0,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_4801c7e177c56f6e7299c273d0120988.png","path":"img/ICS_Lab2/upload_4801c7e177c56f6e7299c273d0120988.png","modified":0,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_64ed470376ec6b72dc43690bf9b4ea0e.png","path":"img/ICS_Lab2/upload_64ed470376ec6b72dc43690bf9b4ea0e.png","modified":0,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_9ea5cd30293a18357af1da93c35e0f59.png","path":"img/ICS_Lab2/upload_9ea5cd30293a18357af1da93c35e0f59.png","modified":0,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_a18a67d1b4dbfa16a7fd8800e3ee304b.png","path":"img/ICS_Lab2/upload_a18a67d1b4dbfa16a7fd8800e3ee304b.png","modified":0,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_ae5e359c30ff5ccb9292a7472c39eb19.png","path":"img/ICS_Lab2/upload_ae5e359c30ff5ccb9292a7472c39eb19.png","modified":0,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_dfddd1801cd10c701dd2753164434977.png","path":"img/ICS_Lab2/upload_dfddd1801cd10c701dd2753164434977.png","modified":0,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_f2ecdd05728cbefbba59b068a29fdfdc.png","path":"img/ICS_Lab2/upload_f2ecdd05728cbefbba59b068a29fdfdc.png","modified":0,"renderable":0},{"_id":"source/img/OS/banner.png","path":"img/OS/banner.png","modified":0,"renderable":0},{"_id":"source/img/Pic/DS.png","path":"img/Pic/DS.png","modified":0,"renderable":0},{"_id":"source/img/Pic/PointCloud.jpg","path":"img/Pic/PointCloud.jpg","modified":0,"renderable":0},{"_id":"source/img/Pic/Recent.jpeg","path":"img/Pic/Recent.jpeg","modified":0,"renderable":0},{"_id":"source/img/Pic/cnn_img.jpeg","path":"img/Pic/cnn_img.jpeg","modified":0,"renderable":0},{"_id":"source/img/PointCNN/conv.png","path":"img/PointCNN/conv.png","modified":0,"renderable":0},{"_id":"source/img/PointCNN/conv2.png","path":"img/PointCNN/conv2.png","modified":0,"renderable":0},{"_id":"source/img/PointCNN/conv_a.png","path":"img/PointCNN/conv_a.png","modified":0,"renderable":0},{"_id":"source/img/PointCNN/conv_b.png","path":"img/PointCNN/conv_b.png","modified":0,"renderable":0},{"_id":"source/img/PointCNN/knn.png","path":"img/PointCNN/knn.png","modified":0,"renderable":0},{"_id":"source/img/PointCNN/time.png","path":"img/PointCNN/time.png","modified":0,"renderable":0},{"_id":"source/img/PointCNN/time2.png","path":"img/PointCNN/time2.png","modified":0,"renderable":0},{"_id":"source/img/PointCNN/visual.png","path":"img/PointCNN/visual.png","modified":0,"renderable":0},{"_id":"source/img/PointCNN/x_conv.png","path":"img/PointCNN/x_conv.png","modified":0,"renderable":0},{"_id":"source/img/PointCNN/x_transformer.png","path":"img/PointCNN/x_transformer.png","modified":0,"renderable":0},{"_id":"source/img/PointNet/result.png","path":"img/PointNet/result.png","modified":0,"renderable":0},{"_id":"source/img/PointNet/symmetry _function.png","path":"img/PointNet/symmetry _function.png","modified":0,"renderable":0},{"_id":"source/img/PointNet++/res.png","path":"img/PointNet++/res.png","modified":0,"renderable":0},{"_id":"source/img/hello_world/top.png","path":"img/hello_world/top.png","modified":0,"renderable":0},{"_id":"source/img/ICS_Lab1/bits_btest.JPG","path":"img/ICS_Lab1/bits_btest.JPG","modified":0,"renderable":0},{"_id":"source/img/ICS_Lab1/bits_dlc.png","path":"img/ICS_Lab1/bits_dlc.png","modified":0,"renderable":0},{"_id":"source/img/ICS_Lab1/bits_honor_btest.JPG","path":"img/ICS_Lab1/bits_honor_btest.JPG","modified":0,"renderable":0},{"_id":"source/img/ICS_Lab1/bits_honor_dlc.png","path":"img/ICS_Lab1/bits_honor_dlc.png","modified":0,"renderable":0},{"_id":"source/img/ICS_Lab1/top.jpg","path":"img/ICS_Lab1/top.jpg","modified":0,"renderable":0},{"_id":"source/img/NLP/banner.jpeg","path":"img/NLP/banner.jpeg","modified":0,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_7194e52688ff3d696a3b889e2b17d63f.png","path":"img/ICS_Lab2/upload_7194e52688ff3d696a3b889e2b17d63f.png","modified":0,"renderable":0},{"_id":"source/img/DS/tree_差分.png","path":"img/DS/tree_差分.png","modified":0,"renderable":0}],"Cache":[{"_id":"source/.DS_Store","hash":"445c49e383c2fe7b68fb0424a8c3c6a2a444c614","modified":1770097334418},{"_id":"source/_posts/.DS_Store","hash":"ae6968fc735fb720fe47338d7d4dd9598bc1c84c","modified":1770097334419},{"_id":"source/CNAME","hash":"51544cd37f2188326b08d74bd5b18cde71d558ac","modified":1770097334419},{"_id":"source/_posts/Readelf.md","hash":"1997bf2128f4ad5764cef93d4cd6aea9a14e9d85","modified":1770097334444},{"_id":"source/_posts/final_todo.md","hash":"e740ed2486df2836ae42bea7b48436baeb8f4ea2","modified":1770097334452},{"_id":"source/_posts/hello-world.md","hash":"74ee16db7816ba9f602499d9f82a00d082f47b43","modified":1770097334452},{"_id":"source/_posts/Recent-Progress (2020-11-15 ~ 2020-11-27).md","hash":"c9ce92251af5542da8d5f7fedd4b3229a4fb54e4","modified":1770097334446},{"_id":"source/js/duration.js","hash":"5e213d829ccf6a9273bb3cad3c2d39c90dcc10af","modified":1770097334757},{"_id":"source/img/.DS_Store","hash":"a209adefc3972eaef2c3ddd7ea4ac08653b70d06","modified":1770097334454},{"_id":"source/img/PNP.webp","hash":"2241713d4bfac01da4c1ad70d73fb82494abce61","modified":1770097334714},{"_id":"source/img/TODO.png","hash":"52e3cfd0df7fcc4806f62eb27f717cf045158cb3","modified":1770097334746},{"_id":"source/about/index.md","hash":"d19ef6b3db3f8159a0b51facf4ffbbcb877bc2ae","modified":1770097334453},{"_id":"source/_posts/CS231n/CS231n-06-Training-Neural-Networks-II.md","hash":"77fe84659656f273e9dcb31d1c4d0cd5b33326fa","modified":1770097334423},{"_id":"source/_posts/CS231n/CS231n-03-Introduction-to-Convolutional-neural-network.md","hash":"d4dc274759671030bab92a897b1abe4c1999e003","modified":1770097334419},{"_id":"source/_posts/CS231n/CS231n-04-Convolutional-Neural-Networks.md","hash":"63af23d8993f8b340c8f632c4dc8037f619cf215","modified":1770097334420},{"_id":"source/_posts/CS231n/CS231n-05-Training-Neural-Networks-I.md","hash":"c58e16f3abad2ba20c625d57d2a89689b30efa1d","modified":1770097334421},{"_id":"source/_posts/CS231n/CS231n_01_Image_Classification.md","hash":"0734667862fbff18dc441e22ebadfa692c197001","modified":1770097334423},{"_id":"source/_posts/DS/DataStructureNote2.md","hash":"0c2fa3dab75219a4232b40fcf2ca28ce1206a26a","modified":1770097334428},{"_id":"source/_posts/NLP/nlp-ner.md","hash":"ebe4e89cd849ddc86bc70b5292f42a8d0185d99a","modified":1770097334437},{"_id":"source/_posts/DS/DataStructureNote1.md","hash":"56d8264c2b99aca82d3871493b2977837f01e963","modified":1770097334428},{"_id":"source/_posts/ICS/.DS_Store","hash":"5351498d05b17154ab3629af84fae13693023c43","modified":1770097334429},{"_id":"source/_posts/NLP/nlp-sst.md","hash":"31e8cf14d95b197a8d34a6e9d4474e61831a1042","modified":1770097334437},{"_id":"source/_posts/ICS/Dynamic Memory Allocation.md","hash":"5aa193a6e6014b5e944e64440de8e055b8977395","modified":1770097334431},{"_id":"source/_posts/CS231n/CS231n_02_Loss-Functions-and-Optimization.md","hash":"44ee119de7e50c0833c5a28c6891ada76e4c1777","modified":1770097334425},{"_id":"source/_posts/ICS/ICS_Normal.md","hash":"13516bf801e4730b3a743ed529267a5f6cc150b4","modified":1770097334433},{"_id":"source/_posts/ICS/ICS_Lab1.md","hash":"6279b2d5cc2a3b74c18eb26f08c8569bc8ba1361","modified":1770097334432},{"_id":"source/_posts/ICS/ICS_Lab3.md","hash":"24d06de4f3c290ee085267b12c8f9a2ba4b50f94","modified":1770097334433},{"_id":"source/_posts/ICS/ICS_Lab2.md","hash":"6378cae75f62bc460299993051dcd20b31aaf162","modified":1770097334432},{"_id":"source/_posts/ICS/CacheLab.md","hash":"c7918bdb14cfc117eb0fb495cad9429c81a11fff","modified":1770097334431},{"_id":"source/_posts/ICS/ICS_PJ.md","hash":"37b468313891e5ec105b047a447062f79e01f2d4","modified":1770097334436},{"_id":"source/_posts/OS/.DS_Store","hash":"4654d71a95be2ad4cac155cc00e0e0fe545f1471","modified":1770097334440},{"_id":"source/_posts/ICS/MallocLab.md","hash":"0add925f674d064aa8d69af5e805579668645bf5","modified":1770097334436},{"_id":"source/_posts/OS/Locality_Principle.md","hash":"43b50a684e755fdc6f407866769139e83183dd67","modified":1770097334440},{"_id":"source/_posts/Computation_Theory/note.md","hash":"f2d5ec14960498d359c43c1101c2aef8fd9e10f4","modified":1770097334427},{"_id":"source/_posts/OS/OS-Evolution-01.md","hash":"c49fff0d686915cdfa3a80509328c999801edb9e","modified":1770097334443},{"_id":"source/_posts/OS/MemAddressing.md","hash":"e50c94387a3433f3e226c14406ec23bd844f0f47","modified":1770097334443},{"_id":"source/_posts/Network/rdt.md","hash":"8b16dcfe46d76e482398df036efc7658bf004d74","modified":1770097334439},{"_id":"source/_posts/OS/kernelArc.md","hash":"cb3f995f021a119dc84a86ae3ac4abbb6351be3a","modified":1770097334444},{"_id":"source/_posts/OS/Unix.md","hash":"922a09dac63fda81abac954c87f404bda96d4e8e","modified":1770097334444},{"_id":"source/_posts/OS/Process.md","hash":"3db855cc9208c581b6cb7309ec3ea92f074fee27","modified":1770097334444},{"_id":"source/_posts/Research/.DS_Store","hash":"ff79f494941ca0d8f347300d0451df1ae877b61d","modified":1770097334447},{"_id":"source/_posts/Research/CaDDN-Paper.md","hash":"39c4d000b53382fce5e8a77f922c1ebff86adfae","modified":1770097334450},{"_id":"source/_posts/Research/DETR.md","hash":"cc496ea9c81b2fe97e4cf712101ac727532847c3","modified":1770097334450},{"_id":"source/_posts/Research/PointNetpp.md","hash":"94b20526f525cfb2b04a8d3cbdaaabf1dcce1299","modified":1770097334452},{"_id":"source/_posts/Research/PointCNN.md","hash":"883bdd9339e4a89a47a2699499804f43a9ee4b93","modified":1770097334451},{"_id":"source/_posts/Research/PointNet.md","hash":"429cf8de9d341948e3e959a64ba38ac285729a57","modified":1770097334452},{"_id":"source/img/ICS_Lab2/.DS_Store","hash":"ee6df2f45dbbecef218431e70c9d5937af39da22","modified":1770097334667},{"_id":"source/img/ICS_Lab2/upload_4801c7e177c56f6e7299c273d0120988.png","hash":"e59229dcd7bdc1dc4ddb52601b58d5a5dd8557c6","modified":1770097334676},{"_id":"source/img/ICS_Lab2/upload_f2ecdd05728cbefbba59b068a29fdfdc.png","hash":"fc4024d6fb85e7850ba440cd56a267ed060a959a","modified":1770097334689},{"_id":"source/img/Pic/cnn_img.jpeg","hash":"7ceabac10778f93a977196eb371197062cff2319","modified":1770097334720},{"_id":"source/img/Pic/Recent.jpeg","hash":"a894cbfcd2ef37457d03c1eafd83b50842fffdbc","modified":1770097334720},{"_id":"source/img/Pic/DS.png","hash":"de0c67290b8c1fe646ec29df885168c85f405ff8","modified":1770097334716},{"_id":"source/img/PointCNN/conv_a.png","hash":"a83fca017aa6b6adafe08f172a4299a9d3ae1081","modified":1770097334722},{"_id":"source/img/PointCNN/conv_b.png","hash":"abda8f4a4af23358f2a48a73ed1e8667df5c9f24","modified":1770097334722},{"_id":"source/img/PointCNN/conv2.png","hash":"069970fe8dc70a505b2b95330390ff0422d7d01a","modified":1770097334721},{"_id":"source/img/PointCNN/time.png","hash":"e7cdf1994df22ed8b1b5ee22952c5b13f0bfe922","modified":1770097334724},{"_id":"source/img/PointNet/symmetry _function.png","hash":"5b85bc43d6159b9d0f011e837f5efa77230147c0","modified":1770097334743},{"_id":"source/img/hello_world/.DS_Store","hash":"ef305a92aab031f18d61a6dc85104dbe7d8acdfe","modified":1770097334746},{"_id":"source/img/ICS_Lab1/.DS_Store","hash":"3644d2a969a48867287119213604eddc91a7af44","modified":1770097334636},{"_id":"source/img/ICS_Lab1/bits_honor_dlc.png","hash":"72b1d169d0c3703bd268e98134eff20a0e0cc31d","modified":1770097334666},{"_id":"source/img/ICS_Lab1/top.jpg","hash":"72a892ba4833d2e1d3c0bdb6a35d3a8d33e8e8cd","modified":1770097334666},{"_id":"source/img/DS/tree_差分2.png","hash":"732ca9708af1fd33590c2d62f533c562b4b74f41","modified":1770097334634},{"_id":"source/img/Cs231n/top.jpg","hash":"a9f72513df8d124e1ba28899f90ebb6da8fb55b0","modified":1770097334580},{"_id":"source/img/ICS_Lab2/upload_dfddd1801cd10c701dd2753164434977.png","hash":"18eb25f8c6db5cb7bd810129130c7d6dad71a54c","modified":1770097334687},{"_id":"source/img/ICS_Lab2/upload_a18a67d1b4dbfa16a7fd8800e3ee304b.png","hash":"3150fbc95d0db988078ce153187bd333140a3e3d","modified":1770097334685},{"_id":"source/img/ICS_Lab2/upload_ae5e359c30ff5ccb9292a7472c39eb19.png","hash":"6d1014f0788ac311e23beef2c59d068f472f86df","modified":1770097334686},{"_id":"source/img/OS/banner.png","hash":"5e1af15d46ddb12a67b8583bfcd677542fd69d76","modified":1770097334712},{"_id":"source/img/PointCNN/knn.png","hash":"74ea4875a0500805ab5213a9672f3a672dcddd45","modified":1770097334722},{"_id":"source/img/PointCNN/conv.png","hash":"73bc365cdf5d5fa0d49a9d6cc31022bf07b4fbb0","modified":1770097334721},{"_id":"source/img/PointCNN/x_transformer.png","hash":"5ceda2ae38097bfe8e24da1295cc513215a0297d","modified":1770097334737},{"_id":"source/img/PointCNN/x_conv.png","hash":"cbe5888542801d1683deb17ddabbccd3ad9bf9d0","modified":1770097334735},{"_id":"source/img/PointCNN/time2.png","hash":"9a95680da0876d027509cb495feb81abcb59c6d0","modified":1770097334724},{"_id":"source/img/ICS_Lab1/bits_dlc.png","hash":"e8b818f78cd50dae1edd45dab9267c3069edbc02","modified":1770097334646},{"_id":"source/img/ICS_Lab1/bits_btest.JPG","hash":"647438ec455ecd7a47d6167eb2094f815f800d41","modified":1770097334639},{"_id":"source/img/ICS_Lab1/bits_honor_btest.JPG","hash":"8e1b2a958402a82be827e9d37272389e9d07b38c","modified":1770097334655},{"_id":"source/img/PointNet/result.png","hash":"2f05d38ce079e66a88ad024ccccfc861d00770c4","modified":1770097334743},{"_id":"source/img/DS/tree_差分.png","hash":"6a04a5222246a7860b3c6999f4ba2212e22024dc","modified":1770097334595},{"_id":"source/img/ICS_Lab2/upload_7194e52688ff3d696a3b889e2b17d63f.png","hash":"a12aa8b9911ff42e1c7fd341740bb5952026b617","modified":1770097334679},{"_id":"source/img/ICS_Lab2/upload_016df1440f7044a54fb4ced529595b58.png","hash":"4ed4e36ce65df848c9e45f7c8b417ec9c1b7db2a","modified":1770097334670},{"_id":"source/img/ICS_Lab2/upload_244e1f55d2823d58f65eabab9478d7ce.png","hash":"8fc4327e7e7b113cd61b14f62890d8debe0179eb","modified":1770097334672},{"_id":"source/img/ICS_Lab2/upload_27148224f8cf2be48266eaa52f50b2f8.png","hash":"f671afdbca16a239e220b637c08410e667950412","modified":1770097334676},{"_id":"source/img/Pic/PointCloud.jpg","hash":"0f07012fcae8097a4377d4a60bcddefb02ca139a","modified":1770097334719},{"_id":"source/img/PointNet++/res.png","hash":"88f91e34a67f37e751ff2e216cf5c086ae4cca7c","modified":1770097334740},{"_id":"source/img/NLP/banner.jpeg","hash":"d291cacacbe97bb88dadd0f006f92f5a8c1be8df","modified":1770097334708},{"_id":"source/img/ICS_Lab2/upload_64ed470376ec6b72dc43690bf9b4ea0e.png","hash":"70d23c7516d816392111cc32620a4ed82b9f6263","modified":1770097334677},{"_id":"source/img/hello_world/top.png","hash":"c61a20a651af82f4a2fd5e6f3724fc36e148fa07","modified":1770097334753},{"_id":"source/img/tcp.jpeg","hash":"14b8a165e3d6322fe0ad2ae11a61cba0f52621b8","modified":1770097334757},{"_id":"source/img/ICS_Lab2/upload_9ea5cd30293a18357af1da93c35e0f59.png","hash":"7321e52b83920d6f097ef999870bb72d3ece131a","modified":1770097334682},{"_id":"source/img/PointCNN/visual.png","hash":"ae127c6cee0dcd022cb3103ddddbed9faba59b11","modified":1770097334729},{"_id":"themes/fluid/source/css/_pages/_tag/tag.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097334795},{"_id":"themes/fluid/source/css/_pages/_category/category.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097334795},{"_id":"themes/fluid/.editorconfig","hash":"33218fbd623feb43edf5f99f15965392cecc44a6","modified":1770097334780},{"_id":"themes/fluid/.eslintrc","hash":"4bc2b19ce2b8c4d242f97d4ccf2d741e68ab0097","modified":1770097334780},{"_id":"themes/fluid/.gitignore","hash":"bd095eee271360a38772ee1a42d4f000fb722e5f","modified":1770097334782},{"_id":"themes/fluid/LICENSE","hash":"5b919c12e4f5f5cdebb7c17ded4f10f1ebe64811","modified":1770097334782},{"_id":"themes/fluid/README_en.md","hash":"ca8fd19a4948de1f253616a62c0e8a7d81f692f5","modified":1770097334782},{"_id":"themes/fluid/package.json","hash":"623e6f2dc876daa6ab599fbac4636f54782e6ea3","modified":1770097334789},{"_id":"themes/fluid/.gitattributes","hash":"a54f902957d49356376b59287b894b1a3d7a003f","modified":1770097334781},{"_id":"themes/fluid/README.md","hash":"ea55d234aeae3eb9e232f729f8411810d65c6f49","modified":1770097334782},{"_id":"themes/fluid/gulpfile.js","hash":"dc82b6be72c786721a2f5e2acc10a2a94995c540","modified":1770097334783},{"_id":"themes/fluid/languages/de.yml","hash":"13a6a799415fc2f6f69ebd1a399fb44426a5d641","modified":1770097334783},{"_id":"themes/fluid/languages/en.yml","hash":"a85dcc5cc21f9cab50df31e5001b8818ee62d1e2","modified":1770097334783},{"_id":"themes/fluid/languages/ja.yml","hash":"91020031a847c0361a6fd7ab990c7be4bf17529b","modified":1770097334783},{"_id":"themes/fluid/layout/404.ejs","hash":"689d9f4efd2a7f5edfd9b24561a7ade69d46617c","modified":1770097334783},{"_id":"themes/fluid/languages/zh-CN.yml","hash":"21307b4137c3d9b04bb58243747e75af0abc5a71","modified":1770097334783},{"_id":"themes/fluid/_config.yml","hash":"66854ca936b92e9aa1af82fa4ca0ec17b17e6002","modified":1770097334783},{"_id":"themes/fluid/layout/about.ejs","hash":"e3e2de8b0dc63ece51c324bb7942f240cdbfc7bf","modified":1770097334787},{"_id":"themes/fluid/layout/archive.ejs","hash":"472d0813ca5b88000a7bc6039f33b7e27b5a3216","modified":1770097334787},{"_id":"themes/fluid/layout/categories.ejs","hash":"6c4ab9fcdf5f7b58238bf06276b027075872c424","modified":1770097334788},{"_id":"themes/fluid/layout/layout.ejs","hash":"d772721214358a658cfacaecb194d9c6db971488","modified":1770097334788},{"_id":"themes/fluid/layout/links.ejs","hash":"6abd180ff4dd1d5d22e4c70328e3c7f83d174d9c","modified":1770097334788},{"_id":"themes/fluid/layout/category.ejs","hash":"58291dfec65c36889dfce0ddc603540b67e4c598","modified":1770097334788},{"_id":"themes/fluid/layout/page.ejs","hash":"8cab50ead4cdb992d35710147a9a5308fb5df290","modified":1770097334788},{"_id":"themes/fluid/layout/tag.ejs","hash":"0ad89eb7c92a822980fa9a85285e6d94ad845d1d","modified":1770097334789},{"_id":"themes/fluid/layout/tags.ejs","hash":"1d06af34b6cf1d8a20d2eb565e309326ceba309f","modified":1770097334789},{"_id":"themes/fluid/scripts/events/index.js","hash":"a6ab2c6d9f9ba58cd1fabb85c2817874246fd525","modified":1770097334789},{"_id":"themes/fluid/scripts/generators/pages.js","hash":"d9971f15fbb6b775e3d31a1b9b45011959395010","modified":1770097334790},{"_id":"themes/fluid/scripts/generators/local-search.js","hash":"fc2c50405b771b06b7f6cfc4e9de97b992691555","modified":1770097334790},{"_id":"themes/fluid/scripts/filters/locals.js","hash":"58d0fec976f6b1d35e7ea03edc45414088acf05c","modified":1770097334790},{"_id":"themes/fluid/.github/workflows/limit.yaml","hash":"f8bd2edeb4424ee7a055b31583445d5d5dff91a4","modified":1770097334781},{"_id":"themes/fluid/scripts/filters/post-filter.js","hash":"fd567dccd9ea8c158a5dae6847dd99e272c3f43c","modified":1770097334790},{"_id":"themes/fluid/scripts/helpers/export-config.js","hash":"2ec0e2c79de89886c67391d5e94b0f18b2a6021e","modified":1770097334790},{"_id":"themes/fluid/scripts/helpers/page.js","hash":"4607607445233b3029ef20ed5e91de0da0a7f9c5","modified":1770097334791},{"_id":"themes/fluid/scripts/helpers/url.js","hash":"99ab4551dc9c035abcc3bf4da5def2f63449d7ec","modified":1770097334791},{"_id":"themes/fluid/scripts/helpers/utils.js","hash":"9045f47c7a71aab39f16cffb3e3847b752c2e0f1","modified":1770097334791},{"_id":"themes/fluid/scripts/tags/button.js","hash":"3eb43a8cdea0a64576ad6b31b4df6c2bf5698d4c","modified":1770097334791},{"_id":"themes/fluid/.github/workflows/lint.yaml","hash":"bccd7961fa146dd5f0d70f77e7ab94e9f58d5bd3","modified":1770097334782},{"_id":"themes/fluid/scripts/tags/checkbox.js","hash":"63468f7875c09d9557fe8315afc97175745d9087","modified":1770097334791},{"_id":"themes/fluid/scripts/tags/label.js","hash":"f05a6d32cca79535b22907dc03edb9d3fa2d8176","modified":1770097334791},{"_id":"themes/fluid/scripts/tags/group-image.js","hash":"4aeebb797026f1df25646a5d69f7fde79b1bcd26","modified":1770097334791},{"_id":"themes/fluid/scripts/helpers/wordcount.js","hash":"e58d422eddb44c1be893f65f79f4c7feecfe6d5f","modified":1770097334791},{"_id":"themes/fluid/scripts/tags/note.js","hash":"0886cfe3f8589671a1d289495e359c20a9908080","modified":1770097334791},{"_id":"themes/fluid/scripts/utils/object.js","hash":"61e9555f99edcb23d55361c7154e23af33153ecb","modified":1770097334791},{"_id":"themes/fluid/scripts/utils/join-path.js","hash":"629e7deb3955f750c1cfa6fc773f412e020fcef4","modified":1770097334791},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/bug_report.md","hash":"8f20dca8a03aefd495d0550544f25d8c6e44333e","modified":1770097334781},{"_id":"themes/fluid/layout/index.ejs","hash":"58e994d28fd72d585d2e4c63d0c0fd3e61dd14b8","modified":1770097334788},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/bug_report_zh.md","hash":"5c5a5565bb13928bc92332d9b99b968673ea7dfb","modified":1770097334781},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/feature_request.md","hash":"d3a3204d9bb2b43a69c9cb0be59bada8cb91e412","modified":1770097334781},{"_id":"themes/fluid/source/css/main.styl","hash":"d5a8a59c8d1fd17d699a951e59c4ce9ae44c419d","modified":1770097334796},{"_id":"themes/fluid/layout/post.ejs","hash":"f334657509a9b8b4e05d425d3e5f47a1c21b7dd7","modified":1770097334789},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/question_zh.md","hash":"e24b470f7aa8044499a4f5e39634e5dc43899011","modified":1770097334781},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/feature_request_zh.md","hash":"a413dc14e4737dbcaa8fb797d37f85121ede6551","modified":1770097334781},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/question.md","hash":"ab5eab9e3ff889c4ba7fd82846e7f5b7ae15bebc","modified":1770097334781},{"_id":"themes/fluid/source/img/avatar.png","hash":"1253aaa9cbb596c5ce672553d09922f612c89ab1","modified":1770097334796},{"_id":"themes/fluid/source/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1770097334796},{"_id":"themes/fluid/source/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1770097334821},{"_id":"themes/fluid/source/img/default.png","hash":"7bb2b8ee07db305bcadee2985b81b942027ae940","modified":1770097334820},{"_id":"themes/fluid/source/js/color-schema.js","hash":"7d7444387e549e06a4a378706df92558de62e4e7","modified":1770097334821},{"_id":"themes/fluid/source/img/favicon.png","hash":"2defc5fd93898cf749f0ae180f5cf5df12448e6a","modified":1770097334820},{"_id":"themes/fluid/source/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1770097334821},{"_id":"themes/fluid/source/js/events.js","hash":"9b3a3dfdbc64e6b367ae2ebf7700ed611ecd0d47","modified":1770097334822},{"_id":"themes/fluid/source/js/boot.js","hash":"1aea6f229e2298c7c134e9f1cc94576cd3f30611","modified":1770097334821},{"_id":"themes/fluid/source/js/lazyload.js","hash":"0df461660bbd73a79f3125ba4e9bdbc856232e6b","modified":1770097334822},{"_id":"themes/fluid/source/js/local-search.js","hash":"13d5ef2fe68c49bd6096781034dbb26c190b5176","modified":1770097334823},{"_id":"themes/fluid/source/js/plugins.js","hash":"67d68cd2da25edbc98d433f34cf79039d5cdb082","modified":1770097334823},{"_id":"themes/fluid/source/js/debouncer.js","hash":"045f324777bdfb99d4c17b1806169f029f897a65","modified":1770097334822},{"_id":"themes/fluid/source/js/duration.js","hash":"3c20a17ff6eafdb6792f6dd10f25b855a6a891ca","modified":1770097334822},{"_id":"themes/fluid/source/js/utils.js","hash":"17ef83ebf76b262ce2cb09c49a15fb1522b82982","modified":1770097334823},{"_id":"themes/fluid/source/js/leancloud.js","hash":"23e567d77127f5787b0fc7091ddfa085c53b82f4","modified":1770097334822},{"_id":"themes/fluid/source/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1770097334824},{"_id":"themes/fluid/layout/_partial/beian.ejs","hash":"bed4ee45bec0f1f1d3ed469e3197bb8f5e0b684e","modified":1770097334783},{"_id":"themes/fluid/layout/_partial/css.ejs","hash":"ea590a8e8e48148335b94aebca2b73c19bd5f789","modified":1770097334785},{"_id":"themes/fluid/layout/_partial/archive-list.ejs","hash":"8723aa57f61134a2c1dc84cc7ea88ea366f4fda3","modified":1770097334783},{"_id":"themes/fluid/layout/_partial/head.ejs","hash":"ab70ddfcf7b14c7000130d1a2b54c75dde106d66","modified":1770097334786},{"_id":"themes/fluid/layout/_partial/nav.ejs","hash":"70490c67b7313ae305d39331238232fe62f094f1","modified":1770097334786},{"_id":"themes/fluid/layout/_partial/paginator.ejs","hash":"783eee847562ce14db8f723b4ae742fb69aaf620","modified":1770097334786},{"_id":"themes/fluid/layout/_partial/post-meta.ejs","hash":"3e0fa1731b6e54dbcf52ccf8e200e83dc4549bfa","modified":1770097334787},{"_id":"themes/fluid/layout/_partial/scripts.ejs","hash":"1d2ea9c4c905bc4b8e1c64c717246f583bd583ee","modified":1770097334787},{"_id":"themes/fluid/layout/_partial/footer.ejs","hash":"382bd3ee27bc6d90776fc9171a487ff208bc4caa","modified":1770097334785},{"_id":"themes/fluid/scripts/events/lib/footnote.js","hash":"3b2abc5f5e3b681874637e98e047dc4969eb1983","modified":1770097334789},{"_id":"themes/fluid/scripts/events/lib/hello.js","hash":"38f6953e430d452d6608dacc4895ca623b4844a5","modified":1770097334789},{"_id":"themes/fluid/scripts/events/lib/lazyload.js","hash":"0283128db63cc25b565d0da3c8a2120cc45626d1","modified":1770097334790},{"_id":"themes/fluid/layout/_partial/search.ejs","hash":"cdd7919fa01f6ef7ccc09938d662ff3d77f5d999","modified":1770097334787},{"_id":"themes/fluid/scripts/events/lib/highlight.js","hash":"96d56372cad997b09c26dbd29a19f917140c6ab0","modified":1770097334790},{"_id":"themes/fluid/scripts/events/lib/version.js","hash":"0250fb16c7c798afd1f7fc816163ea0728765568","modified":1770097334790},{"_id":"themes/fluid/scripts/events/lib/preset-configs.js","hash":"202459c9444b1ba967396db3625af261b0b19820","modified":1770097334790},{"_id":"themes/fluid/layout/_partial/statistics.ejs","hash":"920bc618d357d48d2b96f8758f6ae8f9488fc4d8","modified":1770097334787},{"_id":"themes/fluid/scripts/events/lib/merge-configs.js","hash":"2264bec80ba051a19ba80396618f3d0c22948f0b","modified":1770097334790},{"_id":"themes/fluid/source/css/_functions/base.styl","hash":"2e46f3f4e2c9fe34c1ff1c598738fc7349ae8188","modified":1770097334792},{"_id":"themes/fluid/source/css/_mixins/base.styl","hash":"542e306ee9494e8a78e44d6d7d409605d94caeb3","modified":1770097334792},{"_id":"themes/fluid/source/css/_variables/base.styl","hash":"fe96204aa2e7ee4f7f404c9e90752a8ff822d779","modified":1770097334796},{"_id":"themes/fluid/layout/_partial/toc.ejs","hash":"3d2fb5552f373e5a0c56bc356702d807bcbcb411","modified":1770097334787},{"_id":"themes/fluid/layout/_partial/plugins/analytics.ejs","hash":"557077a8825fffc0a2c7fe2b29f319287950244f","modified":1770097334786},{"_id":"themes/fluid/layout/_partial/plugins/local-search.ejs","hash":"1e9ed2dde3050b5a650d0e45b9f712a6279f8f0c","modified":1770097334786},{"_id":"themes/fluid/layout/_partial/plugins/math.ejs","hash":"76c4e0608ae362a265ac5e9c0fc49f75c1bc568e","modified":1770097334786},{"_id":"themes/fluid/layout/_partial/plugins/mermaid.ejs","hash":"10ed1f9a611449d37736e17c4e251127b38b3772","modified":1770097334786},{"_id":"themes/fluid/layout/_partial/plugins/nprogress.ejs","hash":"19245797dda67bc97d534a5c3f283ff6dfa8a321","modified":1770097334786},{"_id":"themes/fluid/layout/_partial/plugins/typed.ejs","hash":"ab71df2e56b60e8e193ff827e81704e5b358a977","modified":1770097334787},{"_id":"themes/fluid/layout/_partial/comments/gitalk.ejs","hash":"3cd99f13535e444fff65c97a1f60e838aeaadba6","modified":1770097334784},{"_id":"themes/fluid/layout/_partial/comments/disqus.ejs","hash":"335b52bfa1cdd671cec1c4d745216d8404b2df45","modified":1770097334784},{"_id":"themes/fluid/source/css/_pages/pages.styl","hash":"b8e887bc7fb3b765a1f8ec9448eff8603a41984f","modified":1770097334795},{"_id":"themes/fluid/layout/_partial/comments/livere.ejs","hash":"593649f7e3f86779649e078b69f6fdc584648d72","modified":1770097334784},{"_id":"themes/fluid/layout/_partial/comments/remark42.ejs","hash":"1e9c4364df5a0971087f779f87f33960e3674124","modified":1770097334785},{"_id":"themes/fluid/source/lib/hint/hint.min.css","hash":"b38df228460ebfb4c0b6085336ee2878fe85aafe","modified":1770097334823},{"_id":"themes/fluid/source/css/_pages/_about/about.styl","hash":"15d2786d00418e61022475194ad76445d68e27ea","modified":1770097334792},{"_id":"themes/fluid/layout/_partial/comments/changyan.ejs","hash":"1b42e725454f3ae8d3bff086afcc294ca2fdeb72","modified":1770097334784},{"_id":"themes/fluid/layout/_partial/comments/utterances.ejs","hash":"71239ad210d24ad10a01c339590a797062153e8a","modified":1770097334785},{"_id":"themes/fluid/source/css/_pages/_base/color-schema.styl","hash":"f7004d597163e0af7b9107b0be1df12f4c0a7bc0","modified":1770097334794},{"_id":"themes/fluid/layout/_partial/comments/valine.ejs","hash":"899664e8eea0e77ffcff436a24198ee2da750d11","modified":1770097334785},{"_id":"themes/fluid/source/css/_pages/_base/inline.styl","hash":"fab8441a0b8d8f9db6c8370013659c035345ae79","modified":1770097334794},{"_id":"themes/fluid/source/css/_pages/_base/keyframes.styl","hash":"94065ea50f5bef7566d184f2422f6ac20866ba22","modified":1770097334794},{"_id":"themes/fluid/source/css/_pages/_archive/archive.styl","hash":"6e6f22b664199772370b59ce1678b0c148b5849f","modified":1770097334792},{"_id":"themes/fluid/source/css/_pages/_base/base.styl","hash":"aa2528e71c290dc43b69dfbdcf4d8d6c258015a4","modified":1770097334794},{"_id":"themes/fluid/source/css/_pages/_index/index.styl","hash":"4304bab8ad087911cbf5025a41014fbb67f20b5a","modified":1770097334795},{"_id":"themes/fluid/source/css/_pages/_category/categories.styl","hash":"1ab7db37c2f7dc7ccdb994dcb41c16a4c8920397","modified":1770097334795},{"_id":"themes/fluid/source/css/_pages/_links/links.styl","hash":"cd4ebb1426abed9fda93b797b02c6d5dd71dc2a1","modified":1770097334795},{"_id":"themes/fluid/source/css/_pages/_post/tag_plugin.styl","hash":"cbb49a17fcc030029f0c2fbe1e056613109d1ecc","modified":1770097334795},{"_id":"themes/fluid/source/css/_pages/_base/rewrite.styl","hash":"94a8fb9c160386fce7dcd5ac886dee8cf3a4e750","modified":1770097334795},{"_id":"themes/fluid/source/css/_pages/_post/post.styl","hash":"cc991a481214bf02c54cef4535d98ca45f8729f9","modified":1770097334795},{"_id":"themes/fluid/layout/_partial/comments/twikoo.ejs","hash":"d7d689156a8d2a6b00b306bd30628fa961449135","modified":1770097334785},{"_id":"themes/fluid/source/css/_pages/_tag/tags.styl","hash":"65bfc01c76abc927fa1a23bf2422892b0d566c3f","modified":1770097334795},{"_id":"themes/fluid/source/css/_pages/_base/_widget/banner.styl","hash":"e3d4acfdf0647e89a7a88f53e754ea543641ae30","modified":1770097334793},{"_id":"themes/fluid/source/css/_pages/_base/_widget/copy-btn.styl","hash":"2c9e05a354d4be820646a1c99f814740f299ed37","modified":1770097334793},{"_id":"themes/fluid/source/css/_pages/_base/_widget/qrcode.styl","hash":"461d609a802a4f9aa9f492411ed8074813a956b7","modified":1770097334794},{"_id":"themes/fluid/source/css/_pages/_base/_widget/scroll-btn.styl","hash":"e4ad804ab26bdbf5b55abbc5548b6db395cfed04","modified":1770097334794},{"_id":"themes/fluid/source/css/_pages/_base/_widget/footnote.styl","hash":"ae9289cc89649af2042907f8a003303b987f3404","modified":1770097334793},{"_id":"themes/fluid/source/css/_pages/_base/_widget/search.styl","hash":"10f7e91a91e681fb9fe46f9df7707b9ef78707c8","modified":1770097334794},{"_id":"themes/fluid/source/css/_pages/_base/_widget/footer.styl","hash":"35539a1ce8476e75515015a06d01ec66e4af6834","modified":1770097334793},{"_id":"themes/fluid/source/css/_pages/_base/_widget/board.styl","hash":"32d90bcc8bf2fd5d8d78e86a567973d4b69bcfa1","modified":1770097334793},{"_id":"themes/fluid/source/css/_pages/_base/_widget/header.styl","hash":"7c8170d0e2de47570fe8ed523f10ee1c33138a9f","modified":1770097334794},{"_id":"themes/fluid/source/img/bg_in.jpg","hash":"32c81168dceca41a00e957ca40624fc88eacad49","modified":1770097334818},{"_id":"themes/fluid/source/img/bg.jpg","hash":"b538296f018be0191f38259344c965d36111c06d","modified":1770097334801},{"_id":"source/img/AI.png","hash":"5baef76d6c8f9acab85df7c2003fcfb59e0909df","modified":1770097334534},{"_id":"themes/fluid/source/img/bg2.jpg","hash":"e5b05a7511ac4e3de7cade9b7004392b2086f10c","modified":1770097334815},{"_id":"source/pdf/NER.pdf","hash":"f2d51552ad34ea9218fad357d70627a6ae575c12","modified":1770097334774},{"_id":"public/img/avatar.png","hash":"6a7b1a6305d9badcf7e6fa290822d24db66d5a79","modified":1770097473210},{"_id":"public/img/bg.jpg","hash":"2cf1f2e5430c2b62a98cfa02a744ad8abe0ffaca","modified":1770097473210},{"_id":"public/img/bg2.jpg","hash":"cdd6b748090207df3d26e72f0e47a0afb9966cc6","modified":1770097473210},{"_id":"public/img/bg_in.jpg","hash":"a4faedd145c78afd89a8079192f7cd3e720ff62d","modified":1770097473210},{"_id":"public/img/favicon.png","hash":"53e09faacf395db5264b862fbe2c71a53bc5caff","modified":1770097473210},{"_id":"public/js/duration.js","hash":"5088505f2bb43a2296163ff7be3657e4b3ebd14d","modified":1770097473210},{"_id":"public/img/AI.png","hash":"af71f146a5af8c48fedb443fb3358e7c6476c2b1","modified":1770097473210},{"_id":"public/img/Cs231n/top.jpg","hash":"fbbe6bd223376b9b4828028d41159c69645c349b","modified":1770097473210},{"_id":"public/img/TODO.png","hash":"b2a241f5aeea03ae071663e0f29c7e8ab79406df","modified":1770097473210},{"_id":"public/img/DS/tree_差分2.png","hash":"31bcbc813e8e7c2de7f0c3d9204f92bcc33327d5","modified":1770097473210},{"_id":"public/img/ICS_Lab2/upload_016df1440f7044a54fb4ced529595b58.png","hash":"682be76b2091933bfe6a32c335fa4cf12fd906d4","modified":1770097473210},{"_id":"public/img/ICS_Lab2/upload_244e1f55d2823d58f65eabab9478d7ce.png","hash":"1acdcd860d18409efb2b148b203d4dd59429a2d3","modified":1770097473210},{"_id":"public/img/ICS_Lab2/upload_27148224f8cf2be48266eaa52f50b2f8.png","hash":"ce02ba5a9afb01df23a232ca1be2b58b3dc07600","modified":1770097473210},{"_id":"public/img/ICS_Lab2/upload_4801c7e177c56f6e7299c273d0120988.png","hash":"b1453b17cdd6017fa1a4b2f15b4d7c3e3bd04dad","modified":1770097473210},{"_id":"public/img/ICS_Lab2/upload_64ed470376ec6b72dc43690bf9b4ea0e.png","hash":"455e08f18bdb7480fec8f9eec36a07112cd50222","modified":1770097473210},{"_id":"public/img/ICS_Lab2/upload_9ea5cd30293a18357af1da93c35e0f59.png","hash":"9f5c3bd03a64565c69c96c664de6988be31ef2a6","modified":1770097473210},{"_id":"public/img/ICS_Lab2/upload_a18a67d1b4dbfa16a7fd8800e3ee304b.png","hash":"b6ce237e7294ea20a3bcf72c12ad1f80d36512f1","modified":1770097473210},{"_id":"public/img/ICS_Lab2/upload_ae5e359c30ff5ccb9292a7472c39eb19.png","hash":"bc837c737ca5e301791b18d77bedd3cdca4d3911","modified":1770097473210},{"_id":"public/img/ICS_Lab2/upload_f2ecdd05728cbefbba59b068a29fdfdc.png","hash":"45b3ff0edbbaec32074d13d5113af9cadf42a3cb","modified":1770097473210},{"_id":"public/img/ICS_Lab2/upload_dfddd1801cd10c701dd2753164434977.png","hash":"382b338b925b4eed93c765598474ced5c1371be4","modified":1770097473210},{"_id":"public/img/OS/banner.png","hash":"2dcb3e0d9fd20fbcf64302389e739c762d830988","modified":1770097473210},{"_id":"public/img/Pic/DS.png","hash":"6c8a77a8204d628229366d85850c9637a4288a02","modified":1770097473210},{"_id":"public/img/Pic/PointCloud.jpg","hash":"158b83c208b3bf07e39a950967af21995a6a3e1d","modified":1770097473210},{"_id":"public/img/PointCNN/conv.png","hash":"d73e5d349ec34e54be3c424c9c6e6b158c06655f","modified":1770097473210},{"_id":"public/img/PointCNN/conv2.png","hash":"7b0c8da55f0d1bfcc5a05318f9d557a35e7679e4","modified":1770097473210},{"_id":"public/img/PointCNN/conv_a.png","hash":"28357c24a4973c99ee73ad52c7941dcbb203b243","modified":1770097473210},{"_id":"public/img/PointCNN/conv_b.png","hash":"cee933de85e54eccb934acda92bb8c2dcfd11d48","modified":1770097473210},{"_id":"public/img/PointCNN/knn.png","hash":"45e811efb4e1b6de265672fcf5646e29d0d17947","modified":1770097473210},{"_id":"public/img/PointCNN/time.png","hash":"449209e690652baefef37f46862b8595fdc3097b","modified":1770097473210},{"_id":"public/img/PointCNN/time2.png","hash":"7784db6177b652996cdd6514e125169757d017de","modified":1770097473210},{"_id":"public/img/PointCNN/visual.png","hash":"85649f84cf3f6f58a3f573fd0c733a1c25478ba8","modified":1770097473210},{"_id":"public/img/PointCNN/x_conv.png","hash":"8b1124241f1953aef83420e6353a6568af9311b5","modified":1770097473210},{"_id":"public/img/PointCNN/x_transformer.png","hash":"f5253a9da3725d4784f7599e5279178af8f6e101","modified":1770097473210},{"_id":"public/img/PointNet/result.png","hash":"c89d86e87e66b664ee24cc9bc946706523f659bd","modified":1770097473210},{"_id":"public/img/PointNet/symmetry _function.png","hash":"f1c056b7d2ae480f81a53ac34e6ca3f9c360c4c4","modified":1770097473210},{"_id":"public/img/PointNet++/res.png","hash":"6aaccc4998c3b2eee654eeda01d71898cd94d5c2","modified":1770097473210},{"_id":"public/img/hello_world/top.png","hash":"4ea85138860cc4c3498a793b922a1e71b503b1e3","modified":1770097473210},{"_id":"public/img/ICS_Lab1/bits_btest.JPG","hash":"c8fd1bf5a7fc21abe1a4285459a0022554a9065b","modified":1770097473210},{"_id":"public/img/ICS_Lab1/bits_dlc.png","hash":"84de4fd3d56cbbdb1b8776300b8937dedf0dfc55","modified":1770097473210},{"_id":"public/img/ICS_Lab1/bits_honor_btest.JPG","hash":"e6e8a3ee7d62f8a38308f3e4ebd048b8732a59c0","modified":1770097473210},{"_id":"public/img/ICS_Lab1/bits_honor_dlc.png","hash":"8cce0d1d29aac9d396adacf771f19aff0fc897d6","modified":1770097473210},{"_id":"public/img/ICS_Lab1/top.jpg","hash":"0e99aa0f3259a1b7a5138b545ae50b012ba0f129","modified":1770097473210},{"_id":"public/img/ICS_Lab2/upload_7194e52688ff3d696a3b889e2b17d63f.png","hash":"7511ff0c9c881dcfe169fa6641cc23b4b73e1cb6","modified":1770097473210},{"_id":"public/img/DS/tree_差分.png","hash":"43a2c723da6710036ebf5af47ce2c73e03685e6a","modified":1770097473210},{"_id":"public/local-search.xml","hash":"c4ed7ea663c0bea0a41fc0dee2c9bceff8b9f507","modified":1770097473210},{"_id":"public/2021/12/14/NLP/nlp-ner/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2021/11/24/NLP/nlp-sst/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2021/11/24/Network/rdt/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2021/11/15/OS/Unix/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2021/10/15/OS/Locality_Principle/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2021/10/15/OS/OS-Evolution-01/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2021/08/05/OS/Process/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2021/07/10/OS/MemAddressing/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2021/07/10/OS/kernelArc/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2021/07/05/Computation_Theory/note/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2021/05/22/ICS/MallocLab/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2021/05/21/ICS/Dynamic Memory Allocation/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2021/04/13/ICS/CacheLab/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2021/03/22/Readelf/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2021/03/09/Research/CaDDN-Paper/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2021/03/08/ICS/ICS_Normal/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2021/01/22/Research/DETR/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2021/01/06/ICS/ICS_PJ/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2020/12/17/final_todo/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2020/12/08/Research/PointCNN/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2020/12/08/Research/PointNetpp/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2020/12/07/DS/DataStructureNote2/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2020/12/06/Research/PointNet/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2020/12/05/DS/DataStructureNote1/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2020/11/27/Recent-Progress (2020-11-15 ~ 2020-11-27)/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2020/11/15/ICS/ICS_Lab3/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2020/11/13/CS231n/CS231n-06-Training-Neural-Networks-II/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2020/11/13/CS231n/CS231n-05-Training-Neural-Networks-I/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2020/11/11/CS231n/CS231n-04-Convolutional-Neural-Networks/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2020/11/10/CS231n/CS231n-03-Introduction-to-Convolutional-neural-network/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2020/11/08/CS231n/CS231n_02_Loss-Functions-and-Optimization/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2020/11/07/CS231n/CS231n_01_Image_Classification/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2020/11/06/ICS/ICS_Lab2/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2020/11/05/ICS/ICS_Lab1/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/2020/11/05/hello-world/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1770097473210},{"_id":"public/about/index.html","hash":"5fc76fa3eeb1d91e0d69578766f7d577709d0a2d","modified":1770097473210},{"_id":"public/archives/index.html","hash":"7921ec475bb84e840dbf41cd2e291a11e0fdaf64","modified":1770097473210},{"_id":"public/archives/page/2/index.html","hash":"a020920dc7093716cf4cfabf7fd58711bd779ce4","modified":1770097473210},{"_id":"public/archives/page/3/index.html","hash":"3138527e033ef1e09bade7622bce20a05a55135e","modified":1770097473210},{"_id":"public/archives/page/4/index.html","hash":"2a5fcd766f6e778b5ebdf13f63b4ff789ef733b7","modified":1770097473210},{"_id":"public/archives/2020/index.html","hash":"87ef26d67970135ba25c7f9a3449b5d255755bd0","modified":1770097473210},{"_id":"public/archives/2020/page/2/index.html","hash":"37c450381029e2a5fa7bb541a069aac36adff335","modified":1770097473210},{"_id":"public/archives/2020/11/index.html","hash":"2c84b35ebf3676b46018755b5fa54780276040d1","modified":1770097473210},{"_id":"public/archives/2020/11/page/2/index.html","hash":"83e341b31092680323dbdaa3418a02139e6875c3","modified":1770097473210},{"_id":"public/archives/2020/12/index.html","hash":"ce7b22823149c0c642cd3069b08fea9c2e97822b","modified":1770097473210},{"_id":"public/archives/2021/index.html","hash":"d08f9b2ebe6608f52ccee073ea6865a19a212432","modified":1770097473210},{"_id":"public/archives/2021/page/2/index.html","hash":"68c5c06192585c11f2efe82497ab5c67d0046b2b","modified":1770097473210},{"_id":"public/archives/2021/01/index.html","hash":"723e1ed5349383ef9e2c939df6f49c8c08a84a85","modified":1770097473210},{"_id":"public/archives/2021/03/index.html","hash":"786191b50995edb4470977d165b91a8898800dcb","modified":1770097473210},{"_id":"public/archives/2021/04/index.html","hash":"dad9ba6cae77603a524d9af4a0f26d471209da0e","modified":1770097473210},{"_id":"public/archives/2021/05/index.html","hash":"b1e9e03db7d2142b54c9ea2140bd015c039fbd77","modified":1770097473210},{"_id":"public/archives/2021/07/index.html","hash":"a22419b1095c9f3e05e59ad53e726075d576158d","modified":1770097473210},{"_id":"public/archives/2021/08/index.html","hash":"29b0c628c81c082548c44976533c547f5e0f9e44","modified":1770097473210},{"_id":"public/archives/2021/10/index.html","hash":"e46fb0bac4194c55cfc6756c9fb7781e1a351ede","modified":1770097473210},{"_id":"public/archives/2021/11/index.html","hash":"c4cc4a1a43c67ecb7f8a1078c0f3c750d68bc946","modified":1770097473210},{"_id":"public/archives/2021/12/index.html","hash":"2743611f212fd511e40117b4210d265413ca1e0e","modified":1770097473210},{"_id":"public/categories/TODO/index.html","hash":"73a93eb49a2697717fb6edb220e549c90c4eea83","modified":1770097473210},{"_id":"public/categories/Summary/index.html","hash":"c6cf88593b67cbb033bf4e170ae06365f0aed24e","modified":1770097473210},{"_id":"public/categories/CS231n/index.html","hash":"f11ac887c2ae09d57c15d9aad164cd4cce7ff787","modified":1770097473210},{"_id":"public/categories/ICS/index.html","hash":"4800a22308b2a81d1313ab9e9f7fde6b9a288ea1","modified":1770097473210},{"_id":"public/categories/DataStructure/index.html","hash":"bf365c3e3215bb625a41011bd7e51d39beb4005f","modified":1770097473210},{"_id":"public/categories/NLP/index.html","hash":"c08b6bd992453b7403acc8d97767e65556402359","modified":1770097473210},{"_id":"public/categories/OS/index.html","hash":"ad486e148e49f2c74eedd32a1d89672b00e6224b","modified":1770097473210},{"_id":"public/categories/Computation-Theory/index.html","hash":"8fce078964aa0665cf959a773ecb5f712157972b","modified":1770097473210},{"_id":"public/categories/Research/index.html","hash":"c64e27f00fdc195b31349c842d93e1a72af049f0","modified":1770097473210},{"_id":"public/categories/Network/index.html","hash":"1692d9da5f23905e96af51c005843d742c20433b","modified":1770097473210},{"_id":"public/categories/Research/Object-Detection/index.html","hash":"ac3b81475741ce4570d1cd1cd2fa9163f297a231","modified":1770097473210},{"_id":"public/index.html","hash":"0b86a544474ce8efe7eba23e84ef16f57702e606","modified":1770097473210},{"_id":"public/page/2/index.html","hash":"babb559c908fc3c37abf8281484b15187a41a557","modified":1770097473210},{"_id":"public/page/3/index.html","hash":"90b0650cb81d2a15624242c88f4b9e80dca3ff64","modified":1770097473210},{"_id":"public/page/4/index.html","hash":"128e6b23fae803f4b2c5ac3bc188654fc2c1b6cd","modified":1770097473210},{"_id":"public/tags/Summary/index.html","hash":"64a16d2e4d3b321bf85fc90fa6fc6bdc72ecc5f3","modified":1770097473210},{"_id":"public/tags/TODO/index.html","hash":"316bfd37a7cfc519ef71d45e216697a39ad233b8","modified":1770097473210},{"_id":"public/tags/Hexo/index.html","hash":"4d0d1278dab42bf0066db2a61170a4d9a7f13633","modified":1770097473210},{"_id":"public/tags/Fluid/index.html","hash":"96ae44329dc287bf6a564c39ce8724e7897d9683","modified":1770097473210},{"_id":"public/tags/CV/index.html","hash":"a11a650fbefaac59aba4fb6e4a9026406b9a5954","modified":1770097473210},{"_id":"public/tags/Neural-Network/index.html","hash":"7e495bdb1210c3eb96cf5099a0b935d0b5283cab","modified":1770097473210},{"_id":"public/tags/Link/index.html","hash":"418876d3f137a581a298fec906d1b848a267f23c","modified":1770097473210},{"_id":"public/tags/LCA/index.html","hash":"b28bb513982ba42bb665c373b27b5df559807604","modified":1770097473210},{"_id":"public/tags/UFS/index.html","hash":"b946cc56853459e2b96bd7b22cd90a804293cb75","modified":1770097473210},{"_id":"public/tags/Number-theory/index.html","hash":"4c1ea032702517c80c8e081fcef7c59a7fa8e473","modified":1770097473210},{"_id":"public/tags/Multiplication-algorithm/index.html","hash":"b6c6bea83eb9b781c41f7dfc97017a3f7412507a","modified":1770097473210},{"_id":"public/tags/NER/index.html","hash":"cef80505168f30515e496e236ce945b272d3ae47","modified":1770097473210},{"_id":"public/tags/BIO/index.html","hash":"67d8dd59949de4aa5211b1dcc69d00b49fca6e09","modified":1770097473210},{"_id":"public/tags/Cache/index.html","hash":"576174c4e13740ec5f352d3b380e2e88f98cd29e","modified":1770097473210},{"_id":"public/tags/Malloc/index.html","hash":"c042590bb67bc728a6ff4457a036c09c35b9dabd","modified":1770097473210},{"_id":"public/tags/VM/index.html","hash":"7556d843316f47bc13a388eadb9dd04121316df9","modified":1770097473210},{"_id":"public/tags/Assembly/index.html","hash":"b8386f4a28d82f545c202ce7ffa08e9339e706ca","modified":1770097473210},{"_id":"public/tags/SST/index.html","hash":"d59adfea2067ffe9cdc41a996a49e63fe41b683b","modified":1770097473210},{"_id":"public/tags/Sentiment-Classification/index.html","hash":"cc3e479d544592b088014864b3c6feaf24ceaf93","modified":1770097473210},{"_id":"public/tags/Bits/index.html","hash":"7d1ee26d83ba4f112473bdefd362d621e10b9c1e","modified":1770097473210},{"_id":"public/tags/Linker/index.html","hash":"3f544356b4093f7c12a20ab222bd2b7783cc6de4","modified":1770097473210},{"_id":"public/tags/Sort/index.html","hash":"ccb4396469112d838e6414c7e93eb3ac7ddd4f43","modified":1770097473210},{"_id":"public/tags/CPU/index.html","hash":"76ca429b889171dd826c026e2713a21731a1c038","modified":1770097473210},{"_id":"public/tags/OS/index.html","hash":"34ae8b0f14ad431492376e07be214d8843f35435","modified":1770097473210},{"_id":"public/tags/P-NP/index.html","hash":"07a44eb616c276989bc1707be8155d145895a434","modified":1770097473210},{"_id":"public/tags/Computation-Complexity/index.html","hash":"71a04ca3ea7e06ffd09e4e94d24c7519947d05fb","modified":1770097473210},{"_id":"public/tags/kernel/index.html","hash":"4ce56a5d28771bf5d6e406fc52b2081513685b69","modified":1770097473210},{"_id":"public/tags/memory-addressing/index.html","hash":"a1c101d321457e53d50f0a05aea66f5637677b63","modified":1770097473210},{"_id":"public/tags/Monocular-OD/index.html","hash":"a85909a3aff1f7970d6b1d60327ae8a8c891c7ab","modified":1770097473210},{"_id":"public/tags/process/index.html","hash":"d3aea97ecf273e4311affcff0b8cc38d54b1c3cb","modified":1770097473210},{"_id":"public/tags/RDT/index.html","hash":"18bee2384efc845983193de0024bc4bb02bbe3c3","modified":1770097473210},{"_id":"public/tags/GBN/index.html","hash":"6cad31de06dd19e1ca25cbaec79eb0c702b0069e","modified":1770097473210},{"_id":"public/tags/SR/index.html","hash":"1fd3d216203f23412fc9b5b711246e781f02ccf8","modified":1770097473210},{"_id":"public/tags/PointCNN/index.html","hash":"8399fc9b9b35b13ae77aeec07e2db7f467f8763f","modified":1770097473210},{"_id":"public/tags/PointNet/index.html","hash":"d885eb1de07c92c2b5db007490eff58b820db7d1","modified":1770097473210},{"_id":"public/tags/Transformer/index.html","hash":"28e951aac9d3355b2975f1dcbfb01e99a1d3d742","modified":1770097473210},{"_id":"public/404.html","hash":"72570e8c8ac01173023490a8e31354112595d8ff","modified":1770097473210},{"_id":"public/tags/index.html","hash":"b53960bdd5a19657d01484371663175a901272d1","modified":1770097473210},{"_id":"public/categories/index.html","hash":"3502d1556a19365c50c4e5c8dcb58d6a998c5045","modified":1770097473210},{"_id":"public/links/index.html","hash":"c5fd503552d0c30167d629415bb9eead0191fb56","modified":1770097473210},{"_id":"public/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1770097473210},{"_id":"public/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1770097473210},{"_id":"public/img/default.png","hash":"7bb2b8ee07db305bcadee2985b81b942027ae940","modified":1770097473210},{"_id":"public/CNAME","hash":"51544cd37f2188326b08d74bd5b18cde71d558ac","modified":1770097473210},{"_id":"public/img/PNP.webp","hash":"2241713d4bfac01da4c1ad70d73fb82494abce61","modified":1770097473210},{"_id":"public/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1770097473210},{"_id":"public/img/Pic/Recent.jpeg","hash":"a894cbfcd2ef37457d03c1eafd83b50842fffdbc","modified":1770097473210},{"_id":"public/img/Pic/cnn_img.jpeg","hash":"7ceabac10778f93a977196eb371197062cff2319","modified":1770097473210},{"_id":"public/css/gitalk.css","hash":"2234d7496740d11b5b53aaaef9155dcb2c6f3f73","modified":1770097473210},{"_id":"public/css/main.css","hash":"27e7b83f06a31af2b6c05e01def2ea87ab147eca","modified":1770097473210},{"_id":"public/js/boot.js","hash":"bb6780447ebeaa69a3cc08b6c0b1a8ddb39d5fbd","modified":1770097473210},{"_id":"public/js/color-schema.js","hash":"0d15189ddd7b9eadf856c726358ac0ac5b24a2ee","modified":1770097473210},{"_id":"public/js/events.js","hash":"2b5943b81b257c170658906cc3fa73c80f99c3e4","modified":1770097473210},{"_id":"public/js/lazyload.js","hash":"162f6b8b4e0ac35d67ced30f5ba3bf16fa3c89e8","modified":1770097473210},{"_id":"public/js/plugins.js","hash":"1096ab2d770ac6450cc682fdf987275aaf3f9e69","modified":1770097473210},{"_id":"public/js/debouncer.js","hash":"f195b7b767cb7e902290ef1252115b9684ce239b","modified":1770097473210},{"_id":"public/js/utils.js","hash":"7667875eba3e6124b06b291ff47ba9f618e0e520","modified":1770097473210},{"_id":"public/js/leancloud.js","hash":"d16e63e407cd309467934e7d184b33bccfb30853","modified":1770097473210},{"_id":"public/js/local-search.js","hash":"0746ac1df8338b977823148298b4bba2addf0b91","modified":1770097473210},{"_id":"public/lib/hint/hint.min.css","hash":"b38df228460ebfb4c0b6085336ee2878fe85aafe","modified":1770097473210},{"_id":"public/img/NLP/banner.jpeg","hash":"d291cacacbe97bb88dadd0f006f92f5a8c1be8df","modified":1770097473210},{"_id":"public/img/tcp.jpeg","hash":"14b8a165e3d6322fe0ad2ae11a61cba0f52621b8","modified":1770097473210},{"_id":"public/pdf/NER.pdf","hash":"f2d51552ad34ea9218fad357d70627a6ae575c12","modified":1770097473210}],"Category":[{"name":"Summary","_id":"cml66bzv700047uitdnxhgskk"},{"name":"TODO","_id":"cml66bzv800097uit3jav6ejx"},{"name":"CS231n","_id":"cml66bzv9000f7uit4lt7a9dp"},{"name":"ICS","_id":"cml66bzva000l7uit3uf8b46y"},{"name":"DataStructure","_id":"cml66bzvc00147uit2rsdhpmh"},{"name":"NLP","_id":"cml66bzvd001i7uit2iy7c2l7"},{"name":"OS","_id":"cml66bzvi003b7uit8cee60z1"},{"name":"Computation Theory","_id":"cml66bzvj003j7uit5cd15rzs"},{"name":"Research","_id":"cml66bzvk003w7uit5b3hc53b"},{"name":"Network","_id":"cml66bzvl00437uit5lpc6myt"},{"name":"Object Detection","parent":"cml66bzvk003w7uit5b3hc53b","_id":"cml66bzvl00497uitbfa4e6nn"}],"Data":[],"Page":[{"_content":"!(function() {\n    function update() {\n      var now = new Date();\n      var grt = new Date(\"2020-11-05 00:00:00\");  /** 此处是计时的起始时间 **/\n      now.setTime(now.getTime()+250);\n      days = (now - grt ) / 1000 / 60 / 60 / 24;\n      dnum = Math.floor(days);\n      hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum);\n      hnum = Math.floor(hours);\n      if(String(hnum).length === 1 ){\n        hnum = \"0\" + hnum;\n      }\n      minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);\n      mnum = Math.floor(minutes);\n      if(String(mnum).length === 1 ){\n        mnum = \"0\" + mnum;\n      }\n      seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);\n      snum = Math.round(seconds);\n      if(String(snum).length === 1 ){\n        snum = \"0\" + snum;\n      }\n      document.getElementById(\"timeDate\").innerHTML = \"本站已运行&nbsp\"+dnum+\"&nbsp天\";\n      document.getElementById(\"times\").innerHTML = hnum + \"&nbsp小时&nbsp\" + mnum + \"&nbsp分&nbsp\" + snum + \"&nbsp秒\";\n    }\n    setInterval(update, 1000);\n  })();","source":"js/duration.js","raw":"!(function() {\n    function update() {\n      var now = new Date();\n      var grt = new Date(\"2020-11-05 00:00:00\");  /** 此处是计时的起始时间 **/\n      now.setTime(now.getTime()+250);\n      days = (now - grt ) / 1000 / 60 / 60 / 24;\n      dnum = Math.floor(days);\n      hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum);\n      hnum = Math.floor(hours);\n      if(String(hnum).length === 1 ){\n        hnum = \"0\" + hnum;\n      }\n      minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);\n      mnum = Math.floor(minutes);\n      if(String(mnum).length === 1 ){\n        mnum = \"0\" + mnum;\n      }\n      seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);\n      snum = Math.round(seconds);\n      if(String(snum).length === 1 ){\n        snum = \"0\" + snum;\n      }\n      document.getElementById(\"timeDate\").innerHTML = \"本站已运行&nbsp\"+dnum+\"&nbsp天\";\n      document.getElementById(\"times\").innerHTML = hnum + \"&nbsp小时&nbsp\" + mnum + \"&nbsp分&nbsp\" + snum + \"&nbsp秒\";\n    }\n    setInterval(update, 1000);\n  })();","date":"2026-02-03T05:42:14.757Z","updated":"2026-02-03T05:42:14.757Z","path":"js/duration.js","layout":"false","title":"","comments":1,"_id":"cml66bzv300007uiteupf01q5","content":"!function(){setInterval(function(){var n=new Date,m=new Date(\"2020-11-05 00:00:00\");n.setTime(n.getTime()+250),days=(n-m)/1e3/60/60/24,dnum=Math.floor(days),hours=(n-m)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1===String(hnum).length&&(hnum=\"0\"+hnum),minutes=(n-m)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1===String(mnum).length&&(mnum=\"0\"+mnum),seconds=(n-m)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1===String(snum).length&&(snum=\"0\"+snum),document.getElementById(\"timeDate\").innerHTML=\"本站已运行&nbsp\"+dnum+\"&nbsp天\",document.getElementById(\"times\").innerHTML=hnum+\"&nbsp小时&nbsp\"+mnum+\"&nbsp分&nbsp\"+snum+\"&nbsp秒\"},1e3)}();","site":{"data":{}},"excerpt":"","more":"!function(){setInterval(function(){var n=new Date,m=new Date(\"2020-11-05 00:00:00\");n.setTime(n.getTime()+250),days=(n-m)/1e3/60/60/24,dnum=Math.floor(days),hours=(n-m)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1===String(hnum).length&&(hnum=\"0\"+hnum),minutes=(n-m)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1===String(mnum).length&&(mnum=\"0\"+mnum),seconds=(n-m)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1===String(snum).length&&(snum=\"0\"+snum),document.getElementById(\"timeDate\").innerHTML=\"本站已运行&nbsp\"+dnum+\"&nbsp天\",document.getElementById(\"times\").innerHTML=hnum+\"&nbsp小时&nbsp\"+mnum+\"&nbsp分&nbsp\"+snum+\"&nbsp秒\"},1e3)}();"},{"title":"about","date":"2020-02-24T03:20:33.000Z","layout":"about","_content":"\n","source":"about/index.md","raw":"---\ntitle: about\ndate: 2020-02-23 19:20:33\nlayout: about\n---\n\n","updated":"2026-02-03T05:42:14.453Z","path":"about/index.html","comments":1,"_id":"cml66bzv600027uit50gxbreu","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"近期进展 (2020-11-15 ~ 2020-11-27)","index_img":"/img/Pic/Recent.jpeg","date":"2020-11-27T22:45:21.000Z","_content":"\n# 最近进展\n\n近来比较忙，一直没时间写博客，就暂将这段时间的进展写作一个综述发在博客上\n\n---\n\n## **学业方面**\n### 数据结构 - DataStructure\n数据结构这几周以来都是学的树相关的操作, 对树的相关操作进行了学习和进一步的探究\n\n#### 已经掌握\n\n##### 树的储存\n1. 邻接表形式\n```cpp\nstd::vector<int> Tree[Max]\n```\n\n1. 链式前向星形式\n```cpp\nstruct edge\n{\n    int v;\n    int w;\n    int nex;\n};\n\nedge e[Max];\nint head[Max], cnt = 0; // init -1\n\nvoid add_edge(int u, int v)\n{\n    e[cnt].v = v;\n    e[cnt].w = w;\n    e[cnt].nex = head[u];\n    head[u] = cnt++;\n}\n\n//遍历方式\nfor(int i = head[u]; i != -1; i = e[i].nex)\n```\n> 邻接表相比链式前向星更为动态，但有些阴间题会卡掉邻接表\n\n---\n\n##### 深度优先搜索 (dfs)\n\n基本原则是一种与广度优先搜索对立的，能搜到子节点就往子节点走的搜索方式，既“深度”优先，我们熟知的二叉树的前序和后序遍历都是深度优先搜索的一种。\n\n1. 代码实现 (邻接表形式)\n    ```cpp\n    void dfs(int u, int fa)\n    {\n        for(auto& v : tree[u])\n        {\n            if(v == fa)\n                continue;\n            dfs(v, u)\n        }\n    }\n    ```\n    其中 dfs(v,u) 是 dfs 的精华， 指代如若没搜到叶节点那么则继续向深度搜索，这时候当前节点的子节点作为下一个节点，而当前节点成为其子节点的父节点，因而有从 dfs(u, fa) 到 dfs(v, u) 的向深度搜索\n\n2. 前序遍历 - PreOrder (先出根再出子节点)\n    ```cpp\n    void preOrder(TreeNode* root)\n    {\n        if(!root)\n            return;\n        printf(\"%d\\n\", root->val);\n        for(auto child : root->children)\n            preOrder(root->child)    //递归子树\n    }\n    ```\n\n3. 后序遍历 - PosOrder (先出子节点再出根)\n    ```cpp\n    void posOrder(TreeNode* root)\n    {\n        if(!root)\n            return;\n        for(auto child : root->children)\n            preOrder(root->child)    //递归子树\n        printf(\"%d\\n\", root->val);\n    }\n    ```\n\n 通过两次 dfs 我们可以求树的直径，一次 dfs 到直径的端点，再一次求出直径长度。\n\ndfs 所使用的数据结构是栈，这种数据结构隐含在函数的递归调用中，而对于 bfs 所使用的数据结构是队列，我们就需要\n\n---\n\n##### 广(宽)度优先搜索 (bfs)\nbfs 不同于 dfs 是深度优先的搜索，bfs是将同层的节点全部搜索过后再进入到下一次，既注重 \"广度\" 的搜索模式\n\n1. 代码实现 (邻接表形式)\n```cpp\nbfs(s) \n{\n    q = new queue();\n    q.push(s), visited[s] = true;\n    while (!q.empty()) \n    {\n        u = q.pop();\n        for(auto& v : tree[u])\n        {\n            if (!visited[v]) \n            {\n                q.push(v);\n                visited[v] = true;\n            }\n        }\n    }\n}\n```\n\n1. 层序遍历\n    层序遍历就是一种典型的 bfs，先将同层的打印出来之后再深入一层，代码同上。当然也可以通过 dfs 实现层序这时候就要区分节点的层数\n\n```cpp\n//dfs版本层序\nvector<vector<int> > ans;\nvoid dfs(int u, int fa, int level)\n{\n    if(level > ans.size())\n        ans.emplace_back(vector<int>())\n    ans[level - 1].emplace_back(u);\n    for(auto& v : tree[u])\n    {\n        if(v == fa)\n            continue;\n        dfs(v, u, level + 1)\n    }\n}\n```\n\n---\n\n##### 树形dp\n树形dp，顾名思义是在树上进行的dp，在dfs或bfs的过程中进行动态更新。例如通过树形dp求树的直径\n\n```cpp\nint dfs(int u, int fa)\n{\n    vis[x] = 1;\n    int d1 = 0, d2 = 0;\n    int tmp = 0;\n    for(auto& v : tree[u])\n    {\n        if(v == fa)\n            continue;\n        tmp = dfs(v, u) + 1;\n        if(tmp > d1)\n        {\n            d2 = d1;\n            d1 = tmp;\n        }\n        else if(tmp > d2)\n            d2 = tmp;\n        d = max(d, d1 + d2);\n    }\n    return max;\n}\n```\n\n---\n\n#### **尚未熟练 - TODO**\n  1. LCA问题\n  2. 树状数组\n  3. 线段树\n  4. 树链剖分\n\n---\n\n### 计算机系统 - ICS\n\n最近布置了 y86-64 的 PJ，学习了 CPU 的顺序以及流水线设计模式，开始做PJ。\n\n#### PJ进展:\n##### 设计模式 - C with Class\n在面向过程的 Fetch -> Decode -> Execute -> Memory -> WriteBack 基础上套instr的类壳\n\n##### 后端进度\n1. 完成了Prototype设计\n    - 目前 CC 的 OF 有一点 BUG\n2. 完成了 UniTest 的 Generater\n    - 准备用宏改为 gtest 移植到cpp上\n- TODO:\n    1. 完成 python 到 cpp 的移植\n    2. 尝试添加寄存器\n    3. 实现硬件栈\n  \n##### 前端进度\nTODO中，思考如何设计\n- 可选方案:\n  1. Python 作为中间件用 jinja 模板替换\n  2. C++ 作为后端 js 前端接口（学习中）\n  3. CGI\n\n---\n\n## 科研进度 - CNN\n\n### 目前方向\n3D Instance Segmentation\n\n### 论文收集\n 1. (RDCNet)mini ResNet in 2d Instance Seg\n 2. Attention Based 3d instance segmentation\n 3. Learning Gaussian Instance Segmentation in Point Clouds\n 4. 3D Sementic & Instance Segmentation via Salient Point Clustering Optimization\n\n### TODO\n1. 实现 ResNet Backbone\n2. 复现 Fast R-CNN & Mask R-CNN\n","source":"_posts/Recent-Progress (2020-11-15 ~ 2020-11-27).md","raw":"---\ntitle: 近期进展 (2020-11-15 ~ 2020-11-27)\nindex_img: /img/Pic/Recent.jpeg\ndate: 2020-11-27 14:45:21\ncategory: [Summary]\ntags: Summary\n---\n\n# 最近进展\n\n近来比较忙，一直没时间写博客，就暂将这段时间的进展写作一个综述发在博客上\n\n---\n\n## **学业方面**\n### 数据结构 - DataStructure\n数据结构这几周以来都是学的树相关的操作, 对树的相关操作进行了学习和进一步的探究\n\n#### 已经掌握\n\n##### 树的储存\n1. 邻接表形式\n```cpp\nstd::vector<int> Tree[Max]\n```\n\n1. 链式前向星形式\n```cpp\nstruct edge\n{\n    int v;\n    int w;\n    int nex;\n};\n\nedge e[Max];\nint head[Max], cnt = 0; // init -1\n\nvoid add_edge(int u, int v)\n{\n    e[cnt].v = v;\n    e[cnt].w = w;\n    e[cnt].nex = head[u];\n    head[u] = cnt++;\n}\n\n//遍历方式\nfor(int i = head[u]; i != -1; i = e[i].nex)\n```\n> 邻接表相比链式前向星更为动态，但有些阴间题会卡掉邻接表\n\n---\n\n##### 深度优先搜索 (dfs)\n\n基本原则是一种与广度优先搜索对立的，能搜到子节点就往子节点走的搜索方式，既“深度”优先，我们熟知的二叉树的前序和后序遍历都是深度优先搜索的一种。\n\n1. 代码实现 (邻接表形式)\n    ```cpp\n    void dfs(int u, int fa)\n    {\n        for(auto& v : tree[u])\n        {\n            if(v == fa)\n                continue;\n            dfs(v, u)\n        }\n    }\n    ```\n    其中 dfs(v,u) 是 dfs 的精华， 指代如若没搜到叶节点那么则继续向深度搜索，这时候当前节点的子节点作为下一个节点，而当前节点成为其子节点的父节点，因而有从 dfs(u, fa) 到 dfs(v, u) 的向深度搜索\n\n2. 前序遍历 - PreOrder (先出根再出子节点)\n    ```cpp\n    void preOrder(TreeNode* root)\n    {\n        if(!root)\n            return;\n        printf(\"%d\\n\", root->val);\n        for(auto child : root->children)\n            preOrder(root->child)    //递归子树\n    }\n    ```\n\n3. 后序遍历 - PosOrder (先出子节点再出根)\n    ```cpp\n    void posOrder(TreeNode* root)\n    {\n        if(!root)\n            return;\n        for(auto child : root->children)\n            preOrder(root->child)    //递归子树\n        printf(\"%d\\n\", root->val);\n    }\n    ```\n\n 通过两次 dfs 我们可以求树的直径，一次 dfs 到直径的端点，再一次求出直径长度。\n\ndfs 所使用的数据结构是栈，这种数据结构隐含在函数的递归调用中，而对于 bfs 所使用的数据结构是队列，我们就需要\n\n---\n\n##### 广(宽)度优先搜索 (bfs)\nbfs 不同于 dfs 是深度优先的搜索，bfs是将同层的节点全部搜索过后再进入到下一次，既注重 \"广度\" 的搜索模式\n\n1. 代码实现 (邻接表形式)\n```cpp\nbfs(s) \n{\n    q = new queue();\n    q.push(s), visited[s] = true;\n    while (!q.empty()) \n    {\n        u = q.pop();\n        for(auto& v : tree[u])\n        {\n            if (!visited[v]) \n            {\n                q.push(v);\n                visited[v] = true;\n            }\n        }\n    }\n}\n```\n\n1. 层序遍历\n    层序遍历就是一种典型的 bfs，先将同层的打印出来之后再深入一层，代码同上。当然也可以通过 dfs 实现层序这时候就要区分节点的层数\n\n```cpp\n//dfs版本层序\nvector<vector<int> > ans;\nvoid dfs(int u, int fa, int level)\n{\n    if(level > ans.size())\n        ans.emplace_back(vector<int>())\n    ans[level - 1].emplace_back(u);\n    for(auto& v : tree[u])\n    {\n        if(v == fa)\n            continue;\n        dfs(v, u, level + 1)\n    }\n}\n```\n\n---\n\n##### 树形dp\n树形dp，顾名思义是在树上进行的dp，在dfs或bfs的过程中进行动态更新。例如通过树形dp求树的直径\n\n```cpp\nint dfs(int u, int fa)\n{\n    vis[x] = 1;\n    int d1 = 0, d2 = 0;\n    int tmp = 0;\n    for(auto& v : tree[u])\n    {\n        if(v == fa)\n            continue;\n        tmp = dfs(v, u) + 1;\n        if(tmp > d1)\n        {\n            d2 = d1;\n            d1 = tmp;\n        }\n        else if(tmp > d2)\n            d2 = tmp;\n        d = max(d, d1 + d2);\n    }\n    return max;\n}\n```\n\n---\n\n#### **尚未熟练 - TODO**\n  1. LCA问题\n  2. 树状数组\n  3. 线段树\n  4. 树链剖分\n\n---\n\n### 计算机系统 - ICS\n\n最近布置了 y86-64 的 PJ，学习了 CPU 的顺序以及流水线设计模式，开始做PJ。\n\n#### PJ进展:\n##### 设计模式 - C with Class\n在面向过程的 Fetch -> Decode -> Execute -> Memory -> WriteBack 基础上套instr的类壳\n\n##### 后端进度\n1. 完成了Prototype设计\n    - 目前 CC 的 OF 有一点 BUG\n2. 完成了 UniTest 的 Generater\n    - 准备用宏改为 gtest 移植到cpp上\n- TODO:\n    1. 完成 python 到 cpp 的移植\n    2. 尝试添加寄存器\n    3. 实现硬件栈\n  \n##### 前端进度\nTODO中，思考如何设计\n- 可选方案:\n  1. Python 作为中间件用 jinja 模板替换\n  2. C++ 作为后端 js 前端接口（学习中）\n  3. CGI\n\n---\n\n## 科研进度 - CNN\n\n### 目前方向\n3D Instance Segmentation\n\n### 论文收集\n 1. (RDCNet)mini ResNet in 2d Instance Seg\n 2. Attention Based 3d instance segmentation\n 3. Learning Gaussian Instance Segmentation in Point Clouds\n 4. 3D Sementic & Instance Segmentation via Salient Point Clustering Optimization\n\n### TODO\n1. 实现 ResNet Backbone\n2. 复现 Fast R-CNN & Mask R-CNN\n","slug":"Recent-Progress (2020-11-15 ~ 2020-11-27)","published":1,"updated":"2026-02-03T05:42:14.446Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzv500017uit6sca04t2","content":"<h1 id=\"最近进展\"><a href=\"#最近进展\" class=\"headerlink\" title=\"最近进展\"></a>最近进展</h1><p>近来比较忙，一直没时间写博客，就暂将这段时间的进展写作一个综述发在博客上</p>\n<hr>\n<h2 id=\"学业方面\"><a href=\"#学业方面\" class=\"headerlink\" title=\"学业方面\"></a><strong>学业方面</strong></h2><h3 id=\"数据结构-DataStructure\"><a href=\"#数据结构-DataStructure\" class=\"headerlink\" title=\"数据结构 - DataStructure\"></a>数据结构 - DataStructure</h3><p>数据结构这几周以来都是学的树相关的操作, 对树的相关操作进行了学习和进一步的探究</p>\n<h4 id=\"已经掌握\"><a href=\"#已经掌握\" class=\"headerlink\" title=\"已经掌握\"></a>已经掌握</h4><h5 id=\"树的储存\"><a href=\"#树的储存\" class=\"headerlink\" title=\"树的储存\"></a>树的储存</h5><ol>\n<li><p>邻接表形式</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-built_in\">std</span>::<span class=\"hljs-built_in\">vector</span>&lt;<span class=\"hljs-keyword\">int</span>&gt; Tree[Max]</code></pre>\n</li>\n<li><p>链式前向星形式</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">edge</span></span>\n<span class=\"hljs-class\">&#123;</span>\n    <span class=\"hljs-keyword\">int</span> v;\n    <span class=\"hljs-keyword\">int</span> w;\n    <span class=\"hljs-keyword\">int</span> nex;\n&#125;;\n\nedge e[Max];\n<span class=\"hljs-keyword\">int</span> head[Max], cnt = <span class=\"hljs-number\">0</span>; <span class=\"hljs-comment\">// init -1</span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">add_edge</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> v)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    e[cnt].v = v;\n    e[cnt].w = w;\n    e[cnt].nex = head[u];\n    head[u] = cnt++;\n&#125;\n\n<span class=\"hljs-comment\">//遍历方式</span>\n<span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = head[u]; i != <span class=\"hljs-number\">-1</span>; i = e[i].nex)</code></pre>\n<blockquote>\n<p>邻接表相比链式前向星更为动态，但有些阴间题会卡掉邻接表</p>\n</blockquote>\n</li>\n</ol>\n<hr>\n<h5 id=\"深度优先搜索-dfs\"><a href=\"#深度优先搜索-dfs\" class=\"headerlink\" title=\"深度优先搜索 (dfs)\"></a>深度优先搜索 (dfs)</h5><p>基本原则是一种与广度优先搜索对立的，能搜到子节点就往子节点走的搜索方式，既“深度”优先，我们熟知的二叉树的前序和后序遍历都是深度优先搜索的一种。</p>\n<ol>\n<li><p>代码实现 (邻接表形式)</p>\n <pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">dfs</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span>&amp; v : tree[u])\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(v == fa)\n            <span class=\"hljs-keyword\">continue</span>;\n        dfs(v, u)\n    &#125;\n&#125;</code></pre>\n<p> 其中 dfs(v,u) 是 dfs 的精华， 指代如若没搜到叶节点那么则继续向深度搜索，这时候当前节点的子节点作为下一个节点，而当前节点成为其子节点的父节点，因而有从 dfs(u, fa) 到 dfs(v, u) 的向深度搜索</p>\n</li>\n<li><p>前序遍历 - PreOrder (先出根再出子节点)</p>\n <pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">preOrder</span><span class=\"hljs-params\">(TreeNode* root)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">if</span>(!root)\n        <span class=\"hljs-keyword\">return</span>;\n    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%d\\n&quot;</span>, root-&gt;val);\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span> child : root-&gt;children)\n        preOrder(root-&gt;child)    <span class=\"hljs-comment\">//递归子树</span>\n&#125;</code></pre>\n</li>\n<li><p>后序遍历 - PosOrder (先出子节点再出根)</p>\n <pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">posOrder</span><span class=\"hljs-params\">(TreeNode* root)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">if</span>(!root)\n        <span class=\"hljs-keyword\">return</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span> child : root-&gt;children)\n        preOrder(root-&gt;child)    <span class=\"hljs-comment\">//递归子树</span>\n    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%d\\n&quot;</span>, root-&gt;val);\n&#125;</code></pre>\n<p>通过两次 dfs 我们可以求树的直径，一次 dfs 到直径的端点，再一次求出直径长度。</p>\n</li>\n</ol>\n<p>dfs 所使用的数据结构是栈，这种数据结构隐含在函数的递归调用中，而对于 bfs 所使用的数据结构是队列，我们就需要</p>\n<hr>\n<h5 id=\"广-宽-度优先搜索-bfs\"><a href=\"#广-宽-度优先搜索-bfs\" class=\"headerlink\" title=\"广(宽)度优先搜索 (bfs)\"></a>广(宽)度优先搜索 (bfs)</h5><p>bfs 不同于 dfs 是深度优先的搜索，bfs是将同层的节点全部搜索过后再进入到下一次，既注重 “广度” 的搜索模式</p>\n<ol>\n<li><p>代码实现 (邻接表形式)</p>\n<pre><code class=\"hljs cpp\">bfs(s) \n&#123;\n    q = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">queue</span>();\n    q.push(s), visited[s] = <span class=\"hljs-literal\">true</span>;\n    <span class=\"hljs-keyword\">while</span> (!q.empty()) \n    &#123;\n        u = q.pop();\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span>&amp; v : tree[u])\n        &#123;\n            <span class=\"hljs-keyword\">if</span> (!visited[v]) \n            &#123;\n                q.push(v);\n                visited[v] = <span class=\"hljs-literal\">true</span>;\n            &#125;\n        &#125;\n    &#125;\n&#125;</code></pre>\n</li>\n<li><p>层序遍历<br> 层序遍历就是一种典型的 bfs，先将同层的打印出来之后再深入一层，代码同上。当然也可以通过 dfs 实现层序这时候就要区分节点的层数</p>\n</li>\n</ol>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">//dfs版本层序</span>\n<span class=\"hljs-built_in\">vector</span>&lt;<span class=\"hljs-built_in\">vector</span>&lt;<span class=\"hljs-keyword\">int</span>&gt; &gt; ans;\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">dfs</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa, <span class=\"hljs-keyword\">int</span> level)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">if</span>(level &gt; ans.size())\n        ans.emplace_back(<span class=\"hljs-built_in\">vector</span>&lt;<span class=\"hljs-keyword\">int</span>&gt;())\n    ans[level - <span class=\"hljs-number\">1</span>].emplace_back(u);\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span>&amp; v : tree[u])\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(v == fa)\n            <span class=\"hljs-keyword\">continue</span>;\n        dfs(v, u, level + <span class=\"hljs-number\">1</span>)\n    &#125;\n&#125;</code></pre>\n<hr>\n<h5 id=\"树形dp\"><a href=\"#树形dp\" class=\"headerlink\" title=\"树形dp\"></a>树形dp</h5><p>树形dp，顾名思义是在树上进行的dp，在dfs或bfs的过程中进行动态更新。例如通过树形dp求树的直径</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">dfs</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    vis[x] = <span class=\"hljs-number\">1</span>;\n    <span class=\"hljs-keyword\">int</span> d1 = <span class=\"hljs-number\">0</span>, d2 = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">int</span> tmp = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span>&amp; v : tree[u])\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(v == fa)\n            <span class=\"hljs-keyword\">continue</span>;\n        tmp = dfs(v, u) + <span class=\"hljs-number\">1</span>;\n        <span class=\"hljs-keyword\">if</span>(tmp &gt; d1)\n        &#123;\n            d2 = d1;\n            d1 = tmp;\n        &#125;\n        <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(tmp &gt; d2)\n            d2 = tmp;\n        d = max(d, d1 + d2);\n    &#125;\n    <span class=\"hljs-keyword\">return</span> max;\n&#125;</code></pre>\n<hr>\n<h4 id=\"尚未熟练-TODO\"><a href=\"#尚未熟练-TODO\" class=\"headerlink\" title=\"尚未熟练 - TODO\"></a><strong>尚未熟练 - TODO</strong></h4><ol>\n<li>LCA问题</li>\n<li>树状数组</li>\n<li>线段树</li>\n<li>树链剖分</li>\n</ol>\n<hr>\n<h3 id=\"计算机系统-ICS\"><a href=\"#计算机系统-ICS\" class=\"headerlink\" title=\"计算机系统 - ICS\"></a>计算机系统 - ICS</h3><p>最近布置了 y86-64 的 PJ，学习了 CPU 的顺序以及流水线设计模式，开始做PJ。</p>\n<h4 id=\"PJ进展\"><a href=\"#PJ进展\" class=\"headerlink\" title=\"PJ进展:\"></a>PJ进展:</h4><h5 id=\"设计模式-C-with-Class\"><a href=\"#设计模式-C-with-Class\" class=\"headerlink\" title=\"设计模式 - C with Class\"></a>设计模式 - C with Class</h5><p>在面向过程的 Fetch -&gt; Decode -&gt; Execute -&gt; Memory -&gt; WriteBack 基础上套instr的类壳</p>\n<h5 id=\"后端进度\"><a href=\"#后端进度\" class=\"headerlink\" title=\"后端进度\"></a>后端进度</h5><ol>\n<li>完成了Prototype设计<ul>\n<li>目前 CC 的 OF 有一点 BUG</li>\n</ul>\n</li>\n<li>完成了 UniTest 的 Generater<ul>\n<li>准备用宏改为 gtest 移植到cpp上</li>\n</ul>\n</li>\n</ol>\n<ul>\n<li>TODO:<ol>\n<li>完成 python 到 cpp 的移植</li>\n<li>尝试添加寄存器</li>\n<li>实现硬件栈</li>\n</ol>\n</li>\n</ul>\n<h5 id=\"前端进度\"><a href=\"#前端进度\" class=\"headerlink\" title=\"前端进度\"></a>前端进度</h5><p>TODO中，思考如何设计</p>\n<ul>\n<li>可选方案:<ol>\n<li>Python 作为中间件用 jinja 模板替换</li>\n<li>C++ 作为后端 js 前端接口（学习中）</li>\n<li>CGI</li>\n</ol>\n</li>\n</ul>\n<hr>\n<h2 id=\"科研进度-CNN\"><a href=\"#科研进度-CNN\" class=\"headerlink\" title=\"科研进度 - CNN\"></a>科研进度 - CNN</h2><h3 id=\"目前方向\"><a href=\"#目前方向\" class=\"headerlink\" title=\"目前方向\"></a>目前方向</h3><p>3D Instance Segmentation</p>\n<h3 id=\"论文收集\"><a href=\"#论文收集\" class=\"headerlink\" title=\"论文收集\"></a>论文收集</h3><ol>\n<li>(RDCNet)mini ResNet in 2d Instance Seg</li>\n<li>Attention Based 3d instance segmentation</li>\n<li>Learning Gaussian Instance Segmentation in Point Clouds</li>\n<li>3D Sementic &amp; Instance Segmentation via Salient Point Clustering Optimization</li>\n</ol>\n<h3 id=\"TODO\"><a href=\"#TODO\" class=\"headerlink\" title=\"TODO\"></a>TODO</h3><ol>\n<li>实现 ResNet Backbone</li>\n<li>复现 Fast R-CNN &amp; Mask R-CNN</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"最近进展\"><a href=\"#最近进展\" class=\"headerlink\" title=\"最近进展\"></a>最近进展</h1><p>近来比较忙，一直没时间写博客，就暂将这段时间的进展写作一个综述发在博客上</p>\n<hr>\n<h2 id=\"学业方面\"><a href=\"#学业方面\" class=\"headerlink\" title=\"学业方面\"></a><strong>学业方面</strong></h2><h3 id=\"数据结构-DataStructure\"><a href=\"#数据结构-DataStructure\" class=\"headerlink\" title=\"数据结构 - DataStructure\"></a>数据结构 - DataStructure</h3><p>数据结构这几周以来都是学的树相关的操作, 对树的相关操作进行了学习和进一步的探究</p>\n<h4 id=\"已经掌握\"><a href=\"#已经掌握\" class=\"headerlink\" title=\"已经掌握\"></a>已经掌握</h4><h5 id=\"树的储存\"><a href=\"#树的储存\" class=\"headerlink\" title=\"树的储存\"></a>树的储存</h5><ol>\n<li><p>邻接表形式</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-built_in\">std</span>::<span class=\"hljs-built_in\">vector</span>&lt;<span class=\"hljs-keyword\">int</span>&gt; Tree[Max]</code></pre>\n</li>\n<li><p>链式前向星形式</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">edge</span></span>\n<span class=\"hljs-class\">&#123;</span>\n    <span class=\"hljs-keyword\">int</span> v;\n    <span class=\"hljs-keyword\">int</span> w;\n    <span class=\"hljs-keyword\">int</span> nex;\n&#125;;\n\nedge e[Max];\n<span class=\"hljs-keyword\">int</span> head[Max], cnt = <span class=\"hljs-number\">0</span>; <span class=\"hljs-comment\">// init -1</span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">add_edge</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> v)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    e[cnt].v = v;\n    e[cnt].w = w;\n    e[cnt].nex = head[u];\n    head[u] = cnt++;\n&#125;\n\n<span class=\"hljs-comment\">//遍历方式</span>\n<span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = head[u]; i != <span class=\"hljs-number\">-1</span>; i = e[i].nex)</code></pre>\n<blockquote>\n<p>邻接表相比链式前向星更为动态，但有些阴间题会卡掉邻接表</p>\n</blockquote>\n</li>\n</ol>\n<hr>\n<h5 id=\"深度优先搜索-dfs\"><a href=\"#深度优先搜索-dfs\" class=\"headerlink\" title=\"深度优先搜索 (dfs)\"></a>深度优先搜索 (dfs)</h5><p>基本原则是一种与广度优先搜索对立的，能搜到子节点就往子节点走的搜索方式，既“深度”优先，我们熟知的二叉树的前序和后序遍历都是深度优先搜索的一种。</p>\n<ol>\n<li><p>代码实现 (邻接表形式)</p>\n <pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">dfs</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span>&amp; v : tree[u])\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(v == fa)\n            <span class=\"hljs-keyword\">continue</span>;\n        dfs(v, u)\n    &#125;\n&#125;</code></pre>\n<p> 其中 dfs(v,u) 是 dfs 的精华， 指代如若没搜到叶节点那么则继续向深度搜索，这时候当前节点的子节点作为下一个节点，而当前节点成为其子节点的父节点，因而有从 dfs(u, fa) 到 dfs(v, u) 的向深度搜索</p>\n</li>\n<li><p>前序遍历 - PreOrder (先出根再出子节点)</p>\n <pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">preOrder</span><span class=\"hljs-params\">(TreeNode* root)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">if</span>(!root)\n        <span class=\"hljs-keyword\">return</span>;\n    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%d\\n&quot;</span>, root-&gt;val);\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span> child : root-&gt;children)\n        preOrder(root-&gt;child)    <span class=\"hljs-comment\">//递归子树</span>\n&#125;</code></pre>\n</li>\n<li><p>后序遍历 - PosOrder (先出子节点再出根)</p>\n <pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">posOrder</span><span class=\"hljs-params\">(TreeNode* root)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">if</span>(!root)\n        <span class=\"hljs-keyword\">return</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span> child : root-&gt;children)\n        preOrder(root-&gt;child)    <span class=\"hljs-comment\">//递归子树</span>\n    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%d\\n&quot;</span>, root-&gt;val);\n&#125;</code></pre>\n<p>通过两次 dfs 我们可以求树的直径，一次 dfs 到直径的端点，再一次求出直径长度。</p>\n</li>\n</ol>\n<p>dfs 所使用的数据结构是栈，这种数据结构隐含在函数的递归调用中，而对于 bfs 所使用的数据结构是队列，我们就需要</p>\n<hr>\n<h5 id=\"广-宽-度优先搜索-bfs\"><a href=\"#广-宽-度优先搜索-bfs\" class=\"headerlink\" title=\"广(宽)度优先搜索 (bfs)\"></a>广(宽)度优先搜索 (bfs)</h5><p>bfs 不同于 dfs 是深度优先的搜索，bfs是将同层的节点全部搜索过后再进入到下一次，既注重 “广度” 的搜索模式</p>\n<ol>\n<li><p>代码实现 (邻接表形式)</p>\n<pre><code class=\"hljs cpp\">bfs(s) \n&#123;\n    q = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">queue</span>();\n    q.push(s), visited[s] = <span class=\"hljs-literal\">true</span>;\n    <span class=\"hljs-keyword\">while</span> (!q.empty()) \n    &#123;\n        u = q.pop();\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span>&amp; v : tree[u])\n        &#123;\n            <span class=\"hljs-keyword\">if</span> (!visited[v]) \n            &#123;\n                q.push(v);\n                visited[v] = <span class=\"hljs-literal\">true</span>;\n            &#125;\n        &#125;\n    &#125;\n&#125;</code></pre>\n</li>\n<li><p>层序遍历<br> 层序遍历就是一种典型的 bfs，先将同层的打印出来之后再深入一层，代码同上。当然也可以通过 dfs 实现层序这时候就要区分节点的层数</p>\n</li>\n</ol>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">//dfs版本层序</span>\n<span class=\"hljs-built_in\">vector</span>&lt;<span class=\"hljs-built_in\">vector</span>&lt;<span class=\"hljs-keyword\">int</span>&gt; &gt; ans;\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">dfs</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa, <span class=\"hljs-keyword\">int</span> level)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">if</span>(level &gt; ans.size())\n        ans.emplace_back(<span class=\"hljs-built_in\">vector</span>&lt;<span class=\"hljs-keyword\">int</span>&gt;())\n    ans[level - <span class=\"hljs-number\">1</span>].emplace_back(u);\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span>&amp; v : tree[u])\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(v == fa)\n            <span class=\"hljs-keyword\">continue</span>;\n        dfs(v, u, level + <span class=\"hljs-number\">1</span>)\n    &#125;\n&#125;</code></pre>\n<hr>\n<h5 id=\"树形dp\"><a href=\"#树形dp\" class=\"headerlink\" title=\"树形dp\"></a>树形dp</h5><p>树形dp，顾名思义是在树上进行的dp，在dfs或bfs的过程中进行动态更新。例如通过树形dp求树的直径</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">dfs</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    vis[x] = <span class=\"hljs-number\">1</span>;\n    <span class=\"hljs-keyword\">int</span> d1 = <span class=\"hljs-number\">0</span>, d2 = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">int</span> tmp = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span>&amp; v : tree[u])\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(v == fa)\n            <span class=\"hljs-keyword\">continue</span>;\n        tmp = dfs(v, u) + <span class=\"hljs-number\">1</span>;\n        <span class=\"hljs-keyword\">if</span>(tmp &gt; d1)\n        &#123;\n            d2 = d1;\n            d1 = tmp;\n        &#125;\n        <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(tmp &gt; d2)\n            d2 = tmp;\n        d = max(d, d1 + d2);\n    &#125;\n    <span class=\"hljs-keyword\">return</span> max;\n&#125;</code></pre>\n<hr>\n<h4 id=\"尚未熟练-TODO\"><a href=\"#尚未熟练-TODO\" class=\"headerlink\" title=\"尚未熟练 - TODO\"></a><strong>尚未熟练 - TODO</strong></h4><ol>\n<li>LCA问题</li>\n<li>树状数组</li>\n<li>线段树</li>\n<li>树链剖分</li>\n</ol>\n<hr>\n<h3 id=\"计算机系统-ICS\"><a href=\"#计算机系统-ICS\" class=\"headerlink\" title=\"计算机系统 - ICS\"></a>计算机系统 - ICS</h3><p>最近布置了 y86-64 的 PJ，学习了 CPU 的顺序以及流水线设计模式，开始做PJ。</p>\n<h4 id=\"PJ进展\"><a href=\"#PJ进展\" class=\"headerlink\" title=\"PJ进展:\"></a>PJ进展:</h4><h5 id=\"设计模式-C-with-Class\"><a href=\"#设计模式-C-with-Class\" class=\"headerlink\" title=\"设计模式 - C with Class\"></a>设计模式 - C with Class</h5><p>在面向过程的 Fetch -&gt; Decode -&gt; Execute -&gt; Memory -&gt; WriteBack 基础上套instr的类壳</p>\n<h5 id=\"后端进度\"><a href=\"#后端进度\" class=\"headerlink\" title=\"后端进度\"></a>后端进度</h5><ol>\n<li>完成了Prototype设计<ul>\n<li>目前 CC 的 OF 有一点 BUG</li>\n</ul>\n</li>\n<li>完成了 UniTest 的 Generater<ul>\n<li>准备用宏改为 gtest 移植到cpp上</li>\n</ul>\n</li>\n</ol>\n<ul>\n<li>TODO:<ol>\n<li>完成 python 到 cpp 的移植</li>\n<li>尝试添加寄存器</li>\n<li>实现硬件栈</li>\n</ol>\n</li>\n</ul>\n<h5 id=\"前端进度\"><a href=\"#前端进度\" class=\"headerlink\" title=\"前端进度\"></a>前端进度</h5><p>TODO中，思考如何设计</p>\n<ul>\n<li>可选方案:<ol>\n<li>Python 作为中间件用 jinja 模板替换</li>\n<li>C++ 作为后端 js 前端接口（学习中）</li>\n<li>CGI</li>\n</ol>\n</li>\n</ul>\n<hr>\n<h2 id=\"科研进度-CNN\"><a href=\"#科研进度-CNN\" class=\"headerlink\" title=\"科研进度 - CNN\"></a>科研进度 - CNN</h2><h3 id=\"目前方向\"><a href=\"#目前方向\" class=\"headerlink\" title=\"目前方向\"></a>目前方向</h3><p>3D Instance Segmentation</p>\n<h3 id=\"论文收集\"><a href=\"#论文收集\" class=\"headerlink\" title=\"论文收集\"></a>论文收集</h3><ol>\n<li>(RDCNet)mini ResNet in 2d Instance Seg</li>\n<li>Attention Based 3d instance segmentation</li>\n<li>Learning Gaussian Instance Segmentation in Point Clouds</li>\n<li>3D Sementic &amp; Instance Segmentation via Salient Point Clustering Optimization</li>\n</ol>\n<h3 id=\"TODO\"><a href=\"#TODO\" class=\"headerlink\" title=\"TODO\"></a>TODO</h3><ol>\n<li>实现 ResNet Backbone</li>\n<li>复现 Fast R-CNN &amp; Mask R-CNN</li>\n</ol>\n"},{"title":"期末 DDL + TODOList","date":"2020-12-17T21:04:58.000Z","index_img":"/img/TODO.png","_content":"\n# 期末季DDL\n### 这周的 数据结构/离散/数逻 作业\n#### - 预计需要: 4h+\n\n### 实验室 Reading Group ( *ddl: 12/23 下周三* )\n#### - 预计需要: 2 ~ 3h\n\n### 毛概实践报告 ( *ddl: 12/24 下周四* )\n- 1. 字数5k字\n#### - 预计需要: 2 ~ 3h\n#### - 安排时间：今晚毛概课给它干掉！\n\n### ICSPJ-Stage2 ( *ddl: 12/24 下周四* )\n- 1. 前端优化添加功能 ( 10h )\n- 2. PPT ( 3h )\n#### - 预计需要: 15h+\n\n### 美国文学选读考试 ( *ddl: 12/27 下周日晚上* )\n- 1. 文本复习 ( 5h )\n- 1. 作者复习 ( 5h )\n#### - 预计需要 ( 1day )\n\n### 数据结构上机考 ( *ddl: 12/28 下下周一* )\n- 1. 复习算法 ( 8h )\n- 2. 复习上机题 ( 10h+ )\n#### - 预计需要: 20h+\n\n### 数逻 LAB7 ( *ddl: 12/29 下下周二* )\n#### - 预计需要: 3h+\n\n### 毛概考试 ( *ddl: 12/29 下下周二* )\n- 1. 复习 ( 1h )\n#### - 预计需要: 1h+\n\n### ICS-LAB5 ( *ddl: 12/30 下下周三* )\n#### - 预计需要: 3h\n\n### 近代中国思想与人物期末论文 ( *ddl: 未知* )\n#### - 预计需要: 1day\n\n### 数据结构PJ ( *ddl: 1/3 下下周日* )\n#### - 预计需要: 12h+\n\n### 数据结构考试 ( *ddl: 1/5 下下下周二* )\n- 1. 复习课本 ( 5h )\n#### - 预计需要: 5h+\n\n### 数逻考试 ( *ddl: 1/11 下下下下周一* )\n#### - 预计需要: 1d+\n\n### 离散考试 ( *ddl: 1/12 下下下下周二* )\n#### - 预计需要: 2d+\n","source":"_posts/final_todo.md","raw":"---\ntitle: 期末 DDL + TODOList\ndate: 2020-12-17 13:04:58\nindex_img: /img/TODO.png\ncategory: [TODO]\ntags: TODO\n---\n\n# 期末季DDL\n### 这周的 数据结构/离散/数逻 作业\n#### - 预计需要: 4h+\n\n### 实验室 Reading Group ( *ddl: 12/23 下周三* )\n#### - 预计需要: 2 ~ 3h\n\n### 毛概实践报告 ( *ddl: 12/24 下周四* )\n- 1. 字数5k字\n#### - 预计需要: 2 ~ 3h\n#### - 安排时间：今晚毛概课给它干掉！\n\n### ICSPJ-Stage2 ( *ddl: 12/24 下周四* )\n- 1. 前端优化添加功能 ( 10h )\n- 2. PPT ( 3h )\n#### - 预计需要: 15h+\n\n### 美国文学选读考试 ( *ddl: 12/27 下周日晚上* )\n- 1. 文本复习 ( 5h )\n- 1. 作者复习 ( 5h )\n#### - 预计需要 ( 1day )\n\n### 数据结构上机考 ( *ddl: 12/28 下下周一* )\n- 1. 复习算法 ( 8h )\n- 2. 复习上机题 ( 10h+ )\n#### - 预计需要: 20h+\n\n### 数逻 LAB7 ( *ddl: 12/29 下下周二* )\n#### - 预计需要: 3h+\n\n### 毛概考试 ( *ddl: 12/29 下下周二* )\n- 1. 复习 ( 1h )\n#### - 预计需要: 1h+\n\n### ICS-LAB5 ( *ddl: 12/30 下下周三* )\n#### - 预计需要: 3h\n\n### 近代中国思想与人物期末论文 ( *ddl: 未知* )\n#### - 预计需要: 1day\n\n### 数据结构PJ ( *ddl: 1/3 下下周日* )\n#### - 预计需要: 12h+\n\n### 数据结构考试 ( *ddl: 1/5 下下下周二* )\n- 1. 复习课本 ( 5h )\n#### - 预计需要: 5h+\n\n### 数逻考试 ( *ddl: 1/11 下下下下周一* )\n#### - 预计需要: 1d+\n\n### 离散考试 ( *ddl: 1/12 下下下下周二* )\n#### - 预计需要: 2d+\n","slug":"final_todo","published":1,"updated":"2026-02-03T05:42:14.452Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzv600037uit2k4nawcv","content":"<h1 id=\"期末季DDL\"><a href=\"#期末季DDL\" class=\"headerlink\" title=\"期末季DDL\"></a>期末季DDL</h1><h3 id=\"这周的-数据结构-离散-数逻-作业\"><a href=\"#这周的-数据结构-离散-数逻-作业\" class=\"headerlink\" title=\"这周的 数据结构/离散/数逻 作业\"></a>这周的 数据结构/离散/数逻 作业</h3><h4 id=\"预计需要-4h\"><a href=\"#预计需要-4h\" class=\"headerlink\" title=\"- 预计需要: 4h+\"></a>- 预计需要: 4h+</h4><h3 id=\"实验室-Reading-Group-ddl-12-23-下周三\"><a href=\"#实验室-Reading-Group-ddl-12-23-下周三\" class=\"headerlink\" title=\"实验室 Reading Group ( ddl: 12/23 下周三 )\"></a>实验室 Reading Group ( <em>ddl: 12/23 下周三</em> )</h3><h4 id=\"预计需要-2-3h\"><a href=\"#预计需要-2-3h\" class=\"headerlink\" title=\"- 预计需要: 2 ~ 3h\"></a>- 预计需要: 2 ~ 3h</h4><h3 id=\"毛概实践报告-ddl-12-24-下周四\"><a href=\"#毛概实践报告-ddl-12-24-下周四\" class=\"headerlink\" title=\"毛概实践报告 ( ddl: 12/24 下周四 )\"></a>毛概实践报告 ( <em>ddl: 12/24 下周四</em> )</h3><ul>\n<li><ol>\n<li>字数5k字<h4 id=\"预计需要-2-3h-1\"><a href=\"#预计需要-2-3h-1\" class=\"headerlink\" title=\"- 预计需要: 2 ~ 3h\"></a>- 预计需要: 2 ~ 3h</h4><h4 id=\"安排时间：今晚毛概课给它干掉！\"><a href=\"#安排时间：今晚毛概课给它干掉！\" class=\"headerlink\" title=\"- 安排时间：今晚毛概课给它干掉！\"></a>- 安排时间：今晚毛概课给它干掉！</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"ICSPJ-Stage2-ddl-12-24-下周四\"><a href=\"#ICSPJ-Stage2-ddl-12-24-下周四\" class=\"headerlink\" title=\"ICSPJ-Stage2 ( ddl: 12/24 下周四 )\"></a>ICSPJ-Stage2 ( <em>ddl: 12/24 下周四</em> )</h3><ul>\n<li><ol>\n<li>前端优化添加功能 ( 10h )</li>\n</ol>\n</li>\n<li><ol>\n<li>PPT ( 3h )<h4 id=\"预计需要-15h\"><a href=\"#预计需要-15h\" class=\"headerlink\" title=\"- 预计需要: 15h+\"></a>- 预计需要: 15h+</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"美国文学选读考试-ddl-12-27-下周日晚上\"><a href=\"#美国文学选读考试-ddl-12-27-下周日晚上\" class=\"headerlink\" title=\"美国文学选读考试 ( ddl: 12/27 下周日晚上 )\"></a>美国文学选读考试 ( <em>ddl: 12/27 下周日晚上</em> )</h3><ul>\n<li><ol>\n<li>文本复习 ( 5h )</li>\n</ol>\n</li>\n<li><ol>\n<li>作者复习 ( 5h )<h4 id=\"预计需要-1day\"><a href=\"#预计需要-1day\" class=\"headerlink\" title=\"- 预计需要 ( 1day )\"></a>- 预计需要 ( 1day )</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"数据结构上机考-ddl-12-28-下下周一\"><a href=\"#数据结构上机考-ddl-12-28-下下周一\" class=\"headerlink\" title=\"数据结构上机考 ( ddl: 12/28 下下周一 )\"></a>数据结构上机考 ( <em>ddl: 12/28 下下周一</em> )</h3><ul>\n<li><ol>\n<li>复习算法 ( 8h )</li>\n</ol>\n</li>\n<li><ol>\n<li>复习上机题 ( 10h+ )<h4 id=\"预计需要-20h\"><a href=\"#预计需要-20h\" class=\"headerlink\" title=\"- 预计需要: 20h+\"></a>- 预计需要: 20h+</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"数逻-LAB7-ddl-12-29-下下周二\"><a href=\"#数逻-LAB7-ddl-12-29-下下周二\" class=\"headerlink\" title=\"数逻 LAB7 ( ddl: 12/29 下下周二 )\"></a>数逻 LAB7 ( <em>ddl: 12/29 下下周二</em> )</h3><h4 id=\"预计需要-3h\"><a href=\"#预计需要-3h\" class=\"headerlink\" title=\"- 预计需要: 3h+\"></a>- 预计需要: 3h+</h4><h3 id=\"毛概考试-ddl-12-29-下下周二\"><a href=\"#毛概考试-ddl-12-29-下下周二\" class=\"headerlink\" title=\"毛概考试 ( ddl: 12/29 下下周二 )\"></a>毛概考试 ( <em>ddl: 12/29 下下周二</em> )</h3><ul>\n<li><ol>\n<li>复习 ( 1h )<h4 id=\"预计需要-1h\"><a href=\"#预计需要-1h\" class=\"headerlink\" title=\"- 预计需要: 1h+\"></a>- 预计需要: 1h+</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"ICS-LAB5-ddl-12-30-下下周三\"><a href=\"#ICS-LAB5-ddl-12-30-下下周三\" class=\"headerlink\" title=\"ICS-LAB5 ( ddl: 12/30 下下周三 )\"></a>ICS-LAB5 ( <em>ddl: 12/30 下下周三</em> )</h3><h4 id=\"预计需要-3h-1\"><a href=\"#预计需要-3h-1\" class=\"headerlink\" title=\"- 预计需要: 3h\"></a>- 预计需要: 3h</h4><h3 id=\"近代中国思想与人物期末论文-ddl-未知\"><a href=\"#近代中国思想与人物期末论文-ddl-未知\" class=\"headerlink\" title=\"近代中国思想与人物期末论文 ( ddl: 未知 )\"></a>近代中国思想与人物期末论文 ( <em>ddl: 未知</em> )</h3><h4 id=\"预计需要-1day-1\"><a href=\"#预计需要-1day-1\" class=\"headerlink\" title=\"- 预计需要: 1day\"></a>- 预计需要: 1day</h4><h3 id=\"数据结构PJ-ddl-1-3-下下周日\"><a href=\"#数据结构PJ-ddl-1-3-下下周日\" class=\"headerlink\" title=\"数据结构PJ ( ddl: 1/3 下下周日 )\"></a>数据结构PJ ( <em>ddl: 1/3 下下周日</em> )</h3><h4 id=\"预计需要-12h\"><a href=\"#预计需要-12h\" class=\"headerlink\" title=\"- 预计需要: 12h+\"></a>- 预计需要: 12h+</h4><h3 id=\"数据结构考试-ddl-1-5-下下下周二\"><a href=\"#数据结构考试-ddl-1-5-下下下周二\" class=\"headerlink\" title=\"数据结构考试 ( ddl: 1/5 下下下周二 )\"></a>数据结构考试 ( <em>ddl: 1/5 下下下周二</em> )</h3><ul>\n<li><ol>\n<li>复习课本 ( 5h )<h4 id=\"预计需要-5h\"><a href=\"#预计需要-5h\" class=\"headerlink\" title=\"- 预计需要: 5h+\"></a>- 预计需要: 5h+</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"数逻考试-ddl-1-11-下下下下周一\"><a href=\"#数逻考试-ddl-1-11-下下下下周一\" class=\"headerlink\" title=\"数逻考试 ( ddl: 1/11 下下下下周一 )\"></a>数逻考试 ( <em>ddl: 1/11 下下下下周一</em> )</h3><h4 id=\"预计需要-1d\"><a href=\"#预计需要-1d\" class=\"headerlink\" title=\"- 预计需要: 1d+\"></a>- 预计需要: 1d+</h4><h3 id=\"离散考试-ddl-1-12-下下下下周二\"><a href=\"#离散考试-ddl-1-12-下下下下周二\" class=\"headerlink\" title=\"离散考试 ( ddl: 1/12 下下下下周二 )\"></a>离散考试 ( <em>ddl: 1/12 下下下下周二</em> )</h3><h4 id=\"预计需要-2d\"><a href=\"#预计需要-2d\" class=\"headerlink\" title=\"- 预计需要: 2d+\"></a>- 预计需要: 2d+</h4>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"期末季DDL\"><a href=\"#期末季DDL\" class=\"headerlink\" title=\"期末季DDL\"></a>期末季DDL</h1><h3 id=\"这周的-数据结构-离散-数逻-作业\"><a href=\"#这周的-数据结构-离散-数逻-作业\" class=\"headerlink\" title=\"这周的 数据结构/离散/数逻 作业\"></a>这周的 数据结构/离散/数逻 作业</h3><h4 id=\"预计需要-4h\"><a href=\"#预计需要-4h\" class=\"headerlink\" title=\"- 预计需要: 4h+\"></a>- 预计需要: 4h+</h4><h3 id=\"实验室-Reading-Group-ddl-12-23-下周三\"><a href=\"#实验室-Reading-Group-ddl-12-23-下周三\" class=\"headerlink\" title=\"实验室 Reading Group ( ddl: 12/23 下周三 )\"></a>实验室 Reading Group ( <em>ddl: 12/23 下周三</em> )</h3><h4 id=\"预计需要-2-3h\"><a href=\"#预计需要-2-3h\" class=\"headerlink\" title=\"- 预计需要: 2 ~ 3h\"></a>- 预计需要: 2 ~ 3h</h4><h3 id=\"毛概实践报告-ddl-12-24-下周四\"><a href=\"#毛概实践报告-ddl-12-24-下周四\" class=\"headerlink\" title=\"毛概实践报告 ( ddl: 12/24 下周四 )\"></a>毛概实践报告 ( <em>ddl: 12/24 下周四</em> )</h3><ul>\n<li><ol>\n<li>字数5k字<h4 id=\"预计需要-2-3h-1\"><a href=\"#预计需要-2-3h-1\" class=\"headerlink\" title=\"- 预计需要: 2 ~ 3h\"></a>- 预计需要: 2 ~ 3h</h4><h4 id=\"安排时间：今晚毛概课给它干掉！\"><a href=\"#安排时间：今晚毛概课给它干掉！\" class=\"headerlink\" title=\"- 安排时间：今晚毛概课给它干掉！\"></a>- 安排时间：今晚毛概课给它干掉！</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"ICSPJ-Stage2-ddl-12-24-下周四\"><a href=\"#ICSPJ-Stage2-ddl-12-24-下周四\" class=\"headerlink\" title=\"ICSPJ-Stage2 ( ddl: 12/24 下周四 )\"></a>ICSPJ-Stage2 ( <em>ddl: 12/24 下周四</em> )</h3><ul>\n<li><ol>\n<li>前端优化添加功能 ( 10h )</li>\n</ol>\n</li>\n<li><ol>\n<li>PPT ( 3h )<h4 id=\"预计需要-15h\"><a href=\"#预计需要-15h\" class=\"headerlink\" title=\"- 预计需要: 15h+\"></a>- 预计需要: 15h+</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"美国文学选读考试-ddl-12-27-下周日晚上\"><a href=\"#美国文学选读考试-ddl-12-27-下周日晚上\" class=\"headerlink\" title=\"美国文学选读考试 ( ddl: 12/27 下周日晚上 )\"></a>美国文学选读考试 ( <em>ddl: 12/27 下周日晚上</em> )</h3><ul>\n<li><ol>\n<li>文本复习 ( 5h )</li>\n</ol>\n</li>\n<li><ol>\n<li>作者复习 ( 5h )<h4 id=\"预计需要-1day\"><a href=\"#预计需要-1day\" class=\"headerlink\" title=\"- 预计需要 ( 1day )\"></a>- 预计需要 ( 1day )</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"数据结构上机考-ddl-12-28-下下周一\"><a href=\"#数据结构上机考-ddl-12-28-下下周一\" class=\"headerlink\" title=\"数据结构上机考 ( ddl: 12/28 下下周一 )\"></a>数据结构上机考 ( <em>ddl: 12/28 下下周一</em> )</h3><ul>\n<li><ol>\n<li>复习算法 ( 8h )</li>\n</ol>\n</li>\n<li><ol>\n<li>复习上机题 ( 10h+ )<h4 id=\"预计需要-20h\"><a href=\"#预计需要-20h\" class=\"headerlink\" title=\"- 预计需要: 20h+\"></a>- 预计需要: 20h+</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"数逻-LAB7-ddl-12-29-下下周二\"><a href=\"#数逻-LAB7-ddl-12-29-下下周二\" class=\"headerlink\" title=\"数逻 LAB7 ( ddl: 12/29 下下周二 )\"></a>数逻 LAB7 ( <em>ddl: 12/29 下下周二</em> )</h3><h4 id=\"预计需要-3h\"><a href=\"#预计需要-3h\" class=\"headerlink\" title=\"- 预计需要: 3h+\"></a>- 预计需要: 3h+</h4><h3 id=\"毛概考试-ddl-12-29-下下周二\"><a href=\"#毛概考试-ddl-12-29-下下周二\" class=\"headerlink\" title=\"毛概考试 ( ddl: 12/29 下下周二 )\"></a>毛概考试 ( <em>ddl: 12/29 下下周二</em> )</h3><ul>\n<li><ol>\n<li>复习 ( 1h )<h4 id=\"预计需要-1h\"><a href=\"#预计需要-1h\" class=\"headerlink\" title=\"- 预计需要: 1h+\"></a>- 预计需要: 1h+</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"ICS-LAB5-ddl-12-30-下下周三\"><a href=\"#ICS-LAB5-ddl-12-30-下下周三\" class=\"headerlink\" title=\"ICS-LAB5 ( ddl: 12/30 下下周三 )\"></a>ICS-LAB5 ( <em>ddl: 12/30 下下周三</em> )</h3><h4 id=\"预计需要-3h-1\"><a href=\"#预计需要-3h-1\" class=\"headerlink\" title=\"- 预计需要: 3h\"></a>- 预计需要: 3h</h4><h3 id=\"近代中国思想与人物期末论文-ddl-未知\"><a href=\"#近代中国思想与人物期末论文-ddl-未知\" class=\"headerlink\" title=\"近代中国思想与人物期末论文 ( ddl: 未知 )\"></a>近代中国思想与人物期末论文 ( <em>ddl: 未知</em> )</h3><h4 id=\"预计需要-1day-1\"><a href=\"#预计需要-1day-1\" class=\"headerlink\" title=\"- 预计需要: 1day\"></a>- 预计需要: 1day</h4><h3 id=\"数据结构PJ-ddl-1-3-下下周日\"><a href=\"#数据结构PJ-ddl-1-3-下下周日\" class=\"headerlink\" title=\"数据结构PJ ( ddl: 1/3 下下周日 )\"></a>数据结构PJ ( <em>ddl: 1/3 下下周日</em> )</h3><h4 id=\"预计需要-12h\"><a href=\"#预计需要-12h\" class=\"headerlink\" title=\"- 预计需要: 12h+\"></a>- 预计需要: 12h+</h4><h3 id=\"数据结构考试-ddl-1-5-下下下周二\"><a href=\"#数据结构考试-ddl-1-5-下下下周二\" class=\"headerlink\" title=\"数据结构考试 ( ddl: 1/5 下下下周二 )\"></a>数据结构考试 ( <em>ddl: 1/5 下下下周二</em> )</h3><ul>\n<li><ol>\n<li>复习课本 ( 5h )<h4 id=\"预计需要-5h\"><a href=\"#预计需要-5h\" class=\"headerlink\" title=\"- 预计需要: 5h+\"></a>- 预计需要: 5h+</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"数逻考试-ddl-1-11-下下下下周一\"><a href=\"#数逻考试-ddl-1-11-下下下下周一\" class=\"headerlink\" title=\"数逻考试 ( ddl: 1/11 下下下下周一 )\"></a>数逻考试 ( <em>ddl: 1/11 下下下下周一</em> )</h3><h4 id=\"预计需要-1d\"><a href=\"#预计需要-1d\" class=\"headerlink\" title=\"- 预计需要: 1d+\"></a>- 预计需要: 1d+</h4><h3 id=\"离散考试-ddl-1-12-下下下下周二\"><a href=\"#离散考试-ddl-1-12-下下下下周二\" class=\"headerlink\" title=\"离散考试 ( ddl: 1/12 下下下下周二 )\"></a>离散考试 ( <em>ddl: 1/12 下下下下周二</em> )</h3><h4 id=\"预计需要-2d\"><a href=\"#预计需要-2d\" class=\"headerlink\" title=\"- 预计需要: 2d+\"></a>- 预计需要: 2d+</h4>"},{"title":"Hello World","index_img":"/img/hello_world/top.png","date":"2020-11-05T18:00:00.000Z","math":true,"_content":"\n## 第一篇博客用以测试\n\n### 一、 下面是一段C++代码\n```cpp\n#include <iostream>\nusing namespace std;\n\nint main()\n{\n    cout << \"Hello World!\" << endl;\n}\n```\n\n### 二、 下面是一段表格\n\n| 0 | 1 | 2 | 3 | 4 | \n| :---: | :---: | :---: | :---: | :---: |\n| x | x | x | x | x |\n\n### 三、 下面是一段 Latex\n\n\n$$E= mc^2$$\n\n\n### 四、下面是一张图片\n\n![](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRP-ciAYVH8UlH3ZaZC3NkN3ow9CrG36O5crg&usqp=CAU)","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\ntags: [Hexo, Fluid]\nindex_img: /img/hello_world/top.png\ndate: 2020-11-5 10:00:00\nmath: true\n---\n\n## 第一篇博客用以测试\n\n### 一、 下面是一段C++代码\n```cpp\n#include <iostream>\nusing namespace std;\n\nint main()\n{\n    cout << \"Hello World!\" << endl;\n}\n```\n\n### 二、 下面是一段表格\n\n| 0 | 1 | 2 | 3 | 4 | \n| :---: | :---: | :---: | :---: | :---: |\n| x | x | x | x | x |\n\n### 三、 下面是一段 Latex\n\n\n$$E= mc^2$$\n\n\n### 四、下面是一张图片\n\n![](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRP-ciAYVH8UlH3ZaZC3NkN3ow9CrG36O5crg&usqp=CAU)","slug":"hello-world","published":1,"updated":"2026-02-03T05:42:14.452Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzv700067uithczyfwwo","content":"<h2 id=\"第一篇博客用以测试\"><a href=\"#第一篇博客用以测试\" class=\"headerlink\" title=\"第一篇博客用以测试\"></a>第一篇博客用以测试</h2><h3 id=\"一、-下面是一段C-代码\"><a href=\"#一、-下面是一段C-代码\" class=\"headerlink\" title=\"一、 下面是一段C++代码\"></a>一、 下面是一段C++代码</h3><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;iostream&gt;</span></span>\n<span class=\"hljs-keyword\">using</span> <span class=\"hljs-keyword\">namespace</span> <span class=\"hljs-built_in\">std</span>;\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-built_in\">cout</span> &lt;&lt; <span class=\"hljs-string\">&quot;Hello World!&quot;</span> &lt;&lt; <span class=\"hljs-built_in\">endl</span>;\n&#125;</code></pre>\n<h3 id=\"二、-下面是一段表格\"><a href=\"#二、-下面是一段表格\" class=\"headerlink\" title=\"二、 下面是一段表格\"></a>二、 下面是一段表格</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">0</th>\n<th style=\"text-align:center\">1</th>\n<th style=\"text-align:center\">2</th>\n<th style=\"text-align:center\">3</th>\n<th style=\"text-align:center\">4</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">x</td>\n<td style=\"text-align:center\">x</td>\n<td style=\"text-align:center\">x</td>\n<td style=\"text-align:center\">x</td>\n<td style=\"text-align:center\">x</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"三、-下面是一段-Latex\"><a href=\"#三、-下面是一段-Latex\" class=\"headerlink\" title=\"三、 下面是一段 Latex\"></a>三、 下面是一段 Latex</h3><script type=\"math/tex; mode=display\">E= mc^2</script><h3 id=\"四、下面是一张图片\"><a href=\"#四、下面是一张图片\" class=\"headerlink\" title=\"四、下面是一张图片\"></a>四、下面是一张图片</h3><p><img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRP-ciAYVH8UlH3ZaZC3NkN3ow9CrG36O5crg&amp;usqp=CAU\" alt></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"第一篇博客用以测试\"><a href=\"#第一篇博客用以测试\" class=\"headerlink\" title=\"第一篇博客用以测试\"></a>第一篇博客用以测试</h2><h3 id=\"一、-下面是一段C-代码\"><a href=\"#一、-下面是一段C-代码\" class=\"headerlink\" title=\"一、 下面是一段C++代码\"></a>一、 下面是一段C++代码</h3><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;iostream&gt;</span></span>\n<span class=\"hljs-keyword\">using</span> <span class=\"hljs-keyword\">namespace</span> <span class=\"hljs-built_in\">std</span>;\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-built_in\">cout</span> &lt;&lt; <span class=\"hljs-string\">&quot;Hello World!&quot;</span> &lt;&lt; <span class=\"hljs-built_in\">endl</span>;\n&#125;</code></pre>\n<h3 id=\"二、-下面是一段表格\"><a href=\"#二、-下面是一段表格\" class=\"headerlink\" title=\"二、 下面是一段表格\"></a>二、 下面是一段表格</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">0</th>\n<th style=\"text-align:center\">1</th>\n<th style=\"text-align:center\">2</th>\n<th style=\"text-align:center\">3</th>\n<th style=\"text-align:center\">4</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">x</td>\n<td style=\"text-align:center\">x</td>\n<td style=\"text-align:center\">x</td>\n<td style=\"text-align:center\">x</td>\n<td style=\"text-align:center\">x</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"三、-下面是一段-Latex\"><a href=\"#三、-下面是一段-Latex\" class=\"headerlink\" title=\"三、 下面是一段 Latex\"></a>三、 下面是一段 Latex</h3><script type=\"math/tex; mode=display\">E= mc^2</script><h3 id=\"四、下面是一张图片\"><a href=\"#四、下面是一张图片\" class=\"headerlink\" title=\"四、下面是一张图片\"></a>四、下面是一张图片</h3><p><img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRP-ciAYVH8UlH3ZaZC3NkN3ow9CrG36O5crg&amp;usqp=CAU\" alt></p>\n"},{"title":"CS231n Introduction to Convolutional neural network 03","date":"2020-11-10T08:57:26.000Z","index_img":"/img/Cs231n/top.jpg","math":true,"_content":"\n### Computational graphs\n\n![](https://s1.ax1x.com/2020/11/10/BbDAaD.png)\n\n### BackPropagation - A method to compute the gradients of abitrarily complex function\n\n- A recursive application of Chain rule\n\n![](https://s1.ax1x.com/2020/11/10/BbDCKx.png)\n\n> We get the gradient backprop from the front and comupte with the local gradient to prop to the back.\n\n![](https://s1.ax1x.com/2020/11/10/BbDPr6.png)\n\n> In some cases, some part of the graph can be represented by some func that we already know to simplify the computations. (trade off the math)\n\n![](https://s1.ax1x.com/2020/11/10/BbDiqK.png)\n\n- Patterns in backward flow\n\n1. **add gate:** gradient distributor (local = 1)\n2. **max gate:** gradient distributor (local = 1 & 0)\n3. **mul gate:** gradient switcher (local = y & x )\n\n*Gradients add at branches n->1*\n\n- Then We Got the gradients in the form of Jacobian Matrix\n\n![](https://s1.ax1x.com/2020/11/10/BbDkVO.png)\n\n![](https://s1.ax1x.com/2020/11/10/BbDZPH.png)\n\n*This place include some linear algebra*\n\n### Modularized implementation: Forward / Backward API\n\n```python\nclass ComputationalGraph(object):\n    def forward(inputs):\n        # 1. pass inputs to input gates\n        # 2. forward the computational graph\n        for gate in self.graph.nodes_topologically_sorted():\n            gate.forward()\n        return loss\n    def backward():\n        for gate in reversed(self.graph.nodes_topologically_sorted())\n            gate.backward() # compute the gradients\n        return inputs_gradients\n```\n\n#### EXAMPLE: MulGate\n\n```python\nclass MultiplyGate(object):\n    def forward(x, y):\n        z = x*y\n        self.x = x\n        self.y = y\n    def backward(dz):\n        dx = self.y * z\n        dy = self.x * z\n        return [dx, dy]\n```\n\n> This practice is common.\n\n![](https://s1.ax1x.com/2020/11/10/BbDeGd.png)\n\n### Summary so Far\n\n![](https://s1.ax1x.com/2020/11/10/BbDmRA.png)\n\n### Neural networks\n\n(Before) Linear score function: $f = Wx$\n(Now) 2-layers Neural Network $f = W_2max(0, W_1x)$\n....or more layers\n\n![](https://s1.ax1x.com/2020/11/10/BbDEIe.png)\n\n> The h is the scores W1 output, and we put one more linear layer W2 on the top of it to weighting the scores given by h \n","source":"_posts/CS231n/CS231n-03-Introduction-to-Convolutional-neural-network.md","raw":"---\ntitle: CS231n Introduction to Convolutional neural network 03\ndate: 2020-11-10 00:57:26\ntags: [CV,Neural Network]\ncategory: [CS231n]\nindex_img: /img/Cs231n/top.jpg\nmath: true\n---\n\n### Computational graphs\n\n![](https://s1.ax1x.com/2020/11/10/BbDAaD.png)\n\n### BackPropagation - A method to compute the gradients of abitrarily complex function\n\n- A recursive application of Chain rule\n\n![](https://s1.ax1x.com/2020/11/10/BbDCKx.png)\n\n> We get the gradient backprop from the front and comupte with the local gradient to prop to the back.\n\n![](https://s1.ax1x.com/2020/11/10/BbDPr6.png)\n\n> In some cases, some part of the graph can be represented by some func that we already know to simplify the computations. (trade off the math)\n\n![](https://s1.ax1x.com/2020/11/10/BbDiqK.png)\n\n- Patterns in backward flow\n\n1. **add gate:** gradient distributor (local = 1)\n2. **max gate:** gradient distributor (local = 1 & 0)\n3. **mul gate:** gradient switcher (local = y & x )\n\n*Gradients add at branches n->1*\n\n- Then We Got the gradients in the form of Jacobian Matrix\n\n![](https://s1.ax1x.com/2020/11/10/BbDkVO.png)\n\n![](https://s1.ax1x.com/2020/11/10/BbDZPH.png)\n\n*This place include some linear algebra*\n\n### Modularized implementation: Forward / Backward API\n\n```python\nclass ComputationalGraph(object):\n    def forward(inputs):\n        # 1. pass inputs to input gates\n        # 2. forward the computational graph\n        for gate in self.graph.nodes_topologically_sorted():\n            gate.forward()\n        return loss\n    def backward():\n        for gate in reversed(self.graph.nodes_topologically_sorted())\n            gate.backward() # compute the gradients\n        return inputs_gradients\n```\n\n#### EXAMPLE: MulGate\n\n```python\nclass MultiplyGate(object):\n    def forward(x, y):\n        z = x*y\n        self.x = x\n        self.y = y\n    def backward(dz):\n        dx = self.y * z\n        dy = self.x * z\n        return [dx, dy]\n```\n\n> This practice is common.\n\n![](https://s1.ax1x.com/2020/11/10/BbDeGd.png)\n\n### Summary so Far\n\n![](https://s1.ax1x.com/2020/11/10/BbDmRA.png)\n\n### Neural networks\n\n(Before) Linear score function: $f = Wx$\n(Now) 2-layers Neural Network $f = W_2max(0, W_1x)$\n....or more layers\n\n![](https://s1.ax1x.com/2020/11/10/BbDEIe.png)\n\n> The h is the scores W1 output, and we put one more linear layer W2 on the top of it to weighting the scores given by h \n","slug":"CS231n/CS231n-03-Introduction-to-Convolutional-neural-network","published":1,"updated":"2026-02-03T05:42:14.419Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzv800077uit94dz19kn","content":"<h3 id=\"Computational-graphs\"><a href=\"#Computational-graphs\" class=\"headerlink\" title=\"Computational graphs\"></a>Computational graphs</h3><p><img src=\"https://s1.ax1x.com/2020/11/10/BbDAaD.png\" alt></p>\n<h3 id=\"BackPropagation-A-method-to-compute-the-gradients-of-abitrarily-complex-function\"><a href=\"#BackPropagation-A-method-to-compute-the-gradients-of-abitrarily-complex-function\" class=\"headerlink\" title=\"BackPropagation - A method to compute the gradients of abitrarily complex function\"></a>BackPropagation - A method to compute the gradients of abitrarily complex function</h3><ul>\n<li>A recursive application of Chain rule</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDCKx.png\" alt></p>\n<blockquote>\n<p>We get the gradient backprop from the front and comupte with the local gradient to prop to the back.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDPr6.png\" alt></p>\n<blockquote>\n<p>In some cases, some part of the graph can be represented by some func that we already know to simplify the computations. (trade off the math)</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDiqK.png\" alt></p>\n<ul>\n<li>Patterns in backward flow</li>\n</ul>\n<ol>\n<li><strong>add gate:</strong> gradient distributor (local = 1)</li>\n<li><strong>max gate:</strong> gradient distributor (local = 1 &amp; 0)</li>\n<li><strong>mul gate:</strong> gradient switcher (local = y &amp; x )</li>\n</ol>\n<p><em>Gradients add at branches n-&gt;1</em></p>\n<ul>\n<li>Then We Got the gradients in the form of Jacobian Matrix</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDkVO.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDZPH.png\" alt></p>\n<p><em>This place include some linear algebra</em></p>\n<h3 id=\"Modularized-implementation-Forward-Backward-API\"><a href=\"#Modularized-implementation-Forward-Backward-API\" class=\"headerlink\" title=\"Modularized implementation: Forward / Backward API\"></a>Modularized implementation: Forward / Backward API</h3><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ComputationalGraph</span>(<span class=\"hljs-params\"><span class=\"hljs-built_in\">object</span></span>):</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">forward</span>(<span class=\"hljs-params\">inputs</span>):</span>\n        <span class=\"hljs-comment\"># 1. pass inputs to input gates</span>\n        <span class=\"hljs-comment\"># 2. forward the computational graph</span>\n        <span class=\"hljs-keyword\">for</span> gate <span class=\"hljs-keyword\">in</span> self.graph.nodes_topologically_sorted():\n            gate.forward()\n        <span class=\"hljs-keyword\">return</span> loss\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">backward</span>():</span>\n        <span class=\"hljs-keyword\">for</span> gate <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">reversed</span>(self.graph.nodes_topologically_sorted())\n            gate.backward() <span class=\"hljs-comment\"># compute the gradients</span>\n        <span class=\"hljs-keyword\">return</span> inputs_gradients</code></pre>\n<h4 id=\"EXAMPLE-MulGate\"><a href=\"#EXAMPLE-MulGate\" class=\"headerlink\" title=\"EXAMPLE: MulGate\"></a>EXAMPLE: MulGate</h4><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">MultiplyGate</span>(<span class=\"hljs-params\"><span class=\"hljs-built_in\">object</span></span>):</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">forward</span>(<span class=\"hljs-params\">x, y</span>):</span>\n        z = x*y\n        self.x = x\n        self.y = y\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">backward</span>(<span class=\"hljs-params\">dz</span>):</span>\n        dx = self.y * z\n        dy = self.x * z\n        <span class=\"hljs-keyword\">return</span> [dx, dy]</code></pre>\n<blockquote>\n<p>This practice is common.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDeGd.png\" alt></p>\n<h3 id=\"Summary-so-Far\"><a href=\"#Summary-so-Far\" class=\"headerlink\" title=\"Summary so Far\"></a>Summary so Far</h3><p><img src=\"https://s1.ax1x.com/2020/11/10/BbDmRA.png\" alt></p>\n<h3 id=\"Neural-networks\"><a href=\"#Neural-networks\" class=\"headerlink\" title=\"Neural networks\"></a>Neural networks</h3><p>(Before) Linear score function: $f = Wx$<br>(Now) 2-layers Neural Network $f = W_2max(0, W_1x)$<br>….or more layers</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDEIe.png\" alt></p>\n<blockquote>\n<p>The h is the scores W1 output, and we put one more linear layer W2 on the top of it to weighting the scores given by h </p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Computational-graphs\"><a href=\"#Computational-graphs\" class=\"headerlink\" title=\"Computational graphs\"></a>Computational graphs</h3><p><img src=\"https://s1.ax1x.com/2020/11/10/BbDAaD.png\" alt></p>\n<h3 id=\"BackPropagation-A-method-to-compute-the-gradients-of-abitrarily-complex-function\"><a href=\"#BackPropagation-A-method-to-compute-the-gradients-of-abitrarily-complex-function\" class=\"headerlink\" title=\"BackPropagation - A method to compute the gradients of abitrarily complex function\"></a>BackPropagation - A method to compute the gradients of abitrarily complex function</h3><ul>\n<li>A recursive application of Chain rule</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDCKx.png\" alt></p>\n<blockquote>\n<p>We get the gradient backprop from the front and comupte with the local gradient to prop to the back.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDPr6.png\" alt></p>\n<blockquote>\n<p>In some cases, some part of the graph can be represented by some func that we already know to simplify the computations. (trade off the math)</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDiqK.png\" alt></p>\n<ul>\n<li>Patterns in backward flow</li>\n</ul>\n<ol>\n<li><strong>add gate:</strong> gradient distributor (local = 1)</li>\n<li><strong>max gate:</strong> gradient distributor (local = 1 &amp; 0)</li>\n<li><strong>mul gate:</strong> gradient switcher (local = y &amp; x )</li>\n</ol>\n<p><em>Gradients add at branches n-&gt;1</em></p>\n<ul>\n<li>Then We Got the gradients in the form of Jacobian Matrix</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDkVO.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDZPH.png\" alt></p>\n<p><em>This place include some linear algebra</em></p>\n<h3 id=\"Modularized-implementation-Forward-Backward-API\"><a href=\"#Modularized-implementation-Forward-Backward-API\" class=\"headerlink\" title=\"Modularized implementation: Forward / Backward API\"></a>Modularized implementation: Forward / Backward API</h3><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ComputationalGraph</span>(<span class=\"hljs-params\"><span class=\"hljs-built_in\">object</span></span>):</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">forward</span>(<span class=\"hljs-params\">inputs</span>):</span>\n        <span class=\"hljs-comment\"># 1. pass inputs to input gates</span>\n        <span class=\"hljs-comment\"># 2. forward the computational graph</span>\n        <span class=\"hljs-keyword\">for</span> gate <span class=\"hljs-keyword\">in</span> self.graph.nodes_topologically_sorted():\n            gate.forward()\n        <span class=\"hljs-keyword\">return</span> loss\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">backward</span>():</span>\n        <span class=\"hljs-keyword\">for</span> gate <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">reversed</span>(self.graph.nodes_topologically_sorted())\n            gate.backward() <span class=\"hljs-comment\"># compute the gradients</span>\n        <span class=\"hljs-keyword\">return</span> inputs_gradients</code></pre>\n<h4 id=\"EXAMPLE-MulGate\"><a href=\"#EXAMPLE-MulGate\" class=\"headerlink\" title=\"EXAMPLE: MulGate\"></a>EXAMPLE: MulGate</h4><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">MultiplyGate</span>(<span class=\"hljs-params\"><span class=\"hljs-built_in\">object</span></span>):</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">forward</span>(<span class=\"hljs-params\">x, y</span>):</span>\n        z = x*y\n        self.x = x\n        self.y = y\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">backward</span>(<span class=\"hljs-params\">dz</span>):</span>\n        dx = self.y * z\n        dy = self.x * z\n        <span class=\"hljs-keyword\">return</span> [dx, dy]</code></pre>\n<blockquote>\n<p>This practice is common.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDeGd.png\" alt></p>\n<h3 id=\"Summary-so-Far\"><a href=\"#Summary-so-Far\" class=\"headerlink\" title=\"Summary so Far\"></a>Summary so Far</h3><p><img src=\"https://s1.ax1x.com/2020/11/10/BbDmRA.png\" alt></p>\n<h3 id=\"Neural-networks\"><a href=\"#Neural-networks\" class=\"headerlink\" title=\"Neural networks\"></a>Neural networks</h3><p>(Before) Linear score function: $f = Wx$<br>(Now) 2-layers Neural Network $f = W_2max(0, W_1x)$<br>….or more layers</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDEIe.png\" alt></p>\n<blockquote>\n<p>The h is the scores W1 output, and we put one more linear layer W2 on the top of it to weighting the scores given by h </p>\n</blockquote>\n"},{"title":"ELF头简介","date":"2021-03-22T18:48:36.000Z","index_img":"/img/ICS_Lab1/top.jpg","_content":"\n*项目地址： https://github.com/ZiYang-xie/Readelf* （My Readelf Implement）\n\n---\n\n​\t在linux中我们常用readelf指令来读取ELF (Executable and Linkable Format) 文件中的信息，本文首先介绍ELF头的基本信息，在下篇文章中将会介绍一下个人实现的一个简单的读取ELF头的程序，等效于readelf -h <file>\n\n![ELF文件结构](https://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Elf-layout--en.svg/260px-Elf-layout--en.svg.png)\n\n### ELF头\n\nelf头是位于elf文件的头部，里面存储着一些机器和该ELF文件的基本信息。\n\n```c\ntypedef struct {\n        unsigned char   e_ident[EI_NIDENT];\n        Elf64_Half      e_type;\n        Elf64_Half      e_machine;\n        Elf64_Word      e_version;\n        Elf64_Addr      e_entry;\n        Elf64_Off       e_phoff;\n        Elf64_Off       e_shoff;\n        Elf64_Word      e_flags;\n        Elf64_Half      e_ehsize;\n        Elf64_Half      e_phentsize;\n        Elf64_Half      e_phnum;\n        Elf64_Half      e_shentsize;\n        Elf64_Half      e_shnum;\n        Elf64_Half      e_shstrndx;\n} Elf64_Ehdr;\n```\n\n我们分别介绍其含义\n\n---\n\n#### 1、e_ident\n\n- **长度：16字节**\n- **简介：包含着文件和操作系统信息**\n- <img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosklimwgzj30m00fmq55.jpg\" style=\"zoom:50%;\" />\n\n##### Magic Num - e_ident[0:3]\n\n​\t前四个字节包含着一个 magic number，表示该文件是一个 ELF 文件\n\n##### EI_Class - e_ident[4]\n\n​\t指示文件类型，是ELF32还是ELF64位\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskl3oqhyj30dq05qq3h.jpg\" style=\"zoom:50%;\" />\n\n##### EI_DATA - e_ident[5]\n\n​\t指示文件的编码方式，是大端法还是小端法\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskkp5pdjj30fy05ggm5.jpg\" style=\"zoom:50%;\" />\n\n​\t**ELFDATA2LSB - 小端法**\n\n​\t**ELFDATA2MSB - 大端法**\n\n##### EI_Version - e_ident[6]\n\n​\t标识ELF Version, 该值等于EV_CURRENT，目前为1\n\n##### EI_OSABI - e_ident[7]\n\n​\t表示着该文件运行的操作系统\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskk8xx2wj30oi0jmadb.jpg\" alt=\"操作系统类型对应\" style=\"zoom:50%;\" />\n\n##### EI_ABIVERSION - e_ident[8]\n\n​\t标志着 ABI （应用二进制接口）的版本，ABI相当于硬件层级的API（见下图）\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosknnji29j31400u0qd8.jpg\" alt=\"ABI解释\" style=\"zoom:40%;\" />\n\n##### EI_PAD - e_ident[8:15]\n\n​\t填充位，用零填充用以对齐，可以预留给未来使用\n\n\n\n#### 2、e_type\n\n- **长度：2字节**\n\n- **简介：**指示文件类型\n\n  <img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm36oov3j30he0da40a.jpg\" style=\"zoom:50%;\" />\n\n​\t\n\n#### 3、e_machine\n\n- **长度：2字节**\n\n- **简介：**指示机器类型\n\n  <img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm42l3lxj30u00x2wkc.jpg\" alt=\"部分机器类型\" style=\"zoom:50%;\" />\n\n\n\n#### 4、e_version\n\n​\t**长度：4字节**\n\n​\t**简介：指示文件版本**\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm8c0knij30dk04gglx.jpg\" style=\"zoom:50%;\" />\n\n#### 5、e_entry\n\n​\t**长度：4字节（32位）/8字节（64位）**\n\n​\t**简介：进程开始的虚拟地址**\n\n#### 6、e_phoff\n\n​\t**长度：4字节（32位）/8字节（64位）**\n\n​\t**简介：指向程序头部表的开始**\t\n\n#### 7、e_shoff\n\n​\t**长度：4字节（32位）/8字节（64位）**\n\n​\t**简介：指向节头部表的开始**\t\n\n#### 8、e_flags\n\n​\t**长度：4字节**\n\n​\t**简介：意义取决于目标架构**\t\n\n#### 9、e_ehsize\n\n​\t**长度：2字节**\t\n\n​\t**简介：该文件头部的大小**\n\n#### 10、e_phentsize\n\n​\t**长度：2字节**\t\n\n**简介：程序头部的大小**\t\n\n#### 11、e_phnum\n\n​\t**长度：2字节**\t\n\n​\t**简介：程序头部的条目数**\n\n#### 12、e_shentsize\n\n​\t**长度：2字节**\t\n\n​\t**简介：节头部表的大小**\n\n#### 13、e_shnum\n\n​\t**长度：2字节**\t\n\n​\t**简介：节头部表的条目数**\n\n#### 14、e_shstrndx\n\n​\t**长度：2字节**\t\n\n​\t**简介：节头部表的条目和其位置 (idx) 的对应关系**\n\n---\n\n### Reference\n\n[1] https://en.wikipedia.org/wiki/Executable_and_Linkable_Format\n\n[2] https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html\n\n","source":"_posts/Readelf.md","raw":"---\ntitle: ELF头简介\ndate: 2021-03-22 11:48:36\nindex_img: /img/ICS_Lab1/top.jpg\ncategory: [ICS]\ntags: [Link]\n---\n\n*项目地址： https://github.com/ZiYang-xie/Readelf* （My Readelf Implement）\n\n---\n\n​\t在linux中我们常用readelf指令来读取ELF (Executable and Linkable Format) 文件中的信息，本文首先介绍ELF头的基本信息，在下篇文章中将会介绍一下个人实现的一个简单的读取ELF头的程序，等效于readelf -h <file>\n\n![ELF文件结构](https://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Elf-layout--en.svg/260px-Elf-layout--en.svg.png)\n\n### ELF头\n\nelf头是位于elf文件的头部，里面存储着一些机器和该ELF文件的基本信息。\n\n```c\ntypedef struct {\n        unsigned char   e_ident[EI_NIDENT];\n        Elf64_Half      e_type;\n        Elf64_Half      e_machine;\n        Elf64_Word      e_version;\n        Elf64_Addr      e_entry;\n        Elf64_Off       e_phoff;\n        Elf64_Off       e_shoff;\n        Elf64_Word      e_flags;\n        Elf64_Half      e_ehsize;\n        Elf64_Half      e_phentsize;\n        Elf64_Half      e_phnum;\n        Elf64_Half      e_shentsize;\n        Elf64_Half      e_shnum;\n        Elf64_Half      e_shstrndx;\n} Elf64_Ehdr;\n```\n\n我们分别介绍其含义\n\n---\n\n#### 1、e_ident\n\n- **长度：16字节**\n- **简介：包含着文件和操作系统信息**\n- <img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosklimwgzj30m00fmq55.jpg\" style=\"zoom:50%;\" />\n\n##### Magic Num - e_ident[0:3]\n\n​\t前四个字节包含着一个 magic number，表示该文件是一个 ELF 文件\n\n##### EI_Class - e_ident[4]\n\n​\t指示文件类型，是ELF32还是ELF64位\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskl3oqhyj30dq05qq3h.jpg\" style=\"zoom:50%;\" />\n\n##### EI_DATA - e_ident[5]\n\n​\t指示文件的编码方式，是大端法还是小端法\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskkp5pdjj30fy05ggm5.jpg\" style=\"zoom:50%;\" />\n\n​\t**ELFDATA2LSB - 小端法**\n\n​\t**ELFDATA2MSB - 大端法**\n\n##### EI_Version - e_ident[6]\n\n​\t标识ELF Version, 该值等于EV_CURRENT，目前为1\n\n##### EI_OSABI - e_ident[7]\n\n​\t表示着该文件运行的操作系统\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskk8xx2wj30oi0jmadb.jpg\" alt=\"操作系统类型对应\" style=\"zoom:50%;\" />\n\n##### EI_ABIVERSION - e_ident[8]\n\n​\t标志着 ABI （应用二进制接口）的版本，ABI相当于硬件层级的API（见下图）\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosknnji29j31400u0qd8.jpg\" alt=\"ABI解释\" style=\"zoom:40%;\" />\n\n##### EI_PAD - e_ident[8:15]\n\n​\t填充位，用零填充用以对齐，可以预留给未来使用\n\n\n\n#### 2、e_type\n\n- **长度：2字节**\n\n- **简介：**指示文件类型\n\n  <img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm36oov3j30he0da40a.jpg\" style=\"zoom:50%;\" />\n\n​\t\n\n#### 3、e_machine\n\n- **长度：2字节**\n\n- **简介：**指示机器类型\n\n  <img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm42l3lxj30u00x2wkc.jpg\" alt=\"部分机器类型\" style=\"zoom:50%;\" />\n\n\n\n#### 4、e_version\n\n​\t**长度：4字节**\n\n​\t**简介：指示文件版本**\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm8c0knij30dk04gglx.jpg\" style=\"zoom:50%;\" />\n\n#### 5、e_entry\n\n​\t**长度：4字节（32位）/8字节（64位）**\n\n​\t**简介：进程开始的虚拟地址**\n\n#### 6、e_phoff\n\n​\t**长度：4字节（32位）/8字节（64位）**\n\n​\t**简介：指向程序头部表的开始**\t\n\n#### 7、e_shoff\n\n​\t**长度：4字节（32位）/8字节（64位）**\n\n​\t**简介：指向节头部表的开始**\t\n\n#### 8、e_flags\n\n​\t**长度：4字节**\n\n​\t**简介：意义取决于目标架构**\t\n\n#### 9、e_ehsize\n\n​\t**长度：2字节**\t\n\n​\t**简介：该文件头部的大小**\n\n#### 10、e_phentsize\n\n​\t**长度：2字节**\t\n\n**简介：程序头部的大小**\t\n\n#### 11、e_phnum\n\n​\t**长度：2字节**\t\n\n​\t**简介：程序头部的条目数**\n\n#### 12、e_shentsize\n\n​\t**长度：2字节**\t\n\n​\t**简介：节头部表的大小**\n\n#### 13、e_shnum\n\n​\t**长度：2字节**\t\n\n​\t**简介：节头部表的条目数**\n\n#### 14、e_shstrndx\n\n​\t**长度：2字节**\t\n\n​\t**简介：节头部表的条目和其位置 (idx) 的对应关系**\n\n---\n\n### Reference\n\n[1] https://en.wikipedia.org/wiki/Executable_and_Linkable_Format\n\n[2] https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html\n\n","slug":"Readelf","published":1,"updated":"2026-02-03T05:42:14.444Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzv800087uitdqy407ot","content":"<p><em>项目地址： <a href=\"https://github.com/ZiYang-xie/Readelf\">https://github.com/ZiYang-xie/Readelf</a></em> （My Readelf Implement）</p>\n<hr>\n<p>​    在linux中我们常用readelf指令来读取ELF (Executable and Linkable Format) 文件中的信息，本文首先介绍ELF头的基本信息，在下篇文章中将会介绍一下个人实现的一个简单的读取ELF头的程序，等效于readelf -h <file></file></p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Elf-layout--en.svg/260px-Elf-layout--en.svg.png\" alt=\"ELF文件结构\"></p>\n<h3 id=\"ELF头\"><a href=\"#ELF头\" class=\"headerlink\" title=\"ELF头\"></a>ELF头</h3><p>elf头是位于elf文件的头部，里面存储着一些机器和该ELF文件的基本信息。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-keyword\">typedef</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> &#123;</span>\n        <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">char</span>   e_ident[EI_NIDENT];\n        Elf64_Half      e_type;\n        Elf64_Half      e_machine;\n        Elf64_Word      e_version;\n        Elf64_Addr      e_entry;\n        Elf64_Off       e_phoff;\n        Elf64_Off       e_shoff;\n        Elf64_Word      e_flags;\n        Elf64_Half      e_ehsize;\n        Elf64_Half      e_phentsize;\n        Elf64_Half      e_phnum;\n        Elf64_Half      e_shentsize;\n        Elf64_Half      e_shnum;\n        Elf64_Half      e_shstrndx;\n&#125; Elf64_Ehdr;</code></pre>\n<p>我们分别介绍其含义</p>\n<hr>\n<h4 id=\"1、e-ident\"><a href=\"#1、e-ident\" class=\"headerlink\" title=\"1、e_ident\"></a>1、e_ident</h4><ul>\n<li><strong>长度：16字节</strong></li>\n<li><strong>简介：包含着文件和操作系统信息</strong></li>\n<li><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosklimwgzj30m00fmq55.jpg\" style=\"zoom:50%;\"></li>\n</ul>\n<h5 id=\"Magic-Num-e-ident-0-3\"><a href=\"#Magic-Num-e-ident-0-3\" class=\"headerlink\" title=\"Magic Num - e_ident[0:3]\"></a>Magic Num - e_ident[0:3]</h5><p>​    前四个字节包含着一个 magic number，表示该文件是一个 ELF 文件</p>\n<h5 id=\"EI-Class-e-ident-4\"><a href=\"#EI-Class-e-ident-4\" class=\"headerlink\" title=\"EI_Class - e_ident[4]\"></a>EI_Class - e_ident[4]</h5><p>​    指示文件类型，是ELF32还是ELF64位</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskl3oqhyj30dq05qq3h.jpg\" style=\"zoom:50%;\"></p>\n<h5 id=\"EI-DATA-e-ident-5\"><a href=\"#EI-DATA-e-ident-5\" class=\"headerlink\" title=\"EI_DATA - e_ident[5]\"></a>EI_DATA - e_ident[5]</h5><p>​    指示文件的编码方式，是大端法还是小端法</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskkp5pdjj30fy05ggm5.jpg\" style=\"zoom:50%;\"></p>\n<p>​    <strong>ELFDATA2LSB - 小端法</strong></p>\n<p>​    <strong>ELFDATA2MSB - 大端法</strong></p>\n<h5 id=\"EI-Version-e-ident-6\"><a href=\"#EI-Version-e-ident-6\" class=\"headerlink\" title=\"EI_Version - e_ident[6]\"></a>EI_Version - e_ident[6]</h5><p>​    标识ELF Version, 该值等于EV_CURRENT，目前为1</p>\n<h5 id=\"EI-OSABI-e-ident-7\"><a href=\"#EI-OSABI-e-ident-7\" class=\"headerlink\" title=\"EI_OSABI - e_ident[7]\"></a>EI_OSABI - e_ident[7]</h5><p>​    表示着该文件运行的操作系统</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskk8xx2wj30oi0jmadb.jpg\" alt=\"操作系统类型对应\" style=\"zoom:50%;\"></p>\n<h5 id=\"EI-ABIVERSION-e-ident-8\"><a href=\"#EI-ABIVERSION-e-ident-8\" class=\"headerlink\" title=\"EI_ABIVERSION - e_ident[8]\"></a>EI_ABIVERSION - e_ident[8]</h5><p>​    标志着 ABI （应用二进制接口）的版本，ABI相当于硬件层级的API（见下图）</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosknnji29j31400u0qd8.jpg\" alt=\"ABI解释\" style=\"zoom:40%;\"></p>\n<h5 id=\"EI-PAD-e-ident-8-15\"><a href=\"#EI-PAD-e-ident-8-15\" class=\"headerlink\" title=\"EI_PAD - e_ident[8:15]\"></a>EI_PAD - e_ident[8:15]</h5><p>​    填充位，用零填充用以对齐，可以预留给未来使用</p>\n<h4 id=\"2、e-type\"><a href=\"#2、e-type\" class=\"headerlink\" title=\"2、e_type\"></a>2、e_type</h4><ul>\n<li><p><strong>长度：2字节</strong></p>\n</li>\n<li><p><strong>简介：</strong>指示文件类型</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm36oov3j30he0da40a.jpg\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n<p>​    </p>\n<h4 id=\"3、e-machine\"><a href=\"#3、e-machine\" class=\"headerlink\" title=\"3、e_machine\"></a>3、e_machine</h4><ul>\n<li><p><strong>长度：2字节</strong></p>\n</li>\n<li><p><strong>简介：</strong>指示机器类型</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm42l3lxj30u00x2wkc.jpg\" alt=\"部分机器类型\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n<h4 id=\"4、e-version\"><a href=\"#4、e-version\" class=\"headerlink\" title=\"4、e_version\"></a>4、e_version</h4><p>​    <strong>长度：4字节</strong></p>\n<p>​    <strong>简介：指示文件版本</strong></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm8c0knij30dk04gglx.jpg\" style=\"zoom:50%;\"></p>\n<h4 id=\"5、e-entry\"><a href=\"#5、e-entry\" class=\"headerlink\" title=\"5、e_entry\"></a>5、e_entry</h4><p>​    <strong>长度：4字节（32位）/8字节（64位）</strong></p>\n<p>​    <strong>简介：进程开始的虚拟地址</strong></p>\n<h4 id=\"6、e-phoff\"><a href=\"#6、e-phoff\" class=\"headerlink\" title=\"6、e_phoff\"></a>6、e_phoff</h4><p>​    <strong>长度：4字节（32位）/8字节（64位）</strong></p>\n<p>​    <strong>简介：指向程序头部表的开始</strong>    </p>\n<h4 id=\"7、e-shoff\"><a href=\"#7、e-shoff\" class=\"headerlink\" title=\"7、e_shoff\"></a>7、e_shoff</h4><p>​    <strong>长度：4字节（32位）/8字节（64位）</strong></p>\n<p>​    <strong>简介：指向节头部表的开始</strong>    </p>\n<h4 id=\"8、e-flags\"><a href=\"#8、e-flags\" class=\"headerlink\" title=\"8、e_flags\"></a>8、e_flags</h4><p>​    <strong>长度：4字节</strong></p>\n<p>​    <strong>简介：意义取决于目标架构</strong>    </p>\n<h4 id=\"9、e-ehsize\"><a href=\"#9、e-ehsize\" class=\"headerlink\" title=\"9、e_ehsize\"></a>9、e_ehsize</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p>​    <strong>简介：该文件头部的大小</strong></p>\n<h4 id=\"10、e-phentsize\"><a href=\"#10、e-phentsize\" class=\"headerlink\" title=\"10、e_phentsize\"></a>10、e_phentsize</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p><strong>简介：程序头部的大小</strong>    </p>\n<h4 id=\"11、e-phnum\"><a href=\"#11、e-phnum\" class=\"headerlink\" title=\"11、e_phnum\"></a>11、e_phnum</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p>​    <strong>简介：程序头部的条目数</strong></p>\n<h4 id=\"12、e-shentsize\"><a href=\"#12、e-shentsize\" class=\"headerlink\" title=\"12、e_shentsize\"></a>12、e_shentsize</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p>​    <strong>简介：节头部表的大小</strong></p>\n<h4 id=\"13、e-shnum\"><a href=\"#13、e-shnum\" class=\"headerlink\" title=\"13、e_shnum\"></a>13、e_shnum</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p>​    <strong>简介：节头部表的条目数</strong></p>\n<h4 id=\"14、e-shstrndx\"><a href=\"#14、e-shstrndx\" class=\"headerlink\" title=\"14、e_shstrndx\"></a>14、e_shstrndx</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p>​    <strong>简介：节头部表的条目和其位置 (idx) 的对应关系</strong></p>\n<hr>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><p>[1] <a href=\"https://en.wikipedia.org/wiki/Executable_and_Linkable_Format\">https://en.wikipedia.org/wiki/Executable_and_Linkable_Format</a></p>\n<p>[2] <a href=\"https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html\">https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><em>项目地址： <a href=\"https://github.com/ZiYang-xie/Readelf\">https://github.com/ZiYang-xie/Readelf</a></em> （My Readelf Implement）</p>\n<hr>\n<p>​    在linux中我们常用readelf指令来读取ELF (Executable and Linkable Format) 文件中的信息，本文首先介绍ELF头的基本信息，在下篇文章中将会介绍一下个人实现的一个简单的读取ELF头的程序，等效于readelf -h <file></file></p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Elf-layout--en.svg/260px-Elf-layout--en.svg.png\" alt=\"ELF文件结构\"></p>\n<h3 id=\"ELF头\"><a href=\"#ELF头\" class=\"headerlink\" title=\"ELF头\"></a>ELF头</h3><p>elf头是位于elf文件的头部，里面存储着一些机器和该ELF文件的基本信息。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-keyword\">typedef</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> &#123;</span>\n        <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">char</span>   e_ident[EI_NIDENT];\n        Elf64_Half      e_type;\n        Elf64_Half      e_machine;\n        Elf64_Word      e_version;\n        Elf64_Addr      e_entry;\n        Elf64_Off       e_phoff;\n        Elf64_Off       e_shoff;\n        Elf64_Word      e_flags;\n        Elf64_Half      e_ehsize;\n        Elf64_Half      e_phentsize;\n        Elf64_Half      e_phnum;\n        Elf64_Half      e_shentsize;\n        Elf64_Half      e_shnum;\n        Elf64_Half      e_shstrndx;\n&#125; Elf64_Ehdr;</code></pre>\n<p>我们分别介绍其含义</p>\n<hr>\n<h4 id=\"1、e-ident\"><a href=\"#1、e-ident\" class=\"headerlink\" title=\"1、e_ident\"></a>1、e_ident</h4><ul>\n<li><strong>长度：16字节</strong></li>\n<li><strong>简介：包含着文件和操作系统信息</strong></li>\n<li><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosklimwgzj30m00fmq55.jpg\" style=\"zoom:50%;\"></li>\n</ul>\n<h5 id=\"Magic-Num-e-ident-0-3\"><a href=\"#Magic-Num-e-ident-0-3\" class=\"headerlink\" title=\"Magic Num - e_ident[0:3]\"></a>Magic Num - e_ident[0:3]</h5><p>​    前四个字节包含着一个 magic number，表示该文件是一个 ELF 文件</p>\n<h5 id=\"EI-Class-e-ident-4\"><a href=\"#EI-Class-e-ident-4\" class=\"headerlink\" title=\"EI_Class - e_ident[4]\"></a>EI_Class - e_ident[4]</h5><p>​    指示文件类型，是ELF32还是ELF64位</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskl3oqhyj30dq05qq3h.jpg\" style=\"zoom:50%;\"></p>\n<h5 id=\"EI-DATA-e-ident-5\"><a href=\"#EI-DATA-e-ident-5\" class=\"headerlink\" title=\"EI_DATA - e_ident[5]\"></a>EI_DATA - e_ident[5]</h5><p>​    指示文件的编码方式，是大端法还是小端法</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskkp5pdjj30fy05ggm5.jpg\" style=\"zoom:50%;\"></p>\n<p>​    <strong>ELFDATA2LSB - 小端法</strong></p>\n<p>​    <strong>ELFDATA2MSB - 大端法</strong></p>\n<h5 id=\"EI-Version-e-ident-6\"><a href=\"#EI-Version-e-ident-6\" class=\"headerlink\" title=\"EI_Version - e_ident[6]\"></a>EI_Version - e_ident[6]</h5><p>​    标识ELF Version, 该值等于EV_CURRENT，目前为1</p>\n<h5 id=\"EI-OSABI-e-ident-7\"><a href=\"#EI-OSABI-e-ident-7\" class=\"headerlink\" title=\"EI_OSABI - e_ident[7]\"></a>EI_OSABI - e_ident[7]</h5><p>​    表示着该文件运行的操作系统</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskk8xx2wj30oi0jmadb.jpg\" alt=\"操作系统类型对应\" style=\"zoom:50%;\"></p>\n<h5 id=\"EI-ABIVERSION-e-ident-8\"><a href=\"#EI-ABIVERSION-e-ident-8\" class=\"headerlink\" title=\"EI_ABIVERSION - e_ident[8]\"></a>EI_ABIVERSION - e_ident[8]</h5><p>​    标志着 ABI （应用二进制接口）的版本，ABI相当于硬件层级的API（见下图）</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosknnji29j31400u0qd8.jpg\" alt=\"ABI解释\" style=\"zoom:40%;\"></p>\n<h5 id=\"EI-PAD-e-ident-8-15\"><a href=\"#EI-PAD-e-ident-8-15\" class=\"headerlink\" title=\"EI_PAD - e_ident[8:15]\"></a>EI_PAD - e_ident[8:15]</h5><p>​    填充位，用零填充用以对齐，可以预留给未来使用</p>\n<h4 id=\"2、e-type\"><a href=\"#2、e-type\" class=\"headerlink\" title=\"2、e_type\"></a>2、e_type</h4><ul>\n<li><p><strong>长度：2字节</strong></p>\n</li>\n<li><p><strong>简介：</strong>指示文件类型</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm36oov3j30he0da40a.jpg\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n<p>​    </p>\n<h4 id=\"3、e-machine\"><a href=\"#3、e-machine\" class=\"headerlink\" title=\"3、e_machine\"></a>3、e_machine</h4><ul>\n<li><p><strong>长度：2字节</strong></p>\n</li>\n<li><p><strong>简介：</strong>指示机器类型</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm42l3lxj30u00x2wkc.jpg\" alt=\"部分机器类型\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n<h4 id=\"4、e-version\"><a href=\"#4、e-version\" class=\"headerlink\" title=\"4、e_version\"></a>4、e_version</h4><p>​    <strong>长度：4字节</strong></p>\n<p>​    <strong>简介：指示文件版本</strong></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm8c0knij30dk04gglx.jpg\" style=\"zoom:50%;\"></p>\n<h4 id=\"5、e-entry\"><a href=\"#5、e-entry\" class=\"headerlink\" title=\"5、e_entry\"></a>5、e_entry</h4><p>​    <strong>长度：4字节（32位）/8字节（64位）</strong></p>\n<p>​    <strong>简介：进程开始的虚拟地址</strong></p>\n<h4 id=\"6、e-phoff\"><a href=\"#6、e-phoff\" class=\"headerlink\" title=\"6、e_phoff\"></a>6、e_phoff</h4><p>​    <strong>长度：4字节（32位）/8字节（64位）</strong></p>\n<p>​    <strong>简介：指向程序头部表的开始</strong>    </p>\n<h4 id=\"7、e-shoff\"><a href=\"#7、e-shoff\" class=\"headerlink\" title=\"7、e_shoff\"></a>7、e_shoff</h4><p>​    <strong>长度：4字节（32位）/8字节（64位）</strong></p>\n<p>​    <strong>简介：指向节头部表的开始</strong>    </p>\n<h4 id=\"8、e-flags\"><a href=\"#8、e-flags\" class=\"headerlink\" title=\"8、e_flags\"></a>8、e_flags</h4><p>​    <strong>长度：4字节</strong></p>\n<p>​    <strong>简介：意义取决于目标架构</strong>    </p>\n<h4 id=\"9、e-ehsize\"><a href=\"#9、e-ehsize\" class=\"headerlink\" title=\"9、e_ehsize\"></a>9、e_ehsize</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p>​    <strong>简介：该文件头部的大小</strong></p>\n<h4 id=\"10、e-phentsize\"><a href=\"#10、e-phentsize\" class=\"headerlink\" title=\"10、e_phentsize\"></a>10、e_phentsize</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p><strong>简介：程序头部的大小</strong>    </p>\n<h4 id=\"11、e-phnum\"><a href=\"#11、e-phnum\" class=\"headerlink\" title=\"11、e_phnum\"></a>11、e_phnum</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p>​    <strong>简介：程序头部的条目数</strong></p>\n<h4 id=\"12、e-shentsize\"><a href=\"#12、e-shentsize\" class=\"headerlink\" title=\"12、e_shentsize\"></a>12、e_shentsize</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p>​    <strong>简介：节头部表的大小</strong></p>\n<h4 id=\"13、e-shnum\"><a href=\"#13、e-shnum\" class=\"headerlink\" title=\"13、e_shnum\"></a>13、e_shnum</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p>​    <strong>简介：节头部表的条目数</strong></p>\n<h4 id=\"14、e-shstrndx\"><a href=\"#14、e-shstrndx\" class=\"headerlink\" title=\"14、e_shstrndx\"></a>14、e_shstrndx</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p>​    <strong>简介：节头部表的条目和其位置 (idx) 的对应关系</strong></p>\n<hr>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><p>[1] <a href=\"https://en.wikipedia.org/wiki/Executable_and_Linkable_Format\">https://en.wikipedia.org/wiki/Executable_and_Linkable_Format</a></p>\n<p>[2] <a href=\"https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html\">https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html</a></p>\n"},{"title":"CS231n Convolutional_Neural_Networks 04","date":"2020-11-11T08:57:54.000Z","index_img":"/img/Cs231n/top.jpg","math":true,"_content":"\n### A bit of CNN History\n\n![](https://s1.ax1x.com/2020/11/11/BOGJ5n.png)\n\n![](https://s1.ax1x.com/2020/11/11/BOGGUs.png)\n\n#### Fully Connected Layer\n\n![](https://s1.ax1x.com/2020/11/11/BOGlDg.png)\n\n#### Convolution Layer\n\n![](https://s1.ax1x.com/2020/11/11/BOG1bQ.png)\n\n> We just let the 5x5x3 filter $w$ to take a dot product between itself and a small 5x5z3 chunck of the image\n\n$$W^Tx+b$$\n**The $W$ and $x$ is streched into 1 dimention vec**\n\n- Then the Outcome:\n\n![](https://s1.ax1x.com/2020/11/11/BOG8Ej.png)\n\n> We can use different layers on the top of it and get more activation maps stack them together to get a new image, just as the following pic depicted.\n\n![](https://s1.ax1x.com/2020/11/11/BOGtCq.png)\n\n> Then we can recursively do that work, make the front layer's output be the next layer's input\n\n![](https://s1.ax1x.com/2020/11/11/BOGU2V.png)\n\n**The Layers may look like..**\n*Simple -> Complex*\n \n![](https://s1.ax1x.com/2020/11/11/BOGN80.png)\n\n![](https://s1.ax1x.com/2020/11/11/BOGrVJ.png)\n\n- The Convolution of two signals:\n\n$$f[x,y]*g[x,y] = \\sum\\limits_{n_1 = -\\infin}^{\\infin}\\sum\\limits_{n_2 = -\\infin}^{\\infin}f[n_1,n_2]·g[x-n_1,y-n_2]$$\n\n- A little bit preview\n\n![](https://s1.ax1x.com/2020/11/11/BOG0rF.png)\n\n---\n\n- Convolution Box\n\n![](https://s1.ax1x.com/2020/11/11/BOGwKU.png)\n\n> We can tell that the activation maps are becomming smaller after the filter, so we commonly use zero pad to deal with it.\n\n![](https://s1.ax1x.com/2020/11/11/BOGBb4.png)\n\n![](https://s1.ax1x.com/2020/11/11/BOGsa9.png)\n\n> The Matrix shrinks from 32 —> 28 -> 24 (lose info)\n\n---\n\n### Summary\n1. Accepts a volume of size $W_1 * H_1 * D_1$\n2. Four Hyperparas\n    - Number of filters $K$\n    - spatial extent $F$\n    - stride $S$\n    - zero padding amount $P$\n3. Produces a volume of size $W_2 * H_2 * D_2$\n    - $W_2 = (W_1 - F + 2P)/S + 1$\n    - $H_2 = (H_1 - F + 2P)/S + 1$\n    - $D_2 = K$ *Depth keeps the same*\n\n#### Common Settings\n\nK = (powers of 2)\n- F = 3, S = 1, P =1\n- F = 5, S = 1, P =2\n- F = 1, S = 1, P = 0 \n\n---\n\n### Conv details\n\n- One by One CONV\n\n![](https://s1.ax1x.com/2020/11/11/BOGy5R.png)\n\n- EXAMPLE: CONV in pyTorch\n\n![](https://s1.ax1x.com/2020/11/11/BOGRxK.png)\n\n- The Brain/Neuron View of CONV\n\n![](https://s1.ax1x.com/2020/11/11/BOG226.png)\n\n- Pooling layer\n\n![](https://s1.ax1x.com/2020/11/11/BOGg8x.png)\n\n> Just spacially down sample the image to make it smaller.\nCommon Practice is Max Pooling\n\n![](https://s1.ax1x.com/2020/11/11/BOGcP1.png)\n\n> We may can just use stride to replace pooling?\n\n\n","source":"_posts/CS231n/CS231n-04-Convolutional-Neural-Networks.md","raw":"---\ntitle: CS231n Convolutional_Neural_Networks 04\ndate: 2020-11-11 00:57:54\ntags: [CV,Neural Network]\ncategory: [CS231n]\nindex_img: /img/Cs231n/top.jpg\nmath: true\n---\n\n### A bit of CNN History\n\n![](https://s1.ax1x.com/2020/11/11/BOGJ5n.png)\n\n![](https://s1.ax1x.com/2020/11/11/BOGGUs.png)\n\n#### Fully Connected Layer\n\n![](https://s1.ax1x.com/2020/11/11/BOGlDg.png)\n\n#### Convolution Layer\n\n![](https://s1.ax1x.com/2020/11/11/BOG1bQ.png)\n\n> We just let the 5x5x3 filter $w$ to take a dot product between itself and a small 5x5z3 chunck of the image\n\n$$W^Tx+b$$\n**The $W$ and $x$ is streched into 1 dimention vec**\n\n- Then the Outcome:\n\n![](https://s1.ax1x.com/2020/11/11/BOG8Ej.png)\n\n> We can use different layers on the top of it and get more activation maps stack them together to get a new image, just as the following pic depicted.\n\n![](https://s1.ax1x.com/2020/11/11/BOGtCq.png)\n\n> Then we can recursively do that work, make the front layer's output be the next layer's input\n\n![](https://s1.ax1x.com/2020/11/11/BOGU2V.png)\n\n**The Layers may look like..**\n*Simple -> Complex*\n \n![](https://s1.ax1x.com/2020/11/11/BOGN80.png)\n\n![](https://s1.ax1x.com/2020/11/11/BOGrVJ.png)\n\n- The Convolution of two signals:\n\n$$f[x,y]*g[x,y] = \\sum\\limits_{n_1 = -\\infin}^{\\infin}\\sum\\limits_{n_2 = -\\infin}^{\\infin}f[n_1,n_2]·g[x-n_1,y-n_2]$$\n\n- A little bit preview\n\n![](https://s1.ax1x.com/2020/11/11/BOG0rF.png)\n\n---\n\n- Convolution Box\n\n![](https://s1.ax1x.com/2020/11/11/BOGwKU.png)\n\n> We can tell that the activation maps are becomming smaller after the filter, so we commonly use zero pad to deal with it.\n\n![](https://s1.ax1x.com/2020/11/11/BOGBb4.png)\n\n![](https://s1.ax1x.com/2020/11/11/BOGsa9.png)\n\n> The Matrix shrinks from 32 —> 28 -> 24 (lose info)\n\n---\n\n### Summary\n1. Accepts a volume of size $W_1 * H_1 * D_1$\n2. Four Hyperparas\n    - Number of filters $K$\n    - spatial extent $F$\n    - stride $S$\n    - zero padding amount $P$\n3. Produces a volume of size $W_2 * H_2 * D_2$\n    - $W_2 = (W_1 - F + 2P)/S + 1$\n    - $H_2 = (H_1 - F + 2P)/S + 1$\n    - $D_2 = K$ *Depth keeps the same*\n\n#### Common Settings\n\nK = (powers of 2)\n- F = 3, S = 1, P =1\n- F = 5, S = 1, P =2\n- F = 1, S = 1, P = 0 \n\n---\n\n### Conv details\n\n- One by One CONV\n\n![](https://s1.ax1x.com/2020/11/11/BOGy5R.png)\n\n- EXAMPLE: CONV in pyTorch\n\n![](https://s1.ax1x.com/2020/11/11/BOGRxK.png)\n\n- The Brain/Neuron View of CONV\n\n![](https://s1.ax1x.com/2020/11/11/BOG226.png)\n\n- Pooling layer\n\n![](https://s1.ax1x.com/2020/11/11/BOGg8x.png)\n\n> Just spacially down sample the image to make it smaller.\nCommon Practice is Max Pooling\n\n![](https://s1.ax1x.com/2020/11/11/BOGcP1.png)\n\n> We may can just use stride to replace pooling?\n\n\n","slug":"CS231n/CS231n-04-Convolutional-Neural-Networks","published":1,"updated":"2026-02-03T05:42:14.420Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzv9000c7uitgr7m7qb2","content":"<h3 id=\"A-bit-of-CNN-History\"><a href=\"#A-bit-of-CNN-History\" class=\"headerlink\" title=\"A bit of CNN History\"></a>A bit of CNN History</h3><p><img src=\"https://s1.ax1x.com/2020/11/11/BOGJ5n.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGGUs.png\" alt></p>\n<h4 id=\"Fully-Connected-Layer\"><a href=\"#Fully-Connected-Layer\" class=\"headerlink\" title=\"Fully Connected Layer\"></a>Fully Connected Layer</h4><p><img src=\"https://s1.ax1x.com/2020/11/11/BOGlDg.png\" alt></p>\n<h4 id=\"Convolution-Layer\"><a href=\"#Convolution-Layer\" class=\"headerlink\" title=\"Convolution Layer\"></a>Convolution Layer</h4><p><img src=\"https://s1.ax1x.com/2020/11/11/BOG1bQ.png\" alt></p>\n<blockquote>\n<p>We just let the 5x5x3 filter $w$ to take a dot product between itself and a small 5x5z3 chunck of the image</p>\n</blockquote>\n<script type=\"math/tex; mode=display\">W^Tx+b</script><p><strong>The $W$ and $x$ is streched into 1 dimention vec</strong></p>\n<ul>\n<li>Then the Outcome:</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOG8Ej.png\" alt></p>\n<blockquote>\n<p>We can use different layers on the top of it and get more activation maps stack them together to get a new image, just as the following pic depicted.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGtCq.png\" alt></p>\n<blockquote>\n<p>Then we can recursively do that work, make the front layer’s output be the next layer’s input</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGU2V.png\" alt></p>\n<p><strong>The Layers may look like..</strong><br><em>Simple -&gt; Complex</em></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGN80.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGrVJ.png\" alt></p>\n<ul>\n<li>The Convolution of two signals:</li>\n</ul>\n<script type=\"math/tex; mode=display\">f[x,y]*g[x,y] = \\sum\\limits_{n_1 = -\\infin}^{\\infin}\\sum\\limits_{n_2 = -\\infin}^{\\infin}f[n_1,n_2]·g[x-n_1,y-n_2]</script><ul>\n<li>A little bit preview</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOG0rF.png\" alt></p>\n<hr>\n<ul>\n<li>Convolution Box</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGwKU.png\" alt></p>\n<blockquote>\n<p>We can tell that the activation maps are becomming smaller after the filter, so we commonly use zero pad to deal with it.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGBb4.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGsa9.png\" alt></p>\n<blockquote>\n<p>The Matrix shrinks from 32 —&gt; 28 -&gt; 24 (lose info)</p>\n</blockquote>\n<hr>\n<h3 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h3><ol>\n<li>Accepts a volume of size $W_1 <em> H_1 </em> D_1$</li>\n<li>Four Hyperparas<ul>\n<li>Number of filters $K$</li>\n<li>spatial extent $F$</li>\n<li>stride $S$</li>\n<li>zero padding amount $P$</li>\n</ul>\n</li>\n<li>Produces a volume of size $W_2 <em> H_2 </em> D_2$<ul>\n<li>$W_2 = (W_1 - F + 2P)/S + 1$</li>\n<li>$H_2 = (H_1 - F + 2P)/S + 1$</li>\n<li>$D_2 = K$ <em>Depth keeps the same</em></li>\n</ul>\n</li>\n</ol>\n<h4 id=\"Common-Settings\"><a href=\"#Common-Settings\" class=\"headerlink\" title=\"Common Settings\"></a>Common Settings</h4><p>K = (powers of 2)</p>\n<ul>\n<li>F = 3, S = 1, P =1</li>\n<li>F = 5, S = 1, P =2</li>\n<li>F = 1, S = 1, P = 0 </li>\n</ul>\n<hr>\n<h3 id=\"Conv-details\"><a href=\"#Conv-details\" class=\"headerlink\" title=\"Conv details\"></a>Conv details</h3><ul>\n<li>One by One CONV</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGy5R.png\" alt></p>\n<ul>\n<li>EXAMPLE: CONV in pyTorch</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGRxK.png\" alt></p>\n<ul>\n<li>The Brain/Neuron View of CONV</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOG226.png\" alt></p>\n<ul>\n<li>Pooling layer</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGg8x.png\" alt></p>\n<blockquote>\n<p>Just spacially down sample the image to make it smaller.<br>Common Practice is Max Pooling</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGcP1.png\" alt></p>\n<blockquote>\n<p>We may can just use stride to replace pooling?</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"A-bit-of-CNN-History\"><a href=\"#A-bit-of-CNN-History\" class=\"headerlink\" title=\"A bit of CNN History\"></a>A bit of CNN History</h3><p><img src=\"https://s1.ax1x.com/2020/11/11/BOGJ5n.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGGUs.png\" alt></p>\n<h4 id=\"Fully-Connected-Layer\"><a href=\"#Fully-Connected-Layer\" class=\"headerlink\" title=\"Fully Connected Layer\"></a>Fully Connected Layer</h4><p><img src=\"https://s1.ax1x.com/2020/11/11/BOGlDg.png\" alt></p>\n<h4 id=\"Convolution-Layer\"><a href=\"#Convolution-Layer\" class=\"headerlink\" title=\"Convolution Layer\"></a>Convolution Layer</h4><p><img src=\"https://s1.ax1x.com/2020/11/11/BOG1bQ.png\" alt></p>\n<blockquote>\n<p>We just let the 5x5x3 filter $w$ to take a dot product between itself and a small 5x5z3 chunck of the image</p>\n</blockquote>\n<script type=\"math/tex; mode=display\">W^Tx+b</script><p><strong>The $W$ and $x$ is streched into 1 dimention vec</strong></p>\n<ul>\n<li>Then the Outcome:</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOG8Ej.png\" alt></p>\n<blockquote>\n<p>We can use different layers on the top of it and get more activation maps stack them together to get a new image, just as the following pic depicted.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGtCq.png\" alt></p>\n<blockquote>\n<p>Then we can recursively do that work, make the front layer’s output be the next layer’s input</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGU2V.png\" alt></p>\n<p><strong>The Layers may look like..</strong><br><em>Simple -&gt; Complex</em></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGN80.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGrVJ.png\" alt></p>\n<ul>\n<li>The Convolution of two signals:</li>\n</ul>\n<script type=\"math/tex; mode=display\">f[x,y]*g[x,y] = \\sum\\limits_{n_1 = -\\infin}^{\\infin}\\sum\\limits_{n_2 = -\\infin}^{\\infin}f[n_1,n_2]·g[x-n_1,y-n_2]</script><ul>\n<li>A little bit preview</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOG0rF.png\" alt></p>\n<hr>\n<ul>\n<li>Convolution Box</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGwKU.png\" alt></p>\n<blockquote>\n<p>We can tell that the activation maps are becomming smaller after the filter, so we commonly use zero pad to deal with it.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGBb4.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGsa9.png\" alt></p>\n<blockquote>\n<p>The Matrix shrinks from 32 —&gt; 28 -&gt; 24 (lose info)</p>\n</blockquote>\n<hr>\n<h3 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h3><ol>\n<li>Accepts a volume of size $W_1 <em> H_1 </em> D_1$</li>\n<li>Four Hyperparas<ul>\n<li>Number of filters $K$</li>\n<li>spatial extent $F$</li>\n<li>stride $S$</li>\n<li>zero padding amount $P$</li>\n</ul>\n</li>\n<li>Produces a volume of size $W_2 <em> H_2 </em> D_2$<ul>\n<li>$W_2 = (W_1 - F + 2P)/S + 1$</li>\n<li>$H_2 = (H_1 - F + 2P)/S + 1$</li>\n<li>$D_2 = K$ <em>Depth keeps the same</em></li>\n</ul>\n</li>\n</ol>\n<h4 id=\"Common-Settings\"><a href=\"#Common-Settings\" class=\"headerlink\" title=\"Common Settings\"></a>Common Settings</h4><p>K = (powers of 2)</p>\n<ul>\n<li>F = 3, S = 1, P =1</li>\n<li>F = 5, S = 1, P =2</li>\n<li>F = 1, S = 1, P = 0 </li>\n</ul>\n<hr>\n<h3 id=\"Conv-details\"><a href=\"#Conv-details\" class=\"headerlink\" title=\"Conv details\"></a>Conv details</h3><ul>\n<li>One by One CONV</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGy5R.png\" alt></p>\n<ul>\n<li>EXAMPLE: CONV in pyTorch</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGRxK.png\" alt></p>\n<ul>\n<li>The Brain/Neuron View of CONV</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOG226.png\" alt></p>\n<ul>\n<li>Pooling layer</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGg8x.png\" alt></p>\n<blockquote>\n<p>Just spacially down sample the image to make it smaller.<br>Common Practice is Max Pooling</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGcP1.png\" alt></p>\n<blockquote>\n<p>We may can just use stride to replace pooling?</p>\n</blockquote>\n"},{"title":"CS231n Training Neural Networks I 05","date":"2020-11-14T05:09:24.000Z","index_img":"/img/Cs231n/top.jpg","math":true,"_content":"\n### OverView\n1. One time setup\n2. Training dynamics\n3. Evaluation\n\n### Part 1\n- Activation Functions\n- Data Preprocessing\n- Weight initialization\n- Batch Normalization\n- Babysitting the Learning Process\n- Hyperparameter Optimization\n\n---\n\n### Activation Functions\n\n![](https://s3.ax1x.com/2020/11/13/D9uofs.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9uIYj.png)\n\n#### Sigmoid \n\n$$\\sigma(x) = 1/(1+e^{-x})$$\n\n- Squashes numbers to range [0,1]\n- Historically popular \"firing rate\" of a neuron\n\n![](https://s3.ax1x.com/2020/11/13/D9uhTg.png)\n\n**3 Problems**\n1. Saturated the neural may kill the gradient.\n\n![](https://s3.ax1x.com/2020/11/13/D9u5kQ.png)\n\n> x is a very negative and very positive val, its gradient will be killed to zero\n\n1. Sigmoid outputs are not zero-centered\n\n![](https://s3.ax1x.com/2020/11/13/D9u7pn.png)\n\n> For the sign of x and gradient is always the same, it gonna behaves like is above pic.\n\n> thats why we need zero-mean data, to optimize the w just through the zig zag path.\n\n1. exp() is a bit compute expensive\n\n---\n\n#### Tanh\n\n- Squashes numbers to range [-1, 1]\n- zero centered (nice)\n- still kills gradients when saturated\n\n![](https://s3.ax1x.com/2020/11/13/D9uHlq.png)\n\n---\n\n#### ReLU\n\n$$f(x) = max(0, x)$$\n\n![](https://s3.ax1x.com/2020/11/13/D9ub60.png)\n\n- Does not saturate (in + region)\n- Very computationally efficient\n- Converges much faster than sigmoid/tanh in practice\n- Actually more biologically plausible than sigmoid\n\n**Problems**\n1. Not zero-centered output\n2. An annoyance:\n3. when x <= 0 the gradient is slashed to zero (kill half the gradient)\n\n![](https://s3.ax1x.com/2020/11/13/D9uX0U.png)\n\n- Bad Init\n- Learning rate too high\n\n> people like to initialize ReLU neurons with slightly positive biases (eg 0.01), to increase the possibility that being activated.\n\n---\n\n#### Leaky ReLu\n\n$$f(x) = max(0.01x,x)$$\n\n![](https://s3.ax1x.com/2020/11/13/D9uqXV.png)\n\n- Does not saturated\n- Computationally efficient\n- Converges much faster ...\n- **will not die**\n\nor **Para Rectifier ReLu**\n\n$$f(x) = max(\\alpha{x},x)$$\n\n---\n\n#### Exponential Linear Units (ELU)\n\n![](https://s3.ax1x.com/2020/11/13/D9uOmT.png)\n\n- All benefits of ReLU\n- Closer to zero mean outputs\n- Negative saturation regime adds some robustness to noise\n\n*While it requires exp()*\n\n---\n\n#### Maxout \"Neuron\"\n\n![](https://s3.ax1x.com/2020/11/13/D9uj7F.png)\n\n---\n\n#### In practice\n\n- Use ReLU. (zbe careful with learning rates)\n- Try Leaky *ReLU / Maxout / ELU*\n- Don't use sigmoid\n\n---\n\n### Data Preprocessing\n\n#### Step1: Preprocess the data\n\n![](https://s3.ax1x.com/2020/11/13/D9uxk4.png)\n\n- In CV we usually don't normalize the data.\n\n![](https://s3.ax1x.com/2020/11/13/D9KSh9.png)\n\nPractice above make the data zero-mean, but only the first layer, and that's why we need the activation func tobe zero-mean.\n\n---\n\n### Weight Initialization\n\n#### First idea: Small random numbers\n\n```python\nW = 0.01* np.random.randn(D,H)\n```\n\n> Works Okay for small, but have problems in big one.\n\n![](https://s3.ax1x.com/2020/11/13/D9KC11.png)\n\n#### How about making Weight big?\n\n![](https://s3.ax1x.com/2020/11/13/D9KP6x.png)\n\n> it gonna saturated the regime to be either very possitive or very negative input of tanh, and comes out near zero gradients. The weight will not be updated.\n\n\n#### Xavier initialization\n*Woo my initialzation? haha*\n\n![](https://s3.ax1x.com/2020/11/13/D9KiX6.png)\n\n> ensure we are at the active region of tanh\n\n![](https://s3.ax1x.com/2020/11/13/D9KA0O.png)\n\n> Can be addressed by add an extra /2， to ensure the neural won't die in ReLU\n\n---\n\n### Batch Normalization\n\n![](https://s3.ax1x.com/2020/11/13/D9KknK.png)\n\n> To regulize the input tobe unit gaussian.\n\n*I have no idea about it. What is unit gaussian?*\n\n![](https://s3.ax1x.com/2020/11/13/D9KetH.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9KE7D.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9KZAe.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9Kmhd.png)\n\n---\n\n### Babysitting the Learning Process\n\n- 1. Preprocess data\n- 2. Choose the architecture:\n- 3. Double check that the loss is reasonable\n\n![](https://s3.ax1x.com/2020/11/13/D9KK1I.png)\n\n#### The Learning Rate\n\n- Very small learning rate 1e-6\n> litter help\n\n![](https://s3.ax1x.com/2020/11/13/D9K3B8.png)\n\n- Very great learning rate 1e6\n> go extreme\n\n![](https://s3.ax1x.com/2020/11/13/D9KQjP.png)\n\n- A Rough Range\n\n$$1\\times{10}^{-3} \\to 1\\times{10}^{-5} $$\n\n---\n\n### Hyperparameter Optimization\n\n- Cross-validation strategy\n*coarse -> fine*\n\n- Random Sample\n\n![](https://s3.ax1x.com/2020/11/13/D9Ku9A.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9KMct.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9K1nf.png)\n","source":"_posts/CS231n/CS231n-05-Training-Neural-Networks-I.md","raw":"---\ntitle: CS231n Training Neural Networks I 05\ndate: 2020-11-13 21:09:24\ntags: [CV,Neural Network]\ncategory: [CS231n]\nindex_img: /img/Cs231n/top.jpg\nmath: true\n---\n\n### OverView\n1. One time setup\n2. Training dynamics\n3. Evaluation\n\n### Part 1\n- Activation Functions\n- Data Preprocessing\n- Weight initialization\n- Batch Normalization\n- Babysitting the Learning Process\n- Hyperparameter Optimization\n\n---\n\n### Activation Functions\n\n![](https://s3.ax1x.com/2020/11/13/D9uofs.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9uIYj.png)\n\n#### Sigmoid \n\n$$\\sigma(x) = 1/(1+e^{-x})$$\n\n- Squashes numbers to range [0,1]\n- Historically popular \"firing rate\" of a neuron\n\n![](https://s3.ax1x.com/2020/11/13/D9uhTg.png)\n\n**3 Problems**\n1. Saturated the neural may kill the gradient.\n\n![](https://s3.ax1x.com/2020/11/13/D9u5kQ.png)\n\n> x is a very negative and very positive val, its gradient will be killed to zero\n\n1. Sigmoid outputs are not zero-centered\n\n![](https://s3.ax1x.com/2020/11/13/D9u7pn.png)\n\n> For the sign of x and gradient is always the same, it gonna behaves like is above pic.\n\n> thats why we need zero-mean data, to optimize the w just through the zig zag path.\n\n1. exp() is a bit compute expensive\n\n---\n\n#### Tanh\n\n- Squashes numbers to range [-1, 1]\n- zero centered (nice)\n- still kills gradients when saturated\n\n![](https://s3.ax1x.com/2020/11/13/D9uHlq.png)\n\n---\n\n#### ReLU\n\n$$f(x) = max(0, x)$$\n\n![](https://s3.ax1x.com/2020/11/13/D9ub60.png)\n\n- Does not saturate (in + region)\n- Very computationally efficient\n- Converges much faster than sigmoid/tanh in practice\n- Actually more biologically plausible than sigmoid\n\n**Problems**\n1. Not zero-centered output\n2. An annoyance:\n3. when x <= 0 the gradient is slashed to zero (kill half the gradient)\n\n![](https://s3.ax1x.com/2020/11/13/D9uX0U.png)\n\n- Bad Init\n- Learning rate too high\n\n> people like to initialize ReLU neurons with slightly positive biases (eg 0.01), to increase the possibility that being activated.\n\n---\n\n#### Leaky ReLu\n\n$$f(x) = max(0.01x,x)$$\n\n![](https://s3.ax1x.com/2020/11/13/D9uqXV.png)\n\n- Does not saturated\n- Computationally efficient\n- Converges much faster ...\n- **will not die**\n\nor **Para Rectifier ReLu**\n\n$$f(x) = max(\\alpha{x},x)$$\n\n---\n\n#### Exponential Linear Units (ELU)\n\n![](https://s3.ax1x.com/2020/11/13/D9uOmT.png)\n\n- All benefits of ReLU\n- Closer to zero mean outputs\n- Negative saturation regime adds some robustness to noise\n\n*While it requires exp()*\n\n---\n\n#### Maxout \"Neuron\"\n\n![](https://s3.ax1x.com/2020/11/13/D9uj7F.png)\n\n---\n\n#### In practice\n\n- Use ReLU. (zbe careful with learning rates)\n- Try Leaky *ReLU / Maxout / ELU*\n- Don't use sigmoid\n\n---\n\n### Data Preprocessing\n\n#### Step1: Preprocess the data\n\n![](https://s3.ax1x.com/2020/11/13/D9uxk4.png)\n\n- In CV we usually don't normalize the data.\n\n![](https://s3.ax1x.com/2020/11/13/D9KSh9.png)\n\nPractice above make the data zero-mean, but only the first layer, and that's why we need the activation func tobe zero-mean.\n\n---\n\n### Weight Initialization\n\n#### First idea: Small random numbers\n\n```python\nW = 0.01* np.random.randn(D,H)\n```\n\n> Works Okay for small, but have problems in big one.\n\n![](https://s3.ax1x.com/2020/11/13/D9KC11.png)\n\n#### How about making Weight big?\n\n![](https://s3.ax1x.com/2020/11/13/D9KP6x.png)\n\n> it gonna saturated the regime to be either very possitive or very negative input of tanh, and comes out near zero gradients. The weight will not be updated.\n\n\n#### Xavier initialization\n*Woo my initialzation? haha*\n\n![](https://s3.ax1x.com/2020/11/13/D9KiX6.png)\n\n> ensure we are at the active region of tanh\n\n![](https://s3.ax1x.com/2020/11/13/D9KA0O.png)\n\n> Can be addressed by add an extra /2， to ensure the neural won't die in ReLU\n\n---\n\n### Batch Normalization\n\n![](https://s3.ax1x.com/2020/11/13/D9KknK.png)\n\n> To regulize the input tobe unit gaussian.\n\n*I have no idea about it. What is unit gaussian?*\n\n![](https://s3.ax1x.com/2020/11/13/D9KetH.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9KE7D.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9KZAe.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9Kmhd.png)\n\n---\n\n### Babysitting the Learning Process\n\n- 1. Preprocess data\n- 2. Choose the architecture:\n- 3. Double check that the loss is reasonable\n\n![](https://s3.ax1x.com/2020/11/13/D9KK1I.png)\n\n#### The Learning Rate\n\n- Very small learning rate 1e-6\n> litter help\n\n![](https://s3.ax1x.com/2020/11/13/D9K3B8.png)\n\n- Very great learning rate 1e6\n> go extreme\n\n![](https://s3.ax1x.com/2020/11/13/D9KQjP.png)\n\n- A Rough Range\n\n$$1\\times{10}^{-3} \\to 1\\times{10}^{-5} $$\n\n---\n\n### Hyperparameter Optimization\n\n- Cross-validation strategy\n*coarse -> fine*\n\n- Random Sample\n\n![](https://s3.ax1x.com/2020/11/13/D9Ku9A.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9KMct.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9K1nf.png)\n","slug":"CS231n/CS231n-05-Training-Neural-Networks-I","published":1,"updated":"2026-02-03T05:42:14.421Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzv9000d7uit3xkg1efx","content":"<h3 id=\"OverView\"><a href=\"#OverView\" class=\"headerlink\" title=\"OverView\"></a>OverView</h3><ol>\n<li>One time setup</li>\n<li>Training dynamics</li>\n<li>Evaluation</li>\n</ol>\n<h3 id=\"Part-1\"><a href=\"#Part-1\" class=\"headerlink\" title=\"Part 1\"></a>Part 1</h3><ul>\n<li>Activation Functions</li>\n<li>Data Preprocessing</li>\n<li>Weight initialization</li>\n<li>Batch Normalization</li>\n<li>Babysitting the Learning Process</li>\n<li>Hyperparameter Optimization</li>\n</ul>\n<hr>\n<h3 id=\"Activation-Functions\"><a href=\"#Activation-Functions\" class=\"headerlink\" title=\"Activation Functions\"></a>Activation Functions</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9uofs.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9uIYj.png\" alt></p>\n<h4 id=\"Sigmoid\"><a href=\"#Sigmoid\" class=\"headerlink\" title=\"Sigmoid\"></a>Sigmoid</h4><script type=\"math/tex; mode=display\">\\sigma(x) = 1/(1+e^{-x})</script><ul>\n<li>Squashes numbers to range [0,1]</li>\n<li>Historically popular “firing rate” of a neuron</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9uhTg.png\" alt></p>\n<p><strong>3 Problems</strong></p>\n<ol>\n<li>Saturated the neural may kill the gradient.</li>\n</ol>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9u5kQ.png\" alt></p>\n<blockquote>\n<p>x is a very negative and very positive val, its gradient will be killed to zero</p>\n</blockquote>\n<ol>\n<li>Sigmoid outputs are not zero-centered</li>\n</ol>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9u7pn.png\" alt></p>\n<blockquote>\n<p>For the sign of x and gradient is always the same, it gonna behaves like is above pic.</p>\n<p>thats why we need zero-mean data, to optimize the w just through the zig zag path.</p>\n</blockquote>\n<ol>\n<li>exp() is a bit compute expensive</li>\n</ol>\n<hr>\n<h4 id=\"Tanh\"><a href=\"#Tanh\" class=\"headerlink\" title=\"Tanh\"></a>Tanh</h4><ul>\n<li>Squashes numbers to range [-1, 1]</li>\n<li>zero centered (nice)</li>\n<li>still kills gradients when saturated</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9uHlq.png\" alt></p>\n<hr>\n<h4 id=\"ReLU\"><a href=\"#ReLU\" class=\"headerlink\" title=\"ReLU\"></a>ReLU</h4><script type=\"math/tex; mode=display\">f(x) = max(0, x)</script><p><img src=\"https://s3.ax1x.com/2020/11/13/D9ub60.png\" alt></p>\n<ul>\n<li>Does not saturate (in + region)</li>\n<li>Very computationally efficient</li>\n<li>Converges much faster than sigmoid/tanh in practice</li>\n<li>Actually more biologically plausible than sigmoid</li>\n</ul>\n<p><strong>Problems</strong></p>\n<ol>\n<li>Not zero-centered output</li>\n<li>An annoyance:</li>\n<li>when x &lt;= 0 the gradient is slashed to zero (kill half the gradient)</li>\n</ol>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9uX0U.png\" alt></p>\n<ul>\n<li>Bad Init</li>\n<li>Learning rate too high</li>\n</ul>\n<blockquote>\n<p>people like to initialize ReLU neurons with slightly positive biases (eg 0.01), to increase the possibility that being activated.</p>\n</blockquote>\n<hr>\n<h4 id=\"Leaky-ReLu\"><a href=\"#Leaky-ReLu\" class=\"headerlink\" title=\"Leaky ReLu\"></a>Leaky ReLu</h4><script type=\"math/tex; mode=display\">f(x) = max(0.01x,x)</script><p><img src=\"https://s3.ax1x.com/2020/11/13/D9uqXV.png\" alt></p>\n<ul>\n<li>Does not saturated</li>\n<li>Computationally efficient</li>\n<li>Converges much faster …</li>\n<li><strong>will not die</strong></li>\n</ul>\n<p>or <strong>Para Rectifier ReLu</strong></p>\n<script type=\"math/tex; mode=display\">f(x) = max(\\alpha{x},x)</script><hr>\n<h4 id=\"Exponential-Linear-Units-ELU\"><a href=\"#Exponential-Linear-Units-ELU\" class=\"headerlink\" title=\"Exponential Linear Units (ELU)\"></a>Exponential Linear Units (ELU)</h4><p><img src=\"https://s3.ax1x.com/2020/11/13/D9uOmT.png\" alt></p>\n<ul>\n<li>All benefits of ReLU</li>\n<li>Closer to zero mean outputs</li>\n<li>Negative saturation regime adds some robustness to noise</li>\n</ul>\n<p><em>While it requires exp()</em></p>\n<hr>\n<h4 id=\"Maxout-“Neuron”\"><a href=\"#Maxout-“Neuron”\" class=\"headerlink\" title=\"Maxout “Neuron”\"></a>Maxout “Neuron”</h4><p><img src=\"https://s3.ax1x.com/2020/11/13/D9uj7F.png\" alt></p>\n<hr>\n<h4 id=\"In-practice\"><a href=\"#In-practice\" class=\"headerlink\" title=\"In practice\"></a>In practice</h4><ul>\n<li>Use ReLU. (zbe careful with learning rates)</li>\n<li>Try Leaky <em>ReLU / Maxout / ELU</em></li>\n<li>Don’t use sigmoid</li>\n</ul>\n<hr>\n<h3 id=\"Data-Preprocessing\"><a href=\"#Data-Preprocessing\" class=\"headerlink\" title=\"Data Preprocessing\"></a>Data Preprocessing</h3><h4 id=\"Step1-Preprocess-the-data\"><a href=\"#Step1-Preprocess-the-data\" class=\"headerlink\" title=\"Step1: Preprocess the data\"></a>Step1: Preprocess the data</h4><p><img src=\"https://s3.ax1x.com/2020/11/13/D9uxk4.png\" alt></p>\n<ul>\n<li>In CV we usually don’t normalize the data.</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KSh9.png\" alt></p>\n<p>Practice above make the data zero-mean, but only the first layer, and that’s why we need the activation func tobe zero-mean.</p>\n<hr>\n<h3 id=\"Weight-Initialization\"><a href=\"#Weight-Initialization\" class=\"headerlink\" title=\"Weight Initialization\"></a>Weight Initialization</h3><h4 id=\"First-idea-Small-random-numbers\"><a href=\"#First-idea-Small-random-numbers\" class=\"headerlink\" title=\"First idea: Small random numbers\"></a>First idea: Small random numbers</h4><pre><code class=\"hljs python\">W = <span class=\"hljs-number\">0.01</span>* np.random.randn(D,H)</code></pre>\n<blockquote>\n<p>Works Okay for small, but have problems in big one.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KC11.png\" alt></p>\n<h4 id=\"How-about-making-Weight-big\"><a href=\"#How-about-making-Weight-big\" class=\"headerlink\" title=\"How about making Weight big?\"></a>How about making Weight big?</h4><p><img src=\"https://s3.ax1x.com/2020/11/13/D9KP6x.png\" alt></p>\n<blockquote>\n<p>it gonna saturated the regime to be either very possitive or very negative input of tanh, and comes out near zero gradients. The weight will not be updated.</p>\n</blockquote>\n<h4 id=\"Xavier-initialization\"><a href=\"#Xavier-initialization\" class=\"headerlink\" title=\"Xavier initialization\"></a>Xavier initialization</h4><p><em>Woo my initialzation? haha</em></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KiX6.png\" alt></p>\n<blockquote>\n<p>ensure we are at the active region of tanh</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KA0O.png\" alt></p>\n<blockquote>\n<p>Can be addressed by add an extra /2， to ensure the neural won’t die in ReLU</p>\n</blockquote>\n<hr>\n<h3 id=\"Batch-Normalization\"><a href=\"#Batch-Normalization\" class=\"headerlink\" title=\"Batch Normalization\"></a>Batch Normalization</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9KknK.png\" alt></p>\n<blockquote>\n<p>To regulize the input tobe unit gaussian.</p>\n</blockquote>\n<p><em>I have no idea about it. What is unit gaussian?</em></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KetH.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KE7D.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KZAe.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Kmhd.png\" alt></p>\n<hr>\n<h3 id=\"Babysitting-the-Learning-Process\"><a href=\"#Babysitting-the-Learning-Process\" class=\"headerlink\" title=\"Babysitting the Learning Process\"></a>Babysitting the Learning Process</h3><ul>\n<li><ol>\n<li>Preprocess data</li>\n</ol>\n</li>\n<li><ol>\n<li>Choose the architecture:</li>\n</ol>\n</li>\n<li><ol>\n<li>Double check that the loss is reasonable</li>\n</ol>\n</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KK1I.png\" alt></p>\n<h4 id=\"The-Learning-Rate\"><a href=\"#The-Learning-Rate\" class=\"headerlink\" title=\"The Learning Rate\"></a>The Learning Rate</h4><ul>\n<li>Very small learning rate 1e-6<blockquote>\n<p>litter help</p>\n</blockquote>\n</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9K3B8.png\" alt></p>\n<ul>\n<li>Very great learning rate 1e6<blockquote>\n<p>go extreme</p>\n</blockquote>\n</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KQjP.png\" alt></p>\n<ul>\n<li>A Rough Range</li>\n</ul>\n<script type=\"math/tex; mode=display\">1\\times{10}^{-3} \\to 1\\times{10}^{-5}</script><hr>\n<h3 id=\"Hyperparameter-Optimization\"><a href=\"#Hyperparameter-Optimization\" class=\"headerlink\" title=\"Hyperparameter Optimization\"></a>Hyperparameter Optimization</h3><ul>\n<li><p>Cross-validation strategy<br><em>coarse -&gt; fine</em></p>\n</li>\n<li><p>Random Sample</p>\n</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Ku9A.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KMct.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9K1nf.png\" alt></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"OverView\"><a href=\"#OverView\" class=\"headerlink\" title=\"OverView\"></a>OverView</h3><ol>\n<li>One time setup</li>\n<li>Training dynamics</li>\n<li>Evaluation</li>\n</ol>\n<h3 id=\"Part-1\"><a href=\"#Part-1\" class=\"headerlink\" title=\"Part 1\"></a>Part 1</h3><ul>\n<li>Activation Functions</li>\n<li>Data Preprocessing</li>\n<li>Weight initialization</li>\n<li>Batch Normalization</li>\n<li>Babysitting the Learning Process</li>\n<li>Hyperparameter Optimization</li>\n</ul>\n<hr>\n<h3 id=\"Activation-Functions\"><a href=\"#Activation-Functions\" class=\"headerlink\" title=\"Activation Functions\"></a>Activation Functions</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9uofs.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9uIYj.png\" alt></p>\n<h4 id=\"Sigmoid\"><a href=\"#Sigmoid\" class=\"headerlink\" title=\"Sigmoid\"></a>Sigmoid</h4><script type=\"math/tex; mode=display\">\\sigma(x) = 1/(1+e^{-x})</script><ul>\n<li>Squashes numbers to range [0,1]</li>\n<li>Historically popular “firing rate” of a neuron</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9uhTg.png\" alt></p>\n<p><strong>3 Problems</strong></p>\n<ol>\n<li>Saturated the neural may kill the gradient.</li>\n</ol>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9u5kQ.png\" alt></p>\n<blockquote>\n<p>x is a very negative and very positive val, its gradient will be killed to zero</p>\n</blockquote>\n<ol>\n<li>Sigmoid outputs are not zero-centered</li>\n</ol>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9u7pn.png\" alt></p>\n<blockquote>\n<p>For the sign of x and gradient is always the same, it gonna behaves like is above pic.</p>\n<p>thats why we need zero-mean data, to optimize the w just through the zig zag path.</p>\n</blockquote>\n<ol>\n<li>exp() is a bit compute expensive</li>\n</ol>\n<hr>\n<h4 id=\"Tanh\"><a href=\"#Tanh\" class=\"headerlink\" title=\"Tanh\"></a>Tanh</h4><ul>\n<li>Squashes numbers to range [-1, 1]</li>\n<li>zero centered (nice)</li>\n<li>still kills gradients when saturated</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9uHlq.png\" alt></p>\n<hr>\n<h4 id=\"ReLU\"><a href=\"#ReLU\" class=\"headerlink\" title=\"ReLU\"></a>ReLU</h4><script type=\"math/tex; mode=display\">f(x) = max(0, x)</script><p><img src=\"https://s3.ax1x.com/2020/11/13/D9ub60.png\" alt></p>\n<ul>\n<li>Does not saturate (in + region)</li>\n<li>Very computationally efficient</li>\n<li>Converges much faster than sigmoid/tanh in practice</li>\n<li>Actually more biologically plausible than sigmoid</li>\n</ul>\n<p><strong>Problems</strong></p>\n<ol>\n<li>Not zero-centered output</li>\n<li>An annoyance:</li>\n<li>when x &lt;= 0 the gradient is slashed to zero (kill half the gradient)</li>\n</ol>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9uX0U.png\" alt></p>\n<ul>\n<li>Bad Init</li>\n<li>Learning rate too high</li>\n</ul>\n<blockquote>\n<p>people like to initialize ReLU neurons with slightly positive biases (eg 0.01), to increase the possibility that being activated.</p>\n</blockquote>\n<hr>\n<h4 id=\"Leaky-ReLu\"><a href=\"#Leaky-ReLu\" class=\"headerlink\" title=\"Leaky ReLu\"></a>Leaky ReLu</h4><script type=\"math/tex; mode=display\">f(x) = max(0.01x,x)</script><p><img src=\"https://s3.ax1x.com/2020/11/13/D9uqXV.png\" alt></p>\n<ul>\n<li>Does not saturated</li>\n<li>Computationally efficient</li>\n<li>Converges much faster …</li>\n<li><strong>will not die</strong></li>\n</ul>\n<p>or <strong>Para Rectifier ReLu</strong></p>\n<script type=\"math/tex; mode=display\">f(x) = max(\\alpha{x},x)</script><hr>\n<h4 id=\"Exponential-Linear-Units-ELU\"><a href=\"#Exponential-Linear-Units-ELU\" class=\"headerlink\" title=\"Exponential Linear Units (ELU)\"></a>Exponential Linear Units (ELU)</h4><p><img src=\"https://s3.ax1x.com/2020/11/13/D9uOmT.png\" alt></p>\n<ul>\n<li>All benefits of ReLU</li>\n<li>Closer to zero mean outputs</li>\n<li>Negative saturation regime adds some robustness to noise</li>\n</ul>\n<p><em>While it requires exp()</em></p>\n<hr>\n<h4 id=\"Maxout-“Neuron”\"><a href=\"#Maxout-“Neuron”\" class=\"headerlink\" title=\"Maxout “Neuron”\"></a>Maxout “Neuron”</h4><p><img src=\"https://s3.ax1x.com/2020/11/13/D9uj7F.png\" alt></p>\n<hr>\n<h4 id=\"In-practice\"><a href=\"#In-practice\" class=\"headerlink\" title=\"In practice\"></a>In practice</h4><ul>\n<li>Use ReLU. (zbe careful with learning rates)</li>\n<li>Try Leaky <em>ReLU / Maxout / ELU</em></li>\n<li>Don’t use sigmoid</li>\n</ul>\n<hr>\n<h3 id=\"Data-Preprocessing\"><a href=\"#Data-Preprocessing\" class=\"headerlink\" title=\"Data Preprocessing\"></a>Data Preprocessing</h3><h4 id=\"Step1-Preprocess-the-data\"><a href=\"#Step1-Preprocess-the-data\" class=\"headerlink\" title=\"Step1: Preprocess the data\"></a>Step1: Preprocess the data</h4><p><img src=\"https://s3.ax1x.com/2020/11/13/D9uxk4.png\" alt></p>\n<ul>\n<li>In CV we usually don’t normalize the data.</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KSh9.png\" alt></p>\n<p>Practice above make the data zero-mean, but only the first layer, and that’s why we need the activation func tobe zero-mean.</p>\n<hr>\n<h3 id=\"Weight-Initialization\"><a href=\"#Weight-Initialization\" class=\"headerlink\" title=\"Weight Initialization\"></a>Weight Initialization</h3><h4 id=\"First-idea-Small-random-numbers\"><a href=\"#First-idea-Small-random-numbers\" class=\"headerlink\" title=\"First idea: Small random numbers\"></a>First idea: Small random numbers</h4><pre><code class=\"hljs python\">W = <span class=\"hljs-number\">0.01</span>* np.random.randn(D,H)</code></pre>\n<blockquote>\n<p>Works Okay for small, but have problems in big one.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KC11.png\" alt></p>\n<h4 id=\"How-about-making-Weight-big\"><a href=\"#How-about-making-Weight-big\" class=\"headerlink\" title=\"How about making Weight big?\"></a>How about making Weight big?</h4><p><img src=\"https://s3.ax1x.com/2020/11/13/D9KP6x.png\" alt></p>\n<blockquote>\n<p>it gonna saturated the regime to be either very possitive or very negative input of tanh, and comes out near zero gradients. The weight will not be updated.</p>\n</blockquote>\n<h4 id=\"Xavier-initialization\"><a href=\"#Xavier-initialization\" class=\"headerlink\" title=\"Xavier initialization\"></a>Xavier initialization</h4><p><em>Woo my initialzation? haha</em></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KiX6.png\" alt></p>\n<blockquote>\n<p>ensure we are at the active region of tanh</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KA0O.png\" alt></p>\n<blockquote>\n<p>Can be addressed by add an extra /2， to ensure the neural won’t die in ReLU</p>\n</blockquote>\n<hr>\n<h3 id=\"Batch-Normalization\"><a href=\"#Batch-Normalization\" class=\"headerlink\" title=\"Batch Normalization\"></a>Batch Normalization</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9KknK.png\" alt></p>\n<blockquote>\n<p>To regulize the input tobe unit gaussian.</p>\n</blockquote>\n<p><em>I have no idea about it. What is unit gaussian?</em></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KetH.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KE7D.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KZAe.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Kmhd.png\" alt></p>\n<hr>\n<h3 id=\"Babysitting-the-Learning-Process\"><a href=\"#Babysitting-the-Learning-Process\" class=\"headerlink\" title=\"Babysitting the Learning Process\"></a>Babysitting the Learning Process</h3><ul>\n<li><ol>\n<li>Preprocess data</li>\n</ol>\n</li>\n<li><ol>\n<li>Choose the architecture:</li>\n</ol>\n</li>\n<li><ol>\n<li>Double check that the loss is reasonable</li>\n</ol>\n</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KK1I.png\" alt></p>\n<h4 id=\"The-Learning-Rate\"><a href=\"#The-Learning-Rate\" class=\"headerlink\" title=\"The Learning Rate\"></a>The Learning Rate</h4><ul>\n<li>Very small learning rate 1e-6<blockquote>\n<p>litter help</p>\n</blockquote>\n</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9K3B8.png\" alt></p>\n<ul>\n<li>Very great learning rate 1e6<blockquote>\n<p>go extreme</p>\n</blockquote>\n</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KQjP.png\" alt></p>\n<ul>\n<li>A Rough Range</li>\n</ul>\n<script type=\"math/tex; mode=display\">1\\times{10}^{-3} \\to 1\\times{10}^{-5}</script><hr>\n<h3 id=\"Hyperparameter-Optimization\"><a href=\"#Hyperparameter-Optimization\" class=\"headerlink\" title=\"Hyperparameter Optimization\"></a>Hyperparameter Optimization</h3><ul>\n<li><p>Cross-validation strategy<br><em>coarse -&gt; fine</em></p>\n</li>\n<li><p>Random Sample</p>\n</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Ku9A.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KMct.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9K1nf.png\" alt></p>\n"},{"title":"CS231n Training Neural Networks II 06","date":"2020-11-14T05:11:23.000Z","index_img":"/img/Cs231n/top.jpg","math":true,"_content":"\n### PreView\n- Fancier optimization\n- Regularization\n- Transfer Learning\n\n---\n\n### Problem with SGD\n\n![](https://s3.ax1x.com/2020/11/13/D9JOns.png)\n\n> The zig-zag path reveal the drawbacks of SGD\n\n![](https://s3.ax1x.com/2020/11/13/D9JbcQ.png)\n\n> Stuck in the local minima.\n\n- Saddle points much more common in high dimension.\n\n**Add an Momentum term may solve these problems**\n\n![](https://s3.ax1x.com/2020/11/13/D9JqXj.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9JXBn.png)\n\n> Owing to the exsistance of momentum we can training more faster and overcome the problems mentioned before.\n\n\n![](https://s3.ax1x.com/2020/11/13/D9JH1g.png)\n\n- **Nesterov Momentum**\n\n$$v_{t+1} = \\rho{v_t}-\\alpha{\\nabla{f(x_t+\\rho{v_t})}}\n\\\\\nx_{t+1} = x_t + v_{t+1}\n$$\n\n![](https://s3.ax1x.com/2020/11/13/D9Jj7q.png)\n\n> some kind error correcting term of present v and the previous v\n\n![](https://s3.ax1x.com/2020/11/13/D9JzNV.png)\n\n---\n\n### AdaGrad\n\n```python\ngrad_squared = 0\nwhile True:\n    dx = compute_gradient(x)\n    grad_squared += dx * dx\n    x -= learning_rate * dx / (np.sqrt(grad_squared) + 1e-7)\n```\n\n> The basic idea about AdaGrad algorithm is that the step of dimention with smaller gradients will be divided by small vals and make it move faster, while greater one slower to avoid zig-zag behavior.\n\n> while the step will become smaller and smaller while you get closer to the minima, but in turn with higher risks to stuck in the local minima.\n\n---\n\n### RMSProp\n\n![](https://s3.ax1x.com/2020/11/13/D9JxA0.png)\n\n> With a decay rate to make a smooth stop the reducing of steps.\n\n![](https://s3.ax1x.com/2020/11/13/D9Y99U.png)\n\n---\n\n### Adam (almost)\n\n```python\nfirst_moment = 0\nsecond_moment = 0\nwhile True:\n    dx = compute_gradient(x)\n    first_moment = beta1 + first_moment + (1 - beta1) * dx\n    # Momentum\n    second_moment = beta2 * second_moment + (1 - beta2) * dx * dx\n    # AdaGrad / RMSProp\n    x -= learning_rate * first_moment / (np.sqrt(second_moment) + 1e-7)\n```\n\n> It combine the two methods, but with a little bug of the first step, which gonna be super large.\n\n### Adam (full form)\n\n```python\nfirst_moment = 0\nsecond_moment = 0\nfor t in range(num_iterations):\n    dx = compute_gradient(x)\n    first_moment = beta1 + first_moment + (1 - beta1) * dx\n    # Momentum\n    second_moment = beta2 * second_moment + (1 - beta2) * dx * dx\n    # AdaGrad / RMSProp\n    first_unbias = first_moment / (1 - beta1 ** t)\n    second_unbias = second_moment / (1 - beta2 ** t)\n    x -= learning_rate * first_unbias / (np.sqrt(second_unbias) + 1e-7)\n```\n\n> Bias correction for the fact that first and second moment estimates start at zero\n\n- Great starting point\n1. beta1 = 0.9\n2. beta2 = 0.999\n3. learning_rate = 1e-3 or 5e-4\n\n---\n\n### Decay the learning rate to make it finer\n\n![](https://s3.ax1x.com/2020/11/13/D9YShT.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9YPc4.png)\n\n---\n\n### little bit Fancier Optimization \n\n![](https://s3.ax1x.com/2020/11/13/D9YC3F.png)\n\n> First derivative optimization\n\n![](https://s3.ax1x.com/2020/11/13/D9YijJ.png)\n\n> Second derivative optimization, direct to the mini\n\n![](https://s3.ax1x.com/2020/11/13/D9Yku9.png)\n\n> Don't need learning rate, but impractical for Hessian has O(N^2) elements and Inverting takes O(N^3)\n\n#### Quasi - Newton methods (BGFS)\n\n![](https://s3.ax1x.com/2020/11/13/D9YABR.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9YEH1.png)\n\n---\n\n### In Practice:\n\n- Using Adam\n- If full batch updates can be afforded, try out **L-BFGS**\n\n---\n\n### Reduce the gap between train and unseen data\n\n#### Model Ensembles\n\n1. Train multiple independent models\n2. At test time average their results\n\n2% improvement maybe\n\n![](https://s3.ax1x.com/2020/11/13/D9YeN6.png)\n\n> Instead of using actual parameter vector, keep a moving average of the para vector and use that at test time\n\n```python\nwhile True:\n    data_batch = dataset.sample_data_batch()\n    loss = network.forward(data_batch)\n    dx = network.backward()\n    x += - learning_rate * dx\n    x_test = 0.995*x_test + 0.005*x\n```\n\n#### Regularization to make single model performs better\n\n- Dropout\n\n![](https://s3.ax1x.com/2020/11/13/D9Ym4K.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9YK3D.png)\n\n> Another interpretation is that you can percive each binary mask as a single model, so it just like dropout is training a large ensemble of models with shared paras.\n\n![](https://s3.ax1x.com/2020/11/13/D9Yu9O.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9YMge.png)\n\n#### Batch Normalization\n\n> Which can achieve the same effect as the Dropout, for it includes some noises.\n#### Data Augmentation\n\n> To introduce noise to make it performs better on unseen data.\n\n![](https://s3.ax1x.com/2020/11/13/D9YQjH.png)\n\n#### Stochastic Depth\n\n> Randomly drop layers during training.\n> Use the full networks during testing.\n\n---\n\n### Transfer Learning\n\n> There is no need for huge amount of data.\n\n![](https://s3.ax1x.com/2020/11/13/D9Y1ud.png)\n","source":"_posts/CS231n/CS231n-06-Training-Neural-Networks-II.md","raw":"---\ntitle: CS231n Training Neural Networks II 06\ndate: 2020-11-13 21:11:23\ntags: [CV,Neural Network]\ncategory: [CS231n]\nindex_img: /img/Cs231n/top.jpg\nmath: true\n---\n\n### PreView\n- Fancier optimization\n- Regularization\n- Transfer Learning\n\n---\n\n### Problem with SGD\n\n![](https://s3.ax1x.com/2020/11/13/D9JOns.png)\n\n> The zig-zag path reveal the drawbacks of SGD\n\n![](https://s3.ax1x.com/2020/11/13/D9JbcQ.png)\n\n> Stuck in the local minima.\n\n- Saddle points much more common in high dimension.\n\n**Add an Momentum term may solve these problems**\n\n![](https://s3.ax1x.com/2020/11/13/D9JqXj.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9JXBn.png)\n\n> Owing to the exsistance of momentum we can training more faster and overcome the problems mentioned before.\n\n\n![](https://s3.ax1x.com/2020/11/13/D9JH1g.png)\n\n- **Nesterov Momentum**\n\n$$v_{t+1} = \\rho{v_t}-\\alpha{\\nabla{f(x_t+\\rho{v_t})}}\n\\\\\nx_{t+1} = x_t + v_{t+1}\n$$\n\n![](https://s3.ax1x.com/2020/11/13/D9Jj7q.png)\n\n> some kind error correcting term of present v and the previous v\n\n![](https://s3.ax1x.com/2020/11/13/D9JzNV.png)\n\n---\n\n### AdaGrad\n\n```python\ngrad_squared = 0\nwhile True:\n    dx = compute_gradient(x)\n    grad_squared += dx * dx\n    x -= learning_rate * dx / (np.sqrt(grad_squared) + 1e-7)\n```\n\n> The basic idea about AdaGrad algorithm is that the step of dimention with smaller gradients will be divided by small vals and make it move faster, while greater one slower to avoid zig-zag behavior.\n\n> while the step will become smaller and smaller while you get closer to the minima, but in turn with higher risks to stuck in the local minima.\n\n---\n\n### RMSProp\n\n![](https://s3.ax1x.com/2020/11/13/D9JxA0.png)\n\n> With a decay rate to make a smooth stop the reducing of steps.\n\n![](https://s3.ax1x.com/2020/11/13/D9Y99U.png)\n\n---\n\n### Adam (almost)\n\n```python\nfirst_moment = 0\nsecond_moment = 0\nwhile True:\n    dx = compute_gradient(x)\n    first_moment = beta1 + first_moment + (1 - beta1) * dx\n    # Momentum\n    second_moment = beta2 * second_moment + (1 - beta2) * dx * dx\n    # AdaGrad / RMSProp\n    x -= learning_rate * first_moment / (np.sqrt(second_moment) + 1e-7)\n```\n\n> It combine the two methods, but with a little bug of the first step, which gonna be super large.\n\n### Adam (full form)\n\n```python\nfirst_moment = 0\nsecond_moment = 0\nfor t in range(num_iterations):\n    dx = compute_gradient(x)\n    first_moment = beta1 + first_moment + (1 - beta1) * dx\n    # Momentum\n    second_moment = beta2 * second_moment + (1 - beta2) * dx * dx\n    # AdaGrad / RMSProp\n    first_unbias = first_moment / (1 - beta1 ** t)\n    second_unbias = second_moment / (1 - beta2 ** t)\n    x -= learning_rate * first_unbias / (np.sqrt(second_unbias) + 1e-7)\n```\n\n> Bias correction for the fact that first and second moment estimates start at zero\n\n- Great starting point\n1. beta1 = 0.9\n2. beta2 = 0.999\n3. learning_rate = 1e-3 or 5e-4\n\n---\n\n### Decay the learning rate to make it finer\n\n![](https://s3.ax1x.com/2020/11/13/D9YShT.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9YPc4.png)\n\n---\n\n### little bit Fancier Optimization \n\n![](https://s3.ax1x.com/2020/11/13/D9YC3F.png)\n\n> First derivative optimization\n\n![](https://s3.ax1x.com/2020/11/13/D9YijJ.png)\n\n> Second derivative optimization, direct to the mini\n\n![](https://s3.ax1x.com/2020/11/13/D9Yku9.png)\n\n> Don't need learning rate, but impractical for Hessian has O(N^2) elements and Inverting takes O(N^3)\n\n#### Quasi - Newton methods (BGFS)\n\n![](https://s3.ax1x.com/2020/11/13/D9YABR.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9YEH1.png)\n\n---\n\n### In Practice:\n\n- Using Adam\n- If full batch updates can be afforded, try out **L-BFGS**\n\n---\n\n### Reduce the gap between train and unseen data\n\n#### Model Ensembles\n\n1. Train multiple independent models\n2. At test time average their results\n\n2% improvement maybe\n\n![](https://s3.ax1x.com/2020/11/13/D9YeN6.png)\n\n> Instead of using actual parameter vector, keep a moving average of the para vector and use that at test time\n\n```python\nwhile True:\n    data_batch = dataset.sample_data_batch()\n    loss = network.forward(data_batch)\n    dx = network.backward()\n    x += - learning_rate * dx\n    x_test = 0.995*x_test + 0.005*x\n```\n\n#### Regularization to make single model performs better\n\n- Dropout\n\n![](https://s3.ax1x.com/2020/11/13/D9Ym4K.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9YK3D.png)\n\n> Another interpretation is that you can percive each binary mask as a single model, so it just like dropout is training a large ensemble of models with shared paras.\n\n![](https://s3.ax1x.com/2020/11/13/D9Yu9O.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9YMge.png)\n\n#### Batch Normalization\n\n> Which can achieve the same effect as the Dropout, for it includes some noises.\n#### Data Augmentation\n\n> To introduce noise to make it performs better on unseen data.\n\n![](https://s3.ax1x.com/2020/11/13/D9YQjH.png)\n\n#### Stochastic Depth\n\n> Randomly drop layers during training.\n> Use the full networks during testing.\n\n---\n\n### Transfer Learning\n\n> There is no need for huge amount of data.\n\n![](https://s3.ax1x.com/2020/11/13/D9Y1ud.png)\n","slug":"CS231n/CS231n-06-Training-Neural-Networks-II","published":1,"updated":"2026-02-03T05:42:14.423Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzva000h7uit04x2gt25","content":"<h3 id=\"PreView\"><a href=\"#PreView\" class=\"headerlink\" title=\"PreView\"></a>PreView</h3><ul>\n<li>Fancier optimization</li>\n<li>Regularization</li>\n<li>Transfer Learning</li>\n</ul>\n<hr>\n<h3 id=\"Problem-with-SGD\"><a href=\"#Problem-with-SGD\" class=\"headerlink\" title=\"Problem with SGD\"></a>Problem with SGD</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9JOns.png\" alt></p>\n<blockquote>\n<p>The zig-zag path reveal the drawbacks of SGD</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9JbcQ.png\" alt></p>\n<blockquote>\n<p>Stuck in the local minima.</p>\n</blockquote>\n<ul>\n<li>Saddle points much more common in high dimension.</li>\n</ul>\n<p><strong>Add an Momentum term may solve these problems</strong></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9JqXj.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9JXBn.png\" alt></p>\n<blockquote>\n<p>Owing to the exsistance of momentum we can training more faster and overcome the problems mentioned before.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9JH1g.png\" alt></p>\n<ul>\n<li><strong>Nesterov Momentum</strong></li>\n</ul>\n<script type=\"math/tex; mode=display\">v_{t+1} = \\rho{v_t}-\\alpha{\\nabla{f(x_t+\\rho{v_t})}}\n\\\\\nx_{t+1} = x_t + v_{t+1}</script><p><img src=\"https://s3.ax1x.com/2020/11/13/D9Jj7q.png\" alt></p>\n<blockquote>\n<p>some kind error correcting term of present v and the previous v</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9JzNV.png\" alt></p>\n<hr>\n<h3 id=\"AdaGrad\"><a href=\"#AdaGrad\" class=\"headerlink\" title=\"AdaGrad\"></a>AdaGrad</h3><pre><code class=\"hljs python\">grad_squared = <span class=\"hljs-number\">0</span>\n<span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n    dx = compute_gradient(x)\n    grad_squared += dx * dx\n    x -= learning_rate * dx / (np.sqrt(grad_squared) + <span class=\"hljs-number\">1e-7</span>)</code></pre>\n<blockquote>\n<p>The basic idea about AdaGrad algorithm is that the step of dimention with smaller gradients will be divided by small vals and make it move faster, while greater one slower to avoid zig-zag behavior.</p>\n<p>while the step will become smaller and smaller while you get closer to the minima, but in turn with higher risks to stuck in the local minima.</p>\n</blockquote>\n<hr>\n<h3 id=\"RMSProp\"><a href=\"#RMSProp\" class=\"headerlink\" title=\"RMSProp\"></a>RMSProp</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9JxA0.png\" alt></p>\n<blockquote>\n<p>With a decay rate to make a smooth stop the reducing of steps.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Y99U.png\" alt></p>\n<hr>\n<h3 id=\"Adam-almost\"><a href=\"#Adam-almost\" class=\"headerlink\" title=\"Adam (almost)\"></a>Adam (almost)</h3><pre><code class=\"hljs python\">first_moment = <span class=\"hljs-number\">0</span>\nsecond_moment = <span class=\"hljs-number\">0</span>\n<span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n    dx = compute_gradient(x)\n    first_moment = beta1 + first_moment + (<span class=\"hljs-number\">1</span> - beta1) * dx\n    <span class=\"hljs-comment\"># Momentum</span>\n    second_moment = beta2 * second_moment + (<span class=\"hljs-number\">1</span> - beta2) * dx * dx\n    <span class=\"hljs-comment\"># AdaGrad / RMSProp</span>\n    x -= learning_rate * first_moment / (np.sqrt(second_moment) + <span class=\"hljs-number\">1e-7</span>)</code></pre>\n<blockquote>\n<p>It combine the two methods, but with a little bug of the first step, which gonna be super large.</p>\n</blockquote>\n<h3 id=\"Adam-full-form\"><a href=\"#Adam-full-form\" class=\"headerlink\" title=\"Adam (full form)\"></a>Adam (full form)</h3><pre><code class=\"hljs python\">first_moment = <span class=\"hljs-number\">0</span>\nsecond_moment = <span class=\"hljs-number\">0</span>\n<span class=\"hljs-keyword\">for</span> t <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(num_iterations):\n    dx = compute_gradient(x)\n    first_moment = beta1 + first_moment + (<span class=\"hljs-number\">1</span> - beta1) * dx\n    <span class=\"hljs-comment\"># Momentum</span>\n    second_moment = beta2 * second_moment + (<span class=\"hljs-number\">1</span> - beta2) * dx * dx\n    <span class=\"hljs-comment\"># AdaGrad / RMSProp</span>\n    first_unbias = first_moment / (<span class=\"hljs-number\">1</span> - beta1 ** t)\n    second_unbias = second_moment / (<span class=\"hljs-number\">1</span> - beta2 ** t)\n    x -= learning_rate * first_unbias / (np.sqrt(second_unbias) + <span class=\"hljs-number\">1e-7</span>)</code></pre>\n<blockquote>\n<p>Bias correction for the fact that first and second moment estimates start at zero</p>\n</blockquote>\n<ul>\n<li>Great starting point</li>\n</ul>\n<ol>\n<li>beta1 = 0.9</li>\n<li>beta2 = 0.999</li>\n<li>learning_rate = 1e-3 or 5e-4</li>\n</ol>\n<hr>\n<h3 id=\"Decay-the-learning-rate-to-make-it-finer\"><a href=\"#Decay-the-learning-rate-to-make-it-finer\" class=\"headerlink\" title=\"Decay the learning rate to make it finer\"></a>Decay the learning rate to make it finer</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9YShT.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YPc4.png\" alt></p>\n<hr>\n<h3 id=\"little-bit-Fancier-Optimization\"><a href=\"#little-bit-Fancier-Optimization\" class=\"headerlink\" title=\"little bit Fancier Optimization\"></a>little bit Fancier Optimization</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9YC3F.png\" alt></p>\n<blockquote>\n<p>First derivative optimization</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YijJ.png\" alt></p>\n<blockquote>\n<p>Second derivative optimization, direct to the mini</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Yku9.png\" alt></p>\n<blockquote>\n<p>Don’t need learning rate, but impractical for Hessian has O(N^2) elements and Inverting takes O(N^3)</p>\n</blockquote>\n<h4 id=\"Quasi-Newton-methods-BGFS\"><a href=\"#Quasi-Newton-methods-BGFS\" class=\"headerlink\" title=\"Quasi - Newton methods (BGFS)\"></a>Quasi - Newton methods (BGFS)</h4><p><img src=\"https://s3.ax1x.com/2020/11/13/D9YABR.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YEH1.png\" alt></p>\n<hr>\n<h3 id=\"In-Practice\"><a href=\"#In-Practice\" class=\"headerlink\" title=\"In Practice:\"></a>In Practice:</h3><ul>\n<li>Using Adam</li>\n<li>If full batch updates can be afforded, try out <strong>L-BFGS</strong></li>\n</ul>\n<hr>\n<h3 id=\"Reduce-the-gap-between-train-and-unseen-data\"><a href=\"#Reduce-the-gap-between-train-and-unseen-data\" class=\"headerlink\" title=\"Reduce the gap between train and unseen data\"></a>Reduce the gap between train and unseen data</h3><h4 id=\"Model-Ensembles\"><a href=\"#Model-Ensembles\" class=\"headerlink\" title=\"Model Ensembles\"></a>Model Ensembles</h4><ol>\n<li>Train multiple independent models</li>\n<li>At test time average their results</li>\n</ol>\n<p>2% improvement maybe</p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YeN6.png\" alt></p>\n<blockquote>\n<p>Instead of using actual parameter vector, keep a moving average of the para vector and use that at test time</p>\n</blockquote>\n<pre><code class=\"hljs python\"><span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n    data_batch = dataset.sample_data_batch()\n    loss = network.forward(data_batch)\n    dx = network.backward()\n    x += - learning_rate * dx\n    x_test = <span class=\"hljs-number\">0.995</span>*x_test + <span class=\"hljs-number\">0.005</span>*x</code></pre>\n<h4 id=\"Regularization-to-make-single-model-performs-better\"><a href=\"#Regularization-to-make-single-model-performs-better\" class=\"headerlink\" title=\"Regularization to make single model performs better\"></a>Regularization to make single model performs better</h4><ul>\n<li>Dropout</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Ym4K.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YK3D.png\" alt></p>\n<blockquote>\n<p>Another interpretation is that you can percive each binary mask as a single model, so it just like dropout is training a large ensemble of models with shared paras.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Yu9O.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YMge.png\" alt></p>\n<h4 id=\"Batch-Normalization\"><a href=\"#Batch-Normalization\" class=\"headerlink\" title=\"Batch Normalization\"></a>Batch Normalization</h4><blockquote>\n<p>Which can achieve the same effect as the Dropout, for it includes some noises.</p>\n<h4 id=\"Data-Augmentation\"><a href=\"#Data-Augmentation\" class=\"headerlink\" title=\"Data Augmentation\"></a>Data Augmentation</h4><p>To introduce noise to make it performs better on unseen data.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YQjH.png\" alt></p>\n<h4 id=\"Stochastic-Depth\"><a href=\"#Stochastic-Depth\" class=\"headerlink\" title=\"Stochastic Depth\"></a>Stochastic Depth</h4><blockquote>\n<p>Randomly drop layers during training.<br>Use the full networks during testing.</p>\n</blockquote>\n<hr>\n<h3 id=\"Transfer-Learning\"><a href=\"#Transfer-Learning\" class=\"headerlink\" title=\"Transfer Learning\"></a>Transfer Learning</h3><blockquote>\n<p>There is no need for huge amount of data.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Y1ud.png\" alt></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"PreView\"><a href=\"#PreView\" class=\"headerlink\" title=\"PreView\"></a>PreView</h3><ul>\n<li>Fancier optimization</li>\n<li>Regularization</li>\n<li>Transfer Learning</li>\n</ul>\n<hr>\n<h3 id=\"Problem-with-SGD\"><a href=\"#Problem-with-SGD\" class=\"headerlink\" title=\"Problem with SGD\"></a>Problem with SGD</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9JOns.png\" alt></p>\n<blockquote>\n<p>The zig-zag path reveal the drawbacks of SGD</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9JbcQ.png\" alt></p>\n<blockquote>\n<p>Stuck in the local minima.</p>\n</blockquote>\n<ul>\n<li>Saddle points much more common in high dimension.</li>\n</ul>\n<p><strong>Add an Momentum term may solve these problems</strong></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9JqXj.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9JXBn.png\" alt></p>\n<blockquote>\n<p>Owing to the exsistance of momentum we can training more faster and overcome the problems mentioned before.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9JH1g.png\" alt></p>\n<ul>\n<li><strong>Nesterov Momentum</strong></li>\n</ul>\n<script type=\"math/tex; mode=display\">v_{t+1} = \\rho{v_t}-\\alpha{\\nabla{f(x_t+\\rho{v_t})}}\n\\\\\nx_{t+1} = x_t + v_{t+1}</script><p><img src=\"https://s3.ax1x.com/2020/11/13/D9Jj7q.png\" alt></p>\n<blockquote>\n<p>some kind error correcting term of present v and the previous v</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9JzNV.png\" alt></p>\n<hr>\n<h3 id=\"AdaGrad\"><a href=\"#AdaGrad\" class=\"headerlink\" title=\"AdaGrad\"></a>AdaGrad</h3><pre><code class=\"hljs python\">grad_squared = <span class=\"hljs-number\">0</span>\n<span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n    dx = compute_gradient(x)\n    grad_squared += dx * dx\n    x -= learning_rate * dx / (np.sqrt(grad_squared) + <span class=\"hljs-number\">1e-7</span>)</code></pre>\n<blockquote>\n<p>The basic idea about AdaGrad algorithm is that the step of dimention with smaller gradients will be divided by small vals and make it move faster, while greater one slower to avoid zig-zag behavior.</p>\n<p>while the step will become smaller and smaller while you get closer to the minima, but in turn with higher risks to stuck in the local minima.</p>\n</blockquote>\n<hr>\n<h3 id=\"RMSProp\"><a href=\"#RMSProp\" class=\"headerlink\" title=\"RMSProp\"></a>RMSProp</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9JxA0.png\" alt></p>\n<blockquote>\n<p>With a decay rate to make a smooth stop the reducing of steps.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Y99U.png\" alt></p>\n<hr>\n<h3 id=\"Adam-almost\"><a href=\"#Adam-almost\" class=\"headerlink\" title=\"Adam (almost)\"></a>Adam (almost)</h3><pre><code class=\"hljs python\">first_moment = <span class=\"hljs-number\">0</span>\nsecond_moment = <span class=\"hljs-number\">0</span>\n<span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n    dx = compute_gradient(x)\n    first_moment = beta1 + first_moment + (<span class=\"hljs-number\">1</span> - beta1) * dx\n    <span class=\"hljs-comment\"># Momentum</span>\n    second_moment = beta2 * second_moment + (<span class=\"hljs-number\">1</span> - beta2) * dx * dx\n    <span class=\"hljs-comment\"># AdaGrad / RMSProp</span>\n    x -= learning_rate * first_moment / (np.sqrt(second_moment) + <span class=\"hljs-number\">1e-7</span>)</code></pre>\n<blockquote>\n<p>It combine the two methods, but with a little bug of the first step, which gonna be super large.</p>\n</blockquote>\n<h3 id=\"Adam-full-form\"><a href=\"#Adam-full-form\" class=\"headerlink\" title=\"Adam (full form)\"></a>Adam (full form)</h3><pre><code class=\"hljs python\">first_moment = <span class=\"hljs-number\">0</span>\nsecond_moment = <span class=\"hljs-number\">0</span>\n<span class=\"hljs-keyword\">for</span> t <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(num_iterations):\n    dx = compute_gradient(x)\n    first_moment = beta1 + first_moment + (<span class=\"hljs-number\">1</span> - beta1) * dx\n    <span class=\"hljs-comment\"># Momentum</span>\n    second_moment = beta2 * second_moment + (<span class=\"hljs-number\">1</span> - beta2) * dx * dx\n    <span class=\"hljs-comment\"># AdaGrad / RMSProp</span>\n    first_unbias = first_moment / (<span class=\"hljs-number\">1</span> - beta1 ** t)\n    second_unbias = second_moment / (<span class=\"hljs-number\">1</span> - beta2 ** t)\n    x -= learning_rate * first_unbias / (np.sqrt(second_unbias) + <span class=\"hljs-number\">1e-7</span>)</code></pre>\n<blockquote>\n<p>Bias correction for the fact that first and second moment estimates start at zero</p>\n</blockquote>\n<ul>\n<li>Great starting point</li>\n</ul>\n<ol>\n<li>beta1 = 0.9</li>\n<li>beta2 = 0.999</li>\n<li>learning_rate = 1e-3 or 5e-4</li>\n</ol>\n<hr>\n<h3 id=\"Decay-the-learning-rate-to-make-it-finer\"><a href=\"#Decay-the-learning-rate-to-make-it-finer\" class=\"headerlink\" title=\"Decay the learning rate to make it finer\"></a>Decay the learning rate to make it finer</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9YShT.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YPc4.png\" alt></p>\n<hr>\n<h3 id=\"little-bit-Fancier-Optimization\"><a href=\"#little-bit-Fancier-Optimization\" class=\"headerlink\" title=\"little bit Fancier Optimization\"></a>little bit Fancier Optimization</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9YC3F.png\" alt></p>\n<blockquote>\n<p>First derivative optimization</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YijJ.png\" alt></p>\n<blockquote>\n<p>Second derivative optimization, direct to the mini</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Yku9.png\" alt></p>\n<blockquote>\n<p>Don’t need learning rate, but impractical for Hessian has O(N^2) elements and Inverting takes O(N^3)</p>\n</blockquote>\n<h4 id=\"Quasi-Newton-methods-BGFS\"><a href=\"#Quasi-Newton-methods-BGFS\" class=\"headerlink\" title=\"Quasi - Newton methods (BGFS)\"></a>Quasi - Newton methods (BGFS)</h4><p><img src=\"https://s3.ax1x.com/2020/11/13/D9YABR.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YEH1.png\" alt></p>\n<hr>\n<h3 id=\"In-Practice\"><a href=\"#In-Practice\" class=\"headerlink\" title=\"In Practice:\"></a>In Practice:</h3><ul>\n<li>Using Adam</li>\n<li>If full batch updates can be afforded, try out <strong>L-BFGS</strong></li>\n</ul>\n<hr>\n<h3 id=\"Reduce-the-gap-between-train-and-unseen-data\"><a href=\"#Reduce-the-gap-between-train-and-unseen-data\" class=\"headerlink\" title=\"Reduce the gap between train and unseen data\"></a>Reduce the gap between train and unseen data</h3><h4 id=\"Model-Ensembles\"><a href=\"#Model-Ensembles\" class=\"headerlink\" title=\"Model Ensembles\"></a>Model Ensembles</h4><ol>\n<li>Train multiple independent models</li>\n<li>At test time average their results</li>\n</ol>\n<p>2% improvement maybe</p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YeN6.png\" alt></p>\n<blockquote>\n<p>Instead of using actual parameter vector, keep a moving average of the para vector and use that at test time</p>\n</blockquote>\n<pre><code class=\"hljs python\"><span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n    data_batch = dataset.sample_data_batch()\n    loss = network.forward(data_batch)\n    dx = network.backward()\n    x += - learning_rate * dx\n    x_test = <span class=\"hljs-number\">0.995</span>*x_test + <span class=\"hljs-number\">0.005</span>*x</code></pre>\n<h4 id=\"Regularization-to-make-single-model-performs-better\"><a href=\"#Regularization-to-make-single-model-performs-better\" class=\"headerlink\" title=\"Regularization to make single model performs better\"></a>Regularization to make single model performs better</h4><ul>\n<li>Dropout</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Ym4K.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YK3D.png\" alt></p>\n<blockquote>\n<p>Another interpretation is that you can percive each binary mask as a single model, so it just like dropout is training a large ensemble of models with shared paras.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Yu9O.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YMge.png\" alt></p>\n<h4 id=\"Batch-Normalization\"><a href=\"#Batch-Normalization\" class=\"headerlink\" title=\"Batch Normalization\"></a>Batch Normalization</h4><blockquote>\n<p>Which can achieve the same effect as the Dropout, for it includes some noises.</p>\n<h4 id=\"Data-Augmentation\"><a href=\"#Data-Augmentation\" class=\"headerlink\" title=\"Data Augmentation\"></a>Data Augmentation</h4><p>To introduce noise to make it performs better on unseen data.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YQjH.png\" alt></p>\n<h4 id=\"Stochastic-Depth\"><a href=\"#Stochastic-Depth\" class=\"headerlink\" title=\"Stochastic Depth\"></a>Stochastic Depth</h4><blockquote>\n<p>Randomly drop layers during training.<br>Use the full networks during testing.</p>\n</blockquote>\n<hr>\n<h3 id=\"Transfer-Learning\"><a href=\"#Transfer-Learning\" class=\"headerlink\" title=\"Transfer Learning\"></a>Transfer Learning</h3><blockquote>\n<p>There is no need for huge amount of data.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Y1ud.png\" alt></p>\n"},{"title":"CS231n Image Classification 01","date":"2020-11-08T06:11:53.000Z","index_img":"/img/Cs231n/top.jpg","math":true,"_content":"\n**Preface:** This is the note of Stanford course CS231n, paving the way for my lab research.\n\n# Image Classification\n*A core task in Computer Vision*\n\n---\n\n### Computer' Work \nInput an image, and assign one of the label amoung the given labels.\n\n- **The Problem:** \n1. Semantic Gap\n2. Viewpoint variation\n3. illumination \n4. Deformation\n5. Occlusion\n6. Intraclass variation\n\n---\n\n### An image classifier\n> Coding might be difficult \n\n```python\ndef classify_image(image):\n    # Do Some Magic\n    return class_label\n```\n\n- Attmpts\n  \n![](https://s1.ax1x.com/2020/11/07/BIMSmD.png)\n\n---\n\n### Data-Driven Approach\n1. Collect a dataset of images and labels\n2. Use Machine Learning to train a classifier\n3. Evaluate the classifier on new images\n\n- First classifier: Nearest Neighbor\n\n*Just Memorize all data and labels*\n```python\ndef train(images, labels):\n    # Machine Learning!\n    return model\n```\n\n*Predict the label of the most similar training image*\n```python\ndef predict(model, test_images):\n    # Use model to predict labels\n    return test_labels\n```\n\n**Example Dataset:** CIFAR10\n\n![](https://s1.ax1x.com/2020/11/07/BIM9TH.png)\n\n> **Issues:** Although pics may seem visually similar, but still give lots of errors.\n> \n---\n\n- Compare func used in it\n### **K nearest Neighbors Method**\n\n**L1 distance:** $d_1(I_1,I_2) = \\sum\\limits_{p} \\mid I_1^p - I_2^p \\mid$\n\n![](https://s1.ax1x.com/2020/11/07/BIKXSx.png)\n\n*Minimize the sum given the most similar pics*\n\n#### **BackWards**\n\n![](https://s1.ax1x.com/2020/11/07/BIKjl6.png)\n\n#### **What it looks like**\n\n![](https://s1.ax1x.com/2020/11/07/BIMp0e.png)\n\n**Issues**\n\n1. Isolated Yellow Point\n2. Noisy of one single point (green into blue)\n\n**Use K Nearest Neighbors to Optimize it**\n![](https://s1.ax1x.com/2020/11/07/BIMitA.png)\n\n---\n\n*A Better Cmp Func*\n**L2(Euclidean) distance:** $d_1(I_1,I_2) = \\sqrt{\\sum\\limits_{p}{(I_1^p - I_2^p)}^2}$\n\n![](https://s1.ax1x.com/2020/11/07/BIMFfI.png)\n\n> The L1 Distance depends on the coordinate system, whenever there is a rotate, it would change the L1 Distance, while that won't happen in the L2 Distance case (simply because it's a circle)\n\n---\n\n#### **Hyperparameters**\n- What's the best value of **k**\n- What's the best **distance** to use? (L1,L2 or anything else)\n\n*These things are preset rather than learn automatically from learning process*\n\nThis is **Very problem-dependent**, just try!, but How?\n\n![](https://s1.ax1x.com/2020/11/07/BIME1P.png)\n\n**Training & Validation process should not mixed with the test data**\n\n- Cross Validation\n\n![](https://s1.ax1x.com/2020/11/07/BIMApt.png)\n\n- Validation process\n\n![](https://s1.ax1x.com/2020/11/07/BIMV6f.png)\n\n> using the validation data to choose the best hyperparameters.\n\n![](https://s1.ax1x.com/2020/11/07/BIMu7Q.png)\n\n> Cause we sum the offset, though the differences bettween pics and pics are various, they still got the same L2 distance, which is not so good.\n\n\n---\n\n### **Linear Classification**\n\n- **Parametric Model**\n![](https://s1.ax1x.com/2020/11/07/BIMZX8.png)\n\n$$f(x,W) = Wx + b$$\n> We need f(x,W) to be 10x1 and the x is actually 3072x1, so the W we input may be 10x3072, sometimes we add a bias to balance.\n\n![](https://s1.ax1x.com/2020/11/07/BIMn0g.png)\n\n![](https://s1.ax1x.com/2020/11/07/BIMMkj.png)\n\n> It use a single line to separate the object based on its RGB info\n\nBut how can we tell the quality of W ?\n(View the next lecture)\n\n- **Problems**\n![](https://s1.ax1x.com/2020/11/07/BIMQts.png)\n\n> Since it's linear the Problems is obivious.\n","source":"_posts/CS231n/CS231n_01_Image_Classification.md","raw":"---\ntitle: CS231n Image Classification 01\ndate: 2020-11-07 22:11:53\ntags: [CV,Neural Network]\ncategory: [CS231n]\nindex_img: /img/Cs231n/top.jpg\nmath: true\n---\n\n**Preface:** This is the note of Stanford course CS231n, paving the way for my lab research.\n\n# Image Classification\n*A core task in Computer Vision*\n\n---\n\n### Computer' Work \nInput an image, and assign one of the label amoung the given labels.\n\n- **The Problem:** \n1. Semantic Gap\n2. Viewpoint variation\n3. illumination \n4. Deformation\n5. Occlusion\n6. Intraclass variation\n\n---\n\n### An image classifier\n> Coding might be difficult \n\n```python\ndef classify_image(image):\n    # Do Some Magic\n    return class_label\n```\n\n- Attmpts\n  \n![](https://s1.ax1x.com/2020/11/07/BIMSmD.png)\n\n---\n\n### Data-Driven Approach\n1. Collect a dataset of images and labels\n2. Use Machine Learning to train a classifier\n3. Evaluate the classifier on new images\n\n- First classifier: Nearest Neighbor\n\n*Just Memorize all data and labels*\n```python\ndef train(images, labels):\n    # Machine Learning!\n    return model\n```\n\n*Predict the label of the most similar training image*\n```python\ndef predict(model, test_images):\n    # Use model to predict labels\n    return test_labels\n```\n\n**Example Dataset:** CIFAR10\n\n![](https://s1.ax1x.com/2020/11/07/BIM9TH.png)\n\n> **Issues:** Although pics may seem visually similar, but still give lots of errors.\n> \n---\n\n- Compare func used in it\n### **K nearest Neighbors Method**\n\n**L1 distance:** $d_1(I_1,I_2) = \\sum\\limits_{p} \\mid I_1^p - I_2^p \\mid$\n\n![](https://s1.ax1x.com/2020/11/07/BIKXSx.png)\n\n*Minimize the sum given the most similar pics*\n\n#### **BackWards**\n\n![](https://s1.ax1x.com/2020/11/07/BIKjl6.png)\n\n#### **What it looks like**\n\n![](https://s1.ax1x.com/2020/11/07/BIMp0e.png)\n\n**Issues**\n\n1. Isolated Yellow Point\n2. Noisy of one single point (green into blue)\n\n**Use K Nearest Neighbors to Optimize it**\n![](https://s1.ax1x.com/2020/11/07/BIMitA.png)\n\n---\n\n*A Better Cmp Func*\n**L2(Euclidean) distance:** $d_1(I_1,I_2) = \\sqrt{\\sum\\limits_{p}{(I_1^p - I_2^p)}^2}$\n\n![](https://s1.ax1x.com/2020/11/07/BIMFfI.png)\n\n> The L1 Distance depends on the coordinate system, whenever there is a rotate, it would change the L1 Distance, while that won't happen in the L2 Distance case (simply because it's a circle)\n\n---\n\n#### **Hyperparameters**\n- What's the best value of **k**\n- What's the best **distance** to use? (L1,L2 or anything else)\n\n*These things are preset rather than learn automatically from learning process*\n\nThis is **Very problem-dependent**, just try!, but How?\n\n![](https://s1.ax1x.com/2020/11/07/BIME1P.png)\n\n**Training & Validation process should not mixed with the test data**\n\n- Cross Validation\n\n![](https://s1.ax1x.com/2020/11/07/BIMApt.png)\n\n- Validation process\n\n![](https://s1.ax1x.com/2020/11/07/BIMV6f.png)\n\n> using the validation data to choose the best hyperparameters.\n\n![](https://s1.ax1x.com/2020/11/07/BIMu7Q.png)\n\n> Cause we sum the offset, though the differences bettween pics and pics are various, they still got the same L2 distance, which is not so good.\n\n\n---\n\n### **Linear Classification**\n\n- **Parametric Model**\n![](https://s1.ax1x.com/2020/11/07/BIMZX8.png)\n\n$$f(x,W) = Wx + b$$\n> We need f(x,W) to be 10x1 and the x is actually 3072x1, so the W we input may be 10x3072, sometimes we add a bias to balance.\n\n![](https://s1.ax1x.com/2020/11/07/BIMn0g.png)\n\n![](https://s1.ax1x.com/2020/11/07/BIMMkj.png)\n\n> It use a single line to separate the object based on its RGB info\n\nBut how can we tell the quality of W ?\n(View the next lecture)\n\n- **Problems**\n![](https://s1.ax1x.com/2020/11/07/BIMQts.png)\n\n> Since it's linear the Problems is obivious.\n","slug":"CS231n/CS231n_01_Image_Classification","published":1,"updated":"2026-02-03T05:42:14.423Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzva000j7uithr2525yo","content":"<p><strong>Preface:</strong> This is the note of Stanford course CS231n, paving the way for my lab research.</p>\n<h1 id=\"Image-Classification\"><a href=\"#Image-Classification\" class=\"headerlink\" title=\"Image Classification\"></a>Image Classification</h1><p><em>A core task in Computer Vision</em></p>\n<hr>\n<h3 id=\"Computer’-Work\"><a href=\"#Computer’-Work\" class=\"headerlink\" title=\"Computer’ Work\"></a>Computer’ Work</h3><p>Input an image, and assign one of the label amoung the given labels.</p>\n<ul>\n<li><strong>The Problem:</strong> </li>\n</ul>\n<ol>\n<li>Semantic Gap</li>\n<li>Viewpoint variation</li>\n<li>illumination </li>\n<li>Deformation</li>\n<li>Occlusion</li>\n<li>Intraclass variation</li>\n</ol>\n<hr>\n<h3 id=\"An-image-classifier\"><a href=\"#An-image-classifier\" class=\"headerlink\" title=\"An image classifier\"></a>An image classifier</h3><blockquote>\n<p>Coding might be difficult </p>\n</blockquote>\n<pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">classify_image</span>(<span class=\"hljs-params\">image</span>):</span>\n    <span class=\"hljs-comment\"># Do Some Magic</span>\n    <span class=\"hljs-keyword\">return</span> class_label</code></pre>\n<ul>\n<li>Attmpts</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMSmD.png\" alt></p>\n<hr>\n<h3 id=\"Data-Driven-Approach\"><a href=\"#Data-Driven-Approach\" class=\"headerlink\" title=\"Data-Driven Approach\"></a>Data-Driven Approach</h3><ol>\n<li>Collect a dataset of images and labels</li>\n<li>Use Machine Learning to train a classifier</li>\n<li>Evaluate the classifier on new images</li>\n</ol>\n<ul>\n<li>First classifier: Nearest Neighbor</li>\n</ul>\n<p><em>Just Memorize all data and labels</em><br><pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">train</span>(<span class=\"hljs-params\">images, labels</span>):</span>\n    <span class=\"hljs-comment\"># Machine Learning!</span>\n    <span class=\"hljs-keyword\">return</span> model</code></pre></p>\n<p><em>Predict the label of the most similar training image</em><br><pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">predict</span>(<span class=\"hljs-params\">model, test_images</span>):</span>\n    <span class=\"hljs-comment\"># Use model to predict labels</span>\n    <span class=\"hljs-keyword\">return</span> test_labels</code></pre></p>\n<p><strong>Example Dataset:</strong> CIFAR10</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIM9TH.png\" alt></p>\n<blockquote>\n<p><strong>Issues:</strong> Although pics may seem visually similar, but still give lots of errors.</p>\n<hr>\n</blockquote>\n<ul>\n<li>Compare func used in it<h3 id=\"K-nearest-Neighbors-Method\"><a href=\"#K-nearest-Neighbors-Method\" class=\"headerlink\" title=\"K nearest Neighbors Method\"></a><strong>K nearest Neighbors Method</strong></h3></li>\n</ul>\n<p><strong>L1 distance:</strong> $d<em>1(I_1,I_2) = \\sum\\limits</em>{p} \\mid I_1^p - I_2^p \\mid$</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIKXSx.png\" alt></p>\n<p><em>Minimize the sum given the most similar pics</em></p>\n<h4 id=\"BackWards\"><a href=\"#BackWards\" class=\"headerlink\" title=\"BackWards\"></a><strong>BackWards</strong></h4><p><img src=\"https://s1.ax1x.com/2020/11/07/BIKjl6.png\" alt></p>\n<h4 id=\"What-it-looks-like\"><a href=\"#What-it-looks-like\" class=\"headerlink\" title=\"What it looks like\"></a><strong>What it looks like</strong></h4><p><img src=\"https://s1.ax1x.com/2020/11/07/BIMp0e.png\" alt></p>\n<p><strong>Issues</strong></p>\n<ol>\n<li>Isolated Yellow Point</li>\n<li>Noisy of one single point (green into blue)</li>\n</ol>\n<p><strong>Use K Nearest Neighbors to Optimize it</strong><br><img src=\"https://s1.ax1x.com/2020/11/07/BIMitA.png\" alt></p>\n<hr>\n<p><em>A Better Cmp Func</em><br><strong>L2(Euclidean) distance:</strong> $d<em>1(I_1,I_2) = \\sqrt{\\sum\\limits</em>{p}{(I_1^p - I_2^p)}^2}$</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMFfI.png\" alt></p>\n<blockquote>\n<p>The L1 Distance depends on the coordinate system, whenever there is a rotate, it would change the L1 Distance, while that won’t happen in the L2 Distance case (simply because it’s a circle)</p>\n</blockquote>\n<hr>\n<h4 id=\"Hyperparameters\"><a href=\"#Hyperparameters\" class=\"headerlink\" title=\"Hyperparameters\"></a><strong>Hyperparameters</strong></h4><ul>\n<li>What’s the best value of <strong>k</strong></li>\n<li>What’s the best <strong>distance</strong> to use? (L1,L2 or anything else)</li>\n</ul>\n<p><em>These things are preset rather than learn automatically from learning process</em></p>\n<p>This is <strong>Very problem-dependent</strong>, just try!, but How?</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIME1P.png\" alt></p>\n<p><strong>Training &amp; Validation process should not mixed with the test data</strong></p>\n<ul>\n<li>Cross Validation</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMApt.png\" alt></p>\n<ul>\n<li>Validation process</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMV6f.png\" alt></p>\n<blockquote>\n<p>using the validation data to choose the best hyperparameters.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMu7Q.png\" alt></p>\n<blockquote>\n<p>Cause we sum the offset, though the differences bettween pics and pics are various, they still got the same L2 distance, which is not so good.</p>\n</blockquote>\n<hr>\n<h3 id=\"Linear-Classification\"><a href=\"#Linear-Classification\" class=\"headerlink\" title=\"Linear Classification\"></a><strong>Linear Classification</strong></h3><ul>\n<li><strong>Parametric Model</strong><br><img src=\"https://s1.ax1x.com/2020/11/07/BIMZX8.png\" alt></li>\n</ul>\n<script type=\"math/tex; mode=display\">f(x,W) = Wx + b</script><blockquote>\n<p>We need f(x,W) to be 10x1 and the x is actually 3072x1, so the W we input may be 10x3072, sometimes we add a bias to balance.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMn0g.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMMkj.png\" alt></p>\n<blockquote>\n<p>It use a single line to separate the object based on its RGB info</p>\n</blockquote>\n<p>But how can we tell the quality of W ?<br>(View the next lecture)</p>\n<ul>\n<li><strong>Problems</strong><br><img src=\"https://s1.ax1x.com/2020/11/07/BIMQts.png\" alt></li>\n</ul>\n<blockquote>\n<p>Since it’s linear the Problems is obivious.</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<p><strong>Preface:</strong> This is the note of Stanford course CS231n, paving the way for my lab research.</p>\n<h1 id=\"Image-Classification\"><a href=\"#Image-Classification\" class=\"headerlink\" title=\"Image Classification\"></a>Image Classification</h1><p><em>A core task in Computer Vision</em></p>\n<hr>\n<h3 id=\"Computer’-Work\"><a href=\"#Computer’-Work\" class=\"headerlink\" title=\"Computer’ Work\"></a>Computer’ Work</h3><p>Input an image, and assign one of the label amoung the given labels.</p>\n<ul>\n<li><strong>The Problem:</strong> </li>\n</ul>\n<ol>\n<li>Semantic Gap</li>\n<li>Viewpoint variation</li>\n<li>illumination </li>\n<li>Deformation</li>\n<li>Occlusion</li>\n<li>Intraclass variation</li>\n</ol>\n<hr>\n<h3 id=\"An-image-classifier\"><a href=\"#An-image-classifier\" class=\"headerlink\" title=\"An image classifier\"></a>An image classifier</h3><blockquote>\n<p>Coding might be difficult </p>\n</blockquote>\n<pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">classify_image</span>(<span class=\"hljs-params\">image</span>):</span>\n    <span class=\"hljs-comment\"># Do Some Magic</span>\n    <span class=\"hljs-keyword\">return</span> class_label</code></pre>\n<ul>\n<li>Attmpts</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMSmD.png\" alt></p>\n<hr>\n<h3 id=\"Data-Driven-Approach\"><a href=\"#Data-Driven-Approach\" class=\"headerlink\" title=\"Data-Driven Approach\"></a>Data-Driven Approach</h3><ol>\n<li>Collect a dataset of images and labels</li>\n<li>Use Machine Learning to train a classifier</li>\n<li>Evaluate the classifier on new images</li>\n</ol>\n<ul>\n<li>First classifier: Nearest Neighbor</li>\n</ul>\n<p><em>Just Memorize all data and labels</em><br><pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">train</span>(<span class=\"hljs-params\">images, labels</span>):</span>\n    <span class=\"hljs-comment\"># Machine Learning!</span>\n    <span class=\"hljs-keyword\">return</span> model</code></pre></p>\n<p><em>Predict the label of the most similar training image</em><br><pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">predict</span>(<span class=\"hljs-params\">model, test_images</span>):</span>\n    <span class=\"hljs-comment\"># Use model to predict labels</span>\n    <span class=\"hljs-keyword\">return</span> test_labels</code></pre></p>\n<p><strong>Example Dataset:</strong> CIFAR10</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIM9TH.png\" alt></p>\n<blockquote>\n<p><strong>Issues:</strong> Although pics may seem visually similar, but still give lots of errors.</p>\n<hr>\n</blockquote>\n<ul>\n<li>Compare func used in it<h3 id=\"K-nearest-Neighbors-Method\"><a href=\"#K-nearest-Neighbors-Method\" class=\"headerlink\" title=\"K nearest Neighbors Method\"></a><strong>K nearest Neighbors Method</strong></h3></li>\n</ul>\n<p><strong>L1 distance:</strong> $d<em>1(I_1,I_2) = \\sum\\limits</em>{p} \\mid I_1^p - I_2^p \\mid$</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIKXSx.png\" alt></p>\n<p><em>Minimize the sum given the most similar pics</em></p>\n<h4 id=\"BackWards\"><a href=\"#BackWards\" class=\"headerlink\" title=\"BackWards\"></a><strong>BackWards</strong></h4><p><img src=\"https://s1.ax1x.com/2020/11/07/BIKjl6.png\" alt></p>\n<h4 id=\"What-it-looks-like\"><a href=\"#What-it-looks-like\" class=\"headerlink\" title=\"What it looks like\"></a><strong>What it looks like</strong></h4><p><img src=\"https://s1.ax1x.com/2020/11/07/BIMp0e.png\" alt></p>\n<p><strong>Issues</strong></p>\n<ol>\n<li>Isolated Yellow Point</li>\n<li>Noisy of one single point (green into blue)</li>\n</ol>\n<p><strong>Use K Nearest Neighbors to Optimize it</strong><br><img src=\"https://s1.ax1x.com/2020/11/07/BIMitA.png\" alt></p>\n<hr>\n<p><em>A Better Cmp Func</em><br><strong>L2(Euclidean) distance:</strong> $d<em>1(I_1,I_2) = \\sqrt{\\sum\\limits</em>{p}{(I_1^p - I_2^p)}^2}$</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMFfI.png\" alt></p>\n<blockquote>\n<p>The L1 Distance depends on the coordinate system, whenever there is a rotate, it would change the L1 Distance, while that won’t happen in the L2 Distance case (simply because it’s a circle)</p>\n</blockquote>\n<hr>\n<h4 id=\"Hyperparameters\"><a href=\"#Hyperparameters\" class=\"headerlink\" title=\"Hyperparameters\"></a><strong>Hyperparameters</strong></h4><ul>\n<li>What’s the best value of <strong>k</strong></li>\n<li>What’s the best <strong>distance</strong> to use? (L1,L2 or anything else)</li>\n</ul>\n<p><em>These things are preset rather than learn automatically from learning process</em></p>\n<p>This is <strong>Very problem-dependent</strong>, just try!, but How?</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIME1P.png\" alt></p>\n<p><strong>Training &amp; Validation process should not mixed with the test data</strong></p>\n<ul>\n<li>Cross Validation</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMApt.png\" alt></p>\n<ul>\n<li>Validation process</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMV6f.png\" alt></p>\n<blockquote>\n<p>using the validation data to choose the best hyperparameters.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMu7Q.png\" alt></p>\n<blockquote>\n<p>Cause we sum the offset, though the differences bettween pics and pics are various, they still got the same L2 distance, which is not so good.</p>\n</blockquote>\n<hr>\n<h3 id=\"Linear-Classification\"><a href=\"#Linear-Classification\" class=\"headerlink\" title=\"Linear Classification\"></a><strong>Linear Classification</strong></h3><ul>\n<li><strong>Parametric Model</strong><br><img src=\"https://s1.ax1x.com/2020/11/07/BIMZX8.png\" alt></li>\n</ul>\n<script type=\"math/tex; mode=display\">f(x,W) = Wx + b</script><blockquote>\n<p>We need f(x,W) to be 10x1 and the x is actually 3072x1, so the W we input may be 10x3072, sometimes we add a bias to balance.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMn0g.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMMkj.png\" alt></p>\n<blockquote>\n<p>It use a single line to separate the object based on its RGB info</p>\n</blockquote>\n<p>But how can we tell the quality of W ?<br>(View the next lecture)</p>\n<ul>\n<li><strong>Problems</strong><br><img src=\"https://s1.ax1x.com/2020/11/07/BIMQts.png\" alt></li>\n</ul>\n<blockquote>\n<p>Since it’s linear the Problems is obivious.</p>\n</blockquote>\n"},{"title":"CS231n Loss Functions and Optimization 02","date":"2020-11-09T04:52:06.000Z","index_img":"/img/Cs231n/top.jpg","math":true,"_content":"\n### Preview the Goal in this lecture\n1. Define a loss function\n2. Come up with a way of finding the paras that minimize the (1)\n(optimization)\n\n**The Remain Problem from last lecture**\n\n- How to choose the W para ? \n\n![](https://s1.ax1x.com/2020/11/08/BTZxgK.png)\n\n### Loss function\n\n> A loss function tells how good our current classifier is.\n\n$${(x_i,y_i)}_{i=1}^N$$\n\nThe $X_i$ is image and the $y_i$ is label (int)\n\nThe Total loss is defined as the func follows.\n\n$$L = \\frac{1}{N}\\sum\\limits_iL_i(f(x_i,W),y_i)$$\n*Which is the sum of every single test's loss*\n\n---\n\n#### **Muticlass SVM loss**\n\nGiven an example $(x_i,y_i)$ where $x_i$ is the image and where $y_i$ is the (int) label, using the shorthand for the score vec $s = f(x_i,W)$\n\nThe SVM loss has the form:\n\n![](https://s1.ax1x.com/2020/11/08/BTZ7B4.png)\n\n> if the incorrect score is smaller than the right score (x margin), we set the loss to 0.\nin this case the safe margin is set to one\n**Margin choice depends on our need**\n\n\n- Then we loop the class\n\n![](https://s1.ax1x.com/2020/11/08/BTZqE9.png)\n\n![](https://s1.ax1x.com/2020/11/08/BTZLNR.png)\n\n- What if we use\n\n$$L = \\frac{1}{N}\\sum\\limits_iL_i(f(x_i,W),y_i)^2$$\n> This is not a linear function and totally different, it's may be useful sometimes depends on the way you care about the errors.\n\n#### Example Code\n\n```python\ndef L_i_vectorized(x, y, W):\n    scores = W.dot(x)\n    margins = np.maximun(0, scores - scores[y] + margin)\n    margins[y] = 0\n    loss_i = np.sum(margins)\n    return loss_i\n    # pretty easy\n```\n\n![](https://s1.ax1x.com/2020/11/08/BTZO41.png)\n\n> It just change the gap bettween scores\n\n![](https://s1.ax1x.com/2020/11/08/BTZzjO.png)\n\n![](https://s1.ax1x.com/2020/11/08/BTe9De.png)\n\n> often use L2 regularization just Euclid norm.\n\n![](https://s1.ax1x.com/2020/11/08/BTepuD.png)\n\n> In this case the L1 and L2 reg is equal, but we can tell that L1 prefers the $w_1$ for it contains more zero, while the L2 prefers the $w_2$ for the weight is evenly spreaded through the test case.\n\n> The Multiclass SVM loss just care about the gap bettween the right labels and the wrongs.\n\n#### **Softmax Classifier**\n\n![](https://s1.ax1x.com/2020/11/08/BTeiEd.png)\n\n> We just want to make the true probability closer to 1 (closer the better, eq is the best), so the loss func can be chosed by using the -log on the $P$.\n\n![](https://s1.ax1x.com/2020/11/08/BTeCHH.png)\n\n> If we want to get the zero loss, the score may goes to inf! But Computer don't like that.\n\n- Debugging Way\noutcomes might be $logC$\n\n---\n\n![](https://s1.ax1x.com/2020/11/08/BTek4I.png)\n\n![](https://s1.ax1x.com/2020/11/08/BTeECt.png)\n\n---\n\n### Optimization\n\n#### Random Search - The Naive but Simplest way \n> Really Slow !!!\n\n#### Gradient Descent\n> We just get the Gradient of W and go down to the bottom (maybe local best?)\n\n![](https://s1.ax1x.com/2020/11/08/BTeFUA.png)\n\n**Code**\n\n```python\n# Vanilla Gradient Descent\n\nwhile True:\n    weight_grad = evaluate_gradient(loss_fun, data, weights)\n    weights += -step_size * weight_grad\n```\n\n**Step size is called elearning rate which is important**\n\n![](https://s1.ax1x.com/2020/11/08/BTeV8P.png)\n\n> Since the N might be super large, we sample some sets called minibatch and use it to estimate the true gradient.\n\n![](https://s1.ax1x.com/2020/11/08/BTeZgf.png)\n\n\n---\n\n![](https://s1.ax1x.com/2020/11/08/BTenKS.png)\n\n![](https://s1.ax1x.com/2020/11/08/BTeuDg.png)\n\n**Color Feature**\n![](https://s1.ax1x.com/2020/11/08/BTeQEj.png)\n\n**Gradient** *Extract the edge info*\n![](https://s1.ax1x.com/2020/11/08/BTelUs.png)\n\n**NLP?**\n![](https://s1.ax1x.com/2020/11/08/BTeG80.png)\n\n> clustering different image patches from images\n\n![](https://s1.ax1x.com/2020/11/08/BTe15n.png)\n- Differences\n1. Extract the Feature at first and feed into the linear classificator\n2. Convolutional Neutral Network would learn the feature automatically during the training process.","source":"_posts/CS231n/CS231n_02_Loss-Functions-and-Optimization.md","raw":"---\ntitle: CS231n Loss Functions and Optimization 02\ndate: 2020-11-08 20:52:06\ntags: [CV,Neural Network]\ncategory: [CS231n]\nindex_img: /img/Cs231n/top.jpg\nmath: true\n---\n\n### Preview the Goal in this lecture\n1. Define a loss function\n2. Come up with a way of finding the paras that minimize the (1)\n(optimization)\n\n**The Remain Problem from last lecture**\n\n- How to choose the W para ? \n\n![](https://s1.ax1x.com/2020/11/08/BTZxgK.png)\n\n### Loss function\n\n> A loss function tells how good our current classifier is.\n\n$${(x_i,y_i)}_{i=1}^N$$\n\nThe $X_i$ is image and the $y_i$ is label (int)\n\nThe Total loss is defined as the func follows.\n\n$$L = \\frac{1}{N}\\sum\\limits_iL_i(f(x_i,W),y_i)$$\n*Which is the sum of every single test's loss*\n\n---\n\n#### **Muticlass SVM loss**\n\nGiven an example $(x_i,y_i)$ where $x_i$ is the image and where $y_i$ is the (int) label, using the shorthand for the score vec $s = f(x_i,W)$\n\nThe SVM loss has the form:\n\n![](https://s1.ax1x.com/2020/11/08/BTZ7B4.png)\n\n> if the incorrect score is smaller than the right score (x margin), we set the loss to 0.\nin this case the safe margin is set to one\n**Margin choice depends on our need**\n\n\n- Then we loop the class\n\n![](https://s1.ax1x.com/2020/11/08/BTZqE9.png)\n\n![](https://s1.ax1x.com/2020/11/08/BTZLNR.png)\n\n- What if we use\n\n$$L = \\frac{1}{N}\\sum\\limits_iL_i(f(x_i,W),y_i)^2$$\n> This is not a linear function and totally different, it's may be useful sometimes depends on the way you care about the errors.\n\n#### Example Code\n\n```python\ndef L_i_vectorized(x, y, W):\n    scores = W.dot(x)\n    margins = np.maximun(0, scores - scores[y] + margin)\n    margins[y] = 0\n    loss_i = np.sum(margins)\n    return loss_i\n    # pretty easy\n```\n\n![](https://s1.ax1x.com/2020/11/08/BTZO41.png)\n\n> It just change the gap bettween scores\n\n![](https://s1.ax1x.com/2020/11/08/BTZzjO.png)\n\n![](https://s1.ax1x.com/2020/11/08/BTe9De.png)\n\n> often use L2 regularization just Euclid norm.\n\n![](https://s1.ax1x.com/2020/11/08/BTepuD.png)\n\n> In this case the L1 and L2 reg is equal, but we can tell that L1 prefers the $w_1$ for it contains more zero, while the L2 prefers the $w_2$ for the weight is evenly spreaded through the test case.\n\n> The Multiclass SVM loss just care about the gap bettween the right labels and the wrongs.\n\n#### **Softmax Classifier**\n\n![](https://s1.ax1x.com/2020/11/08/BTeiEd.png)\n\n> We just want to make the true probability closer to 1 (closer the better, eq is the best), so the loss func can be chosed by using the -log on the $P$.\n\n![](https://s1.ax1x.com/2020/11/08/BTeCHH.png)\n\n> If we want to get the zero loss, the score may goes to inf! But Computer don't like that.\n\n- Debugging Way\noutcomes might be $logC$\n\n---\n\n![](https://s1.ax1x.com/2020/11/08/BTek4I.png)\n\n![](https://s1.ax1x.com/2020/11/08/BTeECt.png)\n\n---\n\n### Optimization\n\n#### Random Search - The Naive but Simplest way \n> Really Slow !!!\n\n#### Gradient Descent\n> We just get the Gradient of W and go down to the bottom (maybe local best?)\n\n![](https://s1.ax1x.com/2020/11/08/BTeFUA.png)\n\n**Code**\n\n```python\n# Vanilla Gradient Descent\n\nwhile True:\n    weight_grad = evaluate_gradient(loss_fun, data, weights)\n    weights += -step_size * weight_grad\n```\n\n**Step size is called elearning rate which is important**\n\n![](https://s1.ax1x.com/2020/11/08/BTeV8P.png)\n\n> Since the N might be super large, we sample some sets called minibatch and use it to estimate the true gradient.\n\n![](https://s1.ax1x.com/2020/11/08/BTeZgf.png)\n\n\n---\n\n![](https://s1.ax1x.com/2020/11/08/BTenKS.png)\n\n![](https://s1.ax1x.com/2020/11/08/BTeuDg.png)\n\n**Color Feature**\n![](https://s1.ax1x.com/2020/11/08/BTeQEj.png)\n\n**Gradient** *Extract the edge info*\n![](https://s1.ax1x.com/2020/11/08/BTelUs.png)\n\n**NLP?**\n![](https://s1.ax1x.com/2020/11/08/BTeG80.png)\n\n> clustering different image patches from images\n\n![](https://s1.ax1x.com/2020/11/08/BTe15n.png)\n- Differences\n1. Extract the Feature at first and feed into the linear classificator\n2. Convolutional Neutral Network would learn the feature automatically during the training process.","slug":"CS231n/CS231n_02_Loss-Functions-and-Optimization","published":1,"updated":"2026-02-03T05:42:14.425Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzva000n7uitbn439co0","content":"<h3 id=\"Preview-the-Goal-in-this-lecture\"><a href=\"#Preview-the-Goal-in-this-lecture\" class=\"headerlink\" title=\"Preview the Goal in this lecture\"></a>Preview the Goal in this lecture</h3><ol>\n<li>Define a loss function</li>\n<li>Come up with a way of finding the paras that minimize the (1)<br>(optimization)</li>\n</ol>\n<p><strong>The Remain Problem from last lecture</strong></p>\n<ul>\n<li>How to choose the W para ? </li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZxgK.png\" alt></p>\n<h3 id=\"Loss-function\"><a href=\"#Loss-function\" class=\"headerlink\" title=\"Loss function\"></a>Loss function</h3><blockquote>\n<p>A loss function tells how good our current classifier is.</p>\n</blockquote>\n<script type=\"math/tex; mode=display\">{(x_i,y_i)}_{i=1}^N</script><p>The $X_i$ is image and the $y_i$ is label (int)</p>\n<p>The Total loss is defined as the func follows.</p>\n<script type=\"math/tex; mode=display\">L = \\frac{1}{N}\\sum\\limits_iL_i(f(x_i,W),y_i)</script><p><em>Which is the sum of every single test’s loss</em></p>\n<hr>\n<h4 id=\"Muticlass-SVM-loss\"><a href=\"#Muticlass-SVM-loss\" class=\"headerlink\" title=\"Muticlass SVM loss\"></a><strong>Muticlass SVM loss</strong></h4><p>Given an example $(x_i,y_i)$ where $x_i$ is the image and where $y_i$ is the (int) label, using the shorthand for the score vec $s = f(x_i,W)$</p>\n<p>The SVM loss has the form:</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZ7B4.png\" alt></p>\n<blockquote>\n<p>if the incorrect score is smaller than the right score (x margin), we set the loss to 0.<br>in this case the safe margin is set to one<br><strong>Margin choice depends on our need</strong></p>\n</blockquote>\n<ul>\n<li>Then we loop the class</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZqE9.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZLNR.png\" alt></p>\n<ul>\n<li>What if we use</li>\n</ul>\n<script type=\"math/tex; mode=display\">L = \\frac{1}{N}\\sum\\limits_iL_i(f(x_i,W),y_i)^2</script><blockquote>\n<p>This is not a linear function and totally different, it’s may be useful sometimes depends on the way you care about the errors.</p>\n</blockquote>\n<h4 id=\"Example-Code\"><a href=\"#Example-Code\" class=\"headerlink\" title=\"Example Code\"></a>Example Code</h4><pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">L_i_vectorized</span>(<span class=\"hljs-params\">x, y, W</span>):</span>\n    scores = W.dot(x)\n    margins = np.maximun(<span class=\"hljs-number\">0</span>, scores - scores[y] + margin)\n    margins[y] = <span class=\"hljs-number\">0</span>\n    loss_i = np.<span class=\"hljs-built_in\">sum</span>(margins)\n    <span class=\"hljs-keyword\">return</span> loss_i\n    <span class=\"hljs-comment\"># pretty easy</span></code></pre>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZO41.png\" alt></p>\n<blockquote>\n<p>It just change the gap bettween scores</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZzjO.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTe9De.png\" alt></p>\n<blockquote>\n<p>often use L2 regularization just Euclid norm.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTepuD.png\" alt></p>\n<blockquote>\n<p>In this case the L1 and L2 reg is equal, but we can tell that L1 prefers the $w_1$ for it contains more zero, while the L2 prefers the $w_2$ for the weight is evenly spreaded through the test case.</p>\n<p>The Multiclass SVM loss just care about the gap bettween the right labels and the wrongs.</p>\n</blockquote>\n<h4 id=\"Softmax-Classifier\"><a href=\"#Softmax-Classifier\" class=\"headerlink\" title=\"Softmax Classifier\"></a><strong>Softmax Classifier</strong></h4><p><img src=\"https://s1.ax1x.com/2020/11/08/BTeiEd.png\" alt></p>\n<blockquote>\n<p>We just want to make the true probability closer to 1 (closer the better, eq is the best), so the loss func can be chosed by using the -log on the $P$.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeCHH.png\" alt></p>\n<blockquote>\n<p>If we want to get the zero loss, the score may goes to inf! But Computer don’t like that.</p>\n</blockquote>\n<ul>\n<li>Debugging Way<br>outcomes might be $logC$</li>\n</ul>\n<hr>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTek4I.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeECt.png\" alt></p>\n<hr>\n<h3 id=\"Optimization\"><a href=\"#Optimization\" class=\"headerlink\" title=\"Optimization\"></a>Optimization</h3><h4 id=\"Random-Search-The-Naive-but-Simplest-way\"><a href=\"#Random-Search-The-Naive-but-Simplest-way\" class=\"headerlink\" title=\"Random Search - The Naive but Simplest way\"></a>Random Search - The Naive but Simplest way</h4><blockquote>\n<p>Really Slow !!!</p>\n</blockquote>\n<h4 id=\"Gradient-Descent\"><a href=\"#Gradient-Descent\" class=\"headerlink\" title=\"Gradient Descent\"></a>Gradient Descent</h4><blockquote>\n<p>We just get the Gradient of W and go down to the bottom (maybe local best?)</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeFUA.png\" alt></p>\n<p><strong>Code</strong></p>\n<pre><code class=\"hljs python\"><span class=\"hljs-comment\"># Vanilla Gradient Descent</span>\n\n<span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n    weight_grad = evaluate_gradient(loss_fun, data, weights)\n    weights += -step_size * weight_grad</code></pre>\n<p><strong>Step size is called elearning rate which is important</strong></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeV8P.png\" alt></p>\n<blockquote>\n<p>Since the N might be super large, we sample some sets called minibatch and use it to estimate the true gradient.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeZgf.png\" alt></p>\n<hr>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTenKS.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeuDg.png\" alt></p>\n<p><strong>Color Feature</strong><br><img src=\"https://s1.ax1x.com/2020/11/08/BTeQEj.png\" alt></p>\n<p><strong>Gradient</strong> <em>Extract the edge info</em><br><img src=\"https://s1.ax1x.com/2020/11/08/BTelUs.png\" alt></p>\n<p><strong>NLP?</strong><br><img src=\"https://s1.ax1x.com/2020/11/08/BTeG80.png\" alt></p>\n<blockquote>\n<p>clustering different image patches from images</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTe15n.png\" alt></p>\n<ul>\n<li>Differences</li>\n</ul>\n<ol>\n<li>Extract the Feature at first and feed into the linear classificator</li>\n<li>Convolutional Neutral Network would learn the feature automatically during the training process.</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Preview-the-Goal-in-this-lecture\"><a href=\"#Preview-the-Goal-in-this-lecture\" class=\"headerlink\" title=\"Preview the Goal in this lecture\"></a>Preview the Goal in this lecture</h3><ol>\n<li>Define a loss function</li>\n<li>Come up with a way of finding the paras that minimize the (1)<br>(optimization)</li>\n</ol>\n<p><strong>The Remain Problem from last lecture</strong></p>\n<ul>\n<li>How to choose the W para ? </li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZxgK.png\" alt></p>\n<h3 id=\"Loss-function\"><a href=\"#Loss-function\" class=\"headerlink\" title=\"Loss function\"></a>Loss function</h3><blockquote>\n<p>A loss function tells how good our current classifier is.</p>\n</blockquote>\n<script type=\"math/tex; mode=display\">{(x_i,y_i)}_{i=1}^N</script><p>The $X_i$ is image and the $y_i$ is label (int)</p>\n<p>The Total loss is defined as the func follows.</p>\n<script type=\"math/tex; mode=display\">L = \\frac{1}{N}\\sum\\limits_iL_i(f(x_i,W),y_i)</script><p><em>Which is the sum of every single test’s loss</em></p>\n<hr>\n<h4 id=\"Muticlass-SVM-loss\"><a href=\"#Muticlass-SVM-loss\" class=\"headerlink\" title=\"Muticlass SVM loss\"></a><strong>Muticlass SVM loss</strong></h4><p>Given an example $(x_i,y_i)$ where $x_i$ is the image and where $y_i$ is the (int) label, using the shorthand for the score vec $s = f(x_i,W)$</p>\n<p>The SVM loss has the form:</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZ7B4.png\" alt></p>\n<blockquote>\n<p>if the incorrect score is smaller than the right score (x margin), we set the loss to 0.<br>in this case the safe margin is set to one<br><strong>Margin choice depends on our need</strong></p>\n</blockquote>\n<ul>\n<li>Then we loop the class</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZqE9.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZLNR.png\" alt></p>\n<ul>\n<li>What if we use</li>\n</ul>\n<script type=\"math/tex; mode=display\">L = \\frac{1}{N}\\sum\\limits_iL_i(f(x_i,W),y_i)^2</script><blockquote>\n<p>This is not a linear function and totally different, it’s may be useful sometimes depends on the way you care about the errors.</p>\n</blockquote>\n<h4 id=\"Example-Code\"><a href=\"#Example-Code\" class=\"headerlink\" title=\"Example Code\"></a>Example Code</h4><pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">L_i_vectorized</span>(<span class=\"hljs-params\">x, y, W</span>):</span>\n    scores = W.dot(x)\n    margins = np.maximun(<span class=\"hljs-number\">0</span>, scores - scores[y] + margin)\n    margins[y] = <span class=\"hljs-number\">0</span>\n    loss_i = np.<span class=\"hljs-built_in\">sum</span>(margins)\n    <span class=\"hljs-keyword\">return</span> loss_i\n    <span class=\"hljs-comment\"># pretty easy</span></code></pre>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZO41.png\" alt></p>\n<blockquote>\n<p>It just change the gap bettween scores</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZzjO.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTe9De.png\" alt></p>\n<blockquote>\n<p>often use L2 regularization just Euclid norm.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTepuD.png\" alt></p>\n<blockquote>\n<p>In this case the L1 and L2 reg is equal, but we can tell that L1 prefers the $w_1$ for it contains more zero, while the L2 prefers the $w_2$ for the weight is evenly spreaded through the test case.</p>\n<p>The Multiclass SVM loss just care about the gap bettween the right labels and the wrongs.</p>\n</blockquote>\n<h4 id=\"Softmax-Classifier\"><a href=\"#Softmax-Classifier\" class=\"headerlink\" title=\"Softmax Classifier\"></a><strong>Softmax Classifier</strong></h4><p><img src=\"https://s1.ax1x.com/2020/11/08/BTeiEd.png\" alt></p>\n<blockquote>\n<p>We just want to make the true probability closer to 1 (closer the better, eq is the best), so the loss func can be chosed by using the -log on the $P$.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeCHH.png\" alt></p>\n<blockquote>\n<p>If we want to get the zero loss, the score may goes to inf! But Computer don’t like that.</p>\n</blockquote>\n<ul>\n<li>Debugging Way<br>outcomes might be $logC$</li>\n</ul>\n<hr>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTek4I.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeECt.png\" alt></p>\n<hr>\n<h3 id=\"Optimization\"><a href=\"#Optimization\" class=\"headerlink\" title=\"Optimization\"></a>Optimization</h3><h4 id=\"Random-Search-The-Naive-but-Simplest-way\"><a href=\"#Random-Search-The-Naive-but-Simplest-way\" class=\"headerlink\" title=\"Random Search - The Naive but Simplest way\"></a>Random Search - The Naive but Simplest way</h4><blockquote>\n<p>Really Slow !!!</p>\n</blockquote>\n<h4 id=\"Gradient-Descent\"><a href=\"#Gradient-Descent\" class=\"headerlink\" title=\"Gradient Descent\"></a>Gradient Descent</h4><blockquote>\n<p>We just get the Gradient of W and go down to the bottom (maybe local best?)</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeFUA.png\" alt></p>\n<p><strong>Code</strong></p>\n<pre><code class=\"hljs python\"><span class=\"hljs-comment\"># Vanilla Gradient Descent</span>\n\n<span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n    weight_grad = evaluate_gradient(loss_fun, data, weights)\n    weights += -step_size * weight_grad</code></pre>\n<p><strong>Step size is called elearning rate which is important</strong></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeV8P.png\" alt></p>\n<blockquote>\n<p>Since the N might be super large, we sample some sets called minibatch and use it to estimate the true gradient.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeZgf.png\" alt></p>\n<hr>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTenKS.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeuDg.png\" alt></p>\n<p><strong>Color Feature</strong><br><img src=\"https://s1.ax1x.com/2020/11/08/BTeQEj.png\" alt></p>\n<p><strong>Gradient</strong> <em>Extract the edge info</em><br><img src=\"https://s1.ax1x.com/2020/11/08/BTelUs.png\" alt></p>\n<p><strong>NLP?</strong><br><img src=\"https://s1.ax1x.com/2020/11/08/BTeG80.png\" alt></p>\n<blockquote>\n<p>clustering different image patches from images</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTe15n.png\" alt></p>\n<ul>\n<li>Differences</li>\n</ul>\n<ol>\n<li>Extract the Feature at first and feed into the linear classificator</li>\n<li>Convolutional Neutral Network would learn the feature automatically during the training process.</li>\n</ol>\n"},{"title":"数据结构笔记 (2020-11-30 ~ 2020-12-05)","index_img":"/img/Pic/DS.png","date":"2020-12-05T18:10:02.000Z","math":true,"_content":"\n# 数据结构 - DataStructure\n\n数据结构这周依然是树上操作，课上学了AVL树，然后讲了之前用过的Hash，然后作业里面主要学会了LCA的倍增和不太熟练的欧拉序RMQ，最后学会了并查集的使用（就可以学最后的Tarjan LCA算法了) ，然后这周作业题主要是并查集，带有一道树上差分算法。\n\n---\n\n## LCA 问题\n\nLCA (Least Common Ancestors) 最近公共祖先问题，顾名思义既要找到两个节点最近的公共祖先，朴素做法是，两个节点中深的那个节点向上跳，直到两个节点深度相同，两个节点再同时向上跳（询问父节点）如果他们跳到最后的父节点是同一个那么这个节点就是他们的最近公共祖先。\n\n这种朴素的算法很好思考，但复杂度也是很高的，单次询问时间复杂度 O(n) 因为最坏要把所有节点都跳一遍。\n\n![](https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=1414039454,330983716&fm=26&gp=0.jpg)\n\n### **LCA - 倍增算法**\n\n倍增算法是LCA的经典算法，如同二分算法的本质一样，都是通过每次尽量把问题规模缩减2的幂次，从而达到 O(lgn) 的时间复杂度。\n\n我们简单讲解一下，倍增算法就是我不再像朴素算法一样一个个往上跳，我直接跳2的幂次，从大到小枚举，如果符合题意就跳，直到 2^0 跳一个节点，这样一次遍历下来，总能覆盖所有情况而满足题意跳到要跳的地方，但复杂度却大大降低减为 O(lgn)\n\n- 代码实现\n```cpp\nvoid dfs(int u, int fa)\n{\n    up[u][0] = fa;  // 预处理父亲\n    dep[u] = dep[fa] + 1;\n    for(auto& v : tree[u])\n    {\n        if(v == fa)\n            continue;\n        dfs(v, u);\n    }\n}\n\nvoid pre()\n{\n    for(int k = 1; (1 << k) <= n; ++k)\n        for(int i = 1; i <= n; ++i)\n            up[i][k] = up[up[i][k - 1]][k - 1]; \n            // 预处理所有的上跳\n            // 状态转移方程 跳 2^k 步，等于先跳2^k-1步再往上跳2^k-1步\n            // 2 ^ k = 2 ^ (k - 1) + 2 ^ (k - 1)\n}   \n\nint lca(int x, int y)\n{\n    if(dep[x] < dep[y])\n        swap(x, y); // 让深度大的为x\n    if(dep[x] != dep[y])\n    {\n        for(int k = 31; k >= 0; --k)\n        {\n            if(dep[up[x][k]] >= dep[y])\n                x = up[x][k];   // 调整为同一深度\n        }\n    }\n\n    if(x == y)\n        return x;   \n        // 如果一个是另外一个的长辈那么这时候两个直接就相等了，直接返回\n\n    for(int k = 31; k >= 0; --k)\n    {\n        if(up[x][k] != up[y][k])    // 同时上跳不过头\n        {\n            x = up[x][k];   \n            y = up[y][k];\n        }\n    }\n\n    return up[x][0];    // 最后 lca 就是里面任意一个的父亲\n}\n```\n\n---\n\n### **LCA - 欧拉序RMQ算法**\n\n这边涉及到RMQ问题，我们就先来讲一讲RMQ问题。\n\n- *RMQ 问题*\nRMQ 是英文 Range Maximum/Minimum Query 的缩写，表示区间最大（最小）值。\n\nRMQ问题一般可以使用单调栈、ST表、线段树来解决\n\n通过欧拉序将LCA问题转为RMQ问题后，我们一般使用ST表来解决RMQ问题。因为ST表在时间复杂度上表现优秀，需要 O(nlgn)的预处理，就能做到O(1)的询问。而写起来又较为简单，不像线段树一样复杂。可以处理大部分不需要在线修改的 RMQ 问题。\n\n另一方面如果我们使用单调栈和线段树在单次询问的时间复杂度仍然是 O(lgn) 级别的本没有做到比倍增算法更优，但在代码方面却比倍增算法更为复杂，因而我们选择ST表进行处理。\n\n\n### **ST表 - Sparse table**\n\n我们说 ST 表可以用来解决可重复贡献问题，因为ST表涉及到区间重叠，我们要保证区间重叠不会影响到我们要求的问题。所以ST表只能解决可重复贡献问题，例如最值和gcd。\n\nST表运用的也是倍增的思想，通过倍增区间覆盖来解决问题。\n\n```cpp\n// ST表\nint f[Max][lgn]\b, Logn[Max], a[Max];\n// f[i][k] 表示区间 i ~ i + 2^k - 1 的最值\n\nvoid pre()\n{\n    Logn[1] = 0;\n    for(int i = 2; i < Max; ++i)\n        Logn[i] = Logn[i / 2] + 1;\n}\n\n// 状态转移：\n    // 前者表示 i ~ i + 2^(k - 1) - 1 的区间最值\n    // 后者表示 i + 2^(k - 1) ~ i + 2^k - 1 的区间最值\n    // 合并即为 i ~ i + 2^k - 1的区间最值\nvoid preSet()\n{\n    for(int i = 1; i <= n; ++i)\n        f[i][0] = a[i]; // 显然 f[i][0] = a[i]\n\n    for(int k = 1; k < lgn; ++k)\n        for(int i = 1; i + (1 << (k - 1)) <= n; ++i)\n            f[i][k] = max(f[i][k - 1], f[i + (1 << (k - 1))][k - 1]);\n}\n\n// 查询操作：\n    // 如果我们要查询 区间 l ~ r 的最值, 我们根据ST表性质知道\n    // f[i][k] 表示 l ~ l + 2^k - 1 的区间最值\n    // r - 2^k + 1 ~ r 的区间最值就可以用 f[r - 1 << k + 1][k] 表示\n    // 那么我们需要这两个区间覆盖整个查询区间且不超过\n    // 则 l + 2^k - 1 >= r - 2^k + 1 且 l + 2^k - 1 <= r 且 r - 2^k + 1 >= l\n    // 则 k >= lg(r - l + 2) - 1 且 k <= floor(lg(r - l + 1));\n    // 我们直接取 k == floor(lg(r - l + 1))\n\nint find(int l, int r)\n{\n    int k = Logn[r - l + 1];\n    return max(f[i][k], f[r - (1 << k) + 1][k]); // O(1) 查询\n}\n\n```\n\n这样一个ST表就写好了，回到正题，我们是通过欧拉序把 LCA问题转换为RMQ问题，我们现在来看这是如何进行的。\n\n在看欧拉序之前我们先看一看基本的 dfs 序是怎么做的（真就递归学习呗）\n\n![dfs序](https://img-blog.csdnimg.cn/20191008210415266.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3djeHlreQ==,size_16,color_FFFFFF,t_70)\n\n正常的dfs序是深度优先不记录回溯的，如上图 dfs 序就是 \n**A->B->D->E->G->C->F->H**\n每个节点在dfs序中出现且仅出现一次\n\n而我们再来看欧拉序\n\n![欧拉序](https://img-blog.csdnimg.cn/20191008210445328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3djeHlreQ==,size_16,color_FFFFFF,t_70)\n\n它不同于dfs序将栈pop的元素也加入队列中，从而就形成了上图“逆时针”的模式\n上图欧拉序就是\n**A->B->D->B->E->G->E->B->A->C->F->H->F->C->A**\n一种intuition就是欧拉序是一种正常人走路遍历所有节点的顺序，只要叶节点大于2个的树就不可能是欧拉图或半欧拉图，那么必然要走回头路，在dfs序的基础上将回头路线画出就是欧拉序。\n\n我们来观察欧拉序可以发现，其首尾必然是根节点，然后除了叶节点仅出现一次，其余点出现2次以上(取决于是几叉树)，如果我们默认是二叉树，那么欧拉序的大小就不会超过 2n - 1 (考虑单链或就两叉到底的最坏情况)\n\n如果我们在欧拉序节点旁配上它的深度再结合图来观察\n**A(0)->B(1)->D(2)->B(1)->E(2)->G(3)->E(2)->B(1)->A(0)->C(1)->F(2)->H(3)->F(2)->C(1)->A(0)**\n我们根据欧拉序的性质不难发现一个节点的左右子树必然夹在其在欧拉序中第二次出现的位置的左右两边，例如 B 的 左右子树 D, E 出现在B第二次出现位置[3]的两边[2]、[4]。\n那么我们想如果我们找，两个节点的 LCA 就直接找两个节点第一次出现的位置，将其作为区间左右，在中间找深度最小的点就行了，这样找到的一定就是他们的LCA (不可能找到更浅的祖先) 。 当然其中包含了左边一个节点的子树，但为了方便我们就统一取第一次出现的位置即可。\n\n这样我们就在线性的时间内将LCA问题转化成了RMQ问题，然后通过之前O(nlgn)的预处理我们可以做到 O(1)的询问，这样LCA问题的总复杂度就是ST表预处理的 O(nlogn) 的复杂度。\n\n似乎总体没有比倍增更优，但单次询问比倍增快了很多，适合需要及时快速反馈的应用场景。\n\n- 代码实现\n\n```cpp\n// get eula array\nvoid dfs(int u, int fa, int level)\n{\n    pos[u] = cnt_2;\n    find_u[cnt_2++] = u;\n    dep[u] = level;\n    \n    for(int i = head[u]; i != -1; i = e[i].nex)\n    {\n        int v = e[i].v;\n        \n        // 欧拉序，回溯也放入\n        pos[v] = cnt_2;\n        find_u[cnt_2++] = v;\n        dep[v] = level + 1;\n        dfs(v, u, level + 1);\n    }\n}\n\nvoid ST()\n{\n    // Preset Log\n    Logn[1] = 0;\n    for(int i = 2; i <= n; ++i)\n        Logn[i] = Logn[i >> 1] + 1;\n    \n    for(int i = 1; i <= n; ++i)\n        f[i][0] = find_u[i];\n\n    for(int j = 1; j <= logn; ++j)\n        for(int i = 1; i <= n; ++i)\n            f[i][j] = dep[f[i][j - 1]] < dep[f[i + (j << 1)][j - 1]] ? f[i][j - 1] : f[i + (j << 1)][j - 1];\n\n}\n\nint lca(int u, int v)\n{\n    int l = pos[u], r = pos[v];\n    int j = Logn[r - l + 1];\n    // 直接找区间最小深度的节点\n    int ans = min(f[l][j], f[r - (1 << j) + 1][j]);\n    return pos[ans];    // 返回节点位置...\n}\n```\n\n---\n\n## 并查集\n\n再来讲讲这周学的并查集\n\n并查集顾名思义支持且仅支持两种操作\n1. 合并两个集合\n2. 查询元素所在的集合\n\n并查集是一种树上的操作，通过根节点直接代表整棵树，初始化的时候根节点父节点为自身。\n\n- 合并操作\n\n合并操作相对比较简单，由于我们通过根节点来代表这个集合，那么合并两个集合只需要将其中一个的根节点作为另一个的子节点连接上即可。但同时我们要注意整棵树的深度会影响我们的时间复杂度，因而我们要尽可能不加深或是少加深树的深度，所以我们采用将深度较小的树连接到深度较大的树上，每次这样操作，树深度每次至多 +1，这种策略称之为**按秩合并（启发式合并）**\n\n![](https://oi-wiki.org/ds/images/dsu1.png)\n\n- 代码\n\n```cpp\nvoid unionSet(int x, int y)\n{\n    int tmp_x = find(x);\n    int tmp_y = find(y);\n    if(tmp_x == tmp_y)  // 本来就在同一集合中\n        return; \n    if(sz[tmp_x] > sz[tmp_y])\n        swap(tmp_x, tmp_y); // 让 tmp_x 是深度小的集合\n    fa[tmp_x] = tmp_y; // 将 tmp_x 连接到 tmp_y 上\n}\n```\n\n- 查询操作\n\n我们来讲并查集关键的查询操作，并查集的查询操作给出一个节点，我们查询其父节点，如若其父节点不是自身就继续向上查询，直到查询到根节点（父节点为自身）返回根节点作为这个集合的代表。\n\n我们不难看出这样的查询操作单次是 $O(n)$ 的，原因是我们每次查询都要走完完整的一条链，但是其实我们并不关心该节点的父节点是谁，我们只想知道其根节点是什么。所以我们可以直接让它的父节点直接是根节点，这样虽然在第一次操作的时候，我们还是要走完一条链，但之后该节点的父节点直接就是根节点。这种操作称为**路径压缩**\n\n![](https://oi-wiki.org/ds/images/dsu2.png)\n\n```cpp\n\nint find(int x)\n{\n    if(fa[x] == x)\n        return x;\n    return fa[x] = find(fa[x]); // 路径压缩\n}\n```\n\n- **复杂度分析**\n\n我们现在来分析一下复杂度，朴素算法毫无疑问单次操作是 $O(mn)$ 的\n如果我们使用了路径压缩，在Tarjan大神的论文[1] 中给出了复杂度的证明，只使用路径压缩不使用按秩合并的最坏时间复杂度是 $O(mlogn)$ 已经满足大部分题的需求，所以一般只需要路径压缩就能过题。\n在姚期智的论文 [2] 中，证明了只路径压缩的平均复杂度为 $O(m\\alpha{(m,n)})$\n*注： $\\alpha$ 是阿克曼函数的反函数，其增长极其缓慢，也就是说其单次操作的平均运行时间可以认为是一个很小的常数。*\n\n如果我们同时使用了路径压缩和按秩合并，那么我们可以做到 $O(m\\alpha{(m,n)})$ 的最坏时间复杂度。相当于单次询问是常数级别复杂度。\n\nAckermann 函数\n$$\nA(m,n) =\\left\\{\n\\begin{array}{l}\n    n + 1, \\; m = 0 \\\\\n    A(m - 1, 1), m > 0 \\;and\\; n = 0 \\\\\n    A(m - 1, A(m, n - 1)),\\;othercases\n\\end{array}\n\\right.\n$$\n\n$A(4, 3)$ 大的惊人，其反函数增长就相对应慢的惊人，直接可看为常数\n\n---\n\n## 树上差分算法\n\n讲一下这周作业题里涉及到的树上差分算法\n树上差分问题可以用树链剖分解决，但我目前还不太会，就写一下现在会一点的树上差分。\n\n树上差分分为两种，边差分和点差分。\n\n- 边差分\n考虑一个经典问题，**给出两点x, y 将其路径上的边权加1，最后给出所有边权。**\n\n![图源:https://www.cnblogs.com/zhwer/p/12800475.html](https://s3.ax1x.com/2020/12/08/r99w60.png)\n\n我们看这张图，数组 c[k] 是差分数组只不过我们是自下而上加的，为不影响其他子树的结果，我们的统计在回溯过程中完成，因而是自下而上的，那么这个边权修改过程就可以看做是 c[x]++, c[y]++, 然后 根节点到lca(x, y)被加了两次，我们都要减去 c[lca(x, y)] -= 2\n\n既然是差分那么对于权值的更新，我们就可以如同前缀和一样计算，这不过这里的\"前缀\"是所有的子树权值，我们将所有子树权值收集起来到父节点上。\n\n- 代码实现\n\n```cpp\n// 已求出差分数组c\nvoid getAns(int u, int fa)\n{  \n    for(int i = head[u]; i != -1; i = e[i].nex)\n    {\n        int v = e[i].v;\n        if(v != fa)\n        {\n            getAns(v, u);\n            c[u] += c[v] // 收集子树权值更新c为原本数组\n            // 更新后的c就代表其和其父节点连接边的边权\n        }\n    }\n}\n```\n\n- 点差分\n点差分和边差分差不多，但这回每个点都代表的是自己了。\n![图源:https://www.cnblogs.com/zhwer/p/12800475.html](https://s3.ax1x.com/2020/12/08/r990XV.png)\n\n和边差分不同的是，这回lca不需要减2了，因为每个点代表的就是自己，在统计的时候 x, y 路径上是有 lca(x, y) 的，因而只需要减去一次重复计算即可。但这边lca在计算\"前缀和\"的时候会 +1，差分数组某一地方值的变动会影响到后面所有的值（这就是差分数组的精髓和意义所在）但lca的父亲并不应该 +1 所以我们要将 c[fa[lca(x,y)]]-- 这个过程之后，我们的差分数组就完成了。\n最后自下而上的收集一下，就能得到所有节点的权值了。\n\n- 思想总结\n\n差分的思想就是将原来本不相干的值联系到了一起，把后面点的部分信息移到了前面的点中，形成了区间的覆盖，这种效果正好能够用于解决区间修改问题，避免了暴力算法对每个点都进行操作，很巧妙的思想。\n\n---\n\n## 最后总结\n\n本周DS主要学习这些内容，AVL树很惭愧虽然上课讲了但还没有深入去看，线段树和树链剖分还不太会，树状数组也快忘记了。最近又重新听到了《蜗牛》这首歌，隔了这么多年，再听还是很感动。“历经的伤都不感觉疼”，“任风吹干流过的泪和汗，总有一天我有属于我的天。” \n每周都在不断吸收新知识，很充实也很疲倦，每天都学到12点之后。就是希望能够在未来有一片自己的天。科研也在不断做，但进度很慢，时间分配越来越不够了，最近越来越感到拔尖班的藏龙卧虎，个个都是人才，让我感到了很大的压力。但就像《蜗牛》中说的即使我很慢，拖着重重的壳，只要我每天一步一步的向上爬，我总能触碰到那片属于我的蓝天。\n\n---\n\n## Reference\n[1]Tarjan, R. E., & Van Leeuwen, J. (1984). Worst-case analysis of set union algorithms.\n[2]Yao, A. C. (1985). On the expected performance of path compression algorithms. SIAM Journal on Computing, 14(1), 129-133.","source":"_posts/DS/DataStructureNote1.md","raw":"---\ntitle: 数据结构笔记 (2020-11-30 ~ 2020-12-05)\nindex_img: /img/Pic/DS.png\ndate: 2020-12-05 10:10:02\ncategory: [DataStructure]\ntags: [LCA,UFS]\nmath: true\n---\n\n# 数据结构 - DataStructure\n\n数据结构这周依然是树上操作，课上学了AVL树，然后讲了之前用过的Hash，然后作业里面主要学会了LCA的倍增和不太熟练的欧拉序RMQ，最后学会了并查集的使用（就可以学最后的Tarjan LCA算法了) ，然后这周作业题主要是并查集，带有一道树上差分算法。\n\n---\n\n## LCA 问题\n\nLCA (Least Common Ancestors) 最近公共祖先问题，顾名思义既要找到两个节点最近的公共祖先，朴素做法是，两个节点中深的那个节点向上跳，直到两个节点深度相同，两个节点再同时向上跳（询问父节点）如果他们跳到最后的父节点是同一个那么这个节点就是他们的最近公共祖先。\n\n这种朴素的算法很好思考，但复杂度也是很高的，单次询问时间复杂度 O(n) 因为最坏要把所有节点都跳一遍。\n\n![](https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=1414039454,330983716&fm=26&gp=0.jpg)\n\n### **LCA - 倍增算法**\n\n倍增算法是LCA的经典算法，如同二分算法的本质一样，都是通过每次尽量把问题规模缩减2的幂次，从而达到 O(lgn) 的时间复杂度。\n\n我们简单讲解一下，倍增算法就是我不再像朴素算法一样一个个往上跳，我直接跳2的幂次，从大到小枚举，如果符合题意就跳，直到 2^0 跳一个节点，这样一次遍历下来，总能覆盖所有情况而满足题意跳到要跳的地方，但复杂度却大大降低减为 O(lgn)\n\n- 代码实现\n```cpp\nvoid dfs(int u, int fa)\n{\n    up[u][0] = fa;  // 预处理父亲\n    dep[u] = dep[fa] + 1;\n    for(auto& v : tree[u])\n    {\n        if(v == fa)\n            continue;\n        dfs(v, u);\n    }\n}\n\nvoid pre()\n{\n    for(int k = 1; (1 << k) <= n; ++k)\n        for(int i = 1; i <= n; ++i)\n            up[i][k] = up[up[i][k - 1]][k - 1]; \n            // 预处理所有的上跳\n            // 状态转移方程 跳 2^k 步，等于先跳2^k-1步再往上跳2^k-1步\n            // 2 ^ k = 2 ^ (k - 1) + 2 ^ (k - 1)\n}   \n\nint lca(int x, int y)\n{\n    if(dep[x] < dep[y])\n        swap(x, y); // 让深度大的为x\n    if(dep[x] != dep[y])\n    {\n        for(int k = 31; k >= 0; --k)\n        {\n            if(dep[up[x][k]] >= dep[y])\n                x = up[x][k];   // 调整为同一深度\n        }\n    }\n\n    if(x == y)\n        return x;   \n        // 如果一个是另外一个的长辈那么这时候两个直接就相等了，直接返回\n\n    for(int k = 31; k >= 0; --k)\n    {\n        if(up[x][k] != up[y][k])    // 同时上跳不过头\n        {\n            x = up[x][k];   \n            y = up[y][k];\n        }\n    }\n\n    return up[x][0];    // 最后 lca 就是里面任意一个的父亲\n}\n```\n\n---\n\n### **LCA - 欧拉序RMQ算法**\n\n这边涉及到RMQ问题，我们就先来讲一讲RMQ问题。\n\n- *RMQ 问题*\nRMQ 是英文 Range Maximum/Minimum Query 的缩写，表示区间最大（最小）值。\n\nRMQ问题一般可以使用单调栈、ST表、线段树来解决\n\n通过欧拉序将LCA问题转为RMQ问题后，我们一般使用ST表来解决RMQ问题。因为ST表在时间复杂度上表现优秀，需要 O(nlgn)的预处理，就能做到O(1)的询问。而写起来又较为简单，不像线段树一样复杂。可以处理大部分不需要在线修改的 RMQ 问题。\n\n另一方面如果我们使用单调栈和线段树在单次询问的时间复杂度仍然是 O(lgn) 级别的本没有做到比倍增算法更优，但在代码方面却比倍增算法更为复杂，因而我们选择ST表进行处理。\n\n\n### **ST表 - Sparse table**\n\n我们说 ST 表可以用来解决可重复贡献问题，因为ST表涉及到区间重叠，我们要保证区间重叠不会影响到我们要求的问题。所以ST表只能解决可重复贡献问题，例如最值和gcd。\n\nST表运用的也是倍增的思想，通过倍增区间覆盖来解决问题。\n\n```cpp\n// ST表\nint f[Max][lgn]\b, Logn[Max], a[Max];\n// f[i][k] 表示区间 i ~ i + 2^k - 1 的最值\n\nvoid pre()\n{\n    Logn[1] = 0;\n    for(int i = 2; i < Max; ++i)\n        Logn[i] = Logn[i / 2] + 1;\n}\n\n// 状态转移：\n    // 前者表示 i ~ i + 2^(k - 1) - 1 的区间最值\n    // 后者表示 i + 2^(k - 1) ~ i + 2^k - 1 的区间最值\n    // 合并即为 i ~ i + 2^k - 1的区间最值\nvoid preSet()\n{\n    for(int i = 1; i <= n; ++i)\n        f[i][0] = a[i]; // 显然 f[i][0] = a[i]\n\n    for(int k = 1; k < lgn; ++k)\n        for(int i = 1; i + (1 << (k - 1)) <= n; ++i)\n            f[i][k] = max(f[i][k - 1], f[i + (1 << (k - 1))][k - 1]);\n}\n\n// 查询操作：\n    // 如果我们要查询 区间 l ~ r 的最值, 我们根据ST表性质知道\n    // f[i][k] 表示 l ~ l + 2^k - 1 的区间最值\n    // r - 2^k + 1 ~ r 的区间最值就可以用 f[r - 1 << k + 1][k] 表示\n    // 那么我们需要这两个区间覆盖整个查询区间且不超过\n    // 则 l + 2^k - 1 >= r - 2^k + 1 且 l + 2^k - 1 <= r 且 r - 2^k + 1 >= l\n    // 则 k >= lg(r - l + 2) - 1 且 k <= floor(lg(r - l + 1));\n    // 我们直接取 k == floor(lg(r - l + 1))\n\nint find(int l, int r)\n{\n    int k = Logn[r - l + 1];\n    return max(f[i][k], f[r - (1 << k) + 1][k]); // O(1) 查询\n}\n\n```\n\n这样一个ST表就写好了，回到正题，我们是通过欧拉序把 LCA问题转换为RMQ问题，我们现在来看这是如何进行的。\n\n在看欧拉序之前我们先看一看基本的 dfs 序是怎么做的（真就递归学习呗）\n\n![dfs序](https://img-blog.csdnimg.cn/20191008210415266.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3djeHlreQ==,size_16,color_FFFFFF,t_70)\n\n正常的dfs序是深度优先不记录回溯的，如上图 dfs 序就是 \n**A->B->D->E->G->C->F->H**\n每个节点在dfs序中出现且仅出现一次\n\n而我们再来看欧拉序\n\n![欧拉序](https://img-blog.csdnimg.cn/20191008210445328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3djeHlreQ==,size_16,color_FFFFFF,t_70)\n\n它不同于dfs序将栈pop的元素也加入队列中，从而就形成了上图“逆时针”的模式\n上图欧拉序就是\n**A->B->D->B->E->G->E->B->A->C->F->H->F->C->A**\n一种intuition就是欧拉序是一种正常人走路遍历所有节点的顺序，只要叶节点大于2个的树就不可能是欧拉图或半欧拉图，那么必然要走回头路，在dfs序的基础上将回头路线画出就是欧拉序。\n\n我们来观察欧拉序可以发现，其首尾必然是根节点，然后除了叶节点仅出现一次，其余点出现2次以上(取决于是几叉树)，如果我们默认是二叉树，那么欧拉序的大小就不会超过 2n - 1 (考虑单链或就两叉到底的最坏情况)\n\n如果我们在欧拉序节点旁配上它的深度再结合图来观察\n**A(0)->B(1)->D(2)->B(1)->E(2)->G(3)->E(2)->B(1)->A(0)->C(1)->F(2)->H(3)->F(2)->C(1)->A(0)**\n我们根据欧拉序的性质不难发现一个节点的左右子树必然夹在其在欧拉序中第二次出现的位置的左右两边，例如 B 的 左右子树 D, E 出现在B第二次出现位置[3]的两边[2]、[4]。\n那么我们想如果我们找，两个节点的 LCA 就直接找两个节点第一次出现的位置，将其作为区间左右，在中间找深度最小的点就行了，这样找到的一定就是他们的LCA (不可能找到更浅的祖先) 。 当然其中包含了左边一个节点的子树，但为了方便我们就统一取第一次出现的位置即可。\n\n这样我们就在线性的时间内将LCA问题转化成了RMQ问题，然后通过之前O(nlgn)的预处理我们可以做到 O(1)的询问，这样LCA问题的总复杂度就是ST表预处理的 O(nlogn) 的复杂度。\n\n似乎总体没有比倍增更优，但单次询问比倍增快了很多，适合需要及时快速反馈的应用场景。\n\n- 代码实现\n\n```cpp\n// get eula array\nvoid dfs(int u, int fa, int level)\n{\n    pos[u] = cnt_2;\n    find_u[cnt_2++] = u;\n    dep[u] = level;\n    \n    for(int i = head[u]; i != -1; i = e[i].nex)\n    {\n        int v = e[i].v;\n        \n        // 欧拉序，回溯也放入\n        pos[v] = cnt_2;\n        find_u[cnt_2++] = v;\n        dep[v] = level + 1;\n        dfs(v, u, level + 1);\n    }\n}\n\nvoid ST()\n{\n    // Preset Log\n    Logn[1] = 0;\n    for(int i = 2; i <= n; ++i)\n        Logn[i] = Logn[i >> 1] + 1;\n    \n    for(int i = 1; i <= n; ++i)\n        f[i][0] = find_u[i];\n\n    for(int j = 1; j <= logn; ++j)\n        for(int i = 1; i <= n; ++i)\n            f[i][j] = dep[f[i][j - 1]] < dep[f[i + (j << 1)][j - 1]] ? f[i][j - 1] : f[i + (j << 1)][j - 1];\n\n}\n\nint lca(int u, int v)\n{\n    int l = pos[u], r = pos[v];\n    int j = Logn[r - l + 1];\n    // 直接找区间最小深度的节点\n    int ans = min(f[l][j], f[r - (1 << j) + 1][j]);\n    return pos[ans];    // 返回节点位置...\n}\n```\n\n---\n\n## 并查集\n\n再来讲讲这周学的并查集\n\n并查集顾名思义支持且仅支持两种操作\n1. 合并两个集合\n2. 查询元素所在的集合\n\n并查集是一种树上的操作，通过根节点直接代表整棵树，初始化的时候根节点父节点为自身。\n\n- 合并操作\n\n合并操作相对比较简单，由于我们通过根节点来代表这个集合，那么合并两个集合只需要将其中一个的根节点作为另一个的子节点连接上即可。但同时我们要注意整棵树的深度会影响我们的时间复杂度，因而我们要尽可能不加深或是少加深树的深度，所以我们采用将深度较小的树连接到深度较大的树上，每次这样操作，树深度每次至多 +1，这种策略称之为**按秩合并（启发式合并）**\n\n![](https://oi-wiki.org/ds/images/dsu1.png)\n\n- 代码\n\n```cpp\nvoid unionSet(int x, int y)\n{\n    int tmp_x = find(x);\n    int tmp_y = find(y);\n    if(tmp_x == tmp_y)  // 本来就在同一集合中\n        return; \n    if(sz[tmp_x] > sz[tmp_y])\n        swap(tmp_x, tmp_y); // 让 tmp_x 是深度小的集合\n    fa[tmp_x] = tmp_y; // 将 tmp_x 连接到 tmp_y 上\n}\n```\n\n- 查询操作\n\n我们来讲并查集关键的查询操作，并查集的查询操作给出一个节点，我们查询其父节点，如若其父节点不是自身就继续向上查询，直到查询到根节点（父节点为自身）返回根节点作为这个集合的代表。\n\n我们不难看出这样的查询操作单次是 $O(n)$ 的，原因是我们每次查询都要走完完整的一条链，但是其实我们并不关心该节点的父节点是谁，我们只想知道其根节点是什么。所以我们可以直接让它的父节点直接是根节点，这样虽然在第一次操作的时候，我们还是要走完一条链，但之后该节点的父节点直接就是根节点。这种操作称为**路径压缩**\n\n![](https://oi-wiki.org/ds/images/dsu2.png)\n\n```cpp\n\nint find(int x)\n{\n    if(fa[x] == x)\n        return x;\n    return fa[x] = find(fa[x]); // 路径压缩\n}\n```\n\n- **复杂度分析**\n\n我们现在来分析一下复杂度，朴素算法毫无疑问单次操作是 $O(mn)$ 的\n如果我们使用了路径压缩，在Tarjan大神的论文[1] 中给出了复杂度的证明，只使用路径压缩不使用按秩合并的最坏时间复杂度是 $O(mlogn)$ 已经满足大部分题的需求，所以一般只需要路径压缩就能过题。\n在姚期智的论文 [2] 中，证明了只路径压缩的平均复杂度为 $O(m\\alpha{(m,n)})$\n*注： $\\alpha$ 是阿克曼函数的反函数，其增长极其缓慢，也就是说其单次操作的平均运行时间可以认为是一个很小的常数。*\n\n如果我们同时使用了路径压缩和按秩合并，那么我们可以做到 $O(m\\alpha{(m,n)})$ 的最坏时间复杂度。相当于单次询问是常数级别复杂度。\n\nAckermann 函数\n$$\nA(m,n) =\\left\\{\n\\begin{array}{l}\n    n + 1, \\; m = 0 \\\\\n    A(m - 1, 1), m > 0 \\;and\\; n = 0 \\\\\n    A(m - 1, A(m, n - 1)),\\;othercases\n\\end{array}\n\\right.\n$$\n\n$A(4, 3)$ 大的惊人，其反函数增长就相对应慢的惊人，直接可看为常数\n\n---\n\n## 树上差分算法\n\n讲一下这周作业题里涉及到的树上差分算法\n树上差分问题可以用树链剖分解决，但我目前还不太会，就写一下现在会一点的树上差分。\n\n树上差分分为两种，边差分和点差分。\n\n- 边差分\n考虑一个经典问题，**给出两点x, y 将其路径上的边权加1，最后给出所有边权。**\n\n![图源:https://www.cnblogs.com/zhwer/p/12800475.html](https://s3.ax1x.com/2020/12/08/r99w60.png)\n\n我们看这张图，数组 c[k] 是差分数组只不过我们是自下而上加的，为不影响其他子树的结果，我们的统计在回溯过程中完成，因而是自下而上的，那么这个边权修改过程就可以看做是 c[x]++, c[y]++, 然后 根节点到lca(x, y)被加了两次，我们都要减去 c[lca(x, y)] -= 2\n\n既然是差分那么对于权值的更新，我们就可以如同前缀和一样计算，这不过这里的\"前缀\"是所有的子树权值，我们将所有子树权值收集起来到父节点上。\n\n- 代码实现\n\n```cpp\n// 已求出差分数组c\nvoid getAns(int u, int fa)\n{  \n    for(int i = head[u]; i != -1; i = e[i].nex)\n    {\n        int v = e[i].v;\n        if(v != fa)\n        {\n            getAns(v, u);\n            c[u] += c[v] // 收集子树权值更新c为原本数组\n            // 更新后的c就代表其和其父节点连接边的边权\n        }\n    }\n}\n```\n\n- 点差分\n点差分和边差分差不多，但这回每个点都代表的是自己了。\n![图源:https://www.cnblogs.com/zhwer/p/12800475.html](https://s3.ax1x.com/2020/12/08/r990XV.png)\n\n和边差分不同的是，这回lca不需要减2了，因为每个点代表的就是自己，在统计的时候 x, y 路径上是有 lca(x, y) 的，因而只需要减去一次重复计算即可。但这边lca在计算\"前缀和\"的时候会 +1，差分数组某一地方值的变动会影响到后面所有的值（这就是差分数组的精髓和意义所在）但lca的父亲并不应该 +1 所以我们要将 c[fa[lca(x,y)]]-- 这个过程之后，我们的差分数组就完成了。\n最后自下而上的收集一下，就能得到所有节点的权值了。\n\n- 思想总结\n\n差分的思想就是将原来本不相干的值联系到了一起，把后面点的部分信息移到了前面的点中，形成了区间的覆盖，这种效果正好能够用于解决区间修改问题，避免了暴力算法对每个点都进行操作，很巧妙的思想。\n\n---\n\n## 最后总结\n\n本周DS主要学习这些内容，AVL树很惭愧虽然上课讲了但还没有深入去看，线段树和树链剖分还不太会，树状数组也快忘记了。最近又重新听到了《蜗牛》这首歌，隔了这么多年，再听还是很感动。“历经的伤都不感觉疼”，“任风吹干流过的泪和汗，总有一天我有属于我的天。” \n每周都在不断吸收新知识，很充实也很疲倦，每天都学到12点之后。就是希望能够在未来有一片自己的天。科研也在不断做，但进度很慢，时间分配越来越不够了，最近越来越感到拔尖班的藏龙卧虎，个个都是人才，让我感到了很大的压力。但就像《蜗牛》中说的即使我很慢，拖着重重的壳，只要我每天一步一步的向上爬，我总能触碰到那片属于我的蓝天。\n\n---\n\n## Reference\n[1]Tarjan, R. E., & Van Leeuwen, J. (1984). Worst-case analysis of set union algorithms.\n[2]Yao, A. C. (1985). On the expected performance of path compression algorithms. SIAM Journal on Computing, 14(1), 129-133.","slug":"DS/DataStructureNote1","published":1,"updated":"2026-02-03T05:42:14.428Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvb000o7uit0oma3jpj","content":"<h1 id=\"数据结构-DataStructure\"><a href=\"#数据结构-DataStructure\" class=\"headerlink\" title=\"数据结构 - DataStructure\"></a>数据结构 - DataStructure</h1><p>数据结构这周依然是树上操作，课上学了AVL树，然后讲了之前用过的Hash，然后作业里面主要学会了LCA的倍增和不太熟练的欧拉序RMQ，最后学会了并查集的使用（就可以学最后的Tarjan LCA算法了) ，然后这周作业题主要是并查集，带有一道树上差分算法。</p>\n<hr>\n<h2 id=\"LCA-问题\"><a href=\"#LCA-问题\" class=\"headerlink\" title=\"LCA 问题\"></a>LCA 问题</h2><p>LCA (Least Common Ancestors) 最近公共祖先问题，顾名思义既要找到两个节点最近的公共祖先，朴素做法是，两个节点中深的那个节点向上跳，直到两个节点深度相同，两个节点再同时向上跳（询问父节点）如果他们跳到最后的父节点是同一个那么这个节点就是他们的最近公共祖先。</p>\n<p>这种朴素的算法很好思考，但复杂度也是很高的，单次询问时间复杂度 O(n) 因为最坏要把所有节点都跳一遍。</p>\n<p><img src=\"https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=1414039454,330983716&amp;fm=26&amp;gp=0.jpg\" alt></p>\n<h3 id=\"LCA-倍增算法\"><a href=\"#LCA-倍增算法\" class=\"headerlink\" title=\"LCA - 倍增算法\"></a><strong>LCA - 倍增算法</strong></h3><p>倍增算法是LCA的经典算法，如同二分算法的本质一样，都是通过每次尽量把问题规模缩减2的幂次，从而达到 O(lgn) 的时间复杂度。</p>\n<p>我们简单讲解一下，倍增算法就是我不再像朴素算法一样一个个往上跳，我直接跳2的幂次，从大到小枚举，如果符合题意就跳，直到 2^0 跳一个节点，这样一次遍历下来，总能覆盖所有情况而满足题意跳到要跳的地方，但复杂度却大大降低减为 O(lgn)</p>\n<ul>\n<li>代码实现<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">dfs</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    up[u][<span class=\"hljs-number\">0</span>] = fa;  <span class=\"hljs-comment\">// 预处理父亲</span>\n    dep[u] = dep[fa] + <span class=\"hljs-number\">1</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span>&amp; v : tree[u])\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(v == fa)\n            <span class=\"hljs-keyword\">continue</span>;\n        dfs(v, u);\n    &#125;\n&#125;\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">pre</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> k = <span class=\"hljs-number\">1</span>; (<span class=\"hljs-number\">1</span> &lt;&lt; k) &lt;= n; ++k)\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">1</span>; i &lt;= n; ++i)\n            up[i][k] = up[up[i][k - <span class=\"hljs-number\">1</span>]][k - <span class=\"hljs-number\">1</span>]; \n            <span class=\"hljs-comment\">// 预处理所有的上跳</span>\n            <span class=\"hljs-comment\">// 状态转移方程 跳 2^k 步，等于先跳2^k-1步再往上跳2^k-1步</span>\n            <span class=\"hljs-comment\">// 2 ^ k = 2 ^ (k - 1) + 2 ^ (k - 1)</span>\n&#125;   \n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">lca</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> y)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">if</span>(dep[x] &lt; dep[y])\n        swap(x, y); <span class=\"hljs-comment\">// 让深度大的为x</span>\n    <span class=\"hljs-keyword\">if</span>(dep[x] != dep[y])\n    &#123;\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> k = <span class=\"hljs-number\">31</span>; k &gt;= <span class=\"hljs-number\">0</span>; --k)\n        &#123;\n            <span class=\"hljs-keyword\">if</span>(dep[up[x][k]] &gt;= dep[y])\n                x = up[x][k];   <span class=\"hljs-comment\">// 调整为同一深度</span>\n        &#125;\n    &#125;\n\n    <span class=\"hljs-keyword\">if</span>(x == y)\n        <span class=\"hljs-keyword\">return</span> x;   \n        <span class=\"hljs-comment\">// 如果一个是另外一个的长辈那么这时候两个直接就相等了，直接返回</span>\n\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> k = <span class=\"hljs-number\">31</span>; k &gt;= <span class=\"hljs-number\">0</span>; --k)\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(up[x][k] != up[y][k])    <span class=\"hljs-comment\">// 同时上跳不过头</span>\n        &#123;\n            x = up[x][k];   \n            y = up[y][k];\n        &#125;\n    &#125;\n\n    <span class=\"hljs-keyword\">return</span> up[x][<span class=\"hljs-number\">0</span>];    <span class=\"hljs-comment\">// 最后 lca 就是里面任意一个的父亲</span>\n&#125;</code></pre>\n</li>\n</ul>\n<hr>\n<h3 id=\"LCA-欧拉序RMQ算法\"><a href=\"#LCA-欧拉序RMQ算法\" class=\"headerlink\" title=\"LCA - 欧拉序RMQ算法\"></a><strong>LCA - 欧拉序RMQ算法</strong></h3><p>这边涉及到RMQ问题，我们就先来讲一讲RMQ问题。</p>\n<ul>\n<li><em>RMQ 问题</em><br>RMQ 是英文 Range Maximum/Minimum Query 的缩写，表示区间最大（最小）值。</li>\n</ul>\n<p>RMQ问题一般可以使用单调栈、ST表、线段树来解决</p>\n<p>通过欧拉序将LCA问题转为RMQ问题后，我们一般使用ST表来解决RMQ问题。因为ST表在时间复杂度上表现优秀，需要 O(nlgn)的预处理，就能做到O(1)的询问。而写起来又较为简单，不像线段树一样复杂。可以处理大部分不需要在线修改的 RMQ 问题。</p>\n<p>另一方面如果我们使用单调栈和线段树在单次询问的时间复杂度仍然是 O(lgn) 级别的本没有做到比倍增算法更优，但在代码方面却比倍增算法更为复杂，因而我们选择ST表进行处理。</p>\n<h3 id=\"ST表-Sparse-table\"><a href=\"#ST表-Sparse-table\" class=\"headerlink\" title=\"ST表 - Sparse table\"></a><strong>ST表 - Sparse table</strong></h3><p>我们说 ST 表可以用来解决可重复贡献问题，因为ST表涉及到区间重叠，我们要保证区间重叠不会影响到我们要求的问题。所以ST表只能解决可重复贡献问题，例如最值和gcd。</p>\n<p>ST表运用的也是倍增的思想，通过倍增区间覆盖来解决问题。</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// ST表</span>\n<span class=\"hljs-keyword\">int</span> f[Max][lgn]\b, Logn[Max], a[Max];\n<span class=\"hljs-comment\">// f[i][k] 表示区间 i ~ i + 2^k - 1 的最值</span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">pre</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    Logn[<span class=\"hljs-number\">1</span>] = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">2</span>; i &lt; Max; ++i)\n        Logn[i] = Logn[i / <span class=\"hljs-number\">2</span>] + <span class=\"hljs-number\">1</span>;\n&#125;\n\n<span class=\"hljs-comment\">// 状态转移：</span>\n    <span class=\"hljs-comment\">// 前者表示 i ~ i + 2^(k - 1) - 1 的区间最值</span>\n    <span class=\"hljs-comment\">// 后者表示 i + 2^(k - 1) ~ i + 2^k - 1 的区间最值</span>\n    <span class=\"hljs-comment\">// 合并即为 i ~ i + 2^k - 1的区间最值</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">preSet</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">1</span>; i &lt;= n; ++i)\n        f[i][<span class=\"hljs-number\">0</span>] = a[i]; <span class=\"hljs-comment\">// 显然 f[i][0] = a[i]</span>\n\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> k = <span class=\"hljs-number\">1</span>; k &lt; lgn; ++k)\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">1</span>; i + (<span class=\"hljs-number\">1</span> &lt;&lt; (k - <span class=\"hljs-number\">1</span>)) &lt;= n; ++i)\n            f[i][k] = max(f[i][k - <span class=\"hljs-number\">1</span>], f[i + (<span class=\"hljs-number\">1</span> &lt;&lt; (k - <span class=\"hljs-number\">1</span>))][k - <span class=\"hljs-number\">1</span>]);\n&#125;\n\n<span class=\"hljs-comment\">// 查询操作：</span>\n    <span class=\"hljs-comment\">// 如果我们要查询 区间 l ~ r 的最值, 我们根据ST表性质知道</span>\n    <span class=\"hljs-comment\">// f[i][k] 表示 l ~ l + 2^k - 1 的区间最值</span>\n    <span class=\"hljs-comment\">// r - 2^k + 1 ~ r 的区间最值就可以用 f[r - 1 &lt;&lt; k + 1][k] 表示</span>\n    <span class=\"hljs-comment\">// 那么我们需要这两个区间覆盖整个查询区间且不超过</span>\n    <span class=\"hljs-comment\">// 则 l + 2^k - 1 &gt;= r - 2^k + 1 且 l + 2^k - 1 &lt;= r 且 r - 2^k + 1 &gt;= l</span>\n    <span class=\"hljs-comment\">// 则 k &gt;= lg(r - l + 2) - 1 且 k &lt;= floor(lg(r - l + 1));</span>\n    <span class=\"hljs-comment\">// 我们直接取 k == floor(lg(r - l + 1))</span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">find</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> l, <span class=\"hljs-keyword\">int</span> r)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> k = Logn[r - l + <span class=\"hljs-number\">1</span>];\n    <span class=\"hljs-keyword\">return</span> max(f[i][k], f[r - (<span class=\"hljs-number\">1</span> &lt;&lt; k) + <span class=\"hljs-number\">1</span>][k]); <span class=\"hljs-comment\">// O(1) 查询</span>\n&#125;\n</code></pre>\n<p>这样一个ST表就写好了，回到正题，我们是通过欧拉序把 LCA问题转换为RMQ问题，我们现在来看这是如何进行的。</p>\n<p>在看欧拉序之前我们先看一看基本的 dfs 序是怎么做的（真就递归学习呗）</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20191008210415266.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3djeHlreQ==,size_16,color_FFFFFF,t_70\" alt=\"dfs序\"></p>\n<p>正常的dfs序是深度优先不记录回溯的，如上图 dfs 序就是<br><strong>A-&gt;B-&gt;D-&gt;E-&gt;G-&gt;C-&gt;F-&gt;H</strong><br>每个节点在dfs序中出现且仅出现一次</p>\n<p>而我们再来看欧拉序</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20191008210445328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3djeHlreQ==,size_16,color_FFFFFF,t_70\" alt=\"欧拉序\"></p>\n<p>它不同于dfs序将栈pop的元素也加入队列中，从而就形成了上图“逆时针”的模式<br>上图欧拉序就是<br><strong>A-&gt;B-&gt;D-&gt;B-&gt;E-&gt;G-&gt;E-&gt;B-&gt;A-&gt;C-&gt;F-&gt;H-&gt;F-&gt;C-&gt;A</strong><br>一种intuition就是欧拉序是一种正常人走路遍历所有节点的顺序，只要叶节点大于2个的树就不可能是欧拉图或半欧拉图，那么必然要走回头路，在dfs序的基础上将回头路线画出就是欧拉序。</p>\n<p>我们来观察欧拉序可以发现，其首尾必然是根节点，然后除了叶节点仅出现一次，其余点出现2次以上(取决于是几叉树)，如果我们默认是二叉树，那么欧拉序的大小就不会超过 2n - 1 (考虑单链或就两叉到底的最坏情况)</p>\n<p>如果我们在欧拉序节点旁配上它的深度再结合图来观察<br><strong>A(0)-&gt;B(1)-&gt;D(2)-&gt;B(1)-&gt;E(2)-&gt;G(3)-&gt;E(2)-&gt;B(1)-&gt;A(0)-&gt;C(1)-&gt;F(2)-&gt;H(3)-&gt;F(2)-&gt;C(1)-&gt;A(0)</strong><br>我们根据欧拉序的性质不难发现一个节点的左右子树必然夹在其在欧拉序中第二次出现的位置的左右两边，例如 B 的 左右子树 D, E 出现在B第二次出现位置[3]的两边[2]、[4]。<br>那么我们想如果我们找，两个节点的 LCA 就直接找两个节点第一次出现的位置，将其作为区间左右，在中间找深度最小的点就行了，这样找到的一定就是他们的LCA (不可能找到更浅的祖先) 。 当然其中包含了左边一个节点的子树，但为了方便我们就统一取第一次出现的位置即可。</p>\n<p>这样我们就在线性的时间内将LCA问题转化成了RMQ问题，然后通过之前O(nlgn)的预处理我们可以做到 O(1)的询问，这样LCA问题的总复杂度就是ST表预处理的 O(nlogn) 的复杂度。</p>\n<p>似乎总体没有比倍增更优，但单次询问比倍增快了很多，适合需要及时快速反馈的应用场景。</p>\n<ul>\n<li>代码实现</li>\n</ul>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// get eula array</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">dfs</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa, <span class=\"hljs-keyword\">int</span> level)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    pos[u] = cnt_2;\n    find_u[cnt_2++] = u;\n    dep[u] = level;\n    \n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = head[u]; i != <span class=\"hljs-number\">-1</span>; i = e[i].nex)\n    &#123;\n        <span class=\"hljs-keyword\">int</span> v = e[i].v;\n        \n        <span class=\"hljs-comment\">// 欧拉序，回溯也放入</span>\n        pos[v] = cnt_2;\n        find_u[cnt_2++] = v;\n        dep[v] = level + <span class=\"hljs-number\">1</span>;\n        dfs(v, u, level + <span class=\"hljs-number\">1</span>);\n    &#125;\n&#125;\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">ST</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-comment\">// Preset Log</span>\n    Logn[<span class=\"hljs-number\">1</span>] = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">2</span>; i &lt;= n; ++i)\n        Logn[i] = Logn[i &gt;&gt; <span class=\"hljs-number\">1</span>] + <span class=\"hljs-number\">1</span>;\n    \n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">1</span>; i &lt;= n; ++i)\n        f[i][<span class=\"hljs-number\">0</span>] = find_u[i];\n\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> j = <span class=\"hljs-number\">1</span>; j &lt;= logn; ++j)\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">1</span>; i &lt;= n; ++i)\n            f[i][j] = dep[f[i][j - <span class=\"hljs-number\">1</span>]] &lt; dep[f[i + (j &lt;&lt; <span class=\"hljs-number\">1</span>)][j - <span class=\"hljs-number\">1</span>]] ? f[i][j - <span class=\"hljs-number\">1</span>] : f[i + (j &lt;&lt; <span class=\"hljs-number\">1</span>)][j - <span class=\"hljs-number\">1</span>];\n\n&#125;\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">lca</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> v)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> l = pos[u], r = pos[v];\n    <span class=\"hljs-keyword\">int</span> j = Logn[r - l + <span class=\"hljs-number\">1</span>];\n    <span class=\"hljs-comment\">// 直接找区间最小深度的节点</span>\n    <span class=\"hljs-keyword\">int</span> ans = min(f[l][j], f[r - (<span class=\"hljs-number\">1</span> &lt;&lt; j) + <span class=\"hljs-number\">1</span>][j]);\n    <span class=\"hljs-keyword\">return</span> pos[ans];    <span class=\"hljs-comment\">// 返回节点位置...</span>\n&#125;</code></pre>\n<hr>\n<h2 id=\"并查集\"><a href=\"#并查集\" class=\"headerlink\" title=\"并查集\"></a>并查集</h2><p>再来讲讲这周学的并查集</p>\n<p>并查集顾名思义支持且仅支持两种操作</p>\n<ol>\n<li>合并两个集合</li>\n<li>查询元素所在的集合</li>\n</ol>\n<p>并查集是一种树上的操作，通过根节点直接代表整棵树，初始化的时候根节点父节点为自身。</p>\n<ul>\n<li>合并操作</li>\n</ul>\n<p>合并操作相对比较简单，由于我们通过根节点来代表这个集合，那么合并两个集合只需要将其中一个的根节点作为另一个的子节点连接上即可。但同时我们要注意整棵树的深度会影响我们的时间复杂度，因而我们要尽可能不加深或是少加深树的深度，所以我们采用将深度较小的树连接到深度较大的树上，每次这样操作，树深度每次至多 +1，这种策略称之为<strong>按秩合并（启发式合并）</strong></p>\n<p><img src=\"https://oi-wiki.org/ds/images/dsu1.png\" alt></p>\n<ul>\n<li>代码</li>\n</ul>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">unionSet</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> y)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> tmp_x = find(x);\n    <span class=\"hljs-keyword\">int</span> tmp_y = find(y);\n    <span class=\"hljs-keyword\">if</span>(tmp_x == tmp_y)  <span class=\"hljs-comment\">// 本来就在同一集合中</span>\n        <span class=\"hljs-keyword\">return</span>; \n    <span class=\"hljs-keyword\">if</span>(sz[tmp_x] &gt; sz[tmp_y])\n        swap(tmp_x, tmp_y); <span class=\"hljs-comment\">// 让 tmp_x 是深度小的集合</span>\n    fa[tmp_x] = tmp_y; <span class=\"hljs-comment\">// 将 tmp_x 连接到 tmp_y 上</span>\n&#125;</code></pre>\n<ul>\n<li>查询操作</li>\n</ul>\n<p>我们来讲并查集关键的查询操作，并查集的查询操作给出一个节点，我们查询其父节点，如若其父节点不是自身就继续向上查询，直到查询到根节点（父节点为自身）返回根节点作为这个集合的代表。</p>\n<p>我们不难看出这样的查询操作单次是 $O(n)$ 的，原因是我们每次查询都要走完完整的一条链，但是其实我们并不关心该节点的父节点是谁，我们只想知道其根节点是什么。所以我们可以直接让它的父节点直接是根节点，这样虽然在第一次操作的时候，我们还是要走完一条链，但之后该节点的父节点直接就是根节点。这种操作称为<strong>路径压缩</strong></p>\n<p><img src=\"https://oi-wiki.org/ds/images/dsu2.png\" alt></p>\n<pre><code class=\"hljs cpp\">\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">find</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">if</span>(fa[x] == x)\n        <span class=\"hljs-keyword\">return</span> x;\n    <span class=\"hljs-keyword\">return</span> fa[x] = find(fa[x]); <span class=\"hljs-comment\">// 路径压缩</span>\n&#125;</code></pre>\n<ul>\n<li><strong>复杂度分析</strong></li>\n</ul>\n<p>我们现在来分析一下复杂度，朴素算法毫无疑问单次操作是 $O(mn)$ 的<br>如果我们使用了路径压缩，在Tarjan大神的论文[1] 中给出了复杂度的证明，只使用路径压缩不使用按秩合并的最坏时间复杂度是 $O(mlogn)$ 已经满足大部分题的需求，所以一般只需要路径压缩就能过题。<br>在姚期智的论文 [2] 中，证明了只路径压缩的平均复杂度为 $O(m\\alpha{(m,n)})$<br><em>注： $\\alpha$ 是阿克曼函数的反函数，其增长极其缓慢，也就是说其单次操作的平均运行时间可以认为是一个很小的常数。</em></p>\n<p>如果我们同时使用了路径压缩和按秩合并，那么我们可以做到 $O(m\\alpha{(m,n)})$ 的最坏时间复杂度。相当于单次询问是常数级别复杂度。</p>\n<p>Ackermann 函数</p>\n<script type=\"math/tex; mode=display\">\nA(m,n) =\\left\\{\n\\begin{array}{l}\n    n + 1, \\; m = 0 \\\\\n    A(m - 1, 1), m > 0 \\;and\\; n = 0 \\\\\n    A(m - 1, A(m, n - 1)),\\;othercases\n\\end{array}\n\\right.</script><p>$A(4, 3)$ 大的惊人，其反函数增长就相对应慢的惊人，直接可看为常数</p>\n<hr>\n<h2 id=\"树上差分算法\"><a href=\"#树上差分算法\" class=\"headerlink\" title=\"树上差分算法\"></a>树上差分算法</h2><p>讲一下这周作业题里涉及到的树上差分算法<br>树上差分问题可以用树链剖分解决，但我目前还不太会，就写一下现在会一点的树上差分。</p>\n<p>树上差分分为两种，边差分和点差分。</p>\n<ul>\n<li>边差分<br>考虑一个经典问题，<strong>给出两点x, y 将其路径上的边权加1，最后给出所有边权。</strong></li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r99w60.png\" alt=\"图源:https://www.cnblogs.com/zhwer/p/12800475.html\"></p>\n<p>我们看这张图，数组 c[k] 是差分数组只不过我们是自下而上加的，为不影响其他子树的结果，我们的统计在回溯过程中完成，因而是自下而上的，那么这个边权修改过程就可以看做是 c[x]++, c[y]++, 然后 根节点到lca(x, y)被加了两次，我们都要减去 c[lca(x, y)] -= 2</p>\n<p>既然是差分那么对于权值的更新，我们就可以如同前缀和一样计算，这不过这里的”前缀”是所有的子树权值，我们将所有子树权值收集起来到父节点上。</p>\n<ul>\n<li>代码实现</li>\n</ul>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// 已求出差分数组c</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">getAns</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa)</span></span>\n<span class=\"hljs-function\"></span>&#123;  \n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = head[u]; i != <span class=\"hljs-number\">-1</span>; i = e[i].nex)\n    &#123;\n        <span class=\"hljs-keyword\">int</span> v = e[i].v;\n        <span class=\"hljs-keyword\">if</span>(v != fa)\n        &#123;\n            getAns(v, u);\n            c[u] += c[v] <span class=\"hljs-comment\">// 收集子树权值更新c为原本数组</span>\n            <span class=\"hljs-comment\">// 更新后的c就代表其和其父节点连接边的边权</span>\n        &#125;\n    &#125;\n&#125;</code></pre>\n<ul>\n<li>点差分<br>点差分和边差分差不多，但这回每个点都代表的是自己了。<br><img src=\"https://s3.ax1x.com/2020/12/08/r990XV.png\" alt=\"图源:https://www.cnblogs.com/zhwer/p/12800475.html\"></li>\n</ul>\n<p>和边差分不同的是，这回lca不需要减2了，因为每个点代表的就是自己，在统计的时候 x, y 路径上是有 lca(x, y) 的，因而只需要减去一次重复计算即可。但这边lca在计算”前缀和”的时候会 +1，差分数组某一地方值的变动会影响到后面所有的值（这就是差分数组的精髓和意义所在）但lca的父亲并不应该 +1 所以我们要将 c[fa[lca(x,y)]]— 这个过程之后，我们的差分数组就完成了。<br>最后自下而上的收集一下，就能得到所有节点的权值了。</p>\n<ul>\n<li>思想总结</li>\n</ul>\n<p>差分的思想就是将原来本不相干的值联系到了一起，把后面点的部分信息移到了前面的点中，形成了区间的覆盖，这种效果正好能够用于解决区间修改问题，避免了暴力算法对每个点都进行操作，很巧妙的思想。</p>\n<hr>\n<h2 id=\"最后总结\"><a href=\"#最后总结\" class=\"headerlink\" title=\"最后总结\"></a>最后总结</h2><p>本周DS主要学习这些内容，AVL树很惭愧虽然上课讲了但还没有深入去看，线段树和树链剖分还不太会，树状数组也快忘记了。最近又重新听到了《蜗牛》这首歌，隔了这么多年，再听还是很感动。“历经的伤都不感觉疼”，“任风吹干流过的泪和汗，总有一天我有属于我的天。”<br>每周都在不断吸收新知识，很充实也很疲倦，每天都学到12点之后。就是希望能够在未来有一片自己的天。科研也在不断做，但进度很慢，时间分配越来越不够了，最近越来越感到拔尖班的藏龙卧虎，个个都是人才，让我感到了很大的压力。但就像《蜗牛》中说的即使我很慢，拖着重重的壳，只要我每天一步一步的向上爬，我总能触碰到那片属于我的蓝天。</p>\n<hr>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>[1]Tarjan, R. E., &amp; Van Leeuwen, J. (1984). Worst-case analysis of set union algorithms.<br>[2]Yao, A. C. (1985). On the expected performance of path compression algorithms. SIAM Journal on Computing, 14(1), 129-133.</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"数据结构-DataStructure\"><a href=\"#数据结构-DataStructure\" class=\"headerlink\" title=\"数据结构 - DataStructure\"></a>数据结构 - DataStructure</h1><p>数据结构这周依然是树上操作，课上学了AVL树，然后讲了之前用过的Hash，然后作业里面主要学会了LCA的倍增和不太熟练的欧拉序RMQ，最后学会了并查集的使用（就可以学最后的Tarjan LCA算法了) ，然后这周作业题主要是并查集，带有一道树上差分算法。</p>\n<hr>\n<h2 id=\"LCA-问题\"><a href=\"#LCA-问题\" class=\"headerlink\" title=\"LCA 问题\"></a>LCA 问题</h2><p>LCA (Least Common Ancestors) 最近公共祖先问题，顾名思义既要找到两个节点最近的公共祖先，朴素做法是，两个节点中深的那个节点向上跳，直到两个节点深度相同，两个节点再同时向上跳（询问父节点）如果他们跳到最后的父节点是同一个那么这个节点就是他们的最近公共祖先。</p>\n<p>这种朴素的算法很好思考，但复杂度也是很高的，单次询问时间复杂度 O(n) 因为最坏要把所有节点都跳一遍。</p>\n<p><img src=\"https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=1414039454,330983716&amp;fm=26&amp;gp=0.jpg\" alt></p>\n<h3 id=\"LCA-倍增算法\"><a href=\"#LCA-倍增算法\" class=\"headerlink\" title=\"LCA - 倍增算法\"></a><strong>LCA - 倍增算法</strong></h3><p>倍增算法是LCA的经典算法，如同二分算法的本质一样，都是通过每次尽量把问题规模缩减2的幂次，从而达到 O(lgn) 的时间复杂度。</p>\n<p>我们简单讲解一下，倍增算法就是我不再像朴素算法一样一个个往上跳，我直接跳2的幂次，从大到小枚举，如果符合题意就跳，直到 2^0 跳一个节点，这样一次遍历下来，总能覆盖所有情况而满足题意跳到要跳的地方，但复杂度却大大降低减为 O(lgn)</p>\n<ul>\n<li>代码实现<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">dfs</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    up[u][<span class=\"hljs-number\">0</span>] = fa;  <span class=\"hljs-comment\">// 预处理父亲</span>\n    dep[u] = dep[fa] + <span class=\"hljs-number\">1</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span>&amp; v : tree[u])\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(v == fa)\n            <span class=\"hljs-keyword\">continue</span>;\n        dfs(v, u);\n    &#125;\n&#125;\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">pre</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> k = <span class=\"hljs-number\">1</span>; (<span class=\"hljs-number\">1</span> &lt;&lt; k) &lt;= n; ++k)\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">1</span>; i &lt;= n; ++i)\n            up[i][k] = up[up[i][k - <span class=\"hljs-number\">1</span>]][k - <span class=\"hljs-number\">1</span>]; \n            <span class=\"hljs-comment\">// 预处理所有的上跳</span>\n            <span class=\"hljs-comment\">// 状态转移方程 跳 2^k 步，等于先跳2^k-1步再往上跳2^k-1步</span>\n            <span class=\"hljs-comment\">// 2 ^ k = 2 ^ (k - 1) + 2 ^ (k - 1)</span>\n&#125;   \n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">lca</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> y)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">if</span>(dep[x] &lt; dep[y])\n        swap(x, y); <span class=\"hljs-comment\">// 让深度大的为x</span>\n    <span class=\"hljs-keyword\">if</span>(dep[x] != dep[y])\n    &#123;\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> k = <span class=\"hljs-number\">31</span>; k &gt;= <span class=\"hljs-number\">0</span>; --k)\n        &#123;\n            <span class=\"hljs-keyword\">if</span>(dep[up[x][k]] &gt;= dep[y])\n                x = up[x][k];   <span class=\"hljs-comment\">// 调整为同一深度</span>\n        &#125;\n    &#125;\n\n    <span class=\"hljs-keyword\">if</span>(x == y)\n        <span class=\"hljs-keyword\">return</span> x;   \n        <span class=\"hljs-comment\">// 如果一个是另外一个的长辈那么这时候两个直接就相等了，直接返回</span>\n\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> k = <span class=\"hljs-number\">31</span>; k &gt;= <span class=\"hljs-number\">0</span>; --k)\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(up[x][k] != up[y][k])    <span class=\"hljs-comment\">// 同时上跳不过头</span>\n        &#123;\n            x = up[x][k];   \n            y = up[y][k];\n        &#125;\n    &#125;\n\n    <span class=\"hljs-keyword\">return</span> up[x][<span class=\"hljs-number\">0</span>];    <span class=\"hljs-comment\">// 最后 lca 就是里面任意一个的父亲</span>\n&#125;</code></pre>\n</li>\n</ul>\n<hr>\n<h3 id=\"LCA-欧拉序RMQ算法\"><a href=\"#LCA-欧拉序RMQ算法\" class=\"headerlink\" title=\"LCA - 欧拉序RMQ算法\"></a><strong>LCA - 欧拉序RMQ算法</strong></h3><p>这边涉及到RMQ问题，我们就先来讲一讲RMQ问题。</p>\n<ul>\n<li><em>RMQ 问题</em><br>RMQ 是英文 Range Maximum/Minimum Query 的缩写，表示区间最大（最小）值。</li>\n</ul>\n<p>RMQ问题一般可以使用单调栈、ST表、线段树来解决</p>\n<p>通过欧拉序将LCA问题转为RMQ问题后，我们一般使用ST表来解决RMQ问题。因为ST表在时间复杂度上表现优秀，需要 O(nlgn)的预处理，就能做到O(1)的询问。而写起来又较为简单，不像线段树一样复杂。可以处理大部分不需要在线修改的 RMQ 问题。</p>\n<p>另一方面如果我们使用单调栈和线段树在单次询问的时间复杂度仍然是 O(lgn) 级别的本没有做到比倍增算法更优，但在代码方面却比倍增算法更为复杂，因而我们选择ST表进行处理。</p>\n<h3 id=\"ST表-Sparse-table\"><a href=\"#ST表-Sparse-table\" class=\"headerlink\" title=\"ST表 - Sparse table\"></a><strong>ST表 - Sparse table</strong></h3><p>我们说 ST 表可以用来解决可重复贡献问题，因为ST表涉及到区间重叠，我们要保证区间重叠不会影响到我们要求的问题。所以ST表只能解决可重复贡献问题，例如最值和gcd。</p>\n<p>ST表运用的也是倍增的思想，通过倍增区间覆盖来解决问题。</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// ST表</span>\n<span class=\"hljs-keyword\">int</span> f[Max][lgn]\b, Logn[Max], a[Max];\n<span class=\"hljs-comment\">// f[i][k] 表示区间 i ~ i + 2^k - 1 的最值</span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">pre</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    Logn[<span class=\"hljs-number\">1</span>] = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">2</span>; i &lt; Max; ++i)\n        Logn[i] = Logn[i / <span class=\"hljs-number\">2</span>] + <span class=\"hljs-number\">1</span>;\n&#125;\n\n<span class=\"hljs-comment\">// 状态转移：</span>\n    <span class=\"hljs-comment\">// 前者表示 i ~ i + 2^(k - 1) - 1 的区间最值</span>\n    <span class=\"hljs-comment\">// 后者表示 i + 2^(k - 1) ~ i + 2^k - 1 的区间最值</span>\n    <span class=\"hljs-comment\">// 合并即为 i ~ i + 2^k - 1的区间最值</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">preSet</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">1</span>; i &lt;= n; ++i)\n        f[i][<span class=\"hljs-number\">0</span>] = a[i]; <span class=\"hljs-comment\">// 显然 f[i][0] = a[i]</span>\n\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> k = <span class=\"hljs-number\">1</span>; k &lt; lgn; ++k)\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">1</span>; i + (<span class=\"hljs-number\">1</span> &lt;&lt; (k - <span class=\"hljs-number\">1</span>)) &lt;= n; ++i)\n            f[i][k] = max(f[i][k - <span class=\"hljs-number\">1</span>], f[i + (<span class=\"hljs-number\">1</span> &lt;&lt; (k - <span class=\"hljs-number\">1</span>))][k - <span class=\"hljs-number\">1</span>]);\n&#125;\n\n<span class=\"hljs-comment\">// 查询操作：</span>\n    <span class=\"hljs-comment\">// 如果我们要查询 区间 l ~ r 的最值, 我们根据ST表性质知道</span>\n    <span class=\"hljs-comment\">// f[i][k] 表示 l ~ l + 2^k - 1 的区间最值</span>\n    <span class=\"hljs-comment\">// r - 2^k + 1 ~ r 的区间最值就可以用 f[r - 1 &lt;&lt; k + 1][k] 表示</span>\n    <span class=\"hljs-comment\">// 那么我们需要这两个区间覆盖整个查询区间且不超过</span>\n    <span class=\"hljs-comment\">// 则 l + 2^k - 1 &gt;= r - 2^k + 1 且 l + 2^k - 1 &lt;= r 且 r - 2^k + 1 &gt;= l</span>\n    <span class=\"hljs-comment\">// 则 k &gt;= lg(r - l + 2) - 1 且 k &lt;= floor(lg(r - l + 1));</span>\n    <span class=\"hljs-comment\">// 我们直接取 k == floor(lg(r - l + 1))</span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">find</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> l, <span class=\"hljs-keyword\">int</span> r)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> k = Logn[r - l + <span class=\"hljs-number\">1</span>];\n    <span class=\"hljs-keyword\">return</span> max(f[i][k], f[r - (<span class=\"hljs-number\">1</span> &lt;&lt; k) + <span class=\"hljs-number\">1</span>][k]); <span class=\"hljs-comment\">// O(1) 查询</span>\n&#125;\n</code></pre>\n<p>这样一个ST表就写好了，回到正题，我们是通过欧拉序把 LCA问题转换为RMQ问题，我们现在来看这是如何进行的。</p>\n<p>在看欧拉序之前我们先看一看基本的 dfs 序是怎么做的（真就递归学习呗）</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20191008210415266.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3djeHlreQ==,size_16,color_FFFFFF,t_70\" alt=\"dfs序\"></p>\n<p>正常的dfs序是深度优先不记录回溯的，如上图 dfs 序就是<br><strong>A-&gt;B-&gt;D-&gt;E-&gt;G-&gt;C-&gt;F-&gt;H</strong><br>每个节点在dfs序中出现且仅出现一次</p>\n<p>而我们再来看欧拉序</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20191008210445328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3djeHlreQ==,size_16,color_FFFFFF,t_70\" alt=\"欧拉序\"></p>\n<p>它不同于dfs序将栈pop的元素也加入队列中，从而就形成了上图“逆时针”的模式<br>上图欧拉序就是<br><strong>A-&gt;B-&gt;D-&gt;B-&gt;E-&gt;G-&gt;E-&gt;B-&gt;A-&gt;C-&gt;F-&gt;H-&gt;F-&gt;C-&gt;A</strong><br>一种intuition就是欧拉序是一种正常人走路遍历所有节点的顺序，只要叶节点大于2个的树就不可能是欧拉图或半欧拉图，那么必然要走回头路，在dfs序的基础上将回头路线画出就是欧拉序。</p>\n<p>我们来观察欧拉序可以发现，其首尾必然是根节点，然后除了叶节点仅出现一次，其余点出现2次以上(取决于是几叉树)，如果我们默认是二叉树，那么欧拉序的大小就不会超过 2n - 1 (考虑单链或就两叉到底的最坏情况)</p>\n<p>如果我们在欧拉序节点旁配上它的深度再结合图来观察<br><strong>A(0)-&gt;B(1)-&gt;D(2)-&gt;B(1)-&gt;E(2)-&gt;G(3)-&gt;E(2)-&gt;B(1)-&gt;A(0)-&gt;C(1)-&gt;F(2)-&gt;H(3)-&gt;F(2)-&gt;C(1)-&gt;A(0)</strong><br>我们根据欧拉序的性质不难发现一个节点的左右子树必然夹在其在欧拉序中第二次出现的位置的左右两边，例如 B 的 左右子树 D, E 出现在B第二次出现位置[3]的两边[2]、[4]。<br>那么我们想如果我们找，两个节点的 LCA 就直接找两个节点第一次出现的位置，将其作为区间左右，在中间找深度最小的点就行了，这样找到的一定就是他们的LCA (不可能找到更浅的祖先) 。 当然其中包含了左边一个节点的子树，但为了方便我们就统一取第一次出现的位置即可。</p>\n<p>这样我们就在线性的时间内将LCA问题转化成了RMQ问题，然后通过之前O(nlgn)的预处理我们可以做到 O(1)的询问，这样LCA问题的总复杂度就是ST表预处理的 O(nlogn) 的复杂度。</p>\n<p>似乎总体没有比倍增更优，但单次询问比倍增快了很多，适合需要及时快速反馈的应用场景。</p>\n<ul>\n<li>代码实现</li>\n</ul>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// get eula array</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">dfs</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa, <span class=\"hljs-keyword\">int</span> level)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    pos[u] = cnt_2;\n    find_u[cnt_2++] = u;\n    dep[u] = level;\n    \n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = head[u]; i != <span class=\"hljs-number\">-1</span>; i = e[i].nex)\n    &#123;\n        <span class=\"hljs-keyword\">int</span> v = e[i].v;\n        \n        <span class=\"hljs-comment\">// 欧拉序，回溯也放入</span>\n        pos[v] = cnt_2;\n        find_u[cnt_2++] = v;\n        dep[v] = level + <span class=\"hljs-number\">1</span>;\n        dfs(v, u, level + <span class=\"hljs-number\">1</span>);\n    &#125;\n&#125;\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">ST</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-comment\">// Preset Log</span>\n    Logn[<span class=\"hljs-number\">1</span>] = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">2</span>; i &lt;= n; ++i)\n        Logn[i] = Logn[i &gt;&gt; <span class=\"hljs-number\">1</span>] + <span class=\"hljs-number\">1</span>;\n    \n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">1</span>; i &lt;= n; ++i)\n        f[i][<span class=\"hljs-number\">0</span>] = find_u[i];\n\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> j = <span class=\"hljs-number\">1</span>; j &lt;= logn; ++j)\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">1</span>; i &lt;= n; ++i)\n            f[i][j] = dep[f[i][j - <span class=\"hljs-number\">1</span>]] &lt; dep[f[i + (j &lt;&lt; <span class=\"hljs-number\">1</span>)][j - <span class=\"hljs-number\">1</span>]] ? f[i][j - <span class=\"hljs-number\">1</span>] : f[i + (j &lt;&lt; <span class=\"hljs-number\">1</span>)][j - <span class=\"hljs-number\">1</span>];\n\n&#125;\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">lca</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> v)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> l = pos[u], r = pos[v];\n    <span class=\"hljs-keyword\">int</span> j = Logn[r - l + <span class=\"hljs-number\">1</span>];\n    <span class=\"hljs-comment\">// 直接找区间最小深度的节点</span>\n    <span class=\"hljs-keyword\">int</span> ans = min(f[l][j], f[r - (<span class=\"hljs-number\">1</span> &lt;&lt; j) + <span class=\"hljs-number\">1</span>][j]);\n    <span class=\"hljs-keyword\">return</span> pos[ans];    <span class=\"hljs-comment\">// 返回节点位置...</span>\n&#125;</code></pre>\n<hr>\n<h2 id=\"并查集\"><a href=\"#并查集\" class=\"headerlink\" title=\"并查集\"></a>并查集</h2><p>再来讲讲这周学的并查集</p>\n<p>并查集顾名思义支持且仅支持两种操作</p>\n<ol>\n<li>合并两个集合</li>\n<li>查询元素所在的集合</li>\n</ol>\n<p>并查集是一种树上的操作，通过根节点直接代表整棵树，初始化的时候根节点父节点为自身。</p>\n<ul>\n<li>合并操作</li>\n</ul>\n<p>合并操作相对比较简单，由于我们通过根节点来代表这个集合，那么合并两个集合只需要将其中一个的根节点作为另一个的子节点连接上即可。但同时我们要注意整棵树的深度会影响我们的时间复杂度，因而我们要尽可能不加深或是少加深树的深度，所以我们采用将深度较小的树连接到深度较大的树上，每次这样操作，树深度每次至多 +1，这种策略称之为<strong>按秩合并（启发式合并）</strong></p>\n<p><img src=\"https://oi-wiki.org/ds/images/dsu1.png\" alt></p>\n<ul>\n<li>代码</li>\n</ul>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">unionSet</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> y)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> tmp_x = find(x);\n    <span class=\"hljs-keyword\">int</span> tmp_y = find(y);\n    <span class=\"hljs-keyword\">if</span>(tmp_x == tmp_y)  <span class=\"hljs-comment\">// 本来就在同一集合中</span>\n        <span class=\"hljs-keyword\">return</span>; \n    <span class=\"hljs-keyword\">if</span>(sz[tmp_x] &gt; sz[tmp_y])\n        swap(tmp_x, tmp_y); <span class=\"hljs-comment\">// 让 tmp_x 是深度小的集合</span>\n    fa[tmp_x] = tmp_y; <span class=\"hljs-comment\">// 将 tmp_x 连接到 tmp_y 上</span>\n&#125;</code></pre>\n<ul>\n<li>查询操作</li>\n</ul>\n<p>我们来讲并查集关键的查询操作，并查集的查询操作给出一个节点，我们查询其父节点，如若其父节点不是自身就继续向上查询，直到查询到根节点（父节点为自身）返回根节点作为这个集合的代表。</p>\n<p>我们不难看出这样的查询操作单次是 $O(n)$ 的，原因是我们每次查询都要走完完整的一条链，但是其实我们并不关心该节点的父节点是谁，我们只想知道其根节点是什么。所以我们可以直接让它的父节点直接是根节点，这样虽然在第一次操作的时候，我们还是要走完一条链，但之后该节点的父节点直接就是根节点。这种操作称为<strong>路径压缩</strong></p>\n<p><img src=\"https://oi-wiki.org/ds/images/dsu2.png\" alt></p>\n<pre><code class=\"hljs cpp\">\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">find</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">if</span>(fa[x] == x)\n        <span class=\"hljs-keyword\">return</span> x;\n    <span class=\"hljs-keyword\">return</span> fa[x] = find(fa[x]); <span class=\"hljs-comment\">// 路径压缩</span>\n&#125;</code></pre>\n<ul>\n<li><strong>复杂度分析</strong></li>\n</ul>\n<p>我们现在来分析一下复杂度，朴素算法毫无疑问单次操作是 $O(mn)$ 的<br>如果我们使用了路径压缩，在Tarjan大神的论文[1] 中给出了复杂度的证明，只使用路径压缩不使用按秩合并的最坏时间复杂度是 $O(mlogn)$ 已经满足大部分题的需求，所以一般只需要路径压缩就能过题。<br>在姚期智的论文 [2] 中，证明了只路径压缩的平均复杂度为 $O(m\\alpha{(m,n)})$<br><em>注： $\\alpha$ 是阿克曼函数的反函数，其增长极其缓慢，也就是说其单次操作的平均运行时间可以认为是一个很小的常数。</em></p>\n<p>如果我们同时使用了路径压缩和按秩合并，那么我们可以做到 $O(m\\alpha{(m,n)})$ 的最坏时间复杂度。相当于单次询问是常数级别复杂度。</p>\n<p>Ackermann 函数</p>\n<script type=\"math/tex; mode=display\">\nA(m,n) =\\left\\{\n\\begin{array}{l}\n    n + 1, \\; m = 0 \\\\\n    A(m - 1, 1), m > 0 \\;and\\; n = 0 \\\\\n    A(m - 1, A(m, n - 1)),\\;othercases\n\\end{array}\n\\right.</script><p>$A(4, 3)$ 大的惊人，其反函数增长就相对应慢的惊人，直接可看为常数</p>\n<hr>\n<h2 id=\"树上差分算法\"><a href=\"#树上差分算法\" class=\"headerlink\" title=\"树上差分算法\"></a>树上差分算法</h2><p>讲一下这周作业题里涉及到的树上差分算法<br>树上差分问题可以用树链剖分解决，但我目前还不太会，就写一下现在会一点的树上差分。</p>\n<p>树上差分分为两种，边差分和点差分。</p>\n<ul>\n<li>边差分<br>考虑一个经典问题，<strong>给出两点x, y 将其路径上的边权加1，最后给出所有边权。</strong></li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r99w60.png\" alt=\"图源:https://www.cnblogs.com/zhwer/p/12800475.html\"></p>\n<p>我们看这张图，数组 c[k] 是差分数组只不过我们是自下而上加的，为不影响其他子树的结果，我们的统计在回溯过程中完成，因而是自下而上的，那么这个边权修改过程就可以看做是 c[x]++, c[y]++, 然后 根节点到lca(x, y)被加了两次，我们都要减去 c[lca(x, y)] -= 2</p>\n<p>既然是差分那么对于权值的更新，我们就可以如同前缀和一样计算，这不过这里的”前缀”是所有的子树权值，我们将所有子树权值收集起来到父节点上。</p>\n<ul>\n<li>代码实现</li>\n</ul>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// 已求出差分数组c</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">getAns</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa)</span></span>\n<span class=\"hljs-function\"></span>&#123;  \n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = head[u]; i != <span class=\"hljs-number\">-1</span>; i = e[i].nex)\n    &#123;\n        <span class=\"hljs-keyword\">int</span> v = e[i].v;\n        <span class=\"hljs-keyword\">if</span>(v != fa)\n        &#123;\n            getAns(v, u);\n            c[u] += c[v] <span class=\"hljs-comment\">// 收集子树权值更新c为原本数组</span>\n            <span class=\"hljs-comment\">// 更新后的c就代表其和其父节点连接边的边权</span>\n        &#125;\n    &#125;\n&#125;</code></pre>\n<ul>\n<li>点差分<br>点差分和边差分差不多，但这回每个点都代表的是自己了。<br><img src=\"https://s3.ax1x.com/2020/12/08/r990XV.png\" alt=\"图源:https://www.cnblogs.com/zhwer/p/12800475.html\"></li>\n</ul>\n<p>和边差分不同的是，这回lca不需要减2了，因为每个点代表的就是自己，在统计的时候 x, y 路径上是有 lca(x, y) 的，因而只需要减去一次重复计算即可。但这边lca在计算”前缀和”的时候会 +1，差分数组某一地方值的变动会影响到后面所有的值（这就是差分数组的精髓和意义所在）但lca的父亲并不应该 +1 所以我们要将 c[fa[lca(x,y)]]— 这个过程之后，我们的差分数组就完成了。<br>最后自下而上的收集一下，就能得到所有节点的权值了。</p>\n<ul>\n<li>思想总结</li>\n</ul>\n<p>差分的思想就是将原来本不相干的值联系到了一起，把后面点的部分信息移到了前面的点中，形成了区间的覆盖，这种效果正好能够用于解决区间修改问题，避免了暴力算法对每个点都进行操作，很巧妙的思想。</p>\n<hr>\n<h2 id=\"最后总结\"><a href=\"#最后总结\" class=\"headerlink\" title=\"最后总结\"></a>最后总结</h2><p>本周DS主要学习这些内容，AVL树很惭愧虽然上课讲了但还没有深入去看，线段树和树链剖分还不太会，树状数组也快忘记了。最近又重新听到了《蜗牛》这首歌，隔了这么多年，再听还是很感动。“历经的伤都不感觉疼”，“任风吹干流过的泪和汗，总有一天我有属于我的天。”<br>每周都在不断吸收新知识，很充实也很疲倦，每天都学到12点之后。就是希望能够在未来有一片自己的天。科研也在不断做，但进度很慢，时间分配越来越不够了，最近越来越感到拔尖班的藏龙卧虎，个个都是人才，让我感到了很大的压力。但就像《蜗牛》中说的即使我很慢，拖着重重的壳，只要我每天一步一步的向上爬，我总能触碰到那片属于我的蓝天。</p>\n<hr>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>[1]Tarjan, R. E., &amp; Van Leeuwen, J. (1984). Worst-case analysis of set union algorithms.<br>[2]Yao, A. C. (1985). On the expected performance of path compression algorithms. SIAM Journal on Computing, 14(1), 129-133.</p>\n"},{"title":"素数筛法 (2020-12-7)","index_img":"/img/Pic/DS.png","date":"2020-12-08T07:12:25.000Z","math":true,"_content":"\n# 素数筛法\n\n我们今天来讲讲筛法，今天上机出其不意的考了一手筛法，我居然天真的在写暴力素数判断。所以今天就来复习(重学)一下筛法。\n\n如果我们想要判断一个数是否是素数有什么方法呢？ 暴力判断肯定是最容易想到的方法，按定义素数不能被1和其自身以外的数整除，我们自然会想到从 x - 1到2全判一遍的算法。但显然，我们做了很多重复的工作。\n\n实际上我们可以发现，如果我们判断出了一个素数，那么它的倍数显然就不可能是素数，这样就可以直接将其开除“素籍“，踢出待选区域。这种筛选素数的方法就像一个筛子，每碰到一个素数就筛掉一批非素数，大大降低了复杂度。\n\n![](https://images2015.cnblogs.com/blog/927750/201612/927750-20161229220529101-1487746442.png)\n\n## 埃拉托斯特尼筛法\n\n按上述思想写出代码，就是埃氏筛法。\n\n- 代码实现\n\n```cpp\nint Eratosthenes(int n) {\n    int p = 0;\n    for (int i = 0; i <= n; ++i) \n        is_prime[i] = 1;\n    is_prime[0] = is_prime[1] = 0;\n    for (int i = 2; i <= n; ++i) \n    {\n        if (is_prime[i]) // 直接从2开筛不会放进来一个非素数\n        {\n            prime[p++] = i; \n            if ((long long)i * i <= n)\n                for (int j = i * i; j <= n; j += i)\n                    // 因为从 2 到 i - 1 的倍数我们之前筛过了，这里直接从 i 的 i倍开始，提高了运行速度\n                    is_prime[j] = 0;  // 是i的倍数的均不是素数\n        }\n    }\n    return p;\n}\n```\n\n### 复杂度计算\n\n关于埃氏筛法的复杂度计算，我们来做一个推导，首先我们可以看出每次循环中，若当前素数是p，那么单次循环执行 n/p 次， 所以总的表达式就是 n 乘上所有素数的倒数和 $n\\sum_{p} \\frac{1}{p}$\n\n关于所有素数的倒数和，在欧拉相关的论文中有明确的估计。\n\n$$\\sum_{p\\le x} \\frac{1}{p} = \\ln\\ln(x) + \\gamma + \\sum_{m = 2}^{\\infty}{\\mu (m){\\frac{\\zeta(m)}{m} + \\delta}}$$\n论文链接 [https://arxiv.org/pdf/math/0504289.pdf]\n\n可知埃氏筛法的复杂度为 $O(nloglogn)$\n\n---\n\n## 欧拉筛法 （线性筛）\n\nTODO","source":"_posts/DS/DataStructureNote2.md","raw":"---\ntitle: 素数筛法 (2020-12-7)\nindex_img: /img/Pic/DS.png\ndate: 2020-12-07 23:12:25\ncategory: [DataStructure]\ntags: [Number theory, Multiplication algorithm]\nmath: true\n---\n\n# 素数筛法\n\n我们今天来讲讲筛法，今天上机出其不意的考了一手筛法，我居然天真的在写暴力素数判断。所以今天就来复习(重学)一下筛法。\n\n如果我们想要判断一个数是否是素数有什么方法呢？ 暴力判断肯定是最容易想到的方法，按定义素数不能被1和其自身以外的数整除，我们自然会想到从 x - 1到2全判一遍的算法。但显然，我们做了很多重复的工作。\n\n实际上我们可以发现，如果我们判断出了一个素数，那么它的倍数显然就不可能是素数，这样就可以直接将其开除“素籍“，踢出待选区域。这种筛选素数的方法就像一个筛子，每碰到一个素数就筛掉一批非素数，大大降低了复杂度。\n\n![](https://images2015.cnblogs.com/blog/927750/201612/927750-20161229220529101-1487746442.png)\n\n## 埃拉托斯特尼筛法\n\n按上述思想写出代码，就是埃氏筛法。\n\n- 代码实现\n\n```cpp\nint Eratosthenes(int n) {\n    int p = 0;\n    for (int i = 0; i <= n; ++i) \n        is_prime[i] = 1;\n    is_prime[0] = is_prime[1] = 0;\n    for (int i = 2; i <= n; ++i) \n    {\n        if (is_prime[i]) // 直接从2开筛不会放进来一个非素数\n        {\n            prime[p++] = i; \n            if ((long long)i * i <= n)\n                for (int j = i * i; j <= n; j += i)\n                    // 因为从 2 到 i - 1 的倍数我们之前筛过了，这里直接从 i 的 i倍开始，提高了运行速度\n                    is_prime[j] = 0;  // 是i的倍数的均不是素数\n        }\n    }\n    return p;\n}\n```\n\n### 复杂度计算\n\n关于埃氏筛法的复杂度计算，我们来做一个推导，首先我们可以看出每次循环中，若当前素数是p，那么单次循环执行 n/p 次， 所以总的表达式就是 n 乘上所有素数的倒数和 $n\\sum_{p} \\frac{1}{p}$\n\n关于所有素数的倒数和，在欧拉相关的论文中有明确的估计。\n\n$$\\sum_{p\\le x} \\frac{1}{p} = \\ln\\ln(x) + \\gamma + \\sum_{m = 2}^{\\infty}{\\mu (m){\\frac{\\zeta(m)}{m} + \\delta}}$$\n论文链接 [https://arxiv.org/pdf/math/0504289.pdf]\n\n可知埃氏筛法的复杂度为 $O(nloglogn)$\n\n---\n\n## 欧拉筛法 （线性筛）\n\nTODO","slug":"DS/DataStructureNote2","published":1,"updated":"2026-02-03T05:42:14.428Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvb000s7uithljbh5v1","content":"<h1 id=\"素数筛法\"><a href=\"#素数筛法\" class=\"headerlink\" title=\"素数筛法\"></a>素数筛法</h1><p>我们今天来讲讲筛法，今天上机出其不意的考了一手筛法，我居然天真的在写暴力素数判断。所以今天就来复习(重学)一下筛法。</p>\n<p>如果我们想要判断一个数是否是素数有什么方法呢？ 暴力判断肯定是最容易想到的方法，按定义素数不能被1和其自身以外的数整除，我们自然会想到从 x - 1到2全判一遍的算法。但显然，我们做了很多重复的工作。</p>\n<p>实际上我们可以发现，如果我们判断出了一个素数，那么它的倍数显然就不可能是素数，这样就可以直接将其开除“素籍“，踢出待选区域。这种筛选素数的方法就像一个筛子，每碰到一个素数就筛掉一批非素数，大大降低了复杂度。</p>\n<p><img src=\"https://images2015.cnblogs.com/blog/927750/201612/927750-20161229220529101-1487746442.png\" alt></p>\n<h2 id=\"埃拉托斯特尼筛法\"><a href=\"#埃拉托斯特尼筛法\" class=\"headerlink\" title=\"埃拉托斯特尼筛法\"></a>埃拉托斯特尼筛法</h2><p>按上述思想写出代码，就是埃氏筛法。</p>\n<ul>\n<li>代码实现</li>\n</ul>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">Eratosthenes</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;\n    <span class=\"hljs-keyword\">int</span> p = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt;= n; ++i) \n        is_prime[i] = <span class=\"hljs-number\">1</span>;\n    is_prime[<span class=\"hljs-number\">0</span>] = is_prime[<span class=\"hljs-number\">1</span>] = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">2</span>; i &lt;= n; ++i) \n    &#123;\n        <span class=\"hljs-keyword\">if</span> (is_prime[i]) <span class=\"hljs-comment\">// 直接从2开筛不会放进来一个非素数</span>\n        &#123;\n            prime[p++] = i; \n            <span class=\"hljs-keyword\">if</span> ((<span class=\"hljs-keyword\">long</span> <span class=\"hljs-keyword\">long</span>)i * i &lt;= n)\n                <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> j = i * i; j &lt;= n; j += i)\n                    <span class=\"hljs-comment\">// 因为从 2 到 i - 1 的倍数我们之前筛过了，这里直接从 i 的 i倍开始，提高了运行速度</span>\n                    is_prime[j] = <span class=\"hljs-number\">0</span>;  <span class=\"hljs-comment\">// 是i的倍数的均不是素数</span>\n        &#125;\n    &#125;\n    <span class=\"hljs-keyword\">return</span> p;\n&#125;</code></pre>\n<h3 id=\"复杂度计算\"><a href=\"#复杂度计算\" class=\"headerlink\" title=\"复杂度计算\"></a>复杂度计算</h3><p>关于埃氏筛法的复杂度计算，我们来做一个推导，首先我们可以看出每次循环中，若当前素数是p，那么单次循环执行 n/p 次， 所以总的表达式就是 n 乘上所有素数的倒数和 $n\\sum_{p} \\frac{1}{p}$</p>\n<p>关于所有素数的倒数和，在欧拉相关的论文中有明确的估计。</p>\n<script type=\"math/tex; mode=display\">\\sum_{p\\le x} \\frac{1}{p} = \\ln\\ln(x) + \\gamma + \\sum_{m = 2}^{\\infty}{\\mu (m){\\frac{\\zeta(m)}{m} + \\delta}}</script><p>论文链接 [<a href=\"https://arxiv.org/pdf/math/0504289.pdf\">https://arxiv.org/pdf/math/0504289.pdf</a>]</p>\n<p>可知埃氏筛法的复杂度为 $O(nloglogn)$</p>\n<hr>\n<h2 id=\"欧拉筛法-（线性筛）\"><a href=\"#欧拉筛法-（线性筛）\" class=\"headerlink\" title=\"欧拉筛法 （线性筛）\"></a>欧拉筛法 （线性筛）</h2><p>TODO</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"素数筛法\"><a href=\"#素数筛法\" class=\"headerlink\" title=\"素数筛法\"></a>素数筛法</h1><p>我们今天来讲讲筛法，今天上机出其不意的考了一手筛法，我居然天真的在写暴力素数判断。所以今天就来复习(重学)一下筛法。</p>\n<p>如果我们想要判断一个数是否是素数有什么方法呢？ 暴力判断肯定是最容易想到的方法，按定义素数不能被1和其自身以外的数整除，我们自然会想到从 x - 1到2全判一遍的算法。但显然，我们做了很多重复的工作。</p>\n<p>实际上我们可以发现，如果我们判断出了一个素数，那么它的倍数显然就不可能是素数，这样就可以直接将其开除“素籍“，踢出待选区域。这种筛选素数的方法就像一个筛子，每碰到一个素数就筛掉一批非素数，大大降低了复杂度。</p>\n<p><img src=\"https://images2015.cnblogs.com/blog/927750/201612/927750-20161229220529101-1487746442.png\" alt></p>\n<h2 id=\"埃拉托斯特尼筛法\"><a href=\"#埃拉托斯特尼筛法\" class=\"headerlink\" title=\"埃拉托斯特尼筛法\"></a>埃拉托斯特尼筛法</h2><p>按上述思想写出代码，就是埃氏筛法。</p>\n<ul>\n<li>代码实现</li>\n</ul>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">Eratosthenes</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;\n    <span class=\"hljs-keyword\">int</span> p = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt;= n; ++i) \n        is_prime[i] = <span class=\"hljs-number\">1</span>;\n    is_prime[<span class=\"hljs-number\">0</span>] = is_prime[<span class=\"hljs-number\">1</span>] = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">2</span>; i &lt;= n; ++i) \n    &#123;\n        <span class=\"hljs-keyword\">if</span> (is_prime[i]) <span class=\"hljs-comment\">// 直接从2开筛不会放进来一个非素数</span>\n        &#123;\n            prime[p++] = i; \n            <span class=\"hljs-keyword\">if</span> ((<span class=\"hljs-keyword\">long</span> <span class=\"hljs-keyword\">long</span>)i * i &lt;= n)\n                <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> j = i * i; j &lt;= n; j += i)\n                    <span class=\"hljs-comment\">// 因为从 2 到 i - 1 的倍数我们之前筛过了，这里直接从 i 的 i倍开始，提高了运行速度</span>\n                    is_prime[j] = <span class=\"hljs-number\">0</span>;  <span class=\"hljs-comment\">// 是i的倍数的均不是素数</span>\n        &#125;\n    &#125;\n    <span class=\"hljs-keyword\">return</span> p;\n&#125;</code></pre>\n<h3 id=\"复杂度计算\"><a href=\"#复杂度计算\" class=\"headerlink\" title=\"复杂度计算\"></a>复杂度计算</h3><p>关于埃氏筛法的复杂度计算，我们来做一个推导，首先我们可以看出每次循环中，若当前素数是p，那么单次循环执行 n/p 次， 所以总的表达式就是 n 乘上所有素数的倒数和 $n\\sum_{p} \\frac{1}{p}$</p>\n<p>关于所有素数的倒数和，在欧拉相关的论文中有明确的估计。</p>\n<script type=\"math/tex; mode=display\">\\sum_{p\\le x} \\frac{1}{p} = \\ln\\ln(x) + \\gamma + \\sum_{m = 2}^{\\infty}{\\mu (m){\\frac{\\zeta(m)}{m} + \\delta}}</script><p>论文链接 [<a href=\"https://arxiv.org/pdf/math/0504289.pdf\">https://arxiv.org/pdf/math/0504289.pdf</a>]</p>\n<p>可知埃氏筛法的复杂度为 $O(nloglogn)$</p>\n<hr>\n<h2 id=\"欧拉筛法-（线性筛）\"><a href=\"#欧拉筛法-（线性筛）\" class=\"headerlink\" title=\"欧拉筛法 （线性筛）\"></a>欧拉筛法 （线性筛）</h2><p>TODO</p>\n"},{"title":"NLP 名称实体标注任务 (NER)","date":"2021-12-15T02:42:45.000Z","index_img":"/img/NLP/banner.jpeg","math":true,"_content":"\n<object data=\"/pdf/NER.pdf\" type=\"application/pdf\" width=\"100%\" height=\"1024px\">\n\n\n","source":"_posts/NLP/nlp-ner.md","raw":"---\ntitle: NLP 名称实体标注任务 (NER)\ndate: 2021-12-14 18:42:45\nindex_img: /img/NLP/banner.jpeg\ncategory: [NLP]\ntags: [NER, BIO]\nmath: true\n---\n\n<object data=\"/pdf/NER.pdf\" type=\"application/pdf\" width=\"100%\" height=\"1024px\">\n\n\n","slug":"NLP/nlp-ner","published":1,"updated":"2026-02-03T05:42:14.437Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvb000v7uitair9h926","content":"<object data=\"/pdf/NER.pdf\" type=\"application/pdf\" width=\"100%\" height=\"1024px\">\n\n\n</object>","site":{"data":{}},"excerpt":"","more":"<object data=\"/pdf/NER.pdf\" type=\"application/pdf\" width=\"100%\" height=\"1024px\">\n\n\n</object>"},{"title":"Cache Lab 理解高速缓存","date":"2021-04-13T23:13:55.000Z","index_img":"/img/ICS_Lab1/top.jpg","_content":"\n*注：本实验报告为 CMU CSAPP CacheLab 实验报告*\n\n## 一、实验简介\n\n​\tCache Lab实验主要在于帮助学生理解高速缓存的工作方式，以及如何针对Cache编写程序。实验主体总共分为两个部分 \n\n### **PartA** \n\n编写一个Cache的模拟程序用以统计在L\\S\\M过程中Cache Hit\\Miss\\Eviction 的总数。\n\n官方给出了 csim-ref 程序，我们需要编写代码实现其功能，输出 Hit/Miss/Eviction 的总数\n\n```shell\nUsage: ./csim-ref [-hv] -s <num> -E <num> -b <num> -t <file>\nOptions:\n  -h         Print this help message.\n  -v         Optional verbose flag.\n  -s <num>   Number of set index bits.\n  -E <num>   Number of lines per set.\n  -b <num>   Number of block offset bits.\n  -t <file>  Trace file.\n\nExamples:\n  linux>  ./csim-ref -s 4 -E 1 -b 4 -t traces/yi.trace\n  linux>  ./csim-ref -v -s 8 -E 2 -b 4 -t traces/yi.trace\n```\n\n**测试方法：**\n\n​\t使用 test-csim.c 进行测试，测试器会输出你的编译器和标准结果，并进行比较计算分数。\n\n```shell\nxzy@ubuntu:~/Desktop/ICSLAB/CacheLab$ ./test-csim \n                        Your simulator     Reference simulator\nPoints (s,E,b)    Hits  Misses  Evicts    Hits  Misses  Evicts\n     3 (1,1,1)       9       8       6       9       8       6  traces/yi2.trace\n     3 (4,2,4)       4       5       2       4       5       2  traces/yi.trace\n     3 (2,1,4)       2       3       1       2       3       1  traces/dave.trace\n     3 (2,1,3)     167      71      67     167      71      67  traces/trans.trace\n     3 (2,2,3)     201      37      29     201      37      29  traces/trans.trace\n     3 (2,4,3)     212      26      10     212      26      10  traces/trans.trace\n     3 (5,1,5)     231       7       0     231       7       0  traces/trans.trace\n     6 (5,1,5)  265189   21775   21743  265189   21775   21743  traces/long.trace\n    27\n\nTEST_CSIM_RESULTS=27\n```\n\n\n\n### **PartB**\n\n编写适应Cache的矩阵转置程序，使Cache的miss数尽量的小。\n\n​\t给出总大小1kb，每个 block 为 32byte 的直接映射Cache\n\n​\t共包含3个测试、分别为 32x32 \\ 64x64 \\ 61x67 大小的矩阵\n\n**测试方法：**\n\n​\t使用 test-trans.c 进行测试\n\n```shell\nUsage: ./test-trans [-h] -M <rows> -N <cols>\nOptions:\n  -h          Print this help message.\n  -M <rows>   Number of matrix rows (max 256)\n  -N <cols>   Number of  matrix columns (max 256)\nExample: ./test-trans -M 8 -N 8\n```\n\n\n\n----\n\n\n\n## 二、实验内容\n\n### PartA\n\n- **关于 Cache 的结构组成**\n\n​\t在 PartA 中我们需要在 csim.c 中编写模拟 Cache 运行的程序。学习过CSAPP第六章我们知道，Cache 的结构是由一行一个valid位，t个tag和一个长度为B的block组成的，总共分为多个Set，每个Set有E行。总共组成 Cache 大小 $C = B \\times E \\times S$ ( valid 和 tag 不计入 )\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gphwionzxcj30e30930t7.jpg)\n\n- **关于 Evict 机制**\n\n  同时由于采取 LRU 策略 （最近最少使用策略），我们需要维护一个 timestamp 来标记其访问时间的远近。可以一开始赋值 INF，然后逐渐减小，LRUstamp 最小的，就会被 Evict。\n\n由此我们确定了 Cache 的组成形式，我们一个 Line 由 valid 位，tag位，LRUstamp，和一个B字节的 Block 组成。由于是模拟Cache，所以其实DataBlock可以不编写，但是为了尽量模拟真实Cache，还是分配了Block的内存\n\n```c\ntypedef struct \n{\n    int valid; // 0/1 : invalid/valid\n    int tag;\n    int LRUstamp; // 越小代表越早使用，可以evict\n    int* Block; // B（2^b） 字节\n} Line_t;\n```\n\n```c\n// s个Set组成Cache\ntypedef struct {\n    int S; // Set 个数 (2^s)\n    int E; // 每个 Set 中 Line 的数量\n    int B; // Block 大小 (2^b)\n    Line_t*** cache_;\n} Cache_t; \n```\n\n我在Cache中设置了S, E, B以方便管理Cache大小，不用每次传参，并编写对应设置函数。\n\n```c\nvoid initCache(const int s, const int E, const int b) \n{\n    Cache.S = (1 << s), Cache.E = E, Cache.B = (1 << b);\n}\n```\n\n\n\n- **关于内存管理**\n\n  之后便是编写函数来进行 Cache的内存分配和释放。这个没什么好说的，就是要养成分配完释放的好习惯，避免内存泄漏。\n\n  ```c\n  /* 分配 Cache */\n  void mallocCache()\n  {\n      Cache.cache_ = (Line_t***)malloc(Cache.S* sizeof(Line_t **));\n      for(int i = 0; i < Cache.S; ++i)\n          Cache.cache_[i] = (Line_t **)malloc(Cache.E * sizeof(Line_t *));\n      for(int i = 0; i < Cache.S; ++i)\n          for(int j = 0; j < Cache.E; ++j)\n              Cache.cache_[i][j] = (Line_t *)malloc(sizeof(Line_t));\n      for(int i = 0; i < Cache.S; ++i)\n          for(int j = 0; j < Cache.E; ++j) {\n              Cache.cache_[i][j]->valid = 0;\n              Cache.cache_[i][j]->tag = 0;\n              Cache.cache_[i][j]->LRUstamp = 1e9;\n              Cache.cache_[i][j]->Block = (int *)malloc(Cache.B * sizeof(int));\n          }\n  }\n  ```\n\n  ```c\n  /* 释放 Cache */\n  void freeCache()\n  {\n      for(int i = 0; i < Cache.S; ++i)\n          for(int j = 0; j < Cache.E; ++j)\n              free(Cache.cache_[i][j]->Block);\n      for(int i = 0; i < Cache.S; ++i)\n          for(int j = 0; j < Cache.E; ++j)\n              free(Cache.cache_[i][j]);\n      for(int i = 0; i < Cache.S; ++i)\n          free(Cache.cache_[i]);\n      free(Cache.cache_);\n  }\n  ```\n\n\n\n- **关于 getter 函数**\n\n  为了方便valid、tag等信息的查找，我编写了一系列getter函数。\n\n  ```c\n  /* 获得 Valid bit */\n  int getValid(const int s, const int E) {return Cache.cache_[s][E]->valid;}\n  \n  /* 获得 Tag */\n  int getTag(const int s, const int E) {return Cache.cache_[s][E]->tag;}\n  \n  /* 获得LRUstamp */\n  int getLRU(const int s, const int E) {return Cache.cache_[s][E]->LRUstamp;}\n  ```\n\n\n\n- **对于Hit和Miss的判定**\n\n  判定hit和miss，就是在Cache对应Set中对比valid和tag，如果valid为1标明有效，并且tag相同，则说明Hit，不然则Miss。\n\n  ```c\n  /* 查看是否命中 */\n  int HitOrMiss(const int s, const int tag)\n  {\n      for(int i = 0; i < Cache.E; ++i)\n          if(getValid(s, i) && getTag(s, i) == tag)\n              return i; // 命中\n      return -1; // Miss \n  }\n  ```\n\n  \n\n- **关于是否Evict**\n\n  根据上文，我们知道我们采取LRU的evict策略，那么在写的时候，如果valid位为1，而tag不一致发生写miss的情况，就要进行evict。evict的位置是LRUstamp最小的那一个。我们维护LRUstamp，在每次操作时，将其赋值为INF (1e9) 并将其余的LRUstamp减1，取最小的 LRUstamp 进行evict，用最新的 tag 和 数据 进行替换\n\n```c\n/* 更新LRU，越小越早使用 */\nvoid lruUpdate(const int s, const int E)\n{\n    Cache.cache_[s][E]->LRUstamp = 1e9;\n    for(int i = 0; i < Cache.E; ++i)\n    {\n        if(i != E)\n            Cache.cache_[s][i]->LRUstamp--;\n    }\n}\n\n/* 更新Cache */\nvoid WriteCache(const int s, const int E, const int tag)\n{\n    Eviction(s, E, tag);\n    Cache.cache_[s][E]->valid = 1;\n    Cache.cache_[s][E]->tag = tag;\n    lruUpdate(s, E);\n}\n```\n\n\n\n- 关于模拟Cache\n\n最后进行Cache的模拟，如果Hit了就值更新LRUstamp，Miss了就获取EvictionPose，并将其替换。\n\n```c\n/* 模拟Cache，获得 Hit 和 Miss 的次数 */\nvoid getAns(const int s, const int tag)\n{\n    int hit_flag = HitOrMiss(s, tag);\n    if(hit_flag != -1) { // Hit\n        Hit++;\n        if(verbose)\n            printf(\"hit \");\n        lruUpdate(s, hit_flag);\n    }\n    else  {\n        Miss++;\n        if(verbose)\n            printf(\"miss \");\n        WriteCache(s, getEvictPos(s), tag);\n    }\n}\n```\n\n\n\n最后完整代码，附于提交 ```csim.c``` 中\n\n\n\n- 完成通过\n\n```c\nYour simulator     Reference simulator\nPoints (s,E,b)    Hits  Misses  Evicts    Hits  Misses  Evicts\n     3 (1,1,1)       9       8       6       9       8       6  traces/yi2.trace\n     3 (4,2,4)       4       5       2       4       5       2  traces/yi.trace\n     3 (2,1,4)       2       3       1       2       3       1  traces/dave.trace\n     3 (2,1,3)     167      71      67     167      71      67  traces/trans.trace\n     3 (2,2,3)     201      37      29     201      37      29  traces/trans.trace\n     3 (2,4,3)     212      26      10     212      26      10  traces/trans.trace\n     3 (5,1,5)     231       7       0     231       7       0  traces/trans.trace\n     6 (5,1,5)  265189   21775   21743  265189   21775   21743  traces/long.trace\n    27\n```\n\n\n\n----\n\n\n\n### PartB\n\n​\t在完成了Cache基本的组织架构之后，我们现在要开始编写Cache友好的程序，以矩阵转置为例。源代码中包含一个最naive的矩阵转置，也是我们平常经常写的。\n\n```c\n/* \n * trans - A simple baseline transpose function, not optimized for the cache.\n */\nchar trans_desc[] = \"Simple row-wise scan transpose\";\nvoid trans(int M, int N, int A[N][M], int B[M][N])\n{\n    int i, j, tmp;\n\n    for (i = 0; i < N; i++) {\n        for (j = 0; j < M; j++) {\n            tmp = A[i][j];\n            B[j][i] = tmp;\n        }\n    }    \n}\n```\n\n测试之后会发现，对于4x4的矩阵，其miss次数有22次之多\n\n```shell\nfunc 1 (Simple row-wise scan transpose): hits:15, misses:22, evictions:19\n```\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gphxvxlx02j312d0iw40v.jpg\" style=\"zoom:50%;\" />\n\n我们可以发现，对于4x4的矩阵，由于Block大小是32bytes且为直接映射Cache，所以每8个int会在同一个Block/Set当中，4x4的矩阵被分在两个不同的 Block 中，对于A矩阵的访问是行优先的，而B矩阵的访问是列优先的。我们可以模拟这个过程\n\n> 访问到 $A_{00}$  Cache cold miss，将 $B_{A_{1}}$ 加入 Cache 中\n>\n> 访问到 $B_{00}$  由于B和A有相同的组索引，所以导致相对位置相同的地方被映射到Cache的同一组中，造成tag不一致，产生miss将会把之前Load到Cache里的A进行驱逐，将 $B_{A_{1}}$ 驱逐 将 $B_{B_{1}}$ 加入 Cache 中\n>\n> 访问到 $A_{01}$  同理，将 $B_{B_{1}}$ 驱逐 将 $B_{A_{1}}$ 加入 Cache 中\n>\n> 之后 $B_{B_{2}}$ 和  $B_{A_{1}}$ 很幸运能够不产生thrash，有几次Cache hit，但是大部分情况下，还是会发生如同上面所描述的抖动。\n\n因此，对于这种情况，我们应该如何修改代码，使其适应Cache，能够尽可能少的Miss呢？\n\n- **暴力方法**\n\n  有一种最暴力的方式，就是考虑到目前矩阵的大小比较小，所以我们可以采取定义8个局部变量的方法，一次性将一个Block全部Load到寄存器中，然后再进行转置，这样就不会发生如上面所描述的 Cache thrash。\n\n  ```c\n  void transpose_4x4(int M, int N, int A[N][M], int B[M][N])\n  {\n      int tmp0, tmp1, tmp2, tmp3, tmp4, tmp5, tmp6, tmp7;\n  \n  \tfor(int x = 0; x < 3; x += 2)\n  \t{\n  \t\ttmp0 = A[x][0], tmp1 = A[x][1], tmp2 = A[x][2], tmp3 = A[x][3];\n  \t\ttmp4 = A[x + 1][0], tmp5 = A[x + 1][1], tmp6 = A[x + 1][2], tmp7 = A[x + 1][3];\n  \n  \t\tB[0][x] = tmp0, B[1][x] = tmp1, B[2][x] = tmp2, B[3][x] = tmp3; \n  \t\tB[0][x + 1] = tmp4, B[1][x + 1] = tmp5, B[2][x + 1] = tmp6, B[3][x + 1] = tmp7; \n  \t}\n  }\n  ```\n\n  ```\n  func 0 (Transpose submission): hits:29, misses:8, evictions:6\n  ```\n\n  可以看到miss降到了8，有极大的改进，我们用partA中写的csim进行分析。\n\n  ```shell\n  xzy@ubuntu:~/Desktop/ICSLAB/CacheLab$ ./csim -v -s 5 -E 1 -b 5 -t trace.f0\n  S 18e08c,1 miss #系统miss\n  L 18e0a0,8 miss #系统miss\n  L 18e084,4 hit \n  L 18e080,4 hit \n  L 10e080,4 miss eviction \n  L 10e084,4 hit \n  L 10e088,4 hit \n  L 10e08c,4 hit \n  L 10e090,4 hit \n  L 10e094,4 hit \n  L 10e098,4 hit \n  L 10e09c,4 hit \n  S 14e080,4 miss eviction \n  S 14e090,4 hit \n  S 14e0a0,4 miss eviction # 多一次miss\n  S 14e0b0,4 hit \n  S 14e084,4 hit \n  S 14e094,4 hit \n  S 14e0a4,4 hit \n  S 14e0b4,4 hit \n  L 10e0a0,4 miss eviction \n  L 10e0a4,4 hit \n  L 10e0a8,4 hit \n  L 10e0ac,4 hit \n  L 10e0b0,4 hit \n  L 10e0b4,4 hit \n  L 10e0b8,4 hit \n  L 10e0bc,4 hit \n  S 14e088,4 hit \n  S 14e098,4 hit \n  S 14e0a8,4 miss eviction \n  S 14e0b8,4 hit \n  S 14e08c,4 hit \n  S 14e09c,4 hit \n  S 14e0ac,4 hit \n  S 14e0bc,4 hit \n  S 18e08d,1 miss eviction #系统miss\n  hits:29 misses:8 evictions:6\n  ```\n\n  可以看到除了前后3次系统固定的miss之外，距离理论下限4次还有1次，这一次发生在Store矩阵B的时候，由于B是列优先，所以在访问到$B_{B_{2}}$的时候会多发生一次miss。\n\n\t#### 32x32 矩阵转置\n\n​\t\t了解了之后我们来看32x32的矩阵转置，其正好是Cache 1kb的总大小，能够全部装进Cache。所以我们需要避免的就是连续在A,B\n\n之间切换访问相对位置相同的区域（映射到同一个Block）从而导致的Cache thrash。\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gpi2azu5g2j31dl0qz42z.jpg\" style=\"zoom:50%;\" />\n\n我们可以采取 8*8分块的方式，对于每一块中每一行属于同一个Block，经过8x8分块后我们发现，除了对角线的分块之外，其他分块的A、B互不影响，不会产生thrash。\n\n```c\nvoid transpose_32x32(int M, int N, int A[N][M], int B[M][N])\n{\n    int i, j, x, y;\n\t\tint tmp;\n  \n    for(i = 0; i < N; i += 8)\n        for(j = 0; j < M; j += 8)\n          for(x = i; x < i + 8; ++x)\n              for(y = j; y < j + 8; ++y)\n              {\n                tmp = A[x][y], B[y][x] = tmp;\n              }\n  /*\n    注意，这里应该学习示例程序中的 tmp = A[x][y], B[y][x] = tmp; \n    因为我们无法确定调用者是否会使A，B指向内存中的同一块区域从而造成意想不到的后果。\n  */\n}\n```\n\n```shell\nfunc 0 (Transpose submission): hits:1735, misses:350, evictions:318 \t# 8x8 分块\nfunc 1 (Simple row-wise scan transpose): hits:870, misses:1183, evictions:1151\t# Naive\n```\n\n可以看到相比于最初naive的版本1183miss，已经有了极大的改善，但是还是没有达到要求的小于300miss。\n\n\n\n我们可以发现，除对角线之外的分块已经达到miss的下限，所以对角线是需要解决的地方。对于对角线上的分块，我们的处理和Naive方式没有什么区别，都会造成thrash。\n\n有了前面4x4矩阵的铺垫，我们已经知道了应该如何处理这类情况，我们按照之前的解决方法类似解决。\n\n```c\nvoid transpose_32x32(int M, int N, int A[N][M], int B[M][N])\n{\n    int i, j, x, y;\n    int tmp, tmp0, tmp1, tmp2, tmp3, tmp4, tmp5, tmp6, tmp7;\n\n    for(i = 0; i < N; i += 8)\n        for(j = 0; j < M; j += 8)\n\t\t\tfor(x = i; x < i + 8; ++x)\n\t\t\t{\n\t\t\t\tif(i == j)\n\t\t\t\t{\n\t\t\t\t\ttmp0 = A[x][j], tmp1 = A[x][j + 1], tmp2 = A[x][j + 2], tmp3 = A[x][j + 3];\n\t\t\t\t\ttmp4 = A[x][j + 4], tmp5 = A[x][j + 5], tmp6 = A[x][j + 6], tmp7 = A[x][j + 7];\n\n\t\t\t\t\tB[j][x] = tmp0, B[j + 1][x] = tmp1, B[j + 2][x] = tmp2, B[j + 3][x] = tmp3; \n\t\t\t\t\tB[j + 4][x] = tmp4, B[j + 5][x] = tmp5, B[j + 6][x] = tmp6, B[j + 7][x] = tmp7; \n\t\t\t\t}\n\t\t\t\telse \n\t\t\t\t{\n\t\t\t\t\tfor(y = j; y < j + 8; ++y)\n\t\t\t\t\t{\n\t\t\t\t\t\ttmp = A[x][y], B[y][x] = tmp;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n}\n```\n\n```\nfunc 0 (Transpose submission): hits:1766, misses:287, evictions:255\n```\n\n​\t成功将miss降到了287。实际的理论下限是256，我们注意到这种操作方式A矩阵的miss已经达到了下限，而B矩阵的对角线还是会固定miss。这是因为在Load A之前，B矩阵的对角线行已经被前一个转置Load进去，所以会被evict掉，再次调用时就会产生一次Miss。所以我们可以对其进行展开，最后可以做到259次的miss（3次系统miss）由于代码可读性太低，这里不做展开。\n\n\n\n---\n\n#### 64x64矩阵转置\n\n​\t对于64x64矩阵转置，我们注意到其已经超过了Cache的大小，我们首先用8分块尝试一下。\n\n```shell\nfunc 0 (Transpose submission): hits:3586, misses:4611, evictions:4579 # 8分块\nfunc 1 (Simple row-wise scan transpose): hits:3474, misses:4723, evictions:4691 # naive\n```\n\n发现没有什么改进，这是什么原因？我们从Cache大小的角度出发\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gpi5dme0pcj31ok0tnteo.jpg)\n\n我们进行4x4分块试验一下\n\n```c\nint i, j, x, y;\n    int tmp, tmp0, tmp1, tmp2, tmp3;\n\n    for(i = 0; i < N; i += 4)\n        for(j = 0; j < M; j += 4)\n\t\t\tfor(x = i; x < i + 4; ++x)\n\t\t\t{\n\t\t\t\tif(i == j)\n\t\t\t\t{\n\t\t\t\t\ttmp0 = A[x][j], tmp1 = A[x][j + 1], tmp2 = A[x][j + 2], tmp3 = A[x][j + 3];\n\n\t\t\t\t\tB[j][x] = tmp0, B[j + 1][x] = tmp1, B[j + 2][x] = tmp2, B[j + 3][x] = tmp3; \n\t\t\t\t}\n\t\t\t\telse \n\t\t\t\t{\n\t\t\t\t\tfor(y = j; y < j + 4; ++y)\n\t\t\t\t\t{\n\t\t\t\t\t\ttmp = A[x][y], B[y][x] = tmp;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n```\n\n\n\n```shell\nfunc 0 (Transpose submission): hits:6402, misses:1795, evictions:1763\n```\n\n​\t可以看到结果好了很多，但是还是没能达到1300的要求。其原因其实还是在最开始讲的4x4分块的例子中，由于B矩阵是按列访问，在4x4分块之后，访问对角两块的时候，会每一块都会各产生2次miss，有一个小的thrash。\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gpi5iw1wfdj31or0tj0vq.jpg\" style=\"zoom:33%;\" />\n\n​\t对自己电脑寄存器数量有自信的选手可能会选择开16个临时变量来一次性完成转置，但那样太过粗暴而不稳定。我们想是否有什么办法能够使4x4区域中的miss次数降低到1次？我们回去考虑8x8的分块情况。\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gpi5pdjqnuj31tk0laq79.jpg)\n\n- **对于A矩阵**\n\n  我们的策略是一次load掉4行的内容，以防多次访问\n\n- **对于B矩阵**\n\n  我们发现，其实对于2、3两块分块，如果在2处出现miss，那么3其实也被加入了Cache不会发生miss，所以就有了如下策略。\n\n  \n\n  **解决方案：**\n\n  \n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gpi5wquog6j30vb0t4jtx.jpg\" style=\"zoom:25%;\" />\n\n1. 我们可以先一次性Load A1、A2两块到B1、B2两块中，这样只会1次miss。\n\n2. 我们按行将A3转置到B2中， 再将B2中原来放置的A2转置到A3中 (B2 Hit -> B3 miss ->下次B2 miss之后 B2、B3在Cache中便不会miss了) 共2次miss\n3. 之后再将A4转置到B4中，这样会miss1次\n\n总共miss4次，这样一来对于8x8 的 B矩阵，相当于每个4x4只miss了一次，完成了要求。\n\n*< 代码太长见附件 >*\n\n测试一下，效果拔群！\n\n```\nfunc 0 (Transpose submission): hits:9082, misses:1163, evictions:1131\n```\n\n\n\n\n\n---\n\n#### 61x67矩阵\n\n对于这类非方阵，我们采用最简单的分块策略进行测试。\n\n|        | 4x4  | 8x8  | 16x16 | 17x17 |\n| :----: | :--: | :--: | :---: | :---: |\n| miss数 | 2425 | 2118 | 1992  | 1950  |\n\n个人测试了 4x4 \\ 8x8 \\ 16x16 发现16x16可以满足miss数小于 2k 的要求。参考网上资料[1]后，发现 17x17是最优选择，miss数为1950\n\n```c\nvoid transpose_61x67(int M, int N, int A[N][M], int B[M][N])\n{\n    int i, j, x, y, tmp;\n\n    for(i = 0; i < N; i += 17)\n        for(j = 0; j < M; j += 17)\n\t\t\tfor(x = i; x < N && x < i + 17; ++x)\n\t\t\t\tfor(y = j; y < M && y < j + 17; ++y)\n\t\t\t\t{\n\t\t\t\t\ttmp = A[x][y];\n\t\t\t\t\tB[y][x] = tmp; \n\t\t\t\t}\t\t\n}\n```\n\n\n\n----\n\n\n\n## 三、实验结论\n\n最后我们运行 ```drive.py``` 来测试我们的总分\n\n```shell\nPart A: Testing cache simulator\nRunning ./test-csim\n                        Your simulator     Reference simulator\nPoints (s,E,b)    Hits  Misses  Evicts    Hits  Misses  Evicts\n     3 (1,1,1)       9       8       6       9       8       6  traces/yi2.trace\n     3 (4,2,4)       4       5       2       4       5       2  traces/yi.trace\n     3 (2,1,4)       2       3       1       2       3       1  traces/dave.trace\n     3 (2,1,3)     167      71      67     167      71      67  traces/trans.trace\n     3 (2,2,3)     201      37      29     201      37      29  traces/trans.trace\n     3 (2,4,3)     212      26      10     212      26      10  traces/trans.trace\n     3 (5,1,5)     231       7       0     231       7       0  traces/trans.trace\n     6 (5,1,5)  265189   21775   21743  265189   21775   21743  traces/long.trace\n    27\n\n\nPart B: Testing transpose function\nRunning ./test-trans -M 32 -N 32\nRunning ./test-trans -M 64 -N 64\nRunning ./test-trans -M 61 -N 67\n\nCache Lab summary:\n                        Points   Max pts      Misses\nCsim correctness          27.0        27\nTrans perf 32x32           8.0         8         287\nTrans perf 64x64           8.0         8        1163\nTrans perf 61x67          10.0        10        1950\n          Total points    53.0        53\n```\n\n满分 53.0/53\n\n\n\n## 四、参考资料\n\n[1] *Computer Systems: A Programmer's Perspective*, 3/E (CS:APP3e). Randal E. Bryant and David R. O'Hallaron, Carnegie Mellon University\n\n[2] https://blog.csdn.net/xbb224007/article/details/81103995\n\n\n\n","source":"_posts/ICS/CacheLab.md","raw":"---\ntitle: Cache Lab 理解高速缓存\ndate: 2021-04-13 16:13:55\nindex_img: /img/ICS_Lab1/top.jpg\ncategory: [ICS]\ntags: [Cache]\n---\n\n*注：本实验报告为 CMU CSAPP CacheLab 实验报告*\n\n## 一、实验简介\n\n​\tCache Lab实验主要在于帮助学生理解高速缓存的工作方式，以及如何针对Cache编写程序。实验主体总共分为两个部分 \n\n### **PartA** \n\n编写一个Cache的模拟程序用以统计在L\\S\\M过程中Cache Hit\\Miss\\Eviction 的总数。\n\n官方给出了 csim-ref 程序，我们需要编写代码实现其功能，输出 Hit/Miss/Eviction 的总数\n\n```shell\nUsage: ./csim-ref [-hv] -s <num> -E <num> -b <num> -t <file>\nOptions:\n  -h         Print this help message.\n  -v         Optional verbose flag.\n  -s <num>   Number of set index bits.\n  -E <num>   Number of lines per set.\n  -b <num>   Number of block offset bits.\n  -t <file>  Trace file.\n\nExamples:\n  linux>  ./csim-ref -s 4 -E 1 -b 4 -t traces/yi.trace\n  linux>  ./csim-ref -v -s 8 -E 2 -b 4 -t traces/yi.trace\n```\n\n**测试方法：**\n\n​\t使用 test-csim.c 进行测试，测试器会输出你的编译器和标准结果，并进行比较计算分数。\n\n```shell\nxzy@ubuntu:~/Desktop/ICSLAB/CacheLab$ ./test-csim \n                        Your simulator     Reference simulator\nPoints (s,E,b)    Hits  Misses  Evicts    Hits  Misses  Evicts\n     3 (1,1,1)       9       8       6       9       8       6  traces/yi2.trace\n     3 (4,2,4)       4       5       2       4       5       2  traces/yi.trace\n     3 (2,1,4)       2       3       1       2       3       1  traces/dave.trace\n     3 (2,1,3)     167      71      67     167      71      67  traces/trans.trace\n     3 (2,2,3)     201      37      29     201      37      29  traces/trans.trace\n     3 (2,4,3)     212      26      10     212      26      10  traces/trans.trace\n     3 (5,1,5)     231       7       0     231       7       0  traces/trans.trace\n     6 (5,1,5)  265189   21775   21743  265189   21775   21743  traces/long.trace\n    27\n\nTEST_CSIM_RESULTS=27\n```\n\n\n\n### **PartB**\n\n编写适应Cache的矩阵转置程序，使Cache的miss数尽量的小。\n\n​\t给出总大小1kb，每个 block 为 32byte 的直接映射Cache\n\n​\t共包含3个测试、分别为 32x32 \\ 64x64 \\ 61x67 大小的矩阵\n\n**测试方法：**\n\n​\t使用 test-trans.c 进行测试\n\n```shell\nUsage: ./test-trans [-h] -M <rows> -N <cols>\nOptions:\n  -h          Print this help message.\n  -M <rows>   Number of matrix rows (max 256)\n  -N <cols>   Number of  matrix columns (max 256)\nExample: ./test-trans -M 8 -N 8\n```\n\n\n\n----\n\n\n\n## 二、实验内容\n\n### PartA\n\n- **关于 Cache 的结构组成**\n\n​\t在 PartA 中我们需要在 csim.c 中编写模拟 Cache 运行的程序。学习过CSAPP第六章我们知道，Cache 的结构是由一行一个valid位，t个tag和一个长度为B的block组成的，总共分为多个Set，每个Set有E行。总共组成 Cache 大小 $C = B \\times E \\times S$ ( valid 和 tag 不计入 )\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gphwionzxcj30e30930t7.jpg)\n\n- **关于 Evict 机制**\n\n  同时由于采取 LRU 策略 （最近最少使用策略），我们需要维护一个 timestamp 来标记其访问时间的远近。可以一开始赋值 INF，然后逐渐减小，LRUstamp 最小的，就会被 Evict。\n\n由此我们确定了 Cache 的组成形式，我们一个 Line 由 valid 位，tag位，LRUstamp，和一个B字节的 Block 组成。由于是模拟Cache，所以其实DataBlock可以不编写，但是为了尽量模拟真实Cache，还是分配了Block的内存\n\n```c\ntypedef struct \n{\n    int valid; // 0/1 : invalid/valid\n    int tag;\n    int LRUstamp; // 越小代表越早使用，可以evict\n    int* Block; // B（2^b） 字节\n} Line_t;\n```\n\n```c\n// s个Set组成Cache\ntypedef struct {\n    int S; // Set 个数 (2^s)\n    int E; // 每个 Set 中 Line 的数量\n    int B; // Block 大小 (2^b)\n    Line_t*** cache_;\n} Cache_t; \n```\n\n我在Cache中设置了S, E, B以方便管理Cache大小，不用每次传参，并编写对应设置函数。\n\n```c\nvoid initCache(const int s, const int E, const int b) \n{\n    Cache.S = (1 << s), Cache.E = E, Cache.B = (1 << b);\n}\n```\n\n\n\n- **关于内存管理**\n\n  之后便是编写函数来进行 Cache的内存分配和释放。这个没什么好说的，就是要养成分配完释放的好习惯，避免内存泄漏。\n\n  ```c\n  /* 分配 Cache */\n  void mallocCache()\n  {\n      Cache.cache_ = (Line_t***)malloc(Cache.S* sizeof(Line_t **));\n      for(int i = 0; i < Cache.S; ++i)\n          Cache.cache_[i] = (Line_t **)malloc(Cache.E * sizeof(Line_t *));\n      for(int i = 0; i < Cache.S; ++i)\n          for(int j = 0; j < Cache.E; ++j)\n              Cache.cache_[i][j] = (Line_t *)malloc(sizeof(Line_t));\n      for(int i = 0; i < Cache.S; ++i)\n          for(int j = 0; j < Cache.E; ++j) {\n              Cache.cache_[i][j]->valid = 0;\n              Cache.cache_[i][j]->tag = 0;\n              Cache.cache_[i][j]->LRUstamp = 1e9;\n              Cache.cache_[i][j]->Block = (int *)malloc(Cache.B * sizeof(int));\n          }\n  }\n  ```\n\n  ```c\n  /* 释放 Cache */\n  void freeCache()\n  {\n      for(int i = 0; i < Cache.S; ++i)\n          for(int j = 0; j < Cache.E; ++j)\n              free(Cache.cache_[i][j]->Block);\n      for(int i = 0; i < Cache.S; ++i)\n          for(int j = 0; j < Cache.E; ++j)\n              free(Cache.cache_[i][j]);\n      for(int i = 0; i < Cache.S; ++i)\n          free(Cache.cache_[i]);\n      free(Cache.cache_);\n  }\n  ```\n\n\n\n- **关于 getter 函数**\n\n  为了方便valid、tag等信息的查找，我编写了一系列getter函数。\n\n  ```c\n  /* 获得 Valid bit */\n  int getValid(const int s, const int E) {return Cache.cache_[s][E]->valid;}\n  \n  /* 获得 Tag */\n  int getTag(const int s, const int E) {return Cache.cache_[s][E]->tag;}\n  \n  /* 获得LRUstamp */\n  int getLRU(const int s, const int E) {return Cache.cache_[s][E]->LRUstamp;}\n  ```\n\n\n\n- **对于Hit和Miss的判定**\n\n  判定hit和miss，就是在Cache对应Set中对比valid和tag，如果valid为1标明有效，并且tag相同，则说明Hit，不然则Miss。\n\n  ```c\n  /* 查看是否命中 */\n  int HitOrMiss(const int s, const int tag)\n  {\n      for(int i = 0; i < Cache.E; ++i)\n          if(getValid(s, i) && getTag(s, i) == tag)\n              return i; // 命中\n      return -1; // Miss \n  }\n  ```\n\n  \n\n- **关于是否Evict**\n\n  根据上文，我们知道我们采取LRU的evict策略，那么在写的时候，如果valid位为1，而tag不一致发生写miss的情况，就要进行evict。evict的位置是LRUstamp最小的那一个。我们维护LRUstamp，在每次操作时，将其赋值为INF (1e9) 并将其余的LRUstamp减1，取最小的 LRUstamp 进行evict，用最新的 tag 和 数据 进行替换\n\n```c\n/* 更新LRU，越小越早使用 */\nvoid lruUpdate(const int s, const int E)\n{\n    Cache.cache_[s][E]->LRUstamp = 1e9;\n    for(int i = 0; i < Cache.E; ++i)\n    {\n        if(i != E)\n            Cache.cache_[s][i]->LRUstamp--;\n    }\n}\n\n/* 更新Cache */\nvoid WriteCache(const int s, const int E, const int tag)\n{\n    Eviction(s, E, tag);\n    Cache.cache_[s][E]->valid = 1;\n    Cache.cache_[s][E]->tag = tag;\n    lruUpdate(s, E);\n}\n```\n\n\n\n- 关于模拟Cache\n\n最后进行Cache的模拟，如果Hit了就值更新LRUstamp，Miss了就获取EvictionPose，并将其替换。\n\n```c\n/* 模拟Cache，获得 Hit 和 Miss 的次数 */\nvoid getAns(const int s, const int tag)\n{\n    int hit_flag = HitOrMiss(s, tag);\n    if(hit_flag != -1) { // Hit\n        Hit++;\n        if(verbose)\n            printf(\"hit \");\n        lruUpdate(s, hit_flag);\n    }\n    else  {\n        Miss++;\n        if(verbose)\n            printf(\"miss \");\n        WriteCache(s, getEvictPos(s), tag);\n    }\n}\n```\n\n\n\n最后完整代码，附于提交 ```csim.c``` 中\n\n\n\n- 完成通过\n\n```c\nYour simulator     Reference simulator\nPoints (s,E,b)    Hits  Misses  Evicts    Hits  Misses  Evicts\n     3 (1,1,1)       9       8       6       9       8       6  traces/yi2.trace\n     3 (4,2,4)       4       5       2       4       5       2  traces/yi.trace\n     3 (2,1,4)       2       3       1       2       3       1  traces/dave.trace\n     3 (2,1,3)     167      71      67     167      71      67  traces/trans.trace\n     3 (2,2,3)     201      37      29     201      37      29  traces/trans.trace\n     3 (2,4,3)     212      26      10     212      26      10  traces/trans.trace\n     3 (5,1,5)     231       7       0     231       7       0  traces/trans.trace\n     6 (5,1,5)  265189   21775   21743  265189   21775   21743  traces/long.trace\n    27\n```\n\n\n\n----\n\n\n\n### PartB\n\n​\t在完成了Cache基本的组织架构之后，我们现在要开始编写Cache友好的程序，以矩阵转置为例。源代码中包含一个最naive的矩阵转置，也是我们平常经常写的。\n\n```c\n/* \n * trans - A simple baseline transpose function, not optimized for the cache.\n */\nchar trans_desc[] = \"Simple row-wise scan transpose\";\nvoid trans(int M, int N, int A[N][M], int B[M][N])\n{\n    int i, j, tmp;\n\n    for (i = 0; i < N; i++) {\n        for (j = 0; j < M; j++) {\n            tmp = A[i][j];\n            B[j][i] = tmp;\n        }\n    }    \n}\n```\n\n测试之后会发现，对于4x4的矩阵，其miss次数有22次之多\n\n```shell\nfunc 1 (Simple row-wise scan transpose): hits:15, misses:22, evictions:19\n```\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gphxvxlx02j312d0iw40v.jpg\" style=\"zoom:50%;\" />\n\n我们可以发现，对于4x4的矩阵，由于Block大小是32bytes且为直接映射Cache，所以每8个int会在同一个Block/Set当中，4x4的矩阵被分在两个不同的 Block 中，对于A矩阵的访问是行优先的，而B矩阵的访问是列优先的。我们可以模拟这个过程\n\n> 访问到 $A_{00}$  Cache cold miss，将 $B_{A_{1}}$ 加入 Cache 中\n>\n> 访问到 $B_{00}$  由于B和A有相同的组索引，所以导致相对位置相同的地方被映射到Cache的同一组中，造成tag不一致，产生miss将会把之前Load到Cache里的A进行驱逐，将 $B_{A_{1}}$ 驱逐 将 $B_{B_{1}}$ 加入 Cache 中\n>\n> 访问到 $A_{01}$  同理，将 $B_{B_{1}}$ 驱逐 将 $B_{A_{1}}$ 加入 Cache 中\n>\n> 之后 $B_{B_{2}}$ 和  $B_{A_{1}}$ 很幸运能够不产生thrash，有几次Cache hit，但是大部分情况下，还是会发生如同上面所描述的抖动。\n\n因此，对于这种情况，我们应该如何修改代码，使其适应Cache，能够尽可能少的Miss呢？\n\n- **暴力方法**\n\n  有一种最暴力的方式，就是考虑到目前矩阵的大小比较小，所以我们可以采取定义8个局部变量的方法，一次性将一个Block全部Load到寄存器中，然后再进行转置，这样就不会发生如上面所描述的 Cache thrash。\n\n  ```c\n  void transpose_4x4(int M, int N, int A[N][M], int B[M][N])\n  {\n      int tmp0, tmp1, tmp2, tmp3, tmp4, tmp5, tmp6, tmp7;\n  \n  \tfor(int x = 0; x < 3; x += 2)\n  \t{\n  \t\ttmp0 = A[x][0], tmp1 = A[x][1], tmp2 = A[x][2], tmp3 = A[x][3];\n  \t\ttmp4 = A[x + 1][0], tmp5 = A[x + 1][1], tmp6 = A[x + 1][2], tmp7 = A[x + 1][3];\n  \n  \t\tB[0][x] = tmp0, B[1][x] = tmp1, B[2][x] = tmp2, B[3][x] = tmp3; \n  \t\tB[0][x + 1] = tmp4, B[1][x + 1] = tmp5, B[2][x + 1] = tmp6, B[3][x + 1] = tmp7; \n  \t}\n  }\n  ```\n\n  ```\n  func 0 (Transpose submission): hits:29, misses:8, evictions:6\n  ```\n\n  可以看到miss降到了8，有极大的改进，我们用partA中写的csim进行分析。\n\n  ```shell\n  xzy@ubuntu:~/Desktop/ICSLAB/CacheLab$ ./csim -v -s 5 -E 1 -b 5 -t trace.f0\n  S 18e08c,1 miss #系统miss\n  L 18e0a0,8 miss #系统miss\n  L 18e084,4 hit \n  L 18e080,4 hit \n  L 10e080,4 miss eviction \n  L 10e084,4 hit \n  L 10e088,4 hit \n  L 10e08c,4 hit \n  L 10e090,4 hit \n  L 10e094,4 hit \n  L 10e098,4 hit \n  L 10e09c,4 hit \n  S 14e080,4 miss eviction \n  S 14e090,4 hit \n  S 14e0a0,4 miss eviction # 多一次miss\n  S 14e0b0,4 hit \n  S 14e084,4 hit \n  S 14e094,4 hit \n  S 14e0a4,4 hit \n  S 14e0b4,4 hit \n  L 10e0a0,4 miss eviction \n  L 10e0a4,4 hit \n  L 10e0a8,4 hit \n  L 10e0ac,4 hit \n  L 10e0b0,4 hit \n  L 10e0b4,4 hit \n  L 10e0b8,4 hit \n  L 10e0bc,4 hit \n  S 14e088,4 hit \n  S 14e098,4 hit \n  S 14e0a8,4 miss eviction \n  S 14e0b8,4 hit \n  S 14e08c,4 hit \n  S 14e09c,4 hit \n  S 14e0ac,4 hit \n  S 14e0bc,4 hit \n  S 18e08d,1 miss eviction #系统miss\n  hits:29 misses:8 evictions:6\n  ```\n\n  可以看到除了前后3次系统固定的miss之外，距离理论下限4次还有1次，这一次发生在Store矩阵B的时候，由于B是列优先，所以在访问到$B_{B_{2}}$的时候会多发生一次miss。\n\n\t#### 32x32 矩阵转置\n\n​\t\t了解了之后我们来看32x32的矩阵转置，其正好是Cache 1kb的总大小，能够全部装进Cache。所以我们需要避免的就是连续在A,B\n\n之间切换访问相对位置相同的区域（映射到同一个Block）从而导致的Cache thrash。\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gpi2azu5g2j31dl0qz42z.jpg\" style=\"zoom:50%;\" />\n\n我们可以采取 8*8分块的方式，对于每一块中每一行属于同一个Block，经过8x8分块后我们发现，除了对角线的分块之外，其他分块的A、B互不影响，不会产生thrash。\n\n```c\nvoid transpose_32x32(int M, int N, int A[N][M], int B[M][N])\n{\n    int i, j, x, y;\n\t\tint tmp;\n  \n    for(i = 0; i < N; i += 8)\n        for(j = 0; j < M; j += 8)\n          for(x = i; x < i + 8; ++x)\n              for(y = j; y < j + 8; ++y)\n              {\n                tmp = A[x][y], B[y][x] = tmp;\n              }\n  /*\n    注意，这里应该学习示例程序中的 tmp = A[x][y], B[y][x] = tmp; \n    因为我们无法确定调用者是否会使A，B指向内存中的同一块区域从而造成意想不到的后果。\n  */\n}\n```\n\n```shell\nfunc 0 (Transpose submission): hits:1735, misses:350, evictions:318 \t# 8x8 分块\nfunc 1 (Simple row-wise scan transpose): hits:870, misses:1183, evictions:1151\t# Naive\n```\n\n可以看到相比于最初naive的版本1183miss，已经有了极大的改善，但是还是没有达到要求的小于300miss。\n\n\n\n我们可以发现，除对角线之外的分块已经达到miss的下限，所以对角线是需要解决的地方。对于对角线上的分块，我们的处理和Naive方式没有什么区别，都会造成thrash。\n\n有了前面4x4矩阵的铺垫，我们已经知道了应该如何处理这类情况，我们按照之前的解决方法类似解决。\n\n```c\nvoid transpose_32x32(int M, int N, int A[N][M], int B[M][N])\n{\n    int i, j, x, y;\n    int tmp, tmp0, tmp1, tmp2, tmp3, tmp4, tmp5, tmp6, tmp7;\n\n    for(i = 0; i < N; i += 8)\n        for(j = 0; j < M; j += 8)\n\t\t\tfor(x = i; x < i + 8; ++x)\n\t\t\t{\n\t\t\t\tif(i == j)\n\t\t\t\t{\n\t\t\t\t\ttmp0 = A[x][j], tmp1 = A[x][j + 1], tmp2 = A[x][j + 2], tmp3 = A[x][j + 3];\n\t\t\t\t\ttmp4 = A[x][j + 4], tmp5 = A[x][j + 5], tmp6 = A[x][j + 6], tmp7 = A[x][j + 7];\n\n\t\t\t\t\tB[j][x] = tmp0, B[j + 1][x] = tmp1, B[j + 2][x] = tmp2, B[j + 3][x] = tmp3; \n\t\t\t\t\tB[j + 4][x] = tmp4, B[j + 5][x] = tmp5, B[j + 6][x] = tmp6, B[j + 7][x] = tmp7; \n\t\t\t\t}\n\t\t\t\telse \n\t\t\t\t{\n\t\t\t\t\tfor(y = j; y < j + 8; ++y)\n\t\t\t\t\t{\n\t\t\t\t\t\ttmp = A[x][y], B[y][x] = tmp;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n}\n```\n\n```\nfunc 0 (Transpose submission): hits:1766, misses:287, evictions:255\n```\n\n​\t成功将miss降到了287。实际的理论下限是256，我们注意到这种操作方式A矩阵的miss已经达到了下限，而B矩阵的对角线还是会固定miss。这是因为在Load A之前，B矩阵的对角线行已经被前一个转置Load进去，所以会被evict掉，再次调用时就会产生一次Miss。所以我们可以对其进行展开，最后可以做到259次的miss（3次系统miss）由于代码可读性太低，这里不做展开。\n\n\n\n---\n\n#### 64x64矩阵转置\n\n​\t对于64x64矩阵转置，我们注意到其已经超过了Cache的大小，我们首先用8分块尝试一下。\n\n```shell\nfunc 0 (Transpose submission): hits:3586, misses:4611, evictions:4579 # 8分块\nfunc 1 (Simple row-wise scan transpose): hits:3474, misses:4723, evictions:4691 # naive\n```\n\n发现没有什么改进，这是什么原因？我们从Cache大小的角度出发\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gpi5dme0pcj31ok0tnteo.jpg)\n\n我们进行4x4分块试验一下\n\n```c\nint i, j, x, y;\n    int tmp, tmp0, tmp1, tmp2, tmp3;\n\n    for(i = 0; i < N; i += 4)\n        for(j = 0; j < M; j += 4)\n\t\t\tfor(x = i; x < i + 4; ++x)\n\t\t\t{\n\t\t\t\tif(i == j)\n\t\t\t\t{\n\t\t\t\t\ttmp0 = A[x][j], tmp1 = A[x][j + 1], tmp2 = A[x][j + 2], tmp3 = A[x][j + 3];\n\n\t\t\t\t\tB[j][x] = tmp0, B[j + 1][x] = tmp1, B[j + 2][x] = tmp2, B[j + 3][x] = tmp3; \n\t\t\t\t}\n\t\t\t\telse \n\t\t\t\t{\n\t\t\t\t\tfor(y = j; y < j + 4; ++y)\n\t\t\t\t\t{\n\t\t\t\t\t\ttmp = A[x][y], B[y][x] = tmp;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n```\n\n\n\n```shell\nfunc 0 (Transpose submission): hits:6402, misses:1795, evictions:1763\n```\n\n​\t可以看到结果好了很多，但是还是没能达到1300的要求。其原因其实还是在最开始讲的4x4分块的例子中，由于B矩阵是按列访问，在4x4分块之后，访问对角两块的时候，会每一块都会各产生2次miss，有一个小的thrash。\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gpi5iw1wfdj31or0tj0vq.jpg\" style=\"zoom:33%;\" />\n\n​\t对自己电脑寄存器数量有自信的选手可能会选择开16个临时变量来一次性完成转置，但那样太过粗暴而不稳定。我们想是否有什么办法能够使4x4区域中的miss次数降低到1次？我们回去考虑8x8的分块情况。\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gpi5pdjqnuj31tk0laq79.jpg)\n\n- **对于A矩阵**\n\n  我们的策略是一次load掉4行的内容，以防多次访问\n\n- **对于B矩阵**\n\n  我们发现，其实对于2、3两块分块，如果在2处出现miss，那么3其实也被加入了Cache不会发生miss，所以就有了如下策略。\n\n  \n\n  **解决方案：**\n\n  \n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gpi5wquog6j30vb0t4jtx.jpg\" style=\"zoom:25%;\" />\n\n1. 我们可以先一次性Load A1、A2两块到B1、B2两块中，这样只会1次miss。\n\n2. 我们按行将A3转置到B2中， 再将B2中原来放置的A2转置到A3中 (B2 Hit -> B3 miss ->下次B2 miss之后 B2、B3在Cache中便不会miss了) 共2次miss\n3. 之后再将A4转置到B4中，这样会miss1次\n\n总共miss4次，这样一来对于8x8 的 B矩阵，相当于每个4x4只miss了一次，完成了要求。\n\n*< 代码太长见附件 >*\n\n测试一下，效果拔群！\n\n```\nfunc 0 (Transpose submission): hits:9082, misses:1163, evictions:1131\n```\n\n\n\n\n\n---\n\n#### 61x67矩阵\n\n对于这类非方阵，我们采用最简单的分块策略进行测试。\n\n|        | 4x4  | 8x8  | 16x16 | 17x17 |\n| :----: | :--: | :--: | :---: | :---: |\n| miss数 | 2425 | 2118 | 1992  | 1950  |\n\n个人测试了 4x4 \\ 8x8 \\ 16x16 发现16x16可以满足miss数小于 2k 的要求。参考网上资料[1]后，发现 17x17是最优选择，miss数为1950\n\n```c\nvoid transpose_61x67(int M, int N, int A[N][M], int B[M][N])\n{\n    int i, j, x, y, tmp;\n\n    for(i = 0; i < N; i += 17)\n        for(j = 0; j < M; j += 17)\n\t\t\tfor(x = i; x < N && x < i + 17; ++x)\n\t\t\t\tfor(y = j; y < M && y < j + 17; ++y)\n\t\t\t\t{\n\t\t\t\t\ttmp = A[x][y];\n\t\t\t\t\tB[y][x] = tmp; \n\t\t\t\t}\t\t\n}\n```\n\n\n\n----\n\n\n\n## 三、实验结论\n\n最后我们运行 ```drive.py``` 来测试我们的总分\n\n```shell\nPart A: Testing cache simulator\nRunning ./test-csim\n                        Your simulator     Reference simulator\nPoints (s,E,b)    Hits  Misses  Evicts    Hits  Misses  Evicts\n     3 (1,1,1)       9       8       6       9       8       6  traces/yi2.trace\n     3 (4,2,4)       4       5       2       4       5       2  traces/yi.trace\n     3 (2,1,4)       2       3       1       2       3       1  traces/dave.trace\n     3 (2,1,3)     167      71      67     167      71      67  traces/trans.trace\n     3 (2,2,3)     201      37      29     201      37      29  traces/trans.trace\n     3 (2,4,3)     212      26      10     212      26      10  traces/trans.trace\n     3 (5,1,5)     231       7       0     231       7       0  traces/trans.trace\n     6 (5,1,5)  265189   21775   21743  265189   21775   21743  traces/long.trace\n    27\n\n\nPart B: Testing transpose function\nRunning ./test-trans -M 32 -N 32\nRunning ./test-trans -M 64 -N 64\nRunning ./test-trans -M 61 -N 67\n\nCache Lab summary:\n                        Points   Max pts      Misses\nCsim correctness          27.0        27\nTrans perf 32x32           8.0         8         287\nTrans perf 64x64           8.0         8        1163\nTrans perf 61x67          10.0        10        1950\n          Total points    53.0        53\n```\n\n满分 53.0/53\n\n\n\n## 四、参考资料\n\n[1] *Computer Systems: A Programmer's Perspective*, 3/E (CS:APP3e). Randal E. Bryant and David R. O'Hallaron, Carnegie Mellon University\n\n[2] https://blog.csdn.net/xbb224007/article/details/81103995\n\n\n\n","slug":"ICS/CacheLab","published":1,"updated":"2026-02-03T05:42:14.431Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvc000z7uit8vmm8lia","content":"<p><em>注：本实验报告为 CMU CSAPP CacheLab 实验报告</em></p>\n<h2 id=\"一、实验简介\"><a href=\"#一、实验简介\" class=\"headerlink\" title=\"一、实验简介\"></a>一、实验简介</h2><p>​    Cache Lab实验主要在于帮助学生理解高速缓存的工作方式，以及如何针对Cache编写程序。实验主体总共分为两个部分 </p>\n<h3 id=\"PartA\"><a href=\"#PartA\" class=\"headerlink\" title=\"PartA\"></a><strong>PartA</strong></h3><p>编写一个Cache的模拟程序用以统计在L\\S\\M过程中Cache Hit\\Miss\\Eviction 的总数。</p>\n<p>官方给出了 csim-ref 程序，我们需要编写代码实现其功能，输出 Hit/Miss/Eviction 的总数</p>\n<pre><code class=\"hljs shell\">Usage: ./csim-ref [-hv] -s &lt;num&gt; -E &lt;num&gt; -b &lt;num&gt; -t &lt;file&gt;\nOptions:\n  -h         Print this help message.\n  -v         Optional verbose flag.\n  -s &lt;num&gt;   Number of set index bits.\n  -E &lt;num&gt;   Number of lines per set.\n  -b &lt;num&gt;   Number of block offset bits.\n  -t &lt;file&gt;  Trace file.\n\nExamples:\n<span class=\"hljs-meta\">  linux&gt;</span><span class=\"bash\">  ./csim-ref -s 4 -E 1 -b 4 -t traces/yi.trace</span>\n<span class=\"hljs-meta\">  linux&gt;</span><span class=\"bash\">  ./csim-ref -v -s 8 -E 2 -b 4 -t traces/yi.trace</span></code></pre>\n<p><strong>测试方法：</strong></p>\n<p>​    使用 test-csim.c 进行测试，测试器会输出你的编译器和标准结果，并进行比较计算分数。</p>\n<pre><code class=\"hljs shell\">xzy@ubuntu:~/Desktop/ICSLAB/CacheLab$ ./test-csim \n                        Your simulator     Reference simulator\nPoints (s,E,b)    Hits  Misses  Evicts    Hits  Misses  Evicts\n     3 (1,1,1)       9       8       6       9       8       6  traces/yi2.trace\n     3 (4,2,4)       4       5       2       4       5       2  traces/yi.trace\n     3 (2,1,4)       2       3       1       2       3       1  traces/dave.trace\n     3 (2,1,3)     167      71      67     167      71      67  traces/trans.trace\n     3 (2,2,3)     201      37      29     201      37      29  traces/trans.trace\n     3 (2,4,3)     212      26      10     212      26      10  traces/trans.trace\n     3 (5,1,5)     231       7       0     231       7       0  traces/trans.trace\n     6 (5,1,5)  265189   21775   21743  265189   21775   21743  traces/long.trace\n    27\n\nTEST_CSIM_RESULTS=27</code></pre>\n<h3 id=\"PartB\"><a href=\"#PartB\" class=\"headerlink\" title=\"PartB\"></a><strong>PartB</strong></h3><p>编写适应Cache的矩阵转置程序，使Cache的miss数尽量的小。</p>\n<p>​    给出总大小1kb，每个 block 为 32byte 的直接映射Cache</p>\n<p>​    共包含3个测试、分别为 32x32 \\ 64x64 \\ 61x67 大小的矩阵</p>\n<p><strong>测试方法：</strong></p>\n<p>​    使用 test-trans.c 进行测试</p>\n<pre><code class=\"hljs shell\">Usage: ./test-trans [-h] -M &lt;rows&gt; -N &lt;cols&gt;\nOptions:\n  -h          Print this help message.\n  -M &lt;rows&gt;   Number of matrix rows (max 256)\n  -N &lt;cols&gt;   Number of  matrix columns (max 256)\nExample: ./test-trans -M 8 -N 8</code></pre>\n<hr>\n<h2 id=\"二、实验内容\"><a href=\"#二、实验内容\" class=\"headerlink\" title=\"二、实验内容\"></a>二、实验内容</h2><h3 id=\"PartA-1\"><a href=\"#PartA-1\" class=\"headerlink\" title=\"PartA\"></a>PartA</h3><ul>\n<li><strong>关于 Cache 的结构组成</strong></li>\n</ul>\n<p>​    在 PartA 中我们需要在 csim.c 中编写模拟 Cache 运行的程序。学习过CSAPP第六章我们知道，Cache 的结构是由一行一个valid位，t个tag和一个长度为B的block组成的，总共分为多个Set，每个Set有E行。总共组成 Cache 大小 $C = B \\times E \\times S$ ( valid 和 tag 不计入 )</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gphwionzxcj30e30930t7.jpg\" alt></p>\n<ul>\n<li><p><strong>关于 Evict 机制</strong></p>\n<p>同时由于采取 LRU 策略 （最近最少使用策略），我们需要维护一个 timestamp 来标记其访问时间的远近。可以一开始赋值 INF，然后逐渐减小，LRUstamp 最小的，就会被 Evict。</p>\n</li>\n</ul>\n<p>由此我们确定了 Cache 的组成形式，我们一个 Line 由 valid 位，tag位，LRUstamp，和一个B字节的 Block 组成。由于是模拟Cache，所以其实DataBlock可以不编写，但是为了尽量模拟真实Cache，还是分配了Block的内存</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-keyword\">typedef</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> </span>\n<span class=\"hljs-class\">&#123;</span>\n    <span class=\"hljs-keyword\">int</span> valid; <span class=\"hljs-comment\">// 0/1 : invalid/valid</span>\n    <span class=\"hljs-keyword\">int</span> tag;\n    <span class=\"hljs-keyword\">int</span> LRUstamp; <span class=\"hljs-comment\">// 越小代表越早使用，可以evict</span>\n    <span class=\"hljs-keyword\">int</span>* Block; <span class=\"hljs-comment\">// B（2^b） 字节</span>\n&#125; Line_t;</code></pre>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">// s个Set组成Cache</span>\n<span class=\"hljs-keyword\">typedef</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> &#123;</span>\n    <span class=\"hljs-keyword\">int</span> S; <span class=\"hljs-comment\">// Set 个数 (2^s)</span>\n    <span class=\"hljs-keyword\">int</span> E; <span class=\"hljs-comment\">// 每个 Set 中 Line 的数量</span>\n    <span class=\"hljs-keyword\">int</span> B; <span class=\"hljs-comment\">// Block 大小 (2^b)</span>\n    Line_t*** cache_;\n&#125; Cache_t;</code></pre>\n<p>我在Cache中设置了S, E, B以方便管理Cache大小，不用每次传参，并编写对应设置函数。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">initCache</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> s, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> E, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> b)</span> </span>\n<span class=\"hljs-function\"></span>&#123;\n    Cache.S = (<span class=\"hljs-number\">1</span> &lt;&lt; s), Cache.E = E, Cache.B = (<span class=\"hljs-number\">1</span> &lt;&lt; b);\n&#125;</code></pre>\n<ul>\n<li><p><strong>关于内存管理</strong></p>\n<p>之后便是编写函数来进行 Cache的内存分配和释放。这个没什么好说的，就是要养成分配完释放的好习惯，避免内存泄漏。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">/* 分配 Cache */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">mallocCache</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    Cache.cache_ = (Line_t***)<span class=\"hljs-built_in\">malloc</span>(Cache.S* <span class=\"hljs-keyword\">sizeof</span>(Line_t **));\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; Cache.S; ++i)\n        Cache.cache_[i] = (Line_t **)<span class=\"hljs-built_in\">malloc</span>(Cache.E * <span class=\"hljs-keyword\">sizeof</span>(Line_t *));\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; Cache.S; ++i)\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; Cache.E; ++j)\n            Cache.cache_[i][j] = (Line_t *)<span class=\"hljs-built_in\">malloc</span>(<span class=\"hljs-keyword\">sizeof</span>(Line_t));\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; Cache.S; ++i)\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; Cache.E; ++j) &#123;\n            Cache.cache_[i][j]-&gt;valid = <span class=\"hljs-number\">0</span>;\n            Cache.cache_[i][j]-&gt;tag = <span class=\"hljs-number\">0</span>;\n            Cache.cache_[i][j]-&gt;LRUstamp = <span class=\"hljs-number\">1e9</span>;\n            Cache.cache_[i][j]-&gt;Block = (<span class=\"hljs-keyword\">int</span> *)<span class=\"hljs-built_in\">malloc</span>(Cache.B * <span class=\"hljs-keyword\">sizeof</span>(<span class=\"hljs-keyword\">int</span>));\n        &#125;\n&#125;</code></pre>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">/* 释放 Cache */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">freeCache</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; Cache.S; ++i)\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; Cache.E; ++j)\n            <span class=\"hljs-built_in\">free</span>(Cache.cache_[i][j]-&gt;Block);\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; Cache.S; ++i)\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; Cache.E; ++j)\n            <span class=\"hljs-built_in\">free</span>(Cache.cache_[i][j]);\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; Cache.S; ++i)\n        <span class=\"hljs-built_in\">free</span>(Cache.cache_[i]);\n    <span class=\"hljs-built_in\">free</span>(Cache.cache_);\n&#125;</code></pre>\n</li>\n</ul>\n<ul>\n<li><p><strong>关于 getter 函数</strong></p>\n<p>为了方便valid、tag等信息的查找，我编写了一系列getter函数。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">/* 获得 Valid bit */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">getValid</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> s, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> E)</span> </span>&#123;<span class=\"hljs-keyword\">return</span> Cache.cache_[s][E]-&gt;valid;&#125;\n\n<span class=\"hljs-comment\">/* 获得 Tag */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">getTag</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> s, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> E)</span> </span>&#123;<span class=\"hljs-keyword\">return</span> Cache.cache_[s][E]-&gt;tag;&#125;\n\n<span class=\"hljs-comment\">/* 获得LRUstamp */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">getLRU</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> s, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> E)</span> </span>&#123;<span class=\"hljs-keyword\">return</span> Cache.cache_[s][E]-&gt;LRUstamp;&#125;</code></pre>\n</li>\n</ul>\n<ul>\n<li><p><strong>对于Hit和Miss的判定</strong></p>\n<p>判定hit和miss，就是在Cache对应Set中对比valid和tag，如果valid为1标明有效，并且tag相同，则说明Hit，不然则Miss。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">/* 查看是否命中 */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">HitOrMiss</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> s, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> tag)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; Cache.E; ++i)\n        <span class=\"hljs-keyword\">if</span>(getValid(s, i) &amp;&amp; getTag(s, i) == tag)\n            <span class=\"hljs-keyword\">return</span> i; <span class=\"hljs-comment\">// 命中</span>\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">-1</span>; <span class=\"hljs-comment\">// Miss </span>\n&#125;</code></pre>\n</li>\n</ul>\n<ul>\n<li><p><strong>关于是否Evict</strong></p>\n<p>根据上文，我们知道我们采取LRU的evict策略，那么在写的时候，如果valid位为1，而tag不一致发生写miss的情况，就要进行evict。evict的位置是LRUstamp最小的那一个。我们维护LRUstamp，在每次操作时，将其赋值为INF (1e9) 并将其余的LRUstamp减1，取最小的 LRUstamp 进行evict，用最新的 tag 和 数据 进行替换</p>\n</li>\n</ul>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">/* 更新LRU，越小越早使用 */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">lruUpdate</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> s, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> E)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    Cache.cache_[s][E]-&gt;LRUstamp = <span class=\"hljs-number\">1e9</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; Cache.E; ++i)\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(i != E)\n            Cache.cache_[s][i]-&gt;LRUstamp--;\n    &#125;\n&#125;\n\n<span class=\"hljs-comment\">/* 更新Cache */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">WriteCache</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> s, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> E, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> tag)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    Eviction(s, E, tag);\n    Cache.cache_[s][E]-&gt;valid = <span class=\"hljs-number\">1</span>;\n    Cache.cache_[s][E]-&gt;tag = tag;\n    lruUpdate(s, E);\n&#125;</code></pre>\n<ul>\n<li>关于模拟Cache</li>\n</ul>\n<p>最后进行Cache的模拟，如果Hit了就值更新LRUstamp，Miss了就获取EvictionPose，并将其替换。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">/* 模拟Cache，获得 Hit 和 Miss 的次数 */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">getAns</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> s, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> tag)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> hit_flag = HitOrMiss(s, tag);\n    <span class=\"hljs-keyword\">if</span>(hit_flag != <span class=\"hljs-number\">-1</span>) &#123; <span class=\"hljs-comment\">// Hit</span>\n        Hit++;\n        <span class=\"hljs-keyword\">if</span>(verbose)\n            <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;hit &quot;</span>);\n        lruUpdate(s, hit_flag);\n    &#125;\n    <span class=\"hljs-keyword\">else</span>  &#123;\n        Miss++;\n        <span class=\"hljs-keyword\">if</span>(verbose)\n            <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;miss &quot;</span>);\n        WriteCache(s, getEvictPos(s), tag);\n    &#125;\n&#125;</code></pre>\n<p>最后完整代码，附于提交 <code>csim.c</code> 中</p>\n<ul>\n<li>完成通过</li>\n</ul>\n<pre><code class=\"hljs c\">Your simulator     Reference simulator\nPoints (s,E,b)    Hits  Misses  Evicts    Hits  Misses  Evicts\n     <span class=\"hljs-number\">3</span> (<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>)       <span class=\"hljs-number\">9</span>       <span class=\"hljs-number\">8</span>       <span class=\"hljs-number\">6</span>       <span class=\"hljs-number\">9</span>       <span class=\"hljs-number\">8</span>       <span class=\"hljs-number\">6</span>  traces/yi2.trace\n     <span class=\"hljs-number\">3</span> (<span class=\"hljs-number\">4</span>,<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">4</span>)       <span class=\"hljs-number\">4</span>       <span class=\"hljs-number\">5</span>       <span class=\"hljs-number\">2</span>       <span class=\"hljs-number\">4</span>       <span class=\"hljs-number\">5</span>       <span class=\"hljs-number\">2</span>  traces/yi.trace\n     <span class=\"hljs-number\">3</span> (<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">4</span>)       <span class=\"hljs-number\">2</span>       <span class=\"hljs-number\">3</span>       <span class=\"hljs-number\">1</span>       <span class=\"hljs-number\">2</span>       <span class=\"hljs-number\">3</span>       <span class=\"hljs-number\">1</span>  traces/dave.trace\n     <span class=\"hljs-number\">3</span> (<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">3</span>)     <span class=\"hljs-number\">167</span>      <span class=\"hljs-number\">71</span>      <span class=\"hljs-number\">67</span>     <span class=\"hljs-number\">167</span>      <span class=\"hljs-number\">71</span>      <span class=\"hljs-number\">67</span>  traces/trans.trace\n     <span class=\"hljs-number\">3</span> (<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">3</span>)     <span class=\"hljs-number\">201</span>      <span class=\"hljs-number\">37</span>      <span class=\"hljs-number\">29</span>     <span class=\"hljs-number\">201</span>      <span class=\"hljs-number\">37</span>      <span class=\"hljs-number\">29</span>  traces/trans.trace\n     <span class=\"hljs-number\">3</span> (<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">4</span>,<span class=\"hljs-number\">3</span>)     <span class=\"hljs-number\">212</span>      <span class=\"hljs-number\">26</span>      <span class=\"hljs-number\">10</span>     <span class=\"hljs-number\">212</span>      <span class=\"hljs-number\">26</span>      <span class=\"hljs-number\">10</span>  traces/trans.trace\n     <span class=\"hljs-number\">3</span> (<span class=\"hljs-number\">5</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">5</span>)     <span class=\"hljs-number\">231</span>       <span class=\"hljs-number\">7</span>       <span class=\"hljs-number\">0</span>     <span class=\"hljs-number\">231</span>       <span class=\"hljs-number\">7</span>       <span class=\"hljs-number\">0</span>  traces/trans.trace\n     <span class=\"hljs-number\">6</span> (<span class=\"hljs-number\">5</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">5</span>)  <span class=\"hljs-number\">265189</span>   <span class=\"hljs-number\">21775</span>   <span class=\"hljs-number\">21743</span>  <span class=\"hljs-number\">265189</span>   <span class=\"hljs-number\">21775</span>   <span class=\"hljs-number\">21743</span>  traces/<span class=\"hljs-keyword\">long</span>.trace\n    <span class=\"hljs-number\">27</span></code></pre>\n<hr>\n<h3 id=\"PartB-1\"><a href=\"#PartB-1\" class=\"headerlink\" title=\"PartB\"></a>PartB</h3><p>​    在完成了Cache基本的组织架构之后，我们现在要开始编写Cache友好的程序，以矩阵转置为例。源代码中包含一个最naive的矩阵转置，也是我们平常经常写的。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">/* </span>\n<span class=\"hljs-comment\"> * trans - A simple baseline transpose function, not optimized for the cache.</span>\n<span class=\"hljs-comment\"> */</span>\n<span class=\"hljs-keyword\">char</span> trans_desc[] = <span class=\"hljs-string\">&quot;Simple row-wise scan transpose&quot;</span>;\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">trans</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> M, <span class=\"hljs-keyword\">int</span> N, <span class=\"hljs-keyword\">int</span> A[N][M], <span class=\"hljs-keyword\">int</span> B[M][N])</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> i, j, tmp;\n\n    <span class=\"hljs-keyword\">for</span> (i = <span class=\"hljs-number\">0</span>; i &lt; N; i++) &#123;\n        <span class=\"hljs-keyword\">for</span> (j = <span class=\"hljs-number\">0</span>; j &lt; M; j++) &#123;\n            tmp = A[i][j];\n            B[j][i] = tmp;\n        &#125;\n    &#125;    \n&#125;</code></pre>\n<p>测试之后会发现，对于4x4的矩阵，其miss次数有22次之多</p>\n<pre><code class=\"hljs shell\">func 1 (Simple row-wise scan transpose): hits:15, misses:22, evictions:19</code></pre>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gphxvxlx02j312d0iw40v.jpg\" style=\"zoom:50%;\"></p>\n<p>我们可以发现，对于4x4的矩阵，由于Block大小是32bytes且为直接映射Cache，所以每8个int会在同一个Block/Set当中，4x4的矩阵被分在两个不同的 Block 中，对于A矩阵的访问是行优先的，而B矩阵的访问是列优先的。我们可以模拟这个过程</p>\n<blockquote>\n<p>访问到 $A<em>{00}$  Cache cold miss，将 $B</em>{A_{1}}$ 加入 Cache 中</p>\n<p>访问到 $B<em>{00}$  由于B和A有相同的组索引，所以导致相对位置相同的地方被映射到Cache的同一组中，造成tag不一致，产生miss将会把之前Load到Cache里的A进行驱逐，将 $B</em>{A<em>{1}}$ 驱逐 将 $B</em>{B_{1}}$ 加入 Cache 中</p>\n<p>访问到 $A<em>{01}$  同理，将 $B</em>{B<em>{1}}$ 驱逐 将 $B</em>{A_{1}}$ 加入 Cache 中</p>\n<p>之后 $B<em>{B</em>{2}}$ 和  $B<em>{A</em>{1}}$ 很幸运能够不产生thrash，有几次Cache hit，但是大部分情况下，还是会发生如同上面所描述的抖动。</p>\n</blockquote>\n<p>因此，对于这种情况，我们应该如何修改代码，使其适应Cache，能够尽可能少的Miss呢？</p>\n<ul>\n<li><p><strong>暴力方法</strong></p>\n<p>有一种最暴力的方式，就是考虑到目前矩阵的大小比较小，所以我们可以采取定义8个局部变量的方法，一次性将一个Block全部Load到寄存器中，然后再进行转置，这样就不会发生如上面所描述的 Cache thrash。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">transpose_4x4</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> M, <span class=\"hljs-keyword\">int</span> N, <span class=\"hljs-keyword\">int</span> A[N][M], <span class=\"hljs-keyword\">int</span> B[M][N])</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> tmp0, tmp1, tmp2, tmp3, tmp4, tmp5, tmp6, tmp7;\n\n\t<span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> x = <span class=\"hljs-number\">0</span>; x &lt; <span class=\"hljs-number\">3</span>; x += <span class=\"hljs-number\">2</span>)\n\t&#123;\n\t\ttmp0 = A[x][<span class=\"hljs-number\">0</span>], tmp1 = A[x][<span class=\"hljs-number\">1</span>], tmp2 = A[x][<span class=\"hljs-number\">2</span>], tmp3 = A[x][<span class=\"hljs-number\">3</span>];\n\t\ttmp4 = A[x + <span class=\"hljs-number\">1</span>][<span class=\"hljs-number\">0</span>], tmp5 = A[x + <span class=\"hljs-number\">1</span>][<span class=\"hljs-number\">1</span>], tmp6 = A[x + <span class=\"hljs-number\">1</span>][<span class=\"hljs-number\">2</span>], tmp7 = A[x + <span class=\"hljs-number\">1</span>][<span class=\"hljs-number\">3</span>];\n\n\t\tB[<span class=\"hljs-number\">0</span>][x] = tmp0, B[<span class=\"hljs-number\">1</span>][x] = tmp1, B[<span class=\"hljs-number\">2</span>][x] = tmp2, B[<span class=\"hljs-number\">3</span>][x] = tmp3; \n\t\tB[<span class=\"hljs-number\">0</span>][x + <span class=\"hljs-number\">1</span>] = tmp4, B[<span class=\"hljs-number\">1</span>][x + <span class=\"hljs-number\">1</span>] = tmp5, B[<span class=\"hljs-number\">2</span>][x + <span class=\"hljs-number\">1</span>] = tmp6, B[<span class=\"hljs-number\">3</span>][x + <span class=\"hljs-number\">1</span>] = tmp7; \n\t&#125;\n&#125;</code></pre>\n<pre><code class=\"hljs angelscript\">func <span class=\"hljs-number\">0</span> (Transpose submission): hits:<span class=\"hljs-number\">29</span>, misses:<span class=\"hljs-number\">8</span>, evictions:<span class=\"hljs-number\">6</span></code></pre>\n<p>可以看到miss降到了8，有极大的改进，我们用partA中写的csim进行分析。</p>\n<pre><code class=\"hljs shell\">xzy@ubuntu:~/Desktop/ICSLAB/CacheLab$ ./csim -v -s 5 -E 1 -b 5 -t trace.f0\nS 18e08c,1 miss #系统miss\nL 18e0a0,8 miss #系统miss\nL 18e084,4 hit \nL 18e080,4 hit \nL 10e080,4 miss eviction \nL 10e084,4 hit \nL 10e088,4 hit \nL 10e08c,4 hit \nL 10e090,4 hit \nL 10e094,4 hit \nL 10e098,4 hit \nL 10e09c,4 hit \nS 14e080,4 miss eviction \nS 14e090,4 hit \nS 14e0a0,4 miss eviction # 多一次miss\nS 14e0b0,4 hit \nS 14e084,4 hit \nS 14e094,4 hit \nS 14e0a4,4 hit \nS 14e0b4,4 hit \nL 10e0a0,4 miss eviction \nL 10e0a4,4 hit \nL 10e0a8,4 hit \nL 10e0ac,4 hit \nL 10e0b0,4 hit \nL 10e0b4,4 hit \nL 10e0b8,4 hit \nL 10e0bc,4 hit \nS 14e088,4 hit \nS 14e098,4 hit \nS 14e0a8,4 miss eviction \nS 14e0b8,4 hit \nS 14e08c,4 hit \nS 14e09c,4 hit \nS 14e0ac,4 hit \nS 14e0bc,4 hit \nS 18e08d,1 miss eviction #系统miss\nhits:29 misses:8 evictions:6</code></pre>\n<p>可以看到除了前后3次系统固定的miss之外，距离理论下限4次还有1次，这一次发生在Store矩阵B的时候，由于B是列优先，所以在访问到$B<em>{B</em>{2}}$的时候会多发生一次miss。</p>\n<h4 id=\"32x32-矩阵转置\"><a href=\"#32x32-矩阵转置\" class=\"headerlink\" title=\"32x32 矩阵转置\"></a>32x32 矩阵转置</h4></li>\n</ul>\n<p>​        了解了之后我们来看32x32的矩阵转置，其正好是Cache 1kb的总大小，能够全部装进Cache。所以我们需要避免的就是连续在A,B</p>\n<p>之间切换访问相对位置相同的区域（映射到同一个Block）从而导致的Cache thrash。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gpi2azu5g2j31dl0qz42z.jpg\" style=\"zoom:50%;\"></p>\n<p>我们可以采取 8*8分块的方式，对于每一块中每一行属于同一个Block，经过8x8分块后我们发现，除了对角线的分块之外，其他分块的A、B互不影响，不会产生thrash。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">transpose_32x32</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> M, <span class=\"hljs-keyword\">int</span> N, <span class=\"hljs-keyword\">int</span> A[N][M], <span class=\"hljs-keyword\">int</span> B[M][N])</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> i, j, x, y;\n\t\t<span class=\"hljs-keyword\">int</span> tmp;\n  \n    <span class=\"hljs-keyword\">for</span>(i = <span class=\"hljs-number\">0</span>; i &lt; N; i += <span class=\"hljs-number\">8</span>)\n        <span class=\"hljs-keyword\">for</span>(j = <span class=\"hljs-number\">0</span>; j &lt; M; j += <span class=\"hljs-number\">8</span>)\n          <span class=\"hljs-keyword\">for</span>(x = i; x &lt; i + <span class=\"hljs-number\">8</span>; ++x)\n              <span class=\"hljs-keyword\">for</span>(y = j; y &lt; j + <span class=\"hljs-number\">8</span>; ++y)\n              &#123;\n                tmp = A[x][y], B[y][x] = tmp;\n              &#125;\n  <span class=\"hljs-comment\">/*</span>\n<span class=\"hljs-comment\">    注意，这里应该学习示例程序中的 tmp = A[x][y], B[y][x] = tmp; </span>\n<span class=\"hljs-comment\">    因为我们无法确定调用者是否会使A，B指向内存中的同一块区域从而造成意想不到的后果。</span>\n<span class=\"hljs-comment\">  */</span>\n&#125;</code></pre>\n<pre><code class=\"hljs shell\">func 0 (Transpose submission): hits:1735, misses:350, evictions:318 \t# 8x8 分块\nfunc 1 (Simple row-wise scan transpose): hits:870, misses:1183, evictions:1151\t# Naive</code></pre>\n<p>可以看到相比于最初naive的版本1183miss，已经有了极大的改善，但是还是没有达到要求的小于300miss。</p>\n<p>我们可以发现，除对角线之外的分块已经达到miss的下限，所以对角线是需要解决的地方。对于对角线上的分块，我们的处理和Naive方式没有什么区别，都会造成thrash。</p>\n<p>有了前面4x4矩阵的铺垫，我们已经知道了应该如何处理这类情况，我们按照之前的解决方法类似解决。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">transpose_32x32</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> M, <span class=\"hljs-keyword\">int</span> N, <span class=\"hljs-keyword\">int</span> A[N][M], <span class=\"hljs-keyword\">int</span> B[M][N])</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> i, j, x, y;\n    <span class=\"hljs-keyword\">int</span> tmp, tmp0, tmp1, tmp2, tmp3, tmp4, tmp5, tmp6, tmp7;\n\n    <span class=\"hljs-keyword\">for</span>(i = <span class=\"hljs-number\">0</span>; i &lt; N; i += <span class=\"hljs-number\">8</span>)\n        <span class=\"hljs-keyword\">for</span>(j = <span class=\"hljs-number\">0</span>; j &lt; M; j += <span class=\"hljs-number\">8</span>)\n\t\t\t<span class=\"hljs-keyword\">for</span>(x = i; x &lt; i + <span class=\"hljs-number\">8</span>; ++x)\n\t\t\t&#123;\n\t\t\t\t<span class=\"hljs-keyword\">if</span>(i == j)\n\t\t\t\t&#123;\n\t\t\t\t\ttmp0 = A[x][j], tmp1 = A[x][j + <span class=\"hljs-number\">1</span>], tmp2 = A[x][j + <span class=\"hljs-number\">2</span>], tmp3 = A[x][j + <span class=\"hljs-number\">3</span>];\n\t\t\t\t\ttmp4 = A[x][j + <span class=\"hljs-number\">4</span>], tmp5 = A[x][j + <span class=\"hljs-number\">5</span>], tmp6 = A[x][j + <span class=\"hljs-number\">6</span>], tmp7 = A[x][j + <span class=\"hljs-number\">7</span>];\n\n\t\t\t\t\tB[j][x] = tmp0, B[j + <span class=\"hljs-number\">1</span>][x] = tmp1, B[j + <span class=\"hljs-number\">2</span>][x] = tmp2, B[j + <span class=\"hljs-number\">3</span>][x] = tmp3; \n\t\t\t\t\tB[j + <span class=\"hljs-number\">4</span>][x] = tmp4, B[j + <span class=\"hljs-number\">5</span>][x] = tmp5, B[j + <span class=\"hljs-number\">6</span>][x] = tmp6, B[j + <span class=\"hljs-number\">7</span>][x] = tmp7; \n\t\t\t\t&#125;\n\t\t\t\t<span class=\"hljs-keyword\">else</span> \n\t\t\t\t&#123;\n\t\t\t\t\t<span class=\"hljs-keyword\">for</span>(y = j; y &lt; j + <span class=\"hljs-number\">8</span>; ++y)\n\t\t\t\t\t&#123;\n\t\t\t\t\t\ttmp = A[x][y], B[y][x] = tmp;\n\t\t\t\t\t&#125;\n\t\t\t\t&#125;\n\t\t\t&#125;\n&#125;</code></pre>\n<pre><code class=\"hljs angelscript\">func <span class=\"hljs-number\">0</span> (Transpose submission): hits:<span class=\"hljs-number\">1766</span>, misses:<span class=\"hljs-number\">287</span>, evictions:<span class=\"hljs-number\">255</span></code></pre>\n<p>​    成功将miss降到了287。实际的理论下限是256，我们注意到这种操作方式A矩阵的miss已经达到了下限，而B矩阵的对角线还是会固定miss。这是因为在Load A之前，B矩阵的对角线行已经被前一个转置Load进去，所以会被evict掉，再次调用时就会产生一次Miss。所以我们可以对其进行展开，最后可以做到259次的miss（3次系统miss）由于代码可读性太低，这里不做展开。</p>\n<hr>\n<h4 id=\"64x64矩阵转置\"><a href=\"#64x64矩阵转置\" class=\"headerlink\" title=\"64x64矩阵转置\"></a>64x64矩阵转置</h4><p>​    对于64x64矩阵转置，我们注意到其已经超过了Cache的大小，我们首先用8分块尝试一下。</p>\n<pre><code class=\"hljs shell\">func 0 (Transpose submission): hits:3586, misses:4611, evictions:4579 # 8分块\nfunc 1 (Simple row-wise scan transpose): hits:3474, misses:4723, evictions:4691 # naive</code></pre>\n<p>发现没有什么改进，这是什么原因？我们从Cache大小的角度出发</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gpi5dme0pcj31ok0tnteo.jpg\" alt></p>\n<p>我们进行4x4分块试验一下</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-keyword\">int</span> i, j, x, y;\n    <span class=\"hljs-keyword\">int</span> tmp, tmp0, tmp1, tmp2, tmp3;\n\n    <span class=\"hljs-keyword\">for</span>(i = <span class=\"hljs-number\">0</span>; i &lt; N; i += <span class=\"hljs-number\">4</span>)\n        <span class=\"hljs-keyword\">for</span>(j = <span class=\"hljs-number\">0</span>; j &lt; M; j += <span class=\"hljs-number\">4</span>)\n\t\t\t<span class=\"hljs-keyword\">for</span>(x = i; x &lt; i + <span class=\"hljs-number\">4</span>; ++x)\n\t\t\t&#123;\n\t\t\t\t<span class=\"hljs-keyword\">if</span>(i == j)\n\t\t\t\t&#123;\n\t\t\t\t\ttmp0 = A[x][j], tmp1 = A[x][j + <span class=\"hljs-number\">1</span>], tmp2 = A[x][j + <span class=\"hljs-number\">2</span>], tmp3 = A[x][j + <span class=\"hljs-number\">3</span>];\n\n\t\t\t\t\tB[j][x] = tmp0, B[j + <span class=\"hljs-number\">1</span>][x] = tmp1, B[j + <span class=\"hljs-number\">2</span>][x] = tmp2, B[j + <span class=\"hljs-number\">3</span>][x] = tmp3; \n\t\t\t\t&#125;\n\t\t\t\t<span class=\"hljs-keyword\">else</span> \n\t\t\t\t&#123;\n\t\t\t\t\t<span class=\"hljs-keyword\">for</span>(y = j; y &lt; j + <span class=\"hljs-number\">4</span>; ++y)\n\t\t\t\t\t&#123;\n\t\t\t\t\t\ttmp = A[x][y], B[y][x] = tmp;\n\t\t\t\t\t&#125;\n\t\t\t\t&#125;\n\t\t\t&#125;</code></pre>\n<pre><code class=\"hljs shell\">func 0 (Transpose submission): hits:6402, misses:1795, evictions:1763</code></pre>\n<p>​    可以看到结果好了很多，但是还是没能达到1300的要求。其原因其实还是在最开始讲的4x4分块的例子中，由于B矩阵是按列访问，在4x4分块之后，访问对角两块的时候，会每一块都会各产生2次miss，有一个小的thrash。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gpi5iw1wfdj31or0tj0vq.jpg\" style=\"zoom:33%;\"></p>\n<p>​    对自己电脑寄存器数量有自信的选手可能会选择开16个临时变量来一次性完成转置，但那样太过粗暴而不稳定。我们想是否有什么办法能够使4x4区域中的miss次数降低到1次？我们回去考虑8x8的分块情况。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gpi5pdjqnuj31tk0laq79.jpg\" alt></p>\n<ul>\n<li><p><strong>对于A矩阵</strong></p>\n<p>我们的策略是一次load掉4行的内容，以防多次访问</p>\n</li>\n<li><p><strong>对于B矩阵</strong></p>\n<p>我们发现，其实对于2、3两块分块，如果在2处出现miss，那么3其实也被加入了Cache不会发生miss，所以就有了如下策略。</p>\n</li>\n</ul>\n<p>  <strong>解决方案：</strong></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gpi5wquog6j30vb0t4jtx.jpg\" style=\"zoom:25%;\"></p>\n<ol>\n<li><p>我们可以先一次性Load A1、A2两块到B1、B2两块中，这样只会1次miss。</p>\n</li>\n<li><p>我们按行将A3转置到B2中， 再将B2中原来放置的A2转置到A3中 (B2 Hit -&gt; B3 miss -&gt;下次B2 miss之后 B2、B3在Cache中便不会miss了) 共2次miss</p>\n</li>\n<li>之后再将A4转置到B4中，这样会miss1次</li>\n</ol>\n<p>总共miss4次，这样一来对于8x8 的 B矩阵，相当于每个4x4只miss了一次，完成了要求。</p>\n<p><em>&lt; 代码太长见附件 &gt;</em></p>\n<p>测试一下，效果拔群！</p>\n<pre><code class=\"hljs angelscript\">func <span class=\"hljs-number\">0</span> (Transpose submission): hits:<span class=\"hljs-number\">9082</span>, misses:<span class=\"hljs-number\">1163</span>, evictions:<span class=\"hljs-number\">1131</span></code></pre>\n<hr>\n<h4 id=\"61x67矩阵\"><a href=\"#61x67矩阵\" class=\"headerlink\" title=\"61x67矩阵\"></a>61x67矩阵</h4><p>对于这类非方阵，我们采用最简单的分块策略进行测试。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"></th>\n<th style=\"text-align:center\">4x4</th>\n<th style=\"text-align:center\">8x8</th>\n<th style=\"text-align:center\">16x16</th>\n<th style=\"text-align:center\">17x17</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">miss数</td>\n<td style=\"text-align:center\">2425</td>\n<td style=\"text-align:center\">2118</td>\n<td style=\"text-align:center\">1992</td>\n<td style=\"text-align:center\">1950</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>个人测试了 4x4 \\ 8x8 \\ 16x16 发现16x16可以满足miss数小于 2k 的要求。参考网上资料[1]后，发现 17x17是最优选择，miss数为1950</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">transpose_61x67</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> M, <span class=\"hljs-keyword\">int</span> N, <span class=\"hljs-keyword\">int</span> A[N][M], <span class=\"hljs-keyword\">int</span> B[M][N])</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> i, j, x, y, tmp;\n\n    <span class=\"hljs-keyword\">for</span>(i = <span class=\"hljs-number\">0</span>; i &lt; N; i += <span class=\"hljs-number\">17</span>)\n        <span class=\"hljs-keyword\">for</span>(j = <span class=\"hljs-number\">0</span>; j &lt; M; j += <span class=\"hljs-number\">17</span>)\n\t\t\t<span class=\"hljs-keyword\">for</span>(x = i; x &lt; N &amp;&amp; x &lt; i + <span class=\"hljs-number\">17</span>; ++x)\n\t\t\t\t<span class=\"hljs-keyword\">for</span>(y = j; y &lt; M &amp;&amp; y &lt; j + <span class=\"hljs-number\">17</span>; ++y)\n\t\t\t\t&#123;\n\t\t\t\t\ttmp = A[x][y];\n\t\t\t\t\tB[y][x] = tmp; \n\t\t\t\t&#125;\t\t\n&#125;</code></pre>\n<hr>\n<h2 id=\"三、实验结论\"><a href=\"#三、实验结论\" class=\"headerlink\" title=\"三、实验结论\"></a>三、实验结论</h2><p>最后我们运行 <code>drive.py</code> 来测试我们的总分</p>\n<pre><code class=\"hljs shell\">Part A: Testing cache simulator\nRunning ./test-csim\n                        Your simulator     Reference simulator\nPoints (s,E,b)    Hits  Misses  Evicts    Hits  Misses  Evicts\n     3 (1,1,1)       9       8       6       9       8       6  traces/yi2.trace\n     3 (4,2,4)       4       5       2       4       5       2  traces/yi.trace\n     3 (2,1,4)       2       3       1       2       3       1  traces/dave.trace\n     3 (2,1,3)     167      71      67     167      71      67  traces/trans.trace\n     3 (2,2,3)     201      37      29     201      37      29  traces/trans.trace\n     3 (2,4,3)     212      26      10     212      26      10  traces/trans.trace\n     3 (5,1,5)     231       7       0     231       7       0  traces/trans.trace\n     6 (5,1,5)  265189   21775   21743  265189   21775   21743  traces/long.trace\n    27\n\n\nPart B: Testing transpose function\nRunning ./test-trans -M 32 -N 32\nRunning ./test-trans -M 64 -N 64\nRunning ./test-trans -M 61 -N 67\n\nCache Lab summary:\n                        Points   Max pts      Misses\nCsim correctness          27.0        27\nTrans perf 32x32           8.0         8         287\nTrans perf 64x64           8.0         8        1163\nTrans perf 61x67          10.0        10        1950\n          Total points    53.0        53</code></pre>\n<p>满分 53.0/53</p>\n<h2 id=\"四、参考资料\"><a href=\"#四、参考资料\" class=\"headerlink\" title=\"四、参考资料\"></a>四、参考资料</h2><p>[1] <em>Computer Systems: A Programmer’s Perspective</em>, 3/E (CS:APP3e). Randal E. Bryant and David R. O’Hallaron, Carnegie Mellon University</p>\n<p>[2] <a href=\"https://blog.csdn.net/xbb224007/article/details/81103995\">https://blog.csdn.net/xbb224007/article/details/81103995</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><em>注：本实验报告为 CMU CSAPP CacheLab 实验报告</em></p>\n<h2 id=\"一、实验简介\"><a href=\"#一、实验简介\" class=\"headerlink\" title=\"一、实验简介\"></a>一、实验简介</h2><p>​    Cache Lab实验主要在于帮助学生理解高速缓存的工作方式，以及如何针对Cache编写程序。实验主体总共分为两个部分 </p>\n<h3 id=\"PartA\"><a href=\"#PartA\" class=\"headerlink\" title=\"PartA\"></a><strong>PartA</strong></h3><p>编写一个Cache的模拟程序用以统计在L\\S\\M过程中Cache Hit\\Miss\\Eviction 的总数。</p>\n<p>官方给出了 csim-ref 程序，我们需要编写代码实现其功能，输出 Hit/Miss/Eviction 的总数</p>\n<pre><code class=\"hljs shell\">Usage: ./csim-ref [-hv] -s &lt;num&gt; -E &lt;num&gt; -b &lt;num&gt; -t &lt;file&gt;\nOptions:\n  -h         Print this help message.\n  -v         Optional verbose flag.\n  -s &lt;num&gt;   Number of set index bits.\n  -E &lt;num&gt;   Number of lines per set.\n  -b &lt;num&gt;   Number of block offset bits.\n  -t &lt;file&gt;  Trace file.\n\nExamples:\n<span class=\"hljs-meta\">  linux&gt;</span><span class=\"bash\">  ./csim-ref -s 4 -E 1 -b 4 -t traces/yi.trace</span>\n<span class=\"hljs-meta\">  linux&gt;</span><span class=\"bash\">  ./csim-ref -v -s 8 -E 2 -b 4 -t traces/yi.trace</span></code></pre>\n<p><strong>测试方法：</strong></p>\n<p>​    使用 test-csim.c 进行测试，测试器会输出你的编译器和标准结果，并进行比较计算分数。</p>\n<pre><code class=\"hljs shell\">xzy@ubuntu:~/Desktop/ICSLAB/CacheLab$ ./test-csim \n                        Your simulator     Reference simulator\nPoints (s,E,b)    Hits  Misses  Evicts    Hits  Misses  Evicts\n     3 (1,1,1)       9       8       6       9       8       6  traces/yi2.trace\n     3 (4,2,4)       4       5       2       4       5       2  traces/yi.trace\n     3 (2,1,4)       2       3       1       2       3       1  traces/dave.trace\n     3 (2,1,3)     167      71      67     167      71      67  traces/trans.trace\n     3 (2,2,3)     201      37      29     201      37      29  traces/trans.trace\n     3 (2,4,3)     212      26      10     212      26      10  traces/trans.trace\n     3 (5,1,5)     231       7       0     231       7       0  traces/trans.trace\n     6 (5,1,5)  265189   21775   21743  265189   21775   21743  traces/long.trace\n    27\n\nTEST_CSIM_RESULTS=27</code></pre>\n<h3 id=\"PartB\"><a href=\"#PartB\" class=\"headerlink\" title=\"PartB\"></a><strong>PartB</strong></h3><p>编写适应Cache的矩阵转置程序，使Cache的miss数尽量的小。</p>\n<p>​    给出总大小1kb，每个 block 为 32byte 的直接映射Cache</p>\n<p>​    共包含3个测试、分别为 32x32 \\ 64x64 \\ 61x67 大小的矩阵</p>\n<p><strong>测试方法：</strong></p>\n<p>​    使用 test-trans.c 进行测试</p>\n<pre><code class=\"hljs shell\">Usage: ./test-trans [-h] -M &lt;rows&gt; -N &lt;cols&gt;\nOptions:\n  -h          Print this help message.\n  -M &lt;rows&gt;   Number of matrix rows (max 256)\n  -N &lt;cols&gt;   Number of  matrix columns (max 256)\nExample: ./test-trans -M 8 -N 8</code></pre>\n<hr>\n<h2 id=\"二、实验内容\"><a href=\"#二、实验内容\" class=\"headerlink\" title=\"二、实验内容\"></a>二、实验内容</h2><h3 id=\"PartA-1\"><a href=\"#PartA-1\" class=\"headerlink\" title=\"PartA\"></a>PartA</h3><ul>\n<li><strong>关于 Cache 的结构组成</strong></li>\n</ul>\n<p>​    在 PartA 中我们需要在 csim.c 中编写模拟 Cache 运行的程序。学习过CSAPP第六章我们知道，Cache 的结构是由一行一个valid位，t个tag和一个长度为B的block组成的，总共分为多个Set，每个Set有E行。总共组成 Cache 大小 $C = B \\times E \\times S$ ( valid 和 tag 不计入 )</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gphwionzxcj30e30930t7.jpg\" alt></p>\n<ul>\n<li><p><strong>关于 Evict 机制</strong></p>\n<p>同时由于采取 LRU 策略 （最近最少使用策略），我们需要维护一个 timestamp 来标记其访问时间的远近。可以一开始赋值 INF，然后逐渐减小，LRUstamp 最小的，就会被 Evict。</p>\n</li>\n</ul>\n<p>由此我们确定了 Cache 的组成形式，我们一个 Line 由 valid 位，tag位，LRUstamp，和一个B字节的 Block 组成。由于是模拟Cache，所以其实DataBlock可以不编写，但是为了尽量模拟真实Cache，还是分配了Block的内存</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-keyword\">typedef</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> </span>\n<span class=\"hljs-class\">&#123;</span>\n    <span class=\"hljs-keyword\">int</span> valid; <span class=\"hljs-comment\">// 0/1 : invalid/valid</span>\n    <span class=\"hljs-keyword\">int</span> tag;\n    <span class=\"hljs-keyword\">int</span> LRUstamp; <span class=\"hljs-comment\">// 越小代表越早使用，可以evict</span>\n    <span class=\"hljs-keyword\">int</span>* Block; <span class=\"hljs-comment\">// B（2^b） 字节</span>\n&#125; Line_t;</code></pre>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">// s个Set组成Cache</span>\n<span class=\"hljs-keyword\">typedef</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> &#123;</span>\n    <span class=\"hljs-keyword\">int</span> S; <span class=\"hljs-comment\">// Set 个数 (2^s)</span>\n    <span class=\"hljs-keyword\">int</span> E; <span class=\"hljs-comment\">// 每个 Set 中 Line 的数量</span>\n    <span class=\"hljs-keyword\">int</span> B; <span class=\"hljs-comment\">// Block 大小 (2^b)</span>\n    Line_t*** cache_;\n&#125; Cache_t;</code></pre>\n<p>我在Cache中设置了S, E, B以方便管理Cache大小，不用每次传参，并编写对应设置函数。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">initCache</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> s, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> E, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> b)</span> </span>\n<span class=\"hljs-function\"></span>&#123;\n    Cache.S = (<span class=\"hljs-number\">1</span> &lt;&lt; s), Cache.E = E, Cache.B = (<span class=\"hljs-number\">1</span> &lt;&lt; b);\n&#125;</code></pre>\n<ul>\n<li><p><strong>关于内存管理</strong></p>\n<p>之后便是编写函数来进行 Cache的内存分配和释放。这个没什么好说的，就是要养成分配完释放的好习惯，避免内存泄漏。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">/* 分配 Cache */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">mallocCache</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    Cache.cache_ = (Line_t***)<span class=\"hljs-built_in\">malloc</span>(Cache.S* <span class=\"hljs-keyword\">sizeof</span>(Line_t **));\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; Cache.S; ++i)\n        Cache.cache_[i] = (Line_t **)<span class=\"hljs-built_in\">malloc</span>(Cache.E * <span class=\"hljs-keyword\">sizeof</span>(Line_t *));\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; Cache.S; ++i)\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; Cache.E; ++j)\n            Cache.cache_[i][j] = (Line_t *)<span class=\"hljs-built_in\">malloc</span>(<span class=\"hljs-keyword\">sizeof</span>(Line_t));\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; Cache.S; ++i)\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; Cache.E; ++j) &#123;\n            Cache.cache_[i][j]-&gt;valid = <span class=\"hljs-number\">0</span>;\n            Cache.cache_[i][j]-&gt;tag = <span class=\"hljs-number\">0</span>;\n            Cache.cache_[i][j]-&gt;LRUstamp = <span class=\"hljs-number\">1e9</span>;\n            Cache.cache_[i][j]-&gt;Block = (<span class=\"hljs-keyword\">int</span> *)<span class=\"hljs-built_in\">malloc</span>(Cache.B * <span class=\"hljs-keyword\">sizeof</span>(<span class=\"hljs-keyword\">int</span>));\n        &#125;\n&#125;</code></pre>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">/* 释放 Cache */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">freeCache</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; Cache.S; ++i)\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; Cache.E; ++j)\n            <span class=\"hljs-built_in\">free</span>(Cache.cache_[i][j]-&gt;Block);\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; Cache.S; ++i)\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> j = <span class=\"hljs-number\">0</span>; j &lt; Cache.E; ++j)\n            <span class=\"hljs-built_in\">free</span>(Cache.cache_[i][j]);\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; Cache.S; ++i)\n        <span class=\"hljs-built_in\">free</span>(Cache.cache_[i]);\n    <span class=\"hljs-built_in\">free</span>(Cache.cache_);\n&#125;</code></pre>\n</li>\n</ul>\n<ul>\n<li><p><strong>关于 getter 函数</strong></p>\n<p>为了方便valid、tag等信息的查找，我编写了一系列getter函数。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">/* 获得 Valid bit */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">getValid</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> s, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> E)</span> </span>&#123;<span class=\"hljs-keyword\">return</span> Cache.cache_[s][E]-&gt;valid;&#125;\n\n<span class=\"hljs-comment\">/* 获得 Tag */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">getTag</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> s, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> E)</span> </span>&#123;<span class=\"hljs-keyword\">return</span> Cache.cache_[s][E]-&gt;tag;&#125;\n\n<span class=\"hljs-comment\">/* 获得LRUstamp */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">getLRU</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> s, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> E)</span> </span>&#123;<span class=\"hljs-keyword\">return</span> Cache.cache_[s][E]-&gt;LRUstamp;&#125;</code></pre>\n</li>\n</ul>\n<ul>\n<li><p><strong>对于Hit和Miss的判定</strong></p>\n<p>判定hit和miss，就是在Cache对应Set中对比valid和tag，如果valid为1标明有效，并且tag相同，则说明Hit，不然则Miss。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">/* 查看是否命中 */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">HitOrMiss</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> s, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> tag)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; Cache.E; ++i)\n        <span class=\"hljs-keyword\">if</span>(getValid(s, i) &amp;&amp; getTag(s, i) == tag)\n            <span class=\"hljs-keyword\">return</span> i; <span class=\"hljs-comment\">// 命中</span>\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">-1</span>; <span class=\"hljs-comment\">// Miss </span>\n&#125;</code></pre>\n</li>\n</ul>\n<ul>\n<li><p><strong>关于是否Evict</strong></p>\n<p>根据上文，我们知道我们采取LRU的evict策略，那么在写的时候，如果valid位为1，而tag不一致发生写miss的情况，就要进行evict。evict的位置是LRUstamp最小的那一个。我们维护LRUstamp，在每次操作时，将其赋值为INF (1e9) 并将其余的LRUstamp减1，取最小的 LRUstamp 进行evict，用最新的 tag 和 数据 进行替换</p>\n</li>\n</ul>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">/* 更新LRU，越小越早使用 */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">lruUpdate</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> s, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> E)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    Cache.cache_[s][E]-&gt;LRUstamp = <span class=\"hljs-number\">1e9</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; Cache.E; ++i)\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(i != E)\n            Cache.cache_[s][i]-&gt;LRUstamp--;\n    &#125;\n&#125;\n\n<span class=\"hljs-comment\">/* 更新Cache */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">WriteCache</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> s, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> E, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> tag)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    Eviction(s, E, tag);\n    Cache.cache_[s][E]-&gt;valid = <span class=\"hljs-number\">1</span>;\n    Cache.cache_[s][E]-&gt;tag = tag;\n    lruUpdate(s, E);\n&#125;</code></pre>\n<ul>\n<li>关于模拟Cache</li>\n</ul>\n<p>最后进行Cache的模拟，如果Hit了就值更新LRUstamp，Miss了就获取EvictionPose，并将其替换。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">/* 模拟Cache，获得 Hit 和 Miss 的次数 */</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">getAns</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> s, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">int</span> tag)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> hit_flag = HitOrMiss(s, tag);\n    <span class=\"hljs-keyword\">if</span>(hit_flag != <span class=\"hljs-number\">-1</span>) &#123; <span class=\"hljs-comment\">// Hit</span>\n        Hit++;\n        <span class=\"hljs-keyword\">if</span>(verbose)\n            <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;hit &quot;</span>);\n        lruUpdate(s, hit_flag);\n    &#125;\n    <span class=\"hljs-keyword\">else</span>  &#123;\n        Miss++;\n        <span class=\"hljs-keyword\">if</span>(verbose)\n            <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;miss &quot;</span>);\n        WriteCache(s, getEvictPos(s), tag);\n    &#125;\n&#125;</code></pre>\n<p>最后完整代码，附于提交 <code>csim.c</code> 中</p>\n<ul>\n<li>完成通过</li>\n</ul>\n<pre><code class=\"hljs c\">Your simulator     Reference simulator\nPoints (s,E,b)    Hits  Misses  Evicts    Hits  Misses  Evicts\n     <span class=\"hljs-number\">3</span> (<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">1</span>)       <span class=\"hljs-number\">9</span>       <span class=\"hljs-number\">8</span>       <span class=\"hljs-number\">6</span>       <span class=\"hljs-number\">9</span>       <span class=\"hljs-number\">8</span>       <span class=\"hljs-number\">6</span>  traces/yi2.trace\n     <span class=\"hljs-number\">3</span> (<span class=\"hljs-number\">4</span>,<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">4</span>)       <span class=\"hljs-number\">4</span>       <span class=\"hljs-number\">5</span>       <span class=\"hljs-number\">2</span>       <span class=\"hljs-number\">4</span>       <span class=\"hljs-number\">5</span>       <span class=\"hljs-number\">2</span>  traces/yi.trace\n     <span class=\"hljs-number\">3</span> (<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">4</span>)       <span class=\"hljs-number\">2</span>       <span class=\"hljs-number\">3</span>       <span class=\"hljs-number\">1</span>       <span class=\"hljs-number\">2</span>       <span class=\"hljs-number\">3</span>       <span class=\"hljs-number\">1</span>  traces/dave.trace\n     <span class=\"hljs-number\">3</span> (<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">3</span>)     <span class=\"hljs-number\">167</span>      <span class=\"hljs-number\">71</span>      <span class=\"hljs-number\">67</span>     <span class=\"hljs-number\">167</span>      <span class=\"hljs-number\">71</span>      <span class=\"hljs-number\">67</span>  traces/trans.trace\n     <span class=\"hljs-number\">3</span> (<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">3</span>)     <span class=\"hljs-number\">201</span>      <span class=\"hljs-number\">37</span>      <span class=\"hljs-number\">29</span>     <span class=\"hljs-number\">201</span>      <span class=\"hljs-number\">37</span>      <span class=\"hljs-number\">29</span>  traces/trans.trace\n     <span class=\"hljs-number\">3</span> (<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">4</span>,<span class=\"hljs-number\">3</span>)     <span class=\"hljs-number\">212</span>      <span class=\"hljs-number\">26</span>      <span class=\"hljs-number\">10</span>     <span class=\"hljs-number\">212</span>      <span class=\"hljs-number\">26</span>      <span class=\"hljs-number\">10</span>  traces/trans.trace\n     <span class=\"hljs-number\">3</span> (<span class=\"hljs-number\">5</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">5</span>)     <span class=\"hljs-number\">231</span>       <span class=\"hljs-number\">7</span>       <span class=\"hljs-number\">0</span>     <span class=\"hljs-number\">231</span>       <span class=\"hljs-number\">7</span>       <span class=\"hljs-number\">0</span>  traces/trans.trace\n     <span class=\"hljs-number\">6</span> (<span class=\"hljs-number\">5</span>,<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">5</span>)  <span class=\"hljs-number\">265189</span>   <span class=\"hljs-number\">21775</span>   <span class=\"hljs-number\">21743</span>  <span class=\"hljs-number\">265189</span>   <span class=\"hljs-number\">21775</span>   <span class=\"hljs-number\">21743</span>  traces/<span class=\"hljs-keyword\">long</span>.trace\n    <span class=\"hljs-number\">27</span></code></pre>\n<hr>\n<h3 id=\"PartB-1\"><a href=\"#PartB-1\" class=\"headerlink\" title=\"PartB\"></a>PartB</h3><p>​    在完成了Cache基本的组织架构之后，我们现在要开始编写Cache友好的程序，以矩阵转置为例。源代码中包含一个最naive的矩阵转置，也是我们平常经常写的。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">/* </span>\n<span class=\"hljs-comment\"> * trans - A simple baseline transpose function, not optimized for the cache.</span>\n<span class=\"hljs-comment\"> */</span>\n<span class=\"hljs-keyword\">char</span> trans_desc[] = <span class=\"hljs-string\">&quot;Simple row-wise scan transpose&quot;</span>;\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">trans</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> M, <span class=\"hljs-keyword\">int</span> N, <span class=\"hljs-keyword\">int</span> A[N][M], <span class=\"hljs-keyword\">int</span> B[M][N])</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> i, j, tmp;\n\n    <span class=\"hljs-keyword\">for</span> (i = <span class=\"hljs-number\">0</span>; i &lt; N; i++) &#123;\n        <span class=\"hljs-keyword\">for</span> (j = <span class=\"hljs-number\">0</span>; j &lt; M; j++) &#123;\n            tmp = A[i][j];\n            B[j][i] = tmp;\n        &#125;\n    &#125;    \n&#125;</code></pre>\n<p>测试之后会发现，对于4x4的矩阵，其miss次数有22次之多</p>\n<pre><code class=\"hljs shell\">func 1 (Simple row-wise scan transpose): hits:15, misses:22, evictions:19</code></pre>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gphxvxlx02j312d0iw40v.jpg\" style=\"zoom:50%;\"></p>\n<p>我们可以发现，对于4x4的矩阵，由于Block大小是32bytes且为直接映射Cache，所以每8个int会在同一个Block/Set当中，4x4的矩阵被分在两个不同的 Block 中，对于A矩阵的访问是行优先的，而B矩阵的访问是列优先的。我们可以模拟这个过程</p>\n<blockquote>\n<p>访问到 $A<em>{00}$  Cache cold miss，将 $B</em>{A_{1}}$ 加入 Cache 中</p>\n<p>访问到 $B<em>{00}$  由于B和A有相同的组索引，所以导致相对位置相同的地方被映射到Cache的同一组中，造成tag不一致，产生miss将会把之前Load到Cache里的A进行驱逐，将 $B</em>{A<em>{1}}$ 驱逐 将 $B</em>{B_{1}}$ 加入 Cache 中</p>\n<p>访问到 $A<em>{01}$  同理，将 $B</em>{B<em>{1}}$ 驱逐 将 $B</em>{A_{1}}$ 加入 Cache 中</p>\n<p>之后 $B<em>{B</em>{2}}$ 和  $B<em>{A</em>{1}}$ 很幸运能够不产生thrash，有几次Cache hit，但是大部分情况下，还是会发生如同上面所描述的抖动。</p>\n</blockquote>\n<p>因此，对于这种情况，我们应该如何修改代码，使其适应Cache，能够尽可能少的Miss呢？</p>\n<ul>\n<li><p><strong>暴力方法</strong></p>\n<p>有一种最暴力的方式，就是考虑到目前矩阵的大小比较小，所以我们可以采取定义8个局部变量的方法，一次性将一个Block全部Load到寄存器中，然后再进行转置，这样就不会发生如上面所描述的 Cache thrash。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">transpose_4x4</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> M, <span class=\"hljs-keyword\">int</span> N, <span class=\"hljs-keyword\">int</span> A[N][M], <span class=\"hljs-keyword\">int</span> B[M][N])</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> tmp0, tmp1, tmp2, tmp3, tmp4, tmp5, tmp6, tmp7;\n\n\t<span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> x = <span class=\"hljs-number\">0</span>; x &lt; <span class=\"hljs-number\">3</span>; x += <span class=\"hljs-number\">2</span>)\n\t&#123;\n\t\ttmp0 = A[x][<span class=\"hljs-number\">0</span>], tmp1 = A[x][<span class=\"hljs-number\">1</span>], tmp2 = A[x][<span class=\"hljs-number\">2</span>], tmp3 = A[x][<span class=\"hljs-number\">3</span>];\n\t\ttmp4 = A[x + <span class=\"hljs-number\">1</span>][<span class=\"hljs-number\">0</span>], tmp5 = A[x + <span class=\"hljs-number\">1</span>][<span class=\"hljs-number\">1</span>], tmp6 = A[x + <span class=\"hljs-number\">1</span>][<span class=\"hljs-number\">2</span>], tmp7 = A[x + <span class=\"hljs-number\">1</span>][<span class=\"hljs-number\">3</span>];\n\n\t\tB[<span class=\"hljs-number\">0</span>][x] = tmp0, B[<span class=\"hljs-number\">1</span>][x] = tmp1, B[<span class=\"hljs-number\">2</span>][x] = tmp2, B[<span class=\"hljs-number\">3</span>][x] = tmp3; \n\t\tB[<span class=\"hljs-number\">0</span>][x + <span class=\"hljs-number\">1</span>] = tmp4, B[<span class=\"hljs-number\">1</span>][x + <span class=\"hljs-number\">1</span>] = tmp5, B[<span class=\"hljs-number\">2</span>][x + <span class=\"hljs-number\">1</span>] = tmp6, B[<span class=\"hljs-number\">3</span>][x + <span class=\"hljs-number\">1</span>] = tmp7; \n\t&#125;\n&#125;</code></pre>\n<pre><code class=\"hljs angelscript\">func <span class=\"hljs-number\">0</span> (Transpose submission): hits:<span class=\"hljs-number\">29</span>, misses:<span class=\"hljs-number\">8</span>, evictions:<span class=\"hljs-number\">6</span></code></pre>\n<p>可以看到miss降到了8，有极大的改进，我们用partA中写的csim进行分析。</p>\n<pre><code class=\"hljs shell\">xzy@ubuntu:~/Desktop/ICSLAB/CacheLab$ ./csim -v -s 5 -E 1 -b 5 -t trace.f0\nS 18e08c,1 miss #系统miss\nL 18e0a0,8 miss #系统miss\nL 18e084,4 hit \nL 18e080,4 hit \nL 10e080,4 miss eviction \nL 10e084,4 hit \nL 10e088,4 hit \nL 10e08c,4 hit \nL 10e090,4 hit \nL 10e094,4 hit \nL 10e098,4 hit \nL 10e09c,4 hit \nS 14e080,4 miss eviction \nS 14e090,4 hit \nS 14e0a0,4 miss eviction # 多一次miss\nS 14e0b0,4 hit \nS 14e084,4 hit \nS 14e094,4 hit \nS 14e0a4,4 hit \nS 14e0b4,4 hit \nL 10e0a0,4 miss eviction \nL 10e0a4,4 hit \nL 10e0a8,4 hit \nL 10e0ac,4 hit \nL 10e0b0,4 hit \nL 10e0b4,4 hit \nL 10e0b8,4 hit \nL 10e0bc,4 hit \nS 14e088,4 hit \nS 14e098,4 hit \nS 14e0a8,4 miss eviction \nS 14e0b8,4 hit \nS 14e08c,4 hit \nS 14e09c,4 hit \nS 14e0ac,4 hit \nS 14e0bc,4 hit \nS 18e08d,1 miss eviction #系统miss\nhits:29 misses:8 evictions:6</code></pre>\n<p>可以看到除了前后3次系统固定的miss之外，距离理论下限4次还有1次，这一次发生在Store矩阵B的时候，由于B是列优先，所以在访问到$B<em>{B</em>{2}}$的时候会多发生一次miss。</p>\n<h4 id=\"32x32-矩阵转置\"><a href=\"#32x32-矩阵转置\" class=\"headerlink\" title=\"32x32 矩阵转置\"></a>32x32 矩阵转置</h4></li>\n</ul>\n<p>​        了解了之后我们来看32x32的矩阵转置，其正好是Cache 1kb的总大小，能够全部装进Cache。所以我们需要避免的就是连续在A,B</p>\n<p>之间切换访问相对位置相同的区域（映射到同一个Block）从而导致的Cache thrash。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gpi2azu5g2j31dl0qz42z.jpg\" style=\"zoom:50%;\"></p>\n<p>我们可以采取 8*8分块的方式，对于每一块中每一行属于同一个Block，经过8x8分块后我们发现，除了对角线的分块之外，其他分块的A、B互不影响，不会产生thrash。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">transpose_32x32</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> M, <span class=\"hljs-keyword\">int</span> N, <span class=\"hljs-keyword\">int</span> A[N][M], <span class=\"hljs-keyword\">int</span> B[M][N])</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> i, j, x, y;\n\t\t<span class=\"hljs-keyword\">int</span> tmp;\n  \n    <span class=\"hljs-keyword\">for</span>(i = <span class=\"hljs-number\">0</span>; i &lt; N; i += <span class=\"hljs-number\">8</span>)\n        <span class=\"hljs-keyword\">for</span>(j = <span class=\"hljs-number\">0</span>; j &lt; M; j += <span class=\"hljs-number\">8</span>)\n          <span class=\"hljs-keyword\">for</span>(x = i; x &lt; i + <span class=\"hljs-number\">8</span>; ++x)\n              <span class=\"hljs-keyword\">for</span>(y = j; y &lt; j + <span class=\"hljs-number\">8</span>; ++y)\n              &#123;\n                tmp = A[x][y], B[y][x] = tmp;\n              &#125;\n  <span class=\"hljs-comment\">/*</span>\n<span class=\"hljs-comment\">    注意，这里应该学习示例程序中的 tmp = A[x][y], B[y][x] = tmp; </span>\n<span class=\"hljs-comment\">    因为我们无法确定调用者是否会使A，B指向内存中的同一块区域从而造成意想不到的后果。</span>\n<span class=\"hljs-comment\">  */</span>\n&#125;</code></pre>\n<pre><code class=\"hljs shell\">func 0 (Transpose submission): hits:1735, misses:350, evictions:318 \t# 8x8 分块\nfunc 1 (Simple row-wise scan transpose): hits:870, misses:1183, evictions:1151\t# Naive</code></pre>\n<p>可以看到相比于最初naive的版本1183miss，已经有了极大的改善，但是还是没有达到要求的小于300miss。</p>\n<p>我们可以发现，除对角线之外的分块已经达到miss的下限，所以对角线是需要解决的地方。对于对角线上的分块，我们的处理和Naive方式没有什么区别，都会造成thrash。</p>\n<p>有了前面4x4矩阵的铺垫，我们已经知道了应该如何处理这类情况，我们按照之前的解决方法类似解决。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">transpose_32x32</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> M, <span class=\"hljs-keyword\">int</span> N, <span class=\"hljs-keyword\">int</span> A[N][M], <span class=\"hljs-keyword\">int</span> B[M][N])</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> i, j, x, y;\n    <span class=\"hljs-keyword\">int</span> tmp, tmp0, tmp1, tmp2, tmp3, tmp4, tmp5, tmp6, tmp7;\n\n    <span class=\"hljs-keyword\">for</span>(i = <span class=\"hljs-number\">0</span>; i &lt; N; i += <span class=\"hljs-number\">8</span>)\n        <span class=\"hljs-keyword\">for</span>(j = <span class=\"hljs-number\">0</span>; j &lt; M; j += <span class=\"hljs-number\">8</span>)\n\t\t\t<span class=\"hljs-keyword\">for</span>(x = i; x &lt; i + <span class=\"hljs-number\">8</span>; ++x)\n\t\t\t&#123;\n\t\t\t\t<span class=\"hljs-keyword\">if</span>(i == j)\n\t\t\t\t&#123;\n\t\t\t\t\ttmp0 = A[x][j], tmp1 = A[x][j + <span class=\"hljs-number\">1</span>], tmp2 = A[x][j + <span class=\"hljs-number\">2</span>], tmp3 = A[x][j + <span class=\"hljs-number\">3</span>];\n\t\t\t\t\ttmp4 = A[x][j + <span class=\"hljs-number\">4</span>], tmp5 = A[x][j + <span class=\"hljs-number\">5</span>], tmp6 = A[x][j + <span class=\"hljs-number\">6</span>], tmp7 = A[x][j + <span class=\"hljs-number\">7</span>];\n\n\t\t\t\t\tB[j][x] = tmp0, B[j + <span class=\"hljs-number\">1</span>][x] = tmp1, B[j + <span class=\"hljs-number\">2</span>][x] = tmp2, B[j + <span class=\"hljs-number\">3</span>][x] = tmp3; \n\t\t\t\t\tB[j + <span class=\"hljs-number\">4</span>][x] = tmp4, B[j + <span class=\"hljs-number\">5</span>][x] = tmp5, B[j + <span class=\"hljs-number\">6</span>][x] = tmp6, B[j + <span class=\"hljs-number\">7</span>][x] = tmp7; \n\t\t\t\t&#125;\n\t\t\t\t<span class=\"hljs-keyword\">else</span> \n\t\t\t\t&#123;\n\t\t\t\t\t<span class=\"hljs-keyword\">for</span>(y = j; y &lt; j + <span class=\"hljs-number\">8</span>; ++y)\n\t\t\t\t\t&#123;\n\t\t\t\t\t\ttmp = A[x][y], B[y][x] = tmp;\n\t\t\t\t\t&#125;\n\t\t\t\t&#125;\n\t\t\t&#125;\n&#125;</code></pre>\n<pre><code class=\"hljs angelscript\">func <span class=\"hljs-number\">0</span> (Transpose submission): hits:<span class=\"hljs-number\">1766</span>, misses:<span class=\"hljs-number\">287</span>, evictions:<span class=\"hljs-number\">255</span></code></pre>\n<p>​    成功将miss降到了287。实际的理论下限是256，我们注意到这种操作方式A矩阵的miss已经达到了下限，而B矩阵的对角线还是会固定miss。这是因为在Load A之前，B矩阵的对角线行已经被前一个转置Load进去，所以会被evict掉，再次调用时就会产生一次Miss。所以我们可以对其进行展开，最后可以做到259次的miss（3次系统miss）由于代码可读性太低，这里不做展开。</p>\n<hr>\n<h4 id=\"64x64矩阵转置\"><a href=\"#64x64矩阵转置\" class=\"headerlink\" title=\"64x64矩阵转置\"></a>64x64矩阵转置</h4><p>​    对于64x64矩阵转置，我们注意到其已经超过了Cache的大小，我们首先用8分块尝试一下。</p>\n<pre><code class=\"hljs shell\">func 0 (Transpose submission): hits:3586, misses:4611, evictions:4579 # 8分块\nfunc 1 (Simple row-wise scan transpose): hits:3474, misses:4723, evictions:4691 # naive</code></pre>\n<p>发现没有什么改进，这是什么原因？我们从Cache大小的角度出发</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gpi5dme0pcj31ok0tnteo.jpg\" alt></p>\n<p>我们进行4x4分块试验一下</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-keyword\">int</span> i, j, x, y;\n    <span class=\"hljs-keyword\">int</span> tmp, tmp0, tmp1, tmp2, tmp3;\n\n    <span class=\"hljs-keyword\">for</span>(i = <span class=\"hljs-number\">0</span>; i &lt; N; i += <span class=\"hljs-number\">4</span>)\n        <span class=\"hljs-keyword\">for</span>(j = <span class=\"hljs-number\">0</span>; j &lt; M; j += <span class=\"hljs-number\">4</span>)\n\t\t\t<span class=\"hljs-keyword\">for</span>(x = i; x &lt; i + <span class=\"hljs-number\">4</span>; ++x)\n\t\t\t&#123;\n\t\t\t\t<span class=\"hljs-keyword\">if</span>(i == j)\n\t\t\t\t&#123;\n\t\t\t\t\ttmp0 = A[x][j], tmp1 = A[x][j + <span class=\"hljs-number\">1</span>], tmp2 = A[x][j + <span class=\"hljs-number\">2</span>], tmp3 = A[x][j + <span class=\"hljs-number\">3</span>];\n\n\t\t\t\t\tB[j][x] = tmp0, B[j + <span class=\"hljs-number\">1</span>][x] = tmp1, B[j + <span class=\"hljs-number\">2</span>][x] = tmp2, B[j + <span class=\"hljs-number\">3</span>][x] = tmp3; \n\t\t\t\t&#125;\n\t\t\t\t<span class=\"hljs-keyword\">else</span> \n\t\t\t\t&#123;\n\t\t\t\t\t<span class=\"hljs-keyword\">for</span>(y = j; y &lt; j + <span class=\"hljs-number\">4</span>; ++y)\n\t\t\t\t\t&#123;\n\t\t\t\t\t\ttmp = A[x][y], B[y][x] = tmp;\n\t\t\t\t\t&#125;\n\t\t\t\t&#125;\n\t\t\t&#125;</code></pre>\n<pre><code class=\"hljs shell\">func 0 (Transpose submission): hits:6402, misses:1795, evictions:1763</code></pre>\n<p>​    可以看到结果好了很多，但是还是没能达到1300的要求。其原因其实还是在最开始讲的4x4分块的例子中，由于B矩阵是按列访问，在4x4分块之后，访问对角两块的时候，会每一块都会各产生2次miss，有一个小的thrash。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gpi5iw1wfdj31or0tj0vq.jpg\" style=\"zoom:33%;\"></p>\n<p>​    对自己电脑寄存器数量有自信的选手可能会选择开16个临时变量来一次性完成转置，但那样太过粗暴而不稳定。我们想是否有什么办法能够使4x4区域中的miss次数降低到1次？我们回去考虑8x8的分块情况。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gpi5pdjqnuj31tk0laq79.jpg\" alt></p>\n<ul>\n<li><p><strong>对于A矩阵</strong></p>\n<p>我们的策略是一次load掉4行的内容，以防多次访问</p>\n</li>\n<li><p><strong>对于B矩阵</strong></p>\n<p>我们发现，其实对于2、3两块分块，如果在2处出现miss，那么3其实也被加入了Cache不会发生miss，所以就有了如下策略。</p>\n</li>\n</ul>\n<p>  <strong>解决方案：</strong></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gpi5wquog6j30vb0t4jtx.jpg\" style=\"zoom:25%;\"></p>\n<ol>\n<li><p>我们可以先一次性Load A1、A2两块到B1、B2两块中，这样只会1次miss。</p>\n</li>\n<li><p>我们按行将A3转置到B2中， 再将B2中原来放置的A2转置到A3中 (B2 Hit -&gt; B3 miss -&gt;下次B2 miss之后 B2、B3在Cache中便不会miss了) 共2次miss</p>\n</li>\n<li>之后再将A4转置到B4中，这样会miss1次</li>\n</ol>\n<p>总共miss4次，这样一来对于8x8 的 B矩阵，相当于每个4x4只miss了一次，完成了要求。</p>\n<p><em>&lt; 代码太长见附件 &gt;</em></p>\n<p>测试一下，效果拔群！</p>\n<pre><code class=\"hljs angelscript\">func <span class=\"hljs-number\">0</span> (Transpose submission): hits:<span class=\"hljs-number\">9082</span>, misses:<span class=\"hljs-number\">1163</span>, evictions:<span class=\"hljs-number\">1131</span></code></pre>\n<hr>\n<h4 id=\"61x67矩阵\"><a href=\"#61x67矩阵\" class=\"headerlink\" title=\"61x67矩阵\"></a>61x67矩阵</h4><p>对于这类非方阵，我们采用最简单的分块策略进行测试。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"></th>\n<th style=\"text-align:center\">4x4</th>\n<th style=\"text-align:center\">8x8</th>\n<th style=\"text-align:center\">16x16</th>\n<th style=\"text-align:center\">17x17</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">miss数</td>\n<td style=\"text-align:center\">2425</td>\n<td style=\"text-align:center\">2118</td>\n<td style=\"text-align:center\">1992</td>\n<td style=\"text-align:center\">1950</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>个人测试了 4x4 \\ 8x8 \\ 16x16 发现16x16可以满足miss数小于 2k 的要求。参考网上资料[1]后，发现 17x17是最优选择，miss数为1950</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">transpose_61x67</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> M, <span class=\"hljs-keyword\">int</span> N, <span class=\"hljs-keyword\">int</span> A[N][M], <span class=\"hljs-keyword\">int</span> B[M][N])</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> i, j, x, y, tmp;\n\n    <span class=\"hljs-keyword\">for</span>(i = <span class=\"hljs-number\">0</span>; i &lt; N; i += <span class=\"hljs-number\">17</span>)\n        <span class=\"hljs-keyword\">for</span>(j = <span class=\"hljs-number\">0</span>; j &lt; M; j += <span class=\"hljs-number\">17</span>)\n\t\t\t<span class=\"hljs-keyword\">for</span>(x = i; x &lt; N &amp;&amp; x &lt; i + <span class=\"hljs-number\">17</span>; ++x)\n\t\t\t\t<span class=\"hljs-keyword\">for</span>(y = j; y &lt; M &amp;&amp; y &lt; j + <span class=\"hljs-number\">17</span>; ++y)\n\t\t\t\t&#123;\n\t\t\t\t\ttmp = A[x][y];\n\t\t\t\t\tB[y][x] = tmp; \n\t\t\t\t&#125;\t\t\n&#125;</code></pre>\n<hr>\n<h2 id=\"三、实验结论\"><a href=\"#三、实验结论\" class=\"headerlink\" title=\"三、实验结论\"></a>三、实验结论</h2><p>最后我们运行 <code>drive.py</code> 来测试我们的总分</p>\n<pre><code class=\"hljs shell\">Part A: Testing cache simulator\nRunning ./test-csim\n                        Your simulator     Reference simulator\nPoints (s,E,b)    Hits  Misses  Evicts    Hits  Misses  Evicts\n     3 (1,1,1)       9       8       6       9       8       6  traces/yi2.trace\n     3 (4,2,4)       4       5       2       4       5       2  traces/yi.trace\n     3 (2,1,4)       2       3       1       2       3       1  traces/dave.trace\n     3 (2,1,3)     167      71      67     167      71      67  traces/trans.trace\n     3 (2,2,3)     201      37      29     201      37      29  traces/trans.trace\n     3 (2,4,3)     212      26      10     212      26      10  traces/trans.trace\n     3 (5,1,5)     231       7       0     231       7       0  traces/trans.trace\n     6 (5,1,5)  265189   21775   21743  265189   21775   21743  traces/long.trace\n    27\n\n\nPart B: Testing transpose function\nRunning ./test-trans -M 32 -N 32\nRunning ./test-trans -M 64 -N 64\nRunning ./test-trans -M 61 -N 67\n\nCache Lab summary:\n                        Points   Max pts      Misses\nCsim correctness          27.0        27\nTrans perf 32x32           8.0         8         287\nTrans perf 64x64           8.0         8        1163\nTrans perf 61x67          10.0        10        1950\n          Total points    53.0        53</code></pre>\n<p>满分 53.0/53</p>\n<h2 id=\"四、参考资料\"><a href=\"#四、参考资料\" class=\"headerlink\" title=\"四、参考资料\"></a>四、参考资料</h2><p>[1] <em>Computer Systems: A Programmer’s Perspective</em>, 3/E (CS:APP3e). Randal E. Bryant and David R. O’Hallaron, Carnegie Mellon University</p>\n<p>[2] <a href=\"https://blog.csdn.net/xbb224007/article/details/81103995\">https://blog.csdn.net/xbb224007/article/details/81103995</a></p>\n"},{"title":"Linux 动态内存分配机制详解","date":"2021-05-22T04:11:27.000Z","index_img":"/img/ICS_Lab1/top.jpg","_content":"\n\n\n​\t动态内存分配是虚拟内存组织中的核心概念，理解它对于帮助整个linux虚拟内存的组织以及堆上内存分配过程。本文会系统介绍动态内存的分配机制以及内存堆块的组织形式，并最后以 CMU CSAPP Malloc Lab 为例来详细讲解。\n\n**Malloc Lab 代码：[ZiYang-xie/Malloc_Lab: CMU Malloc Lab Repo (github.com)](https://github.com/ZiYang-xie/Malloc_Lab)** \n\n在开始介绍 malloc 机制前，我们先看一下虚拟内存的组织形式。\n\n# 【序】虚拟内存组织形式\n\n​\tlinux虚拟内存形式安装堆栈形式组织，栈位于内存高地址，分为内核栈和用户栈，增长方向从高到低。而堆位于内存的低地址，是程序员进行动态内存分配的空间，增长方向由低到高。堆和栈中间是共享映射空间，用于共享库在内存中的映射，这样每次如果有不同代码调用相同的共享库，就不需要再次向内存中复制一份副本，节省了时间和空间。\n\n​\t栈内存的更高地址用于存放一些全局数据结构\n\n​\t堆内存的更低地址按地址从低到高放置着代码段（.text）、已分配数据段（.data）、未分配数据段（.bss）。你可能还听说过 COMMON 段专门储存未初始化全局变量，真正的.bss存储未初始化的静态变量以及初始化为0的全局和静态变量 [1]，组织形式如下\n\n```c\nSECTIONS { \n  .text : { *(.text) }\n  .data : { *(.data) } \n  .bss :  { *(.bss)  *(COMMON) } \n} \n```\n\n虚拟内存的大致组成形式如下图所示。\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gqr0n9olxfj30e80e0gn3.jpg)\n\n​\t可以看到代码段从 *0x40000000* 处开始，从0到0x40000000的内存地址单纯是未被映射，代码段和0地址之间相隔一段距离在早期是为了防止 nullptr 对代码段的修改*（此处仅凭记忆，真实性需要进一步验证*）。但如今权限设计更加完善，上述意义已不再成立，这就变成了一种约定俗成的规则。\n\n在了解了虚拟内存的大致组织模式之后，我们便可以开始讲解 Malloc 的基本机制。\n\n\n\n# 【一】动态内存分配的实现方式\n\n​\tLinux动态内存分配的实现方式是由 mmap, munmap 以及 brk, sbrk 这四个系统函数联合完成的。\n\n## mmap 与 munmap\n\n**mmap**\n\n```c\nvoid *mmap(void *addr, size_t length, int prot, int flags,\n           int fd, off_t offset);\n```\n\nmmap 创建一个新的虚拟内存空间和文件设备之间的映射。\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gqr27vczrhj30jd0a9tah.jpg)\n\n​\t其中 addr 代表分配开始地址，fd是相应文件描述符，len是指文件存储部分映射的长度，offset指的是从文件头开始offset距离开始分配。\n\n- prot包含权限位\n\n```c\nPROT_EXEC // 可执行\nPROT_READ // 可读\nPROT_WRITE // 可写\nPROT_NONE // 不可访问\n```\n\n- Flags 表示映射对象类型\n\n```c\nMAP_ANON // 匿名请求二进制零的\nMAP_PRIVATE // 私有的\nMAP_SHARED // 共享的\n```\n\n\n\n**munmap**\n\n取消相应地址内存块的映射\n\n```c\nint munmap(void *addr, size_t length);\n```\n\n很好理解取消开始地址为 addr 长度为 length 的内存映射。\n\n\n\n## brk 与 sbrk\n\n​\tbrk, sbrk 用来移动 program break 指向的指针来扩展堆内存，program break 位于堆顶未初始化数据段末尾之后，通过移动 program break 指针来动态控制堆的大小。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gqri33m8lkj30ic0huq62.jpg\" style=\"zoom:50%;\" />\n\n**brk**\n\n```c\nint brk(void *addr);\n```\n\n​\tbrk 会在允许的情况下简单的将 program break 设为 addr 地址，来控制堆内存大小。相当于 program break 的绝对移动\n\n**sbrk**\n\n```c\nvoid *sbrk(intptr_t increment);\n```\n\n​\tsbrk 会在允许的情况下将 program break 指针加 increment 值，返回扩展前的 program break 地址。当```increment```为正值时，堆被扩展；为0时，返回当前 program break 的指针；为负值时，堆被收缩。相当于 program break 的相对移动\n\n​\t值得注意的是，当无法扩展时 (申请了大于允许的内存，或碰到了共享内存段)，sbrk会返回 (void *)-1 并且会设置 errorno 为 **ENOMEM**（ENO Memory）\n\n### 关于 sbrk 的更多细节\n\n​\tsbrk 实际上是 linux 的一个上古函数，如今大多数内存分配器都倾向于使用 mmap 而不使用 sbrk，是因为 sbrk 是线程不安全的。由于 sbrk 的组织形式是对 program break 的相对移动来进行对扩展，那么对堆块的组织释放方式只能使用 LIFO。假设 sbrk 函数是原子的，在多进程调用时，如果一个进程要释放一个块，且其正好位于结尾program break处，我们选择 increment 为一个负值进行堆收缩（这是正确的）；但在我们还未释放的时候，另一个进程选择分配内存，调用 sbrk。在分配后我们继续进行释放此时我们需要释放的块后增加了一个新块，再调用 sbrk 会导致另一个进程分配的块被释放从而引发错误。\n\n​\t为了解决这个问题，我们也可以自己设计一个进程安全的 sbrk 函数，称为 sbrk_safe\n\n```c\nvoid *sbrk_safe(intptr_t increment, void *expect_top);\n```\n\n​\t其增加了一个参数expect_top，思想很简单，就是在每次调用 sbrk_safe 的时候将选择释放块的内存地址填入 expect_top，函数中验证其是否是在堆顶，如果不是就返回错误。\n\n​\t（另外 sbrk 可能还有其他问题，比如受到 mmap 分配内存和共享内存的阻碍导致内存分配的间断。这里有待进一步研究探讨）\n\n\n\n# 【二】动态内存分配器的设计\n\n​\t\t对于堆上的动态内存分配，我们通常将其组织为“块”的模式，一个块就是指一段连续内存地址，而根据其是否被分配数据又被划分为**空闲块**和**分配块**两种。\n\n## 序、内存块结构\n\n​\t首先我们需要了解一个简单的技巧，就是如果有空闲块相邻时我们是可以将其进行合并为一个空闲块的，这样一来我们就可以分配更大的内存，并减少内存的碎片程度。注意到由于我们需要对块进行分配和合并，所以我们必须要知道块的**大小信息**和**块的分类**，因而一个内存块中其并不是所有位置都存储着有效信息。以32位系统为例，双字对齐（8 bytes）我们设计一个块的头部一个字大小（4 bytes）放置着块的大小信息和分配信息，由于是双字对齐的，所以块大小的后3位永远是0（1000）, 因此我们用前29位放大小信息，后3位放置分配信息（实际上是最后一位）001表示已分配、000表示空闲。中间放置有效载荷、即数据段，尾部可有一个填充。\n\n​\t最后注意到我们需要对块进行**合并**（在后文中我们会详细讨论合并策略），所以在尾部也放置一个大小和分配标记有利于下一块相邻块快速找到上一块的分配状态和大小来达成向前合并的操作，所以我们在脚部也增加一个字大小（4 bytes）和头部相同的大小分配标记。这个特征称为**边界标记**\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gqrjzzz4iaj30go0dwjyj.jpg\" style=\"zoom:50%;\" />\n\n## 一、内存碎片\n\n​\t\t关于内存分配，首先我们要有一个直观，在组织过程中我们确实可以简单的每次分配内存都创建一个所需大小的块，但经过频繁的分配释放，很快堆上的整块内存就会被划分为十分杂乱的小块。这种情况称之为内存碎片化，内存碎片化是一个十分严重的问题，其可能导致内存极大的浪费，因此要理解动态内存分配器的设计之前首先我们需要理解内存碎片的概念，来帮助我们更好的设计一个性能更加优良的分配器。\n\n​\t关于内存碎片根据其表现形式可以分为两类，内部碎片和外部碎片。\n\n### 内部内存碎片\n\n​\t内部内存碎片可以有一个直观的理解（虽然可能有点夸张），就是如果你仅仅需要 1kb 的内存用于存放数据，但是你申请了 2GB 大小的内存空间用来存这 1kb 的数据，那么里面大部分的内存全部都被浪费掉了，这时候如果你再要申请内存，空闲的内存可能就不够了。这就是内部碎片。\n\n​\t这时候有人可能会问，那么我们之间分配需要分配的内存大小就好了啊？那为什么内部碎片还会产生呢？确实说的很对，。但有时候由于内存对齐需要以及分配器策略等影响我们并不能够直接分配正好就是需求大小的内存块，其产生机制我将会在下文中进一步深入讲解\n\n\n\n### 外部内存碎片\n\n​\t外部内存碎片的产生主要源于频繁的大小不一的内存分配和释放过程。经过一系列的分配释放，最后整块的内存会被切分成空闲块分配块相互交杂的情况，如下图所示，这时候如果我们想要再分配一个 1000 kb 的数据块，可能所有的空闲块加起来是大于 1000 kb 的但是由于没有一个空闲块是大于 1000 kb 的就会导致内存分配的失败。同时由于内存映射已经建立，重整虚拟内存会导致整个程序到虚拟内存，虚拟内存到物理内存的映射表都需要更改，这种花费是我们无法承受的，所以我们需要设计更好的分配方式尽量避免这种碎片化情况的产生。\n\n![](https://tva1.sinaimg.cn/large/008i3skNly1gqrji3uyl1g30b404l3yd.gif)\n\n## 二、空闲块组织模式\n\n​\t关于动态内存分配器的设计其有不同的设计策略，而一种最为常见的区分方式是通过空闲块的组织模式来区分不同的分配器，这里简单介绍两种来自 CSAPP 的空闲块组织模式。\n\n### 隐式空闲链表\n\n​\t关于隐式空闲链表，它组织内存空闲块的形式非常简单，可以说是根本没有任何组织，我们可以通过遍历所有堆块（因为我们知道每一个堆块的大小）并验证其是否空闲来找到所有空闲块。所以将这种空闲块组织模式成为隐式空闲链表组织模式。\n\n- **优点：**简单、无需其他数据结构、节省空间\n\n- **缺点：**时间复杂度高，每次寻找空闲块都需要 O(n) 时间复杂度遍历所有堆块\n\n### 显示空闲链表\n\n​\t关于显示空闲链表，其是通过在空闲块中间添加两个指针分别指向前趋空闲块和后继空闲块，将空闲块串联成一个链表的模式。这时候我们在全局需要存储一个入口指针指向第一个空闲块，因为其显示的将所有空闲块进行串联，所以我们称这种组织模式为显示空闲链表\n\n- **优势：**速度快效率高，只需要 O(m) 遍历所有空闲块\n- **缺点：**组织复杂，且最小块大小较大（空闲块需要多两个指针的大小）\n\n在实际的动态内存分配器中我们常常使用显示空闲链表的模式，因为相比于它的效率提升，其多出的空间花费是微不足道的。\n\n\n\n## 三、空闲块适配模式\n\n​\t说完了空闲块组织模式，我们来谈谈常见的空闲块适配模式，为什么要适配空闲块？当然是因为请求分配一个内存大小的时候要找到一个相应合适的内存块，空闲块适配这个概念和前面讲到的内存碎片有着很大的联系，如果我们选的太大那么就会导致内部碎片的产生（如果没有其他分割策略），如果外部碎片太多，那么我们可能根本找不到合适的空闲块。\n\n接下来我主要介绍三类空闲块组织模式，首次适配（First Fit）、再次适配（Next Fit)和最佳适配（Best Fit）\n\n- **首次适配：** 遍历空闲块找到的第一个合适的空闲块就用来分配 （速度快，内存不一定节省）\n- **再次适配：**不从头找起，从上一次分配的空闲块继续往下找，找到的第一个适合的空闲块就用来分配 （默认了分配内存的大小基本一致，需要依赖于程序的内存分配特点和空闲块大小组织方式，效率不固定）\n- **最佳适配：**遍历所有空闲块，找到一个在能够符合分配条件下最小的空闲块来最大化减少内部碎片的产生（内存利用率最佳，但效率较低）\n\n\n\n## 四、空闲块顺序安排\n\n​\t空闲块顺序安排这个概念是归属于显示空闲链表组织模式下的，隐式空闲链表就完全不会有这个概念（因为根本没有组织xs）\n\n​\t下面来讲讲空闲块的顺序安排，其主要有两种组织形式，LIFO 顺序和地址顺序\n\n- **LIFO 顺序：**把释放块插入到空闲链表的开始处，结合首次适配策略，我们便每次会分配适合分配大小的最近释放的空闲块。\n\n由于我们每次都在空闲块链表开头插入新释放的空闲块，其释放能够在常数时间内 O(1) 完成。\n\n- **地址顺序：** 我们也可以简单地按地址顺序安排空闲块链表，即让空闲块链表中空闲块地址从低到高排序，这样符合堆的地址增长方式。\n\n通常情况下地址顺序结合首次适配的方式比LIFO结合首次适配拥有**更高的内存利用率**，这是从实验中得出的\n\n\n\n## 五、空闲块的存储技术\n\n### 分离适配与分段空闲链表（ Segregated Free List ）\n\n​\t在实际应用中，我们可以对空闲块的组织模式进行一定的大小分类，通过分类的方式，我们可以进一步减少空闲块的索引时间。\n\n**（这里的思想是运用的分层级的思想，这一思想在计算机科学中无处不在，例如数据库中的多级索引，多级页表的组织等，其实际上就是用分组的形式形成层级结构，通过使用更多的空间来换取索引的时间，是典型的空间换时间模式）**\n\n我们将根据空闲块大小的分类得出的不同类称为大小类，通常在一个最简单的应用中，我们可以使用二的幂次来对其进行表示。在实现上，我们可以将其组织为一个叫做分段空闲链表（Segregated Free List）的组织形式（如下图所示）。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gqrl8pm35nj30wc0u0aj5.jpg\" style=\"zoom:40%;\" />\n\n​\t例如我们将空闲块按二的幂次分为 MAX_ORDER 个大小类，每个 index = i 维护一个链表，连接着一类大小位于 $ 2^{i - 1}$ ~ $2^i$ 的空闲块，这样的组织形式，我们就可以先根据分配需求索引大类的大小，定位之后再进入链表根据适配规则适配空闲块。\n\n\n\n# Reference\n\n[1] *Computer Systems: A Programmer's Perspective*, 3/E (CS:APP3e). Randal E. Bryant and David R. O'Hallaron, Carnegie Mellon University.  Page 469\n\n[2] [Life of a Computer Scientist: sbrk() is not thread safe (likai.org)](https://lifecs.likai.org/2010/02/sbrk-is-not-thread-safe.html)\n\n","source":"_posts/ICS/Dynamic Memory Allocation.md","raw":"---\ntitle: Linux 动态内存分配机制详解\ndate: 2021-05-21 21:11:27\nindex_img: /img/ICS_Lab1/top.jpg\ncategory: [ICS]\ntags: [Malloc, VM]\n---\n\n\n\n​\t动态内存分配是虚拟内存组织中的核心概念，理解它对于帮助整个linux虚拟内存的组织以及堆上内存分配过程。本文会系统介绍动态内存的分配机制以及内存堆块的组织形式，并最后以 CMU CSAPP Malloc Lab 为例来详细讲解。\n\n**Malloc Lab 代码：[ZiYang-xie/Malloc_Lab: CMU Malloc Lab Repo (github.com)](https://github.com/ZiYang-xie/Malloc_Lab)** \n\n在开始介绍 malloc 机制前，我们先看一下虚拟内存的组织形式。\n\n# 【序】虚拟内存组织形式\n\n​\tlinux虚拟内存形式安装堆栈形式组织，栈位于内存高地址，分为内核栈和用户栈，增长方向从高到低。而堆位于内存的低地址，是程序员进行动态内存分配的空间，增长方向由低到高。堆和栈中间是共享映射空间，用于共享库在内存中的映射，这样每次如果有不同代码调用相同的共享库，就不需要再次向内存中复制一份副本，节省了时间和空间。\n\n​\t栈内存的更高地址用于存放一些全局数据结构\n\n​\t堆内存的更低地址按地址从低到高放置着代码段（.text）、已分配数据段（.data）、未分配数据段（.bss）。你可能还听说过 COMMON 段专门储存未初始化全局变量，真正的.bss存储未初始化的静态变量以及初始化为0的全局和静态变量 [1]，组织形式如下\n\n```c\nSECTIONS { \n  .text : { *(.text) }\n  .data : { *(.data) } \n  .bss :  { *(.bss)  *(COMMON) } \n} \n```\n\n虚拟内存的大致组成形式如下图所示。\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gqr0n9olxfj30e80e0gn3.jpg)\n\n​\t可以看到代码段从 *0x40000000* 处开始，从0到0x40000000的内存地址单纯是未被映射，代码段和0地址之间相隔一段距离在早期是为了防止 nullptr 对代码段的修改*（此处仅凭记忆，真实性需要进一步验证*）。但如今权限设计更加完善，上述意义已不再成立，这就变成了一种约定俗成的规则。\n\n在了解了虚拟内存的大致组织模式之后，我们便可以开始讲解 Malloc 的基本机制。\n\n\n\n# 【一】动态内存分配的实现方式\n\n​\tLinux动态内存分配的实现方式是由 mmap, munmap 以及 brk, sbrk 这四个系统函数联合完成的。\n\n## mmap 与 munmap\n\n**mmap**\n\n```c\nvoid *mmap(void *addr, size_t length, int prot, int flags,\n           int fd, off_t offset);\n```\n\nmmap 创建一个新的虚拟内存空间和文件设备之间的映射。\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gqr27vczrhj30jd0a9tah.jpg)\n\n​\t其中 addr 代表分配开始地址，fd是相应文件描述符，len是指文件存储部分映射的长度，offset指的是从文件头开始offset距离开始分配。\n\n- prot包含权限位\n\n```c\nPROT_EXEC // 可执行\nPROT_READ // 可读\nPROT_WRITE // 可写\nPROT_NONE // 不可访问\n```\n\n- Flags 表示映射对象类型\n\n```c\nMAP_ANON // 匿名请求二进制零的\nMAP_PRIVATE // 私有的\nMAP_SHARED // 共享的\n```\n\n\n\n**munmap**\n\n取消相应地址内存块的映射\n\n```c\nint munmap(void *addr, size_t length);\n```\n\n很好理解取消开始地址为 addr 长度为 length 的内存映射。\n\n\n\n## brk 与 sbrk\n\n​\tbrk, sbrk 用来移动 program break 指向的指针来扩展堆内存，program break 位于堆顶未初始化数据段末尾之后，通过移动 program break 指针来动态控制堆的大小。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gqri33m8lkj30ic0huq62.jpg\" style=\"zoom:50%;\" />\n\n**brk**\n\n```c\nint brk(void *addr);\n```\n\n​\tbrk 会在允许的情况下简单的将 program break 设为 addr 地址，来控制堆内存大小。相当于 program break 的绝对移动\n\n**sbrk**\n\n```c\nvoid *sbrk(intptr_t increment);\n```\n\n​\tsbrk 会在允许的情况下将 program break 指针加 increment 值，返回扩展前的 program break 地址。当```increment```为正值时，堆被扩展；为0时，返回当前 program break 的指针；为负值时，堆被收缩。相当于 program break 的相对移动\n\n​\t值得注意的是，当无法扩展时 (申请了大于允许的内存，或碰到了共享内存段)，sbrk会返回 (void *)-1 并且会设置 errorno 为 **ENOMEM**（ENO Memory）\n\n### 关于 sbrk 的更多细节\n\n​\tsbrk 实际上是 linux 的一个上古函数，如今大多数内存分配器都倾向于使用 mmap 而不使用 sbrk，是因为 sbrk 是线程不安全的。由于 sbrk 的组织形式是对 program break 的相对移动来进行对扩展，那么对堆块的组织释放方式只能使用 LIFO。假设 sbrk 函数是原子的，在多进程调用时，如果一个进程要释放一个块，且其正好位于结尾program break处，我们选择 increment 为一个负值进行堆收缩（这是正确的）；但在我们还未释放的时候，另一个进程选择分配内存，调用 sbrk。在分配后我们继续进行释放此时我们需要释放的块后增加了一个新块，再调用 sbrk 会导致另一个进程分配的块被释放从而引发错误。\n\n​\t为了解决这个问题，我们也可以自己设计一个进程安全的 sbrk 函数，称为 sbrk_safe\n\n```c\nvoid *sbrk_safe(intptr_t increment, void *expect_top);\n```\n\n​\t其增加了一个参数expect_top，思想很简单，就是在每次调用 sbrk_safe 的时候将选择释放块的内存地址填入 expect_top，函数中验证其是否是在堆顶，如果不是就返回错误。\n\n​\t（另外 sbrk 可能还有其他问题，比如受到 mmap 分配内存和共享内存的阻碍导致内存分配的间断。这里有待进一步研究探讨）\n\n\n\n# 【二】动态内存分配器的设计\n\n​\t\t对于堆上的动态内存分配，我们通常将其组织为“块”的模式，一个块就是指一段连续内存地址，而根据其是否被分配数据又被划分为**空闲块**和**分配块**两种。\n\n## 序、内存块结构\n\n​\t首先我们需要了解一个简单的技巧，就是如果有空闲块相邻时我们是可以将其进行合并为一个空闲块的，这样一来我们就可以分配更大的内存，并减少内存的碎片程度。注意到由于我们需要对块进行分配和合并，所以我们必须要知道块的**大小信息**和**块的分类**，因而一个内存块中其并不是所有位置都存储着有效信息。以32位系统为例，双字对齐（8 bytes）我们设计一个块的头部一个字大小（4 bytes）放置着块的大小信息和分配信息，由于是双字对齐的，所以块大小的后3位永远是0（1000）, 因此我们用前29位放大小信息，后3位放置分配信息（实际上是最后一位）001表示已分配、000表示空闲。中间放置有效载荷、即数据段，尾部可有一个填充。\n\n​\t最后注意到我们需要对块进行**合并**（在后文中我们会详细讨论合并策略），所以在尾部也放置一个大小和分配标记有利于下一块相邻块快速找到上一块的分配状态和大小来达成向前合并的操作，所以我们在脚部也增加一个字大小（4 bytes）和头部相同的大小分配标记。这个特征称为**边界标记**\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gqrjzzz4iaj30go0dwjyj.jpg\" style=\"zoom:50%;\" />\n\n## 一、内存碎片\n\n​\t\t关于内存分配，首先我们要有一个直观，在组织过程中我们确实可以简单的每次分配内存都创建一个所需大小的块，但经过频繁的分配释放，很快堆上的整块内存就会被划分为十分杂乱的小块。这种情况称之为内存碎片化，内存碎片化是一个十分严重的问题，其可能导致内存极大的浪费，因此要理解动态内存分配器的设计之前首先我们需要理解内存碎片的概念，来帮助我们更好的设计一个性能更加优良的分配器。\n\n​\t关于内存碎片根据其表现形式可以分为两类，内部碎片和外部碎片。\n\n### 内部内存碎片\n\n​\t内部内存碎片可以有一个直观的理解（虽然可能有点夸张），就是如果你仅仅需要 1kb 的内存用于存放数据，但是你申请了 2GB 大小的内存空间用来存这 1kb 的数据，那么里面大部分的内存全部都被浪费掉了，这时候如果你再要申请内存，空闲的内存可能就不够了。这就是内部碎片。\n\n​\t这时候有人可能会问，那么我们之间分配需要分配的内存大小就好了啊？那为什么内部碎片还会产生呢？确实说的很对，。但有时候由于内存对齐需要以及分配器策略等影响我们并不能够直接分配正好就是需求大小的内存块，其产生机制我将会在下文中进一步深入讲解\n\n\n\n### 外部内存碎片\n\n​\t外部内存碎片的产生主要源于频繁的大小不一的内存分配和释放过程。经过一系列的分配释放，最后整块的内存会被切分成空闲块分配块相互交杂的情况，如下图所示，这时候如果我们想要再分配一个 1000 kb 的数据块，可能所有的空闲块加起来是大于 1000 kb 的但是由于没有一个空闲块是大于 1000 kb 的就会导致内存分配的失败。同时由于内存映射已经建立，重整虚拟内存会导致整个程序到虚拟内存，虚拟内存到物理内存的映射表都需要更改，这种花费是我们无法承受的，所以我们需要设计更好的分配方式尽量避免这种碎片化情况的产生。\n\n![](https://tva1.sinaimg.cn/large/008i3skNly1gqrji3uyl1g30b404l3yd.gif)\n\n## 二、空闲块组织模式\n\n​\t关于动态内存分配器的设计其有不同的设计策略，而一种最为常见的区分方式是通过空闲块的组织模式来区分不同的分配器，这里简单介绍两种来自 CSAPP 的空闲块组织模式。\n\n### 隐式空闲链表\n\n​\t关于隐式空闲链表，它组织内存空闲块的形式非常简单，可以说是根本没有任何组织，我们可以通过遍历所有堆块（因为我们知道每一个堆块的大小）并验证其是否空闲来找到所有空闲块。所以将这种空闲块组织模式成为隐式空闲链表组织模式。\n\n- **优点：**简单、无需其他数据结构、节省空间\n\n- **缺点：**时间复杂度高，每次寻找空闲块都需要 O(n) 时间复杂度遍历所有堆块\n\n### 显示空闲链表\n\n​\t关于显示空闲链表，其是通过在空闲块中间添加两个指针分别指向前趋空闲块和后继空闲块，将空闲块串联成一个链表的模式。这时候我们在全局需要存储一个入口指针指向第一个空闲块，因为其显示的将所有空闲块进行串联，所以我们称这种组织模式为显示空闲链表\n\n- **优势：**速度快效率高，只需要 O(m) 遍历所有空闲块\n- **缺点：**组织复杂，且最小块大小较大（空闲块需要多两个指针的大小）\n\n在实际的动态内存分配器中我们常常使用显示空闲链表的模式，因为相比于它的效率提升，其多出的空间花费是微不足道的。\n\n\n\n## 三、空闲块适配模式\n\n​\t说完了空闲块组织模式，我们来谈谈常见的空闲块适配模式，为什么要适配空闲块？当然是因为请求分配一个内存大小的时候要找到一个相应合适的内存块，空闲块适配这个概念和前面讲到的内存碎片有着很大的联系，如果我们选的太大那么就会导致内部碎片的产生（如果没有其他分割策略），如果外部碎片太多，那么我们可能根本找不到合适的空闲块。\n\n接下来我主要介绍三类空闲块组织模式，首次适配（First Fit）、再次适配（Next Fit)和最佳适配（Best Fit）\n\n- **首次适配：** 遍历空闲块找到的第一个合适的空闲块就用来分配 （速度快，内存不一定节省）\n- **再次适配：**不从头找起，从上一次分配的空闲块继续往下找，找到的第一个适合的空闲块就用来分配 （默认了分配内存的大小基本一致，需要依赖于程序的内存分配特点和空闲块大小组织方式，效率不固定）\n- **最佳适配：**遍历所有空闲块，找到一个在能够符合分配条件下最小的空闲块来最大化减少内部碎片的产生（内存利用率最佳，但效率较低）\n\n\n\n## 四、空闲块顺序安排\n\n​\t空闲块顺序安排这个概念是归属于显示空闲链表组织模式下的，隐式空闲链表就完全不会有这个概念（因为根本没有组织xs）\n\n​\t下面来讲讲空闲块的顺序安排，其主要有两种组织形式，LIFO 顺序和地址顺序\n\n- **LIFO 顺序：**把释放块插入到空闲链表的开始处，结合首次适配策略，我们便每次会分配适合分配大小的最近释放的空闲块。\n\n由于我们每次都在空闲块链表开头插入新释放的空闲块，其释放能够在常数时间内 O(1) 完成。\n\n- **地址顺序：** 我们也可以简单地按地址顺序安排空闲块链表，即让空闲块链表中空闲块地址从低到高排序，这样符合堆的地址增长方式。\n\n通常情况下地址顺序结合首次适配的方式比LIFO结合首次适配拥有**更高的内存利用率**，这是从实验中得出的\n\n\n\n## 五、空闲块的存储技术\n\n### 分离适配与分段空闲链表（ Segregated Free List ）\n\n​\t在实际应用中，我们可以对空闲块的组织模式进行一定的大小分类，通过分类的方式，我们可以进一步减少空闲块的索引时间。\n\n**（这里的思想是运用的分层级的思想，这一思想在计算机科学中无处不在，例如数据库中的多级索引，多级页表的组织等，其实际上就是用分组的形式形成层级结构，通过使用更多的空间来换取索引的时间，是典型的空间换时间模式）**\n\n我们将根据空闲块大小的分类得出的不同类称为大小类，通常在一个最简单的应用中，我们可以使用二的幂次来对其进行表示。在实现上，我们可以将其组织为一个叫做分段空闲链表（Segregated Free List）的组织形式（如下图所示）。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gqrl8pm35nj30wc0u0aj5.jpg\" style=\"zoom:40%;\" />\n\n​\t例如我们将空闲块按二的幂次分为 MAX_ORDER 个大小类，每个 index = i 维护一个链表，连接着一类大小位于 $ 2^{i - 1}$ ~ $2^i$ 的空闲块，这样的组织形式，我们就可以先根据分配需求索引大类的大小，定位之后再进入链表根据适配规则适配空闲块。\n\n\n\n# Reference\n\n[1] *Computer Systems: A Programmer's Perspective*, 3/E (CS:APP3e). Randal E. Bryant and David R. O'Hallaron, Carnegie Mellon University.  Page 469\n\n[2] [Life of a Computer Scientist: sbrk() is not thread safe (likai.org)](https://lifecs.likai.org/2010/02/sbrk-is-not-thread-safe.html)\n\n","slug":"ICS/Dynamic Memory Allocation","published":1,"updated":"2026-02-03T05:42:14.431Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvc00127uit2v5g1f67","content":"<p>​    动态内存分配是虚拟内存组织中的核心概念，理解它对于帮助整个linux虚拟内存的组织以及堆上内存分配过程。本文会系统介绍动态内存的分配机制以及内存堆块的组织形式，并最后以 CMU CSAPP Malloc Lab 为例来详细讲解。</p>\n<p><strong>Malloc Lab 代码：<a href=\"https://github.com/ZiYang-xie/Malloc_Lab\">ZiYang-xie/Malloc_Lab: CMU Malloc Lab Repo (github.com)</a></strong> </p>\n<p>在开始介绍 malloc 机制前，我们先看一下虚拟内存的组织形式。</p>\n<h1 id=\"【序】虚拟内存组织形式\"><a href=\"#【序】虚拟内存组织形式\" class=\"headerlink\" title=\"【序】虚拟内存组织形式\"></a>【序】虚拟内存组织形式</h1><p>​    linux虚拟内存形式安装堆栈形式组织，栈位于内存高地址，分为内核栈和用户栈，增长方向从高到低。而堆位于内存的低地址，是程序员进行动态内存分配的空间，增长方向由低到高。堆和栈中间是共享映射空间，用于共享库在内存中的映射，这样每次如果有不同代码调用相同的共享库，就不需要再次向内存中复制一份副本，节省了时间和空间。</p>\n<p>​    栈内存的更高地址用于存放一些全局数据结构</p>\n<p>​    堆内存的更低地址按地址从低到高放置着代码段（.text）、已分配数据段（.data）、未分配数据段（.bss）。你可能还听说过 COMMON 段专门储存未初始化全局变量，真正的.bss存储未初始化的静态变量以及初始化为0的全局和静态变量 [1]，组织形式如下</p>\n<pre><code class=\"hljs c\">SECTIONS &#123; \n  .text : &#123; *(.text) &#125;\n  .data : &#123; *(.data) &#125; \n  .bss :  &#123; *(.bss)  *(COMMON) &#125; \n&#125;</code></pre>\n<p>虚拟内存的大致组成形式如下图所示。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gqr0n9olxfj30e80e0gn3.jpg\" alt></p>\n<p>​    可以看到代码段从 <em>0x40000000</em> 处开始，从0到0x40000000的内存地址单纯是未被映射，代码段和0地址之间相隔一段距离在早期是为了防止 nullptr 对代码段的修改<em>（此处仅凭记忆，真实性需要进一步验证</em>）。但如今权限设计更加完善，上述意义已不再成立，这就变成了一种约定俗成的规则。</p>\n<p>在了解了虚拟内存的大致组织模式之后，我们便可以开始讲解 Malloc 的基本机制。</p>\n<h1 id=\"【一】动态内存分配的实现方式\"><a href=\"#【一】动态内存分配的实现方式\" class=\"headerlink\" title=\"【一】动态内存分配的实现方式\"></a>【一】动态内存分配的实现方式</h1><p>​    Linux动态内存分配的实现方式是由 mmap, munmap 以及 brk, sbrk 这四个系统函数联合完成的。</p>\n<h2 id=\"mmap-与-munmap\"><a href=\"#mmap-与-munmap\" class=\"headerlink\" title=\"mmap 与 munmap\"></a>mmap 与 munmap</h2><p><strong>mmap</strong></p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> *<span class=\"hljs-title\">mmap</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span> *addr, <span class=\"hljs-keyword\">size_t</span> length, <span class=\"hljs-keyword\">int</span> prot, <span class=\"hljs-keyword\">int</span> flags,</span></span>\n<span class=\"hljs-function\"><span class=\"hljs-params\">           <span class=\"hljs-keyword\">int</span> fd, <span class=\"hljs-keyword\">off_t</span> offset)</span></span>;</code></pre>\n<p>mmap 创建一个新的虚拟内存空间和文件设备之间的映射。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gqr27vczrhj30jd0a9tah.jpg\" alt></p>\n<p>​    其中 addr 代表分配开始地址，fd是相应文件描述符，len是指文件存储部分映射的长度，offset指的是从文件头开始offset距离开始分配。</p>\n<ul>\n<li>prot包含权限位</li>\n</ul>\n<pre><code class=\"hljs c\">PROT_EXEC <span class=\"hljs-comment\">// 可执行</span>\nPROT_READ <span class=\"hljs-comment\">// 可读</span>\nPROT_WRITE <span class=\"hljs-comment\">// 可写</span>\nPROT_NONE <span class=\"hljs-comment\">// 不可访问</span></code></pre>\n<ul>\n<li>Flags 表示映射对象类型</li>\n</ul>\n<pre><code class=\"hljs c\">MAP_ANON <span class=\"hljs-comment\">// 匿名请求二进制零的</span>\nMAP_PRIVATE <span class=\"hljs-comment\">// 私有的</span>\nMAP_SHARED <span class=\"hljs-comment\">// 共享的</span></code></pre>\n<p><strong>munmap</strong></p>\n<p>取消相应地址内存块的映射</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">munmap</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span> *addr, <span class=\"hljs-keyword\">size_t</span> length)</span></span>;</code></pre>\n<p>很好理解取消开始地址为 addr 长度为 length 的内存映射。</p>\n<h2 id=\"brk-与-sbrk\"><a href=\"#brk-与-sbrk\" class=\"headerlink\" title=\"brk 与 sbrk\"></a>brk 与 sbrk</h2><p>​    brk, sbrk 用来移动 program break 指向的指针来扩展堆内存，program break 位于堆顶未初始化数据段末尾之后，通过移动 program break 指针来动态控制堆的大小。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gqri33m8lkj30ic0huq62.jpg\" style=\"zoom:50%;\"></p>\n<p><strong>brk</strong></p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">brk</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span> *addr)</span></span>;</code></pre>\n<p>​    brk 会在允许的情况下简单的将 program break 设为 addr 地址，来控制堆内存大小。相当于 program break 的绝对移动</p>\n<p><strong>sbrk</strong></p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> *<span class=\"hljs-title\">sbrk</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">intptr_t</span> increment)</span></span>;</code></pre>\n<p>​    sbrk 会在允许的情况下将 program break 指针加 increment 值，返回扩展前的 program break 地址。当<code>increment</code>为正值时，堆被扩展；为0时，返回当前 program break 的指针；为负值时，堆被收缩。相当于 program break 的相对移动</p>\n<p>​    值得注意的是，当无法扩展时 (申请了大于允许的内存，或碰到了共享内存段)，sbrk会返回 (void <em>)-1 并且会设置 errorno 为 <em>*ENOMEM</em></em>（ENO Memory）</p>\n<h3 id=\"关于-sbrk-的更多细节\"><a href=\"#关于-sbrk-的更多细节\" class=\"headerlink\" title=\"关于 sbrk 的更多细节\"></a>关于 sbrk 的更多细节</h3><p>​    sbrk 实际上是 linux 的一个上古函数，如今大多数内存分配器都倾向于使用 mmap 而不使用 sbrk，是因为 sbrk 是线程不安全的。由于 sbrk 的组织形式是对 program break 的相对移动来进行对扩展，那么对堆块的组织释放方式只能使用 LIFO。假设 sbrk 函数是原子的，在多进程调用时，如果一个进程要释放一个块，且其正好位于结尾program break处，我们选择 increment 为一个负值进行堆收缩（这是正确的）；但在我们还未释放的时候，另一个进程选择分配内存，调用 sbrk。在分配后我们继续进行释放此时我们需要释放的块后增加了一个新块，再调用 sbrk 会导致另一个进程分配的块被释放从而引发错误。</p>\n<p>​    为了解决这个问题，我们也可以自己设计一个进程安全的 sbrk 函数，称为 sbrk_safe</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> *<span class=\"hljs-title\">sbrk_safe</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">intptr_t</span> increment, <span class=\"hljs-keyword\">void</span> *expect_top)</span></span>;</code></pre>\n<p>​    其增加了一个参数expect_top，思想很简单，就是在每次调用 sbrk_safe 的时候将选择释放块的内存地址填入 expect_top，函数中验证其是否是在堆顶，如果不是就返回错误。</p>\n<p>​    （另外 sbrk 可能还有其他问题，比如受到 mmap 分配内存和共享内存的阻碍导致内存分配的间断。这里有待进一步研究探讨）</p>\n<h1 id=\"【二】动态内存分配器的设计\"><a href=\"#【二】动态内存分配器的设计\" class=\"headerlink\" title=\"【二】动态内存分配器的设计\"></a>【二】动态内存分配器的设计</h1><p>​        对于堆上的动态内存分配，我们通常将其组织为“块”的模式，一个块就是指一段连续内存地址，而根据其是否被分配数据又被划分为<strong>空闲块</strong>和<strong>分配块</strong>两种。</p>\n<h2 id=\"序、内存块结构\"><a href=\"#序、内存块结构\" class=\"headerlink\" title=\"序、内存块结构\"></a>序、内存块结构</h2><p>​    首先我们需要了解一个简单的技巧，就是如果有空闲块相邻时我们是可以将其进行合并为一个空闲块的，这样一来我们就可以分配更大的内存，并减少内存的碎片程度。注意到由于我们需要对块进行分配和合并，所以我们必须要知道块的<strong>大小信息</strong>和<strong>块的分类</strong>，因而一个内存块中其并不是所有位置都存储着有效信息。以32位系统为例，双字对齐（8 bytes）我们设计一个块的头部一个字大小（4 bytes）放置着块的大小信息和分配信息，由于是双字对齐的，所以块大小的后3位永远是0（1000）, 因此我们用前29位放大小信息，后3位放置分配信息（实际上是最后一位）001表示已分配、000表示空闲。中间放置有效载荷、即数据段，尾部可有一个填充。</p>\n<p>​    最后注意到我们需要对块进行<strong>合并</strong>（在后文中我们会详细讨论合并策略），所以在尾部也放置一个大小和分配标记有利于下一块相邻块快速找到上一块的分配状态和大小来达成向前合并的操作，所以我们在脚部也增加一个字大小（4 bytes）和头部相同的大小分配标记。这个特征称为<strong>边界标记</strong></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gqrjzzz4iaj30go0dwjyj.jpg\" style=\"zoom:50%;\"></p>\n<h2 id=\"一、内存碎片\"><a href=\"#一、内存碎片\" class=\"headerlink\" title=\"一、内存碎片\"></a>一、内存碎片</h2><p>​        关于内存分配，首先我们要有一个直观，在组织过程中我们确实可以简单的每次分配内存都创建一个所需大小的块，但经过频繁的分配释放，很快堆上的整块内存就会被划分为十分杂乱的小块。这种情况称之为内存碎片化，内存碎片化是一个十分严重的问题，其可能导致内存极大的浪费，因此要理解动态内存分配器的设计之前首先我们需要理解内存碎片的概念，来帮助我们更好的设计一个性能更加优良的分配器。</p>\n<p>​    关于内存碎片根据其表现形式可以分为两类，内部碎片和外部碎片。</p>\n<h3 id=\"内部内存碎片\"><a href=\"#内部内存碎片\" class=\"headerlink\" title=\"内部内存碎片\"></a>内部内存碎片</h3><p>​    内部内存碎片可以有一个直观的理解（虽然可能有点夸张），就是如果你仅仅需要 1kb 的内存用于存放数据，但是你申请了 2GB 大小的内存空间用来存这 1kb 的数据，那么里面大部分的内存全部都被浪费掉了，这时候如果你再要申请内存，空闲的内存可能就不够了。这就是内部碎片。</p>\n<p>​    这时候有人可能会问，那么我们之间分配需要分配的内存大小就好了啊？那为什么内部碎片还会产生呢？确实说的很对，。但有时候由于内存对齐需要以及分配器策略等影响我们并不能够直接分配正好就是需求大小的内存块，其产生机制我将会在下文中进一步深入讲解</p>\n<h3 id=\"外部内存碎片\"><a href=\"#外部内存碎片\" class=\"headerlink\" title=\"外部内存碎片\"></a>外部内存碎片</h3><p>​    外部内存碎片的产生主要源于频繁的大小不一的内存分配和释放过程。经过一系列的分配释放，最后整块的内存会被切分成空闲块分配块相互交杂的情况，如下图所示，这时候如果我们想要再分配一个 1000 kb 的数据块，可能所有的空闲块加起来是大于 1000 kb 的但是由于没有一个空闲块是大于 1000 kb 的就会导致内存分配的失败。同时由于内存映射已经建立，重整虚拟内存会导致整个程序到虚拟内存，虚拟内存到物理内存的映射表都需要更改，这种花费是我们无法承受的，所以我们需要设计更好的分配方式尽量避免这种碎片化情况的产生。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gqrji3uyl1g30b404l3yd.gif\" alt></p>\n<h2 id=\"二、空闲块组织模式\"><a href=\"#二、空闲块组织模式\" class=\"headerlink\" title=\"二、空闲块组织模式\"></a>二、空闲块组织模式</h2><p>​    关于动态内存分配器的设计其有不同的设计策略，而一种最为常见的区分方式是通过空闲块的组织模式来区分不同的分配器，这里简单介绍两种来自 CSAPP 的空闲块组织模式。</p>\n<h3 id=\"隐式空闲链表\"><a href=\"#隐式空闲链表\" class=\"headerlink\" title=\"隐式空闲链表\"></a>隐式空闲链表</h3><p>​    关于隐式空闲链表，它组织内存空闲块的形式非常简单，可以说是根本没有任何组织，我们可以通过遍历所有堆块（因为我们知道每一个堆块的大小）并验证其是否空闲来找到所有空闲块。所以将这种空闲块组织模式成为隐式空闲链表组织模式。</p>\n<ul>\n<li><p><strong>优点：</strong>简单、无需其他数据结构、节省空间</p>\n</li>\n<li><p><strong>缺点：</strong>时间复杂度高，每次寻找空闲块都需要 O(n) 时间复杂度遍历所有堆块</p>\n</li>\n</ul>\n<h3 id=\"显示空闲链表\"><a href=\"#显示空闲链表\" class=\"headerlink\" title=\"显示空闲链表\"></a>显示空闲链表</h3><p>​    关于显示空闲链表，其是通过在空闲块中间添加两个指针分别指向前趋空闲块和后继空闲块，将空闲块串联成一个链表的模式。这时候我们在全局需要存储一个入口指针指向第一个空闲块，因为其显示的将所有空闲块进行串联，所以我们称这种组织模式为显示空闲链表</p>\n<ul>\n<li><strong>优势：</strong>速度快效率高，只需要 O(m) 遍历所有空闲块</li>\n<li><strong>缺点：</strong>组织复杂，且最小块大小较大（空闲块需要多两个指针的大小）</li>\n</ul>\n<p>在实际的动态内存分配器中我们常常使用显示空闲链表的模式，因为相比于它的效率提升，其多出的空间花费是微不足道的。</p>\n<h2 id=\"三、空闲块适配模式\"><a href=\"#三、空闲块适配模式\" class=\"headerlink\" title=\"三、空闲块适配模式\"></a>三、空闲块适配模式</h2><p>​    说完了空闲块组织模式，我们来谈谈常见的空闲块适配模式，为什么要适配空闲块？当然是因为请求分配一个内存大小的时候要找到一个相应合适的内存块，空闲块适配这个概念和前面讲到的内存碎片有着很大的联系，如果我们选的太大那么就会导致内部碎片的产生（如果没有其他分割策略），如果外部碎片太多，那么我们可能根本找不到合适的空闲块。</p>\n<p>接下来我主要介绍三类空闲块组织模式，首次适配（First Fit）、再次适配（Next Fit)和最佳适配（Best Fit）</p>\n<ul>\n<li><strong>首次适配：</strong> 遍历空闲块找到的第一个合适的空闲块就用来分配 （速度快，内存不一定节省）</li>\n<li><strong>再次适配：</strong>不从头找起，从上一次分配的空闲块继续往下找，找到的第一个适合的空闲块就用来分配 （默认了分配内存的大小基本一致，需要依赖于程序的内存分配特点和空闲块大小组织方式，效率不固定）</li>\n<li><strong>最佳适配：</strong>遍历所有空闲块，找到一个在能够符合分配条件下最小的空闲块来最大化减少内部碎片的产生（内存利用率最佳，但效率较低）</li>\n</ul>\n<h2 id=\"四、空闲块顺序安排\"><a href=\"#四、空闲块顺序安排\" class=\"headerlink\" title=\"四、空闲块顺序安排\"></a>四、空闲块顺序安排</h2><p>​    空闲块顺序安排这个概念是归属于显示空闲链表组织模式下的，隐式空闲链表就完全不会有这个概念（因为根本没有组织xs）</p>\n<p>​    下面来讲讲空闲块的顺序安排，其主要有两种组织形式，LIFO 顺序和地址顺序</p>\n<ul>\n<li><strong>LIFO 顺序：</strong>把释放块插入到空闲链表的开始处，结合首次适配策略，我们便每次会分配适合分配大小的最近释放的空闲块。</li>\n</ul>\n<p>由于我们每次都在空闲块链表开头插入新释放的空闲块，其释放能够在常数时间内 O(1) 完成。</p>\n<ul>\n<li><strong>地址顺序：</strong> 我们也可以简单地按地址顺序安排空闲块链表，即让空闲块链表中空闲块地址从低到高排序，这样符合堆的地址增长方式。</li>\n</ul>\n<p>通常情况下地址顺序结合首次适配的方式比LIFO结合首次适配拥有<strong>更高的内存利用率</strong>，这是从实验中得出的</p>\n<h2 id=\"五、空闲块的存储技术\"><a href=\"#五、空闲块的存储技术\" class=\"headerlink\" title=\"五、空闲块的存储技术\"></a>五、空闲块的存储技术</h2><h3 id=\"分离适配与分段空闲链表（-Segregated-Free-List-）\"><a href=\"#分离适配与分段空闲链表（-Segregated-Free-List-）\" class=\"headerlink\" title=\"分离适配与分段空闲链表（ Segregated Free List ）\"></a>分离适配与分段空闲链表（ Segregated Free List ）</h3><p>​    在实际应用中，我们可以对空闲块的组织模式进行一定的大小分类，通过分类的方式，我们可以进一步减少空闲块的索引时间。</p>\n<p><strong>（这里的思想是运用的分层级的思想，这一思想在计算机科学中无处不在，例如数据库中的多级索引，多级页表的组织等，其实际上就是用分组的形式形成层级结构，通过使用更多的空间来换取索引的时间，是典型的空间换时间模式）</strong></p>\n<p>我们将根据空闲块大小的分类得出的不同类称为大小类，通常在一个最简单的应用中，我们可以使用二的幂次来对其进行表示。在实现上，我们可以将其组织为一个叫做分段空闲链表（Segregated Free List）的组织形式（如下图所示）。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gqrl8pm35nj30wc0u0aj5.jpg\" style=\"zoom:40%;\"></p>\n<p>​    例如我们将空闲块按二的幂次分为 MAX_ORDER 个大小类，每个 index = i 维护一个链表，连接着一类大小位于 $ 2^{i - 1}$ ~ $2^i$ 的空闲块，这样的组织形式，我们就可以先根据分配需求索引大类的大小，定位之后再进入链表根据适配规则适配空闲块。</p>\n<h1 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h1><p>[1] <em>Computer Systems: A Programmer’s Perspective</em>, 3/E (CS:APP3e). Randal E. Bryant and David R. O’Hallaron, Carnegie Mellon University.  Page 469</p>\n<p>[2] <a href=\"https://lifecs.likai.org/2010/02/sbrk-is-not-thread-safe.html\">Life of a Computer Scientist: sbrk() is not thread safe (likai.org)</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>​    动态内存分配是虚拟内存组织中的核心概念，理解它对于帮助整个linux虚拟内存的组织以及堆上内存分配过程。本文会系统介绍动态内存的分配机制以及内存堆块的组织形式，并最后以 CMU CSAPP Malloc Lab 为例来详细讲解。</p>\n<p><strong>Malloc Lab 代码：<a href=\"https://github.com/ZiYang-xie/Malloc_Lab\">ZiYang-xie/Malloc_Lab: CMU Malloc Lab Repo (github.com)</a></strong> </p>\n<p>在开始介绍 malloc 机制前，我们先看一下虚拟内存的组织形式。</p>\n<h1 id=\"【序】虚拟内存组织形式\"><a href=\"#【序】虚拟内存组织形式\" class=\"headerlink\" title=\"【序】虚拟内存组织形式\"></a>【序】虚拟内存组织形式</h1><p>​    linux虚拟内存形式安装堆栈形式组织，栈位于内存高地址，分为内核栈和用户栈，增长方向从高到低。而堆位于内存的低地址，是程序员进行动态内存分配的空间，增长方向由低到高。堆和栈中间是共享映射空间，用于共享库在内存中的映射，这样每次如果有不同代码调用相同的共享库，就不需要再次向内存中复制一份副本，节省了时间和空间。</p>\n<p>​    栈内存的更高地址用于存放一些全局数据结构</p>\n<p>​    堆内存的更低地址按地址从低到高放置着代码段（.text）、已分配数据段（.data）、未分配数据段（.bss）。你可能还听说过 COMMON 段专门储存未初始化全局变量，真正的.bss存储未初始化的静态变量以及初始化为0的全局和静态变量 [1]，组织形式如下</p>\n<pre><code class=\"hljs c\">SECTIONS &#123; \n  .text : &#123; *(.text) &#125;\n  .data : &#123; *(.data) &#125; \n  .bss :  &#123; *(.bss)  *(COMMON) &#125; \n&#125;</code></pre>\n<p>虚拟内存的大致组成形式如下图所示。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gqr0n9olxfj30e80e0gn3.jpg\" alt></p>\n<p>​    可以看到代码段从 <em>0x40000000</em> 处开始，从0到0x40000000的内存地址单纯是未被映射，代码段和0地址之间相隔一段距离在早期是为了防止 nullptr 对代码段的修改<em>（此处仅凭记忆，真实性需要进一步验证</em>）。但如今权限设计更加完善，上述意义已不再成立，这就变成了一种约定俗成的规则。</p>\n<p>在了解了虚拟内存的大致组织模式之后，我们便可以开始讲解 Malloc 的基本机制。</p>\n<h1 id=\"【一】动态内存分配的实现方式\"><a href=\"#【一】动态内存分配的实现方式\" class=\"headerlink\" title=\"【一】动态内存分配的实现方式\"></a>【一】动态内存分配的实现方式</h1><p>​    Linux动态内存分配的实现方式是由 mmap, munmap 以及 brk, sbrk 这四个系统函数联合完成的。</p>\n<h2 id=\"mmap-与-munmap\"><a href=\"#mmap-与-munmap\" class=\"headerlink\" title=\"mmap 与 munmap\"></a>mmap 与 munmap</h2><p><strong>mmap</strong></p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> *<span class=\"hljs-title\">mmap</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span> *addr, <span class=\"hljs-keyword\">size_t</span> length, <span class=\"hljs-keyword\">int</span> prot, <span class=\"hljs-keyword\">int</span> flags,</span></span>\n<span class=\"hljs-function\"><span class=\"hljs-params\">           <span class=\"hljs-keyword\">int</span> fd, <span class=\"hljs-keyword\">off_t</span> offset)</span></span>;</code></pre>\n<p>mmap 创建一个新的虚拟内存空间和文件设备之间的映射。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gqr27vczrhj30jd0a9tah.jpg\" alt></p>\n<p>​    其中 addr 代表分配开始地址，fd是相应文件描述符，len是指文件存储部分映射的长度，offset指的是从文件头开始offset距离开始分配。</p>\n<ul>\n<li>prot包含权限位</li>\n</ul>\n<pre><code class=\"hljs c\">PROT_EXEC <span class=\"hljs-comment\">// 可执行</span>\nPROT_READ <span class=\"hljs-comment\">// 可读</span>\nPROT_WRITE <span class=\"hljs-comment\">// 可写</span>\nPROT_NONE <span class=\"hljs-comment\">// 不可访问</span></code></pre>\n<ul>\n<li>Flags 表示映射对象类型</li>\n</ul>\n<pre><code class=\"hljs c\">MAP_ANON <span class=\"hljs-comment\">// 匿名请求二进制零的</span>\nMAP_PRIVATE <span class=\"hljs-comment\">// 私有的</span>\nMAP_SHARED <span class=\"hljs-comment\">// 共享的</span></code></pre>\n<p><strong>munmap</strong></p>\n<p>取消相应地址内存块的映射</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">munmap</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span> *addr, <span class=\"hljs-keyword\">size_t</span> length)</span></span>;</code></pre>\n<p>很好理解取消开始地址为 addr 长度为 length 的内存映射。</p>\n<h2 id=\"brk-与-sbrk\"><a href=\"#brk-与-sbrk\" class=\"headerlink\" title=\"brk 与 sbrk\"></a>brk 与 sbrk</h2><p>​    brk, sbrk 用来移动 program break 指向的指针来扩展堆内存，program break 位于堆顶未初始化数据段末尾之后，通过移动 program break 指针来动态控制堆的大小。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gqri33m8lkj30ic0huq62.jpg\" style=\"zoom:50%;\"></p>\n<p><strong>brk</strong></p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">brk</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span> *addr)</span></span>;</code></pre>\n<p>​    brk 会在允许的情况下简单的将 program break 设为 addr 地址，来控制堆内存大小。相当于 program break 的绝对移动</p>\n<p><strong>sbrk</strong></p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> *<span class=\"hljs-title\">sbrk</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">intptr_t</span> increment)</span></span>;</code></pre>\n<p>​    sbrk 会在允许的情况下将 program break 指针加 increment 值，返回扩展前的 program break 地址。当<code>increment</code>为正值时，堆被扩展；为0时，返回当前 program break 的指针；为负值时，堆被收缩。相当于 program break 的相对移动</p>\n<p>​    值得注意的是，当无法扩展时 (申请了大于允许的内存，或碰到了共享内存段)，sbrk会返回 (void <em>)-1 并且会设置 errorno 为 <em>*ENOMEM</em></em>（ENO Memory）</p>\n<h3 id=\"关于-sbrk-的更多细节\"><a href=\"#关于-sbrk-的更多细节\" class=\"headerlink\" title=\"关于 sbrk 的更多细节\"></a>关于 sbrk 的更多细节</h3><p>​    sbrk 实际上是 linux 的一个上古函数，如今大多数内存分配器都倾向于使用 mmap 而不使用 sbrk，是因为 sbrk 是线程不安全的。由于 sbrk 的组织形式是对 program break 的相对移动来进行对扩展，那么对堆块的组织释放方式只能使用 LIFO。假设 sbrk 函数是原子的，在多进程调用时，如果一个进程要释放一个块，且其正好位于结尾program break处，我们选择 increment 为一个负值进行堆收缩（这是正确的）；但在我们还未释放的时候，另一个进程选择分配内存，调用 sbrk。在分配后我们继续进行释放此时我们需要释放的块后增加了一个新块，再调用 sbrk 会导致另一个进程分配的块被释放从而引发错误。</p>\n<p>​    为了解决这个问题，我们也可以自己设计一个进程安全的 sbrk 函数，称为 sbrk_safe</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> *<span class=\"hljs-title\">sbrk_safe</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">intptr_t</span> increment, <span class=\"hljs-keyword\">void</span> *expect_top)</span></span>;</code></pre>\n<p>​    其增加了一个参数expect_top，思想很简单，就是在每次调用 sbrk_safe 的时候将选择释放块的内存地址填入 expect_top，函数中验证其是否是在堆顶，如果不是就返回错误。</p>\n<p>​    （另外 sbrk 可能还有其他问题，比如受到 mmap 分配内存和共享内存的阻碍导致内存分配的间断。这里有待进一步研究探讨）</p>\n<h1 id=\"【二】动态内存分配器的设计\"><a href=\"#【二】动态内存分配器的设计\" class=\"headerlink\" title=\"【二】动态内存分配器的设计\"></a>【二】动态内存分配器的设计</h1><p>​        对于堆上的动态内存分配，我们通常将其组织为“块”的模式，一个块就是指一段连续内存地址，而根据其是否被分配数据又被划分为<strong>空闲块</strong>和<strong>分配块</strong>两种。</p>\n<h2 id=\"序、内存块结构\"><a href=\"#序、内存块结构\" class=\"headerlink\" title=\"序、内存块结构\"></a>序、内存块结构</h2><p>​    首先我们需要了解一个简单的技巧，就是如果有空闲块相邻时我们是可以将其进行合并为一个空闲块的，这样一来我们就可以分配更大的内存，并减少内存的碎片程度。注意到由于我们需要对块进行分配和合并，所以我们必须要知道块的<strong>大小信息</strong>和<strong>块的分类</strong>，因而一个内存块中其并不是所有位置都存储着有效信息。以32位系统为例，双字对齐（8 bytes）我们设计一个块的头部一个字大小（4 bytes）放置着块的大小信息和分配信息，由于是双字对齐的，所以块大小的后3位永远是0（1000）, 因此我们用前29位放大小信息，后3位放置分配信息（实际上是最后一位）001表示已分配、000表示空闲。中间放置有效载荷、即数据段，尾部可有一个填充。</p>\n<p>​    最后注意到我们需要对块进行<strong>合并</strong>（在后文中我们会详细讨论合并策略），所以在尾部也放置一个大小和分配标记有利于下一块相邻块快速找到上一块的分配状态和大小来达成向前合并的操作，所以我们在脚部也增加一个字大小（4 bytes）和头部相同的大小分配标记。这个特征称为<strong>边界标记</strong></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gqrjzzz4iaj30go0dwjyj.jpg\" style=\"zoom:50%;\"></p>\n<h2 id=\"一、内存碎片\"><a href=\"#一、内存碎片\" class=\"headerlink\" title=\"一、内存碎片\"></a>一、内存碎片</h2><p>​        关于内存分配，首先我们要有一个直观，在组织过程中我们确实可以简单的每次分配内存都创建一个所需大小的块，但经过频繁的分配释放，很快堆上的整块内存就会被划分为十分杂乱的小块。这种情况称之为内存碎片化，内存碎片化是一个十分严重的问题，其可能导致内存极大的浪费，因此要理解动态内存分配器的设计之前首先我们需要理解内存碎片的概念，来帮助我们更好的设计一个性能更加优良的分配器。</p>\n<p>​    关于内存碎片根据其表现形式可以分为两类，内部碎片和外部碎片。</p>\n<h3 id=\"内部内存碎片\"><a href=\"#内部内存碎片\" class=\"headerlink\" title=\"内部内存碎片\"></a>内部内存碎片</h3><p>​    内部内存碎片可以有一个直观的理解（虽然可能有点夸张），就是如果你仅仅需要 1kb 的内存用于存放数据，但是你申请了 2GB 大小的内存空间用来存这 1kb 的数据，那么里面大部分的内存全部都被浪费掉了，这时候如果你再要申请内存，空闲的内存可能就不够了。这就是内部碎片。</p>\n<p>​    这时候有人可能会问，那么我们之间分配需要分配的内存大小就好了啊？那为什么内部碎片还会产生呢？确实说的很对，。但有时候由于内存对齐需要以及分配器策略等影响我们并不能够直接分配正好就是需求大小的内存块，其产生机制我将会在下文中进一步深入讲解</p>\n<h3 id=\"外部内存碎片\"><a href=\"#外部内存碎片\" class=\"headerlink\" title=\"外部内存碎片\"></a>外部内存碎片</h3><p>​    外部内存碎片的产生主要源于频繁的大小不一的内存分配和释放过程。经过一系列的分配释放，最后整块的内存会被切分成空闲块分配块相互交杂的情况，如下图所示，这时候如果我们想要再分配一个 1000 kb 的数据块，可能所有的空闲块加起来是大于 1000 kb 的但是由于没有一个空闲块是大于 1000 kb 的就会导致内存分配的失败。同时由于内存映射已经建立，重整虚拟内存会导致整个程序到虚拟内存，虚拟内存到物理内存的映射表都需要更改，这种花费是我们无法承受的，所以我们需要设计更好的分配方式尽量避免这种碎片化情况的产生。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gqrji3uyl1g30b404l3yd.gif\" alt></p>\n<h2 id=\"二、空闲块组织模式\"><a href=\"#二、空闲块组织模式\" class=\"headerlink\" title=\"二、空闲块组织模式\"></a>二、空闲块组织模式</h2><p>​    关于动态内存分配器的设计其有不同的设计策略，而一种最为常见的区分方式是通过空闲块的组织模式来区分不同的分配器，这里简单介绍两种来自 CSAPP 的空闲块组织模式。</p>\n<h3 id=\"隐式空闲链表\"><a href=\"#隐式空闲链表\" class=\"headerlink\" title=\"隐式空闲链表\"></a>隐式空闲链表</h3><p>​    关于隐式空闲链表，它组织内存空闲块的形式非常简单，可以说是根本没有任何组织，我们可以通过遍历所有堆块（因为我们知道每一个堆块的大小）并验证其是否空闲来找到所有空闲块。所以将这种空闲块组织模式成为隐式空闲链表组织模式。</p>\n<ul>\n<li><p><strong>优点：</strong>简单、无需其他数据结构、节省空间</p>\n</li>\n<li><p><strong>缺点：</strong>时间复杂度高，每次寻找空闲块都需要 O(n) 时间复杂度遍历所有堆块</p>\n</li>\n</ul>\n<h3 id=\"显示空闲链表\"><a href=\"#显示空闲链表\" class=\"headerlink\" title=\"显示空闲链表\"></a>显示空闲链表</h3><p>​    关于显示空闲链表，其是通过在空闲块中间添加两个指针分别指向前趋空闲块和后继空闲块，将空闲块串联成一个链表的模式。这时候我们在全局需要存储一个入口指针指向第一个空闲块，因为其显示的将所有空闲块进行串联，所以我们称这种组织模式为显示空闲链表</p>\n<ul>\n<li><strong>优势：</strong>速度快效率高，只需要 O(m) 遍历所有空闲块</li>\n<li><strong>缺点：</strong>组织复杂，且最小块大小较大（空闲块需要多两个指针的大小）</li>\n</ul>\n<p>在实际的动态内存分配器中我们常常使用显示空闲链表的模式，因为相比于它的效率提升，其多出的空间花费是微不足道的。</p>\n<h2 id=\"三、空闲块适配模式\"><a href=\"#三、空闲块适配模式\" class=\"headerlink\" title=\"三、空闲块适配模式\"></a>三、空闲块适配模式</h2><p>​    说完了空闲块组织模式，我们来谈谈常见的空闲块适配模式，为什么要适配空闲块？当然是因为请求分配一个内存大小的时候要找到一个相应合适的内存块，空闲块适配这个概念和前面讲到的内存碎片有着很大的联系，如果我们选的太大那么就会导致内部碎片的产生（如果没有其他分割策略），如果外部碎片太多，那么我们可能根本找不到合适的空闲块。</p>\n<p>接下来我主要介绍三类空闲块组织模式，首次适配（First Fit）、再次适配（Next Fit)和最佳适配（Best Fit）</p>\n<ul>\n<li><strong>首次适配：</strong> 遍历空闲块找到的第一个合适的空闲块就用来分配 （速度快，内存不一定节省）</li>\n<li><strong>再次适配：</strong>不从头找起，从上一次分配的空闲块继续往下找，找到的第一个适合的空闲块就用来分配 （默认了分配内存的大小基本一致，需要依赖于程序的内存分配特点和空闲块大小组织方式，效率不固定）</li>\n<li><strong>最佳适配：</strong>遍历所有空闲块，找到一个在能够符合分配条件下最小的空闲块来最大化减少内部碎片的产生（内存利用率最佳，但效率较低）</li>\n</ul>\n<h2 id=\"四、空闲块顺序安排\"><a href=\"#四、空闲块顺序安排\" class=\"headerlink\" title=\"四、空闲块顺序安排\"></a>四、空闲块顺序安排</h2><p>​    空闲块顺序安排这个概念是归属于显示空闲链表组织模式下的，隐式空闲链表就完全不会有这个概念（因为根本没有组织xs）</p>\n<p>​    下面来讲讲空闲块的顺序安排，其主要有两种组织形式，LIFO 顺序和地址顺序</p>\n<ul>\n<li><strong>LIFO 顺序：</strong>把释放块插入到空闲链表的开始处，结合首次适配策略，我们便每次会分配适合分配大小的最近释放的空闲块。</li>\n</ul>\n<p>由于我们每次都在空闲块链表开头插入新释放的空闲块，其释放能够在常数时间内 O(1) 完成。</p>\n<ul>\n<li><strong>地址顺序：</strong> 我们也可以简单地按地址顺序安排空闲块链表，即让空闲块链表中空闲块地址从低到高排序，这样符合堆的地址增长方式。</li>\n</ul>\n<p>通常情况下地址顺序结合首次适配的方式比LIFO结合首次适配拥有<strong>更高的内存利用率</strong>，这是从实验中得出的</p>\n<h2 id=\"五、空闲块的存储技术\"><a href=\"#五、空闲块的存储技术\" class=\"headerlink\" title=\"五、空闲块的存储技术\"></a>五、空闲块的存储技术</h2><h3 id=\"分离适配与分段空闲链表（-Segregated-Free-List-）\"><a href=\"#分离适配与分段空闲链表（-Segregated-Free-List-）\" class=\"headerlink\" title=\"分离适配与分段空闲链表（ Segregated Free List ）\"></a>分离适配与分段空闲链表（ Segregated Free List ）</h3><p>​    在实际应用中，我们可以对空闲块的组织模式进行一定的大小分类，通过分类的方式，我们可以进一步减少空闲块的索引时间。</p>\n<p><strong>（这里的思想是运用的分层级的思想，这一思想在计算机科学中无处不在，例如数据库中的多级索引，多级页表的组织等，其实际上就是用分组的形式形成层级结构，通过使用更多的空间来换取索引的时间，是典型的空间换时间模式）</strong></p>\n<p>我们将根据空闲块大小的分类得出的不同类称为大小类，通常在一个最简单的应用中，我们可以使用二的幂次来对其进行表示。在实现上，我们可以将其组织为一个叫做分段空闲链表（Segregated Free List）的组织形式（如下图所示）。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gqrl8pm35nj30wc0u0aj5.jpg\" style=\"zoom:40%;\"></p>\n<p>​    例如我们将空闲块按二的幂次分为 MAX_ORDER 个大小类，每个 index = i 维护一个链表，连接着一类大小位于 $ 2^{i - 1}$ ~ $2^i$ 的空闲块，这样的组织形式，我们就可以先根据分配需求索引大类的大小，定位之后再进入链表根据适配规则适配空闲块。</p>\n<h1 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h1><p>[1] <em>Computer Systems: A Programmer’s Perspective</em>, 3/E (CS:APP3e). Randal E. Bryant and David R. O’Hallaron, Carnegie Mellon University.  Page 469</p>\n<p>[2] <a href=\"https://lifecs.likai.org/2010/02/sbrk-is-not-thread-safe.html\">Life of a Computer Scientist: sbrk() is not thread safe (likai.org)</a></p>\n"},{"title":"ICS-Lab2 二进制炸弹","index_img":"/img/ICS_Lab1/top.jpg","date":"2020-11-06T23:44:39.000Z","_content":"\n# ICS-Lab2-Bomb\n\n> 这个是CS:APP的第二个lab，主要着重于汇编代码的阅读\n\n***\n\n## 完成截图\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_244e1f55d2823d58f65eabab9478d7ce.png></img>\n\n***\n\n## Phase 1 - 入门\n### 一、分析\n\n> 练手入门题，用esi寄存器储存答案地址 (一个立即数)\n```\nmov    $0x402400,%esi\n```\n> 之后调用了一个 string_not_equal 函数比较输入和答案是否一致，一致就通过了。\n```\ncallq  401338 <strings_not_equal>\n```\n\n### 二、gdb调试\n> 看一下内存地址里面存了什么，获得flag\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_4801c7e177c56f6e7299c273d0120988.png></img>\n\n\n- **答案**: Border relations with Canada have never been better.\n\n***\n\n## Phase 2 - 循环\n### 分析\n\n> 本题是一个do while Loop, 难度不大, 耐心读就行了\n\n**关键位置**\n- 信息1 ： 看到 read_six_number 知道输入6个数，再往下看\n\n```\ncmpl   $0x1,(%rsp) # 比较栈顶地址所存变量大小是否为1\nje     400f30 <phase_2+0x34> # 如果为1 跳转至地址 400f30\ncallq  40143a <explode_bomb> # 如果不为1，直接炸了\njmp    400f30 <phase_2+0x34> # 跳转至地址 400f30\n```\n\n- 信息2 : 第一个数为1\n\n下面进入Loop Body\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_27148224f8cf2be48266eaa52f50b2f8.png></img>\n\n- 信息3 : \n可以看到这个循环把前一个数乘了2，跟后一个数比较, 如果相等就能够继续，不然就炸了。\n\n> 综上也就是说这是一个首项为1，公比为2的等比数列，共6项。\n\n所以答案就是 1 2 4 8 16 32\n\n***\n\n## Phase 3 - 分支\n### 分析\n\n> 第三题关键点在于用gdb查看一下jumptable\n\n 我们先看一下输入，在输入了两个变量后，esi里放了内存中的一个可疑的东西，我们用gdb看一眼。\n```\nmov    $0x4025cf,%esi\n```\n\n```shell=\n(gdb) p(char *) 0x4025cf\n\"%d %d\"\n```\n\n 发现原来是输入两个整型，再往下看\n\n```\ncmpl   $0x7,0x8(%rsp) # 将 M(rsp + 8) 看作32位无符号数跟7比较\nja     400fad <phase_3+0x6a> # 如果大于就跳转至 0x400fad (炸弹炸了)\n```\n\n 发现如果输入的第一个数大于7就爆炸了，看来switch最多只有7个case\n\n```\njmpq   *0x402470(,%rax,8) \n# 跳转至 (eax * 8 + 0x402470)处所存的地址 （jumptable）\n```\n\n> 最关键的是这一句，构造了一个 switch 的 jumptable，我们知道地址是 0x402470，按照 case * 8 + 0x402470 跳转到该地址里面的地址，所以我们用gdb看一下。\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_ae5e359c30ff5ccb9292a7472c39eb19.png></img>\n\n- 我通关选了case 1（它比较特殊，处理它其他内存地址跳转都是按case从小到大顺序的，只有case 1 在最后一个，当然其他也都能过。）\n\n- case 1 跳转到了 0x400fb9 地址\n\n```\nmov    $0x137,%eax \n# eax = 0x137 (311) (不用跳转了，下面就是 0x400fbe)\n```\n\n其将eax置为了0x137，要小心是16进制，所以对应十进制311\n\n```\ncmp    0xc(%rsp),%eax # 比较 M(rsp + 12) 和 eax\nje     400fc9 <phase_3+0x86> # 如果相等就跳转至 0x400fc9 (过关了！)\n```\n\n最后是一个比较，如果eax和第二个输入值相同就过了。\n\n- 本题答案（不唯一)\n\n| case | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 |\n| :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: |\n| ans | 207 | 311 | 707 | 256 | 389 | 206 | 682 | 327 |\n\n\n***\n\n## Phase 4 - 递归\n### 分析\n- 这题是个递归，不过不用很深，很快就能看出答案。\n\n先正常读两个数，放在rdx，rcx中，检查输入。\n\n```\ncmpl   $0xe,0x8(%rsp) \n# 比较 M(rsp + 8) (既 rdx) 与 0xe\njbe    40103a <phase_4+0x2e> \n# 如果 rdx <= 0xe (14) 跳转至 0x40103a, 不然就炸了 (作为无符号数)\n```\n\n> 这两行汇编告诉我们，rdx一定要小于 0xe (14) 且大于等于0, 不然炸了, 大幅度缩小了范围。\n\n> 接下来就进入了函数递归调用，先做点预处理，把edx里面存一个立即数14，然后edi为第一个输入值，esi = 0 进入fun4\n\n```\nmov    $0xe,%edx # edx = 0xe (14)\nmov    $0x0,%esi # esi = 0\nmov    0x8(%rsp),%edi # edi = (第一个输入值)\ncallq  400fce <func4> # 调用func4\n```\n> 先不着急看fun4，先看看最后要怎么过关\n```\ntest   %eax,%eax # eax & eax\njne    401058 <phase_4+0x4c> \n# 如果ZF == 0 就跳转（既eax != 0)，跳转至 0x401058 炸了\ncmpl   $0x0,0xc(%rsp) # 比较 M(rsp + 12) 和 0\nje     40105d <phase_4+0x51> # 如果相等就跳转到 0x40105d, 不然就炸了\n```\n- test 实际上就是一个与操作，所以我们知道需要 eax == 0 且 M(rsp + 12) == 0，到这我们发现，第二个条件只要我们一开始输入的第二个参数为0，就能够保证，那么下面我们就要看进入fun4之后如何让返回值 eax == 0\n\n> 再回来看fun4，其分为两部分，一个是递归的主体，一个是判断是否继续递归。一开始先对eax 和 ecx 进行一些操作。\n- 我们发现 eax 和 ecx 的值在第一层递归都被置为14，(esi 为 0)按其操作得到 eax 除2, ecx 逻辑右移 31 位为0, 接着其实就是比较 edi 和 rax, **相当于就是比较第一个参数和常数 7**\n\n```\njle    400ff2 <func4+0x24> # 若ecx <= 就跳转至 0x400ff2\n```\n```\nmov    $0x0,%eax # eax = 0;\ncmp    %edi,%ecx # 比较 ecx 和 edi \njge    401007 <func4+0x39> \n# 若 edi >= ecx 跳转至 0x401007 返回\n```\n\n- 接着是一个跳转, 如果满足我们就跳转至 0x400ff2, 我们发现这里已经满足了我们需要的 eax == 0，而想要结束就得使 edi >= ecx (7), 所以我们发现，对于上下两个跳转条件，只要 edi == ecx == 7 就能一直成立，从而直接达成条件，不用进入递归。\n\n进而我们得到了本题答案：7 0\n\n***\n\n## Phase 5 - 指针\n### 分析\n- 这题我觉得是最好玩的一题，先直接分析如何通关。\n\n```\nmov    $0x40245e,%esi # esi = 0x40245e \n# 待比较的 string (flyers) 从 0x40245e 移动至 esi\n```\n\n- 我们在接近返回时看到了一个非常可疑的内存地址，直接给它打出来。\n\n```\n(gdb) p(char*) 0x40245e\n$4 = 0x40245e \"flyers\"\n```\n\n> 发现是一个可疑字符串 flyers，阅读上下文汇编代码可知，最后是比较字符串是否和指定字符串 \"flyers\" 一致。\n\n- 我们再往上看看要怎么输入\n\n```\ncallq  40131b <string_length> # 比较字符长度是否为6\ncmp    $0x6,%eax # 比较 eax 和 6\n```\n\n发现输入一定要是六个字符 *(于是试了试 flyers 果然不对)*\n\n- 往下看，发现了一个 Loop 循环了6次\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_016df1440f7044a54fb4ced529595b58.png></img>\n\n> 经过仔细阅读后，发现这个居然是遍历六个输入字符，将其 ascii 码低4位取出来作为偏移量 (offset),在一个基地址 （0x4024b0）后面取字符出来组成 flyers.\n\n- 立刻开启 gdb 查看基地址附近的内存\n\n**发现分别对应的偏移量是 9, 15, 14, 5, 6, 7**\n> 直接查 ascii 码，发现对应 ionefg 、IONEFG 或者有一些不是字母的字符也行，只要低四位是正确的就可以。 \n\n**本题答案:**  ionefg (答案不唯一)\n\n***\n\n## Phase 6 - Node结构体\n### 分析\n这题还是比较麻烦的，代码比较长也比较复杂，要耐心读。\n\n- 这题的代码可以大致分为输入检测与处理和一个对结构体的顺序检测.\n> 最开始上来先输入六个数之后有个双循环，外部保证输入的六个数要大于等于1，且小于等于6，内部保证互异。所以总体看来就是输入的六个数就是123456, 现在问题是输入的顺序。\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_7194e52688ff3d696a3b889e2b17d63f.png></img>\n\n这段代码遍历了所有输入并用7减去了输入的每个数，所以最后做出答案要记得反一下。\n\n- 接下来代码比较复杂，外面大循环循环了六次，内部有两个平行的小循环。作用是构造结构体，并在栈帧中将其存放位置按照输入的数的大小计算得出\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_9ea5cd30293a18357af1da93c35e0f59.png></img>\n\n\n> 分析代码，我们先发现一种特殊情况就是当前计算的数为1时（输入为6）edx直接就是给定的地址 0x6032d0, 其余的都按照其大小，在第一个小循环中循环相应次数，给 rdx 在原地址上相应偏移16位。\n\n> 接着下来将其存入栈帧中 rsp + 32 到 rsp + 80 的位置\n\n- 使用 gdb 查看 node\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_f2ecdd05728cbefbba59b068a29fdfdc.png></img>\n\n\n最后我们看如何通关\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_a18a67d1b4dbfa16a7fd8800e3ee304b.png></img>\n\n> 发现通关条件是要求定序，前面node大于后面的节点，根据gdb node节点的值和要求我们得到了 3 4 5 6 1 2 的结果，最后不要忘记这是被7减过之后的结果，原来的输入要还原。所以答案就是 4 3 2 1 6 5\n\n**本题答案:** 4 3 2 1 6 5\n\n***\n\n## Secret Phase- 递归\n### 一、进入方法\n- 输入上面六种答案之后，发现 secret phase 并没有出现，于是开始着手寻找入口。\n\n> 根据最后结果出现的字符顺藤摸瓜找到了 phase_defuse 函数，一看发现其中有一个可疑的 <string_not_equal> 函数以及几个可疑的内存地址,统统用 gdb 打印。\n\n```\n(gdb) p(char*) 0x402619\n$2 = 0x402619 \"%d %d %s\"\n```\n\n```\n(gdb) p(char*) 0x402622\n$3 = 0x402622 \"DrEvil\"\n```\n\n> 发现之前调用过的__isoc99_sscanf@plt 还有隐藏用法，在输入两个数后再输入一个字符串 \"DrEvil\" 就能成功开启secret phase.\n\n- 所以我们在最后一次调用__isoc99_sscanf@plt的 phase 4 输入 7 0 DrEvil, 果然在 phase 6 之后进入了 secret phase。\n\n### 分析\n- 虽然说是隐藏关，但是复杂度和难度比 phase 6 低了不少，和 phase 4 一样是一个递归，但不同的是这次真的需要递归几次，但也不深。只要确定好路线还是比较容易的。\n\n```\ncallq  40149e <read_line> # 读一行\n...\ncallq  400bd0 <strtol@plt> # 调用 strtol@plt\n```\n\n> secret phase上来读了一整行然后调用了一个 strtol，经过阅读strtol的源码，发现它是以10为base将字符串转为一个整型，实际上就是剔除了最后答案中除了数字以外的字符。(所以写上答案数字然后乱输字母也能过 bushi)\n\n```\nlea    -0x1(%rax),%eax \n# eax = (rax) - 1\ncmp    $0x3e8,%eax \n# eax == 0x3e8 ? (即判断返回值与0x3e9)\n```\n\n- 这段代码告诉我们输入的数要小于 1000\n\n```\nmov    $0x6030f0,%edi # edi = 0x6030f0 (36)\ncallq  401204 <fun7> # 调用fun7\n```\n- 将edi置为 0x6030f0 (里面存的是36) 接着开始调用fun7\n\n> 我们先不着急看fun7, 老样子先看过关要求。\n\n```\ncmp    $0x2,%eax # 比较一下 eax 返回是否为2\n```\n\n发现非常简单，只要eax返回值为2就行\n\n- 再来看fun7\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_64ed470376ec6b72dc43690bf9b4ea0e.png></img>\n\n> 一看这个递归是逃不过了，但我们要让eax == 2, 路线其实非常明确，第一次先走 way3 将 eax 弄成1，再走 way1 让eax*2， 最后一层我们让eax == 0 最后返回我们得到的 eax 就等于2\n*（eax = 0 -> 1 -> 2）*\n\n> 关键是一个 edx 和 esi 的比较，edx == rdi, 然后每次改变rdi使其中储存地址中所储存的变量逐步接近 esi 完成递归操作。\n\n根据所存地址(注意/d打出的是10进制)，可以很容易找出递归路径\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_dfddd1801cd10c701dd2753164434977.png style=\"width:65%\"></img>\n\n- 输入22可以正好满足需求\n> **22 <= 36 因而 rdi = (rdi + 8) (存8)，22 > 8 因而 rdi = = (rdi + 16) (存22), 22==22 所以 eax 返回 0 ，返回 1， 返回2，最终过关**\n\n**本题答案:** 22 (可以带非数字字符)\n\n\n\n\n","source":"_posts/ICS/ICS_Lab2.md","raw":"---\ntitle: ICS-Lab2 二进制炸弹\nindex_img: /img/ICS_Lab1/top.jpg\ndate: 2020-11-06 15:44:39\ncategory: [ICS]\ntags: [Assembly]\n---\n\n# ICS-Lab2-Bomb\n\n> 这个是CS:APP的第二个lab，主要着重于汇编代码的阅读\n\n***\n\n## 完成截图\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_244e1f55d2823d58f65eabab9478d7ce.png></img>\n\n***\n\n## Phase 1 - 入门\n### 一、分析\n\n> 练手入门题，用esi寄存器储存答案地址 (一个立即数)\n```\nmov    $0x402400,%esi\n```\n> 之后调用了一个 string_not_equal 函数比较输入和答案是否一致，一致就通过了。\n```\ncallq  401338 <strings_not_equal>\n```\n\n### 二、gdb调试\n> 看一下内存地址里面存了什么，获得flag\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_4801c7e177c56f6e7299c273d0120988.png></img>\n\n\n- **答案**: Border relations with Canada have never been better.\n\n***\n\n## Phase 2 - 循环\n### 分析\n\n> 本题是一个do while Loop, 难度不大, 耐心读就行了\n\n**关键位置**\n- 信息1 ： 看到 read_six_number 知道输入6个数，再往下看\n\n```\ncmpl   $0x1,(%rsp) # 比较栈顶地址所存变量大小是否为1\nje     400f30 <phase_2+0x34> # 如果为1 跳转至地址 400f30\ncallq  40143a <explode_bomb> # 如果不为1，直接炸了\njmp    400f30 <phase_2+0x34> # 跳转至地址 400f30\n```\n\n- 信息2 : 第一个数为1\n\n下面进入Loop Body\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_27148224f8cf2be48266eaa52f50b2f8.png></img>\n\n- 信息3 : \n可以看到这个循环把前一个数乘了2，跟后一个数比较, 如果相等就能够继续，不然就炸了。\n\n> 综上也就是说这是一个首项为1，公比为2的等比数列，共6项。\n\n所以答案就是 1 2 4 8 16 32\n\n***\n\n## Phase 3 - 分支\n### 分析\n\n> 第三题关键点在于用gdb查看一下jumptable\n\n 我们先看一下输入，在输入了两个变量后，esi里放了内存中的一个可疑的东西，我们用gdb看一眼。\n```\nmov    $0x4025cf,%esi\n```\n\n```shell=\n(gdb) p(char *) 0x4025cf\n\"%d %d\"\n```\n\n 发现原来是输入两个整型，再往下看\n\n```\ncmpl   $0x7,0x8(%rsp) # 将 M(rsp + 8) 看作32位无符号数跟7比较\nja     400fad <phase_3+0x6a> # 如果大于就跳转至 0x400fad (炸弹炸了)\n```\n\n 发现如果输入的第一个数大于7就爆炸了，看来switch最多只有7个case\n\n```\njmpq   *0x402470(,%rax,8) \n# 跳转至 (eax * 8 + 0x402470)处所存的地址 （jumptable）\n```\n\n> 最关键的是这一句，构造了一个 switch 的 jumptable，我们知道地址是 0x402470，按照 case * 8 + 0x402470 跳转到该地址里面的地址，所以我们用gdb看一下。\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_ae5e359c30ff5ccb9292a7472c39eb19.png></img>\n\n- 我通关选了case 1（它比较特殊，处理它其他内存地址跳转都是按case从小到大顺序的，只有case 1 在最后一个，当然其他也都能过。）\n\n- case 1 跳转到了 0x400fb9 地址\n\n```\nmov    $0x137,%eax \n# eax = 0x137 (311) (不用跳转了，下面就是 0x400fbe)\n```\n\n其将eax置为了0x137，要小心是16进制，所以对应十进制311\n\n```\ncmp    0xc(%rsp),%eax # 比较 M(rsp + 12) 和 eax\nje     400fc9 <phase_3+0x86> # 如果相等就跳转至 0x400fc9 (过关了！)\n```\n\n最后是一个比较，如果eax和第二个输入值相同就过了。\n\n- 本题答案（不唯一)\n\n| case | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 |\n| :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: |\n| ans | 207 | 311 | 707 | 256 | 389 | 206 | 682 | 327 |\n\n\n***\n\n## Phase 4 - 递归\n### 分析\n- 这题是个递归，不过不用很深，很快就能看出答案。\n\n先正常读两个数，放在rdx，rcx中，检查输入。\n\n```\ncmpl   $0xe,0x8(%rsp) \n# 比较 M(rsp + 8) (既 rdx) 与 0xe\njbe    40103a <phase_4+0x2e> \n# 如果 rdx <= 0xe (14) 跳转至 0x40103a, 不然就炸了 (作为无符号数)\n```\n\n> 这两行汇编告诉我们，rdx一定要小于 0xe (14) 且大于等于0, 不然炸了, 大幅度缩小了范围。\n\n> 接下来就进入了函数递归调用，先做点预处理，把edx里面存一个立即数14，然后edi为第一个输入值，esi = 0 进入fun4\n\n```\nmov    $0xe,%edx # edx = 0xe (14)\nmov    $0x0,%esi # esi = 0\nmov    0x8(%rsp),%edi # edi = (第一个输入值)\ncallq  400fce <func4> # 调用func4\n```\n> 先不着急看fun4，先看看最后要怎么过关\n```\ntest   %eax,%eax # eax & eax\njne    401058 <phase_4+0x4c> \n# 如果ZF == 0 就跳转（既eax != 0)，跳转至 0x401058 炸了\ncmpl   $0x0,0xc(%rsp) # 比较 M(rsp + 12) 和 0\nje     40105d <phase_4+0x51> # 如果相等就跳转到 0x40105d, 不然就炸了\n```\n- test 实际上就是一个与操作，所以我们知道需要 eax == 0 且 M(rsp + 12) == 0，到这我们发现，第二个条件只要我们一开始输入的第二个参数为0，就能够保证，那么下面我们就要看进入fun4之后如何让返回值 eax == 0\n\n> 再回来看fun4，其分为两部分，一个是递归的主体，一个是判断是否继续递归。一开始先对eax 和 ecx 进行一些操作。\n- 我们发现 eax 和 ecx 的值在第一层递归都被置为14，(esi 为 0)按其操作得到 eax 除2, ecx 逻辑右移 31 位为0, 接着其实就是比较 edi 和 rax, **相当于就是比较第一个参数和常数 7**\n\n```\njle    400ff2 <func4+0x24> # 若ecx <= 就跳转至 0x400ff2\n```\n```\nmov    $0x0,%eax # eax = 0;\ncmp    %edi,%ecx # 比较 ecx 和 edi \njge    401007 <func4+0x39> \n# 若 edi >= ecx 跳转至 0x401007 返回\n```\n\n- 接着是一个跳转, 如果满足我们就跳转至 0x400ff2, 我们发现这里已经满足了我们需要的 eax == 0，而想要结束就得使 edi >= ecx (7), 所以我们发现，对于上下两个跳转条件，只要 edi == ecx == 7 就能一直成立，从而直接达成条件，不用进入递归。\n\n进而我们得到了本题答案：7 0\n\n***\n\n## Phase 5 - 指针\n### 分析\n- 这题我觉得是最好玩的一题，先直接分析如何通关。\n\n```\nmov    $0x40245e,%esi # esi = 0x40245e \n# 待比较的 string (flyers) 从 0x40245e 移动至 esi\n```\n\n- 我们在接近返回时看到了一个非常可疑的内存地址，直接给它打出来。\n\n```\n(gdb) p(char*) 0x40245e\n$4 = 0x40245e \"flyers\"\n```\n\n> 发现是一个可疑字符串 flyers，阅读上下文汇编代码可知，最后是比较字符串是否和指定字符串 \"flyers\" 一致。\n\n- 我们再往上看看要怎么输入\n\n```\ncallq  40131b <string_length> # 比较字符长度是否为6\ncmp    $0x6,%eax # 比较 eax 和 6\n```\n\n发现输入一定要是六个字符 *(于是试了试 flyers 果然不对)*\n\n- 往下看，发现了一个 Loop 循环了6次\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_016df1440f7044a54fb4ced529595b58.png></img>\n\n> 经过仔细阅读后，发现这个居然是遍历六个输入字符，将其 ascii 码低4位取出来作为偏移量 (offset),在一个基地址 （0x4024b0）后面取字符出来组成 flyers.\n\n- 立刻开启 gdb 查看基地址附近的内存\n\n**发现分别对应的偏移量是 9, 15, 14, 5, 6, 7**\n> 直接查 ascii 码，发现对应 ionefg 、IONEFG 或者有一些不是字母的字符也行，只要低四位是正确的就可以。 \n\n**本题答案:**  ionefg (答案不唯一)\n\n***\n\n## Phase 6 - Node结构体\n### 分析\n这题还是比较麻烦的，代码比较长也比较复杂，要耐心读。\n\n- 这题的代码可以大致分为输入检测与处理和一个对结构体的顺序检测.\n> 最开始上来先输入六个数之后有个双循环，外部保证输入的六个数要大于等于1，且小于等于6，内部保证互异。所以总体看来就是输入的六个数就是123456, 现在问题是输入的顺序。\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_7194e52688ff3d696a3b889e2b17d63f.png></img>\n\n这段代码遍历了所有输入并用7减去了输入的每个数，所以最后做出答案要记得反一下。\n\n- 接下来代码比较复杂，外面大循环循环了六次，内部有两个平行的小循环。作用是构造结构体，并在栈帧中将其存放位置按照输入的数的大小计算得出\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_9ea5cd30293a18357af1da93c35e0f59.png></img>\n\n\n> 分析代码，我们先发现一种特殊情况就是当前计算的数为1时（输入为6）edx直接就是给定的地址 0x6032d0, 其余的都按照其大小，在第一个小循环中循环相应次数，给 rdx 在原地址上相应偏移16位。\n\n> 接着下来将其存入栈帧中 rsp + 32 到 rsp + 80 的位置\n\n- 使用 gdb 查看 node\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_f2ecdd05728cbefbba59b068a29fdfdc.png></img>\n\n\n最后我们看如何通关\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_a18a67d1b4dbfa16a7fd8800e3ee304b.png></img>\n\n> 发现通关条件是要求定序，前面node大于后面的节点，根据gdb node节点的值和要求我们得到了 3 4 5 6 1 2 的结果，最后不要忘记这是被7减过之后的结果，原来的输入要还原。所以答案就是 4 3 2 1 6 5\n\n**本题答案:** 4 3 2 1 6 5\n\n***\n\n## Secret Phase- 递归\n### 一、进入方法\n- 输入上面六种答案之后，发现 secret phase 并没有出现，于是开始着手寻找入口。\n\n> 根据最后结果出现的字符顺藤摸瓜找到了 phase_defuse 函数，一看发现其中有一个可疑的 <string_not_equal> 函数以及几个可疑的内存地址,统统用 gdb 打印。\n\n```\n(gdb) p(char*) 0x402619\n$2 = 0x402619 \"%d %d %s\"\n```\n\n```\n(gdb) p(char*) 0x402622\n$3 = 0x402622 \"DrEvil\"\n```\n\n> 发现之前调用过的__isoc99_sscanf@plt 还有隐藏用法，在输入两个数后再输入一个字符串 \"DrEvil\" 就能成功开启secret phase.\n\n- 所以我们在最后一次调用__isoc99_sscanf@plt的 phase 4 输入 7 0 DrEvil, 果然在 phase 6 之后进入了 secret phase。\n\n### 分析\n- 虽然说是隐藏关，但是复杂度和难度比 phase 6 低了不少，和 phase 4 一样是一个递归，但不同的是这次真的需要递归几次，但也不深。只要确定好路线还是比较容易的。\n\n```\ncallq  40149e <read_line> # 读一行\n...\ncallq  400bd0 <strtol@plt> # 调用 strtol@plt\n```\n\n> secret phase上来读了一整行然后调用了一个 strtol，经过阅读strtol的源码，发现它是以10为base将字符串转为一个整型，实际上就是剔除了最后答案中除了数字以外的字符。(所以写上答案数字然后乱输字母也能过 bushi)\n\n```\nlea    -0x1(%rax),%eax \n# eax = (rax) - 1\ncmp    $0x3e8,%eax \n# eax == 0x3e8 ? (即判断返回值与0x3e9)\n```\n\n- 这段代码告诉我们输入的数要小于 1000\n\n```\nmov    $0x6030f0,%edi # edi = 0x6030f0 (36)\ncallq  401204 <fun7> # 调用fun7\n```\n- 将edi置为 0x6030f0 (里面存的是36) 接着开始调用fun7\n\n> 我们先不着急看fun7, 老样子先看过关要求。\n\n```\ncmp    $0x2,%eax # 比较一下 eax 返回是否为2\n```\n\n发现非常简单，只要eax返回值为2就行\n\n- 再来看fun7\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_64ed470376ec6b72dc43690bf9b4ea0e.png></img>\n\n> 一看这个递归是逃不过了，但我们要让eax == 2, 路线其实非常明确，第一次先走 way3 将 eax 弄成1，再走 way1 让eax*2， 最后一层我们让eax == 0 最后返回我们得到的 eax 就等于2\n*（eax = 0 -> 1 -> 2）*\n\n> 关键是一个 edx 和 esi 的比较，edx == rdi, 然后每次改变rdi使其中储存地址中所储存的变量逐步接近 esi 完成递归操作。\n\n根据所存地址(注意/d打出的是10进制)，可以很容易找出递归路径\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_dfddd1801cd10c701dd2753164434977.png style=\"width:65%\"></img>\n\n- 输入22可以正好满足需求\n> **22 <= 36 因而 rdi = (rdi + 8) (存8)，22 > 8 因而 rdi = = (rdi + 16) (存22), 22==22 所以 eax 返回 0 ，返回 1， 返回2，最终过关**\n\n**本题答案:** 22 (可以带非数字字符)\n\n\n\n\n","slug":"ICS/ICS_Lab2","published":1,"updated":"2026-02-03T05:42:14.432Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvc00157uit9ve380o3","content":"<h1 id=\"ICS-Lab2-Bomb\"><a href=\"#ICS-Lab2-Bomb\" class=\"headerlink\" title=\"ICS-Lab2-Bomb\"></a>ICS-Lab2-Bomb</h1><blockquote>\n<p>这个是CS:APP的第二个lab，主要着重于汇编代码的阅读</p>\n</blockquote>\n<hr>\n<h2 id=\"完成截图\"><a href=\"#完成截图\" class=\"headerlink\" title=\"完成截图\"></a>完成截图</h2><p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_244e1f55d2823d58f65eabab9478d7ce.png\"></p>\n<hr>\n<h2 id=\"Phase-1-入门\"><a href=\"#Phase-1-入门\" class=\"headerlink\" title=\"Phase 1 - 入门\"></a>Phase 1 - 入门</h2><h3 id=\"一、分析\"><a href=\"#一、分析\" class=\"headerlink\" title=\"一、分析\"></a>一、分析</h3><blockquote>\n<p>练手入门题，用esi寄存器储存答案地址 (一个立即数)<br><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">402400</span>,%esi</code></pre><br>之后调用了一个 string_not_equal 函数比较输入和答案是否一致，一致就通过了。<br><pre><code class=\"hljs angelscript\">callq  <span class=\"hljs-number\">401338</span> &lt;<span class=\"hljs-built_in\">string</span>s_not_equal&gt;</code></pre></p>\n</blockquote>\n<h3 id=\"二、gdb调试\"><a href=\"#二、gdb调试\" class=\"headerlink\" title=\"二、gdb调试\"></a>二、gdb调试</h3><blockquote>\n<p>看一下内存地址里面存了什么，获得flag</p>\n</blockquote>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_4801c7e177c56f6e7299c273d0120988.png\"></p>\n<ul>\n<li><strong>答案</strong>: Border relations with Canada have never been better.</li>\n</ul>\n<hr>\n<h2 id=\"Phase-2-循环\"><a href=\"#Phase-2-循环\" class=\"headerlink\" title=\"Phase 2 - 循环\"></a>Phase 2 - 循环</h2><h3 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h3><blockquote>\n<p>本题是一个do while Loop, 难度不大, 耐心读就行了</p>\n</blockquote>\n<p><strong>关键位置</strong></p>\n<ul>\n<li>信息1 ： 看到 read_six_number 知道输入6个数，再往下看</li>\n</ul>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">cmpl</span>   $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">1</span>,(%rsp) # 比较栈顶地址所存变量大小是否为<span class=\"hljs-number\">1</span>\n<span class=\"hljs-attribute\">je</span>     <span class=\"hljs-number\">400</span>f<span class=\"hljs-number\">30</span> &lt;phase_<span class=\"hljs-number\">2</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">34</span>&gt; # 如果为<span class=\"hljs-number\">1</span> 跳转至地址 <span class=\"hljs-number\">400</span>f<span class=\"hljs-number\">30</span>\n<span class=\"hljs-attribute\">callq</span>  <span class=\"hljs-number\">40143</span>a &lt;explode_bomb&gt; # 如果不为<span class=\"hljs-number\">1</span>，直接炸了\n<span class=\"hljs-attribute\">jmp</span>    <span class=\"hljs-number\">400</span>f<span class=\"hljs-number\">30</span> &lt;phase_<span class=\"hljs-number\">2</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">34</span>&gt; # 跳转至地址 <span class=\"hljs-number\">400</span>f<span class=\"hljs-number\">30</span></code></pre>\n<ul>\n<li>信息2 : 第一个数为1</li>\n</ul>\n<p>下面进入Loop Body</p>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_27148224f8cf2be48266eaa52f50b2f8.png\"></p>\n<ul>\n<li>信息3 :<br>可以看到这个循环把前一个数乘了2，跟后一个数比较, 如果相等就能够继续，不然就炸了。</li>\n</ul>\n<blockquote>\n<p>综上也就是说这是一个首项为1，公比为2的等比数列，共6项。</p>\n</blockquote>\n<p>所以答案就是 1 2 4 8 16 32</p>\n<hr>\n<h2 id=\"Phase-3-分支\"><a href=\"#Phase-3-分支\" class=\"headerlink\" title=\"Phase 3 - 分支\"></a>Phase 3 - 分支</h2><h3 id=\"分析-1\"><a href=\"#分析-1\" class=\"headerlink\" title=\"分析\"></a>分析</h3><blockquote>\n<p>第三题关键点在于用gdb查看一下jumptable</p>\n</blockquote>\n<p> 我们先看一下输入，在输入了两个变量后，esi里放了内存中的一个可疑的东西，我们用gdb看一眼。<br><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">4025</span>cf,%esi</code></pre></p>\n<pre><code class=\"hljs shell\">(gdb) p(char *) 0x4025cf\n&quot;%d %d&quot;</code></pre>\n<p> 发现原来是输入两个整型，再往下看</p>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">cmpl</span>   $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">7</span>,<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">8</span>(%rsp) # 将 M(rsp + <span class=\"hljs-number\">8</span>) 看作<span class=\"hljs-number\">32</span>位无符号数跟<span class=\"hljs-number\">7</span>比较\n<span class=\"hljs-attribute\">ja</span>     <span class=\"hljs-number\">400</span>fad &lt;phase_<span class=\"hljs-number\">3</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">6</span>a&gt; # 如果大于就跳转至 <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">400</span>fad (炸弹炸了)</code></pre>\n<p> 发现如果输入的第一个数大于7就爆炸了，看来switch最多只有7个case</p>\n<pre><code class=\"hljs angelscript\">jmpq   *<span class=\"hljs-number\">0x402470</span>(,%rax,<span class=\"hljs-number\">8</span>) \n# 跳转至 (eax * <span class=\"hljs-number\">8</span> + <span class=\"hljs-number\">0x402470</span>)处所存的地址 （jumptable）</code></pre>\n<blockquote>\n<p>最关键的是这一句，构造了一个 switch 的 jumptable，我们知道地址是 0x402470，按照 case * 8 + 0x402470 跳转到该地址里面的地址，所以我们用gdb看一下。</p>\n</blockquote>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_ae5e359c30ff5ccb9292a7472c39eb19.png\"></p>\n<ul>\n<li><p>我通关选了case 1（它比较特殊，处理它其他内存地址跳转都是按case从小到大顺序的，只有case 1 在最后一个，当然其他也都能过。）</p>\n</li>\n<li><p>case 1 跳转到了 0x400fb9 地址</p>\n</li>\n</ul>\n<pre><code class=\"hljs angelscript\">mov    $<span class=\"hljs-number\">0x137</span>,%eax \n# eax = <span class=\"hljs-number\">0x137</span> (<span class=\"hljs-number\">311</span>) (不用跳转了，下面就是 <span class=\"hljs-number\">0x400fbe</span>)</code></pre>\n<p>其将eax置为了0x137，要小心是16进制，所以对应十进制311</p>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">cmp</span>    <span class=\"hljs-number\">0</span>xc(%rsp),%eax # 比较 M(rsp + <span class=\"hljs-number\">12</span>) 和 eax\n<span class=\"hljs-attribute\">je</span>     <span class=\"hljs-number\">400</span>fc<span class=\"hljs-number\">9</span> &lt;phase_<span class=\"hljs-number\">3</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">86</span>&gt; # 如果相等就跳转至 <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">400</span>fc<span class=\"hljs-number\">9</span> (过关了！)</code></pre>\n<p>最后是一个比较，如果eax和第二个输入值相同就过了。</p>\n<ul>\n<li>本题答案（不唯一)</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">case</th>\n<th style=\"text-align:center\">0</th>\n<th style=\"text-align:center\">1</th>\n<th style=\"text-align:center\">2</th>\n<th style=\"text-align:center\">3</th>\n<th style=\"text-align:center\">4</th>\n<th style=\"text-align:center\">5</th>\n<th style=\"text-align:center\">6</th>\n<th style=\"text-align:center\">7</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">ans</td>\n<td style=\"text-align:center\">207</td>\n<td style=\"text-align:center\">311</td>\n<td style=\"text-align:center\">707</td>\n<td style=\"text-align:center\">256</td>\n<td style=\"text-align:center\">389</td>\n<td style=\"text-align:center\">206</td>\n<td style=\"text-align:center\">682</td>\n<td style=\"text-align:center\">327</td>\n</tr>\n</tbody>\n</table>\n</div>\n<hr>\n<h2 id=\"Phase-4-递归\"><a href=\"#Phase-4-递归\" class=\"headerlink\" title=\"Phase 4 - 递归\"></a>Phase 4 - 递归</h2><h3 id=\"分析-2\"><a href=\"#分析-2\" class=\"headerlink\" title=\"分析\"></a>分析</h3><ul>\n<li>这题是个递归，不过不用很深，很快就能看出答案。</li>\n</ul>\n<p>先正常读两个数，放在rdx，rcx中，检查输入。</p>\n<pre><code class=\"hljs angelscript\">cmpl   $<span class=\"hljs-number\">0xe</span>,<span class=\"hljs-number\">0x8</span>(%rsp) \n# 比较 M(rsp + <span class=\"hljs-number\">8</span>) (既 rdx) 与 <span class=\"hljs-number\">0xe</span>\njbe    <span class=\"hljs-number\">40103</span>a &lt;phase_4+<span class=\"hljs-number\">0x2e</span>&gt; \n# 如果 rdx &lt;= <span class=\"hljs-number\">0xe</span> (<span class=\"hljs-number\">14</span>) 跳转至 <span class=\"hljs-number\">0x40103a</span>, 不然就炸了 (作为无符号数)</code></pre>\n<blockquote>\n<p>这两行汇编告诉我们，rdx一定要小于 0xe (14) 且大于等于0, 不然炸了, 大幅度缩小了范围。</p>\n<p>接下来就进入了函数递归调用，先做点预处理，把edx里面存一个立即数14，然后edi为第一个输入值，esi = 0 进入fun4</p>\n</blockquote>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>xe,%edx # edx = <span class=\"hljs-number\">0</span>xe (<span class=\"hljs-number\">14</span>)\n<span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">0</span>,%esi # esi = <span class=\"hljs-number\">0</span>\n<span class=\"hljs-attribute\">mov</span>    <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">8</span>(%rsp),%edi # edi = (第一个输入值)\n<span class=\"hljs-attribute\">callq</span>  <span class=\"hljs-number\">400</span>fce &lt;func<span class=\"hljs-number\">4</span>&gt; # 调用func<span class=\"hljs-number\">4</span></code></pre>\n<blockquote>\n<p>先不着急看fun4，先看看最后要怎么过关<br><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">test</span>   %eax,%eax # eax &amp; eax\n<span class=\"hljs-attribute\">jne</span>    <span class=\"hljs-number\">401058</span> &lt;phase_<span class=\"hljs-number\">4</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">4</span>c&gt; \n<span class=\"hljs-comment\"># 如果ZF == 0 就跳转（既eax != 0)，跳转至 0x401058 炸了</span>\n<span class=\"hljs-attribute\">cmpl</span>   $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>xc(%rsp) # 比较 M(rsp + <span class=\"hljs-number\">12</span>) 和 <span class=\"hljs-number\">0</span>\n<span class=\"hljs-attribute\">je</span>     <span class=\"hljs-number\">40105</span>d &lt;phase_<span class=\"hljs-number\">4</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">51</span>&gt; # 如果相等就跳转到 <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">40105</span>d, 不然就炸了</code></pre></p>\n<ul>\n<li>test 实际上就是一个与操作，所以我们知道需要 eax == 0 且 M(rsp + 12) == 0，到这我们发现，第二个条件只要我们一开始输入的第二个参数为0，就能够保证，那么下面我们就要看进入fun4之后如何让返回值 eax == 0</li>\n</ul>\n<p>再回来看fun4，其分为两部分，一个是递归的主体，一个是判断是否继续递归。一开始先对eax 和 ecx 进行一些操作。</p>\n<ul>\n<li>我们发现 eax 和 ecx 的值在第一层递归都被置为14，(esi 为 0)按其操作得到 eax 除2, ecx 逻辑右移 31 位为0, 接着其实就是比较 edi 和 rax, <strong>相当于就是比较第一个参数和常数 7</strong></li>\n</ul>\n</blockquote>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">jle</span>    <span class=\"hljs-number\">400</span>ff<span class=\"hljs-number\">2</span> &lt;func<span class=\"hljs-number\">4</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">24</span>&gt; # 若ecx &lt;= 就跳转至 <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">400</span>ff<span class=\"hljs-number\">2</span></code></pre>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">0</span>,%eax # eax = <span class=\"hljs-number\">0</span>;\n<span class=\"hljs-attribute\">cmp</span>    %edi,%ecx # 比较 ecx 和 edi \n<span class=\"hljs-attribute\">jge</span>    <span class=\"hljs-number\">401007</span> &lt;func<span class=\"hljs-number\">4</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">39</span>&gt; \n<span class=\"hljs-comment\"># 若 edi &gt;= ecx 跳转至 0x401007 返回</span></code></pre>\n<ul>\n<li>接着是一个跳转, 如果满足我们就跳转至 0x400ff2, 我们发现这里已经满足了我们需要的 eax == 0，而想要结束就得使 edi &gt;= ecx (7), 所以我们发现，对于上下两个跳转条件，只要 edi == ecx == 7 就能一直成立，从而直接达成条件，不用进入递归。</li>\n</ul>\n<p>进而我们得到了本题答案：7 0</p>\n<hr>\n<h2 id=\"Phase-5-指针\"><a href=\"#Phase-5-指针\" class=\"headerlink\" title=\"Phase 5 - 指针\"></a>Phase 5 - 指针</h2><h3 id=\"分析-3\"><a href=\"#分析-3\" class=\"headerlink\" title=\"分析\"></a>分析</h3><ul>\n<li>这题我觉得是最好玩的一题，先直接分析如何通关。</li>\n</ul>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">40245</span>e,%esi # esi = <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">40245</span>e \n<span class=\"hljs-comment\"># 待比较的 string (flyers) 从 0x40245e 移动至 esi</span></code></pre>\n<ul>\n<li>我们在接近返回时看到了一个非常可疑的内存地址，直接给它打出来。</li>\n</ul>\n<pre><code class=\"hljs lsl\">(gdb) p(char*) <span class=\"hljs-number\">0x40245e</span>\n$<span class=\"hljs-number\">4</span> = <span class=\"hljs-number\">0x40245e</span> <span class=\"hljs-string\">&quot;flyers&quot;</span></code></pre>\n<blockquote>\n<p>发现是一个可疑字符串 flyers，阅读上下文汇编代码可知，最后是比较字符串是否和指定字符串 “flyers” 一致。</p>\n</blockquote>\n<ul>\n<li>我们再往上看看要怎么输入</li>\n</ul>\n<pre><code class=\"hljs angelscript\">callq  <span class=\"hljs-number\">40131</span>b &lt;<span class=\"hljs-built_in\">string</span>_length&gt; # 比较字符长度是否为<span class=\"hljs-number\">6</span>\ncmp    $<span class=\"hljs-number\">0x6</span>,%eax # 比较 eax 和 <span class=\"hljs-number\">6</span></code></pre>\n<p>发现输入一定要是六个字符 <em>(于是试了试 flyers 果然不对)</em></p>\n<ul>\n<li>往下看，发现了一个 Loop 循环了6次</li>\n</ul>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_016df1440f7044a54fb4ced529595b58.png\"></p>\n<blockquote>\n<p>经过仔细阅读后，发现这个居然是遍历六个输入字符，将其 ascii 码低4位取出来作为偏移量 (offset),在一个基地址 （0x4024b0）后面取字符出来组成 flyers.</p>\n</blockquote>\n<ul>\n<li>立刻开启 gdb 查看基地址附近的内存</li>\n</ul>\n<p><strong>发现分别对应的偏移量是 9, 15, 14, 5, 6, 7</strong></p>\n<blockquote>\n<p>直接查 ascii 码，发现对应 ionefg 、IONEFG 或者有一些不是字母的字符也行，只要低四位是正确的就可以。 </p>\n</blockquote>\n<p><strong>本题答案:</strong>  ionefg (答案不唯一)</p>\n<hr>\n<h2 id=\"Phase-6-Node结构体\"><a href=\"#Phase-6-Node结构体\" class=\"headerlink\" title=\"Phase 6 - Node结构体\"></a>Phase 6 - Node结构体</h2><h3 id=\"分析-4\"><a href=\"#分析-4\" class=\"headerlink\" title=\"分析\"></a>分析</h3><p>这题还是比较麻烦的，代码比较长也比较复杂，要耐心读。</p>\n<ul>\n<li>这题的代码可以大致分为输入检测与处理和一个对结构体的顺序检测.<blockquote>\n<p>最开始上来先输入六个数之后有个双循环，外部保证输入的六个数要大于等于1，且小于等于6，内部保证互异。所以总体看来就是输入的六个数就是123456, 现在问题是输入的顺序。</p>\n</blockquote>\n</li>\n</ul>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_7194e52688ff3d696a3b889e2b17d63f.png\"></p>\n<p>这段代码遍历了所有输入并用7减去了输入的每个数，所以最后做出答案要记得反一下。</p>\n<ul>\n<li>接下来代码比较复杂，外面大循环循环了六次，内部有两个平行的小循环。作用是构造结构体，并在栈帧中将其存放位置按照输入的数的大小计算得出</li>\n</ul>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_9ea5cd30293a18357af1da93c35e0f59.png\"></p>\n<blockquote>\n<p>分析代码，我们先发现一种特殊情况就是当前计算的数为1时（输入为6）edx直接就是给定的地址 0x6032d0, 其余的都按照其大小，在第一个小循环中循环相应次数，给 rdx 在原地址上相应偏移16位。</p>\n<p>接着下来将其存入栈帧中 rsp + 32 到 rsp + 80 的位置</p>\n</blockquote>\n<ul>\n<li>使用 gdb 查看 node</li>\n</ul>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_f2ecdd05728cbefbba59b068a29fdfdc.png\"></p>\n<p>最后我们看如何通关</p>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_a18a67d1b4dbfa16a7fd8800e3ee304b.png\"></p>\n<blockquote>\n<p>发现通关条件是要求定序，前面node大于后面的节点，根据gdb node节点的值和要求我们得到了 3 4 5 6 1 2 的结果，最后不要忘记这是被7减过之后的结果，原来的输入要还原。所以答案就是 4 3 2 1 6 5</p>\n</blockquote>\n<p><strong>本题答案:</strong> 4 3 2 1 6 5</p>\n<hr>\n<h2 id=\"Secret-Phase-递归\"><a href=\"#Secret-Phase-递归\" class=\"headerlink\" title=\"Secret Phase- 递归\"></a>Secret Phase- 递归</h2><h3 id=\"一、进入方法\"><a href=\"#一、进入方法\" class=\"headerlink\" title=\"一、进入方法\"></a>一、进入方法</h3><ul>\n<li>输入上面六种答案之后，发现 secret phase 并没有出现，于是开始着手寻找入口。</li>\n</ul>\n<blockquote>\n<p>根据最后结果出现的字符顺藤摸瓜找到了 phase_defuse 函数，一看发现其中有一个可疑的 <string_not_equal> 函数以及几个可疑的内存地址,统统用 gdb 打印。</string_not_equal></p>\n</blockquote>\n<pre><code class=\"hljs perl\">(gdb) p(char*) <span class=\"hljs-number\">0x402619</span>\n$2 = <span class=\"hljs-number\">0x402619</span> <span class=\"hljs-string\">&quot;%d %d %s&quot;</span></code></pre>\n<pre><code class=\"hljs lsl\">(gdb) p(char*) <span class=\"hljs-number\">0x402622</span>\n$<span class=\"hljs-number\">3</span> = <span class=\"hljs-number\">0x402622</span> <span class=\"hljs-string\">&quot;DrEvil&quot;</span></code></pre>\n<blockquote>\n<p>发现之前调用过的__isoc99_sscanf@plt 还有隐藏用法，在输入两个数后再输入一个字符串 “DrEvil” 就能成功开启secret phase.</p>\n</blockquote>\n<ul>\n<li>所以我们在最后一次调用__isoc99_sscanf@plt的 phase 4 输入 7 0 DrEvil, 果然在 phase 6 之后进入了 secret phase。</li>\n</ul>\n<h3 id=\"分析-5\"><a href=\"#分析-5\" class=\"headerlink\" title=\"分析\"></a>分析</h3><ul>\n<li>虽然说是隐藏关，但是复杂度和难度比 phase 6 低了不少，和 phase 4 一样是一个递归，但不同的是这次真的需要递归几次，但也不深。只要确定好路线还是比较容易的。</li>\n</ul>\n<pre><code class=\"hljs angelscript\">callq  <span class=\"hljs-number\">40149</span>e &lt;read_line&gt; # 读一行\n...\ncallq  <span class=\"hljs-number\">400</span>bd0 &lt;<span class=\"hljs-symbol\">strtol@</span>plt&gt; # 调用 <span class=\"hljs-symbol\">strtol@</span>plt</code></pre>\n<blockquote>\n<p>secret phase上来读了一整行然后调用了一个 strtol，经过阅读strtol的源码，发现它是以10为base将字符串转为一个整型，实际上就是剔除了最后答案中除了数字以外的字符。(所以写上答案数字然后乱输字母也能过 bushi)</p>\n</blockquote>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">lea</span>    -<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">1</span>(%rax),%eax \n<span class=\"hljs-comment\"># eax = (rax) - 1</span>\n<span class=\"hljs-attribute\">cmp</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">3</span>e<span class=\"hljs-number\">8</span>,%eax \n<span class=\"hljs-comment\"># eax == 0x3e8 ? (即判断返回值与0x3e9)</span></code></pre>\n<ul>\n<li>这段代码告诉我们输入的数要小于 1000</li>\n</ul>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">6030</span>f<span class=\"hljs-number\">0</span>,%edi # edi = <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">6030</span>f<span class=\"hljs-number\">0</span> (<span class=\"hljs-number\">36</span>)\n<span class=\"hljs-attribute\">callq</span>  <span class=\"hljs-number\">401204</span> &lt;fun<span class=\"hljs-number\">7</span>&gt; # 调用fun<span class=\"hljs-number\">7</span></code></pre>\n<ul>\n<li>将edi置为 0x6030f0 (里面存的是36) 接着开始调用fun7</li>\n</ul>\n<blockquote>\n<p>我们先不着急看fun7, 老样子先看过关要求。</p>\n</blockquote>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">cmp</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">2</span>,%eax # 比较一下 eax 返回是否为<span class=\"hljs-number\">2</span></code></pre>\n<p>发现非常简单，只要eax返回值为2就行</p>\n<ul>\n<li>再来看fun7</li>\n</ul>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_64ed470376ec6b72dc43690bf9b4ea0e.png\"></p>\n<blockquote>\n<p>一看这个递归是逃不过了，但我们要让eax == 2, 路线其实非常明确，第一次先走 way3 将 eax 弄成1，再走 way1 让eax<em>2， 最后一层我们让eax == 0 最后返回我们得到的 eax 就等于2\n</em>（eax = 0 -&gt; 1 -&gt; 2）*</p>\n<p>关键是一个 edx 和 esi 的比较，edx == rdi, 然后每次改变rdi使其中储存地址中所储存的变量逐步接近 esi 完成递归操作。</p>\n</blockquote>\n<p>根据所存地址(注意/d打出的是10进制)，可以很容易找出递归路径</p>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_dfddd1801cd10c701dd2753164434977.png\" style=\"width:65%\"></p>\n<ul>\n<li>输入22可以正好满足需求<blockquote>\n<p><strong>22 &lt;= 36 因而 rdi = (rdi + 8) (存8)，22 &gt; 8 因而 rdi = = (rdi + 16) (存22), 22==22 所以 eax 返回 0 ，返回 1， 返回2，最终过关</strong></p>\n</blockquote>\n</li>\n</ul>\n<p><strong>本题答案:</strong> 22 (可以带非数字字符)</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"ICS-Lab2-Bomb\"><a href=\"#ICS-Lab2-Bomb\" class=\"headerlink\" title=\"ICS-Lab2-Bomb\"></a>ICS-Lab2-Bomb</h1><blockquote>\n<p>这个是CS:APP的第二个lab，主要着重于汇编代码的阅读</p>\n</blockquote>\n<hr>\n<h2 id=\"完成截图\"><a href=\"#完成截图\" class=\"headerlink\" title=\"完成截图\"></a>完成截图</h2><p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_244e1f55d2823d58f65eabab9478d7ce.png\"></p>\n<hr>\n<h2 id=\"Phase-1-入门\"><a href=\"#Phase-1-入门\" class=\"headerlink\" title=\"Phase 1 - 入门\"></a>Phase 1 - 入门</h2><h3 id=\"一、分析\"><a href=\"#一、分析\" class=\"headerlink\" title=\"一、分析\"></a>一、分析</h3><blockquote>\n<p>练手入门题，用esi寄存器储存答案地址 (一个立即数)<br><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">402400</span>,%esi</code></pre><br>之后调用了一个 string_not_equal 函数比较输入和答案是否一致，一致就通过了。<br><pre><code class=\"hljs angelscript\">callq  <span class=\"hljs-number\">401338</span> &lt;<span class=\"hljs-built_in\">string</span>s_not_equal&gt;</code></pre></p>\n</blockquote>\n<h3 id=\"二、gdb调试\"><a href=\"#二、gdb调试\" class=\"headerlink\" title=\"二、gdb调试\"></a>二、gdb调试</h3><blockquote>\n<p>看一下内存地址里面存了什么，获得flag</p>\n</blockquote>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_4801c7e177c56f6e7299c273d0120988.png\"></p>\n<ul>\n<li><strong>答案</strong>: Border relations with Canada have never been better.</li>\n</ul>\n<hr>\n<h2 id=\"Phase-2-循环\"><a href=\"#Phase-2-循环\" class=\"headerlink\" title=\"Phase 2 - 循环\"></a>Phase 2 - 循环</h2><h3 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h3><blockquote>\n<p>本题是一个do while Loop, 难度不大, 耐心读就行了</p>\n</blockquote>\n<p><strong>关键位置</strong></p>\n<ul>\n<li>信息1 ： 看到 read_six_number 知道输入6个数，再往下看</li>\n</ul>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">cmpl</span>   $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">1</span>,(%rsp) # 比较栈顶地址所存变量大小是否为<span class=\"hljs-number\">1</span>\n<span class=\"hljs-attribute\">je</span>     <span class=\"hljs-number\">400</span>f<span class=\"hljs-number\">30</span> &lt;phase_<span class=\"hljs-number\">2</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">34</span>&gt; # 如果为<span class=\"hljs-number\">1</span> 跳转至地址 <span class=\"hljs-number\">400</span>f<span class=\"hljs-number\">30</span>\n<span class=\"hljs-attribute\">callq</span>  <span class=\"hljs-number\">40143</span>a &lt;explode_bomb&gt; # 如果不为<span class=\"hljs-number\">1</span>，直接炸了\n<span class=\"hljs-attribute\">jmp</span>    <span class=\"hljs-number\">400</span>f<span class=\"hljs-number\">30</span> &lt;phase_<span class=\"hljs-number\">2</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">34</span>&gt; # 跳转至地址 <span class=\"hljs-number\">400</span>f<span class=\"hljs-number\">30</span></code></pre>\n<ul>\n<li>信息2 : 第一个数为1</li>\n</ul>\n<p>下面进入Loop Body</p>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_27148224f8cf2be48266eaa52f50b2f8.png\"></p>\n<ul>\n<li>信息3 :<br>可以看到这个循环把前一个数乘了2，跟后一个数比较, 如果相等就能够继续，不然就炸了。</li>\n</ul>\n<blockquote>\n<p>综上也就是说这是一个首项为1，公比为2的等比数列，共6项。</p>\n</blockquote>\n<p>所以答案就是 1 2 4 8 16 32</p>\n<hr>\n<h2 id=\"Phase-3-分支\"><a href=\"#Phase-3-分支\" class=\"headerlink\" title=\"Phase 3 - 分支\"></a>Phase 3 - 分支</h2><h3 id=\"分析-1\"><a href=\"#分析-1\" class=\"headerlink\" title=\"分析\"></a>分析</h3><blockquote>\n<p>第三题关键点在于用gdb查看一下jumptable</p>\n</blockquote>\n<p> 我们先看一下输入，在输入了两个变量后，esi里放了内存中的一个可疑的东西，我们用gdb看一眼。<br><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">4025</span>cf,%esi</code></pre></p>\n<pre><code class=\"hljs shell\">(gdb) p(char *) 0x4025cf\n&quot;%d %d&quot;</code></pre>\n<p> 发现原来是输入两个整型，再往下看</p>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">cmpl</span>   $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">7</span>,<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">8</span>(%rsp) # 将 M(rsp + <span class=\"hljs-number\">8</span>) 看作<span class=\"hljs-number\">32</span>位无符号数跟<span class=\"hljs-number\">7</span>比较\n<span class=\"hljs-attribute\">ja</span>     <span class=\"hljs-number\">400</span>fad &lt;phase_<span class=\"hljs-number\">3</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">6</span>a&gt; # 如果大于就跳转至 <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">400</span>fad (炸弹炸了)</code></pre>\n<p> 发现如果输入的第一个数大于7就爆炸了，看来switch最多只有7个case</p>\n<pre><code class=\"hljs angelscript\">jmpq   *<span class=\"hljs-number\">0x402470</span>(,%rax,<span class=\"hljs-number\">8</span>) \n# 跳转至 (eax * <span class=\"hljs-number\">8</span> + <span class=\"hljs-number\">0x402470</span>)处所存的地址 （jumptable）</code></pre>\n<blockquote>\n<p>最关键的是这一句，构造了一个 switch 的 jumptable，我们知道地址是 0x402470，按照 case * 8 + 0x402470 跳转到该地址里面的地址，所以我们用gdb看一下。</p>\n</blockquote>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_ae5e359c30ff5ccb9292a7472c39eb19.png\"></p>\n<ul>\n<li><p>我通关选了case 1（它比较特殊，处理它其他内存地址跳转都是按case从小到大顺序的，只有case 1 在最后一个，当然其他也都能过。）</p>\n</li>\n<li><p>case 1 跳转到了 0x400fb9 地址</p>\n</li>\n</ul>\n<pre><code class=\"hljs angelscript\">mov    $<span class=\"hljs-number\">0x137</span>,%eax \n# eax = <span class=\"hljs-number\">0x137</span> (<span class=\"hljs-number\">311</span>) (不用跳转了，下面就是 <span class=\"hljs-number\">0x400fbe</span>)</code></pre>\n<p>其将eax置为了0x137，要小心是16进制，所以对应十进制311</p>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">cmp</span>    <span class=\"hljs-number\">0</span>xc(%rsp),%eax # 比较 M(rsp + <span class=\"hljs-number\">12</span>) 和 eax\n<span class=\"hljs-attribute\">je</span>     <span class=\"hljs-number\">400</span>fc<span class=\"hljs-number\">9</span> &lt;phase_<span class=\"hljs-number\">3</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">86</span>&gt; # 如果相等就跳转至 <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">400</span>fc<span class=\"hljs-number\">9</span> (过关了！)</code></pre>\n<p>最后是一个比较，如果eax和第二个输入值相同就过了。</p>\n<ul>\n<li>本题答案（不唯一)</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">case</th>\n<th style=\"text-align:center\">0</th>\n<th style=\"text-align:center\">1</th>\n<th style=\"text-align:center\">2</th>\n<th style=\"text-align:center\">3</th>\n<th style=\"text-align:center\">4</th>\n<th style=\"text-align:center\">5</th>\n<th style=\"text-align:center\">6</th>\n<th style=\"text-align:center\">7</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">ans</td>\n<td style=\"text-align:center\">207</td>\n<td style=\"text-align:center\">311</td>\n<td style=\"text-align:center\">707</td>\n<td style=\"text-align:center\">256</td>\n<td style=\"text-align:center\">389</td>\n<td style=\"text-align:center\">206</td>\n<td style=\"text-align:center\">682</td>\n<td style=\"text-align:center\">327</td>\n</tr>\n</tbody>\n</table>\n</div>\n<hr>\n<h2 id=\"Phase-4-递归\"><a href=\"#Phase-4-递归\" class=\"headerlink\" title=\"Phase 4 - 递归\"></a>Phase 4 - 递归</h2><h3 id=\"分析-2\"><a href=\"#分析-2\" class=\"headerlink\" title=\"分析\"></a>分析</h3><ul>\n<li>这题是个递归，不过不用很深，很快就能看出答案。</li>\n</ul>\n<p>先正常读两个数，放在rdx，rcx中，检查输入。</p>\n<pre><code class=\"hljs angelscript\">cmpl   $<span class=\"hljs-number\">0xe</span>,<span class=\"hljs-number\">0x8</span>(%rsp) \n# 比较 M(rsp + <span class=\"hljs-number\">8</span>) (既 rdx) 与 <span class=\"hljs-number\">0xe</span>\njbe    <span class=\"hljs-number\">40103</span>a &lt;phase_4+<span class=\"hljs-number\">0x2e</span>&gt; \n# 如果 rdx &lt;= <span class=\"hljs-number\">0xe</span> (<span class=\"hljs-number\">14</span>) 跳转至 <span class=\"hljs-number\">0x40103a</span>, 不然就炸了 (作为无符号数)</code></pre>\n<blockquote>\n<p>这两行汇编告诉我们，rdx一定要小于 0xe (14) 且大于等于0, 不然炸了, 大幅度缩小了范围。</p>\n<p>接下来就进入了函数递归调用，先做点预处理，把edx里面存一个立即数14，然后edi为第一个输入值，esi = 0 进入fun4</p>\n</blockquote>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>xe,%edx # edx = <span class=\"hljs-number\">0</span>xe (<span class=\"hljs-number\">14</span>)\n<span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">0</span>,%esi # esi = <span class=\"hljs-number\">0</span>\n<span class=\"hljs-attribute\">mov</span>    <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">8</span>(%rsp),%edi # edi = (第一个输入值)\n<span class=\"hljs-attribute\">callq</span>  <span class=\"hljs-number\">400</span>fce &lt;func<span class=\"hljs-number\">4</span>&gt; # 调用func<span class=\"hljs-number\">4</span></code></pre>\n<blockquote>\n<p>先不着急看fun4，先看看最后要怎么过关<br><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">test</span>   %eax,%eax # eax &amp; eax\n<span class=\"hljs-attribute\">jne</span>    <span class=\"hljs-number\">401058</span> &lt;phase_<span class=\"hljs-number\">4</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">4</span>c&gt; \n<span class=\"hljs-comment\"># 如果ZF == 0 就跳转（既eax != 0)，跳转至 0x401058 炸了</span>\n<span class=\"hljs-attribute\">cmpl</span>   $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>xc(%rsp) # 比较 M(rsp + <span class=\"hljs-number\">12</span>) 和 <span class=\"hljs-number\">0</span>\n<span class=\"hljs-attribute\">je</span>     <span class=\"hljs-number\">40105</span>d &lt;phase_<span class=\"hljs-number\">4</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">51</span>&gt; # 如果相等就跳转到 <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">40105</span>d, 不然就炸了</code></pre></p>\n<ul>\n<li>test 实际上就是一个与操作，所以我们知道需要 eax == 0 且 M(rsp + 12) == 0，到这我们发现，第二个条件只要我们一开始输入的第二个参数为0，就能够保证，那么下面我们就要看进入fun4之后如何让返回值 eax == 0</li>\n</ul>\n<p>再回来看fun4，其分为两部分，一个是递归的主体，一个是判断是否继续递归。一开始先对eax 和 ecx 进行一些操作。</p>\n<ul>\n<li>我们发现 eax 和 ecx 的值在第一层递归都被置为14，(esi 为 0)按其操作得到 eax 除2, ecx 逻辑右移 31 位为0, 接着其实就是比较 edi 和 rax, <strong>相当于就是比较第一个参数和常数 7</strong></li>\n</ul>\n</blockquote>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">jle</span>    <span class=\"hljs-number\">400</span>ff<span class=\"hljs-number\">2</span> &lt;func<span class=\"hljs-number\">4</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">24</span>&gt; # 若ecx &lt;= 就跳转至 <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">400</span>ff<span class=\"hljs-number\">2</span></code></pre>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">0</span>,%eax # eax = <span class=\"hljs-number\">0</span>;\n<span class=\"hljs-attribute\">cmp</span>    %edi,%ecx # 比较 ecx 和 edi \n<span class=\"hljs-attribute\">jge</span>    <span class=\"hljs-number\">401007</span> &lt;func<span class=\"hljs-number\">4</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">39</span>&gt; \n<span class=\"hljs-comment\"># 若 edi &gt;= ecx 跳转至 0x401007 返回</span></code></pre>\n<ul>\n<li>接着是一个跳转, 如果满足我们就跳转至 0x400ff2, 我们发现这里已经满足了我们需要的 eax == 0，而想要结束就得使 edi &gt;= ecx (7), 所以我们发现，对于上下两个跳转条件，只要 edi == ecx == 7 就能一直成立，从而直接达成条件，不用进入递归。</li>\n</ul>\n<p>进而我们得到了本题答案：7 0</p>\n<hr>\n<h2 id=\"Phase-5-指针\"><a href=\"#Phase-5-指针\" class=\"headerlink\" title=\"Phase 5 - 指针\"></a>Phase 5 - 指针</h2><h3 id=\"分析-3\"><a href=\"#分析-3\" class=\"headerlink\" title=\"分析\"></a>分析</h3><ul>\n<li>这题我觉得是最好玩的一题，先直接分析如何通关。</li>\n</ul>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">40245</span>e,%esi # esi = <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">40245</span>e \n<span class=\"hljs-comment\"># 待比较的 string (flyers) 从 0x40245e 移动至 esi</span></code></pre>\n<ul>\n<li>我们在接近返回时看到了一个非常可疑的内存地址，直接给它打出来。</li>\n</ul>\n<pre><code class=\"hljs lsl\">(gdb) p(char*) <span class=\"hljs-number\">0x40245e</span>\n$<span class=\"hljs-number\">4</span> = <span class=\"hljs-number\">0x40245e</span> <span class=\"hljs-string\">&quot;flyers&quot;</span></code></pre>\n<blockquote>\n<p>发现是一个可疑字符串 flyers，阅读上下文汇编代码可知，最后是比较字符串是否和指定字符串 “flyers” 一致。</p>\n</blockquote>\n<ul>\n<li>我们再往上看看要怎么输入</li>\n</ul>\n<pre><code class=\"hljs angelscript\">callq  <span class=\"hljs-number\">40131</span>b &lt;<span class=\"hljs-built_in\">string</span>_length&gt; # 比较字符长度是否为<span class=\"hljs-number\">6</span>\ncmp    $<span class=\"hljs-number\">0x6</span>,%eax # 比较 eax 和 <span class=\"hljs-number\">6</span></code></pre>\n<p>发现输入一定要是六个字符 <em>(于是试了试 flyers 果然不对)</em></p>\n<ul>\n<li>往下看，发现了一个 Loop 循环了6次</li>\n</ul>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_016df1440f7044a54fb4ced529595b58.png\"></p>\n<blockquote>\n<p>经过仔细阅读后，发现这个居然是遍历六个输入字符，将其 ascii 码低4位取出来作为偏移量 (offset),在一个基地址 （0x4024b0）后面取字符出来组成 flyers.</p>\n</blockquote>\n<ul>\n<li>立刻开启 gdb 查看基地址附近的内存</li>\n</ul>\n<p><strong>发现分别对应的偏移量是 9, 15, 14, 5, 6, 7</strong></p>\n<blockquote>\n<p>直接查 ascii 码，发现对应 ionefg 、IONEFG 或者有一些不是字母的字符也行，只要低四位是正确的就可以。 </p>\n</blockquote>\n<p><strong>本题答案:</strong>  ionefg (答案不唯一)</p>\n<hr>\n<h2 id=\"Phase-6-Node结构体\"><a href=\"#Phase-6-Node结构体\" class=\"headerlink\" title=\"Phase 6 - Node结构体\"></a>Phase 6 - Node结构体</h2><h3 id=\"分析-4\"><a href=\"#分析-4\" class=\"headerlink\" title=\"分析\"></a>分析</h3><p>这题还是比较麻烦的，代码比较长也比较复杂，要耐心读。</p>\n<ul>\n<li>这题的代码可以大致分为输入检测与处理和一个对结构体的顺序检测.<blockquote>\n<p>最开始上来先输入六个数之后有个双循环，外部保证输入的六个数要大于等于1，且小于等于6，内部保证互异。所以总体看来就是输入的六个数就是123456, 现在问题是输入的顺序。</p>\n</blockquote>\n</li>\n</ul>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_7194e52688ff3d696a3b889e2b17d63f.png\"></p>\n<p>这段代码遍历了所有输入并用7减去了输入的每个数，所以最后做出答案要记得反一下。</p>\n<ul>\n<li>接下来代码比较复杂，外面大循环循环了六次，内部有两个平行的小循环。作用是构造结构体，并在栈帧中将其存放位置按照输入的数的大小计算得出</li>\n</ul>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_9ea5cd30293a18357af1da93c35e0f59.png\"></p>\n<blockquote>\n<p>分析代码，我们先发现一种特殊情况就是当前计算的数为1时（输入为6）edx直接就是给定的地址 0x6032d0, 其余的都按照其大小，在第一个小循环中循环相应次数，给 rdx 在原地址上相应偏移16位。</p>\n<p>接着下来将其存入栈帧中 rsp + 32 到 rsp + 80 的位置</p>\n</blockquote>\n<ul>\n<li>使用 gdb 查看 node</li>\n</ul>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_f2ecdd05728cbefbba59b068a29fdfdc.png\"></p>\n<p>最后我们看如何通关</p>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_a18a67d1b4dbfa16a7fd8800e3ee304b.png\"></p>\n<blockquote>\n<p>发现通关条件是要求定序，前面node大于后面的节点，根据gdb node节点的值和要求我们得到了 3 4 5 6 1 2 的结果，最后不要忘记这是被7减过之后的结果，原来的输入要还原。所以答案就是 4 3 2 1 6 5</p>\n</blockquote>\n<p><strong>本题答案:</strong> 4 3 2 1 6 5</p>\n<hr>\n<h2 id=\"Secret-Phase-递归\"><a href=\"#Secret-Phase-递归\" class=\"headerlink\" title=\"Secret Phase- 递归\"></a>Secret Phase- 递归</h2><h3 id=\"一、进入方法\"><a href=\"#一、进入方法\" class=\"headerlink\" title=\"一、进入方法\"></a>一、进入方法</h3><ul>\n<li>输入上面六种答案之后，发现 secret phase 并没有出现，于是开始着手寻找入口。</li>\n</ul>\n<blockquote>\n<p>根据最后结果出现的字符顺藤摸瓜找到了 phase_defuse 函数，一看发现其中有一个可疑的 <string_not_equal> 函数以及几个可疑的内存地址,统统用 gdb 打印。</string_not_equal></p>\n</blockquote>\n<pre><code class=\"hljs perl\">(gdb) p(char*) <span class=\"hljs-number\">0x402619</span>\n$2 = <span class=\"hljs-number\">0x402619</span> <span class=\"hljs-string\">&quot;%d %d %s&quot;</span></code></pre>\n<pre><code class=\"hljs lsl\">(gdb) p(char*) <span class=\"hljs-number\">0x402622</span>\n$<span class=\"hljs-number\">3</span> = <span class=\"hljs-number\">0x402622</span> <span class=\"hljs-string\">&quot;DrEvil&quot;</span></code></pre>\n<blockquote>\n<p>发现之前调用过的__isoc99_sscanf@plt 还有隐藏用法，在输入两个数后再输入一个字符串 “DrEvil” 就能成功开启secret phase.</p>\n</blockquote>\n<ul>\n<li>所以我们在最后一次调用__isoc99_sscanf@plt的 phase 4 输入 7 0 DrEvil, 果然在 phase 6 之后进入了 secret phase。</li>\n</ul>\n<h3 id=\"分析-5\"><a href=\"#分析-5\" class=\"headerlink\" title=\"分析\"></a>分析</h3><ul>\n<li>虽然说是隐藏关，但是复杂度和难度比 phase 6 低了不少，和 phase 4 一样是一个递归，但不同的是这次真的需要递归几次，但也不深。只要确定好路线还是比较容易的。</li>\n</ul>\n<pre><code class=\"hljs angelscript\">callq  <span class=\"hljs-number\">40149</span>e &lt;read_line&gt; # 读一行\n...\ncallq  <span class=\"hljs-number\">400</span>bd0 &lt;<span class=\"hljs-symbol\">strtol@</span>plt&gt; # 调用 <span class=\"hljs-symbol\">strtol@</span>plt</code></pre>\n<blockquote>\n<p>secret phase上来读了一整行然后调用了一个 strtol，经过阅读strtol的源码，发现它是以10为base将字符串转为一个整型，实际上就是剔除了最后答案中除了数字以外的字符。(所以写上答案数字然后乱输字母也能过 bushi)</p>\n</blockquote>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">lea</span>    -<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">1</span>(%rax),%eax \n<span class=\"hljs-comment\"># eax = (rax) - 1</span>\n<span class=\"hljs-attribute\">cmp</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">3</span>e<span class=\"hljs-number\">8</span>,%eax \n<span class=\"hljs-comment\"># eax == 0x3e8 ? (即判断返回值与0x3e9)</span></code></pre>\n<ul>\n<li>这段代码告诉我们输入的数要小于 1000</li>\n</ul>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">6030</span>f<span class=\"hljs-number\">0</span>,%edi # edi = <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">6030</span>f<span class=\"hljs-number\">0</span> (<span class=\"hljs-number\">36</span>)\n<span class=\"hljs-attribute\">callq</span>  <span class=\"hljs-number\">401204</span> &lt;fun<span class=\"hljs-number\">7</span>&gt; # 调用fun<span class=\"hljs-number\">7</span></code></pre>\n<ul>\n<li>将edi置为 0x6030f0 (里面存的是36) 接着开始调用fun7</li>\n</ul>\n<blockquote>\n<p>我们先不着急看fun7, 老样子先看过关要求。</p>\n</blockquote>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">cmp</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">2</span>,%eax # 比较一下 eax 返回是否为<span class=\"hljs-number\">2</span></code></pre>\n<p>发现非常简单，只要eax返回值为2就行</p>\n<ul>\n<li>再来看fun7</li>\n</ul>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_64ed470376ec6b72dc43690bf9b4ea0e.png\"></p>\n<blockquote>\n<p>一看这个递归是逃不过了，但我们要让eax == 2, 路线其实非常明确，第一次先走 way3 将 eax 弄成1，再走 way1 让eax<em>2， 最后一层我们让eax == 0 最后返回我们得到的 eax 就等于2\n</em>（eax = 0 -&gt; 1 -&gt; 2）*</p>\n<p>关键是一个 edx 和 esi 的比较，edx == rdi, 然后每次改变rdi使其中储存地址中所储存的变量逐步接近 esi 完成递归操作。</p>\n</blockquote>\n<p>根据所存地址(注意/d打出的是10进制)，可以很容易找出递归路径</p>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_dfddd1801cd10c701dd2753164434977.png\" style=\"width:65%\"></p>\n<ul>\n<li>输入22可以正好满足需求<blockquote>\n<p><strong>22 &lt;= 36 因而 rdi = (rdi + 8) (存8)，22 &gt; 8 因而 rdi = = (rdi + 16) (存22), 22==22 所以 eax 返回 0 ，返回 1， 返回2，最终过关</strong></p>\n</blockquote>\n</li>\n</ul>\n<p><strong>本题答案:</strong> 22 (可以带非数字字符)</p>\n"},{"title":"NLP 情感分类任务","date":"2021-11-24T09:06:34.000Z","index_img":"/img/NLP/banner.jpeg","math":true,"_content":"\n# NLP PJ-1 基于深度学习的文本分类\n\n## 1. 背景介绍\n\n### 情感分类任务 (Sentiment Classification)\n\n​\t文本情感分类任务是NLP众多下游任务的一种，通过深度学习模型来提取文本情感特征来达到对文本情感类型进行分类的目的。其可以是复杂的判别情感极性的多标签分类任务或是回归任务。我们这里是简单的二分类任务，即给定影评文本，确定其评论是积极 (positive) 还是消极 (negative)\n\n### 词嵌入 (Word Embedding)\n\n​\t我们知道传统的词向量one-hot表示法虽然能够将词进行向量化，但是没办法很好的表示两个含义相近的词在空间当中的距离。同时在语料库很大的情况下，one-hot向量会变得非常稀疏且维度极高，非常不利于计算。为此我们引入了词嵌入的方法来对词向量进行降维，将词映射到一个相对于词数量较小的高维空间中。一个好的词嵌入应当能够反映不同的词语之间的联系，例如“猫”，“狗”两个词对应的词向量就应当比“猫”，“水杯”两个词对应的词向量距离更近。现在主流的词嵌入方法主要有两种，一种是托马斯·米科洛维的Word2Vec，以及斯坦福大学提出的GloVe\n\n- **Word2Vec**\n\n  Word2Vec是在整个语料库上进行预训练，通过相邻的词的词向量预测中心词的词向量  (*CBOW*)，或通过中心词的词向量预测相邻词的词向量 (*Skip-gram*) 两种方式，对于语料库中的词来做词嵌入。\n\n​\t相比CBOW在skip-gram当中，每个词都要收到周围的词的影响，每个词在作为中心词的时候，都要进行K次的预测、调整。因此当数据量较少，或者词为生僻词出现次数较少时， 这种多次的调整会使得词向量相对的更加准确，但是训练时间也要有所增长。\n\n<img src=\"https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FphEkS%2FbtqXSoISyn9%2FeI2vpCZ8svhF7X4U3JCTx0%2Fimg.png\" style=\"zoom:70%;\" />\n\n\n\n- **GloVe**\n\n  我们可以看到Word2Vec仅仅注意到了文本的局部上下文特征，而忽略了全局的文本信息，GloVe在此之上对其做出了改进。GloVe从基于SVD的LSA算法出发，首先要通过滑动窗口计算出共现矩阵。我们知道单词的词向量学习应该跟词共现概率的比率有关，而不是他们的概率本身作者发现用共现概率比也可以很好的体现3个单词间的关联(因为共现概率比符合常理)，所以作者大胆猜想，如果能将3个单词的词向量经过某种计算可以表达共现概率比，那么这样的词向量就与共现矩阵有着一致性，可以体现词间的关系。\n\n  - **主要优化目标:** \t$$J = \\sum_{ij}^{V}f(X_{ij})(v_i^T\\hat{v_j}+b_i + \\hat{b_j}-log(X_{ij}))^2$$\n\n### 循环神经网络 (Recurrent Neural Network)\n\n- **普通RNN**\n\n​\t循环神经网络即RNN，其结构设计基于输入序列和上一级状态对当前隐藏状态进行更新，即可以表示为 $p(y_t)=g(y_{t-1},h_t)$，能够比较好的处理序列内容，因此被广泛的应用于NLP领域。但是我们知道，对于普通的RNN来说一旦序列变长，会导致比较明显的网络退化问题，即梯度消失和梯度爆炸难以避免。\n\n- **LSTM** （Long short-term memory）\n\n  ​\t为了解决上述问题，就有了LSTM的出现，即添加了一个全局的信息传递通道 $c_t$ ，通过 $sigmoid$ 作为门控来对上一个节点传入的输入进行选择性忘记，对全局状态进行少量改变。进而再进入输入阶段，对输入通过 $sigmoid$ 来做门控选择记忆，以及最后的输出隐层。内部使用 $tanh$ 作为激活函。通过添加全局记忆流的方式很好的避免了梯度消失问题，使得模型拥有更加长期的记忆能力。\n\n  ​\t但缺点就是模型比RNN复杂了不少，收敛起来速度更慢。\n\n- **GRU** （Gate Recurrent Unit）\n\n  为了解决LSTM训练收敛速度慢的问题，学界又引入了GRU，与LSTM相比，GRU内部少了一个门控即更新门和重置门，参数比LSTM少，在很大程度上提高训练效率。重置门越小代表前一状态被丢弃信息越多，更新门越大代表前一时刻带入信息越多。同时GRU在并不控制和保留内部记忆$c_t$ ，但从设计上能够达到LSTM同样的避免梯度消失的效果。\n\n<img src=\"https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-07-03-lstm-gru.png\" style=\"zoom:80%;\" />\n\n### Transformer\n\n​\t近年来的研究热点一直是在Transformer上，自从谷歌2017年在Attention is all you need一文中提出Transformer模型，其通过内部编码器解码器结构结合多头注意力机制 $QKV$，能够并行的注意到不同单元的特征信息，从而打破了RNN的网络退化训练难题，以BERT为代表的BERT家族模型目前一直是NLP研究的前沿热点模型，因为字数限制在此就不过多介绍。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n## 2. 实验内容\n\n### 2.1 基于RNN及其变体的分类器\n\n我首先在RNN系列模型上进行了一系列实验，采用统一参数，并且拿出最后一层的输出，做 *drop_out* 后通过一个全连接层得到最后的输出，同时全开bidirection。\n\n​\t同时在对比RNN分类器的实验过程中发现，在没有添加 *pretrain* 的 word_embedding，即使用随机初始化的 embedding 进行训练能够更加明显的对比出不同模型的效果。\n\n- **模型主体**\n\n```python\ndef forward(self, x):\n        batch_size, seq_len = x.size()\n        x = self.embed_dropout(self.embeddings(x))\n        out, _ = self.rnn(x)\n        out = out.view(batch_size, seq_len, self.num_labels, self.hidden_size)\n        out = torch.cat([out[:, -1, 0, :], out[:, 0, 1, :]], dim=-1)\n        out = self.dropout(out)\n        logits = self.fc(out)\n        return logits\n```\n\n- **模型参数及超参数**\n\n```yaml\nembed_dim: 300 \t# 嵌入维度\nhidden_size: 512  # 隐藏层维度\nnum_labels: 2  # 标签数\nnum_layers: 2  # 层数\ndropout: 0.5  # 全连接层 drop out\nembed_dropout: 0.5  # 嵌入层 drop out\nWORD_EMBEDDING: Random # 初始对比不加 Word Embedding 效果更加明显\n```\n\n```yaml\n# 超参数\nEPOCH: 30\nBATCH_SIZE: 64\nOPTIMIZER: # 优化器\n  NAME: AdamW\n  ARGS:\n    lr: 6.0e-5\n    eps: 1.0e-6\nSCHEDULER: # 无LR调节\n  NAME: null\n```\n\n#### 2.1.0 Preprocess\n\n在前处理过程中，滤除了语料库当中的非字母符号，对字母进行全小写化。（尝试滤除stop word但其因为会改变很多语义信息，从而最后并未采纳）\n\n```python\ndef preprocess_data(lines):\n    formatted_lines = []\n    for line in lines:\n        # split into tokens by white space\n        tokens = line.split()\n        # remove punctuation from each token and convert to lowercase\n        table = str.maketrans('', '', string.punctuation)\n        tokens = [w.translate(table).lower() for w in tokens]\n        # remove remaining tokens that are not alphabetic\n        tokens = [word for word in tokens if word.isalpha()]\n        # join the new tokens to form the formatted sentence\n        sentence = \" \".join(tokens)\n        formatted_lines.append(sentence)\n    return formatted_lines\n```\n\n#### 2.1.1 RNN\n\nRNN 在随机初始化的 Word Embedding 上表现较差，在Val上最高的准确率达到 65.30%，后期过拟合现象较为严重。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdqmwrpcbj30t60cp3za.jpg\" style=\"zoom:60%;\" />\n\n#### 2.1.2 LSTM\n\nLSTM 则表现较好，最高在Val上的准确率达到 72.84%，同时由于网络表达能力增强，其过拟合现象比RNN更加严重。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdqpqi5uhj30ya0dnt9n.jpg\" style=\"zoom:50%;\" />\n\n#### 2.1.3 GRU\n\nGRU 同样表现不错，在Val上的准确率最高达到 71.57%, 稍微弱于LSTM，但是其收敛速度快于LSTM\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdqsaqauoj30st0dl0tk.jpg\" style=\"zoom:60%;\" />\n\n#### 2.1.4 小结\n\n​\t实验中我们可以看到，单论模型性能 *LSTM* 是表现最好的网络，*GRU* 作为 *LSTM* 的改进版，能够更快的拟合并获得接近 *LSTM* 的效果，而 *RNN* 则由于梯度消失导致的网络退化问题，难以很好的拟合，梯度爆炸导致训练不稳定，性能较差。\n\n| 模型 | 准确率 / % | Epoch / n |\n| :--: | :--------: | :-------: |\n| RNN  |   65.30    |    16     |\n| LSTM |   72.84    |    13     |\n| GRU  |   71.57    |    12     |\n\n\n\n在实验过程中我们不难得出以下结论\n\n**模型性能上：** $LSTM > GRU > RNN$\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n**收敛速度上：** $GRU>LSTM>RNN$\n\n- **过拟合**\n\n  同时在实验过程中我们很容易观察到，在训练后期模型都不同程度的出现了过拟合现象，这里我们在embedding和fc层都添加了0.5的drop_out，如果不添加的话过拟合现象则会更加研究 (详见后文的ablation study)，我们可以使用 early stop 方法简单的早停止训练来防止过拟合现象发生。我们可以看到三个模型在 15 个 Epoch 左右都达到了其最佳性能，所以我们可以将最大 Epoch 设为 15 来防止后期的过拟合现象发生。\n\n\n\n#### 2.1.5 进一步分析\n\n我们还可以继续计算模型的查准率 (Precision), 召回率 (Recall) , F1 score\n$$\nPrecison = \\frac{TP}{TP+FP}\\\\\\\\\nRecall = \\frac{TP}{TP+FN}\\\\\\\\\nF_1 = \\frac{2*Precision*Recall}{Precision + Recall}\n$$\n\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwehwkiqjlj30sp0azwf1.jpg\" style=\"zoom:50%;\" />\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwehsbzj9oj30fp07l74j.jpg\" style=\"zoom:80%;\" />\n\n- **关于查准率和召回率**\n\n  从图中我们不难看出，模型的查准率和召回率互为拮抗，查准率上升的时候召回率一般会下降，为了平衡衡量这两者来公平衡量二分类模型的准确率，我们可以使用F1 Score\n\n- **F1 Score**\n\n  ​\tF1 score作为兼顾了分类模型的准确率和召回率。F1分数可以看作是模型查准率和召回率的一种加权平均，形式表现为查准率和召回率的调和平均。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n### 2.3 比较不同的 Word Embedding 方式\n\n​\t在上述实验的基础上，我选用 LSTM 来进行进一步的实验，为LSTM添加不同的 pretrain 的 Word_Embedding 参数来查看 Word_Embedding 对网络准确率的影响。\n\n#### 2.3.1 Word2Vec\n\n​\t首先实验的是Word2Vec, 这里我选用的是 ```GoogleNews-vectors-negative300```\n\n```yaml\nWORD_EMBEDDING: \n  NAME: Word2Vec # Word2Vec, GloVe, None\n  PATH: Gensim/GoogleNews-vectors-negative300.bin\n```\n\n```python\ndef load_word2vec(text_field, PATH):\n    word_to_idx = text_field.vocab.stoi\n    pretrained_embeddings = np.random.uniform(-0.25, 0.25, (len(text_field.vocab), 300))\n    pretrained_embeddings[0] = 0\n    word2vec = load_bin_vec(PATH, word_to_idx)\n    for word, vector in word2vec.items():\n        pretrained_embeddings[word_to_idx[word]-1] = vector\n\n    return pretrained_embeddings\n```\n\n​\t使用预训练的参数替换模型中的 embeddings 层的初始值，其余训练参数和超参均同上，进行公平对比。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdr76zpusj30sq0dkaau.jpg\" style=\"zoom:60%;\" />\n\n可以看到，预训练的词嵌入非常好的指导网络在情感分类任务上的训练拟合，拟合速度和准确率相比随机初始化的参数都有较大幅度的提升，仅在第7个epoch就得到了最好性能。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n|     模型      | 准确率 / % | Epoch / n |\n| :-----------: | :--------: | :-------: |\n|  LSTM-Random  |   72.84    |    13     |\n| LSTM-Word2Vec |   75.11    |     7     |\n\n\n\n#### 2.3.2 GloVe\n\n​\t我们换上比Word2Vec更加具有全局信息的GloVe嵌入，这里采用的是 ```glove.840B.300d```\n\n```yaml\nWORD_EMBEDDING: \n  NAME: GloVe # Word2Vec, GloVe, None\n  PATH: 'glove.840B.300d'\n```\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdrc8z2jqj30sn0dnaat.jpg\" style=\"zoom:60%;\" />\n\nGloVe 的词嵌入比 Word2Vec 达到了更好的性能，在Val上达到了79.2%的准确率，可以看到预训练的词嵌入对模型性能的提升有非常大的效果\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdtwdj6awj30xh0e10u5.jpg\" alt=\"image-20211113211031902\" style=\"zoom:55%;\" />\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n|     模型      | 准确率 / % | Epoch / n |\n| :-----------: | :--------: | :-------: |\n|  LSTM-Random  |   72.84    |    13     |\n| LSTM-Word2Vec |   75.11    |     7     |\n|  LSTM-GloVe   |    79.2    |     8     |\n\n#### 2.3.4 总结\n\n​\t可以看到预训练的词嵌入能够非常大的提升模型的性能，让模型更好的抓住句子和词之间的联系，抽取句子的语义信息。对情感分类问题有着较大的帮助。\n\n\n\n\n\n### 2.4 基于CNN的分类器\n\n​\t对于词嵌入向量，我们也可以使用CNN对其进行操作，通过卷积核来提取局部特征，并融合全局视野，不过相比RNN的模型结构。CNN的方式对语言问题少了一些先验的序列化模式，因此收敛速度要明显慢于RNN。\n\n为和RNN对比，使用了统一参数。卷积核采用 $3 \\times embed\\_dim$ 大小，同时随机初始化 Word_embedding\n\n```python\nclass CNN(nn.Module):\n  ....\n   self.conv_layers = nn.ModuleList([nn.Conv2d(in_channels=1,\n                                     out_channels=hidden_size,\n                                     kernel_size=(kernel_size, embed_dim))]*num_layers)\n  ....\n```\n\n#### 2.4.1 实验结果\n\n\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdrjpqd2yj30so0dvdgn.jpg\" style=\"zoom:55%;\" />\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n​\t可以看到CNN的拟合速度明显慢于基于RNN的分类器，担其效果不输LSTM甚至略微优于LSTM，在最后一个 Epoch 甚至达到了 73.48% 的准确率，如果继续训练可能会达到更高的准确率，但为了公平对比，因此不再扩大 Epoch 数。\n\n| 模型 | 准确率 / % | Epoch / n |\n| :--: | :--------: | :-------: |\n| RNN  |   65.30    |    16     |\n| LSTM |   72.84    |    13     |\n| GRU  |   71.57    |    12     |\n| CNN  |   73.48    |    30     |\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n### 2.5 基于BERT及其变体的分类器（Transformer） \n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwds81vpfuj30fe0ndwg2.jpg\" style=\"zoom:60%;\" />\n\n#### 2.5.1 BERT\n\n​\tBERT全名即 *Bidirectional Encoder Representations from Transformers* 即从模型思路上使用了 Transformer 的 Encoder 部分，来对输入词向量做 Self Attention，但其比普通 Transformer 的 Encoder 更深更窄，BERT-base 有 12 个 encoder 模块，hidden-size 是 768。\n\n- **预训练任务**\n\n  BERT出彩的地方是其预训练部分做的很好，除了之前所说的普通Word Embedding方式使用的 **Masked LM** 即遮挡预测以外，BERT还引入了下一句预测的预训练模式 **Next Sentence Prediction**，让模型能够更好的理解句子之间的关系\n\n- **实验方法**\n\n  采用载入预训练的BERT checkpoint 再在下游 SST-2 数据集上进行 fine-tune 的方式进行训练\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n- **实验参数**\n\n```yaml\nMODEL:\n  NAME: BERT # RNN, LSTM, GRU, CNN, BERT\n  ARGS:\n    model_type: bert-base-uncased # bert-base-uncased, bert-large-uncased\n    dropout: 0.5\nOPTIMIZER: \n  NAME: AdamW\n  ARGS:\n    lr: 2.0e-5\n    eps: 1.0e-8\n```\n\n```python\n# 采用 linear_schedule_with_warmup\nscheduler = get_linear_schedule_with_warmup(\n   optimizer=optimizer,\n   num_warmup_steps=0,\n   num_training_steps=num_training_steps\n)\n```\n\n- **实验结果**\n\n我个人分别在 BERT-base-uncased 和 BERT-large-uncased 上进行了训练\n\n- **BERT-base-uncased**\n\n**参数信息：** 12-layer, 768-hidden, 12-heads, 110M parameters\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdsttr9sbj30s90cr750.jpg\" style=\"zoom:60%;\" />\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n- **BERT-large-uncased**\n\n**参数信息：** 24-layer, 1024-hidden, 16-heads, 336M parameters\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdsnvaegsj30sn0cqt9f.jpg\" style=\"zoom:60%;\" />\n\n- **总结**\n\n|        模型        | 准确率 / % | Epoch / n |\n| :----------------: | :--------: | :-------: |\n| BERT-base-uncased  |   86.97    |     1     |\n| BERT-large-uncased |   88.65    |     2     |\n\n可以看到 BERT-large 性能好于 BERT-base 能够达到极高的 88.65% 同时由于参数量的提升，收敛上页略慢于BERT-base，在第2个epoch达到最佳性能。\n\n\n\n#### 2.5.4 其他BERT变种\n\n​\t我继续使用测试了其他 BERT 变种例如 RoBERTa，以及AlBERT来进一步提升模型的准确率，经过实验发现 RoBERTa-large的准确率可以达到90%左右，而最好的准确率是使用 AlBERT-xxlarge 上可以在 Val 上达到 91%的准确率。\n\n- **训练参数设置：**\n\n```yaml\nScheduler: warmup_cosine\nOptimizer: AdamW\nLR: 1e-5\nEpoch: 5\nBatchSize: 8\n```\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n- **AlBERT-xxlarge-v2**\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdszgffm2j30xg0dijsa.jpg\" style=\"zoom:60%;\" />\n\n​\t准确率最高达到 91.01%，可以看到模型在大约第3个epoch达到最佳性能，后开始过拟合。为此我使用early stop，训练3个epoch\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwefzu7y82j30wt0dfgmh.jpg\" style=\"zoom:60%;\" />\n\n​\t模型准确率最高达到91.46%\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n### 2.6 训练方法对模型性能的影响\n\n#### 2.3.2 改变BatchSize\n\n​\tBatch Size 对模型的准确性没有很大的影响，但在小batch的情况下有可能导致训练不稳定，iter之间的loss差距较大。\n\n​\t同时更大的Batch Size能够加快训练速度，更好的在全数据集上拟合，但这也不是说越大越好。过大的batch size可能会导致batch之间梯度变化过小，模型泛化能力缺失。同时也要注意自己使用的是什么Optimizer，如果是SGD优化器，batch size和learning rate之间成线性关系，在更改batch size的时候需要注意更改学习率。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdu5o0h46j30sp0cijsn.jpg\" style=\"zoom:60%;\" />\n\n#### 2.3.4 改变Drop Out\n\n​\tdrop out 对网络过拟合现象有比较大的影响，如果drop out过小网络表达能力过强且集中于几个特定神经元上，导致训练很快拟合到训练集上，从而导致模型泛化能力变差，性能减弱。这里我测试了三种drop_out的大小，分别是0.5, 0.2, 0\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwehhhqij9j30nj0cw3zm.jpg\" style=\"zoom:60%;\" />\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwehla48ruj30nh0cpt9h.jpg\" style=\"zoom:60%;\" />\n\n可以看到网络在 drop out = 0.5 的时候性能最好。在 drop out = 0 的时候过拟合非常严重，性能最差。但因为drop out比较大，拟合上相比0.2和0速度更慢。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwehdm8dyvj30g909f3zc.jpg\" style=\"zoom:67%;\" />\n\n​\t在限制 drop out 为0.5时，其eval上的loss最小，而train上的loss最大，eval和train上的准确率增长较为同步。且过拟合现象最不严重，相比之下，drop out=0 时，过拟合现象十分严重，测试集上loss很大。\n\n- **关于Drop out**\n\n不得不提，如果drop out过大网络的表达能力会被损害，如果drop_out = 1相当于网络中这一层上所有激活全被 drop 掉，网络就无法输出信息了。因此选用合适的drop out十分重要\n\n\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n## 3.总结\n\n​\t在本次实验中，对比了不同的模型在情感分类任务上的性能，探索了不同Word Embedding对模型性能的影响，比较了不同训练方法对模型的影响。基本了解并探索了NLP的基本任务和实验流程。得到如下实验结果\n\n|        模型        | 准确率 / % | Epoch / n |\n| :----------------: | :--------: | :-------: |\n|        RNN         |   65.30    |    16     |\n|        LSTM        |   72.84    |    13     |\n|        GRU         |   71.57    |    12     |\n|        CNN         |   73.48    |    30     |\n|   LSTM-Word2Vec    |   75.11    |     7     |\n|     LSTM-GloVe     |    79.2    |     8     |\n| BERT-base-uncased  |   86.97    |     1     |\n| BERT-large-uncased |   88.65    |     2     |\n|   RoBERTa-large    |   90.02    |     3     |\n| AlBERT-xxlarge-v2  |   91.46    |     3     |\n\n#### 3.1 进一步实验方向\n\n- **蒸馏学习**\n\n  可以通过高准确率的模型例如BERT给低准确率的模型例如LSTM进行蒸馏，在训练过程中增加一个loss进行指导训练，来进一步提升小模型的准确率。这在实际工业场景中有很大的应用场景\n  $$\n  loss = \\alpha CrossEntropy(pred, true) + (1-\\alpha) MSEloss(pred, bert\\_true)\n  $$\n\n- **多模型ensemble**\n\n  可以采用多模型 ensemble 的方式进一步提升模型的准确率，即训练多个不同的模型，或即使是相同模型进行不同初始化的结果，最后做简单的投票。这种ensemble方式能够进一步提升模型的性能，目前广泛应用于对及时性要求较少的场景和各大算法竞赛当中（例如Kaggle）\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n## Reference\n\n[1] Ralf C. Staudemeyer, & Eric Rothstein Morris. (2019). Understanding LSTM – a tutorial into Long Short-Term Memory Recurrent Neural Networks.\n\n[2] Sherstinsky, A. (2020). Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) network*. Physica D: Nonlinear Phenomena, \\*404\\*, 132306.\n\n[3] Jacob Devlin, Ming-Wei Chang, Kenton Lee, & Kristina Toutanova. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.\n\n[4] Victor Sanh, Lysandre Debut, Julien Chaumond, & Thomas Wolf. (2020). DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter.\n\n[5] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, & Veselin Stoyanov. (2019). RoBERTa: A Robustly Optimized BERT Pretraining Approach.\n\n[6] Dang, N., Moreno-García, M., & Prieta, F. (2020). Sentiment Analysis Based on Deep Learning: A Comparative Study*. Electronics, \\*9*(3), 483.\n\n\n\n\n\n","source":"_posts/NLP/nlp-sst.md","raw":"---\ntitle: NLP 情感分类任务\ndate: 2021-11-24 01:06:34\nindex_img: /img/NLP/banner.jpeg\ncategory: [NLP]\ntags: [SST, Sentiment Classification]\nmath: true\n---\n\n# NLP PJ-1 基于深度学习的文本分类\n\n## 1. 背景介绍\n\n### 情感分类任务 (Sentiment Classification)\n\n​\t文本情感分类任务是NLP众多下游任务的一种，通过深度学习模型来提取文本情感特征来达到对文本情感类型进行分类的目的。其可以是复杂的判别情感极性的多标签分类任务或是回归任务。我们这里是简单的二分类任务，即给定影评文本，确定其评论是积极 (positive) 还是消极 (negative)\n\n### 词嵌入 (Word Embedding)\n\n​\t我们知道传统的词向量one-hot表示法虽然能够将词进行向量化，但是没办法很好的表示两个含义相近的词在空间当中的距离。同时在语料库很大的情况下，one-hot向量会变得非常稀疏且维度极高，非常不利于计算。为此我们引入了词嵌入的方法来对词向量进行降维，将词映射到一个相对于词数量较小的高维空间中。一个好的词嵌入应当能够反映不同的词语之间的联系，例如“猫”，“狗”两个词对应的词向量就应当比“猫”，“水杯”两个词对应的词向量距离更近。现在主流的词嵌入方法主要有两种，一种是托马斯·米科洛维的Word2Vec，以及斯坦福大学提出的GloVe\n\n- **Word2Vec**\n\n  Word2Vec是在整个语料库上进行预训练，通过相邻的词的词向量预测中心词的词向量  (*CBOW*)，或通过中心词的词向量预测相邻词的词向量 (*Skip-gram*) 两种方式，对于语料库中的词来做词嵌入。\n\n​\t相比CBOW在skip-gram当中，每个词都要收到周围的词的影响，每个词在作为中心词的时候，都要进行K次的预测、调整。因此当数据量较少，或者词为生僻词出现次数较少时， 这种多次的调整会使得词向量相对的更加准确，但是训练时间也要有所增长。\n\n<img src=\"https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FphEkS%2FbtqXSoISyn9%2FeI2vpCZ8svhF7X4U3JCTx0%2Fimg.png\" style=\"zoom:70%;\" />\n\n\n\n- **GloVe**\n\n  我们可以看到Word2Vec仅仅注意到了文本的局部上下文特征，而忽略了全局的文本信息，GloVe在此之上对其做出了改进。GloVe从基于SVD的LSA算法出发，首先要通过滑动窗口计算出共现矩阵。我们知道单词的词向量学习应该跟词共现概率的比率有关，而不是他们的概率本身作者发现用共现概率比也可以很好的体现3个单词间的关联(因为共现概率比符合常理)，所以作者大胆猜想，如果能将3个单词的词向量经过某种计算可以表达共现概率比，那么这样的词向量就与共现矩阵有着一致性，可以体现词间的关系。\n\n  - **主要优化目标:** \t$$J = \\sum_{ij}^{V}f(X_{ij})(v_i^T\\hat{v_j}+b_i + \\hat{b_j}-log(X_{ij}))^2$$\n\n### 循环神经网络 (Recurrent Neural Network)\n\n- **普通RNN**\n\n​\t循环神经网络即RNN，其结构设计基于输入序列和上一级状态对当前隐藏状态进行更新，即可以表示为 $p(y_t)=g(y_{t-1},h_t)$，能够比较好的处理序列内容，因此被广泛的应用于NLP领域。但是我们知道，对于普通的RNN来说一旦序列变长，会导致比较明显的网络退化问题，即梯度消失和梯度爆炸难以避免。\n\n- **LSTM** （Long short-term memory）\n\n  ​\t为了解决上述问题，就有了LSTM的出现，即添加了一个全局的信息传递通道 $c_t$ ，通过 $sigmoid$ 作为门控来对上一个节点传入的输入进行选择性忘记，对全局状态进行少量改变。进而再进入输入阶段，对输入通过 $sigmoid$ 来做门控选择记忆，以及最后的输出隐层。内部使用 $tanh$ 作为激活函。通过添加全局记忆流的方式很好的避免了梯度消失问题，使得模型拥有更加长期的记忆能力。\n\n  ​\t但缺点就是模型比RNN复杂了不少，收敛起来速度更慢。\n\n- **GRU** （Gate Recurrent Unit）\n\n  为了解决LSTM训练收敛速度慢的问题，学界又引入了GRU，与LSTM相比，GRU内部少了一个门控即更新门和重置门，参数比LSTM少，在很大程度上提高训练效率。重置门越小代表前一状态被丢弃信息越多，更新门越大代表前一时刻带入信息越多。同时GRU在并不控制和保留内部记忆$c_t$ ，但从设计上能够达到LSTM同样的避免梯度消失的效果。\n\n<img src=\"https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-07-03-lstm-gru.png\" style=\"zoom:80%;\" />\n\n### Transformer\n\n​\t近年来的研究热点一直是在Transformer上，自从谷歌2017年在Attention is all you need一文中提出Transformer模型，其通过内部编码器解码器结构结合多头注意力机制 $QKV$，能够并行的注意到不同单元的特征信息，从而打破了RNN的网络退化训练难题，以BERT为代表的BERT家族模型目前一直是NLP研究的前沿热点模型，因为字数限制在此就不过多介绍。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n## 2. 实验内容\n\n### 2.1 基于RNN及其变体的分类器\n\n我首先在RNN系列模型上进行了一系列实验，采用统一参数，并且拿出最后一层的输出，做 *drop_out* 后通过一个全连接层得到最后的输出，同时全开bidirection。\n\n​\t同时在对比RNN分类器的实验过程中发现，在没有添加 *pretrain* 的 word_embedding，即使用随机初始化的 embedding 进行训练能够更加明显的对比出不同模型的效果。\n\n- **模型主体**\n\n```python\ndef forward(self, x):\n        batch_size, seq_len = x.size()\n        x = self.embed_dropout(self.embeddings(x))\n        out, _ = self.rnn(x)\n        out = out.view(batch_size, seq_len, self.num_labels, self.hidden_size)\n        out = torch.cat([out[:, -1, 0, :], out[:, 0, 1, :]], dim=-1)\n        out = self.dropout(out)\n        logits = self.fc(out)\n        return logits\n```\n\n- **模型参数及超参数**\n\n```yaml\nembed_dim: 300 \t# 嵌入维度\nhidden_size: 512  # 隐藏层维度\nnum_labels: 2  # 标签数\nnum_layers: 2  # 层数\ndropout: 0.5  # 全连接层 drop out\nembed_dropout: 0.5  # 嵌入层 drop out\nWORD_EMBEDDING: Random # 初始对比不加 Word Embedding 效果更加明显\n```\n\n```yaml\n# 超参数\nEPOCH: 30\nBATCH_SIZE: 64\nOPTIMIZER: # 优化器\n  NAME: AdamW\n  ARGS:\n    lr: 6.0e-5\n    eps: 1.0e-6\nSCHEDULER: # 无LR调节\n  NAME: null\n```\n\n#### 2.1.0 Preprocess\n\n在前处理过程中，滤除了语料库当中的非字母符号，对字母进行全小写化。（尝试滤除stop word但其因为会改变很多语义信息，从而最后并未采纳）\n\n```python\ndef preprocess_data(lines):\n    formatted_lines = []\n    for line in lines:\n        # split into tokens by white space\n        tokens = line.split()\n        # remove punctuation from each token and convert to lowercase\n        table = str.maketrans('', '', string.punctuation)\n        tokens = [w.translate(table).lower() for w in tokens]\n        # remove remaining tokens that are not alphabetic\n        tokens = [word for word in tokens if word.isalpha()]\n        # join the new tokens to form the formatted sentence\n        sentence = \" \".join(tokens)\n        formatted_lines.append(sentence)\n    return formatted_lines\n```\n\n#### 2.1.1 RNN\n\nRNN 在随机初始化的 Word Embedding 上表现较差，在Val上最高的准确率达到 65.30%，后期过拟合现象较为严重。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdqmwrpcbj30t60cp3za.jpg\" style=\"zoom:60%;\" />\n\n#### 2.1.2 LSTM\n\nLSTM 则表现较好，最高在Val上的准确率达到 72.84%，同时由于网络表达能力增强，其过拟合现象比RNN更加严重。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdqpqi5uhj30ya0dnt9n.jpg\" style=\"zoom:50%;\" />\n\n#### 2.1.3 GRU\n\nGRU 同样表现不错，在Val上的准确率最高达到 71.57%, 稍微弱于LSTM，但是其收敛速度快于LSTM\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdqsaqauoj30st0dl0tk.jpg\" style=\"zoom:60%;\" />\n\n#### 2.1.4 小结\n\n​\t实验中我们可以看到，单论模型性能 *LSTM* 是表现最好的网络，*GRU* 作为 *LSTM* 的改进版，能够更快的拟合并获得接近 *LSTM* 的效果，而 *RNN* 则由于梯度消失导致的网络退化问题，难以很好的拟合，梯度爆炸导致训练不稳定，性能较差。\n\n| 模型 | 准确率 / % | Epoch / n |\n| :--: | :--------: | :-------: |\n| RNN  |   65.30    |    16     |\n| LSTM |   72.84    |    13     |\n| GRU  |   71.57    |    12     |\n\n\n\n在实验过程中我们不难得出以下结论\n\n**模型性能上：** $LSTM > GRU > RNN$\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n**收敛速度上：** $GRU>LSTM>RNN$\n\n- **过拟合**\n\n  同时在实验过程中我们很容易观察到，在训练后期模型都不同程度的出现了过拟合现象，这里我们在embedding和fc层都添加了0.5的drop_out，如果不添加的话过拟合现象则会更加研究 (详见后文的ablation study)，我们可以使用 early stop 方法简单的早停止训练来防止过拟合现象发生。我们可以看到三个模型在 15 个 Epoch 左右都达到了其最佳性能，所以我们可以将最大 Epoch 设为 15 来防止后期的过拟合现象发生。\n\n\n\n#### 2.1.5 进一步分析\n\n我们还可以继续计算模型的查准率 (Precision), 召回率 (Recall) , F1 score\n$$\nPrecison = \\frac{TP}{TP+FP}\\\\\\\\\nRecall = \\frac{TP}{TP+FN}\\\\\\\\\nF_1 = \\frac{2*Precision*Recall}{Precision + Recall}\n$$\n\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwehwkiqjlj30sp0azwf1.jpg\" style=\"zoom:50%;\" />\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwehsbzj9oj30fp07l74j.jpg\" style=\"zoom:80%;\" />\n\n- **关于查准率和召回率**\n\n  从图中我们不难看出，模型的查准率和召回率互为拮抗，查准率上升的时候召回率一般会下降，为了平衡衡量这两者来公平衡量二分类模型的准确率，我们可以使用F1 Score\n\n- **F1 Score**\n\n  ​\tF1 score作为兼顾了分类模型的准确率和召回率。F1分数可以看作是模型查准率和召回率的一种加权平均，形式表现为查准率和召回率的调和平均。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n### 2.3 比较不同的 Word Embedding 方式\n\n​\t在上述实验的基础上，我选用 LSTM 来进行进一步的实验，为LSTM添加不同的 pretrain 的 Word_Embedding 参数来查看 Word_Embedding 对网络准确率的影响。\n\n#### 2.3.1 Word2Vec\n\n​\t首先实验的是Word2Vec, 这里我选用的是 ```GoogleNews-vectors-negative300```\n\n```yaml\nWORD_EMBEDDING: \n  NAME: Word2Vec # Word2Vec, GloVe, None\n  PATH: Gensim/GoogleNews-vectors-negative300.bin\n```\n\n```python\ndef load_word2vec(text_field, PATH):\n    word_to_idx = text_field.vocab.stoi\n    pretrained_embeddings = np.random.uniform(-0.25, 0.25, (len(text_field.vocab), 300))\n    pretrained_embeddings[0] = 0\n    word2vec = load_bin_vec(PATH, word_to_idx)\n    for word, vector in word2vec.items():\n        pretrained_embeddings[word_to_idx[word]-1] = vector\n\n    return pretrained_embeddings\n```\n\n​\t使用预训练的参数替换模型中的 embeddings 层的初始值，其余训练参数和超参均同上，进行公平对比。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdr76zpusj30sq0dkaau.jpg\" style=\"zoom:60%;\" />\n\n可以看到，预训练的词嵌入非常好的指导网络在情感分类任务上的训练拟合，拟合速度和准确率相比随机初始化的参数都有较大幅度的提升，仅在第7个epoch就得到了最好性能。\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n|     模型      | 准确率 / % | Epoch / n |\n| :-----------: | :--------: | :-------: |\n|  LSTM-Random  |   72.84    |    13     |\n| LSTM-Word2Vec |   75.11    |     7     |\n\n\n\n#### 2.3.2 GloVe\n\n​\t我们换上比Word2Vec更加具有全局信息的GloVe嵌入，这里采用的是 ```glove.840B.300d```\n\n```yaml\nWORD_EMBEDDING: \n  NAME: GloVe # Word2Vec, GloVe, None\n  PATH: 'glove.840B.300d'\n```\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdrc8z2jqj30sn0dnaat.jpg\" style=\"zoom:60%;\" />\n\nGloVe 的词嵌入比 Word2Vec 达到了更好的性能，在Val上达到了79.2%的准确率，可以看到预训练的词嵌入对模型性能的提升有非常大的效果\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdtwdj6awj30xh0e10u5.jpg\" alt=\"image-20211113211031902\" style=\"zoom:55%;\" />\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n|     模型      | 准确率 / % | Epoch / n |\n| :-----------: | :--------: | :-------: |\n|  LSTM-Random  |   72.84    |    13     |\n| LSTM-Word2Vec |   75.11    |     7     |\n|  LSTM-GloVe   |    79.2    |     8     |\n\n#### 2.3.4 总结\n\n​\t可以看到预训练的词嵌入能够非常大的提升模型的性能，让模型更好的抓住句子和词之间的联系，抽取句子的语义信息。对情感分类问题有着较大的帮助。\n\n\n\n\n\n### 2.4 基于CNN的分类器\n\n​\t对于词嵌入向量，我们也可以使用CNN对其进行操作，通过卷积核来提取局部特征，并融合全局视野，不过相比RNN的模型结构。CNN的方式对语言问题少了一些先验的序列化模式，因此收敛速度要明显慢于RNN。\n\n为和RNN对比，使用了统一参数。卷积核采用 $3 \\times embed\\_dim$ 大小，同时随机初始化 Word_embedding\n\n```python\nclass CNN(nn.Module):\n  ....\n   self.conv_layers = nn.ModuleList([nn.Conv2d(in_channels=1,\n                                     out_channels=hidden_size,\n                                     kernel_size=(kernel_size, embed_dim))]*num_layers)\n  ....\n```\n\n#### 2.4.1 实验结果\n\n\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdrjpqd2yj30so0dvdgn.jpg\" style=\"zoom:55%;\" />\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n​\t可以看到CNN的拟合速度明显慢于基于RNN的分类器，担其效果不输LSTM甚至略微优于LSTM，在最后一个 Epoch 甚至达到了 73.48% 的准确率，如果继续训练可能会达到更高的准确率，但为了公平对比，因此不再扩大 Epoch 数。\n\n| 模型 | 准确率 / % | Epoch / n |\n| :--: | :--------: | :-------: |\n| RNN  |   65.30    |    16     |\n| LSTM |   72.84    |    13     |\n| GRU  |   71.57    |    12     |\n| CNN  |   73.48    |    30     |\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n### 2.5 基于BERT及其变体的分类器（Transformer） \n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwds81vpfuj30fe0ndwg2.jpg\" style=\"zoom:60%;\" />\n\n#### 2.5.1 BERT\n\n​\tBERT全名即 *Bidirectional Encoder Representations from Transformers* 即从模型思路上使用了 Transformer 的 Encoder 部分，来对输入词向量做 Self Attention，但其比普通 Transformer 的 Encoder 更深更窄，BERT-base 有 12 个 encoder 模块，hidden-size 是 768。\n\n- **预训练任务**\n\n  BERT出彩的地方是其预训练部分做的很好，除了之前所说的普通Word Embedding方式使用的 **Masked LM** 即遮挡预测以外，BERT还引入了下一句预测的预训练模式 **Next Sentence Prediction**，让模型能够更好的理解句子之间的关系\n\n- **实验方法**\n\n  采用载入预训练的BERT checkpoint 再在下游 SST-2 数据集上进行 fine-tune 的方式进行训练\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n- **实验参数**\n\n```yaml\nMODEL:\n  NAME: BERT # RNN, LSTM, GRU, CNN, BERT\n  ARGS:\n    model_type: bert-base-uncased # bert-base-uncased, bert-large-uncased\n    dropout: 0.5\nOPTIMIZER: \n  NAME: AdamW\n  ARGS:\n    lr: 2.0e-5\n    eps: 1.0e-8\n```\n\n```python\n# 采用 linear_schedule_with_warmup\nscheduler = get_linear_schedule_with_warmup(\n   optimizer=optimizer,\n   num_warmup_steps=0,\n   num_training_steps=num_training_steps\n)\n```\n\n- **实验结果**\n\n我个人分别在 BERT-base-uncased 和 BERT-large-uncased 上进行了训练\n\n- **BERT-base-uncased**\n\n**参数信息：** 12-layer, 768-hidden, 12-heads, 110M parameters\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdsttr9sbj30s90cr750.jpg\" style=\"zoom:60%;\" />\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n- **BERT-large-uncased**\n\n**参数信息：** 24-layer, 1024-hidden, 16-heads, 336M parameters\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdsnvaegsj30sn0cqt9f.jpg\" style=\"zoom:60%;\" />\n\n- **总结**\n\n|        模型        | 准确率 / % | Epoch / n |\n| :----------------: | :--------: | :-------: |\n| BERT-base-uncased  |   86.97    |     1     |\n| BERT-large-uncased |   88.65    |     2     |\n\n可以看到 BERT-large 性能好于 BERT-base 能够达到极高的 88.65% 同时由于参数量的提升，收敛上页略慢于BERT-base，在第2个epoch达到最佳性能。\n\n\n\n#### 2.5.4 其他BERT变种\n\n​\t我继续使用测试了其他 BERT 变种例如 RoBERTa，以及AlBERT来进一步提升模型的准确率，经过实验发现 RoBERTa-large的准确率可以达到90%左右，而最好的准确率是使用 AlBERT-xxlarge 上可以在 Val 上达到 91%的准确率。\n\n- **训练参数设置：**\n\n```yaml\nScheduler: warmup_cosine\nOptimizer: AdamW\nLR: 1e-5\nEpoch: 5\nBatchSize: 8\n```\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n- **AlBERT-xxlarge-v2**\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdszgffm2j30xg0dijsa.jpg\" style=\"zoom:60%;\" />\n\n​\t准确率最高达到 91.01%，可以看到模型在大约第3个epoch达到最佳性能，后开始过拟合。为此我使用early stop，训练3个epoch\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwefzu7y82j30wt0dfgmh.jpg\" style=\"zoom:60%;\" />\n\n​\t模型准确率最高达到91.46%\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n### 2.6 训练方法对模型性能的影响\n\n#### 2.3.2 改变BatchSize\n\n​\tBatch Size 对模型的准确性没有很大的影响，但在小batch的情况下有可能导致训练不稳定，iter之间的loss差距较大。\n\n​\t同时更大的Batch Size能够加快训练速度，更好的在全数据集上拟合，但这也不是说越大越好。过大的batch size可能会导致batch之间梯度变化过小，模型泛化能力缺失。同时也要注意自己使用的是什么Optimizer，如果是SGD优化器，batch size和learning rate之间成线性关系，在更改batch size的时候需要注意更改学习率。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdu5o0h46j30sp0cijsn.jpg\" style=\"zoom:60%;\" />\n\n#### 2.3.4 改变Drop Out\n\n​\tdrop out 对网络过拟合现象有比较大的影响，如果drop out过小网络表达能力过强且集中于几个特定神经元上，导致训练很快拟合到训练集上，从而导致模型泛化能力变差，性能减弱。这里我测试了三种drop_out的大小，分别是0.5, 0.2, 0\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwehhhqij9j30nj0cw3zm.jpg\" style=\"zoom:60%;\" />\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwehla48ruj30nh0cpt9h.jpg\" style=\"zoom:60%;\" />\n\n可以看到网络在 drop out = 0.5 的时候性能最好。在 drop out = 0 的时候过拟合非常严重，性能最差。但因为drop out比较大，拟合上相比0.2和0速度更慢。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwehdm8dyvj30g909f3zc.jpg\" style=\"zoom:67%;\" />\n\n​\t在限制 drop out 为0.5时，其eval上的loss最小，而train上的loss最大，eval和train上的准确率增长较为同步。且过拟合现象最不严重，相比之下，drop out=0 时，过拟合现象十分严重，测试集上loss很大。\n\n- **关于Drop out**\n\n不得不提，如果drop out过大网络的表达能力会被损害，如果drop_out = 1相当于网络中这一层上所有激活全被 drop 掉，网络就无法输出信息了。因此选用合适的drop out十分重要\n\n\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n## 3.总结\n\n​\t在本次实验中，对比了不同的模型在情感分类任务上的性能，探索了不同Word Embedding对模型性能的影响，比较了不同训练方法对模型的影响。基本了解并探索了NLP的基本任务和实验流程。得到如下实验结果\n\n|        模型        | 准确率 / % | Epoch / n |\n| :----------------: | :--------: | :-------: |\n|        RNN         |   65.30    |    16     |\n|        LSTM        |   72.84    |    13     |\n|        GRU         |   71.57    |    12     |\n|        CNN         |   73.48    |    30     |\n|   LSTM-Word2Vec    |   75.11    |     7     |\n|     LSTM-GloVe     |    79.2    |     8     |\n| BERT-base-uncased  |   86.97    |     1     |\n| BERT-large-uncased |   88.65    |     2     |\n|   RoBERTa-large    |   90.02    |     3     |\n| AlBERT-xxlarge-v2  |   91.46    |     3     |\n\n#### 3.1 进一步实验方向\n\n- **蒸馏学习**\n\n  可以通过高准确率的模型例如BERT给低准确率的模型例如LSTM进行蒸馏，在训练过程中增加一个loss进行指导训练，来进一步提升小模型的准确率。这在实际工业场景中有很大的应用场景\n  $$\n  loss = \\alpha CrossEntropy(pred, true) + (1-\\alpha) MSEloss(pred, bert\\_true)\n  $$\n\n- **多模型ensemble**\n\n  可以采用多模型 ensemble 的方式进一步提升模型的准确率，即训练多个不同的模型，或即使是相同模型进行不同初始化的结果，最后做简单的投票。这种ensemble方式能够进一步提升模型的性能，目前广泛应用于对及时性要求较少的场景和各大算法竞赛当中（例如Kaggle）\n\n<div STYLE=\"page-break-after: always;\"></div>\n\n## Reference\n\n[1] Ralf C. Staudemeyer, & Eric Rothstein Morris. (2019). Understanding LSTM – a tutorial into Long Short-Term Memory Recurrent Neural Networks.\n\n[2] Sherstinsky, A. (2020). Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) network*. Physica D: Nonlinear Phenomena, \\*404\\*, 132306.\n\n[3] Jacob Devlin, Ming-Wei Chang, Kenton Lee, & Kristina Toutanova. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.\n\n[4] Victor Sanh, Lysandre Debut, Julien Chaumond, & Thomas Wolf. (2020). DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter.\n\n[5] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, & Veselin Stoyanov. (2019). RoBERTa: A Robustly Optimized BERT Pretraining Approach.\n\n[6] Dang, N., Moreno-García, M., & Prieta, F. (2020). Sentiment Analysis Based on Deep Learning: A Comparative Study*. Electronics, \\*9*(3), 483.\n\n\n\n\n\n","slug":"NLP/nlp-sst","published":1,"updated":"2026-02-03T05:42:14.437Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvd00187uit3y0ta414","content":"<h1 id=\"NLP-PJ-1-基于深度学习的文本分类\"><a href=\"#NLP-PJ-1-基于深度学习的文本分类\" class=\"headerlink\" title=\"NLP PJ-1 基于深度学习的文本分类\"></a>NLP PJ-1 基于深度学习的文本分类</h1><h2 id=\"1-背景介绍\"><a href=\"#1-背景介绍\" class=\"headerlink\" title=\"1. 背景介绍\"></a>1. 背景介绍</h2><h3 id=\"情感分类任务-Sentiment-Classification\"><a href=\"#情感分类任务-Sentiment-Classification\" class=\"headerlink\" title=\"情感分类任务 (Sentiment Classification)\"></a>情感分类任务 (Sentiment Classification)</h3><p>​    文本情感分类任务是NLP众多下游任务的一种，通过深度学习模型来提取文本情感特征来达到对文本情感类型进行分类的目的。其可以是复杂的判别情感极性的多标签分类任务或是回归任务。我们这里是简单的二分类任务，即给定影评文本，确定其评论是积极 (positive) 还是消极 (negative)</p>\n<h3 id=\"词嵌入-Word-Embedding\"><a href=\"#词嵌入-Word-Embedding\" class=\"headerlink\" title=\"词嵌入 (Word Embedding)\"></a>词嵌入 (Word Embedding)</h3><p>​    我们知道传统的词向量one-hot表示法虽然能够将词进行向量化，但是没办法很好的表示两个含义相近的词在空间当中的距离。同时在语料库很大的情况下，one-hot向量会变得非常稀疏且维度极高，非常不利于计算。为此我们引入了词嵌入的方法来对词向量进行降维，将词映射到一个相对于词数量较小的高维空间中。一个好的词嵌入应当能够反映不同的词语之间的联系，例如“猫”，“狗”两个词对应的词向量就应当比“猫”，“水杯”两个词对应的词向量距离更近。现在主流的词嵌入方法主要有两种，一种是托马斯·米科洛维的Word2Vec，以及斯坦福大学提出的GloVe</p>\n<ul>\n<li><p><strong>Word2Vec</strong></p>\n<p>Word2Vec是在整个语料库上进行预训练，通过相邻的词的词向量预测中心词的词向量  (<em>CBOW</em>)，或通过中心词的词向量预测相邻词的词向量 (<em>Skip-gram</em>) 两种方式，对于语料库中的词来做词嵌入。</p>\n</li>\n</ul>\n<p>​    相比CBOW在skip-gram当中，每个词都要收到周围的词的影响，每个词在作为中心词的时候，都要进行K次的预测、调整。因此当数据量较少，或者词为生僻词出现次数较少时， 这种多次的调整会使得词向量相对的更加准确，但是训练时间也要有所增长。</p>\n<p><img src=\"https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FphEkS%2FbtqXSoISyn9%2FeI2vpCZ8svhF7X4U3JCTx0%2Fimg.png\" style=\"zoom:70%;\"></p>\n<ul>\n<li><p><strong>GloVe</strong></p>\n<p>我们可以看到Word2Vec仅仅注意到了文本的局部上下文特征，而忽略了全局的文本信息，GloVe在此之上对其做出了改进。GloVe从基于SVD的LSA算法出发，首先要通过滑动窗口计算出共现矩阵。我们知道单词的词向量学习应该跟词共现概率的比率有关，而不是他们的概率本身作者发现用共现概率比也可以很好的体现3个单词间的关联(因为共现概率比符合常理)，所以作者大胆猜想，如果能将3个单词的词向量经过某种计算可以表达共现概率比，那么这样的词向量就与共现矩阵有着一致性，可以体现词间的关系。</p>\n<ul>\n<li><strong>主要优化目标:</strong>     <script type=\"math/tex\">J = \\sum_{ij}^{V}f(X_{ij})(v_i^T\\hat{v_j}+b_i + \\hat{b_j}-log(X_{ij}))^2</script></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"循环神经网络-Recurrent-Neural-Network\"><a href=\"#循环神经网络-Recurrent-Neural-Network\" class=\"headerlink\" title=\"循环神经网络 (Recurrent Neural Network)\"></a>循环神经网络 (Recurrent Neural Network)</h3><ul>\n<li><strong>普通RNN</strong></li>\n</ul>\n<p>​    循环神经网络即RNN，其结构设计基于输入序列和上一级状态对当前隐藏状态进行更新，即可以表示为 $p(y<em>t)=g(y</em>{t-1},h_t)$，能够比较好的处理序列内容，因此被广泛的应用于NLP领域。但是我们知道，对于普通的RNN来说一旦序列变长，会导致比较明显的网络退化问题，即梯度消失和梯度爆炸难以避免。</p>\n<ul>\n<li><p><strong>LSTM</strong> （Long short-term memory）</p>\n<p>​    为了解决上述问题，就有了LSTM的出现，即添加了一个全局的信息传递通道 $c_t$ ，通过 $sigmoid$ 作为门控来对上一个节点传入的输入进行选择性忘记，对全局状态进行少量改变。进而再进入输入阶段，对输入通过 $sigmoid$ 来做门控选择记忆，以及最后的输出隐层。内部使用 $tanh$ 作为激活函。通过添加全局记忆流的方式很好的避免了梯度消失问题，使得模型拥有更加长期的记忆能力。</p>\n<p>​    但缺点就是模型比RNN复杂了不少，收敛起来速度更慢。</p>\n</li>\n<li><p><strong>GRU</strong> （Gate Recurrent Unit）</p>\n<p>为了解决LSTM训练收敛速度慢的问题，学界又引入了GRU，与LSTM相比，GRU内部少了一个门控即更新门和重置门，参数比LSTM少，在很大程度上提高训练效率。重置门越小代表前一状态被丢弃信息越多，更新门越大代表前一时刻带入信息越多。同时GRU在并不控制和保留内部记忆$c_t$ ，但从设计上能够达到LSTM同样的避免梯度消失的效果。</p>\n</li>\n</ul>\n<p><img src=\"https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-07-03-lstm-gru.png\" style=\"zoom:80%;\"></p>\n<h3 id=\"Transformer\"><a href=\"#Transformer\" class=\"headerlink\" title=\"Transformer\"></a>Transformer</h3><p>​    近年来的研究热点一直是在Transformer上，自从谷歌2017年在Attention is all you need一文中提出Transformer模型，其通过内部编码器解码器结构结合多头注意力机制 $QKV$，能够并行的注意到不同单元的特征信息，从而打破了RNN的网络退化训练难题，以BERT为代表的BERT家族模型目前一直是NLP研究的前沿热点模型，因为字数限制在此就不过多介绍。</p>\n<div style=\"page-break-after: always;\"></div>\n\n<h2 id=\"2-实验内容\"><a href=\"#2-实验内容\" class=\"headerlink\" title=\"2. 实验内容\"></a>2. 实验内容</h2><h3 id=\"2-1-基于RNN及其变体的分类器\"><a href=\"#2-1-基于RNN及其变体的分类器\" class=\"headerlink\" title=\"2.1 基于RNN及其变体的分类器\"></a>2.1 基于RNN及其变体的分类器</h3><p>我首先在RNN系列模型上进行了一系列实验，采用统一参数，并且拿出最后一层的输出，做 <em>drop_out</em> 后通过一个全连接层得到最后的输出，同时全开bidirection。</p>\n<p>​    同时在对比RNN分类器的实验过程中发现，在没有添加 <em>pretrain</em> 的 word_embedding，即使用随机初始化的 embedding 进行训练能够更加明显的对比出不同模型的效果。</p>\n<ul>\n<li><strong>模型主体</strong></li>\n</ul>\n<pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">forward</span>(<span class=\"hljs-params\">self, x</span>):</span>\n        batch_size, seq_len = x.size()\n        x = self.embed_dropout(self.embeddings(x))\n        out, _ = self.rnn(x)\n        out = out.view(batch_size, seq_len, self.num_labels, self.hidden_size)\n        out = torch.cat([out[:, <span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">0</span>, :], out[:, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>, :]], dim=<span class=\"hljs-number\">-1</span>)\n        out = self.dropout(out)\n        logits = self.fc(out)\n        <span class=\"hljs-keyword\">return</span> logits</code></pre>\n<ul>\n<li><strong>模型参数及超参数</strong></li>\n</ul>\n<pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">embed_dim:</span> <span class=\"hljs-number\">300</span> \t<span class=\"hljs-comment\"># 嵌入维度</span>\n<span class=\"hljs-attr\">hidden_size:</span> <span class=\"hljs-number\">512</span>  <span class=\"hljs-comment\"># 隐藏层维度</span>\n<span class=\"hljs-attr\">num_labels:</span> <span class=\"hljs-number\">2</span>  <span class=\"hljs-comment\"># 标签数</span>\n<span class=\"hljs-attr\">num_layers:</span> <span class=\"hljs-number\">2</span>  <span class=\"hljs-comment\"># 层数</span>\n<span class=\"hljs-attr\">dropout:</span> <span class=\"hljs-number\">0.5</span>  <span class=\"hljs-comment\"># 全连接层 drop out</span>\n<span class=\"hljs-attr\">embed_dropout:</span> <span class=\"hljs-number\">0.5</span>  <span class=\"hljs-comment\"># 嵌入层 drop out</span>\n<span class=\"hljs-attr\">WORD_EMBEDDING:</span> <span class=\"hljs-string\">Random</span> <span class=\"hljs-comment\"># 初始对比不加 Word Embedding 效果更加明显</span></code></pre>\n<pre><code class=\"hljs yaml\"><span class=\"hljs-comment\"># 超参数</span>\n<span class=\"hljs-attr\">EPOCH:</span> <span class=\"hljs-number\">30</span>\n<span class=\"hljs-attr\">BATCH_SIZE:</span> <span class=\"hljs-number\">64</span>\n<span class=\"hljs-attr\">OPTIMIZER:</span> <span class=\"hljs-comment\"># 优化器</span>\n  <span class=\"hljs-attr\">NAME:</span> <span class=\"hljs-string\">AdamW</span>\n  <span class=\"hljs-attr\">ARGS:</span>\n    <span class=\"hljs-attr\">lr:</span> <span class=\"hljs-number\">6.0e-5</span>\n    <span class=\"hljs-attr\">eps:</span> <span class=\"hljs-number\">1.0e-6</span>\n<span class=\"hljs-attr\">SCHEDULER:</span> <span class=\"hljs-comment\"># 无LR调节</span>\n  <span class=\"hljs-attr\">NAME:</span> <span class=\"hljs-literal\">null</span></code></pre>\n<h4 id=\"2-1-0-Preprocess\"><a href=\"#2-1-0-Preprocess\" class=\"headerlink\" title=\"2.1.0 Preprocess\"></a>2.1.0 Preprocess</h4><p>在前处理过程中，滤除了语料库当中的非字母符号，对字母进行全小写化。（尝试滤除stop word但其因为会改变很多语义信息，从而最后并未采纳）</p>\n<pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">preprocess_data</span>(<span class=\"hljs-params\">lines</span>):</span>\n    formatted_lines = []\n    <span class=\"hljs-keyword\">for</span> line <span class=\"hljs-keyword\">in</span> lines:\n        <span class=\"hljs-comment\"># split into tokens by white space</span>\n        tokens = line.split()\n        <span class=\"hljs-comment\"># remove punctuation from each token and convert to lowercase</span>\n        table = <span class=\"hljs-built_in\">str</span>.maketrans(<span class=\"hljs-string\">&#x27;&#x27;</span>, <span class=\"hljs-string\">&#x27;&#x27;</span>, string.punctuation)\n        tokens = [w.translate(table).lower() <span class=\"hljs-keyword\">for</span> w <span class=\"hljs-keyword\">in</span> tokens]\n        <span class=\"hljs-comment\"># remove remaining tokens that are not alphabetic</span>\n        tokens = [word <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> tokens <span class=\"hljs-keyword\">if</span> word.isalpha()]\n        <span class=\"hljs-comment\"># join the new tokens to form the formatted sentence</span>\n        sentence = <span class=\"hljs-string\">&quot; &quot;</span>.join(tokens)\n        formatted_lines.append(sentence)\n    <span class=\"hljs-keyword\">return</span> formatted_lines</code></pre>\n<h4 id=\"2-1-1-RNN\"><a href=\"#2-1-1-RNN\" class=\"headerlink\" title=\"2.1.1 RNN\"></a>2.1.1 RNN</h4><p>RNN 在随机初始化的 Word Embedding 上表现较差，在Val上最高的准确率达到 65.30%，后期过拟合现象较为严重。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdqmwrpcbj30t60cp3za.jpg\" style=\"zoom:60%;\"></p>\n<h4 id=\"2-1-2-LSTM\"><a href=\"#2-1-2-LSTM\" class=\"headerlink\" title=\"2.1.2 LSTM\"></a>2.1.2 LSTM</h4><p>LSTM 则表现较好，最高在Val上的准确率达到 72.84%，同时由于网络表达能力增强，其过拟合现象比RNN更加严重。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdqpqi5uhj30ya0dnt9n.jpg\" style=\"zoom:50%;\"></p>\n<h4 id=\"2-1-3-GRU\"><a href=\"#2-1-3-GRU\" class=\"headerlink\" title=\"2.1.3 GRU\"></a>2.1.3 GRU</h4><p>GRU 同样表现不错，在Val上的准确率最高达到 71.57%, 稍微弱于LSTM，但是其收敛速度快于LSTM</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdqsaqauoj30st0dl0tk.jpg\" style=\"zoom:60%;\"></p>\n<h4 id=\"2-1-4-小结\"><a href=\"#2-1-4-小结\" class=\"headerlink\" title=\"2.1.4 小结\"></a>2.1.4 小结</h4><p>​    实验中我们可以看到，单论模型性能 <em>LSTM</em> 是表现最好的网络，<em>GRU</em> 作为 <em>LSTM</em> 的改进版，能够更快的拟合并获得接近 <em>LSTM</em> 的效果，而 <em>RNN</em> 则由于梯度消失导致的网络退化问题，难以很好的拟合，梯度爆炸导致训练不稳定，性能较差。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">模型</th>\n<th style=\"text-align:center\">准确率 / %</th>\n<th style=\"text-align:center\">Epoch / n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">RNN</td>\n<td style=\"text-align:center\">65.30</td>\n<td style=\"text-align:center\">16</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LSTM</td>\n<td style=\"text-align:center\">72.84</td>\n<td style=\"text-align:center\">13</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">GRU</td>\n<td style=\"text-align:center\">71.57</td>\n<td style=\"text-align:center\">12</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>在实验过程中我们不难得出以下结论</p>\n<p><strong>模型性能上：</strong> $LSTM &gt; GRU &gt; RNN$</p>\n<div style=\"page-break-after: always;\"></div>\n\n<p><strong>收敛速度上：</strong> $GRU&gt;LSTM&gt;RNN$</p>\n<ul>\n<li><p><strong>过拟合</strong></p>\n<p>同时在实验过程中我们很容易观察到，在训练后期模型都不同程度的出现了过拟合现象，这里我们在embedding和fc层都添加了0.5的drop_out，如果不添加的话过拟合现象则会更加研究 (详见后文的ablation study)，我们可以使用 early stop 方法简单的早停止训练来防止过拟合现象发生。我们可以看到三个模型在 15 个 Epoch 左右都达到了其最佳性能，所以我们可以将最大 Epoch 设为 15 来防止后期的过拟合现象发生。</p>\n</li>\n</ul>\n<h4 id=\"2-1-5-进一步分析\"><a href=\"#2-1-5-进一步分析\" class=\"headerlink\" title=\"2.1.5 进一步分析\"></a>2.1.5 进一步分析</h4><p>我们还可以继续计算模型的查准率 (Precision), 召回率 (Recall) , F1 score</p>\n<script type=\"math/tex; mode=display\">\nPrecison = \\frac{TP}{TP+FP}\\\\\\\\\nRecall = \\frac{TP}{TP+FN}\\\\\\\\\nF_1 = \\frac{2*Precision*Recall}{Precision + Recall}</script><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwehwkiqjlj30sp0azwf1.jpg\" style=\"zoom:50%;\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwehsbzj9oj30fp07l74j.jpg\" style=\"zoom:80%;\"></p>\n<ul>\n<li><p><strong>关于查准率和召回率</strong></p>\n<p>从图中我们不难看出，模型的查准率和召回率互为拮抗，查准率上升的时候召回率一般会下降，为了平衡衡量这两者来公平衡量二分类模型的准确率，我们可以使用F1 Score</p>\n</li>\n<li><p><strong>F1 Score</strong></p>\n<p>​    F1 score作为兼顾了分类模型的准确率和召回率。F1分数可以看作是模型查准率和召回率的一种加权平均，形式表现为查准率和召回率的调和平均。</p>\n</li>\n</ul>\n<div style=\"page-break-after: always;\"></div>\n\n<h3 id=\"2-3-比较不同的-Word-Embedding-方式\"><a href=\"#2-3-比较不同的-Word-Embedding-方式\" class=\"headerlink\" title=\"2.3 比较不同的 Word Embedding 方式\"></a>2.3 比较不同的 Word Embedding 方式</h3><p>​    在上述实验的基础上，我选用 LSTM 来进行进一步的实验，为LSTM添加不同的 pretrain 的 Word_Embedding 参数来查看 Word_Embedding 对网络准确率的影响。</p>\n<h4 id=\"2-3-1-Word2Vec\"><a href=\"#2-3-1-Word2Vec\" class=\"headerlink\" title=\"2.3.1 Word2Vec\"></a>2.3.1 Word2Vec</h4><p>​    首先实验的是Word2Vec, 这里我选用的是 <code>GoogleNews-vectors-negative300</code></p>\n<pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">WORD_EMBEDDING:</span> \n  <span class=\"hljs-attr\">NAME:</span> <span class=\"hljs-string\">Word2Vec</span> <span class=\"hljs-comment\"># Word2Vec, GloVe, None</span>\n  <span class=\"hljs-attr\">PATH:</span> <span class=\"hljs-string\">Gensim/GoogleNews-vectors-negative300.bin</span></code></pre>\n<pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">load_word2vec</span>(<span class=\"hljs-params\">text_field, PATH</span>):</span>\n    word_to_idx = text_field.vocab.stoi\n    pretrained_embeddings = np.random.uniform(<span class=\"hljs-number\">-0.25</span>, <span class=\"hljs-number\">0.25</span>, (<span class=\"hljs-built_in\">len</span>(text_field.vocab), <span class=\"hljs-number\">300</span>))\n    pretrained_embeddings[<span class=\"hljs-number\">0</span>] = <span class=\"hljs-number\">0</span>\n    word2vec = load_bin_vec(PATH, word_to_idx)\n    <span class=\"hljs-keyword\">for</span> word, vector <span class=\"hljs-keyword\">in</span> word2vec.items():\n        pretrained_embeddings[word_to_idx[word]<span class=\"hljs-number\">-1</span>] = vector\n\n    <span class=\"hljs-keyword\">return</span> pretrained_embeddings</code></pre>\n<p>​    使用预训练的参数替换模型中的 embeddings 层的初始值，其余训练参数和超参均同上，进行公平对比。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdr76zpusj30sq0dkaau.jpg\" style=\"zoom:60%;\"></p>\n<p>可以看到，预训练的词嵌入非常好的指导网络在情感分类任务上的训练拟合，拟合速度和准确率相比随机初始化的参数都有较大幅度的提升，仅在第7个epoch就得到了最好性能。</p>\n<div style=\"page-break-after: always;\"></div>\n\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">模型</th>\n<th style=\"text-align:center\">准确率 / %</th>\n<th style=\"text-align:center\">Epoch / n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">LSTM-Random</td>\n<td style=\"text-align:center\">72.84</td>\n<td style=\"text-align:center\">13</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LSTM-Word2Vec</td>\n<td style=\"text-align:center\">75.11</td>\n<td style=\"text-align:center\">7</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h4 id=\"2-3-2-GloVe\"><a href=\"#2-3-2-GloVe\" class=\"headerlink\" title=\"2.3.2 GloVe\"></a>2.3.2 GloVe</h4><p>​    我们换上比Word2Vec更加具有全局信息的GloVe嵌入，这里采用的是 <code>glove.840B.300d</code></p>\n<pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">WORD_EMBEDDING:</span> \n  <span class=\"hljs-attr\">NAME:</span> <span class=\"hljs-string\">GloVe</span> <span class=\"hljs-comment\"># Word2Vec, GloVe, None</span>\n  <span class=\"hljs-attr\">PATH:</span> <span class=\"hljs-string\">&#x27;glove.840B.300d&#x27;</span></code></pre>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdrc8z2jqj30sn0dnaat.jpg\" style=\"zoom:60%;\"></p>\n<p>GloVe 的词嵌入比 Word2Vec 达到了更好的性能，在Val上达到了79.2%的准确率，可以看到预训练的词嵌入对模型性能的提升有非常大的效果</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdtwdj6awj30xh0e10u5.jpg\" alt=\"image-20211113211031902\" style=\"zoom:55%;\"></p>\n<div style=\"page-break-after: always;\"></div>\n\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">模型</th>\n<th style=\"text-align:center\">准确率 / %</th>\n<th style=\"text-align:center\">Epoch / n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">LSTM-Random</td>\n<td style=\"text-align:center\">72.84</td>\n<td style=\"text-align:center\">13</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LSTM-Word2Vec</td>\n<td style=\"text-align:center\">75.11</td>\n<td style=\"text-align:center\">7</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LSTM-GloVe</td>\n<td style=\"text-align:center\">79.2</td>\n<td style=\"text-align:center\">8</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h4 id=\"2-3-4-总结\"><a href=\"#2-3-4-总结\" class=\"headerlink\" title=\"2.3.4 总结\"></a>2.3.4 总结</h4><p>​    可以看到预训练的词嵌入能够非常大的提升模型的性能，让模型更好的抓住句子和词之间的联系，抽取句子的语义信息。对情感分类问题有着较大的帮助。</p>\n<h3 id=\"2-4-基于CNN的分类器\"><a href=\"#2-4-基于CNN的分类器\" class=\"headerlink\" title=\"2.4 基于CNN的分类器\"></a>2.4 基于CNN的分类器</h3><p>​    对于词嵌入向量，我们也可以使用CNN对其进行操作，通过卷积核来提取局部特征，并融合全局视野，不过相比RNN的模型结构。CNN的方式对语言问题少了一些先验的序列化模式，因此收敛速度要明显慢于RNN。</p>\n<p>为和RNN对比，使用了统一参数。卷积核采用 $3 \\times embed_dim$ 大小，同时随机初始化 Word_embedding</p>\n<pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">CNN</span>(<span class=\"hljs-params\">nn.Module</span>):</span>\n  ....\n   self.conv_layers = nn.ModuleList([nn.Conv2d(in_channels=<span class=\"hljs-number\">1</span>,\n                                     out_channels=hidden_size,\n                                     kernel_size=(kernel_size, embed_dim))]*num_layers)\n  ....</code></pre>\n<h4 id=\"2-4-1-实验结果\"><a href=\"#2-4-1-实验结果\" class=\"headerlink\" title=\"2.4.1 实验结果\"></a>2.4.1 实验结果</h4><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdrjpqd2yj30so0dvdgn.jpg\" style=\"zoom:55%;\"></p>\n<div style=\"page-break-after: always;\"></div>\n\n<p>​    可以看到CNN的拟合速度明显慢于基于RNN的分类器，担其效果不输LSTM甚至略微优于LSTM，在最后一个 Epoch 甚至达到了 73.48% 的准确率，如果继续训练可能会达到更高的准确率，但为了公平对比，因此不再扩大 Epoch 数。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">模型</th>\n<th style=\"text-align:center\">准确率 / %</th>\n<th style=\"text-align:center\">Epoch / n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">RNN</td>\n<td style=\"text-align:center\">65.30</td>\n<td style=\"text-align:center\">16</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LSTM</td>\n<td style=\"text-align:center\">72.84</td>\n<td style=\"text-align:center\">13</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">GRU</td>\n<td style=\"text-align:center\">71.57</td>\n<td style=\"text-align:center\">12</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">CNN</td>\n<td style=\"text-align:center\">73.48</td>\n<td style=\"text-align:center\">30</td>\n</tr>\n</tbody>\n</table>\n</div>\n<div style=\"page-break-after: always;\"></div>\n\n<h3 id=\"2-5-基于BERT及其变体的分类器（Transformer）\"><a href=\"#2-5-基于BERT及其变体的分类器（Transformer）\" class=\"headerlink\" title=\"2.5 基于BERT及其变体的分类器（Transformer）\"></a>2.5 基于BERT及其变体的分类器（Transformer）</h3><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwds81vpfuj30fe0ndwg2.jpg\" style=\"zoom:60%;\"></p>\n<h4 id=\"2-5-1-BERT\"><a href=\"#2-5-1-BERT\" class=\"headerlink\" title=\"2.5.1 BERT\"></a>2.5.1 BERT</h4><p>​    BERT全名即 <em>Bidirectional Encoder Representations from Transformers</em> 即从模型思路上使用了 Transformer 的 Encoder 部分，来对输入词向量做 Self Attention，但其比普通 Transformer 的 Encoder 更深更窄，BERT-base 有 12 个 encoder 模块，hidden-size 是 768。</p>\n<ul>\n<li><p><strong>预训练任务</strong></p>\n<p>BERT出彩的地方是其预训练部分做的很好，除了之前所说的普通Word Embedding方式使用的 <strong>Masked LM</strong> 即遮挡预测以外，BERT还引入了下一句预测的预训练模式 <strong>Next Sentence Prediction</strong>，让模型能够更好的理解句子之间的关系</p>\n</li>\n<li><p><strong>实验方法</strong></p>\n<p>采用载入预训练的BERT checkpoint 再在下游 SST-2 数据集上进行 fine-tune 的方式进行训练</p>\n</li>\n</ul>\n<div style=\"page-break-after: always;\"></div>\n\n<ul>\n<li><strong>实验参数</strong></li>\n</ul>\n<pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">MODEL:</span>\n  <span class=\"hljs-attr\">NAME:</span> <span class=\"hljs-string\">BERT</span> <span class=\"hljs-comment\"># RNN, LSTM, GRU, CNN, BERT</span>\n  <span class=\"hljs-attr\">ARGS:</span>\n    <span class=\"hljs-attr\">model_type:</span> <span class=\"hljs-string\">bert-base-uncased</span> <span class=\"hljs-comment\"># bert-base-uncased, bert-large-uncased</span>\n    <span class=\"hljs-attr\">dropout:</span> <span class=\"hljs-number\">0.5</span>\n<span class=\"hljs-attr\">OPTIMIZER:</span> \n  <span class=\"hljs-attr\">NAME:</span> <span class=\"hljs-string\">AdamW</span>\n  <span class=\"hljs-attr\">ARGS:</span>\n    <span class=\"hljs-attr\">lr:</span> <span class=\"hljs-number\">2.0e-5</span>\n    <span class=\"hljs-attr\">eps:</span> <span class=\"hljs-number\">1.0e-8</span></code></pre>\n<pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 采用 linear_schedule_with_warmup</span>\nscheduler = get_linear_schedule_with_warmup(\n   optimizer=optimizer,\n   num_warmup_steps=<span class=\"hljs-number\">0</span>,\n   num_training_steps=num_training_steps\n)</code></pre>\n<ul>\n<li><strong>实验结果</strong></li>\n</ul>\n<p>我个人分别在 BERT-base-uncased 和 BERT-large-uncased 上进行了训练</p>\n<ul>\n<li><strong>BERT-base-uncased</strong></li>\n</ul>\n<p><strong>参数信息：</strong> 12-layer, 768-hidden, 12-heads, 110M parameters</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdsttr9sbj30s90cr750.jpg\" style=\"zoom:60%;\"></p>\n<div style=\"page-break-after: always;\"></div>\n\n<ul>\n<li><strong>BERT-large-uncased</strong></li>\n</ul>\n<p><strong>参数信息：</strong> 24-layer, 1024-hidden, 16-heads, 336M parameters</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdsnvaegsj30sn0cqt9f.jpg\" style=\"zoom:60%;\"></p>\n<ul>\n<li><strong>总结</strong></li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">模型</th>\n<th style=\"text-align:center\">准确率 / %</th>\n<th style=\"text-align:center\">Epoch / n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">BERT-base-uncased</td>\n<td style=\"text-align:center\">86.97</td>\n<td style=\"text-align:center\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">BERT-large-uncased</td>\n<td style=\"text-align:center\">88.65</td>\n<td style=\"text-align:center\">2</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以看到 BERT-large 性能好于 BERT-base 能够达到极高的 88.65% 同时由于参数量的提升，收敛上页略慢于BERT-base，在第2个epoch达到最佳性能。</p>\n<h4 id=\"2-5-4-其他BERT变种\"><a href=\"#2-5-4-其他BERT变种\" class=\"headerlink\" title=\"2.5.4 其他BERT变种\"></a>2.5.4 其他BERT变种</h4><p>​    我继续使用测试了其他 BERT 变种例如 RoBERTa，以及AlBERT来进一步提升模型的准确率，经过实验发现 RoBERTa-large的准确率可以达到90%左右，而最好的准确率是使用 AlBERT-xxlarge 上可以在 Val 上达到 91%的准确率。</p>\n<ul>\n<li><strong>训练参数设置：</strong></li>\n</ul>\n<pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">Scheduler:</span> <span class=\"hljs-string\">warmup_cosine</span>\n<span class=\"hljs-attr\">Optimizer:</span> <span class=\"hljs-string\">AdamW</span>\n<span class=\"hljs-attr\">LR:</span> <span class=\"hljs-number\">1e-5</span>\n<span class=\"hljs-attr\">Epoch:</span> <span class=\"hljs-number\">5</span>\n<span class=\"hljs-attr\">BatchSize:</span> <span class=\"hljs-number\">8</span></code></pre>\n<div style=\"page-break-after: always;\"></div>\n\n<ul>\n<li><strong>AlBERT-xxlarge-v2</strong></li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdszgffm2j30xg0dijsa.jpg\" style=\"zoom:60%;\"></p>\n<p>​    准确率最高达到 91.01%，可以看到模型在大约第3个epoch达到最佳性能，后开始过拟合。为此我使用early stop，训练3个epoch</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwefzu7y82j30wt0dfgmh.jpg\" style=\"zoom:60%;\"></p>\n<p>​    模型准确率最高达到91.46%</p>\n<div style=\"page-break-after: always;\"></div>\n\n<h3 id=\"2-6-训练方法对模型性能的影响\"><a href=\"#2-6-训练方法对模型性能的影响\" class=\"headerlink\" title=\"2.6 训练方法对模型性能的影响\"></a>2.6 训练方法对模型性能的影响</h3><h4 id=\"2-3-2-改变BatchSize\"><a href=\"#2-3-2-改变BatchSize\" class=\"headerlink\" title=\"2.3.2 改变BatchSize\"></a>2.3.2 改变BatchSize</h4><p>​    Batch Size 对模型的准确性没有很大的影响，但在小batch的情况下有可能导致训练不稳定，iter之间的loss差距较大。</p>\n<p>​    同时更大的Batch Size能够加快训练速度，更好的在全数据集上拟合，但这也不是说越大越好。过大的batch size可能会导致batch之间梯度变化过小，模型泛化能力缺失。同时也要注意自己使用的是什么Optimizer，如果是SGD优化器，batch size和learning rate之间成线性关系，在更改batch size的时候需要注意更改学习率。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdu5o0h46j30sp0cijsn.jpg\" style=\"zoom:60%;\"></p>\n<h4 id=\"2-3-4-改变Drop-Out\"><a href=\"#2-3-4-改变Drop-Out\" class=\"headerlink\" title=\"2.3.4 改变Drop Out\"></a>2.3.4 改变Drop Out</h4><p>​    drop out 对网络过拟合现象有比较大的影响，如果drop out过小网络表达能力过强且集中于几个特定神经元上，导致训练很快拟合到训练集上，从而导致模型泛化能力变差，性能减弱。这里我测试了三种drop_out的大小，分别是0.5, 0.2, 0</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwehhhqij9j30nj0cw3zm.jpg\" style=\"zoom:60%;\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwehla48ruj30nh0cpt9h.jpg\" style=\"zoom:60%;\"></p>\n<p>可以看到网络在 drop out = 0.5 的时候性能最好。在 drop out = 0 的时候过拟合非常严重，性能最差。但因为drop out比较大，拟合上相比0.2和0速度更慢。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwehdm8dyvj30g909f3zc.jpg\" style=\"zoom:67%;\"></p>\n<p>​    在限制 drop out 为0.5时，其eval上的loss最小，而train上的loss最大，eval和train上的准确率增长较为同步。且过拟合现象最不严重，相比之下，drop out=0 时，过拟合现象十分严重，测试集上loss很大。</p>\n<ul>\n<li><strong>关于Drop out</strong></li>\n</ul>\n<p>不得不提，如果drop out过大网络的表达能力会被损害，如果drop_out = 1相当于网络中这一层上所有激活全被 drop 掉，网络就无法输出信息了。因此选用合适的drop out十分重要</p>\n<div style=\"page-break-after: always;\"></div>\n\n<h2 id=\"3-总结\"><a href=\"#3-总结\" class=\"headerlink\" title=\"3.总结\"></a>3.总结</h2><p>​    在本次实验中，对比了不同的模型在情感分类任务上的性能，探索了不同Word Embedding对模型性能的影响，比较了不同训练方法对模型的影响。基本了解并探索了NLP的基本任务和实验流程。得到如下实验结果</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">模型</th>\n<th style=\"text-align:center\">准确率 / %</th>\n<th style=\"text-align:center\">Epoch / n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">RNN</td>\n<td style=\"text-align:center\">65.30</td>\n<td style=\"text-align:center\">16</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LSTM</td>\n<td style=\"text-align:center\">72.84</td>\n<td style=\"text-align:center\">13</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">GRU</td>\n<td style=\"text-align:center\">71.57</td>\n<td style=\"text-align:center\">12</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">CNN</td>\n<td style=\"text-align:center\">73.48</td>\n<td style=\"text-align:center\">30</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LSTM-Word2Vec</td>\n<td style=\"text-align:center\">75.11</td>\n<td style=\"text-align:center\">7</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LSTM-GloVe</td>\n<td style=\"text-align:center\">79.2</td>\n<td style=\"text-align:center\">8</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">BERT-base-uncased</td>\n<td style=\"text-align:center\">86.97</td>\n<td style=\"text-align:center\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">BERT-large-uncased</td>\n<td style=\"text-align:center\">88.65</td>\n<td style=\"text-align:center\">2</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">RoBERTa-large</td>\n<td style=\"text-align:center\">90.02</td>\n<td style=\"text-align:center\">3</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">AlBERT-xxlarge-v2</td>\n<td style=\"text-align:center\">91.46</td>\n<td style=\"text-align:center\">3</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h4 id=\"3-1-进一步实验方向\"><a href=\"#3-1-进一步实验方向\" class=\"headerlink\" title=\"3.1 进一步实验方向\"></a>3.1 进一步实验方向</h4><ul>\n<li><p><strong>蒸馏学习</strong></p>\n<p>可以通过高准确率的模型例如BERT给低准确率的模型例如LSTM进行蒸馏，在训练过程中增加一个loss进行指导训练，来进一步提升小模型的准确率。这在实际工业场景中有很大的应用场景</p>\n<script type=\"math/tex; mode=display\">\nloss = \\alpha CrossEntropy(pred, true) + (1-\\alpha) MSEloss(pred, bert\\_true)</script></li>\n<li><p><strong>多模型ensemble</strong></p>\n<p>可以采用多模型 ensemble 的方式进一步提升模型的准确率，即训练多个不同的模型，或即使是相同模型进行不同初始化的结果，最后做简单的投票。这种ensemble方式能够进一步提升模型的性能，目前广泛应用于对及时性要求较少的场景和各大算法竞赛当中（例如Kaggle）</p>\n</li>\n</ul>\n<div style=\"page-break-after: always;\"></div>\n\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>[1] Ralf C. Staudemeyer, &amp; Eric Rothstein Morris. (2019). Understanding LSTM – a tutorial into Long Short-Term Memory Recurrent Neural Networks.</p>\n<p>[2] Sherstinsky, A. (2020). Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) network<em>. Physica D: Nonlinear Phenomena, \\</em>404*, 132306.</p>\n<p>[3] Jacob Devlin, Ming-Wei Chang, Kenton Lee, &amp; Kristina Toutanova. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.</p>\n<p>[4] Victor Sanh, Lysandre Debut, Julien Chaumond, &amp; Thomas Wolf. (2020). DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter.</p>\n<p>[5] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, &amp; Veselin Stoyanov. (2019). RoBERTa: A Robustly Optimized BERT Pretraining Approach.</p>\n<p>[6] Dang, N., Moreno-García, M., &amp; Prieta, F. (2020). Sentiment Analysis Based on Deep Learning: A Comparative Study<em>. Electronics, \\</em>9*(3), 483.</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"NLP-PJ-1-基于深度学习的文本分类\"><a href=\"#NLP-PJ-1-基于深度学习的文本分类\" class=\"headerlink\" title=\"NLP PJ-1 基于深度学习的文本分类\"></a>NLP PJ-1 基于深度学习的文本分类</h1><h2 id=\"1-背景介绍\"><a href=\"#1-背景介绍\" class=\"headerlink\" title=\"1. 背景介绍\"></a>1. 背景介绍</h2><h3 id=\"情感分类任务-Sentiment-Classification\"><a href=\"#情感分类任务-Sentiment-Classification\" class=\"headerlink\" title=\"情感分类任务 (Sentiment Classification)\"></a>情感分类任务 (Sentiment Classification)</h3><p>​    文本情感分类任务是NLP众多下游任务的一种，通过深度学习模型来提取文本情感特征来达到对文本情感类型进行分类的目的。其可以是复杂的判别情感极性的多标签分类任务或是回归任务。我们这里是简单的二分类任务，即给定影评文本，确定其评论是积极 (positive) 还是消极 (negative)</p>\n<h3 id=\"词嵌入-Word-Embedding\"><a href=\"#词嵌入-Word-Embedding\" class=\"headerlink\" title=\"词嵌入 (Word Embedding)\"></a>词嵌入 (Word Embedding)</h3><p>​    我们知道传统的词向量one-hot表示法虽然能够将词进行向量化，但是没办法很好的表示两个含义相近的词在空间当中的距离。同时在语料库很大的情况下，one-hot向量会变得非常稀疏且维度极高，非常不利于计算。为此我们引入了词嵌入的方法来对词向量进行降维，将词映射到一个相对于词数量较小的高维空间中。一个好的词嵌入应当能够反映不同的词语之间的联系，例如“猫”，“狗”两个词对应的词向量就应当比“猫”，“水杯”两个词对应的词向量距离更近。现在主流的词嵌入方法主要有两种，一种是托马斯·米科洛维的Word2Vec，以及斯坦福大学提出的GloVe</p>\n<ul>\n<li><p><strong>Word2Vec</strong></p>\n<p>Word2Vec是在整个语料库上进行预训练，通过相邻的词的词向量预测中心词的词向量  (<em>CBOW</em>)，或通过中心词的词向量预测相邻词的词向量 (<em>Skip-gram</em>) 两种方式，对于语料库中的词来做词嵌入。</p>\n</li>\n</ul>\n<p>​    相比CBOW在skip-gram当中，每个词都要收到周围的词的影响，每个词在作为中心词的时候，都要进行K次的预测、调整。因此当数据量较少，或者词为生僻词出现次数较少时， 这种多次的调整会使得词向量相对的更加准确，但是训练时间也要有所增长。</p>\n<p><img src=\"https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FphEkS%2FbtqXSoISyn9%2FeI2vpCZ8svhF7X4U3JCTx0%2Fimg.png\" style=\"zoom:70%;\"></p>\n<ul>\n<li><p><strong>GloVe</strong></p>\n<p>我们可以看到Word2Vec仅仅注意到了文本的局部上下文特征，而忽略了全局的文本信息，GloVe在此之上对其做出了改进。GloVe从基于SVD的LSA算法出发，首先要通过滑动窗口计算出共现矩阵。我们知道单词的词向量学习应该跟词共现概率的比率有关，而不是他们的概率本身作者发现用共现概率比也可以很好的体现3个单词间的关联(因为共现概率比符合常理)，所以作者大胆猜想，如果能将3个单词的词向量经过某种计算可以表达共现概率比，那么这样的词向量就与共现矩阵有着一致性，可以体现词间的关系。</p>\n<ul>\n<li><strong>主要优化目标:</strong>     <script type=\"math/tex\">J = \\sum_{ij}^{V}f(X_{ij})(v_i^T\\hat{v_j}+b_i + \\hat{b_j}-log(X_{ij}))^2</script></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"循环神经网络-Recurrent-Neural-Network\"><a href=\"#循环神经网络-Recurrent-Neural-Network\" class=\"headerlink\" title=\"循环神经网络 (Recurrent Neural Network)\"></a>循环神经网络 (Recurrent Neural Network)</h3><ul>\n<li><strong>普通RNN</strong></li>\n</ul>\n<p>​    循环神经网络即RNN，其结构设计基于输入序列和上一级状态对当前隐藏状态进行更新，即可以表示为 $p(y<em>t)=g(y</em>{t-1},h_t)$，能够比较好的处理序列内容，因此被广泛的应用于NLP领域。但是我们知道，对于普通的RNN来说一旦序列变长，会导致比较明显的网络退化问题，即梯度消失和梯度爆炸难以避免。</p>\n<ul>\n<li><p><strong>LSTM</strong> （Long short-term memory）</p>\n<p>​    为了解决上述问题，就有了LSTM的出现，即添加了一个全局的信息传递通道 $c_t$ ，通过 $sigmoid$ 作为门控来对上一个节点传入的输入进行选择性忘记，对全局状态进行少量改变。进而再进入输入阶段，对输入通过 $sigmoid$ 来做门控选择记忆，以及最后的输出隐层。内部使用 $tanh$ 作为激活函。通过添加全局记忆流的方式很好的避免了梯度消失问题，使得模型拥有更加长期的记忆能力。</p>\n<p>​    但缺点就是模型比RNN复杂了不少，收敛起来速度更慢。</p>\n</li>\n<li><p><strong>GRU</strong> （Gate Recurrent Unit）</p>\n<p>为了解决LSTM训练收敛速度慢的问题，学界又引入了GRU，与LSTM相比，GRU内部少了一个门控即更新门和重置门，参数比LSTM少，在很大程度上提高训练效率。重置门越小代表前一状态被丢弃信息越多，更新门越大代表前一时刻带入信息越多。同时GRU在并不控制和保留内部记忆$c_t$ ，但从设计上能够达到LSTM同样的避免梯度消失的效果。</p>\n</li>\n</ul>\n<p><img src=\"https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-07-03-lstm-gru.png\" style=\"zoom:80%;\"></p>\n<h3 id=\"Transformer\"><a href=\"#Transformer\" class=\"headerlink\" title=\"Transformer\"></a>Transformer</h3><p>​    近年来的研究热点一直是在Transformer上，自从谷歌2017年在Attention is all you need一文中提出Transformer模型，其通过内部编码器解码器结构结合多头注意力机制 $QKV$，能够并行的注意到不同单元的特征信息，从而打破了RNN的网络退化训练难题，以BERT为代表的BERT家族模型目前一直是NLP研究的前沿热点模型，因为字数限制在此就不过多介绍。</p>\n<div style=\"page-break-after: always;\"></div>\n\n<h2 id=\"2-实验内容\"><a href=\"#2-实验内容\" class=\"headerlink\" title=\"2. 实验内容\"></a>2. 实验内容</h2><h3 id=\"2-1-基于RNN及其变体的分类器\"><a href=\"#2-1-基于RNN及其变体的分类器\" class=\"headerlink\" title=\"2.1 基于RNN及其变体的分类器\"></a>2.1 基于RNN及其变体的分类器</h3><p>我首先在RNN系列模型上进行了一系列实验，采用统一参数，并且拿出最后一层的输出，做 <em>drop_out</em> 后通过一个全连接层得到最后的输出，同时全开bidirection。</p>\n<p>​    同时在对比RNN分类器的实验过程中发现，在没有添加 <em>pretrain</em> 的 word_embedding，即使用随机初始化的 embedding 进行训练能够更加明显的对比出不同模型的效果。</p>\n<ul>\n<li><strong>模型主体</strong></li>\n</ul>\n<pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">forward</span>(<span class=\"hljs-params\">self, x</span>):</span>\n        batch_size, seq_len = x.size()\n        x = self.embed_dropout(self.embeddings(x))\n        out, _ = self.rnn(x)\n        out = out.view(batch_size, seq_len, self.num_labels, self.hidden_size)\n        out = torch.cat([out[:, <span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">0</span>, :], out[:, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>, :]], dim=<span class=\"hljs-number\">-1</span>)\n        out = self.dropout(out)\n        logits = self.fc(out)\n        <span class=\"hljs-keyword\">return</span> logits</code></pre>\n<ul>\n<li><strong>模型参数及超参数</strong></li>\n</ul>\n<pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">embed_dim:</span> <span class=\"hljs-number\">300</span> \t<span class=\"hljs-comment\"># 嵌入维度</span>\n<span class=\"hljs-attr\">hidden_size:</span> <span class=\"hljs-number\">512</span>  <span class=\"hljs-comment\"># 隐藏层维度</span>\n<span class=\"hljs-attr\">num_labels:</span> <span class=\"hljs-number\">2</span>  <span class=\"hljs-comment\"># 标签数</span>\n<span class=\"hljs-attr\">num_layers:</span> <span class=\"hljs-number\">2</span>  <span class=\"hljs-comment\"># 层数</span>\n<span class=\"hljs-attr\">dropout:</span> <span class=\"hljs-number\">0.5</span>  <span class=\"hljs-comment\"># 全连接层 drop out</span>\n<span class=\"hljs-attr\">embed_dropout:</span> <span class=\"hljs-number\">0.5</span>  <span class=\"hljs-comment\"># 嵌入层 drop out</span>\n<span class=\"hljs-attr\">WORD_EMBEDDING:</span> <span class=\"hljs-string\">Random</span> <span class=\"hljs-comment\"># 初始对比不加 Word Embedding 效果更加明显</span></code></pre>\n<pre><code class=\"hljs yaml\"><span class=\"hljs-comment\"># 超参数</span>\n<span class=\"hljs-attr\">EPOCH:</span> <span class=\"hljs-number\">30</span>\n<span class=\"hljs-attr\">BATCH_SIZE:</span> <span class=\"hljs-number\">64</span>\n<span class=\"hljs-attr\">OPTIMIZER:</span> <span class=\"hljs-comment\"># 优化器</span>\n  <span class=\"hljs-attr\">NAME:</span> <span class=\"hljs-string\">AdamW</span>\n  <span class=\"hljs-attr\">ARGS:</span>\n    <span class=\"hljs-attr\">lr:</span> <span class=\"hljs-number\">6.0e-5</span>\n    <span class=\"hljs-attr\">eps:</span> <span class=\"hljs-number\">1.0e-6</span>\n<span class=\"hljs-attr\">SCHEDULER:</span> <span class=\"hljs-comment\"># 无LR调节</span>\n  <span class=\"hljs-attr\">NAME:</span> <span class=\"hljs-literal\">null</span></code></pre>\n<h4 id=\"2-1-0-Preprocess\"><a href=\"#2-1-0-Preprocess\" class=\"headerlink\" title=\"2.1.0 Preprocess\"></a>2.1.0 Preprocess</h4><p>在前处理过程中，滤除了语料库当中的非字母符号，对字母进行全小写化。（尝试滤除stop word但其因为会改变很多语义信息，从而最后并未采纳）</p>\n<pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">preprocess_data</span>(<span class=\"hljs-params\">lines</span>):</span>\n    formatted_lines = []\n    <span class=\"hljs-keyword\">for</span> line <span class=\"hljs-keyword\">in</span> lines:\n        <span class=\"hljs-comment\"># split into tokens by white space</span>\n        tokens = line.split()\n        <span class=\"hljs-comment\"># remove punctuation from each token and convert to lowercase</span>\n        table = <span class=\"hljs-built_in\">str</span>.maketrans(<span class=\"hljs-string\">&#x27;&#x27;</span>, <span class=\"hljs-string\">&#x27;&#x27;</span>, string.punctuation)\n        tokens = [w.translate(table).lower() <span class=\"hljs-keyword\">for</span> w <span class=\"hljs-keyword\">in</span> tokens]\n        <span class=\"hljs-comment\"># remove remaining tokens that are not alphabetic</span>\n        tokens = [word <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> tokens <span class=\"hljs-keyword\">if</span> word.isalpha()]\n        <span class=\"hljs-comment\"># join the new tokens to form the formatted sentence</span>\n        sentence = <span class=\"hljs-string\">&quot; &quot;</span>.join(tokens)\n        formatted_lines.append(sentence)\n    <span class=\"hljs-keyword\">return</span> formatted_lines</code></pre>\n<h4 id=\"2-1-1-RNN\"><a href=\"#2-1-1-RNN\" class=\"headerlink\" title=\"2.1.1 RNN\"></a>2.1.1 RNN</h4><p>RNN 在随机初始化的 Word Embedding 上表现较差，在Val上最高的准确率达到 65.30%，后期过拟合现象较为严重。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdqmwrpcbj30t60cp3za.jpg\" style=\"zoom:60%;\"></p>\n<h4 id=\"2-1-2-LSTM\"><a href=\"#2-1-2-LSTM\" class=\"headerlink\" title=\"2.1.2 LSTM\"></a>2.1.2 LSTM</h4><p>LSTM 则表现较好，最高在Val上的准确率达到 72.84%，同时由于网络表达能力增强，其过拟合现象比RNN更加严重。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdqpqi5uhj30ya0dnt9n.jpg\" style=\"zoom:50%;\"></p>\n<h4 id=\"2-1-3-GRU\"><a href=\"#2-1-3-GRU\" class=\"headerlink\" title=\"2.1.3 GRU\"></a>2.1.3 GRU</h4><p>GRU 同样表现不错，在Val上的准确率最高达到 71.57%, 稍微弱于LSTM，但是其收敛速度快于LSTM</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdqsaqauoj30st0dl0tk.jpg\" style=\"zoom:60%;\"></p>\n<h4 id=\"2-1-4-小结\"><a href=\"#2-1-4-小结\" class=\"headerlink\" title=\"2.1.4 小结\"></a>2.1.4 小结</h4><p>​    实验中我们可以看到，单论模型性能 <em>LSTM</em> 是表现最好的网络，<em>GRU</em> 作为 <em>LSTM</em> 的改进版，能够更快的拟合并获得接近 <em>LSTM</em> 的效果，而 <em>RNN</em> 则由于梯度消失导致的网络退化问题，难以很好的拟合，梯度爆炸导致训练不稳定，性能较差。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">模型</th>\n<th style=\"text-align:center\">准确率 / %</th>\n<th style=\"text-align:center\">Epoch / n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">RNN</td>\n<td style=\"text-align:center\">65.30</td>\n<td style=\"text-align:center\">16</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LSTM</td>\n<td style=\"text-align:center\">72.84</td>\n<td style=\"text-align:center\">13</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">GRU</td>\n<td style=\"text-align:center\">71.57</td>\n<td style=\"text-align:center\">12</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>在实验过程中我们不难得出以下结论</p>\n<p><strong>模型性能上：</strong> $LSTM &gt; GRU &gt; RNN$</p>\n<div style=\"page-break-after: always;\"></div>\n\n<p><strong>收敛速度上：</strong> $GRU&gt;LSTM&gt;RNN$</p>\n<ul>\n<li><p><strong>过拟合</strong></p>\n<p>同时在实验过程中我们很容易观察到，在训练后期模型都不同程度的出现了过拟合现象，这里我们在embedding和fc层都添加了0.5的drop_out，如果不添加的话过拟合现象则会更加研究 (详见后文的ablation study)，我们可以使用 early stop 方法简单的早停止训练来防止过拟合现象发生。我们可以看到三个模型在 15 个 Epoch 左右都达到了其最佳性能，所以我们可以将最大 Epoch 设为 15 来防止后期的过拟合现象发生。</p>\n</li>\n</ul>\n<h4 id=\"2-1-5-进一步分析\"><a href=\"#2-1-5-进一步分析\" class=\"headerlink\" title=\"2.1.5 进一步分析\"></a>2.1.5 进一步分析</h4><p>我们还可以继续计算模型的查准率 (Precision), 召回率 (Recall) , F1 score</p>\n<script type=\"math/tex; mode=display\">\nPrecison = \\frac{TP}{TP+FP}\\\\\\\\\nRecall = \\frac{TP}{TP+FN}\\\\\\\\\nF_1 = \\frac{2*Precision*Recall}{Precision + Recall}</script><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwehwkiqjlj30sp0azwf1.jpg\" style=\"zoom:50%;\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwehsbzj9oj30fp07l74j.jpg\" style=\"zoom:80%;\"></p>\n<ul>\n<li><p><strong>关于查准率和召回率</strong></p>\n<p>从图中我们不难看出，模型的查准率和召回率互为拮抗，查准率上升的时候召回率一般会下降，为了平衡衡量这两者来公平衡量二分类模型的准确率，我们可以使用F1 Score</p>\n</li>\n<li><p><strong>F1 Score</strong></p>\n<p>​    F1 score作为兼顾了分类模型的准确率和召回率。F1分数可以看作是模型查准率和召回率的一种加权平均，形式表现为查准率和召回率的调和平均。</p>\n</li>\n</ul>\n<div style=\"page-break-after: always;\"></div>\n\n<h3 id=\"2-3-比较不同的-Word-Embedding-方式\"><a href=\"#2-3-比较不同的-Word-Embedding-方式\" class=\"headerlink\" title=\"2.3 比较不同的 Word Embedding 方式\"></a>2.3 比较不同的 Word Embedding 方式</h3><p>​    在上述实验的基础上，我选用 LSTM 来进行进一步的实验，为LSTM添加不同的 pretrain 的 Word_Embedding 参数来查看 Word_Embedding 对网络准确率的影响。</p>\n<h4 id=\"2-3-1-Word2Vec\"><a href=\"#2-3-1-Word2Vec\" class=\"headerlink\" title=\"2.3.1 Word2Vec\"></a>2.3.1 Word2Vec</h4><p>​    首先实验的是Word2Vec, 这里我选用的是 <code>GoogleNews-vectors-negative300</code></p>\n<pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">WORD_EMBEDDING:</span> \n  <span class=\"hljs-attr\">NAME:</span> <span class=\"hljs-string\">Word2Vec</span> <span class=\"hljs-comment\"># Word2Vec, GloVe, None</span>\n  <span class=\"hljs-attr\">PATH:</span> <span class=\"hljs-string\">Gensim/GoogleNews-vectors-negative300.bin</span></code></pre>\n<pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">load_word2vec</span>(<span class=\"hljs-params\">text_field, PATH</span>):</span>\n    word_to_idx = text_field.vocab.stoi\n    pretrained_embeddings = np.random.uniform(<span class=\"hljs-number\">-0.25</span>, <span class=\"hljs-number\">0.25</span>, (<span class=\"hljs-built_in\">len</span>(text_field.vocab), <span class=\"hljs-number\">300</span>))\n    pretrained_embeddings[<span class=\"hljs-number\">0</span>] = <span class=\"hljs-number\">0</span>\n    word2vec = load_bin_vec(PATH, word_to_idx)\n    <span class=\"hljs-keyword\">for</span> word, vector <span class=\"hljs-keyword\">in</span> word2vec.items():\n        pretrained_embeddings[word_to_idx[word]<span class=\"hljs-number\">-1</span>] = vector\n\n    <span class=\"hljs-keyword\">return</span> pretrained_embeddings</code></pre>\n<p>​    使用预训练的参数替换模型中的 embeddings 层的初始值，其余训练参数和超参均同上，进行公平对比。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdr76zpusj30sq0dkaau.jpg\" style=\"zoom:60%;\"></p>\n<p>可以看到，预训练的词嵌入非常好的指导网络在情感分类任务上的训练拟合，拟合速度和准确率相比随机初始化的参数都有较大幅度的提升，仅在第7个epoch就得到了最好性能。</p>\n<div style=\"page-break-after: always;\"></div>\n\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">模型</th>\n<th style=\"text-align:center\">准确率 / %</th>\n<th style=\"text-align:center\">Epoch / n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">LSTM-Random</td>\n<td style=\"text-align:center\">72.84</td>\n<td style=\"text-align:center\">13</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LSTM-Word2Vec</td>\n<td style=\"text-align:center\">75.11</td>\n<td style=\"text-align:center\">7</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h4 id=\"2-3-2-GloVe\"><a href=\"#2-3-2-GloVe\" class=\"headerlink\" title=\"2.3.2 GloVe\"></a>2.3.2 GloVe</h4><p>​    我们换上比Word2Vec更加具有全局信息的GloVe嵌入，这里采用的是 <code>glove.840B.300d</code></p>\n<pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">WORD_EMBEDDING:</span> \n  <span class=\"hljs-attr\">NAME:</span> <span class=\"hljs-string\">GloVe</span> <span class=\"hljs-comment\"># Word2Vec, GloVe, None</span>\n  <span class=\"hljs-attr\">PATH:</span> <span class=\"hljs-string\">&#x27;glove.840B.300d&#x27;</span></code></pre>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdrc8z2jqj30sn0dnaat.jpg\" style=\"zoom:60%;\"></p>\n<p>GloVe 的词嵌入比 Word2Vec 达到了更好的性能，在Val上达到了79.2%的准确率，可以看到预训练的词嵌入对模型性能的提升有非常大的效果</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdtwdj6awj30xh0e10u5.jpg\" alt=\"image-20211113211031902\" style=\"zoom:55%;\"></p>\n<div style=\"page-break-after: always;\"></div>\n\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">模型</th>\n<th style=\"text-align:center\">准确率 / %</th>\n<th style=\"text-align:center\">Epoch / n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">LSTM-Random</td>\n<td style=\"text-align:center\">72.84</td>\n<td style=\"text-align:center\">13</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LSTM-Word2Vec</td>\n<td style=\"text-align:center\">75.11</td>\n<td style=\"text-align:center\">7</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LSTM-GloVe</td>\n<td style=\"text-align:center\">79.2</td>\n<td style=\"text-align:center\">8</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h4 id=\"2-3-4-总结\"><a href=\"#2-3-4-总结\" class=\"headerlink\" title=\"2.3.4 总结\"></a>2.3.4 总结</h4><p>​    可以看到预训练的词嵌入能够非常大的提升模型的性能，让模型更好的抓住句子和词之间的联系，抽取句子的语义信息。对情感分类问题有着较大的帮助。</p>\n<h3 id=\"2-4-基于CNN的分类器\"><a href=\"#2-4-基于CNN的分类器\" class=\"headerlink\" title=\"2.4 基于CNN的分类器\"></a>2.4 基于CNN的分类器</h3><p>​    对于词嵌入向量，我们也可以使用CNN对其进行操作，通过卷积核来提取局部特征，并融合全局视野，不过相比RNN的模型结构。CNN的方式对语言问题少了一些先验的序列化模式，因此收敛速度要明显慢于RNN。</p>\n<p>为和RNN对比，使用了统一参数。卷积核采用 $3 \\times embed_dim$ 大小，同时随机初始化 Word_embedding</p>\n<pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">CNN</span>(<span class=\"hljs-params\">nn.Module</span>):</span>\n  ....\n   self.conv_layers = nn.ModuleList([nn.Conv2d(in_channels=<span class=\"hljs-number\">1</span>,\n                                     out_channels=hidden_size,\n                                     kernel_size=(kernel_size, embed_dim))]*num_layers)\n  ....</code></pre>\n<h4 id=\"2-4-1-实验结果\"><a href=\"#2-4-1-实验结果\" class=\"headerlink\" title=\"2.4.1 实验结果\"></a>2.4.1 实验结果</h4><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdrjpqd2yj30so0dvdgn.jpg\" style=\"zoom:55%;\"></p>\n<div style=\"page-break-after: always;\"></div>\n\n<p>​    可以看到CNN的拟合速度明显慢于基于RNN的分类器，担其效果不输LSTM甚至略微优于LSTM，在最后一个 Epoch 甚至达到了 73.48% 的准确率，如果继续训练可能会达到更高的准确率，但为了公平对比，因此不再扩大 Epoch 数。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">模型</th>\n<th style=\"text-align:center\">准确率 / %</th>\n<th style=\"text-align:center\">Epoch / n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">RNN</td>\n<td style=\"text-align:center\">65.30</td>\n<td style=\"text-align:center\">16</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LSTM</td>\n<td style=\"text-align:center\">72.84</td>\n<td style=\"text-align:center\">13</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">GRU</td>\n<td style=\"text-align:center\">71.57</td>\n<td style=\"text-align:center\">12</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">CNN</td>\n<td style=\"text-align:center\">73.48</td>\n<td style=\"text-align:center\">30</td>\n</tr>\n</tbody>\n</table>\n</div>\n<div style=\"page-break-after: always;\"></div>\n\n<h3 id=\"2-5-基于BERT及其变体的分类器（Transformer）\"><a href=\"#2-5-基于BERT及其变体的分类器（Transformer）\" class=\"headerlink\" title=\"2.5 基于BERT及其变体的分类器（Transformer）\"></a>2.5 基于BERT及其变体的分类器（Transformer）</h3><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwds81vpfuj30fe0ndwg2.jpg\" style=\"zoom:60%;\"></p>\n<h4 id=\"2-5-1-BERT\"><a href=\"#2-5-1-BERT\" class=\"headerlink\" title=\"2.5.1 BERT\"></a>2.5.1 BERT</h4><p>​    BERT全名即 <em>Bidirectional Encoder Representations from Transformers</em> 即从模型思路上使用了 Transformer 的 Encoder 部分，来对输入词向量做 Self Attention，但其比普通 Transformer 的 Encoder 更深更窄，BERT-base 有 12 个 encoder 模块，hidden-size 是 768。</p>\n<ul>\n<li><p><strong>预训练任务</strong></p>\n<p>BERT出彩的地方是其预训练部分做的很好，除了之前所说的普通Word Embedding方式使用的 <strong>Masked LM</strong> 即遮挡预测以外，BERT还引入了下一句预测的预训练模式 <strong>Next Sentence Prediction</strong>，让模型能够更好的理解句子之间的关系</p>\n</li>\n<li><p><strong>实验方法</strong></p>\n<p>采用载入预训练的BERT checkpoint 再在下游 SST-2 数据集上进行 fine-tune 的方式进行训练</p>\n</li>\n</ul>\n<div style=\"page-break-after: always;\"></div>\n\n<ul>\n<li><strong>实验参数</strong></li>\n</ul>\n<pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">MODEL:</span>\n  <span class=\"hljs-attr\">NAME:</span> <span class=\"hljs-string\">BERT</span> <span class=\"hljs-comment\"># RNN, LSTM, GRU, CNN, BERT</span>\n  <span class=\"hljs-attr\">ARGS:</span>\n    <span class=\"hljs-attr\">model_type:</span> <span class=\"hljs-string\">bert-base-uncased</span> <span class=\"hljs-comment\"># bert-base-uncased, bert-large-uncased</span>\n    <span class=\"hljs-attr\">dropout:</span> <span class=\"hljs-number\">0.5</span>\n<span class=\"hljs-attr\">OPTIMIZER:</span> \n  <span class=\"hljs-attr\">NAME:</span> <span class=\"hljs-string\">AdamW</span>\n  <span class=\"hljs-attr\">ARGS:</span>\n    <span class=\"hljs-attr\">lr:</span> <span class=\"hljs-number\">2.0e-5</span>\n    <span class=\"hljs-attr\">eps:</span> <span class=\"hljs-number\">1.0e-8</span></code></pre>\n<pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 采用 linear_schedule_with_warmup</span>\nscheduler = get_linear_schedule_with_warmup(\n   optimizer=optimizer,\n   num_warmup_steps=<span class=\"hljs-number\">0</span>,\n   num_training_steps=num_training_steps\n)</code></pre>\n<ul>\n<li><strong>实验结果</strong></li>\n</ul>\n<p>我个人分别在 BERT-base-uncased 和 BERT-large-uncased 上进行了训练</p>\n<ul>\n<li><strong>BERT-base-uncased</strong></li>\n</ul>\n<p><strong>参数信息：</strong> 12-layer, 768-hidden, 12-heads, 110M parameters</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdsttr9sbj30s90cr750.jpg\" style=\"zoom:60%;\"></p>\n<div style=\"page-break-after: always;\"></div>\n\n<ul>\n<li><strong>BERT-large-uncased</strong></li>\n</ul>\n<p><strong>参数信息：</strong> 24-layer, 1024-hidden, 16-heads, 336M parameters</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdsnvaegsj30sn0cqt9f.jpg\" style=\"zoom:60%;\"></p>\n<ul>\n<li><strong>总结</strong></li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">模型</th>\n<th style=\"text-align:center\">准确率 / %</th>\n<th style=\"text-align:center\">Epoch / n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">BERT-base-uncased</td>\n<td style=\"text-align:center\">86.97</td>\n<td style=\"text-align:center\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">BERT-large-uncased</td>\n<td style=\"text-align:center\">88.65</td>\n<td style=\"text-align:center\">2</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>可以看到 BERT-large 性能好于 BERT-base 能够达到极高的 88.65% 同时由于参数量的提升，收敛上页略慢于BERT-base，在第2个epoch达到最佳性能。</p>\n<h4 id=\"2-5-4-其他BERT变种\"><a href=\"#2-5-4-其他BERT变种\" class=\"headerlink\" title=\"2.5.4 其他BERT变种\"></a>2.5.4 其他BERT变种</h4><p>​    我继续使用测试了其他 BERT 变种例如 RoBERTa，以及AlBERT来进一步提升模型的准确率，经过实验发现 RoBERTa-large的准确率可以达到90%左右，而最好的准确率是使用 AlBERT-xxlarge 上可以在 Val 上达到 91%的准确率。</p>\n<ul>\n<li><strong>训练参数设置：</strong></li>\n</ul>\n<pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">Scheduler:</span> <span class=\"hljs-string\">warmup_cosine</span>\n<span class=\"hljs-attr\">Optimizer:</span> <span class=\"hljs-string\">AdamW</span>\n<span class=\"hljs-attr\">LR:</span> <span class=\"hljs-number\">1e-5</span>\n<span class=\"hljs-attr\">Epoch:</span> <span class=\"hljs-number\">5</span>\n<span class=\"hljs-attr\">BatchSize:</span> <span class=\"hljs-number\">8</span></code></pre>\n<div style=\"page-break-after: always;\"></div>\n\n<ul>\n<li><strong>AlBERT-xxlarge-v2</strong></li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdszgffm2j30xg0dijsa.jpg\" style=\"zoom:60%;\"></p>\n<p>​    准确率最高达到 91.01%，可以看到模型在大约第3个epoch达到最佳性能，后开始过拟合。为此我使用early stop，训练3个epoch</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwefzu7y82j30wt0dfgmh.jpg\" style=\"zoom:60%;\"></p>\n<p>​    模型准确率最高达到91.46%</p>\n<div style=\"page-break-after: always;\"></div>\n\n<h3 id=\"2-6-训练方法对模型性能的影响\"><a href=\"#2-6-训练方法对模型性能的影响\" class=\"headerlink\" title=\"2.6 训练方法对模型性能的影响\"></a>2.6 训练方法对模型性能的影响</h3><h4 id=\"2-3-2-改变BatchSize\"><a href=\"#2-3-2-改变BatchSize\" class=\"headerlink\" title=\"2.3.2 改变BatchSize\"></a>2.3.2 改变BatchSize</h4><p>​    Batch Size 对模型的准确性没有很大的影响，但在小batch的情况下有可能导致训练不稳定，iter之间的loss差距较大。</p>\n<p>​    同时更大的Batch Size能够加快训练速度，更好的在全数据集上拟合，但这也不是说越大越好。过大的batch size可能会导致batch之间梯度变化过小，模型泛化能力缺失。同时也要注意自己使用的是什么Optimizer，如果是SGD优化器，batch size和learning rate之间成线性关系，在更改batch size的时候需要注意更改学习率。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwdu5o0h46j30sp0cijsn.jpg\" style=\"zoom:60%;\"></p>\n<h4 id=\"2-3-4-改变Drop-Out\"><a href=\"#2-3-4-改变Drop-Out\" class=\"headerlink\" title=\"2.3.4 改变Drop Out\"></a>2.3.4 改变Drop Out</h4><p>​    drop out 对网络过拟合现象有比较大的影响，如果drop out过小网络表达能力过强且集中于几个特定神经元上，导致训练很快拟合到训练集上，从而导致模型泛化能力变差，性能减弱。这里我测试了三种drop_out的大小，分别是0.5, 0.2, 0</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwehhhqij9j30nj0cw3zm.jpg\" style=\"zoom:60%;\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwehla48ruj30nh0cpt9h.jpg\" style=\"zoom:60%;\"></p>\n<p>可以看到网络在 drop out = 0.5 的时候性能最好。在 drop out = 0 的时候过拟合非常严重，性能最差。但因为drop out比较大，拟合上相比0.2和0速度更慢。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwehdm8dyvj30g909f3zc.jpg\" style=\"zoom:67%;\"></p>\n<p>​    在限制 drop out 为0.5时，其eval上的loss最小，而train上的loss最大，eval和train上的准确率增长较为同步。且过拟合现象最不严重，相比之下，drop out=0 时，过拟合现象十分严重，测试集上loss很大。</p>\n<ul>\n<li><strong>关于Drop out</strong></li>\n</ul>\n<p>不得不提，如果drop out过大网络的表达能力会被损害，如果drop_out = 1相当于网络中这一层上所有激活全被 drop 掉，网络就无法输出信息了。因此选用合适的drop out十分重要</p>\n<div style=\"page-break-after: always;\"></div>\n\n<h2 id=\"3-总结\"><a href=\"#3-总结\" class=\"headerlink\" title=\"3.总结\"></a>3.总结</h2><p>​    在本次实验中，对比了不同的模型在情感分类任务上的性能，探索了不同Word Embedding对模型性能的影响，比较了不同训练方法对模型的影响。基本了解并探索了NLP的基本任务和实验流程。得到如下实验结果</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">模型</th>\n<th style=\"text-align:center\">准确率 / %</th>\n<th style=\"text-align:center\">Epoch / n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">RNN</td>\n<td style=\"text-align:center\">65.30</td>\n<td style=\"text-align:center\">16</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LSTM</td>\n<td style=\"text-align:center\">72.84</td>\n<td style=\"text-align:center\">13</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">GRU</td>\n<td style=\"text-align:center\">71.57</td>\n<td style=\"text-align:center\">12</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">CNN</td>\n<td style=\"text-align:center\">73.48</td>\n<td style=\"text-align:center\">30</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LSTM-Word2Vec</td>\n<td style=\"text-align:center\">75.11</td>\n<td style=\"text-align:center\">7</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">LSTM-GloVe</td>\n<td style=\"text-align:center\">79.2</td>\n<td style=\"text-align:center\">8</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">BERT-base-uncased</td>\n<td style=\"text-align:center\">86.97</td>\n<td style=\"text-align:center\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">BERT-large-uncased</td>\n<td style=\"text-align:center\">88.65</td>\n<td style=\"text-align:center\">2</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">RoBERTa-large</td>\n<td style=\"text-align:center\">90.02</td>\n<td style=\"text-align:center\">3</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">AlBERT-xxlarge-v2</td>\n<td style=\"text-align:center\">91.46</td>\n<td style=\"text-align:center\">3</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h4 id=\"3-1-进一步实验方向\"><a href=\"#3-1-进一步实验方向\" class=\"headerlink\" title=\"3.1 进一步实验方向\"></a>3.1 进一步实验方向</h4><ul>\n<li><p><strong>蒸馏学习</strong></p>\n<p>可以通过高准确率的模型例如BERT给低准确率的模型例如LSTM进行蒸馏，在训练过程中增加一个loss进行指导训练，来进一步提升小模型的准确率。这在实际工业场景中有很大的应用场景</p>\n<script type=\"math/tex; mode=display\">\nloss = \\alpha CrossEntropy(pred, true) + (1-\\alpha) MSEloss(pred, bert\\_true)</script></li>\n<li><p><strong>多模型ensemble</strong></p>\n<p>可以采用多模型 ensemble 的方式进一步提升模型的准确率，即训练多个不同的模型，或即使是相同模型进行不同初始化的结果，最后做简单的投票。这种ensemble方式能够进一步提升模型的性能，目前广泛应用于对及时性要求较少的场景和各大算法竞赛当中（例如Kaggle）</p>\n</li>\n</ul>\n<div style=\"page-break-after: always;\"></div>\n\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>[1] Ralf C. Staudemeyer, &amp; Eric Rothstein Morris. (2019). Understanding LSTM – a tutorial into Long Short-Term Memory Recurrent Neural Networks.</p>\n<p>[2] Sherstinsky, A. (2020). Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) network<em>. Physica D: Nonlinear Phenomena, \\</em>404*, 132306.</p>\n<p>[3] Jacob Devlin, Ming-Wei Chang, Kenton Lee, &amp; Kristina Toutanova. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.</p>\n<p>[4] Victor Sanh, Lysandre Debut, Julien Chaumond, &amp; Thomas Wolf. (2020). DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter.</p>\n<p>[5] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, &amp; Veselin Stoyanov. (2019). RoBERTa: A Robustly Optimized BERT Pretraining Approach.</p>\n<p>[6] Dang, N., Moreno-García, M., &amp; Prieta, F. (2020). Sentiment Analysis Based on Deep Learning: A Comparative Study<em>. Electronics, \\</em>9*(3), 483.</p>\n"},{"title":"ICS-Lab1 位运算","index_img":"/img/ICS_Lab1/top.jpg","date":"2020-11-06T07:58:42.000Z","_content":"\n# ICS_Lab1-位运算\n\n> 这个是CS:APP的第一个lab，也是我ICS课上的第一个lab，主要注重于使用受限制的位运算来完成操作\n\n***\n\n## **Bits.c**\n### **1. bitAnd--与**\n**题目：**\n\n    只用~和|实现&\n\n**样例：**\n\n    bitAnd(6, 5) = 4\n\n**可使用操作：** ~ |\n    \n**最大操作数限制：** 8\n\n**使用操作数：** 4\n\n```cpp\nint bitAnd(int x, int y) {\n  return ~(~x | ~y); //De Morgan's laws\n}\n```\n\n> 应用摩根律 ~(x | y) = ~x & ~y, 可得 x & y = ~(~x | ~y)\n\n***\n\n### **2. getByte--获取字节**\n**题目：**\n\n    从x中提取字节n, n编号从0至3\n\n**样例：**\n\n    getByte(0x12345678,1) = 0x56\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 6\n\n**使用操作数：** 3\n\n**代码：**\n```cpp\nint getByte(int x, int n) {\n  return (x >> (n << 3)) & 0xff;\n}\n```\n\n**分析：**\n\n*由于 1Byte = 8bits = 2^3bits， 所以 n Bytes = 2^3 * n bits*\n> 因而将n左移3位，即 n * 2^3, 再将x右移 n * 2^3 即可将所求字节放在低8位，将其与上0xff，即可取出字节。\n\n***\n\n### **3. logicalShift--逻辑右移**\n**题目：**\n\n    将x逻辑右移n位\n\n**样例：**\n\n    logicalShift(0x87654321,4) = 0x08765432\n\n**可使用操作：**  ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 20\n\n**使用操作数：** 10\n\n**代码：**\n```cpp\nint logicalShift(int x, int n) {\n  //flag equals to: if n == 0 return 0; else return 1;\n  int flag = !!n;\n  int mask = ~(flag << (32 + (~n + 1)));\n  return (x >> n) & mask;\n}\n```\n\n**分析：**\n\n* 算数右移\n> 算数右移即在右移后用原符号位数将高位补齐，保持右移后二进制数的符号保持不变。\n\n* 逻辑右移\n> 逻辑右移即在右移后用 0 将高位补齐，是“逻辑上”的右移。\n\n> 在正常右移运算中使用的是算数右移，因而要解决的问题即对于负数如何将最高位补上0，而非符号位1。\n> 我采取掩码的方式，先将x正常右移n位与上其高位的掩码，使其右移产生的高位变为0\n\n* 掩码构造\n> 掩码不能草率的构造为 ~(-1 << (32 - n)), 这种构造方式当n为0时会因-1被左移32位而导致异常，构造出来的mask仍为0\n\n> 由于不能使用if，为判断n是否为0，我才用了一个flag = !n + ~0, 其有很好的性质。当n为0时，flag也为0，而当n不为零时，flag统一为-1，这样使用flag代替原先的-1, 从而避免上述情况。\n\n> 这样我们可以使用 mask = ~(flag << (32 + (~n + 1)))，来构造掩码，当n为0时，flag为0，从而mask = -1，避免上述错误。\n\n***\n\n### **4. bitCount--比特计数**\n**题目：**\n\n    返回二进制数中1的个数\n\n**样例：**\n\n    bitCount(5) = 2, bitCount(7) = 3\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 40\n\n**使用操作数：** 36\n\n**代码：**\n```cpp\nint bitCount(int x) {\n  int tmp, l1, l2, l4, l8, l16; //tmp is used to save ops\n  tmp = (0x55 << 8) + 0x55;\n  l1 = (tmp << 16) + tmp; //0x55555555\n  tmp = (0x33 << 8) + 0x33;\n  l2 = (tmp << 16) + tmp; //0x33333333\n  tmp = (0x0f << 8) + 0x0f;\n  l4 = (tmp << 16) + tmp; //0x0f0f0f0f\n  l8 = (0xff << 16) + 0xff; //0x00ff00ff\n  l16 = (0xff << 8) + 0xff; //0x0000ffff\n\n  x = (x & l1) + ((x >> 1) & l1);\n  x = (x & l2) + ((x >> 2) & l2);\n  x = (x & l4) + ((x >> 4) & l4);\n  x = (x & l8) + ((x >> 8) & l8);\n  x = (x & l16) + ((x >> 16) & l16);\n  return x;\n}\n```\n\n**分析：**\n\n* 分治思想\n> 本题使用了一个简单的分治思想，对于一个二进制数，要对其中为1的位做计数， 对于1位二进制数来说，1的个数无非就是其本身所表示的1或0。利用这个特性，我们可以先将一个二进制数每一位独立分开为相间隔的两部分, 其每位表示的就是自身的二进制个数，再将两串二进制数对其相加，所得到的每两位分隔的二进制数就是表达这个位置的位为1的个数。\n\n> 进一步相加为4位，8位其所代表的含义不变，最后合并至32位二进制数，其所表示的就是原二进制数中所含1的个数。\n\n```cpp\n//以八位二进制数 10101110 为例//\n按 1|0|1|0|1|1|1|0 分割， 为两串1|1|1|1和0|0|1|0，再将其合并，成为 01 | 01 | 10 | 01, 再将两串 01 | 10 和01 | 01合并得 0010 | 0011（这个很容易看出表示左四位有2个1，右四位有3个1），再次合并得 00000101, 得到总共有5个1。\n\n//对于32位二进制数亦按此继续操作即可//\n```\n\n> 于是为完成分割取位的操作，我们需要采用掩码\n\n* 0x55555555 \\ 0x33333333 \\ 0x0f0f0f0f \\ 0x0000ffff\n\n> 利用位运算分别构造，使用tmp可以节约ops, 之后按照分治思想进行操作即可。\n\n***\n\n### **5. bang--逻辑非**\n\n**题目：**\n\n    计算 !x 而不使用逻辑非!\n\n**样例：**\n\n    bang(3) = 0, bang(0) = 1\n\n**可使用操作：** ~ & ^ | + << >>\n    \n**最大操作数限制：** 12\n\n**使用操作数：** 6\n\n**代码：**\n```cpp\nint bang(int x) {\n  return ((x >> 31) | ((~x + 1) >> 31)) + 1;\n}\n```\n\n**分析：**\n\n* 逻辑非\n> 对于逻辑非运算，应该都很熟悉，!x 当且仅当x为0时其为1，其余时候都为0，可以用来区分零和非零数。\n\n> 该问题的关键就是在于如何区分零和非零数，我们知道零的二补码仍然是零，而对于其余非零数，其符号位会有相应改变，利用这一性质，我们可以对零和非零数做出区分。\n\n> 使用 ```((x >> 31) | ((~x + 1) >> 31))```，将二进制数x的符号位与其补码左移31位相与，如若是非零数，其中符号位至少有一个为1，所以经过31位的算数右移后，其中一项必为-1，一项为0，相与之后得到-1,。而对于0来说，结果始终为0。\n\n> 最后只要将结果+1，就能得到逻辑非的效果。\n\n***\n\n### **6. tmin--最小数**\n\n**题目：**\n\n    返回二补码中最小的数\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 4\n\n**使用操作数：** 1\n\n**代码：**\n```cpp\nint tmin(void) {\n  return 1 << 31;\n}\n```\n\n**分析：**\n\n> 此题非常简单，我们知道计算机中负数是用其补码表示的，int所能表示的最小数为0x80000000(-2^31), 即符号位为1，其余皆为0，所以只要将1左移31位即可。\n\n***\n\n### **7. fitsBits--填充比特**\n\n**题目：**\n\n    返回1如果x可以表示为n位二补码，反之返回0 (1 <= n <= 32)\n\n**样例：**\n\n    fitsBits(5,3) = 0, fitsBits(-4,3) = 1\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 15\n\n**使用操作数：** 7\n\n**代码：**\n```cpp\nint fitsBits(int x, int n) {\n  int k = x >> (n + ~0); // if can k = 0 or -1\n  return !k | !(k + 1);\n}\n```\n\n**分析：**\n\n> 我们知道如若一个数能够被n位二进制数表示，则其第n位即最高位是符号位，那么将其右移n-1位后，根据算术右移，其得到的结果不是0，就是1。否则表示，其还有高于n位的位数， 即不能用n位表示。\n\n> 所以用 k = x >> (n + ~0) 表示将其右移n-1位，再用 !k | !(k + 1) 判断k是否为0或-1\n\n***\n\n### **8. divpwr2--除以2的n次方**\n\n**题目：**\n\n    计算 x/(2^n), (0 <= n <= 30)\n\n**样例：**\n\n    divpwr2(15,1) = 7, divpwr2(-33,4) = -2\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 15\n\n**使用操作数：** 7\n\n**代码：**\n```cpp\nint divpwr2(int x, int n) {\n    int sign = x >> 31;\n    int bias = (1 << n) + ~0;\n    x = x + (bias & sign);\n    return x >> n;\n}\n```\n\n**分析：**\n\n> 本题的难点在于Round toward zero, 我们知道除以2的n次方即为将x右移n位。对于正数，尾数截断，因而自然向0舍入。而对于负数则不是如此，经试验在gcc上对于负数，其是向偶数舍入的，因而我们要对负数进行操作。\n\n> 同时由于其向偶数舍入，我们不能简单地对负数进行+1操作，例如原本正确的 -7/4 = -1.25 = -1，但是经过+1操作后变为-6/4 = -1.5 Round toward even则变为了2。所以我们不应简单加一，而是加一个偏差值，其为2^n - 1，对于-7/4来说，就是3，加上bias之后得到(-7 + 3)/4即为-1。\n\n> 所以我们构造bias = (1 << n) + ~0 (由于不能用减号，-1用+~0表示)，然后我们要记得将sign取出，在x进行加操作时先检查一下x是否是负数，再进行操作。最后只要方向的将x右移n位即可。\n\n\n***\n\n### **9. negate--取负**\n\n**题目：**\n\n    返回-x\n\n**样例：**\n\n    negate(1) = -1.\n\n**可使用操作：**  ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 5\n\n**使用操作数：** 2\n\n**代码：**\n```cpp\nint negate(int x) {\n  return ~x + 1;\n}\n```\n\n**分析：**\n\n> 很简单，对于有符号二进制数取负就是取其补码，而补码等于其取反加一，返回取反加一即可。\n\n***\n\n### **10. isPositive--是正数**\n\n**题目：**\n\n    返回1如果x大于0，反之返回0\n\n**样例：**\n\n    isPositive(-1) = 0.\n\n**可使用操作：**  ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 8\n\n**使用操作数：** 5\n\n**代码：**\n```cpp\nint isPositive(int x) {\n  return !(x >> 31) & !!x;\n}\n```\n\n**分析：**\n> 这题关键在于把0剔除了，区分正负数就是区分其符号位，将x右移31位，负数得-1，正数为0，用一个逻辑非使正数为1，负数为0，然后再和!!x与一下就能剔除0\n\n* !!x 当 x == 0 时返回 0，不为 0 时返回 1\n\n***\n\n### **11. isLessOrEqual--小于等于**\n\n**题目：**\n\n    如果x小于等于y返回1，反之返回0\n\n**样例：**\n\n    isLessOrEqual(4,5) = 1.\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 24\n\n**使用操作数：** 14\n\n**代码：**\n```cpp\nint isLessOrEqual(int x, int y) {\n  int res = y + (~x + 1); // y - x\n  int xSign = x >> 31;\n  int ySign = y >> 31;\n  int dif = ~xSign + ySign;\n  return (~(dif + 1 >> 31) & !(res >> 31)) | !dif;\n}\n```\n\n**分析：**\n> 我在这里采取了作差的方法 res = y + (~x + 1)，即计算一下y-x，判断其是否非负，同时也要考虑溢出问题，即 x 为负数，y为正数，y-x后溢出为负。\n\n> 我将x,y右移31位代表其符号，若负则为-1，若正为0。我同时构造了一个 dif 以表示x,y符号之间的关系。\n\n> **dif = ~xSign + ySign**\n1.  当 x < 0 && y < 0 时，dif = -1 \n2.  当 x < 0 && y > 0 时，dif = 0 \n3.  当 x > 0 && y < 0 时，dif = -2 \n4.  当 x > 0 && y < 0 时，dif = -1\n\n> 将 x,y 符号之间的关系表达出来，把 dif 加一我们可以观察到当 x,y 同号时，dif为0，所以将其取反和 !(res >> 31) 相与，就可以表示同号不溢出的情况，而当 x < 0, y > 0 的情况发生时，我们注意到 dif 就是 0 ，所以我们直接或上 !dif 即可表达这种情况。\n\n***\n\n### **12. ilog2--以2为底的对数**\n\n**题目：**\n\n    返回x取以2为底的对数并向下取整，输入的 x > 0\n\n**样例：**\n\n    ilog2(16) = 4\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 90\n\n**使用操作数：** 48\n\n**代码：**\n\n```cpp\nint ilog2(int x) {\n  int tmp, l1, l2, l4, l8, l16;\n  x |= x >> 1;\n  x |= x >> 2;\n  x |= x >> 4;\n  x |= x >> 8;\n  x |= x >> 16;\n  \n  tmp = (0x55 << 8) + 0x55;\n  l1 = (tmp << 16) + tmp;\n  tmp = (0x33 << 8) + 0x33;\n  l2 = (tmp << 16) + tmp;\n  tmp = (0x0f << 8) + 0x0f;\n  l4 = (tmp << 16) + tmp;\n  l8 = (0xff << 16) + 0xff;\n  l16 = (0xff << 8) + 0xff;\n\n  x = (x & l1) + ((x >> 1) & l1);\n  x = (x & l2) + ((x >> 2) & l2);\n  x = (x & l4) + ((x >> 4) & l4);\n  x = (x & l8) + ((x >> 8) & l8);\n  x = (x & l16) + ((x >> 16) & l16);\n  return x + ~0;\n```\n\n**分析：**\n\n> 我们知道二进制数每位有其位权，所以对 x 取以2为底的对数就是指其为1的最高位的位权。为了获得最高位的位置，其实我们可以将其最高位往下全部变为1，再类似bitsCount数其中1的个数就行了。\n\n> 我把 x 移位相与，保证最高位往下所有数字为1，再使用bitsCount就得到答案。\n\n> 最后不要忘记减一\n\n\n***\n\n### **13. float_neg--浮点数的负数**\n\n**题目：**\n\n    返回-f，当NaN时，返回参数f\n\n**可使用操作：** 所有的整型操作，包括 ||, &&. 以及 if, while\n    \n**最大操作数限制：** 10\n\n**使用操作数：** 5\n\n**代码：**\n```cpp\nunsigned float_neg(unsigned uf) {\n  unsigned exp = uf & 0x7f800000;\n  unsigned frac = uf & 0x007fffff;\n  if(exp == 0x7f800000 && frac)\n    return uf;\n  return uf ^= 0x80000000;\n}\n```\n\n**分析：**\n* IEEE-float\n> 我们知道IEEE单精度浮点数，最高位为符号位，其后8位为阶码exp，后23位为尾数frac。其牺牲了精度来扩大了表达范围。\n\n> 而当 exp 全 1 时，如若frac非全零，则表示NaN。若全零，则表示无穷大/小。\n\n> 这里我们只要将原数和符号位0x80000000异或一下，即可取负。不要忘记排除NaN的情况。\n\n***\n\n### **14. float_i2f--int转float**\n\n**题目：**\n\n    把int类型的数转换为float表示(比特形式)\n\n**可使用操作：** 所有的整型操作，包括 ||, &&. 以及 if, while\n    \n**最大操作数限制：** 30\n\n**使用操作数：** 30\n\n**代码：**\n\n```cpp\nunsigned float_i2f(int x) {\n  unsigned frac, mask1, mask2, mask3, mask4, d;\n  int high = 0x80000000;\n  unsigned sign = x & 0x80000000;\n  unsigned exp = 127;\n  int count = 32, i;\n  if(sign)\n    x = ~x + 1;\n  else if(!x)\n    return x;\n  \n  frac = x;\n\n  for(;high; high >>= 1)\n  {\n    --count;\n    if(high & x)\n      break;\n  }\n  i = count - 23;\n  mask1 = ~(1 << count); // the highest 1\n  mask2 = 1 << i; //the lowest of remain frac;\n  mask3 = mask2 >> 1; // the highest of deserted bits \n  mask4 = mask2 - 1; // the deserted bits\n  exp += count;\n\n  frac &= mask1;\n  \n  if(i > 0)\n  {\n    d = frac & mask4; // deserted bits\n    if(d > mask3 | (d == mask3 && frac & mask2))\n    {\n      frac += mask2;\n      if(frac > 0x3fffffff)\n      {\n        frac = 0;\n        exp++;\n      }\n    }\n    frac >>= i;\n  }\n  else\n    frac <<= -i;\n\n  return sign | exp << 23 | frac;\n}\n```\n\n**分析：**\n\n> 我认为这题比较难，我做了很久很久....它难在浮点数向偶数舍入以及其操作数的限制。\n\n> 我们知道由于浮点数表示范围比整型大，我们可以将整型转换为浮点数，但是相应的会有一些精度的丢失，因为尾数frac只有23位，而int有31位可用。\n\n> 所以其关键在于int的位数，一开始先把该取出来的都用掩码取出来，把负数和零处理一下。之后我利用了一个循环先找出int的最高位在哪，利用count计数。\n\n> 后面我采取了四个掩码，分别代表最高位的1，留下的尾数中的最低位，要舍去的位数的最高位，以及舍弃的位数的掩码。利用这四个掩码我们可以达到存frac时，将其向**偶数舍入**。\n\n> 具体操作是，先取出丢弃的尾数，将其存放在d中，看其有没有超过0.5 (即 d 是否大于 mask3) 如果大于，直接frac++就行。而如果等于的话，还要看frac是否是奇数 (即frac & mask2是否为1) 如果是，则要向偶数舍入,frac++。\n\n> 加完frac之后还要注意**溢出问题**，如果溢出了，要将frac置0，然后把阶码 exp++，再按照之前输出来的尾数移动，将尾数对齐即可 （位数最高默认为1不存，因而把最高位隐去）。\n\n> 最后把符号位，阶码位和尾数位拼接，得到最后的结果。\n\n***\n\n### 15. float_twice--float * 2\n\n**题目：**\n\n    返回float * 2, 当参数是NaN时，返回参数\n\n**可使用操作：** 所有的整型操作，包括 ||, &&. 以及 if, while\n    \n**最大操作数限制：** 30\n\n**使用操作数：** 20\n\n**代码：**\n```cpp\nunsigned float_twice(unsigned uf) {\n  unsigned sign = uf & 0x80000000;\n  unsigned exp = uf & 0x7f800000;\n  unsigned frac = uf & 0x007fffff;\n  if(exp == 0x7f800000) //NaN & inf\n    return uf;\n  if(!exp && !frac) // 0\n    return uf;\n  if(!exp && frac <= 0x3fffff)  // low\n    frac *= 2;\n  else if(!exp && frac > 0x3fffff) // high\n  {\n    exp += 0x00800000;\n    frac = (frac * 2) & 0x7fffff;\n  }\n  else // normal\n    exp += 0x00800000;\n  return sign + exp + frac;\n}\n```\n\n**分析：**\n> 主要要分析的地方，在于当阶码exp为0时，是否在乘2之后进位。所以要考虑尾数是否大于0x3fffff，如果小于等于之，则直接尾数乘2就行，不会溢出，否则则exp要进位，同时尾数乘2之后要与上0x7fffff保证不溢出。\n\n> 其他正常情况直接exp++就行，注意一下特殊情况;\n\n*本题中测试集中有一个inf，也要直接返回参数uf*\n\n***\n\n## **Bits_honor.c**\n### **1. bitReverse--比特翻转**\n\n**题目：**\n\n    把32比特int的比特位翻转\n\n**样例：**\n\n    bitReverse(0x80000004) = 0x20000001\n    bitReverse(0x7FFFFFFF) = 0xFFFFFFFE\n    \n**最大操作数限制：** 40\n\n**使用操作数：** 40\n\n**代码：**\n```cpp\nint bitReverse(int x)\n{\n   int tmp,l1, l2, l4, l8, l16;\n\n   tmp = (0x55 << 8) + 0x55;\n   l1 = (tmp << 16) + tmp;\n   tmp = (0x33 << 8) + 0x33;\n   l2 = (tmp << 16) + tmp;\n   tmp = (0x0f << 8) + 0x0f;\n   l4 = (tmp << 16) + tmp;\n   l8 = (0xff << 16) + 0xff;\n   l16 = (0xff << 8) + 0xff;\n\n   x = ((x >> 16) & l16) | (x << 16);\n   x = ((x >> 8) & l8) | ((x & l8) << 8);\n   x = ((x >> 4) & l4) | ((x & l4) << 4);\n   x = ((x >> 2) & l2) | ((x & l2) << 2);\n   x = ((x >> 1) & l1) | ((x & l1) << 1);\n   return x;\n}\n```\n\n**分析：**\n\n> 这题和 bitsCount 有异曲同工之妙，也是一个分治法，将32位二进制数一分为二，交换，再将内部各自再一分为二，交换，直至最底层2位二进制数互换位置，最后完成了将所有位数翻转的工作。\n\n> 但值得注意的是，给出的是有符号的int，所以在右移交换位置时，会发生因为负数算术右移导致高位全是1的情况，致使在与的过程中高位全部变为1。这边只要将其移动后在和掩码相与就能解决这一问题。而对于低位，先与掩码相与再移动，可以省去取反得到高位掩码的操作数。再用tmp省一下操作数。\n\n> 最后操作数正好卡在40\n\n***\n\n### **2. mod3--取模3**\n\n**题目：**\n\n    计算 x 取模 3，而不用%\n\n**样例：**\n\n    mod3(100) = 1\n    mod3(-100) = -1\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 90\n\n**使用操作数：** 24\n\n**代码：**\n```cpp\nint mod3(int x)\n{\n   int mask = (0xff << 8) + 0xff;\n\n   x = (x >> 16) + (x & mask); // sum base 4^8 digits (a <= 0x1FFFE)\n   x = (x >> 8) + (x & 0xff); // sum base 4^4 digits (a <= 0x2FD)\n   x = (x >> 4) + (x & 0xf); // sum base 4^2 digits (a <= 0x3C)\n   x = (x >> 2) + (x & 0x3); // sum base 4^1 digits (a <= 0x1D)\n   x = (x >> 2) + (x & 0x3); // sum base 4^1 digits (a <= 0x9)\n   x = (x >> 2) + (x & 0x3); // sum base 4^1 digits (a <= 0x4)\n\n   x = (((x + 1) >> 2) + x) & 0x3;\n   return x;\n}\n```\n\n**分析：**\n\n> 这题难度算是比较大的，我参考了一些资料最后才写出这个代码。其实这题也与bitsCount有着一定的联系。\n\n> 对于解这题有一个根本的公式即 \n    \n    a % m = ((b % m)(a/b) + (a % b)) % m\n    其中b是进制数\n\n> 我们知道，如果想要知道一个十进制的数能否被三整除，只要看它所有数位之和是否能被三整除就行了。其实这就是上述公式的特殊情况，由于10 mod 3 == 1 所以其就退化为\n\n    a mod m = (a/b + a % b) % m\n    递归下来就是所有数位之和\n\n> 而对于二进制的情况，我们可以将进制位b选为4，这样正好是两位二进制数，同时4 % 3 == 1，这样一来，对于二进制数中我们只需要统计所有两两数位(四进制)的和能否被三整除就行了。\n\n> 而考虑到我们每做一次 a/b + a % b 统计数位和都减小了数的规模，这样只要做有限次就能够将数控制在<=3的范围内。\n\n> 对于a % 4，这是一个经典的trivial情况，我们只需要做 a & 3，就能够轻松得到a % 4的值。而对于a/4，只需要做a >> 2即可。\n\n> 对于二进制数我们不仅可以按两位两位的四进制数位和来数，也可以直接数其倍数(4^i)，从最大4^8开始统计，一步步减小x的值，最后将x做到<= 3的范围\n\n> 最后要判断x是否为3，如果为3的话则要置为0，我利用3数位全为1的特点，将其+1进位后，右移2位。如果为3，则得到的是1。将其再加上x，如若x是1或2，则还是不变，但如果是3，它又会进位到4，那么我们只要再与上0x3，则会得到0，即为想要的结果。\n\n\n***\n\n### **3. float_f2i--float转int**\n\n**题目：**\n\n    输入一个按二进制位储存的float（以unsigned表示），将其转为int输出。(NaN,inf，溢出直接返回参数)\n\n**可使用操作：** 所有的整型操作，包括 ||, &&. 以及 if, while\n    \n**最大操作数限制：** 30\n\n**使用操作数：** 17\n\n**代码：**\n```cpp\nint float_f2i(unsigned uf)\n{\n   int sign, exp, frac, res;\n   unsigned int tmp;\n\n   if(!uf)\n      return 0;\n   sign = uf & 0x80000000;\n   exp = uf & 0x7f800000;\n   frac = (uf & 0x007fffff) | 0x00800000;\n\n   if(exp == 0x7f800000) //NaN and inf\n      return 0x80000000u;\n\n   exp >>= 23;\n\n   if(exp < 127)\n      return 0;\n   else if(exp > 158)\n      return 0x80000000u;\n   else if(exp > 150)\n      tmp = frac << (exp - 150);\n   else\n      tmp = frac >> (150 - exp);\n\n      \n   if(sign)\n      res = ~tmp + 1;\n   else\n      res = tmp;\n   \n   return res | sign;\n}\n```\n\n**分析：**\n\n> 这题特殊情况比较多，把NaN和inf处理一下，然后注意一下溢出情况，即取出来的exp - bias > 31，肯定超过2^31整型储存的最大值，直接返回0x80000000u，然后对于exp小于127的，其指数是负数，直接返回int值为0。对于在exp - bias 在 0 到 31 之间的，由于frac只有23位，所以要将注意一下讨论23的情况。\n\n> 最后把取出来的符号位对一下，如果负数取反加一，正数直接等，最后再或上符号位，返回答案。\n\n---\n\n## **结果截图**\n### **bits.c**\n\n![bits_btest](/img/ICS_Lab1/bits_btest.JPG)\n\n![bits_dlc](/img/ICS_Lab1/bits_dlc.png)\n\n### **bits_honor.c**\n\n![bits_honor_btest](/img/ICS_Lab1/bits_honor_btest.JPG)\n\n![bits_honor_dlc](/img/ICS_Lab1/bits_honor_dlc.png)\n\n\n\n## 参考\n***\n<https://baike.baidu.com/item/%E7%AE%97%E6%9C%AF%E5%8F%B3%E7%A7%BB/3711081?fr=aladdin>\n<https://blog.csdn.net/jiahonghao2002/article/details/108223366>\n<https://leetcode-cn.com/problems/reverse-bits/solution/dian-dao-er-jin-zhi-wei-by-leetcode/>\n<http://homepage.cs.uiowa.edu/~jones/bcd/mod.shtml#exmod3>\n<https://www.zhihu.com/question/38206659/answer/763034261>\n<https://blog.csdn.net/xindaxinda123/article/details/95617758>\n<https://www.runoob.com/w3cnote/32-float-storage.html>","source":"_posts/ICS/ICS_Lab1.md","raw":"---\ntitle: ICS-Lab1 位运算\nindex_img: /img/ICS_Lab1/top.jpg\ndate: 2020-11-05 23:58:42\ncategory: [ICS]\ntags: [Bits]\n---\n\n# ICS_Lab1-位运算\n\n> 这个是CS:APP的第一个lab，也是我ICS课上的第一个lab，主要注重于使用受限制的位运算来完成操作\n\n***\n\n## **Bits.c**\n### **1. bitAnd--与**\n**题目：**\n\n    只用~和|实现&\n\n**样例：**\n\n    bitAnd(6, 5) = 4\n\n**可使用操作：** ~ |\n    \n**最大操作数限制：** 8\n\n**使用操作数：** 4\n\n```cpp\nint bitAnd(int x, int y) {\n  return ~(~x | ~y); //De Morgan's laws\n}\n```\n\n> 应用摩根律 ~(x | y) = ~x & ~y, 可得 x & y = ~(~x | ~y)\n\n***\n\n### **2. getByte--获取字节**\n**题目：**\n\n    从x中提取字节n, n编号从0至3\n\n**样例：**\n\n    getByte(0x12345678,1) = 0x56\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 6\n\n**使用操作数：** 3\n\n**代码：**\n```cpp\nint getByte(int x, int n) {\n  return (x >> (n << 3)) & 0xff;\n}\n```\n\n**分析：**\n\n*由于 1Byte = 8bits = 2^3bits， 所以 n Bytes = 2^3 * n bits*\n> 因而将n左移3位，即 n * 2^3, 再将x右移 n * 2^3 即可将所求字节放在低8位，将其与上0xff，即可取出字节。\n\n***\n\n### **3. logicalShift--逻辑右移**\n**题目：**\n\n    将x逻辑右移n位\n\n**样例：**\n\n    logicalShift(0x87654321,4) = 0x08765432\n\n**可使用操作：**  ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 20\n\n**使用操作数：** 10\n\n**代码：**\n```cpp\nint logicalShift(int x, int n) {\n  //flag equals to: if n == 0 return 0; else return 1;\n  int flag = !!n;\n  int mask = ~(flag << (32 + (~n + 1)));\n  return (x >> n) & mask;\n}\n```\n\n**分析：**\n\n* 算数右移\n> 算数右移即在右移后用原符号位数将高位补齐，保持右移后二进制数的符号保持不变。\n\n* 逻辑右移\n> 逻辑右移即在右移后用 0 将高位补齐，是“逻辑上”的右移。\n\n> 在正常右移运算中使用的是算数右移，因而要解决的问题即对于负数如何将最高位补上0，而非符号位1。\n> 我采取掩码的方式，先将x正常右移n位与上其高位的掩码，使其右移产生的高位变为0\n\n* 掩码构造\n> 掩码不能草率的构造为 ~(-1 << (32 - n)), 这种构造方式当n为0时会因-1被左移32位而导致异常，构造出来的mask仍为0\n\n> 由于不能使用if，为判断n是否为0，我才用了一个flag = !n + ~0, 其有很好的性质。当n为0时，flag也为0，而当n不为零时，flag统一为-1，这样使用flag代替原先的-1, 从而避免上述情况。\n\n> 这样我们可以使用 mask = ~(flag << (32 + (~n + 1)))，来构造掩码，当n为0时，flag为0，从而mask = -1，避免上述错误。\n\n***\n\n### **4. bitCount--比特计数**\n**题目：**\n\n    返回二进制数中1的个数\n\n**样例：**\n\n    bitCount(5) = 2, bitCount(7) = 3\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 40\n\n**使用操作数：** 36\n\n**代码：**\n```cpp\nint bitCount(int x) {\n  int tmp, l1, l2, l4, l8, l16; //tmp is used to save ops\n  tmp = (0x55 << 8) + 0x55;\n  l1 = (tmp << 16) + tmp; //0x55555555\n  tmp = (0x33 << 8) + 0x33;\n  l2 = (tmp << 16) + tmp; //0x33333333\n  tmp = (0x0f << 8) + 0x0f;\n  l4 = (tmp << 16) + tmp; //0x0f0f0f0f\n  l8 = (0xff << 16) + 0xff; //0x00ff00ff\n  l16 = (0xff << 8) + 0xff; //0x0000ffff\n\n  x = (x & l1) + ((x >> 1) & l1);\n  x = (x & l2) + ((x >> 2) & l2);\n  x = (x & l4) + ((x >> 4) & l4);\n  x = (x & l8) + ((x >> 8) & l8);\n  x = (x & l16) + ((x >> 16) & l16);\n  return x;\n}\n```\n\n**分析：**\n\n* 分治思想\n> 本题使用了一个简单的分治思想，对于一个二进制数，要对其中为1的位做计数， 对于1位二进制数来说，1的个数无非就是其本身所表示的1或0。利用这个特性，我们可以先将一个二进制数每一位独立分开为相间隔的两部分, 其每位表示的就是自身的二进制个数，再将两串二进制数对其相加，所得到的每两位分隔的二进制数就是表达这个位置的位为1的个数。\n\n> 进一步相加为4位，8位其所代表的含义不变，最后合并至32位二进制数，其所表示的就是原二进制数中所含1的个数。\n\n```cpp\n//以八位二进制数 10101110 为例//\n按 1|0|1|0|1|1|1|0 分割， 为两串1|1|1|1和0|0|1|0，再将其合并，成为 01 | 01 | 10 | 01, 再将两串 01 | 10 和01 | 01合并得 0010 | 0011（这个很容易看出表示左四位有2个1，右四位有3个1），再次合并得 00000101, 得到总共有5个1。\n\n//对于32位二进制数亦按此继续操作即可//\n```\n\n> 于是为完成分割取位的操作，我们需要采用掩码\n\n* 0x55555555 \\ 0x33333333 \\ 0x0f0f0f0f \\ 0x0000ffff\n\n> 利用位运算分别构造，使用tmp可以节约ops, 之后按照分治思想进行操作即可。\n\n***\n\n### **5. bang--逻辑非**\n\n**题目：**\n\n    计算 !x 而不使用逻辑非!\n\n**样例：**\n\n    bang(3) = 0, bang(0) = 1\n\n**可使用操作：** ~ & ^ | + << >>\n    \n**最大操作数限制：** 12\n\n**使用操作数：** 6\n\n**代码：**\n```cpp\nint bang(int x) {\n  return ((x >> 31) | ((~x + 1) >> 31)) + 1;\n}\n```\n\n**分析：**\n\n* 逻辑非\n> 对于逻辑非运算，应该都很熟悉，!x 当且仅当x为0时其为1，其余时候都为0，可以用来区分零和非零数。\n\n> 该问题的关键就是在于如何区分零和非零数，我们知道零的二补码仍然是零，而对于其余非零数，其符号位会有相应改变，利用这一性质，我们可以对零和非零数做出区分。\n\n> 使用 ```((x >> 31) | ((~x + 1) >> 31))```，将二进制数x的符号位与其补码左移31位相与，如若是非零数，其中符号位至少有一个为1，所以经过31位的算数右移后，其中一项必为-1，一项为0，相与之后得到-1,。而对于0来说，结果始终为0。\n\n> 最后只要将结果+1，就能得到逻辑非的效果。\n\n***\n\n### **6. tmin--最小数**\n\n**题目：**\n\n    返回二补码中最小的数\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 4\n\n**使用操作数：** 1\n\n**代码：**\n```cpp\nint tmin(void) {\n  return 1 << 31;\n}\n```\n\n**分析：**\n\n> 此题非常简单，我们知道计算机中负数是用其补码表示的，int所能表示的最小数为0x80000000(-2^31), 即符号位为1，其余皆为0，所以只要将1左移31位即可。\n\n***\n\n### **7. fitsBits--填充比特**\n\n**题目：**\n\n    返回1如果x可以表示为n位二补码，反之返回0 (1 <= n <= 32)\n\n**样例：**\n\n    fitsBits(5,3) = 0, fitsBits(-4,3) = 1\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 15\n\n**使用操作数：** 7\n\n**代码：**\n```cpp\nint fitsBits(int x, int n) {\n  int k = x >> (n + ~0); // if can k = 0 or -1\n  return !k | !(k + 1);\n}\n```\n\n**分析：**\n\n> 我们知道如若一个数能够被n位二进制数表示，则其第n位即最高位是符号位，那么将其右移n-1位后，根据算术右移，其得到的结果不是0，就是1。否则表示，其还有高于n位的位数， 即不能用n位表示。\n\n> 所以用 k = x >> (n + ~0) 表示将其右移n-1位，再用 !k | !(k + 1) 判断k是否为0或-1\n\n***\n\n### **8. divpwr2--除以2的n次方**\n\n**题目：**\n\n    计算 x/(2^n), (0 <= n <= 30)\n\n**样例：**\n\n    divpwr2(15,1) = 7, divpwr2(-33,4) = -2\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 15\n\n**使用操作数：** 7\n\n**代码：**\n```cpp\nint divpwr2(int x, int n) {\n    int sign = x >> 31;\n    int bias = (1 << n) + ~0;\n    x = x + (bias & sign);\n    return x >> n;\n}\n```\n\n**分析：**\n\n> 本题的难点在于Round toward zero, 我们知道除以2的n次方即为将x右移n位。对于正数，尾数截断，因而自然向0舍入。而对于负数则不是如此，经试验在gcc上对于负数，其是向偶数舍入的，因而我们要对负数进行操作。\n\n> 同时由于其向偶数舍入，我们不能简单地对负数进行+1操作，例如原本正确的 -7/4 = -1.25 = -1，但是经过+1操作后变为-6/4 = -1.5 Round toward even则变为了2。所以我们不应简单加一，而是加一个偏差值，其为2^n - 1，对于-7/4来说，就是3，加上bias之后得到(-7 + 3)/4即为-1。\n\n> 所以我们构造bias = (1 << n) + ~0 (由于不能用减号，-1用+~0表示)，然后我们要记得将sign取出，在x进行加操作时先检查一下x是否是负数，再进行操作。最后只要方向的将x右移n位即可。\n\n\n***\n\n### **9. negate--取负**\n\n**题目：**\n\n    返回-x\n\n**样例：**\n\n    negate(1) = -1.\n\n**可使用操作：**  ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 5\n\n**使用操作数：** 2\n\n**代码：**\n```cpp\nint negate(int x) {\n  return ~x + 1;\n}\n```\n\n**分析：**\n\n> 很简单，对于有符号二进制数取负就是取其补码，而补码等于其取反加一，返回取反加一即可。\n\n***\n\n### **10. isPositive--是正数**\n\n**题目：**\n\n    返回1如果x大于0，反之返回0\n\n**样例：**\n\n    isPositive(-1) = 0.\n\n**可使用操作：**  ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 8\n\n**使用操作数：** 5\n\n**代码：**\n```cpp\nint isPositive(int x) {\n  return !(x >> 31) & !!x;\n}\n```\n\n**分析：**\n> 这题关键在于把0剔除了，区分正负数就是区分其符号位，将x右移31位，负数得-1，正数为0，用一个逻辑非使正数为1，负数为0，然后再和!!x与一下就能剔除0\n\n* !!x 当 x == 0 时返回 0，不为 0 时返回 1\n\n***\n\n### **11. isLessOrEqual--小于等于**\n\n**题目：**\n\n    如果x小于等于y返回1，反之返回0\n\n**样例：**\n\n    isLessOrEqual(4,5) = 1.\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 24\n\n**使用操作数：** 14\n\n**代码：**\n```cpp\nint isLessOrEqual(int x, int y) {\n  int res = y + (~x + 1); // y - x\n  int xSign = x >> 31;\n  int ySign = y >> 31;\n  int dif = ~xSign + ySign;\n  return (~(dif + 1 >> 31) & !(res >> 31)) | !dif;\n}\n```\n\n**分析：**\n> 我在这里采取了作差的方法 res = y + (~x + 1)，即计算一下y-x，判断其是否非负，同时也要考虑溢出问题，即 x 为负数，y为正数，y-x后溢出为负。\n\n> 我将x,y右移31位代表其符号，若负则为-1，若正为0。我同时构造了一个 dif 以表示x,y符号之间的关系。\n\n> **dif = ~xSign + ySign**\n1.  当 x < 0 && y < 0 时，dif = -1 \n2.  当 x < 0 && y > 0 时，dif = 0 \n3.  当 x > 0 && y < 0 时，dif = -2 \n4.  当 x > 0 && y < 0 时，dif = -1\n\n> 将 x,y 符号之间的关系表达出来，把 dif 加一我们可以观察到当 x,y 同号时，dif为0，所以将其取反和 !(res >> 31) 相与，就可以表示同号不溢出的情况，而当 x < 0, y > 0 的情况发生时，我们注意到 dif 就是 0 ，所以我们直接或上 !dif 即可表达这种情况。\n\n***\n\n### **12. ilog2--以2为底的对数**\n\n**题目：**\n\n    返回x取以2为底的对数并向下取整，输入的 x > 0\n\n**样例：**\n\n    ilog2(16) = 4\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 90\n\n**使用操作数：** 48\n\n**代码：**\n\n```cpp\nint ilog2(int x) {\n  int tmp, l1, l2, l4, l8, l16;\n  x |= x >> 1;\n  x |= x >> 2;\n  x |= x >> 4;\n  x |= x >> 8;\n  x |= x >> 16;\n  \n  tmp = (0x55 << 8) + 0x55;\n  l1 = (tmp << 16) + tmp;\n  tmp = (0x33 << 8) + 0x33;\n  l2 = (tmp << 16) + tmp;\n  tmp = (0x0f << 8) + 0x0f;\n  l4 = (tmp << 16) + tmp;\n  l8 = (0xff << 16) + 0xff;\n  l16 = (0xff << 8) + 0xff;\n\n  x = (x & l1) + ((x >> 1) & l1);\n  x = (x & l2) + ((x >> 2) & l2);\n  x = (x & l4) + ((x >> 4) & l4);\n  x = (x & l8) + ((x >> 8) & l8);\n  x = (x & l16) + ((x >> 16) & l16);\n  return x + ~0;\n```\n\n**分析：**\n\n> 我们知道二进制数每位有其位权，所以对 x 取以2为底的对数就是指其为1的最高位的位权。为了获得最高位的位置，其实我们可以将其最高位往下全部变为1，再类似bitsCount数其中1的个数就行了。\n\n> 我把 x 移位相与，保证最高位往下所有数字为1，再使用bitsCount就得到答案。\n\n> 最后不要忘记减一\n\n\n***\n\n### **13. float_neg--浮点数的负数**\n\n**题目：**\n\n    返回-f，当NaN时，返回参数f\n\n**可使用操作：** 所有的整型操作，包括 ||, &&. 以及 if, while\n    \n**最大操作数限制：** 10\n\n**使用操作数：** 5\n\n**代码：**\n```cpp\nunsigned float_neg(unsigned uf) {\n  unsigned exp = uf & 0x7f800000;\n  unsigned frac = uf & 0x007fffff;\n  if(exp == 0x7f800000 && frac)\n    return uf;\n  return uf ^= 0x80000000;\n}\n```\n\n**分析：**\n* IEEE-float\n> 我们知道IEEE单精度浮点数，最高位为符号位，其后8位为阶码exp，后23位为尾数frac。其牺牲了精度来扩大了表达范围。\n\n> 而当 exp 全 1 时，如若frac非全零，则表示NaN。若全零，则表示无穷大/小。\n\n> 这里我们只要将原数和符号位0x80000000异或一下，即可取负。不要忘记排除NaN的情况。\n\n***\n\n### **14. float_i2f--int转float**\n\n**题目：**\n\n    把int类型的数转换为float表示(比特形式)\n\n**可使用操作：** 所有的整型操作，包括 ||, &&. 以及 if, while\n    \n**最大操作数限制：** 30\n\n**使用操作数：** 30\n\n**代码：**\n\n```cpp\nunsigned float_i2f(int x) {\n  unsigned frac, mask1, mask2, mask3, mask4, d;\n  int high = 0x80000000;\n  unsigned sign = x & 0x80000000;\n  unsigned exp = 127;\n  int count = 32, i;\n  if(sign)\n    x = ~x + 1;\n  else if(!x)\n    return x;\n  \n  frac = x;\n\n  for(;high; high >>= 1)\n  {\n    --count;\n    if(high & x)\n      break;\n  }\n  i = count - 23;\n  mask1 = ~(1 << count); // the highest 1\n  mask2 = 1 << i; //the lowest of remain frac;\n  mask3 = mask2 >> 1; // the highest of deserted bits \n  mask4 = mask2 - 1; // the deserted bits\n  exp += count;\n\n  frac &= mask1;\n  \n  if(i > 0)\n  {\n    d = frac & mask4; // deserted bits\n    if(d > mask3 | (d == mask3 && frac & mask2))\n    {\n      frac += mask2;\n      if(frac > 0x3fffffff)\n      {\n        frac = 0;\n        exp++;\n      }\n    }\n    frac >>= i;\n  }\n  else\n    frac <<= -i;\n\n  return sign | exp << 23 | frac;\n}\n```\n\n**分析：**\n\n> 我认为这题比较难，我做了很久很久....它难在浮点数向偶数舍入以及其操作数的限制。\n\n> 我们知道由于浮点数表示范围比整型大，我们可以将整型转换为浮点数，但是相应的会有一些精度的丢失，因为尾数frac只有23位，而int有31位可用。\n\n> 所以其关键在于int的位数，一开始先把该取出来的都用掩码取出来，把负数和零处理一下。之后我利用了一个循环先找出int的最高位在哪，利用count计数。\n\n> 后面我采取了四个掩码，分别代表最高位的1，留下的尾数中的最低位，要舍去的位数的最高位，以及舍弃的位数的掩码。利用这四个掩码我们可以达到存frac时，将其向**偶数舍入**。\n\n> 具体操作是，先取出丢弃的尾数，将其存放在d中，看其有没有超过0.5 (即 d 是否大于 mask3) 如果大于，直接frac++就行。而如果等于的话，还要看frac是否是奇数 (即frac & mask2是否为1) 如果是，则要向偶数舍入,frac++。\n\n> 加完frac之后还要注意**溢出问题**，如果溢出了，要将frac置0，然后把阶码 exp++，再按照之前输出来的尾数移动，将尾数对齐即可 （位数最高默认为1不存，因而把最高位隐去）。\n\n> 最后把符号位，阶码位和尾数位拼接，得到最后的结果。\n\n***\n\n### 15. float_twice--float * 2\n\n**题目：**\n\n    返回float * 2, 当参数是NaN时，返回参数\n\n**可使用操作：** 所有的整型操作，包括 ||, &&. 以及 if, while\n    \n**最大操作数限制：** 30\n\n**使用操作数：** 20\n\n**代码：**\n```cpp\nunsigned float_twice(unsigned uf) {\n  unsigned sign = uf & 0x80000000;\n  unsigned exp = uf & 0x7f800000;\n  unsigned frac = uf & 0x007fffff;\n  if(exp == 0x7f800000) //NaN & inf\n    return uf;\n  if(!exp && !frac) // 0\n    return uf;\n  if(!exp && frac <= 0x3fffff)  // low\n    frac *= 2;\n  else if(!exp && frac > 0x3fffff) // high\n  {\n    exp += 0x00800000;\n    frac = (frac * 2) & 0x7fffff;\n  }\n  else // normal\n    exp += 0x00800000;\n  return sign + exp + frac;\n}\n```\n\n**分析：**\n> 主要要分析的地方，在于当阶码exp为0时，是否在乘2之后进位。所以要考虑尾数是否大于0x3fffff，如果小于等于之，则直接尾数乘2就行，不会溢出，否则则exp要进位，同时尾数乘2之后要与上0x7fffff保证不溢出。\n\n> 其他正常情况直接exp++就行，注意一下特殊情况;\n\n*本题中测试集中有一个inf，也要直接返回参数uf*\n\n***\n\n## **Bits_honor.c**\n### **1. bitReverse--比特翻转**\n\n**题目：**\n\n    把32比特int的比特位翻转\n\n**样例：**\n\n    bitReverse(0x80000004) = 0x20000001\n    bitReverse(0x7FFFFFFF) = 0xFFFFFFFE\n    \n**最大操作数限制：** 40\n\n**使用操作数：** 40\n\n**代码：**\n```cpp\nint bitReverse(int x)\n{\n   int tmp,l1, l2, l4, l8, l16;\n\n   tmp = (0x55 << 8) + 0x55;\n   l1 = (tmp << 16) + tmp;\n   tmp = (0x33 << 8) + 0x33;\n   l2 = (tmp << 16) + tmp;\n   tmp = (0x0f << 8) + 0x0f;\n   l4 = (tmp << 16) + tmp;\n   l8 = (0xff << 16) + 0xff;\n   l16 = (0xff << 8) + 0xff;\n\n   x = ((x >> 16) & l16) | (x << 16);\n   x = ((x >> 8) & l8) | ((x & l8) << 8);\n   x = ((x >> 4) & l4) | ((x & l4) << 4);\n   x = ((x >> 2) & l2) | ((x & l2) << 2);\n   x = ((x >> 1) & l1) | ((x & l1) << 1);\n   return x;\n}\n```\n\n**分析：**\n\n> 这题和 bitsCount 有异曲同工之妙，也是一个分治法，将32位二进制数一分为二，交换，再将内部各自再一分为二，交换，直至最底层2位二进制数互换位置，最后完成了将所有位数翻转的工作。\n\n> 但值得注意的是，给出的是有符号的int，所以在右移交换位置时，会发生因为负数算术右移导致高位全是1的情况，致使在与的过程中高位全部变为1。这边只要将其移动后在和掩码相与就能解决这一问题。而对于低位，先与掩码相与再移动，可以省去取反得到高位掩码的操作数。再用tmp省一下操作数。\n\n> 最后操作数正好卡在40\n\n***\n\n### **2. mod3--取模3**\n\n**题目：**\n\n    计算 x 取模 3，而不用%\n\n**样例：**\n\n    mod3(100) = 1\n    mod3(-100) = -1\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 90\n\n**使用操作数：** 24\n\n**代码：**\n```cpp\nint mod3(int x)\n{\n   int mask = (0xff << 8) + 0xff;\n\n   x = (x >> 16) + (x & mask); // sum base 4^8 digits (a <= 0x1FFFE)\n   x = (x >> 8) + (x & 0xff); // sum base 4^4 digits (a <= 0x2FD)\n   x = (x >> 4) + (x & 0xf); // sum base 4^2 digits (a <= 0x3C)\n   x = (x >> 2) + (x & 0x3); // sum base 4^1 digits (a <= 0x1D)\n   x = (x >> 2) + (x & 0x3); // sum base 4^1 digits (a <= 0x9)\n   x = (x >> 2) + (x & 0x3); // sum base 4^1 digits (a <= 0x4)\n\n   x = (((x + 1) >> 2) + x) & 0x3;\n   return x;\n}\n```\n\n**分析：**\n\n> 这题难度算是比较大的，我参考了一些资料最后才写出这个代码。其实这题也与bitsCount有着一定的联系。\n\n> 对于解这题有一个根本的公式即 \n    \n    a % m = ((b % m)(a/b) + (a % b)) % m\n    其中b是进制数\n\n> 我们知道，如果想要知道一个十进制的数能否被三整除，只要看它所有数位之和是否能被三整除就行了。其实这就是上述公式的特殊情况，由于10 mod 3 == 1 所以其就退化为\n\n    a mod m = (a/b + a % b) % m\n    递归下来就是所有数位之和\n\n> 而对于二进制的情况，我们可以将进制位b选为4，这样正好是两位二进制数，同时4 % 3 == 1，这样一来，对于二进制数中我们只需要统计所有两两数位(四进制)的和能否被三整除就行了。\n\n> 而考虑到我们每做一次 a/b + a % b 统计数位和都减小了数的规模，这样只要做有限次就能够将数控制在<=3的范围内。\n\n> 对于a % 4，这是一个经典的trivial情况，我们只需要做 a & 3，就能够轻松得到a % 4的值。而对于a/4，只需要做a >> 2即可。\n\n> 对于二进制数我们不仅可以按两位两位的四进制数位和来数，也可以直接数其倍数(4^i)，从最大4^8开始统计，一步步减小x的值，最后将x做到<= 3的范围\n\n> 最后要判断x是否为3，如果为3的话则要置为0，我利用3数位全为1的特点，将其+1进位后，右移2位。如果为3，则得到的是1。将其再加上x，如若x是1或2，则还是不变，但如果是3，它又会进位到4，那么我们只要再与上0x3，则会得到0，即为想要的结果。\n\n\n***\n\n### **3. float_f2i--float转int**\n\n**题目：**\n\n    输入一个按二进制位储存的float（以unsigned表示），将其转为int输出。(NaN,inf，溢出直接返回参数)\n\n**可使用操作：** 所有的整型操作，包括 ||, &&. 以及 if, while\n    \n**最大操作数限制：** 30\n\n**使用操作数：** 17\n\n**代码：**\n```cpp\nint float_f2i(unsigned uf)\n{\n   int sign, exp, frac, res;\n   unsigned int tmp;\n\n   if(!uf)\n      return 0;\n   sign = uf & 0x80000000;\n   exp = uf & 0x7f800000;\n   frac = (uf & 0x007fffff) | 0x00800000;\n\n   if(exp == 0x7f800000) //NaN and inf\n      return 0x80000000u;\n\n   exp >>= 23;\n\n   if(exp < 127)\n      return 0;\n   else if(exp > 158)\n      return 0x80000000u;\n   else if(exp > 150)\n      tmp = frac << (exp - 150);\n   else\n      tmp = frac >> (150 - exp);\n\n      \n   if(sign)\n      res = ~tmp + 1;\n   else\n      res = tmp;\n   \n   return res | sign;\n}\n```\n\n**分析：**\n\n> 这题特殊情况比较多，把NaN和inf处理一下，然后注意一下溢出情况，即取出来的exp - bias > 31，肯定超过2^31整型储存的最大值，直接返回0x80000000u，然后对于exp小于127的，其指数是负数，直接返回int值为0。对于在exp - bias 在 0 到 31 之间的，由于frac只有23位，所以要将注意一下讨论23的情况。\n\n> 最后把取出来的符号位对一下，如果负数取反加一，正数直接等，最后再或上符号位，返回答案。\n\n---\n\n## **结果截图**\n### **bits.c**\n\n![bits_btest](/img/ICS_Lab1/bits_btest.JPG)\n\n![bits_dlc](/img/ICS_Lab1/bits_dlc.png)\n\n### **bits_honor.c**\n\n![bits_honor_btest](/img/ICS_Lab1/bits_honor_btest.JPG)\n\n![bits_honor_dlc](/img/ICS_Lab1/bits_honor_dlc.png)\n\n\n\n## 参考\n***\n<https://baike.baidu.com/item/%E7%AE%97%E6%9C%AF%E5%8F%B3%E7%A7%BB/3711081?fr=aladdin>\n<https://blog.csdn.net/jiahonghao2002/article/details/108223366>\n<https://leetcode-cn.com/problems/reverse-bits/solution/dian-dao-er-jin-zhi-wei-by-leetcode/>\n<http://homepage.cs.uiowa.edu/~jones/bcd/mod.shtml#exmod3>\n<https://www.zhihu.com/question/38206659/answer/763034261>\n<https://blog.csdn.net/xindaxinda123/article/details/95617758>\n<https://www.runoob.com/w3cnote/32-float-storage.html>","slug":"ICS/ICS_Lab1","published":1,"updated":"2026-02-03T05:42:14.432Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvg002v7uith4qta0c1","content":"<h1 id=\"ICS-Lab1-位运算\"><a href=\"#ICS-Lab1-位运算\" class=\"headerlink\" title=\"ICS_Lab1-位运算\"></a>ICS_Lab1-位运算</h1><blockquote>\n<p>这个是CS:APP的第一个lab，也是我ICS课上的第一个lab，主要注重于使用受限制的位运算来完成操作</p>\n</blockquote>\n<hr>\n<h2 id=\"Bits-c\"><a href=\"#Bits-c\" class=\"headerlink\" title=\"Bits.c\"></a><strong>Bits.c</strong></h2><h3 id=\"1-bitAnd—与\"><a href=\"#1-bitAnd—与\" class=\"headerlink\" title=\"1. bitAnd—与\"></a><strong>1. bitAnd—与</strong></h3><p><strong>题目：</strong></p>\n<pre><code>只用~和|实现&amp;\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>bitAnd(6, 5) = 4\n</code></pre><p><strong>可使用操作：</strong> ~ |</p>\n<p><strong>最大操作数限制：</strong> 8</p>\n<p><strong>使用操作数：</strong> 4</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">bitAnd</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> y)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> ~(~x | ~y); <span class=\"hljs-comment\">//De Morgan&#x27;s laws</span>\n&#125;</code></pre>\n<blockquote>\n<p>应用摩根律 ~(x | y) = ~x &amp; ~y, 可得 x &amp; y = ~(~x | ~y)</p>\n</blockquote>\n<hr>\n<h3 id=\"2-getByte—获取字节\"><a href=\"#2-getByte—获取字节\" class=\"headerlink\" title=\"2. getByte—获取字节\"></a><strong>2. getByte—获取字节</strong></h3><p><strong>题目：</strong></p>\n<pre><code>从x中提取字节n, n编号从0至3\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>getByte(0x12345678,1) = 0x56\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 6</p>\n<p><strong>使用操作数：</strong> 3</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">getByte</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> (x &gt;&gt; (n &lt;&lt; <span class=\"hljs-number\">3</span>)) &amp; <span class=\"hljs-number\">0xff</span>;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<p><em>由于 1Byte = 8bits = 2^3bits， 所以 n Bytes = 2^3 </em> n bits*</p>\n<blockquote>\n<p>因而将n左移3位，即 n <em> 2^3, 再将x右移 n </em> 2^3 即可将所求字节放在低8位，将其与上0xff，即可取出字节。</p>\n</blockquote>\n<hr>\n<h3 id=\"3-logicalShift—逻辑右移\"><a href=\"#3-logicalShift—逻辑右移\" class=\"headerlink\" title=\"3. logicalShift—逻辑右移\"></a><strong>3. logicalShift—逻辑右移</strong></h3><p><strong>题目：</strong></p>\n<pre><code>将x逻辑右移n位\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>logicalShift(0x87654321,4) = 0x08765432\n</code></pre><p><strong>可使用操作：</strong>  ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 20</p>\n<p><strong>使用操作数：</strong> 10</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">logicalShift</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;\n  <span class=\"hljs-comment\">//flag equals to: if n == 0 return 0; else return 1;</span>\n  <span class=\"hljs-keyword\">int</span> flag = !!n;\n  <span class=\"hljs-keyword\">int</span> mask = ~(flag &lt;&lt; (<span class=\"hljs-number\">32</span> + (~n + <span class=\"hljs-number\">1</span>)));\n  <span class=\"hljs-keyword\">return</span> (x &gt;&gt; n) &amp; mask;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<ul>\n<li><p>算数右移</p>\n<blockquote>\n<p>算数右移即在右移后用原符号位数将高位补齐，保持右移后二进制数的符号保持不变。</p>\n</blockquote>\n</li>\n<li><p>逻辑右移</p>\n<blockquote>\n<p>逻辑右移即在右移后用 0 将高位补齐，是“逻辑上”的右移。</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>在正常右移运算中使用的是算数右移，因而要解决的问题即对于负数如何将最高位补上0，而非符号位1。<br>我采取掩码的方式，先将x正常右移n位与上其高位的掩码，使其右移产生的高位变为0</p>\n</blockquote>\n<ul>\n<li>掩码构造<blockquote>\n<p>掩码不能草率的构造为 ~(-1 &lt;&lt; (32 - n)), 这种构造方式当n为0时会因-1被左移32位而导致异常，构造出来的mask仍为0</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>由于不能使用if，为判断n是否为0，我才用了一个flag = !n + ~0, 其有很好的性质。当n为0时，flag也为0，而当n不为零时，flag统一为-1，这样使用flag代替原先的-1, 从而避免上述情况。</p>\n<p>这样我们可以使用 mask = ~(flag &lt;&lt; (32 + (~n + 1)))，来构造掩码，当n为0时，flag为0，从而mask = -1，避免上述错误。</p>\n</blockquote>\n<hr>\n<h3 id=\"4-bitCount—比特计数\"><a href=\"#4-bitCount—比特计数\" class=\"headerlink\" title=\"4. bitCount—比特计数\"></a><strong>4. bitCount—比特计数</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回二进制数中1的个数\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>bitCount(5) = 2, bitCount(7) = 3\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 40</p>\n<p><strong>使用操作数：</strong> 36</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">bitCount</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">int</span> tmp, l1, l2, l4, l8, l16; <span class=\"hljs-comment\">//tmp is used to save ops</span>\n  tmp = (<span class=\"hljs-number\">0x55</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x55</span>;\n  l1 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp; <span class=\"hljs-comment\">//0x55555555</span>\n  tmp = (<span class=\"hljs-number\">0x33</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x33</span>;\n  l2 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp; <span class=\"hljs-comment\">//0x33333333</span>\n  tmp = (<span class=\"hljs-number\">0x0f</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x0f</span>;\n  l4 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp; <span class=\"hljs-comment\">//0x0f0f0f0f</span>\n  l8 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">16</span>) + <span class=\"hljs-number\">0xff</span>; <span class=\"hljs-comment\">//0x00ff00ff</span>\n  l16 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0xff</span>; <span class=\"hljs-comment\">//0x0000ffff</span>\n\n  x = (x &amp; l1) + ((x &gt;&gt; <span class=\"hljs-number\">1</span>) &amp; l1);\n  x = (x &amp; l2) + ((x &gt;&gt; <span class=\"hljs-number\">2</span>) &amp; l2);\n  x = (x &amp; l4) + ((x &gt;&gt; <span class=\"hljs-number\">4</span>) &amp; l4);\n  x = (x &amp; l8) + ((x &gt;&gt; <span class=\"hljs-number\">8</span>) &amp; l8);\n  x = (x &amp; l16) + ((x &gt;&gt; <span class=\"hljs-number\">16</span>) &amp; l16);\n  <span class=\"hljs-keyword\">return</span> x;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<ul>\n<li>分治思想<blockquote>\n<p>本题使用了一个简单的分治思想，对于一个二进制数，要对其中为1的位做计数， 对于1位二进制数来说，1的个数无非就是其本身所表示的1或0。利用这个特性，我们可以先将一个二进制数每一位独立分开为相间隔的两部分, 其每位表示的就是自身的二进制个数，再将两串二进制数对其相加，所得到的每两位分隔的二进制数就是表达这个位置的位为1的个数。</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>进一步相加为4位，8位其所代表的含义不变，最后合并至32位二进制数，其所表示的就是原二进制数中所含1的个数。</p>\n</blockquote>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">//以八位二进制数 10101110 为例//</span>\n按 <span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">0</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">0</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">0</span> 分割， 为两串<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">1</span>和<span class=\"hljs-number\">0</span>|<span class=\"hljs-number\">0</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">0</span>，再将其合并，成为 <span class=\"hljs-number\">01</span> | <span class=\"hljs-number\">01</span> | <span class=\"hljs-number\">10</span> | <span class=\"hljs-number\">01</span>, 再将两串 <span class=\"hljs-number\">01</span> | <span class=\"hljs-number\">10</span> 和<span class=\"hljs-number\">01</span> | <span class=\"hljs-number\">01</span>合并得 <span class=\"hljs-number\">0010</span> | <span class=\"hljs-number\">0011</span>（这个很容易看出表示左四位有<span class=\"hljs-number\">2</span>个<span class=\"hljs-number\">1</span>，右四位有<span class=\"hljs-number\">3</span>个<span class=\"hljs-number\">1</span>），再次合并得 <span class=\"hljs-number\">00000101</span>, 得到总共有<span class=\"hljs-number\">5</span>个<span class=\"hljs-number\">1</span>。\n\n<span class=\"hljs-comment\">//对于32位二进制数亦按此继续操作即可//</span></code></pre>\n<blockquote>\n<p>于是为完成分割取位的操作，我们需要采用掩码</p>\n</blockquote>\n<ul>\n<li>0x55555555 \\ 0x33333333 \\ 0x0f0f0f0f \\ 0x0000ffff</li>\n</ul>\n<blockquote>\n<p>利用位运算分别构造，使用tmp可以节约ops, 之后按照分治思想进行操作即可。</p>\n</blockquote>\n<hr>\n<h3 id=\"5-bang—逻辑非\"><a href=\"#5-bang—逻辑非\" class=\"headerlink\" title=\"5. bang—逻辑非\"></a><strong>5. bang—逻辑非</strong></h3><p><strong>题目：</strong></p>\n<pre><code>计算 !x 而不使用逻辑非!\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>bang(3) = 0, bang(0) = 1\n</code></pre><p><strong>可使用操作：</strong> ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 12</p>\n<p><strong>使用操作数：</strong> 6</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">bang</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> ((x &gt;&gt; <span class=\"hljs-number\">31</span>) | ((~x + <span class=\"hljs-number\">1</span>) &gt;&gt; <span class=\"hljs-number\">31</span>)) + <span class=\"hljs-number\">1</span>;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<ul>\n<li>逻辑非<blockquote>\n<p>对于逻辑非运算，应该都很熟悉，!x 当且仅当x为0时其为1，其余时候都为0，可以用来区分零和非零数。</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>该问题的关键就是在于如何区分零和非零数，我们知道零的二补码仍然是零，而对于其余非零数，其符号位会有相应改变，利用这一性质，我们可以对零和非零数做出区分。</p>\n<p>使用 <code>((x &gt;&gt; 31) | ((~x + 1) &gt;&gt; 31))</code>，将二进制数x的符号位与其补码左移31位相与，如若是非零数，其中符号位至少有一个为1，所以经过31位的算数右移后，其中一项必为-1，一项为0，相与之后得到-1,。而对于0来说，结果始终为0。</p>\n<p>最后只要将结果+1，就能得到逻辑非的效果。</p>\n</blockquote>\n<hr>\n<h3 id=\"6-tmin—最小数\"><a href=\"#6-tmin—最小数\" class=\"headerlink\" title=\"6. tmin—最小数\"></a><strong>6. tmin—最小数</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回二补码中最小的数\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 4</p>\n<p><strong>使用操作数：</strong> 1</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">tmin</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">1</span> &lt;&lt; <span class=\"hljs-number\">31</span>;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>此题非常简单，我们知道计算机中负数是用其补码表示的，int所能表示的最小数为0x80000000(-2^31), 即符号位为1，其余皆为0，所以只要将1左移31位即可。</p>\n</blockquote>\n<hr>\n<h3 id=\"7-fitsBits—填充比特\"><a href=\"#7-fitsBits—填充比特\" class=\"headerlink\" title=\"7. fitsBits—填充比特\"></a><strong>7. fitsBits—填充比特</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回1如果x可以表示为n位二补码，反之返回0 (1 &lt;= n &lt;= 32)\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>fitsBits(5,3) = 0, fitsBits(-4,3) = 1\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 15</p>\n<p><strong>使用操作数：</strong> 7</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">fitsBits</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;\n  <span class=\"hljs-keyword\">int</span> k = x &gt;&gt; (n + ~<span class=\"hljs-number\">0</span>); <span class=\"hljs-comment\">// if can k = 0 or -1</span>\n  <span class=\"hljs-keyword\">return</span> !k | !(k + <span class=\"hljs-number\">1</span>);\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>我们知道如若一个数能够被n位二进制数表示，则其第n位即最高位是符号位，那么将其右移n-1位后，根据算术右移，其得到的结果不是0，就是1。否则表示，其还有高于n位的位数， 即不能用n位表示。</p>\n<p>所以用 k = x &gt;&gt; (n + ~0) 表示将其右移n-1位，再用 !k | !(k + 1) 判断k是否为0或-1</p>\n</blockquote>\n<hr>\n<h3 id=\"8-divpwr2—除以2的n次方\"><a href=\"#8-divpwr2—除以2的n次方\" class=\"headerlink\" title=\"8. divpwr2—除以2的n次方\"></a><strong>8. divpwr2—除以2的n次方</strong></h3><p><strong>题目：</strong></p>\n<pre><code>计算 x/(2^n), (0 &lt;= n &lt;= 30)\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>divpwr2(15,1) = 7, divpwr2(-33,4) = -2\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 15</p>\n<p><strong>使用操作数：</strong> 7</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">divpwr2</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;\n    <span class=\"hljs-keyword\">int</span> sign = x &gt;&gt; <span class=\"hljs-number\">31</span>;\n    <span class=\"hljs-keyword\">int</span> bias = (<span class=\"hljs-number\">1</span> &lt;&lt; n) + ~<span class=\"hljs-number\">0</span>;\n    x = x + (bias &amp; sign);\n    <span class=\"hljs-keyword\">return</span> x &gt;&gt; n;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>本题的难点在于Round toward zero, 我们知道除以2的n次方即为将x右移n位。对于正数，尾数截断，因而自然向0舍入。而对于负数则不是如此，经试验在gcc上对于负数，其是向偶数舍入的，因而我们要对负数进行操作。</p>\n<p>同时由于其向偶数舍入，我们不能简单地对负数进行+1操作，例如原本正确的 -7/4 = -1.25 = -1，但是经过+1操作后变为-6/4 = -1.5 Round toward even则变为了2。所以我们不应简单加一，而是加一个偏差值，其为2^n - 1，对于-7/4来说，就是3，加上bias之后得到(-7 + 3)/4即为-1。</p>\n<p>所以我们构造bias = (1 &lt;&lt; n) + ~0 (由于不能用减号，-1用+~0表示)，然后我们要记得将sign取出，在x进行加操作时先检查一下x是否是负数，再进行操作。最后只要方向的将x右移n位即可。</p>\n</blockquote>\n<hr>\n<h3 id=\"9-negate—取负\"><a href=\"#9-negate—取负\" class=\"headerlink\" title=\"9. negate—取负\"></a><strong>9. negate—取负</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回-x\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>negate(1) = -1.\n</code></pre><p><strong>可使用操作：</strong>  ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 5</p>\n<p><strong>使用操作数：</strong> 2</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">negate</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> ~x + <span class=\"hljs-number\">1</span>;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>很简单，对于有符号二进制数取负就是取其补码，而补码等于其取反加一，返回取反加一即可。</p>\n</blockquote>\n<hr>\n<h3 id=\"10-isPositive—是正数\"><a href=\"#10-isPositive—是正数\" class=\"headerlink\" title=\"10. isPositive—是正数\"></a><strong>10. isPositive—是正数</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回1如果x大于0，反之返回0\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>isPositive(-1) = 0.\n</code></pre><p><strong>可使用操作：</strong>  ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 8</p>\n<p><strong>使用操作数：</strong> 5</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">isPositive</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> !(x &gt;&gt; <span class=\"hljs-number\">31</span>) &amp; !!x;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>这题关键在于把0剔除了，区分正负数就是区分其符号位，将x右移31位，负数得-1，正数为0，用一个逻辑非使正数为1，负数为0，然后再和!!x与一下就能剔除0</p>\n</blockquote>\n<ul>\n<li>!!x 当 x == 0 时返回 0，不为 0 时返回 1</li>\n</ul>\n<hr>\n<h3 id=\"11-isLessOrEqual—小于等于\"><a href=\"#11-isLessOrEqual—小于等于\" class=\"headerlink\" title=\"11. isLessOrEqual—小于等于\"></a><strong>11. isLessOrEqual—小于等于</strong></h3><p><strong>题目：</strong></p>\n<pre><code>如果x小于等于y返回1，反之返回0\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>isLessOrEqual(4,5) = 1.\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 24</p>\n<p><strong>使用操作数：</strong> 14</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">isLessOrEqual</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> y)</span> </span>&#123;\n  <span class=\"hljs-keyword\">int</span> res = y + (~x + <span class=\"hljs-number\">1</span>); <span class=\"hljs-comment\">// y - x</span>\n  <span class=\"hljs-keyword\">int</span> xSign = x &gt;&gt; <span class=\"hljs-number\">31</span>;\n  <span class=\"hljs-keyword\">int</span> ySign = y &gt;&gt; <span class=\"hljs-number\">31</span>;\n  <span class=\"hljs-keyword\">int</span> dif = ~xSign + ySign;\n  <span class=\"hljs-keyword\">return</span> (~(dif + <span class=\"hljs-number\">1</span> &gt;&gt; <span class=\"hljs-number\">31</span>) &amp; !(res &gt;&gt; <span class=\"hljs-number\">31</span>)) | !dif;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>我在这里采取了作差的方法 res = y + (~x + 1)，即计算一下y-x，判断其是否非负，同时也要考虑溢出问题，即 x 为负数，y为正数，y-x后溢出为负。</p>\n<p>我将x,y右移31位代表其符号，若负则为-1，若正为0。我同时构造了一个 dif 以表示x,y符号之间的关系。</p>\n<p><strong>dif = ~xSign + ySign</strong></p>\n<ol>\n<li>当 x &lt; 0 &amp;&amp; y &lt; 0 时，dif = -1 </li>\n<li>当 x &lt; 0 &amp;&amp; y &gt; 0 时，dif = 0 </li>\n<li>当 x &gt; 0 &amp;&amp; y &lt; 0 时，dif = -2 </li>\n<li>当 x &gt; 0 &amp;&amp; y &lt; 0 时，dif = -1</li>\n</ol>\n<p>将 x,y 符号之间的关系表达出来，把 dif 加一我们可以观察到当 x,y 同号时，dif为0，所以将其取反和 !(res &gt;&gt; 31) 相与，就可以表示同号不溢出的情况，而当 x &lt; 0, y &gt; 0 的情况发生时，我们注意到 dif 就是 0 ，所以我们直接或上 !dif 即可表达这种情况。</p>\n</blockquote>\n<hr>\n<h3 id=\"12-ilog2—以2为底的对数\"><a href=\"#12-ilog2—以2为底的对数\" class=\"headerlink\" title=\"12. ilog2—以2为底的对数\"></a><strong>12. ilog2—以2为底的对数</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回x取以2为底的对数并向下取整，输入的 x &gt; 0\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>ilog2(16) = 4\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 90</p>\n<p><strong>使用操作数：</strong> 48</p>\n<p><strong>代码：</strong></p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">ilog2</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">int</span> tmp, l1, l2, l4, l8, l16;\n  x |= x &gt;&gt; <span class=\"hljs-number\">1</span>;\n  x |= x &gt;&gt; <span class=\"hljs-number\">2</span>;\n  x |= x &gt;&gt; <span class=\"hljs-number\">4</span>;\n  x |= x &gt;&gt; <span class=\"hljs-number\">8</span>;\n  x |= x &gt;&gt; <span class=\"hljs-number\">16</span>;\n  \n  tmp = (<span class=\"hljs-number\">0x55</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x55</span>;\n  l1 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n  tmp = (<span class=\"hljs-number\">0x33</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x33</span>;\n  l2 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n  tmp = (<span class=\"hljs-number\">0x0f</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x0f</span>;\n  l4 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n  l8 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">16</span>) + <span class=\"hljs-number\">0xff</span>;\n  l16 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0xff</span>;\n\n  x = (x &amp; l1) + ((x &gt;&gt; <span class=\"hljs-number\">1</span>) &amp; l1);\n  x = (x &amp; l2) + ((x &gt;&gt; <span class=\"hljs-number\">2</span>) &amp; l2);\n  x = (x &amp; l4) + ((x &gt;&gt; <span class=\"hljs-number\">4</span>) &amp; l4);\n  x = (x &amp; l8) + ((x &gt;&gt; <span class=\"hljs-number\">8</span>) &amp; l8);\n  x = (x &amp; l16) + ((x &gt;&gt; <span class=\"hljs-number\">16</span>) &amp; l16);\n  <span class=\"hljs-keyword\">return</span> x + ~<span class=\"hljs-number\">0</span>;</code></pre>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>我们知道二进制数每位有其位权，所以对 x 取以2为底的对数就是指其为1的最高位的位权。为了获得最高位的位置，其实我们可以将其最高位往下全部变为1，再类似bitsCount数其中1的个数就行了。</p>\n<p>我把 x 移位相与，保证最高位往下所有数字为1，再使用bitsCount就得到答案。</p>\n<p>最后不要忘记减一</p>\n</blockquote>\n<hr>\n<h3 id=\"13-float-neg—浮点数的负数\"><a href=\"#13-float-neg—浮点数的负数\" class=\"headerlink\" title=\"13. float_neg—浮点数的负数\"></a><strong>13. float_neg—浮点数的负数</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回-f，当NaN时，返回参数f\n</code></pre><p><strong>可使用操作：</strong> 所有的整型操作，包括 ||, &amp;&amp;. 以及 if, while</p>\n<p><strong>最大操作数限制：</strong> 10</p>\n<p><strong>使用操作数：</strong> 5</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-title\">float_neg</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">unsigned</span> uf)</span> </span>&#123;\n  <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-built_in\">exp</span> = uf &amp; <span class=\"hljs-number\">0x7f800000</span>;\n  <span class=\"hljs-keyword\">unsigned</span> frac = uf &amp; <span class=\"hljs-number\">0x007fffff</span>;\n  <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> == <span class=\"hljs-number\">0x7f800000</span> &amp;&amp; frac)\n    <span class=\"hljs-keyword\">return</span> uf;\n  <span class=\"hljs-keyword\">return</span> uf ^= <span class=\"hljs-number\">0x80000000</span>;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<ul>\n<li>IEEE-float<blockquote>\n<p>我们知道IEEE单精度浮点数，最高位为符号位，其后8位为阶码exp，后23位为尾数frac。其牺牲了精度来扩大了表达范围。</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>而当 exp 全 1 时，如若frac非全零，则表示NaN。若全零，则表示无穷大/小。</p>\n<p>这里我们只要将原数和符号位0x80000000异或一下，即可取负。不要忘记排除NaN的情况。</p>\n</blockquote>\n<hr>\n<h3 id=\"14-float-i2f—int转float\"><a href=\"#14-float-i2f—int转float\" class=\"headerlink\" title=\"14. float_i2f—int转float\"></a><strong>14. float_i2f—int转float</strong></h3><p><strong>题目：</strong></p>\n<pre><code>把int类型的数转换为float表示(比特形式)\n</code></pre><p><strong>可使用操作：</strong> 所有的整型操作，包括 ||, &amp;&amp;. 以及 if, while</p>\n<p><strong>最大操作数限制：</strong> 30</p>\n<p><strong>使用操作数：</strong> 30</p>\n<p><strong>代码：</strong></p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-title\">float_i2f</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">unsigned</span> frac, mask1, mask2, mask3, mask4, d;\n  <span class=\"hljs-keyword\">int</span> high = <span class=\"hljs-number\">0x80000000</span>;\n  <span class=\"hljs-keyword\">unsigned</span> sign = x &amp; <span class=\"hljs-number\">0x80000000</span>;\n  <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-built_in\">exp</span> = <span class=\"hljs-number\">127</span>;\n  <span class=\"hljs-keyword\">int</span> count = <span class=\"hljs-number\">32</span>, i;\n  <span class=\"hljs-keyword\">if</span>(sign)\n    x = ~x + <span class=\"hljs-number\">1</span>;\n  <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(!x)\n    <span class=\"hljs-keyword\">return</span> x;\n  \n  frac = x;\n\n  <span class=\"hljs-keyword\">for</span>(;high; high &gt;&gt;= <span class=\"hljs-number\">1</span>)\n  &#123;\n    --count;\n    <span class=\"hljs-keyword\">if</span>(high &amp; x)\n      <span class=\"hljs-keyword\">break</span>;\n  &#125;\n  i = count - <span class=\"hljs-number\">23</span>;\n  mask1 = ~(<span class=\"hljs-number\">1</span> &lt;&lt; count); <span class=\"hljs-comment\">// the highest 1</span>\n  mask2 = <span class=\"hljs-number\">1</span> &lt;&lt; i; <span class=\"hljs-comment\">//the lowest of remain frac;</span>\n  mask3 = mask2 &gt;&gt; <span class=\"hljs-number\">1</span>; <span class=\"hljs-comment\">// the highest of deserted bits </span>\n  mask4 = mask2 - <span class=\"hljs-number\">1</span>; <span class=\"hljs-comment\">// the deserted bits</span>\n  <span class=\"hljs-built_in\">exp</span> += count;\n\n  frac &amp;= mask1;\n  \n  <span class=\"hljs-keyword\">if</span>(i &gt; <span class=\"hljs-number\">0</span>)\n  &#123;\n    d = frac &amp; mask4; <span class=\"hljs-comment\">// deserted bits</span>\n    <span class=\"hljs-keyword\">if</span>(d &gt; mask3 | (d == mask3 &amp;&amp; frac &amp; mask2))\n    &#123;\n      frac += mask2;\n      <span class=\"hljs-keyword\">if</span>(frac &gt; <span class=\"hljs-number\">0x3fffffff</span>)\n      &#123;\n        frac = <span class=\"hljs-number\">0</span>;\n        <span class=\"hljs-built_in\">exp</span>++;\n      &#125;\n    &#125;\n    frac &gt;&gt;= i;\n  &#125;\n  <span class=\"hljs-keyword\">else</span>\n    frac &lt;&lt;= -i;\n\n  <span class=\"hljs-keyword\">return</span> sign | <span class=\"hljs-built_in\">exp</span> &lt;&lt; <span class=\"hljs-number\">23</span> | frac;\n&#125;</code></pre>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>我认为这题比较难，我做了很久很久….它难在浮点数向偶数舍入以及其操作数的限制。</p>\n<p>我们知道由于浮点数表示范围比整型大，我们可以将整型转换为浮点数，但是相应的会有一些精度的丢失，因为尾数frac只有23位，而int有31位可用。</p>\n<p>所以其关键在于int的位数，一开始先把该取出来的都用掩码取出来，把负数和零处理一下。之后我利用了一个循环先找出int的最高位在哪，利用count计数。</p>\n<p>后面我采取了四个掩码，分别代表最高位的1，留下的尾数中的最低位，要舍去的位数的最高位，以及舍弃的位数的掩码。利用这四个掩码我们可以达到存frac时，将其向<strong>偶数舍入</strong>。</p>\n<p>具体操作是，先取出丢弃的尾数，将其存放在d中，看其有没有超过0.5 (即 d 是否大于 mask3) 如果大于，直接frac++就行。而如果等于的话，还要看frac是否是奇数 (即frac &amp; mask2是否为1) 如果是，则要向偶数舍入,frac++。</p>\n<p>加完frac之后还要注意<strong>溢出问题</strong>，如果溢出了，要将frac置0，然后把阶码 exp++，再按照之前输出来的尾数移动，将尾数对齐即可 （位数最高默认为1不存，因而把最高位隐去）。</p>\n<p>最后把符号位，阶码位和尾数位拼接，得到最后的结果。</p>\n</blockquote>\n<hr>\n<h3 id=\"15-float-twice—float-2\"><a href=\"#15-float-twice—float-2\" class=\"headerlink\" title=\"15. float_twice—float * 2\"></a>15. float_twice—float * 2</h3><p><strong>题目：</strong></p>\n<pre><code>返回float * 2, 当参数是NaN时，返回参数\n</code></pre><p><strong>可使用操作：</strong> 所有的整型操作，包括 ||, &amp;&amp;. 以及 if, while</p>\n<p><strong>最大操作数限制：</strong> 30</p>\n<p><strong>使用操作数：</strong> 20</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-title\">float_twice</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">unsigned</span> uf)</span> </span>&#123;\n  <span class=\"hljs-keyword\">unsigned</span> sign = uf &amp; <span class=\"hljs-number\">0x80000000</span>;\n  <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-built_in\">exp</span> = uf &amp; <span class=\"hljs-number\">0x7f800000</span>;\n  <span class=\"hljs-keyword\">unsigned</span> frac = uf &amp; <span class=\"hljs-number\">0x007fffff</span>;\n  <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> == <span class=\"hljs-number\">0x7f800000</span>) <span class=\"hljs-comment\">//NaN &amp; inf</span>\n    <span class=\"hljs-keyword\">return</span> uf;\n  <span class=\"hljs-keyword\">if</span>(!<span class=\"hljs-built_in\">exp</span> &amp;&amp; !frac) <span class=\"hljs-comment\">// 0</span>\n    <span class=\"hljs-keyword\">return</span> uf;\n  <span class=\"hljs-keyword\">if</span>(!<span class=\"hljs-built_in\">exp</span> &amp;&amp; frac &lt;= <span class=\"hljs-number\">0x3fffff</span>)  <span class=\"hljs-comment\">// low</span>\n    frac *= <span class=\"hljs-number\">2</span>;\n  <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(!<span class=\"hljs-built_in\">exp</span> &amp;&amp; frac &gt; <span class=\"hljs-number\">0x3fffff</span>) <span class=\"hljs-comment\">// high</span>\n  &#123;\n    <span class=\"hljs-built_in\">exp</span> += <span class=\"hljs-number\">0x00800000</span>;\n    frac = (frac * <span class=\"hljs-number\">2</span>) &amp; <span class=\"hljs-number\">0x7fffff</span>;\n  &#125;\n  <span class=\"hljs-keyword\">else</span> <span class=\"hljs-comment\">// normal</span>\n    <span class=\"hljs-built_in\">exp</span> += <span class=\"hljs-number\">0x00800000</span>;\n  <span class=\"hljs-keyword\">return</span> sign + <span class=\"hljs-built_in\">exp</span> + frac;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>主要要分析的地方，在于当阶码exp为0时，是否在乘2之后进位。所以要考虑尾数是否大于0x3fffff，如果小于等于之，则直接尾数乘2就行，不会溢出，否则则exp要进位，同时尾数乘2之后要与上0x7fffff保证不溢出。</p>\n<p>其他正常情况直接exp++就行，注意一下特殊情况;</p>\n</blockquote>\n<p><em>本题中测试集中有一个inf，也要直接返回参数uf</em></p>\n<hr>\n<h2 id=\"Bits-honor-c\"><a href=\"#Bits-honor-c\" class=\"headerlink\" title=\"Bits_honor.c\"></a><strong>Bits_honor.c</strong></h2><h3 id=\"1-bitReverse—比特翻转\"><a href=\"#1-bitReverse—比特翻转\" class=\"headerlink\" title=\"1. bitReverse—比特翻转\"></a><strong>1. bitReverse—比特翻转</strong></h3><p><strong>题目：</strong></p>\n<pre><code>把32比特int的比特位翻转\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>bitReverse(0x80000004) = 0x20000001\nbitReverse(0x7FFFFFFF) = 0xFFFFFFFE\n</code></pre><p><strong>最大操作数限制：</strong> 40</p>\n<p><strong>使用操作数：</strong> 40</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">bitReverse</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n   <span class=\"hljs-keyword\">int</span> tmp,l1, l2, l4, l8, l16;\n\n   tmp = (<span class=\"hljs-number\">0x55</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x55</span>;\n   l1 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n   tmp = (<span class=\"hljs-number\">0x33</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x33</span>;\n   l2 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n   tmp = (<span class=\"hljs-number\">0x0f</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x0f</span>;\n   l4 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n   l8 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">16</span>) + <span class=\"hljs-number\">0xff</span>;\n   l16 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0xff</span>;\n\n   x = ((x &gt;&gt; <span class=\"hljs-number\">16</span>) &amp; l16) | (x &lt;&lt; <span class=\"hljs-number\">16</span>);\n   x = ((x &gt;&gt; <span class=\"hljs-number\">8</span>) &amp; l8) | ((x &amp; l8) &lt;&lt; <span class=\"hljs-number\">8</span>);\n   x = ((x &gt;&gt; <span class=\"hljs-number\">4</span>) &amp; l4) | ((x &amp; l4) &lt;&lt; <span class=\"hljs-number\">4</span>);\n   x = ((x &gt;&gt; <span class=\"hljs-number\">2</span>) &amp; l2) | ((x &amp; l2) &lt;&lt; <span class=\"hljs-number\">2</span>);\n   x = ((x &gt;&gt; <span class=\"hljs-number\">1</span>) &amp; l1) | ((x &amp; l1) &lt;&lt; <span class=\"hljs-number\">1</span>);\n   <span class=\"hljs-keyword\">return</span> x;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>这题和 bitsCount 有异曲同工之妙，也是一个分治法，将32位二进制数一分为二，交换，再将内部各自再一分为二，交换，直至最底层2位二进制数互换位置，最后完成了将所有位数翻转的工作。</p>\n<p>但值得注意的是，给出的是有符号的int，所以在右移交换位置时，会发生因为负数算术右移导致高位全是1的情况，致使在与的过程中高位全部变为1。这边只要将其移动后在和掩码相与就能解决这一问题。而对于低位，先与掩码相与再移动，可以省去取反得到高位掩码的操作数。再用tmp省一下操作数。</p>\n<p>最后操作数正好卡在40</p>\n</blockquote>\n<hr>\n<h3 id=\"2-mod3—取模3\"><a href=\"#2-mod3—取模3\" class=\"headerlink\" title=\"2. mod3—取模3\"></a><strong>2. mod3—取模3</strong></h3><p><strong>题目：</strong></p>\n<pre><code>计算 x 取模 3，而不用%\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>mod3(100) = 1\nmod3(-100) = -1\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 90</p>\n<p><strong>使用操作数：</strong> 24</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">mod3</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n   <span class=\"hljs-keyword\">int</span> mask = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0xff</span>;\n\n   x = (x &gt;&gt; <span class=\"hljs-number\">16</span>) + (x &amp; mask); <span class=\"hljs-comment\">// sum base 4^8 digits (a &lt;= 0x1FFFE)</span>\n   x = (x &gt;&gt; <span class=\"hljs-number\">8</span>) + (x &amp; <span class=\"hljs-number\">0xff</span>); <span class=\"hljs-comment\">// sum base 4^4 digits (a &lt;= 0x2FD)</span>\n   x = (x &gt;&gt; <span class=\"hljs-number\">4</span>) + (x &amp; <span class=\"hljs-number\">0xf</span>); <span class=\"hljs-comment\">// sum base 4^2 digits (a &lt;= 0x3C)</span>\n   x = (x &gt;&gt; <span class=\"hljs-number\">2</span>) + (x &amp; <span class=\"hljs-number\">0x3</span>); <span class=\"hljs-comment\">// sum base 4^1 digits (a &lt;= 0x1D)</span>\n   x = (x &gt;&gt; <span class=\"hljs-number\">2</span>) + (x &amp; <span class=\"hljs-number\">0x3</span>); <span class=\"hljs-comment\">// sum base 4^1 digits (a &lt;= 0x9)</span>\n   x = (x &gt;&gt; <span class=\"hljs-number\">2</span>) + (x &amp; <span class=\"hljs-number\">0x3</span>); <span class=\"hljs-comment\">// sum base 4^1 digits (a &lt;= 0x4)</span>\n\n   x = (((x + <span class=\"hljs-number\">1</span>) &gt;&gt; <span class=\"hljs-number\">2</span>) + x) &amp; <span class=\"hljs-number\">0x3</span>;\n   <span class=\"hljs-keyword\">return</span> x;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>这题难度算是比较大的，我参考了一些资料最后才写出这个代码。其实这题也与bitsCount有着一定的联系。</p>\n<p>对于解这题有一个根本的公式即 </p>\n</blockquote>\n<pre><code>a % m = ((b % m)(a/b) + (a % b)) % m\n其中b是进制数\n</code></pre><blockquote>\n<p>我们知道，如果想要知道一个十进制的数能否被三整除，只要看它所有数位之和是否能被三整除就行了。其实这就是上述公式的特殊情况，由于10 mod 3 == 1 所以其就退化为</p>\n</blockquote>\n<pre><code>a mod m = (a/b + a % b) % m\n递归下来就是所有数位之和\n</code></pre><blockquote>\n<p>而对于二进制的情况，我们可以将进制位b选为4，这样正好是两位二进制数，同时4 % 3 == 1，这样一来，对于二进制数中我们只需要统计所有两两数位(四进制)的和能否被三整除就行了。</p>\n<p>而考虑到我们每做一次 a/b + a % b 统计数位和都减小了数的规模，这样只要做有限次就能够将数控制在&lt;=3的范围内。</p>\n<p>对于a % 4，这是一个经典的trivial情况，我们只需要做 a &amp; 3，就能够轻松得到a % 4的值。而对于a/4，只需要做a &gt;&gt; 2即可。</p>\n<p>对于二进制数我们不仅可以按两位两位的四进制数位和来数，也可以直接数其倍数(4^i)，从最大4^8开始统计，一步步减小x的值，最后将x做到&lt;= 3的范围</p>\n<p>最后要判断x是否为3，如果为3的话则要置为0，我利用3数位全为1的特点，将其+1进位后，右移2位。如果为3，则得到的是1。将其再加上x，如若x是1或2，则还是不变，但如果是3，它又会进位到4，那么我们只要再与上0x3，则会得到0，即为想要的结果。</p>\n</blockquote>\n<hr>\n<h3 id=\"3-float-f2i—float转int\"><a href=\"#3-float-f2i—float转int\" class=\"headerlink\" title=\"3. float_f2i—float转int\"></a><strong>3. float_f2i—float转int</strong></h3><p><strong>题目：</strong></p>\n<pre><code>输入一个按二进制位储存的float（以unsigned表示），将其转为int输出。(NaN,inf，溢出直接返回参数)\n</code></pre><p><strong>可使用操作：</strong> 所有的整型操作，包括 ||, &amp;&amp;. 以及 if, while</p>\n<p><strong>最大操作数限制：</strong> 30</p>\n<p><strong>使用操作数：</strong> 17</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">float_f2i</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">unsigned</span> uf)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n   <span class=\"hljs-keyword\">int</span> sign, <span class=\"hljs-built_in\">exp</span>, frac, res;\n   <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">int</span> tmp;\n\n   <span class=\"hljs-keyword\">if</span>(!uf)\n      <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n   sign = uf &amp; <span class=\"hljs-number\">0x80000000</span>;\n   <span class=\"hljs-built_in\">exp</span> = uf &amp; <span class=\"hljs-number\">0x7f800000</span>;\n   frac = (uf &amp; <span class=\"hljs-number\">0x007fffff</span>) | <span class=\"hljs-number\">0x00800000</span>;\n\n   <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> == <span class=\"hljs-number\">0x7f800000</span>) <span class=\"hljs-comment\">//NaN and inf</span>\n      <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0x80000000</span>u;\n\n   <span class=\"hljs-built_in\">exp</span> &gt;&gt;= <span class=\"hljs-number\">23</span>;\n\n   <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> &lt; <span class=\"hljs-number\">127</span>)\n      <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n   <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> &gt; <span class=\"hljs-number\">158</span>)\n      <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0x80000000</span>u;\n   <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> &gt; <span class=\"hljs-number\">150</span>)\n      tmp = frac &lt;&lt; (<span class=\"hljs-built_in\">exp</span> - <span class=\"hljs-number\">150</span>);\n   <span class=\"hljs-keyword\">else</span>\n      tmp = frac &gt;&gt; (<span class=\"hljs-number\">150</span> - <span class=\"hljs-built_in\">exp</span>);\n\n      \n   <span class=\"hljs-keyword\">if</span>(sign)\n      res = ~tmp + <span class=\"hljs-number\">1</span>;\n   <span class=\"hljs-keyword\">else</span>\n      res = tmp;\n   \n   <span class=\"hljs-keyword\">return</span> res | sign;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>这题特殊情况比较多，把NaN和inf处理一下，然后注意一下溢出情况，即取出来的exp - bias &gt; 31，肯定超过2^31整型储存的最大值，直接返回0x80000000u，然后对于exp小于127的，其指数是负数，直接返回int值为0。对于在exp - bias 在 0 到 31 之间的，由于frac只有23位，所以要将注意一下讨论23的情况。</p>\n<p>最后把取出来的符号位对一下，如果负数取反加一，正数直接等，最后再或上符号位，返回答案。</p>\n</blockquote>\n<hr>\n<h2 id=\"结果截图\"><a href=\"#结果截图\" class=\"headerlink\" title=\"结果截图\"></a><strong>结果截图</strong></h2><h3 id=\"bits-c\"><a href=\"#bits-c\" class=\"headerlink\" title=\"bits.c\"></a><strong>bits.c</strong></h3><p><img src=\"/CsBlog/CsBlog/2020/11/05/ICS/ICS_Lab1/ICS_Lab1/bits_btest.JPG\" alt=\"bits_btest\"></p>\n<p><img src=\"/CsBlog/CsBlog/2020/11/05/ICS/ICS_Lab1/ICS_Lab1/bits_dlc.png\" alt=\"bits_dlc\"></p>\n<h3 id=\"bits-honor-c\"><a href=\"#bits-honor-c\" class=\"headerlink\" title=\"bits_honor.c\"></a><strong>bits_honor.c</strong></h3><p><img src=\"/CsBlog/CsBlog/2020/11/05/ICS/ICS_Lab1/ICS_Lab1/bits_honor_btest.JPG\" alt=\"bits_honor_btest\"></p>\n<p><img src=\"/CsBlog/CsBlog/2020/11/05/ICS/ICS_Lab1/ICS_Lab1/bits_honor_dlc.png\" alt=\"bits_honor_dlc\"></p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><hr>\n<p><a href=\"https://baike.baidu.com/item/%E7%AE%97%E6%9C%AF%E5%8F%B3%E7%A7%BB/3711081?fr=aladdin\">https://baike.baidu.com/item/%E7%AE%97%E6%9C%AF%E5%8F%B3%E7%A7%BB/3711081?fr=aladdin</a><br><a href=\"https://blog.csdn.net/jiahonghao2002/article/details/108223366\">https://blog.csdn.net/jiahonghao2002/article/details/108223366</a><br><a href=\"https://leetcode-cn.com/problems/reverse-bits/solution/dian-dao-er-jin-zhi-wei-by-leetcode/\">https://leetcode-cn.com/problems/reverse-bits/solution/dian-dao-er-jin-zhi-wei-by-leetcode/</a><br><a href=\"http://homepage.cs.uiowa.edu/~jones/bcd/mod.shtml#exmod3\">http://homepage.cs.uiowa.edu/~jones/bcd/mod.shtml#exmod3</a><br><a href=\"https://www.zhihu.com/question/38206659/answer/763034261\">https://www.zhihu.com/question/38206659/answer/763034261</a><br><a href=\"https://blog.csdn.net/xindaxinda123/article/details/95617758\">https://blog.csdn.net/xindaxinda123/article/details/95617758</a><br><a href=\"https://www.runoob.com/w3cnote/32-float-storage.html\">https://www.runoob.com/w3cnote/32-float-storage.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"ICS-Lab1-位运算\"><a href=\"#ICS-Lab1-位运算\" class=\"headerlink\" title=\"ICS_Lab1-位运算\"></a>ICS_Lab1-位运算</h1><blockquote>\n<p>这个是CS:APP的第一个lab，也是我ICS课上的第一个lab，主要注重于使用受限制的位运算来完成操作</p>\n</blockquote>\n<hr>\n<h2 id=\"Bits-c\"><a href=\"#Bits-c\" class=\"headerlink\" title=\"Bits.c\"></a><strong>Bits.c</strong></h2><h3 id=\"1-bitAnd—与\"><a href=\"#1-bitAnd—与\" class=\"headerlink\" title=\"1. bitAnd—与\"></a><strong>1. bitAnd—与</strong></h3><p><strong>题目：</strong></p>\n<pre><code>只用~和|实现&amp;\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>bitAnd(6, 5) = 4\n</code></pre><p><strong>可使用操作：</strong> ~ |</p>\n<p><strong>最大操作数限制：</strong> 8</p>\n<p><strong>使用操作数：</strong> 4</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">bitAnd</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> y)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> ~(~x | ~y); <span class=\"hljs-comment\">//De Morgan&#x27;s laws</span>\n&#125;</code></pre>\n<blockquote>\n<p>应用摩根律 ~(x | y) = ~x &amp; ~y, 可得 x &amp; y = ~(~x | ~y)</p>\n</blockquote>\n<hr>\n<h3 id=\"2-getByte—获取字节\"><a href=\"#2-getByte—获取字节\" class=\"headerlink\" title=\"2. getByte—获取字节\"></a><strong>2. getByte—获取字节</strong></h3><p><strong>题目：</strong></p>\n<pre><code>从x中提取字节n, n编号从0至3\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>getByte(0x12345678,1) = 0x56\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 6</p>\n<p><strong>使用操作数：</strong> 3</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">getByte</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> (x &gt;&gt; (n &lt;&lt; <span class=\"hljs-number\">3</span>)) &amp; <span class=\"hljs-number\">0xff</span>;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<p><em>由于 1Byte = 8bits = 2^3bits， 所以 n Bytes = 2^3 </em> n bits*</p>\n<blockquote>\n<p>因而将n左移3位，即 n <em> 2^3, 再将x右移 n </em> 2^3 即可将所求字节放在低8位，将其与上0xff，即可取出字节。</p>\n</blockquote>\n<hr>\n<h3 id=\"3-logicalShift—逻辑右移\"><a href=\"#3-logicalShift—逻辑右移\" class=\"headerlink\" title=\"3. logicalShift—逻辑右移\"></a><strong>3. logicalShift—逻辑右移</strong></h3><p><strong>题目：</strong></p>\n<pre><code>将x逻辑右移n位\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>logicalShift(0x87654321,4) = 0x08765432\n</code></pre><p><strong>可使用操作：</strong>  ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 20</p>\n<p><strong>使用操作数：</strong> 10</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">logicalShift</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;\n  <span class=\"hljs-comment\">//flag equals to: if n == 0 return 0; else return 1;</span>\n  <span class=\"hljs-keyword\">int</span> flag = !!n;\n  <span class=\"hljs-keyword\">int</span> mask = ~(flag &lt;&lt; (<span class=\"hljs-number\">32</span> + (~n + <span class=\"hljs-number\">1</span>)));\n  <span class=\"hljs-keyword\">return</span> (x &gt;&gt; n) &amp; mask;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<ul>\n<li><p>算数右移</p>\n<blockquote>\n<p>算数右移即在右移后用原符号位数将高位补齐，保持右移后二进制数的符号保持不变。</p>\n</blockquote>\n</li>\n<li><p>逻辑右移</p>\n<blockquote>\n<p>逻辑右移即在右移后用 0 将高位补齐，是“逻辑上”的右移。</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>在正常右移运算中使用的是算数右移，因而要解决的问题即对于负数如何将最高位补上0，而非符号位1。<br>我采取掩码的方式，先将x正常右移n位与上其高位的掩码，使其右移产生的高位变为0</p>\n</blockquote>\n<ul>\n<li>掩码构造<blockquote>\n<p>掩码不能草率的构造为 ~(-1 &lt;&lt; (32 - n)), 这种构造方式当n为0时会因-1被左移32位而导致异常，构造出来的mask仍为0</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>由于不能使用if，为判断n是否为0，我才用了一个flag = !n + ~0, 其有很好的性质。当n为0时，flag也为0，而当n不为零时，flag统一为-1，这样使用flag代替原先的-1, 从而避免上述情况。</p>\n<p>这样我们可以使用 mask = ~(flag &lt;&lt; (32 + (~n + 1)))，来构造掩码，当n为0时，flag为0，从而mask = -1，避免上述错误。</p>\n</blockquote>\n<hr>\n<h3 id=\"4-bitCount—比特计数\"><a href=\"#4-bitCount—比特计数\" class=\"headerlink\" title=\"4. bitCount—比特计数\"></a><strong>4. bitCount—比特计数</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回二进制数中1的个数\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>bitCount(5) = 2, bitCount(7) = 3\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 40</p>\n<p><strong>使用操作数：</strong> 36</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">bitCount</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">int</span> tmp, l1, l2, l4, l8, l16; <span class=\"hljs-comment\">//tmp is used to save ops</span>\n  tmp = (<span class=\"hljs-number\">0x55</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x55</span>;\n  l1 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp; <span class=\"hljs-comment\">//0x55555555</span>\n  tmp = (<span class=\"hljs-number\">0x33</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x33</span>;\n  l2 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp; <span class=\"hljs-comment\">//0x33333333</span>\n  tmp = (<span class=\"hljs-number\">0x0f</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x0f</span>;\n  l4 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp; <span class=\"hljs-comment\">//0x0f0f0f0f</span>\n  l8 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">16</span>) + <span class=\"hljs-number\">0xff</span>; <span class=\"hljs-comment\">//0x00ff00ff</span>\n  l16 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0xff</span>; <span class=\"hljs-comment\">//0x0000ffff</span>\n\n  x = (x &amp; l1) + ((x &gt;&gt; <span class=\"hljs-number\">1</span>) &amp; l1);\n  x = (x &amp; l2) + ((x &gt;&gt; <span class=\"hljs-number\">2</span>) &amp; l2);\n  x = (x &amp; l4) + ((x &gt;&gt; <span class=\"hljs-number\">4</span>) &amp; l4);\n  x = (x &amp; l8) + ((x &gt;&gt; <span class=\"hljs-number\">8</span>) &amp; l8);\n  x = (x &amp; l16) + ((x &gt;&gt; <span class=\"hljs-number\">16</span>) &amp; l16);\n  <span class=\"hljs-keyword\">return</span> x;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<ul>\n<li>分治思想<blockquote>\n<p>本题使用了一个简单的分治思想，对于一个二进制数，要对其中为1的位做计数， 对于1位二进制数来说，1的个数无非就是其本身所表示的1或0。利用这个特性，我们可以先将一个二进制数每一位独立分开为相间隔的两部分, 其每位表示的就是自身的二进制个数，再将两串二进制数对其相加，所得到的每两位分隔的二进制数就是表达这个位置的位为1的个数。</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>进一步相加为4位，8位其所代表的含义不变，最后合并至32位二进制数，其所表示的就是原二进制数中所含1的个数。</p>\n</blockquote>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">//以八位二进制数 10101110 为例//</span>\n按 <span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">0</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">0</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">0</span> 分割， 为两串<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">1</span>和<span class=\"hljs-number\">0</span>|<span class=\"hljs-number\">0</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">0</span>，再将其合并，成为 <span class=\"hljs-number\">01</span> | <span class=\"hljs-number\">01</span> | <span class=\"hljs-number\">10</span> | <span class=\"hljs-number\">01</span>, 再将两串 <span class=\"hljs-number\">01</span> | <span class=\"hljs-number\">10</span> 和<span class=\"hljs-number\">01</span> | <span class=\"hljs-number\">01</span>合并得 <span class=\"hljs-number\">0010</span> | <span class=\"hljs-number\">0011</span>（这个很容易看出表示左四位有<span class=\"hljs-number\">2</span>个<span class=\"hljs-number\">1</span>，右四位有<span class=\"hljs-number\">3</span>个<span class=\"hljs-number\">1</span>），再次合并得 <span class=\"hljs-number\">00000101</span>, 得到总共有<span class=\"hljs-number\">5</span>个<span class=\"hljs-number\">1</span>。\n\n<span class=\"hljs-comment\">//对于32位二进制数亦按此继续操作即可//</span></code></pre>\n<blockquote>\n<p>于是为完成分割取位的操作，我们需要采用掩码</p>\n</blockquote>\n<ul>\n<li>0x55555555 \\ 0x33333333 \\ 0x0f0f0f0f \\ 0x0000ffff</li>\n</ul>\n<blockquote>\n<p>利用位运算分别构造，使用tmp可以节约ops, 之后按照分治思想进行操作即可。</p>\n</blockquote>\n<hr>\n<h3 id=\"5-bang—逻辑非\"><a href=\"#5-bang—逻辑非\" class=\"headerlink\" title=\"5. bang—逻辑非\"></a><strong>5. bang—逻辑非</strong></h3><p><strong>题目：</strong></p>\n<pre><code>计算 !x 而不使用逻辑非!\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>bang(3) = 0, bang(0) = 1\n</code></pre><p><strong>可使用操作：</strong> ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 12</p>\n<p><strong>使用操作数：</strong> 6</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">bang</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> ((x &gt;&gt; <span class=\"hljs-number\">31</span>) | ((~x + <span class=\"hljs-number\">1</span>) &gt;&gt; <span class=\"hljs-number\">31</span>)) + <span class=\"hljs-number\">1</span>;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<ul>\n<li>逻辑非<blockquote>\n<p>对于逻辑非运算，应该都很熟悉，!x 当且仅当x为0时其为1，其余时候都为0，可以用来区分零和非零数。</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>该问题的关键就是在于如何区分零和非零数，我们知道零的二补码仍然是零，而对于其余非零数，其符号位会有相应改变，利用这一性质，我们可以对零和非零数做出区分。</p>\n<p>使用 <code>((x &gt;&gt; 31) | ((~x + 1) &gt;&gt; 31))</code>，将二进制数x的符号位与其补码左移31位相与，如若是非零数，其中符号位至少有一个为1，所以经过31位的算数右移后，其中一项必为-1，一项为0，相与之后得到-1,。而对于0来说，结果始终为0。</p>\n<p>最后只要将结果+1，就能得到逻辑非的效果。</p>\n</blockquote>\n<hr>\n<h3 id=\"6-tmin—最小数\"><a href=\"#6-tmin—最小数\" class=\"headerlink\" title=\"6. tmin—最小数\"></a><strong>6. tmin—最小数</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回二补码中最小的数\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 4</p>\n<p><strong>使用操作数：</strong> 1</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">tmin</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">1</span> &lt;&lt; <span class=\"hljs-number\">31</span>;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>此题非常简单，我们知道计算机中负数是用其补码表示的，int所能表示的最小数为0x80000000(-2^31), 即符号位为1，其余皆为0，所以只要将1左移31位即可。</p>\n</blockquote>\n<hr>\n<h3 id=\"7-fitsBits—填充比特\"><a href=\"#7-fitsBits—填充比特\" class=\"headerlink\" title=\"7. fitsBits—填充比特\"></a><strong>7. fitsBits—填充比特</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回1如果x可以表示为n位二补码，反之返回0 (1 &lt;= n &lt;= 32)\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>fitsBits(5,3) = 0, fitsBits(-4,3) = 1\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 15</p>\n<p><strong>使用操作数：</strong> 7</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">fitsBits</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;\n  <span class=\"hljs-keyword\">int</span> k = x &gt;&gt; (n + ~<span class=\"hljs-number\">0</span>); <span class=\"hljs-comment\">// if can k = 0 or -1</span>\n  <span class=\"hljs-keyword\">return</span> !k | !(k + <span class=\"hljs-number\">1</span>);\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>我们知道如若一个数能够被n位二进制数表示，则其第n位即最高位是符号位，那么将其右移n-1位后，根据算术右移，其得到的结果不是0，就是1。否则表示，其还有高于n位的位数， 即不能用n位表示。</p>\n<p>所以用 k = x &gt;&gt; (n + ~0) 表示将其右移n-1位，再用 !k | !(k + 1) 判断k是否为0或-1</p>\n</blockquote>\n<hr>\n<h3 id=\"8-divpwr2—除以2的n次方\"><a href=\"#8-divpwr2—除以2的n次方\" class=\"headerlink\" title=\"8. divpwr2—除以2的n次方\"></a><strong>8. divpwr2—除以2的n次方</strong></h3><p><strong>题目：</strong></p>\n<pre><code>计算 x/(2^n), (0 &lt;= n &lt;= 30)\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>divpwr2(15,1) = 7, divpwr2(-33,4) = -2\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 15</p>\n<p><strong>使用操作数：</strong> 7</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">divpwr2</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;\n    <span class=\"hljs-keyword\">int</span> sign = x &gt;&gt; <span class=\"hljs-number\">31</span>;\n    <span class=\"hljs-keyword\">int</span> bias = (<span class=\"hljs-number\">1</span> &lt;&lt; n) + ~<span class=\"hljs-number\">0</span>;\n    x = x + (bias &amp; sign);\n    <span class=\"hljs-keyword\">return</span> x &gt;&gt; n;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>本题的难点在于Round toward zero, 我们知道除以2的n次方即为将x右移n位。对于正数，尾数截断，因而自然向0舍入。而对于负数则不是如此，经试验在gcc上对于负数，其是向偶数舍入的，因而我们要对负数进行操作。</p>\n<p>同时由于其向偶数舍入，我们不能简单地对负数进行+1操作，例如原本正确的 -7/4 = -1.25 = -1，但是经过+1操作后变为-6/4 = -1.5 Round toward even则变为了2。所以我们不应简单加一，而是加一个偏差值，其为2^n - 1，对于-7/4来说，就是3，加上bias之后得到(-7 + 3)/4即为-1。</p>\n<p>所以我们构造bias = (1 &lt;&lt; n) + ~0 (由于不能用减号，-1用+~0表示)，然后我们要记得将sign取出，在x进行加操作时先检查一下x是否是负数，再进行操作。最后只要方向的将x右移n位即可。</p>\n</blockquote>\n<hr>\n<h3 id=\"9-negate—取负\"><a href=\"#9-negate—取负\" class=\"headerlink\" title=\"9. negate—取负\"></a><strong>9. negate—取负</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回-x\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>negate(1) = -1.\n</code></pre><p><strong>可使用操作：</strong>  ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 5</p>\n<p><strong>使用操作数：</strong> 2</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">negate</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> ~x + <span class=\"hljs-number\">1</span>;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>很简单，对于有符号二进制数取负就是取其补码，而补码等于其取反加一，返回取反加一即可。</p>\n</blockquote>\n<hr>\n<h3 id=\"10-isPositive—是正数\"><a href=\"#10-isPositive—是正数\" class=\"headerlink\" title=\"10. isPositive—是正数\"></a><strong>10. isPositive—是正数</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回1如果x大于0，反之返回0\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>isPositive(-1) = 0.\n</code></pre><p><strong>可使用操作：</strong>  ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 8</p>\n<p><strong>使用操作数：</strong> 5</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">isPositive</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> !(x &gt;&gt; <span class=\"hljs-number\">31</span>) &amp; !!x;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>这题关键在于把0剔除了，区分正负数就是区分其符号位，将x右移31位，负数得-1，正数为0，用一个逻辑非使正数为1，负数为0，然后再和!!x与一下就能剔除0</p>\n</blockquote>\n<ul>\n<li>!!x 当 x == 0 时返回 0，不为 0 时返回 1</li>\n</ul>\n<hr>\n<h3 id=\"11-isLessOrEqual—小于等于\"><a href=\"#11-isLessOrEqual—小于等于\" class=\"headerlink\" title=\"11. isLessOrEqual—小于等于\"></a><strong>11. isLessOrEqual—小于等于</strong></h3><p><strong>题目：</strong></p>\n<pre><code>如果x小于等于y返回1，反之返回0\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>isLessOrEqual(4,5) = 1.\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 24</p>\n<p><strong>使用操作数：</strong> 14</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">isLessOrEqual</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> y)</span> </span>&#123;\n  <span class=\"hljs-keyword\">int</span> res = y + (~x + <span class=\"hljs-number\">1</span>); <span class=\"hljs-comment\">// y - x</span>\n  <span class=\"hljs-keyword\">int</span> xSign = x &gt;&gt; <span class=\"hljs-number\">31</span>;\n  <span class=\"hljs-keyword\">int</span> ySign = y &gt;&gt; <span class=\"hljs-number\">31</span>;\n  <span class=\"hljs-keyword\">int</span> dif = ~xSign + ySign;\n  <span class=\"hljs-keyword\">return</span> (~(dif + <span class=\"hljs-number\">1</span> &gt;&gt; <span class=\"hljs-number\">31</span>) &amp; !(res &gt;&gt; <span class=\"hljs-number\">31</span>)) | !dif;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>我在这里采取了作差的方法 res = y + (~x + 1)，即计算一下y-x，判断其是否非负，同时也要考虑溢出问题，即 x 为负数，y为正数，y-x后溢出为负。</p>\n<p>我将x,y右移31位代表其符号，若负则为-1，若正为0。我同时构造了一个 dif 以表示x,y符号之间的关系。</p>\n<p><strong>dif = ~xSign + ySign</strong></p>\n<ol>\n<li>当 x &lt; 0 &amp;&amp; y &lt; 0 时，dif = -1 </li>\n<li>当 x &lt; 0 &amp;&amp; y &gt; 0 时，dif = 0 </li>\n<li>当 x &gt; 0 &amp;&amp; y &lt; 0 时，dif = -2 </li>\n<li>当 x &gt; 0 &amp;&amp; y &lt; 0 时，dif = -1</li>\n</ol>\n<p>将 x,y 符号之间的关系表达出来，把 dif 加一我们可以观察到当 x,y 同号时，dif为0，所以将其取反和 !(res &gt;&gt; 31) 相与，就可以表示同号不溢出的情况，而当 x &lt; 0, y &gt; 0 的情况发生时，我们注意到 dif 就是 0 ，所以我们直接或上 !dif 即可表达这种情况。</p>\n</blockquote>\n<hr>\n<h3 id=\"12-ilog2—以2为底的对数\"><a href=\"#12-ilog2—以2为底的对数\" class=\"headerlink\" title=\"12. ilog2—以2为底的对数\"></a><strong>12. ilog2—以2为底的对数</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回x取以2为底的对数并向下取整，输入的 x &gt; 0\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>ilog2(16) = 4\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 90</p>\n<p><strong>使用操作数：</strong> 48</p>\n<p><strong>代码：</strong></p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">ilog2</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">int</span> tmp, l1, l2, l4, l8, l16;\n  x |= x &gt;&gt; <span class=\"hljs-number\">1</span>;\n  x |= x &gt;&gt; <span class=\"hljs-number\">2</span>;\n  x |= x &gt;&gt; <span class=\"hljs-number\">4</span>;\n  x |= x &gt;&gt; <span class=\"hljs-number\">8</span>;\n  x |= x &gt;&gt; <span class=\"hljs-number\">16</span>;\n  \n  tmp = (<span class=\"hljs-number\">0x55</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x55</span>;\n  l1 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n  tmp = (<span class=\"hljs-number\">0x33</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x33</span>;\n  l2 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n  tmp = (<span class=\"hljs-number\">0x0f</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x0f</span>;\n  l4 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n  l8 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">16</span>) + <span class=\"hljs-number\">0xff</span>;\n  l16 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0xff</span>;\n\n  x = (x &amp; l1) + ((x &gt;&gt; <span class=\"hljs-number\">1</span>) &amp; l1);\n  x = (x &amp; l2) + ((x &gt;&gt; <span class=\"hljs-number\">2</span>) &amp; l2);\n  x = (x &amp; l4) + ((x &gt;&gt; <span class=\"hljs-number\">4</span>) &amp; l4);\n  x = (x &amp; l8) + ((x &gt;&gt; <span class=\"hljs-number\">8</span>) &amp; l8);\n  x = (x &amp; l16) + ((x &gt;&gt; <span class=\"hljs-number\">16</span>) &amp; l16);\n  <span class=\"hljs-keyword\">return</span> x + ~<span class=\"hljs-number\">0</span>;</code></pre>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>我们知道二进制数每位有其位权，所以对 x 取以2为底的对数就是指其为1的最高位的位权。为了获得最高位的位置，其实我们可以将其最高位往下全部变为1，再类似bitsCount数其中1的个数就行了。</p>\n<p>我把 x 移位相与，保证最高位往下所有数字为1，再使用bitsCount就得到答案。</p>\n<p>最后不要忘记减一</p>\n</blockquote>\n<hr>\n<h3 id=\"13-float-neg—浮点数的负数\"><a href=\"#13-float-neg—浮点数的负数\" class=\"headerlink\" title=\"13. float_neg—浮点数的负数\"></a><strong>13. float_neg—浮点数的负数</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回-f，当NaN时，返回参数f\n</code></pre><p><strong>可使用操作：</strong> 所有的整型操作，包括 ||, &amp;&amp;. 以及 if, while</p>\n<p><strong>最大操作数限制：</strong> 10</p>\n<p><strong>使用操作数：</strong> 5</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-title\">float_neg</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">unsigned</span> uf)</span> </span>&#123;\n  <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-built_in\">exp</span> = uf &amp; <span class=\"hljs-number\">0x7f800000</span>;\n  <span class=\"hljs-keyword\">unsigned</span> frac = uf &amp; <span class=\"hljs-number\">0x007fffff</span>;\n  <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> == <span class=\"hljs-number\">0x7f800000</span> &amp;&amp; frac)\n    <span class=\"hljs-keyword\">return</span> uf;\n  <span class=\"hljs-keyword\">return</span> uf ^= <span class=\"hljs-number\">0x80000000</span>;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<ul>\n<li>IEEE-float<blockquote>\n<p>我们知道IEEE单精度浮点数，最高位为符号位，其后8位为阶码exp，后23位为尾数frac。其牺牲了精度来扩大了表达范围。</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>而当 exp 全 1 时，如若frac非全零，则表示NaN。若全零，则表示无穷大/小。</p>\n<p>这里我们只要将原数和符号位0x80000000异或一下，即可取负。不要忘记排除NaN的情况。</p>\n</blockquote>\n<hr>\n<h3 id=\"14-float-i2f—int转float\"><a href=\"#14-float-i2f—int转float\" class=\"headerlink\" title=\"14. float_i2f—int转float\"></a><strong>14. float_i2f—int转float</strong></h3><p><strong>题目：</strong></p>\n<pre><code>把int类型的数转换为float表示(比特形式)\n</code></pre><p><strong>可使用操作：</strong> 所有的整型操作，包括 ||, &amp;&amp;. 以及 if, while</p>\n<p><strong>最大操作数限制：</strong> 30</p>\n<p><strong>使用操作数：</strong> 30</p>\n<p><strong>代码：</strong></p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-title\">float_i2f</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">unsigned</span> frac, mask1, mask2, mask3, mask4, d;\n  <span class=\"hljs-keyword\">int</span> high = <span class=\"hljs-number\">0x80000000</span>;\n  <span class=\"hljs-keyword\">unsigned</span> sign = x &amp; <span class=\"hljs-number\">0x80000000</span>;\n  <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-built_in\">exp</span> = <span class=\"hljs-number\">127</span>;\n  <span class=\"hljs-keyword\">int</span> count = <span class=\"hljs-number\">32</span>, i;\n  <span class=\"hljs-keyword\">if</span>(sign)\n    x = ~x + <span class=\"hljs-number\">1</span>;\n  <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(!x)\n    <span class=\"hljs-keyword\">return</span> x;\n  \n  frac = x;\n\n  <span class=\"hljs-keyword\">for</span>(;high; high &gt;&gt;= <span class=\"hljs-number\">1</span>)\n  &#123;\n    --count;\n    <span class=\"hljs-keyword\">if</span>(high &amp; x)\n      <span class=\"hljs-keyword\">break</span>;\n  &#125;\n  i = count - <span class=\"hljs-number\">23</span>;\n  mask1 = ~(<span class=\"hljs-number\">1</span> &lt;&lt; count); <span class=\"hljs-comment\">// the highest 1</span>\n  mask2 = <span class=\"hljs-number\">1</span> &lt;&lt; i; <span class=\"hljs-comment\">//the lowest of remain frac;</span>\n  mask3 = mask2 &gt;&gt; <span class=\"hljs-number\">1</span>; <span class=\"hljs-comment\">// the highest of deserted bits </span>\n  mask4 = mask2 - <span class=\"hljs-number\">1</span>; <span class=\"hljs-comment\">// the deserted bits</span>\n  <span class=\"hljs-built_in\">exp</span> += count;\n\n  frac &amp;= mask1;\n  \n  <span class=\"hljs-keyword\">if</span>(i &gt; <span class=\"hljs-number\">0</span>)\n  &#123;\n    d = frac &amp; mask4; <span class=\"hljs-comment\">// deserted bits</span>\n    <span class=\"hljs-keyword\">if</span>(d &gt; mask3 | (d == mask3 &amp;&amp; frac &amp; mask2))\n    &#123;\n      frac += mask2;\n      <span class=\"hljs-keyword\">if</span>(frac &gt; <span class=\"hljs-number\">0x3fffffff</span>)\n      &#123;\n        frac = <span class=\"hljs-number\">0</span>;\n        <span class=\"hljs-built_in\">exp</span>++;\n      &#125;\n    &#125;\n    frac &gt;&gt;= i;\n  &#125;\n  <span class=\"hljs-keyword\">else</span>\n    frac &lt;&lt;= -i;\n\n  <span class=\"hljs-keyword\">return</span> sign | <span class=\"hljs-built_in\">exp</span> &lt;&lt; <span class=\"hljs-number\">23</span> | frac;\n&#125;</code></pre>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>我认为这题比较难，我做了很久很久….它难在浮点数向偶数舍入以及其操作数的限制。</p>\n<p>我们知道由于浮点数表示范围比整型大，我们可以将整型转换为浮点数，但是相应的会有一些精度的丢失，因为尾数frac只有23位，而int有31位可用。</p>\n<p>所以其关键在于int的位数，一开始先把该取出来的都用掩码取出来，把负数和零处理一下。之后我利用了一个循环先找出int的最高位在哪，利用count计数。</p>\n<p>后面我采取了四个掩码，分别代表最高位的1，留下的尾数中的最低位，要舍去的位数的最高位，以及舍弃的位数的掩码。利用这四个掩码我们可以达到存frac时，将其向<strong>偶数舍入</strong>。</p>\n<p>具体操作是，先取出丢弃的尾数，将其存放在d中，看其有没有超过0.5 (即 d 是否大于 mask3) 如果大于，直接frac++就行。而如果等于的话，还要看frac是否是奇数 (即frac &amp; mask2是否为1) 如果是，则要向偶数舍入,frac++。</p>\n<p>加完frac之后还要注意<strong>溢出问题</strong>，如果溢出了，要将frac置0，然后把阶码 exp++，再按照之前输出来的尾数移动，将尾数对齐即可 （位数最高默认为1不存，因而把最高位隐去）。</p>\n<p>最后把符号位，阶码位和尾数位拼接，得到最后的结果。</p>\n</blockquote>\n<hr>\n<h3 id=\"15-float-twice—float-2\"><a href=\"#15-float-twice—float-2\" class=\"headerlink\" title=\"15. float_twice—float * 2\"></a>15. float_twice—float * 2</h3><p><strong>题目：</strong></p>\n<pre><code>返回float * 2, 当参数是NaN时，返回参数\n</code></pre><p><strong>可使用操作：</strong> 所有的整型操作，包括 ||, &amp;&amp;. 以及 if, while</p>\n<p><strong>最大操作数限制：</strong> 30</p>\n<p><strong>使用操作数：</strong> 20</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-title\">float_twice</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">unsigned</span> uf)</span> </span>&#123;\n  <span class=\"hljs-keyword\">unsigned</span> sign = uf &amp; <span class=\"hljs-number\">0x80000000</span>;\n  <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-built_in\">exp</span> = uf &amp; <span class=\"hljs-number\">0x7f800000</span>;\n  <span class=\"hljs-keyword\">unsigned</span> frac = uf &amp; <span class=\"hljs-number\">0x007fffff</span>;\n  <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> == <span class=\"hljs-number\">0x7f800000</span>) <span class=\"hljs-comment\">//NaN &amp; inf</span>\n    <span class=\"hljs-keyword\">return</span> uf;\n  <span class=\"hljs-keyword\">if</span>(!<span class=\"hljs-built_in\">exp</span> &amp;&amp; !frac) <span class=\"hljs-comment\">// 0</span>\n    <span class=\"hljs-keyword\">return</span> uf;\n  <span class=\"hljs-keyword\">if</span>(!<span class=\"hljs-built_in\">exp</span> &amp;&amp; frac &lt;= <span class=\"hljs-number\">0x3fffff</span>)  <span class=\"hljs-comment\">// low</span>\n    frac *= <span class=\"hljs-number\">2</span>;\n  <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(!<span class=\"hljs-built_in\">exp</span> &amp;&amp; frac &gt; <span class=\"hljs-number\">0x3fffff</span>) <span class=\"hljs-comment\">// high</span>\n  &#123;\n    <span class=\"hljs-built_in\">exp</span> += <span class=\"hljs-number\">0x00800000</span>;\n    frac = (frac * <span class=\"hljs-number\">2</span>) &amp; <span class=\"hljs-number\">0x7fffff</span>;\n  &#125;\n  <span class=\"hljs-keyword\">else</span> <span class=\"hljs-comment\">// normal</span>\n    <span class=\"hljs-built_in\">exp</span> += <span class=\"hljs-number\">0x00800000</span>;\n  <span class=\"hljs-keyword\">return</span> sign + <span class=\"hljs-built_in\">exp</span> + frac;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>主要要分析的地方，在于当阶码exp为0时，是否在乘2之后进位。所以要考虑尾数是否大于0x3fffff，如果小于等于之，则直接尾数乘2就行，不会溢出，否则则exp要进位，同时尾数乘2之后要与上0x7fffff保证不溢出。</p>\n<p>其他正常情况直接exp++就行，注意一下特殊情况;</p>\n</blockquote>\n<p><em>本题中测试集中有一个inf，也要直接返回参数uf</em></p>\n<hr>\n<h2 id=\"Bits-honor-c\"><a href=\"#Bits-honor-c\" class=\"headerlink\" title=\"Bits_honor.c\"></a><strong>Bits_honor.c</strong></h2><h3 id=\"1-bitReverse—比特翻转\"><a href=\"#1-bitReverse—比特翻转\" class=\"headerlink\" title=\"1. bitReverse—比特翻转\"></a><strong>1. bitReverse—比特翻转</strong></h3><p><strong>题目：</strong></p>\n<pre><code>把32比特int的比特位翻转\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>bitReverse(0x80000004) = 0x20000001\nbitReverse(0x7FFFFFFF) = 0xFFFFFFFE\n</code></pre><p><strong>最大操作数限制：</strong> 40</p>\n<p><strong>使用操作数：</strong> 40</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">bitReverse</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n   <span class=\"hljs-keyword\">int</span> tmp,l1, l2, l4, l8, l16;\n\n   tmp = (<span class=\"hljs-number\">0x55</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x55</span>;\n   l1 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n   tmp = (<span class=\"hljs-number\">0x33</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x33</span>;\n   l2 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n   tmp = (<span class=\"hljs-number\">0x0f</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x0f</span>;\n   l4 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n   l8 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">16</span>) + <span class=\"hljs-number\">0xff</span>;\n   l16 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0xff</span>;\n\n   x = ((x &gt;&gt; <span class=\"hljs-number\">16</span>) &amp; l16) | (x &lt;&lt; <span class=\"hljs-number\">16</span>);\n   x = ((x &gt;&gt; <span class=\"hljs-number\">8</span>) &amp; l8) | ((x &amp; l8) &lt;&lt; <span class=\"hljs-number\">8</span>);\n   x = ((x &gt;&gt; <span class=\"hljs-number\">4</span>) &amp; l4) | ((x &amp; l4) &lt;&lt; <span class=\"hljs-number\">4</span>);\n   x = ((x &gt;&gt; <span class=\"hljs-number\">2</span>) &amp; l2) | ((x &amp; l2) &lt;&lt; <span class=\"hljs-number\">2</span>);\n   x = ((x &gt;&gt; <span class=\"hljs-number\">1</span>) &amp; l1) | ((x &amp; l1) &lt;&lt; <span class=\"hljs-number\">1</span>);\n   <span class=\"hljs-keyword\">return</span> x;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>这题和 bitsCount 有异曲同工之妙，也是一个分治法，将32位二进制数一分为二，交换，再将内部各自再一分为二，交换，直至最底层2位二进制数互换位置，最后完成了将所有位数翻转的工作。</p>\n<p>但值得注意的是，给出的是有符号的int，所以在右移交换位置时，会发生因为负数算术右移导致高位全是1的情况，致使在与的过程中高位全部变为1。这边只要将其移动后在和掩码相与就能解决这一问题。而对于低位，先与掩码相与再移动，可以省去取反得到高位掩码的操作数。再用tmp省一下操作数。</p>\n<p>最后操作数正好卡在40</p>\n</blockquote>\n<hr>\n<h3 id=\"2-mod3—取模3\"><a href=\"#2-mod3—取模3\" class=\"headerlink\" title=\"2. mod3—取模3\"></a><strong>2. mod3—取模3</strong></h3><p><strong>题目：</strong></p>\n<pre><code>计算 x 取模 3，而不用%\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>mod3(100) = 1\nmod3(-100) = -1\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 90</p>\n<p><strong>使用操作数：</strong> 24</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">mod3</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n   <span class=\"hljs-keyword\">int</span> mask = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0xff</span>;\n\n   x = (x &gt;&gt; <span class=\"hljs-number\">16</span>) + (x &amp; mask); <span class=\"hljs-comment\">// sum base 4^8 digits (a &lt;= 0x1FFFE)</span>\n   x = (x &gt;&gt; <span class=\"hljs-number\">8</span>) + (x &amp; <span class=\"hljs-number\">0xff</span>); <span class=\"hljs-comment\">// sum base 4^4 digits (a &lt;= 0x2FD)</span>\n   x = (x &gt;&gt; <span class=\"hljs-number\">4</span>) + (x &amp; <span class=\"hljs-number\">0xf</span>); <span class=\"hljs-comment\">// sum base 4^2 digits (a &lt;= 0x3C)</span>\n   x = (x &gt;&gt; <span class=\"hljs-number\">2</span>) + (x &amp; <span class=\"hljs-number\">0x3</span>); <span class=\"hljs-comment\">// sum base 4^1 digits (a &lt;= 0x1D)</span>\n   x = (x &gt;&gt; <span class=\"hljs-number\">2</span>) + (x &amp; <span class=\"hljs-number\">0x3</span>); <span class=\"hljs-comment\">// sum base 4^1 digits (a &lt;= 0x9)</span>\n   x = (x &gt;&gt; <span class=\"hljs-number\">2</span>) + (x &amp; <span class=\"hljs-number\">0x3</span>); <span class=\"hljs-comment\">// sum base 4^1 digits (a &lt;= 0x4)</span>\n\n   x = (((x + <span class=\"hljs-number\">1</span>) &gt;&gt; <span class=\"hljs-number\">2</span>) + x) &amp; <span class=\"hljs-number\">0x3</span>;\n   <span class=\"hljs-keyword\">return</span> x;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>这题难度算是比较大的，我参考了一些资料最后才写出这个代码。其实这题也与bitsCount有着一定的联系。</p>\n<p>对于解这题有一个根本的公式即 </p>\n</blockquote>\n<pre><code>a % m = ((b % m)(a/b) + (a % b)) % m\n其中b是进制数\n</code></pre><blockquote>\n<p>我们知道，如果想要知道一个十进制的数能否被三整除，只要看它所有数位之和是否能被三整除就行了。其实这就是上述公式的特殊情况，由于10 mod 3 == 1 所以其就退化为</p>\n</blockquote>\n<pre><code>a mod m = (a/b + a % b) % m\n递归下来就是所有数位之和\n</code></pre><blockquote>\n<p>而对于二进制的情况，我们可以将进制位b选为4，这样正好是两位二进制数，同时4 % 3 == 1，这样一来，对于二进制数中我们只需要统计所有两两数位(四进制)的和能否被三整除就行了。</p>\n<p>而考虑到我们每做一次 a/b + a % b 统计数位和都减小了数的规模，这样只要做有限次就能够将数控制在&lt;=3的范围内。</p>\n<p>对于a % 4，这是一个经典的trivial情况，我们只需要做 a &amp; 3，就能够轻松得到a % 4的值。而对于a/4，只需要做a &gt;&gt; 2即可。</p>\n<p>对于二进制数我们不仅可以按两位两位的四进制数位和来数，也可以直接数其倍数(4^i)，从最大4^8开始统计，一步步减小x的值，最后将x做到&lt;= 3的范围</p>\n<p>最后要判断x是否为3，如果为3的话则要置为0，我利用3数位全为1的特点，将其+1进位后，右移2位。如果为3，则得到的是1。将其再加上x，如若x是1或2，则还是不变，但如果是3，它又会进位到4，那么我们只要再与上0x3，则会得到0，即为想要的结果。</p>\n</blockquote>\n<hr>\n<h3 id=\"3-float-f2i—float转int\"><a href=\"#3-float-f2i—float转int\" class=\"headerlink\" title=\"3. float_f2i—float转int\"></a><strong>3. float_f2i—float转int</strong></h3><p><strong>题目：</strong></p>\n<pre><code>输入一个按二进制位储存的float（以unsigned表示），将其转为int输出。(NaN,inf，溢出直接返回参数)\n</code></pre><p><strong>可使用操作：</strong> 所有的整型操作，包括 ||, &amp;&amp;. 以及 if, while</p>\n<p><strong>最大操作数限制：</strong> 30</p>\n<p><strong>使用操作数：</strong> 17</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">float_f2i</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">unsigned</span> uf)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n   <span class=\"hljs-keyword\">int</span> sign, <span class=\"hljs-built_in\">exp</span>, frac, res;\n   <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">int</span> tmp;\n\n   <span class=\"hljs-keyword\">if</span>(!uf)\n      <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n   sign = uf &amp; <span class=\"hljs-number\">0x80000000</span>;\n   <span class=\"hljs-built_in\">exp</span> = uf &amp; <span class=\"hljs-number\">0x7f800000</span>;\n   frac = (uf &amp; <span class=\"hljs-number\">0x007fffff</span>) | <span class=\"hljs-number\">0x00800000</span>;\n\n   <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> == <span class=\"hljs-number\">0x7f800000</span>) <span class=\"hljs-comment\">//NaN and inf</span>\n      <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0x80000000</span>u;\n\n   <span class=\"hljs-built_in\">exp</span> &gt;&gt;= <span class=\"hljs-number\">23</span>;\n\n   <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> &lt; <span class=\"hljs-number\">127</span>)\n      <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n   <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> &gt; <span class=\"hljs-number\">158</span>)\n      <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0x80000000</span>u;\n   <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> &gt; <span class=\"hljs-number\">150</span>)\n      tmp = frac &lt;&lt; (<span class=\"hljs-built_in\">exp</span> - <span class=\"hljs-number\">150</span>);\n   <span class=\"hljs-keyword\">else</span>\n      tmp = frac &gt;&gt; (<span class=\"hljs-number\">150</span> - <span class=\"hljs-built_in\">exp</span>);\n\n      \n   <span class=\"hljs-keyword\">if</span>(sign)\n      res = ~tmp + <span class=\"hljs-number\">1</span>;\n   <span class=\"hljs-keyword\">else</span>\n      res = tmp;\n   \n   <span class=\"hljs-keyword\">return</span> res | sign;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>这题特殊情况比较多，把NaN和inf处理一下，然后注意一下溢出情况，即取出来的exp - bias &gt; 31，肯定超过2^31整型储存的最大值，直接返回0x80000000u，然后对于exp小于127的，其指数是负数，直接返回int值为0。对于在exp - bias 在 0 到 31 之间的，由于frac只有23位，所以要将注意一下讨论23的情况。</p>\n<p>最后把取出来的符号位对一下，如果负数取反加一，正数直接等，最后再或上符号位，返回答案。</p>\n</blockquote>\n<hr>\n<h2 id=\"结果截图\"><a href=\"#结果截图\" class=\"headerlink\" title=\"结果截图\"></a><strong>结果截图</strong></h2><h3 id=\"bits-c\"><a href=\"#bits-c\" class=\"headerlink\" title=\"bits.c\"></a><strong>bits.c</strong></h3><p><img src=\"/CsBlog/CsBlog/2020/11/05/ICS/ICS_Lab1/ICS_Lab1/bits_btest.JPG\" alt=\"bits_btest\"></p>\n<p><img src=\"/CsBlog/CsBlog/2020/11/05/ICS/ICS_Lab1/ICS_Lab1/bits_dlc.png\" alt=\"bits_dlc\"></p>\n<h3 id=\"bits-honor-c\"><a href=\"#bits-honor-c\" class=\"headerlink\" title=\"bits_honor.c\"></a><strong>bits_honor.c</strong></h3><p><img src=\"/CsBlog/CsBlog/2020/11/05/ICS/ICS_Lab1/ICS_Lab1/bits_honor_btest.JPG\" alt=\"bits_honor_btest\"></p>\n<p><img src=\"/CsBlog/CsBlog/2020/11/05/ICS/ICS_Lab1/ICS_Lab1/bits_honor_dlc.png\" alt=\"bits_honor_dlc\"></p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><hr>\n<p><a href=\"https://baike.baidu.com/item/%E7%AE%97%E6%9C%AF%E5%8F%B3%E7%A7%BB/3711081?fr=aladdin\">https://baike.baidu.com/item/%E7%AE%97%E6%9C%AF%E5%8F%B3%E7%A7%BB/3711081?fr=aladdin</a><br><a href=\"https://blog.csdn.net/jiahonghao2002/article/details/108223366\">https://blog.csdn.net/jiahonghao2002/article/details/108223366</a><br><a href=\"https://leetcode-cn.com/problems/reverse-bits/solution/dian-dao-er-jin-zhi-wei-by-leetcode/\">https://leetcode-cn.com/problems/reverse-bits/solution/dian-dao-er-jin-zhi-wei-by-leetcode/</a><br><a href=\"http://homepage.cs.uiowa.edu/~jones/bcd/mod.shtml#exmod3\">http://homepage.cs.uiowa.edu/~jones/bcd/mod.shtml#exmod3</a><br><a href=\"https://www.zhihu.com/question/38206659/answer/763034261\">https://www.zhihu.com/question/38206659/answer/763034261</a><br><a href=\"https://blog.csdn.net/xindaxinda123/article/details/95617758\">https://blog.csdn.net/xindaxinda123/article/details/95617758</a><br><a href=\"https://www.runoob.com/w3cnote/32-float-storage.html\">https://www.runoob.com/w3cnote/32-float-storage.html</a></p>\n"},{"title":"ICS-Lab4.2 各种链接姿势","date":"2020-11-16T01:37:43.000Z","index_img":"/img/ICS_Lab1/top.jpg","_content":"\n### Task0 - 简单链接\n\n```cpp\n#include \"some.h\"\n\nint main(){\n    testPrint();\n    testPrint(5);\n    notATest();\n    return 0;\n}\n```\n\n- **错误分析**\n\n> 我们可以看到main函数中调用了三个函数，全是外部的，在链接时，符号表会进行搜索匹配。我们再来看some.h中定义了哪些函数.\n\n```cpp\n#include <cstdio>\n\nvoid testPrint();\nvoid testPrint(int num);\n```\n\n> 发现只有两个test函数,而没有notATest定义的函数，根据这个离谱的名字我们可以断定在cstdio中也没有同名函数。\n所以最后符号表中没有匹配上，会引发链接错误。\n\n- **解决方法**\n\n> 直接将 notATest() 注释掉, 再在 makefile 中使用 \n```\ng++ main.cpp some.cpp -o main \n```\n\n---\n\n### Task1 - 链接与重复包含问题\n\n- **解题过程**\n\n通过阅读代码，我们可以发现改题的代码会根据宏DEBUG是否被定义而有不同的行为，决定是否打印更加详细的内容\n\n```cpp\n#include \"function0.h\"\n\nvoid func0(){\n    # ifdef DEBUG\n    printDebug(); //打印debug信息 (详细操作在shared.cpp中)\n    # else\n    print(); //打印正常信息\n    # endif\n}\n```\n\n> 根据题意，我们需要在 Makefile 中,对于要求的 main1 需要做一个相等的条件判断\n\n```makefile\nmain0:\n    g++ main0.cpp function0.cpp function1.cpp shared.cpp -o main0\ndebug = False\nmain1:\nifeq ($(debug),True) \n\tg++ main1.cpp -DDEBUG function0.cpp function1.cpp shared.cpp -o main1\nelse\n\tg++ main1.cpp function0.cpp function1.cpp shared.cpp -o main1\nendif\n```\n\n*值得注意的是，makefile中 if 语句前不能有 tab 或者空格*\n\n**Include 路径**\n![](https://s3.ax1x.com/2020/11/15/DFeVyt.png)\n\n- **问题**\n\n1. 为什么两个function.h都引⽤了shared.h⽽没有出问题？本来有可能出什么问题。\n\n\n> 因为 shared.h 中仅包含函数声明，而不包含函数的定义，因而不会有重定义问题。如果 #include shared.cpp 则会出现重定义问题。\n\n\n2. 如果把shared.h中注释掉的变量定义取消注释会出什么问题？为什么？\n\n> 会出现变量重定义问题，由于全局变量 string 被两次 include 到func0 和 func1 中，最后被同时引用至 main 中，导致重定义。在符号表中产生冲突，报错。\n\n3. 通常使⽤shared.h中另外被注释掉的宏命令(#开头的那些⾏)来规避重复引⽤的⻛险，原理是什么？取消这些注释之后上⼀题的问题解除了吗？背后的原因是什么？\n\n> 通过宏定义，在第一次 include 的时候定义宏为函数名，之后再次include 的时候由于已经 define 就不再次 include。这种方式的缺点是如果有已有宏名与函数名重复时，将会报错。使用 #pragama once 则是由c++编译器保证 include 一次，不会有宏名重复问题。\n\n> 上题的问题并没有解决，因为FOO是全局变量，其赋了初值，被链接器标记为strong，被重复 include 到了 main 中，两个 strong 标记冲突报错。\n\n---\n\n### Task2 - 静态链接库\n\n在这个 Task 中我们需要编译2个静态链接库，并链接3个静态链接库，完成编译。\n\n**A Makefile**\n```makefile\nlibA:\t\n\tg++ -c A.cpp \n\tar -r libA.a A.o\n```\n\n> 先用g++ -c编译出A.o可重定位目标文件，再通过 ar 命令编译静态链接库。（libC 同理）\n\n**Main Makefile**\n```makefile\nmain : \n\tcd A && make libA\n\tcd C && make libC\n\tg++ main.cpp B/libB.a A/libA.a C/libC.a -o main\n```\n\n> 再 CD 入每个目录进行 make 编译， 最后把静态链接库进行链接。 \n\n- **静态库链接搜索路径顺序：**\n\n1. ld会去找GCC命令中的参数-L\n2. 再找gcc的环境变量LIBRARY_PATH\n3. 再找内定目录 /lib /usr/lib /usr/local/lib \n\n- **问题**\n\n1. 若有多个静态链接库需要链接，写命令时需要考虑静态链接库和源⽂件在命令中的顺序吗？是否需要考虑是由什么决定的？\n> **需要考虑**，链接器在链接过程中按命令中输入的顺序进行符号表匹配，可以将这个匹配过程抽象的看作链接器在维护三个集合 E(待合并文件), U(被引用且尚未匹配), D（已匹配），根据顺序动态更新E, 和U,D, 最后如果 U 为空则正常整合 E 生成可执行文件，不然则报错有符号被引用了但未能匹配。所以如果我们的静态库都是相互独立的，那么顺序是没关系的。但如果互相依赖，那么我们必须保证在对某个符号的引用的库后，必然有一个库中存在对其的定义，不然则会报错。\n\n1. 可以使⽤size main命令来查看可执⾏⽂件所占的空间，输出结果的每⼀项是什么意思？\n\n| text  | data   |  bss  |  dec   | hex | filename |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n|  22721  |  712  |  288 |  23721  | 5ca9 | main |\n\n- **text:** 机器代码字节\n- **data:** 包含静态变量和已经初始化的全局变量的数据段字节数大小\n- **bss:** Block Started by Symbol (better save space) 存放程序中未初始化的全局变量的字节数大小，BBS段属于静态内存分配, 不占真实内存空间（仅占位符）\n- **dec:** = test + data + bss\n- **hex:** 16进制的dec\n- **filename:** 顾名思义，文件名\n\n---\n\n### Task3 - 动态链接库\n\n整体操作和上一个Task很像，只是链接的是动态链接库 .so\n\n**A Makefile**\n```makefile\nlibA:\n\tg++ -fPIC -c A.cpp\n\tg++ -shared -fPIC A.o -o libA.so\n```\n\n> 在 A 中先编译出 A.o 再用 -shared 编译出动态链接库 .so\n\n**Main Makefile**\n```makefile\nmain : \n\tcd A && make libA\n\tcd C && make libC\n\tg++ main.cpp A/libA.so ./libB.so C/libC.so -o main\n```\n\n> 直接 cd 进去 make 出动态链接库后，再进行链接。\n\n- **问题**\n\n1. 动态链接库在运⾏时也需要查找库的位置，在Linux中，运⾏时动态链接库的查找顺序是怎样的？\n> **动态链接时、执行时搜索路径顺序:**\n> 1. 编译目标代码时指定的动态库搜索路径\n> 2. 环境变量LD_LIBRARY_PATH指定的动态库搜索路径\n> 3. 配置文件/etc/ld.so.conf中指定的动态库搜索路径\n> 4. 默认的动态库搜索路径/lib\n> 5. 默认的动态库搜索路径/usr/lib\n\n2. 使⽤size main查看编译出的可执⾏⽂件占据的空间，与使⽤静态链接库相⽐占⽤空间有何变化？哪些部分的哪些代码（也要具体到本task）会导致编译出⽂件的占⽤空间发⽣这种变化？\n\n| text  | data  |  bss  |  dec  | hex | filename |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n|  3089 | 720  | 96 | 3905 | f41  |  main |\n\n> **占用空间变小了**，因为不同于静态链接库将所有的静态库都整合入可执行文件中，动态链接库是在程序开始或正在运行时被链接加载的，所有可执行文件本身的空间占用会大幅缩小。\n\n> main 中调用了 A, B, C 函数，所以其中的函数以及静态全局变量 A_name, B_name 会被被置于动态链接库.so中动态加载\n\n1. 编译动态链接库时-fPIC的作⽤是什么，不加会有什么后果？\n-fPIC 含义是 Generate position-independent code (PIC)，例如在汇编的 jmp 语句中通常使用的是固定的内部地址\n```\n100: COMPARE REG1, REG2\n101: JUMP_IF_EQUAL 111\n...\n111: NOP\n```\n> 而通过 -fPIC 参数 jmp 语句所指向的是相对地址\n使用的是代码段和数据段的OFFSET，从而实现位置无关，可以动态加载到内存中，不同进程可以共享。\n\n```\n100: COMPARE REG1, REG2\n101: JUMP_IF_EQUAL CURRENT+10\n...\n111: NOP\n```\n\n> 如果不加，在某些系统下不会有很大的问题，但一般在 -shared 后面最好加上 -fPIC 来保证动态链接库是位置无关的，不然无法实现动态链接（由于位置相关即分配绝对内存地址，导致多个副本存在于内存中，无法实现动态链接）\n\n**info in gcc manual**\n\n- **-shared:**  Produce a shared object which can then be linked with other objects to forman executable. Not all systems support this option. For predictable results,\nyou must also specify the same set of options used for compilation (‘-fpic’,‘-fPIC’, or model suboptions) when you specify this linker option.*\n\n4. 现在被⼴泛使⽤的公开的动态链接库如何进⾏版本替换或共存（以linux系统为例）？\n\n> 通过动态链接，如果开发者需要维护程序的某一部分（某几个功能的函数），仅需要维护修改所在的动态链接库即可，然后将其发布。用户只需要替换动态链接库，在程序运行的时候自然会动态链接到新的链接库，**在接口保持不变**的情况下完成很自然流畅的版本更新。\n\n---\n\n### Task4 - ld手动链接\n\n- **解题过程**\n这题要求我们用ld链接器，进行手动链接，我们先试一下直接链接会发生什么\n\n```makefile\n#链接代码\nld -o main main.o some.o\n```\n\n```cpp\n//报错信息\nld: warning: cannot find entry symbol _start; defaulting to 00000000004000b0\nsome.o: In function `notATest()':\nsome.cpp:(.text+0xc): undefined reference to `puts'\nsome.o: In function `testPrint()':\nsome.cpp:(.text+0x1f): undefined reference to `puts'\nsome.o: In function `testPrint(int)':\nsome.cpp:(.text+0x52): undefined reference to `printf'\nMakefile:2: recipe for target 'main' failed\nmake: *** [main] Error 1\n```\n\n> 发现主要报错信息是 undefined reference to 'puts', 'printf', 说明标准库中的函数符号没有被成功匹配，我们需要把 stdc 加进去\n\n```makefile\n# 链接代码\nld -o main main.o some.o -lc\n# 通过 -lc 命令直接添加标准库，也可以自行指定libc.so路径\n```\n\n> 可以发现main被成功编译出来，但运行时候发现bash报目录中无此文件\n```bash\nbash: ./main: No such file or directory\n```\n\n> 也就是我们并不能运行这个可执行文件，查找资料之后我们尝试指定使用的动态链接器再进行编译，就可以运行了\n\n```makefile\nld -dynamic-linker /lib64/ld-linux-x86-64.so.2 -o main main.o some.o -lc\n```\n\n> 我查询了ld的手册试图查找原因，但并未发现为什么必须要使用--dynamic-linker指令\n\n<div style=\"page-break-after: always;\"></div>\n\n\n- **--dynamic-linker=file**\n>    Set the name of the dynamic linker.  This is only meaningful when generating dynamically linked ELF executables.  **The default dynamic linker is normally correct; don't use this unless you know what you are doing.**\n\n\n\n> 接下去，我们的程序虽然能够运行起来了，但在 main 函数跑完之后会出现 *Segmentation fault (core dumped)* 提示，这也提示了我们对于 main 函数的初始化和结束可能并未正常执行。\n\n- **GDB查看正常程序**\n\n![](https://s3.ax1x.com/2020/11/15/DFeZOP.png)\n\n> 通过 gdb 查看正常程序我们发现，正常的 main 函数执行栈中需要有两个函数为其保证环境 *__lib_csu_init* 和 *__libc_start_main*\n\n- **__libc_start_main**\n我们需要知道，在linux中，main函数的初始化环境和参数传递以及返回值处理工作是由 __libc_start_main 来保证的。一个正常的程序执行需要包含以下要素。\n\n1. performing any necessary security checks if the effective user ID is not the same as the real user ID.\n2. initialize the threading subsystem.\n3. registering the *rtld_fini* to release resources when this dynamic shared object exits (or is unloaded).\n4. registering the *fini* handler to run at program exit.\n5. calling the initializer function *(*init)()*.\n6. calling *main()* with appropriate arguments.\n7. calling *exit()* with the return value from *main()*.\n\n> 具体的初始化和结束调用路径异常复杂，在此不多赘述，放一张图有待进一步研究。\n\n![](https://s3.ax1x.com/2020/11/15/DFemef.png)\n\n*图片来源: https://luomuxiaoxiao.com/?p=516*\n\n---\n\n然后介绍完了主函数的初始化和返回，我们需要知道保证上述的两个函数在哪个动态链接库中，这就涉及到了 *crt1.o, crti.o, crtbegin.o, crtend.o, crtn.o* 这几个库\n*参考： https://blog.csdn.net/farmwang/article/details/73195951*\n\n> **crt是c runtime 的缩写**,用于执行进入main之前的初始化和退出main之后的扫尾工作。\n\n| 目标文件 | crt1.o| crti.o| crtbegin.o| crtend.o | crtn.o |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 作用 | 启动|初始化|构造|析构|结束 |\n\n> 在标准的linux平台下,link的顺序是\n\n\tld crt1.o crti.o [user_objects] [system_libraries] crtn.o\n\n所以我们按照顺序进行链接有如下命令\n\n```makefile\n# 链接指令\nld -dynamic-linker /lib64/ld-linux-x86-64.so.2 -o main /usr/lib/x86_64-linux-gnu/crt1.o main.o some.o -lc /usr/lib/x86_64-linux-gnu/crti.o /usr/lib/x86_64-linux-gnu/crtn.o\n```\n\n> 成功的手动完成了程序的链接工作。\n\n以上艰苦的工作告诉我们，不要轻易尝试手动链接，除非你知道你在干什么。平时好好用 gcc。\n\n- 动态链接器⼀个操作系统中只需要⼀个吗？为什么？\n> 一般来说只要有一个支持的动态链接器即可，完成程序的动态链接工作。 但linux中可能有两个 ld 的版本\n1. ld.so针对a.out格式的二进制可执行文件\n2. ld-linux.so针对ELF格式的二进制可执行文件\n\na.out是旧版类Unix系统中用于执行档、目的码和后来系统中的函数库的一种文件格式，该版本的链接器仍被保留用以向前支持。\n\n---\n\n### Task5 - 运行时打桩\n\nTask5 是一个典型的运行时打桩的 task，给了我们编译好的login程序，让我们改变其行为，让它能够输出 login_success.\n\n> 阅读源码，我们可以发现，login将我们输入的字符串做了hash，与已有某不明hash值，进行比较，如果相等则登陆成功。根据本 lab 的内容主要是讲 make 和链接的，让我们碰撞这个hash显然不是本意。那另一种方法就是通过运行时打桩，改变标准库的链接方式，让strcmp 链接到我们自己写的 strcmp 版本上去，从而我们可以控制其返回值让其返回0使得登陆成功。\n\n*首先要注意 strcmp 并非只有判断密码时的一次唯一调用，在别处还有调用，所以我们要保证 strcmp 函数的基本功能正确*\n```cpp\n// mystrcmp.c\n#define _GNU_SOURCE\n#include <stdio.h>\n#include <dlfcn.h>\n\nint strcmp(const char *lhs, const char *rhs)\n{\n    int(*strcmpp)(const char *lhs, const char *rhs);\n    strcmpp = dlsym(RTLD_NEXT, \"strcmp\");\n\n    char tmp[] = \"3983709877683599140\";\n    if(strcmpp(tmp, rhs) == 0)\n        return 0;\n    return strcmpp(lhs, rhs);\n}\n```\n\n> 我们直接写一个自己的 strcmp 版本，用 dlsym 可以获取在运行时 strcmp 函数的指针 *（不这样做也可以，可以直接自己重写一遍strcmp程序）*，相当于可以直接使用 **真实的标准库中的 strcmp**，然后我们稍微改写一下，让它和我们的hash值比较的时候直接返回0，能够让我们不管输入什么密码都能够 login_success。\n\n接下来我们先将我们写的strcmp编译成动态链接库\n\n```shell\ngcc -shared -fpic -o mystrcmp.so mystrcmp.c -ldl\n```\n\n> 然后使用 **LD_PRELOAD=\"./mystrcmp.so\"** 指令，从而在 strcmp 动态链接到标准库之前让其优先匹配我们写的动态链接库中的 strcmp 符号。\n\n这里需要注意由于是要直接运行 ./login, 所以我们需要把LD_PRELOAD的效果全局化，也既在前面加上 export 标记。\n\n```shell\nexport LD_PRELOAD=\"./mystrcmp.so\"\n```\n\n最后注意不要忘记卸载全局 preload， 不然之后所有程序都 preload 这个strcmp。\n\n```shell\nexport LD_PRELOAD=NULL\n```","source":"_posts/ICS/ICS_Lab3.md","raw":"---\ntitle: ICS-Lab4.2 各种链接姿势\ndate: 2020-11-15 17:37:43\nindex_img: /img/ICS_Lab1/top.jpg\ncategory: [ICS]\ntags: [Linker]\n---\n\n### Task0 - 简单链接\n\n```cpp\n#include \"some.h\"\n\nint main(){\n    testPrint();\n    testPrint(5);\n    notATest();\n    return 0;\n}\n```\n\n- **错误分析**\n\n> 我们可以看到main函数中调用了三个函数，全是外部的，在链接时，符号表会进行搜索匹配。我们再来看some.h中定义了哪些函数.\n\n```cpp\n#include <cstdio>\n\nvoid testPrint();\nvoid testPrint(int num);\n```\n\n> 发现只有两个test函数,而没有notATest定义的函数，根据这个离谱的名字我们可以断定在cstdio中也没有同名函数。\n所以最后符号表中没有匹配上，会引发链接错误。\n\n- **解决方法**\n\n> 直接将 notATest() 注释掉, 再在 makefile 中使用 \n```\ng++ main.cpp some.cpp -o main \n```\n\n---\n\n### Task1 - 链接与重复包含问题\n\n- **解题过程**\n\n通过阅读代码，我们可以发现改题的代码会根据宏DEBUG是否被定义而有不同的行为，决定是否打印更加详细的内容\n\n```cpp\n#include \"function0.h\"\n\nvoid func0(){\n    # ifdef DEBUG\n    printDebug(); //打印debug信息 (详细操作在shared.cpp中)\n    # else\n    print(); //打印正常信息\n    # endif\n}\n```\n\n> 根据题意，我们需要在 Makefile 中,对于要求的 main1 需要做一个相等的条件判断\n\n```makefile\nmain0:\n    g++ main0.cpp function0.cpp function1.cpp shared.cpp -o main0\ndebug = False\nmain1:\nifeq ($(debug),True) \n\tg++ main1.cpp -DDEBUG function0.cpp function1.cpp shared.cpp -o main1\nelse\n\tg++ main1.cpp function0.cpp function1.cpp shared.cpp -o main1\nendif\n```\n\n*值得注意的是，makefile中 if 语句前不能有 tab 或者空格*\n\n**Include 路径**\n![](https://s3.ax1x.com/2020/11/15/DFeVyt.png)\n\n- **问题**\n\n1. 为什么两个function.h都引⽤了shared.h⽽没有出问题？本来有可能出什么问题。\n\n\n> 因为 shared.h 中仅包含函数声明，而不包含函数的定义，因而不会有重定义问题。如果 #include shared.cpp 则会出现重定义问题。\n\n\n2. 如果把shared.h中注释掉的变量定义取消注释会出什么问题？为什么？\n\n> 会出现变量重定义问题，由于全局变量 string 被两次 include 到func0 和 func1 中，最后被同时引用至 main 中，导致重定义。在符号表中产生冲突，报错。\n\n3. 通常使⽤shared.h中另外被注释掉的宏命令(#开头的那些⾏)来规避重复引⽤的⻛险，原理是什么？取消这些注释之后上⼀题的问题解除了吗？背后的原因是什么？\n\n> 通过宏定义，在第一次 include 的时候定义宏为函数名，之后再次include 的时候由于已经 define 就不再次 include。这种方式的缺点是如果有已有宏名与函数名重复时，将会报错。使用 #pragama once 则是由c++编译器保证 include 一次，不会有宏名重复问题。\n\n> 上题的问题并没有解决，因为FOO是全局变量，其赋了初值，被链接器标记为strong，被重复 include 到了 main 中，两个 strong 标记冲突报错。\n\n---\n\n### Task2 - 静态链接库\n\n在这个 Task 中我们需要编译2个静态链接库，并链接3个静态链接库，完成编译。\n\n**A Makefile**\n```makefile\nlibA:\t\n\tg++ -c A.cpp \n\tar -r libA.a A.o\n```\n\n> 先用g++ -c编译出A.o可重定位目标文件，再通过 ar 命令编译静态链接库。（libC 同理）\n\n**Main Makefile**\n```makefile\nmain : \n\tcd A && make libA\n\tcd C && make libC\n\tg++ main.cpp B/libB.a A/libA.a C/libC.a -o main\n```\n\n> 再 CD 入每个目录进行 make 编译， 最后把静态链接库进行链接。 \n\n- **静态库链接搜索路径顺序：**\n\n1. ld会去找GCC命令中的参数-L\n2. 再找gcc的环境变量LIBRARY_PATH\n3. 再找内定目录 /lib /usr/lib /usr/local/lib \n\n- **问题**\n\n1. 若有多个静态链接库需要链接，写命令时需要考虑静态链接库和源⽂件在命令中的顺序吗？是否需要考虑是由什么决定的？\n> **需要考虑**，链接器在链接过程中按命令中输入的顺序进行符号表匹配，可以将这个匹配过程抽象的看作链接器在维护三个集合 E(待合并文件), U(被引用且尚未匹配), D（已匹配），根据顺序动态更新E, 和U,D, 最后如果 U 为空则正常整合 E 生成可执行文件，不然则报错有符号被引用了但未能匹配。所以如果我们的静态库都是相互独立的，那么顺序是没关系的。但如果互相依赖，那么我们必须保证在对某个符号的引用的库后，必然有一个库中存在对其的定义，不然则会报错。\n\n1. 可以使⽤size main命令来查看可执⾏⽂件所占的空间，输出结果的每⼀项是什么意思？\n\n| text  | data   |  bss  |  dec   | hex | filename |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n|  22721  |  712  |  288 |  23721  | 5ca9 | main |\n\n- **text:** 机器代码字节\n- **data:** 包含静态变量和已经初始化的全局变量的数据段字节数大小\n- **bss:** Block Started by Symbol (better save space) 存放程序中未初始化的全局变量的字节数大小，BBS段属于静态内存分配, 不占真实内存空间（仅占位符）\n- **dec:** = test + data + bss\n- **hex:** 16进制的dec\n- **filename:** 顾名思义，文件名\n\n---\n\n### Task3 - 动态链接库\n\n整体操作和上一个Task很像，只是链接的是动态链接库 .so\n\n**A Makefile**\n```makefile\nlibA:\n\tg++ -fPIC -c A.cpp\n\tg++ -shared -fPIC A.o -o libA.so\n```\n\n> 在 A 中先编译出 A.o 再用 -shared 编译出动态链接库 .so\n\n**Main Makefile**\n```makefile\nmain : \n\tcd A && make libA\n\tcd C && make libC\n\tg++ main.cpp A/libA.so ./libB.so C/libC.so -o main\n```\n\n> 直接 cd 进去 make 出动态链接库后，再进行链接。\n\n- **问题**\n\n1. 动态链接库在运⾏时也需要查找库的位置，在Linux中，运⾏时动态链接库的查找顺序是怎样的？\n> **动态链接时、执行时搜索路径顺序:**\n> 1. 编译目标代码时指定的动态库搜索路径\n> 2. 环境变量LD_LIBRARY_PATH指定的动态库搜索路径\n> 3. 配置文件/etc/ld.so.conf中指定的动态库搜索路径\n> 4. 默认的动态库搜索路径/lib\n> 5. 默认的动态库搜索路径/usr/lib\n\n2. 使⽤size main查看编译出的可执⾏⽂件占据的空间，与使⽤静态链接库相⽐占⽤空间有何变化？哪些部分的哪些代码（也要具体到本task）会导致编译出⽂件的占⽤空间发⽣这种变化？\n\n| text  | data  |  bss  |  dec  | hex | filename |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n|  3089 | 720  | 96 | 3905 | f41  |  main |\n\n> **占用空间变小了**，因为不同于静态链接库将所有的静态库都整合入可执行文件中，动态链接库是在程序开始或正在运行时被链接加载的，所有可执行文件本身的空间占用会大幅缩小。\n\n> main 中调用了 A, B, C 函数，所以其中的函数以及静态全局变量 A_name, B_name 会被被置于动态链接库.so中动态加载\n\n1. 编译动态链接库时-fPIC的作⽤是什么，不加会有什么后果？\n-fPIC 含义是 Generate position-independent code (PIC)，例如在汇编的 jmp 语句中通常使用的是固定的内部地址\n```\n100: COMPARE REG1, REG2\n101: JUMP_IF_EQUAL 111\n...\n111: NOP\n```\n> 而通过 -fPIC 参数 jmp 语句所指向的是相对地址\n使用的是代码段和数据段的OFFSET，从而实现位置无关，可以动态加载到内存中，不同进程可以共享。\n\n```\n100: COMPARE REG1, REG2\n101: JUMP_IF_EQUAL CURRENT+10\n...\n111: NOP\n```\n\n> 如果不加，在某些系统下不会有很大的问题，但一般在 -shared 后面最好加上 -fPIC 来保证动态链接库是位置无关的，不然无法实现动态链接（由于位置相关即分配绝对内存地址，导致多个副本存在于内存中，无法实现动态链接）\n\n**info in gcc manual**\n\n- **-shared:**  Produce a shared object which can then be linked with other objects to forman executable. Not all systems support this option. For predictable results,\nyou must also specify the same set of options used for compilation (‘-fpic’,‘-fPIC’, or model suboptions) when you specify this linker option.*\n\n4. 现在被⼴泛使⽤的公开的动态链接库如何进⾏版本替换或共存（以linux系统为例）？\n\n> 通过动态链接，如果开发者需要维护程序的某一部分（某几个功能的函数），仅需要维护修改所在的动态链接库即可，然后将其发布。用户只需要替换动态链接库，在程序运行的时候自然会动态链接到新的链接库，**在接口保持不变**的情况下完成很自然流畅的版本更新。\n\n---\n\n### Task4 - ld手动链接\n\n- **解题过程**\n这题要求我们用ld链接器，进行手动链接，我们先试一下直接链接会发生什么\n\n```makefile\n#链接代码\nld -o main main.o some.o\n```\n\n```cpp\n//报错信息\nld: warning: cannot find entry symbol _start; defaulting to 00000000004000b0\nsome.o: In function `notATest()':\nsome.cpp:(.text+0xc): undefined reference to `puts'\nsome.o: In function `testPrint()':\nsome.cpp:(.text+0x1f): undefined reference to `puts'\nsome.o: In function `testPrint(int)':\nsome.cpp:(.text+0x52): undefined reference to `printf'\nMakefile:2: recipe for target 'main' failed\nmake: *** [main] Error 1\n```\n\n> 发现主要报错信息是 undefined reference to 'puts', 'printf', 说明标准库中的函数符号没有被成功匹配，我们需要把 stdc 加进去\n\n```makefile\n# 链接代码\nld -o main main.o some.o -lc\n# 通过 -lc 命令直接添加标准库，也可以自行指定libc.so路径\n```\n\n> 可以发现main被成功编译出来，但运行时候发现bash报目录中无此文件\n```bash\nbash: ./main: No such file or directory\n```\n\n> 也就是我们并不能运行这个可执行文件，查找资料之后我们尝试指定使用的动态链接器再进行编译，就可以运行了\n\n```makefile\nld -dynamic-linker /lib64/ld-linux-x86-64.so.2 -o main main.o some.o -lc\n```\n\n> 我查询了ld的手册试图查找原因，但并未发现为什么必须要使用--dynamic-linker指令\n\n<div style=\"page-break-after: always;\"></div>\n\n\n- **--dynamic-linker=file**\n>    Set the name of the dynamic linker.  This is only meaningful when generating dynamically linked ELF executables.  **The default dynamic linker is normally correct; don't use this unless you know what you are doing.**\n\n\n\n> 接下去，我们的程序虽然能够运行起来了，但在 main 函数跑完之后会出现 *Segmentation fault (core dumped)* 提示，这也提示了我们对于 main 函数的初始化和结束可能并未正常执行。\n\n- **GDB查看正常程序**\n\n![](https://s3.ax1x.com/2020/11/15/DFeZOP.png)\n\n> 通过 gdb 查看正常程序我们发现，正常的 main 函数执行栈中需要有两个函数为其保证环境 *__lib_csu_init* 和 *__libc_start_main*\n\n- **__libc_start_main**\n我们需要知道，在linux中，main函数的初始化环境和参数传递以及返回值处理工作是由 __libc_start_main 来保证的。一个正常的程序执行需要包含以下要素。\n\n1. performing any necessary security checks if the effective user ID is not the same as the real user ID.\n2. initialize the threading subsystem.\n3. registering the *rtld_fini* to release resources when this dynamic shared object exits (or is unloaded).\n4. registering the *fini* handler to run at program exit.\n5. calling the initializer function *(*init)()*.\n6. calling *main()* with appropriate arguments.\n7. calling *exit()* with the return value from *main()*.\n\n> 具体的初始化和结束调用路径异常复杂，在此不多赘述，放一张图有待进一步研究。\n\n![](https://s3.ax1x.com/2020/11/15/DFemef.png)\n\n*图片来源: https://luomuxiaoxiao.com/?p=516*\n\n---\n\n然后介绍完了主函数的初始化和返回，我们需要知道保证上述的两个函数在哪个动态链接库中，这就涉及到了 *crt1.o, crti.o, crtbegin.o, crtend.o, crtn.o* 这几个库\n*参考： https://blog.csdn.net/farmwang/article/details/73195951*\n\n> **crt是c runtime 的缩写**,用于执行进入main之前的初始化和退出main之后的扫尾工作。\n\n| 目标文件 | crt1.o| crti.o| crtbegin.o| crtend.o | crtn.o |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 作用 | 启动|初始化|构造|析构|结束 |\n\n> 在标准的linux平台下,link的顺序是\n\n\tld crt1.o crti.o [user_objects] [system_libraries] crtn.o\n\n所以我们按照顺序进行链接有如下命令\n\n```makefile\n# 链接指令\nld -dynamic-linker /lib64/ld-linux-x86-64.so.2 -o main /usr/lib/x86_64-linux-gnu/crt1.o main.o some.o -lc /usr/lib/x86_64-linux-gnu/crti.o /usr/lib/x86_64-linux-gnu/crtn.o\n```\n\n> 成功的手动完成了程序的链接工作。\n\n以上艰苦的工作告诉我们，不要轻易尝试手动链接，除非你知道你在干什么。平时好好用 gcc。\n\n- 动态链接器⼀个操作系统中只需要⼀个吗？为什么？\n> 一般来说只要有一个支持的动态链接器即可，完成程序的动态链接工作。 但linux中可能有两个 ld 的版本\n1. ld.so针对a.out格式的二进制可执行文件\n2. ld-linux.so针对ELF格式的二进制可执行文件\n\na.out是旧版类Unix系统中用于执行档、目的码和后来系统中的函数库的一种文件格式，该版本的链接器仍被保留用以向前支持。\n\n---\n\n### Task5 - 运行时打桩\n\nTask5 是一个典型的运行时打桩的 task，给了我们编译好的login程序，让我们改变其行为，让它能够输出 login_success.\n\n> 阅读源码，我们可以发现，login将我们输入的字符串做了hash，与已有某不明hash值，进行比较，如果相等则登陆成功。根据本 lab 的内容主要是讲 make 和链接的，让我们碰撞这个hash显然不是本意。那另一种方法就是通过运行时打桩，改变标准库的链接方式，让strcmp 链接到我们自己写的 strcmp 版本上去，从而我们可以控制其返回值让其返回0使得登陆成功。\n\n*首先要注意 strcmp 并非只有判断密码时的一次唯一调用，在别处还有调用，所以我们要保证 strcmp 函数的基本功能正确*\n```cpp\n// mystrcmp.c\n#define _GNU_SOURCE\n#include <stdio.h>\n#include <dlfcn.h>\n\nint strcmp(const char *lhs, const char *rhs)\n{\n    int(*strcmpp)(const char *lhs, const char *rhs);\n    strcmpp = dlsym(RTLD_NEXT, \"strcmp\");\n\n    char tmp[] = \"3983709877683599140\";\n    if(strcmpp(tmp, rhs) == 0)\n        return 0;\n    return strcmpp(lhs, rhs);\n}\n```\n\n> 我们直接写一个自己的 strcmp 版本，用 dlsym 可以获取在运行时 strcmp 函数的指针 *（不这样做也可以，可以直接自己重写一遍strcmp程序）*，相当于可以直接使用 **真实的标准库中的 strcmp**，然后我们稍微改写一下，让它和我们的hash值比较的时候直接返回0，能够让我们不管输入什么密码都能够 login_success。\n\n接下来我们先将我们写的strcmp编译成动态链接库\n\n```shell\ngcc -shared -fpic -o mystrcmp.so mystrcmp.c -ldl\n```\n\n> 然后使用 **LD_PRELOAD=\"./mystrcmp.so\"** 指令，从而在 strcmp 动态链接到标准库之前让其优先匹配我们写的动态链接库中的 strcmp 符号。\n\n这里需要注意由于是要直接运行 ./login, 所以我们需要把LD_PRELOAD的效果全局化，也既在前面加上 export 标记。\n\n```shell\nexport LD_PRELOAD=\"./mystrcmp.so\"\n```\n\n最后注意不要忘记卸载全局 preload， 不然之后所有程序都 preload 这个strcmp。\n\n```shell\nexport LD_PRELOAD=NULL\n```","slug":"ICS/ICS_Lab3","published":1,"updated":"2026-02-03T05:42:14.433Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvh002w7uit397285mq","content":"<h3 id=\"Task0-简单链接\"><a href=\"#Task0-简单链接\" class=\"headerlink\" title=\"Task0 - 简单链接\"></a>Task0 - 简单链接</h3><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&quot;some.h&quot;</span></span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;\n    testPrint();\n    testPrint(<span class=\"hljs-number\">5</span>);\n    notATest();\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n&#125;</code></pre>\n<ul>\n<li><strong>错误分析</strong></li>\n</ul>\n<blockquote>\n<p>我们可以看到main函数中调用了三个函数，全是外部的，在链接时，符号表会进行搜索匹配。我们再来看some.h中定义了哪些函数.</p>\n</blockquote>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;cstdio&gt;</span></span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">testPrint</span><span class=\"hljs-params\">()</span></span>;\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">testPrint</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> num)</span></span>;</code></pre>\n<blockquote>\n<p>发现只有两个test函数,而没有notATest定义的函数，根据这个离谱的名字我们可以断定在cstdio中也没有同名函数。<br>所以最后符号表中没有匹配上，会引发链接错误。</p>\n</blockquote>\n<ul>\n<li><strong>解决方法</strong></li>\n</ul>\n<blockquote>\n<p>直接将 notATest() 注释掉, 再在 makefile 中使用<br><pre><code class=\"hljs css\"><span class=\"hljs-selector-tag\">g</span>++ <span class=\"hljs-selector-tag\">main</span><span class=\"hljs-selector-class\">.cpp</span> <span class=\"hljs-selector-tag\">some</span><span class=\"hljs-selector-class\">.cpp</span> <span class=\"hljs-selector-tag\">-o</span> <span class=\"hljs-selector-tag\">main</span></code></pre></p>\n</blockquote>\n<hr>\n<h3 id=\"Task1-链接与重复包含问题\"><a href=\"#Task1-链接与重复包含问题\" class=\"headerlink\" title=\"Task1 - 链接与重复包含问题\"></a>Task1 - 链接与重复包含问题</h3><ul>\n<li><strong>解题过程</strong></li>\n</ul>\n<p>通过阅读代码，我们可以发现改题的代码会根据宏DEBUG是否被定义而有不同的行为，决定是否打印更加详细的内容</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&quot;function0.h&quot;</span></span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">func0</span><span class=\"hljs-params\">()</span></span>&#123;\n    <span class=\"hljs-meta\"># <span class=\"hljs-meta-keyword\">ifdef</span> DEBUG</span>\n    printDebug(); <span class=\"hljs-comment\">//打印debug信息 (详细操作在shared.cpp中)</span>\n    <span class=\"hljs-meta\"># <span class=\"hljs-meta-keyword\">else</span></span>\n    print(); <span class=\"hljs-comment\">//打印正常信息</span>\n    <span class=\"hljs-meta\"># <span class=\"hljs-meta-keyword\">endif</span></span>\n&#125;</code></pre>\n<blockquote>\n<p>根据题意，我们需要在 Makefile 中,对于要求的 main1 需要做一个相等的条件判断</p>\n</blockquote>\n<pre><code class=\"hljs makefile\"><span class=\"hljs-section\">main0:</span>\n    g++ main0.cpp function0.cpp function1.cpp shared.cpp -o main0\ndebug = False\n<span class=\"hljs-section\">main1:</span>\n<span class=\"hljs-keyword\">ifeq</span> (<span class=\"hljs-variable\">$(debug)</span>,True) \n\tg++ main1.cpp -DDEBUG function0.cpp function1.cpp shared.cpp -o main1\n<span class=\"hljs-keyword\">else</span>\n\tg++ main1.cpp function0.cpp function1.cpp shared.cpp -o main1\n<span class=\"hljs-keyword\">endif</span></code></pre>\n<p><em>值得注意的是，makefile中 if 语句前不能有 tab 或者空格</em></p>\n<p><strong>Include 路径</strong><br><img src=\"https://s3.ax1x.com/2020/11/15/DFeVyt.png\" alt></p>\n<ul>\n<li><strong>问题</strong></li>\n</ul>\n<ol>\n<li>为什么两个function.h都引⽤了shared.h⽽没有出问题？本来有可能出什么问题。</li>\n</ol>\n<blockquote>\n<p>因为 shared.h 中仅包含函数声明，而不包含函数的定义，因而不会有重定义问题。如果 #include shared.cpp 则会出现重定义问题。</p>\n</blockquote>\n<ol>\n<li>如果把shared.h中注释掉的变量定义取消注释会出什么问题？为什么？</li>\n</ol>\n<blockquote>\n<p>会出现变量重定义问题，由于全局变量 string 被两次 include 到func0 和 func1 中，最后被同时引用至 main 中，导致重定义。在符号表中产生冲突，报错。</p>\n</blockquote>\n<ol>\n<li>通常使⽤shared.h中另外被注释掉的宏命令(#开头的那些⾏)来规避重复引⽤的⻛险，原理是什么？取消这些注释之后上⼀题的问题解除了吗？背后的原因是什么？</li>\n</ol>\n<blockquote>\n<p>通过宏定义，在第一次 include 的时候定义宏为函数名，之后再次include 的时候由于已经 define 就不再次 include。这种方式的缺点是如果有已有宏名与函数名重复时，将会报错。使用 #pragama once 则是由c++编译器保证 include 一次，不会有宏名重复问题。</p>\n<p>上题的问题并没有解决，因为FOO是全局变量，其赋了初值，被链接器标记为strong，被重复 include 到了 main 中，两个 strong 标记冲突报错。</p>\n</blockquote>\n<hr>\n<h3 id=\"Task2-静态链接库\"><a href=\"#Task2-静态链接库\" class=\"headerlink\" title=\"Task2 - 静态链接库\"></a>Task2 - 静态链接库</h3><p>在这个 Task 中我们需要编译2个静态链接库，并链接3个静态链接库，完成编译。</p>\n<p><strong>A Makefile</strong><br><pre><code class=\"hljs makefile\"><span class=\"hljs-section\">libA:\t</span>\n\tg++ -c A.cpp \n\tar -r libA.a A.o</code></pre></p>\n<blockquote>\n<p>先用g++ -c编译出A.o可重定位目标文件，再通过 ar 命令编译静态链接库。（libC 同理）</p>\n</blockquote>\n<p><strong>Main Makefile</strong><br><pre><code class=\"hljs makefile\">main : \n\tcd A &amp;&amp; make libA\n\tcd C &amp;&amp; make libC\n\tg++ main.cpp B/libB.a A/libA.a C/libC.a -o main</code></pre></p>\n<blockquote>\n<p>再 CD 入每个目录进行 make 编译， 最后把静态链接库进行链接。 </p>\n</blockquote>\n<ul>\n<li><strong>静态库链接搜索路径顺序：</strong></li>\n</ul>\n<ol>\n<li>ld会去找GCC命令中的参数-L</li>\n<li>再找gcc的环境变量LIBRARY_PATH</li>\n<li>再找内定目录 /lib /usr/lib /usr/local/lib </li>\n</ol>\n<ul>\n<li><strong>问题</strong></li>\n</ul>\n<ol>\n<li><p>若有多个静态链接库需要链接，写命令时需要考虑静态链接库和源⽂件在命令中的顺序吗？是否需要考虑是由什么决定的？</p>\n<blockquote>\n<p><strong>需要考虑</strong>，链接器在链接过程中按命令中输入的顺序进行符号表匹配，可以将这个匹配过程抽象的看作链接器在维护三个集合 E(待合并文件), U(被引用且尚未匹配), D（已匹配），根据顺序动态更新E, 和U,D, 最后如果 U 为空则正常整合 E 生成可执行文件，不然则报错有符号被引用了但未能匹配。所以如果我们的静态库都是相互独立的，那么顺序是没关系的。但如果互相依赖，那么我们必须保证在对某个符号的引用的库后，必然有一个库中存在对其的定义，不然则会报错。</p>\n</blockquote>\n</li>\n<li><p>可以使⽤size main命令来查看可执⾏⽂件所占的空间，输出结果的每⼀项是什么意思？</p>\n</li>\n</ol>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">text</th>\n<th style=\"text-align:center\">data</th>\n<th style=\"text-align:center\">bss</th>\n<th style=\"text-align:center\">dec</th>\n<th style=\"text-align:center\">hex</th>\n<th style=\"text-align:center\">filename</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">22721</td>\n<td style=\"text-align:center\">712</td>\n<td style=\"text-align:center\">288</td>\n<td style=\"text-align:center\">23721</td>\n<td style=\"text-align:center\">5ca9</td>\n<td style=\"text-align:center\">main</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><strong>text:</strong> 机器代码字节</li>\n<li><strong>data:</strong> 包含静态变量和已经初始化的全局变量的数据段字节数大小</li>\n<li><strong>bss:</strong> Block Started by Symbol (better save space) 存放程序中未初始化的全局变量的字节数大小，BBS段属于静态内存分配, 不占真实内存空间（仅占位符）</li>\n<li><strong>dec:</strong> = test + data + bss</li>\n<li><strong>hex:</strong> 16进制的dec</li>\n<li><strong>filename:</strong> 顾名思义，文件名</li>\n</ul>\n<hr>\n<h3 id=\"Task3-动态链接库\"><a href=\"#Task3-动态链接库\" class=\"headerlink\" title=\"Task3 - 动态链接库\"></a>Task3 - 动态链接库</h3><p>整体操作和上一个Task很像，只是链接的是动态链接库 .so</p>\n<p><strong>A Makefile</strong><br><pre><code class=\"hljs makefile\"><span class=\"hljs-section\">libA:</span>\n\tg++ -fPIC -c A.cpp\n\tg++ -shared -fPIC A.o -o libA.so</code></pre></p>\n<blockquote>\n<p>在 A 中先编译出 A.o 再用 -shared 编译出动态链接库 .so</p>\n</blockquote>\n<p><strong>Main Makefile</strong><br><pre><code class=\"hljs makefile\">main : \n\tcd A &amp;&amp; make libA\n\tcd C &amp;&amp; make libC\n\tg++ main.cpp A/libA.so ./libB.so C/libC.so -o main</code></pre></p>\n<blockquote>\n<p>直接 cd 进去 make 出动态链接库后，再进行链接。</p>\n</blockquote>\n<ul>\n<li><strong>问题</strong></li>\n</ul>\n<ol>\n<li><p>动态链接库在运⾏时也需要查找库的位置，在Linux中，运⾏时动态链接库的查找顺序是怎样的？</p>\n<blockquote>\n<p><strong>动态链接时、执行时搜索路径顺序:</strong></p>\n<ol>\n<li>编译目标代码时指定的动态库搜索路径</li>\n<li>环境变量LD_LIBRARY_PATH指定的动态库搜索路径</li>\n<li>配置文件/etc/ld.so.conf中指定的动态库搜索路径</li>\n<li>默认的动态库搜索路径/lib</li>\n<li>默认的动态库搜索路径/usr/lib</li>\n</ol>\n</blockquote>\n</li>\n<li><p>使⽤size main查看编译出的可执⾏⽂件占据的空间，与使⽤静态链接库相⽐占⽤空间有何变化？哪些部分的哪些代码（也要具体到本task）会导致编译出⽂件的占⽤空间发⽣这种变化？</p>\n</li>\n</ol>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">text</th>\n<th style=\"text-align:center\">data</th>\n<th style=\"text-align:center\">bss</th>\n<th style=\"text-align:center\">dec</th>\n<th style=\"text-align:center\">hex</th>\n<th style=\"text-align:center\">filename</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">3089</td>\n<td style=\"text-align:center\">720</td>\n<td style=\"text-align:center\">96</td>\n<td style=\"text-align:center\">3905</td>\n<td style=\"text-align:center\">f41</td>\n<td style=\"text-align:center\">main</td>\n</tr>\n</tbody>\n</table>\n</div>\n<blockquote>\n<p><strong>占用空间变小了</strong>，因为不同于静态链接库将所有的静态库都整合入可执行文件中，动态链接库是在程序开始或正在运行时被链接加载的，所有可执行文件本身的空间占用会大幅缩小。</p>\n<p>main 中调用了 A, B, C 函数，所以其中的函数以及静态全局变量 A_name, B_name 会被被置于动态链接库.so中动态加载</p>\n</blockquote>\n<ol>\n<li>编译动态链接库时-fPIC的作⽤是什么，不加会有什么后果？<br>-fPIC 含义是 Generate position-independent code (PIC)，例如在汇编的 jmp 语句中通常使用的是固定的内部地址<pre><code class=\"hljs angelscript\"><span class=\"hljs-number\">100</span>: COMPARE REG1, REG2\n<span class=\"hljs-number\">101</span>: JUMP_IF_EQUAL <span class=\"hljs-number\">111</span>\n...\n<span class=\"hljs-number\">111</span>: NOP</code></pre>\n<blockquote>\n<p>而通过 -fPIC 参数 jmp 语句所指向的是相对地址<br>使用的是代码段和数据段的OFFSET，从而实现位置无关，可以动态加载到内存中，不同进程可以共享。</p>\n</blockquote>\n</li>\n</ol>\n<pre><code class=\"hljs angelscript\"><span class=\"hljs-number\">100</span>: COMPARE REG1, REG2\n<span class=\"hljs-number\">101</span>: JUMP_IF_EQUAL CURRENT+<span class=\"hljs-number\">10</span>\n...\n<span class=\"hljs-number\">111</span>: NOP</code></pre>\n<blockquote>\n<p>如果不加，在某些系统下不会有很大的问题，但一般在 -shared 后面最好加上 -fPIC 来保证动态链接库是位置无关的，不然无法实现动态链接（由于位置相关即分配绝对内存地址，导致多个副本存在于内存中，无法实现动态链接）</p>\n</blockquote>\n<p><strong>info in gcc manual</strong></p>\n<ul>\n<li><strong>-shared:</strong>  Produce a shared object which can then be linked with other objects to forman executable. Not all systems support this option. For predictable results,<br>you must also specify the same set of options used for compilation (‘-fpic’,‘-fPIC’, or model suboptions) when you specify this linker option.*</li>\n</ul>\n<ol>\n<li>现在被⼴泛使⽤的公开的动态链接库如何进⾏版本替换或共存（以linux系统为例）？</li>\n</ol>\n<blockquote>\n<p>通过动态链接，如果开发者需要维护程序的某一部分（某几个功能的函数），仅需要维护修改所在的动态链接库即可，然后将其发布。用户只需要替换动态链接库，在程序运行的时候自然会动态链接到新的链接库，<strong>在接口保持不变</strong>的情况下完成很自然流畅的版本更新。</p>\n</blockquote>\n<hr>\n<h3 id=\"Task4-ld手动链接\"><a href=\"#Task4-ld手动链接\" class=\"headerlink\" title=\"Task4 - ld手动链接\"></a>Task4 - ld手动链接</h3><ul>\n<li><strong>解题过程</strong><br>这题要求我们用ld链接器，进行手动链接，我们先试一下直接链接会发生什么</li>\n</ul>\n<pre><code class=\"hljs makefile\"><span class=\"hljs-comment\">#链接代码</span>\nld -o main main.o some.o</code></pre>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">//报错信息</span>\nld: warning: cannot find entry symbol _start; defaulting to <span class=\"hljs-number\">00000000004000b</span>0\nsome.o: In function `notATest()<span class=\"hljs-string\">&#x27;:</span>\nsome.cpp:(.text+0xc): undefined reference to `puts&#x27;\nsome.o: In function `testPrint()<span class=\"hljs-string\">&#x27;:</span>\nsome.cpp:(.text+0x1f): undefined reference to `puts&#x27;\nsome.o: In function `testPrint(<span class=\"hljs-keyword\">int</span>)<span class=\"hljs-string\">&#x27;:</span>\nsome.cpp:(.text+0x52): undefined reference to `printf&#x27;\nMakefile:2: recipe for target &#x27;main&#x27; failed\nmake: *** [main] Error <span class=\"hljs-number\">1</span></code></pre>\n<blockquote>\n<p>发现主要报错信息是 undefined reference to ‘puts’, ‘printf’, 说明标准库中的函数符号没有被成功匹配，我们需要把 stdc 加进去</p>\n</blockquote>\n<pre><code class=\"hljs makefile\"><span class=\"hljs-comment\"># 链接代码</span>\nld -o main main.o some.o -lc\n<span class=\"hljs-comment\"># 通过 -lc 命令直接添加标准库，也可以自行指定libc.so路径</span></code></pre>\n<blockquote>\n<p>可以发现main被成功编译出来，但运行时候发现bash报目录中无此文件<br><pre><code class=\"hljs bash\">bash: ./main: No such file or directory</code></pre></p>\n<p>也就是我们并不能运行这个可执行文件，查找资料之后我们尝试指定使用的动态链接器再进行编译，就可以运行了</p>\n</blockquote>\n<pre><code class=\"hljs makefile\">ld -dynamic-linker /lib64/ld-linux-x86-64.so.2 -o main main.o some.o -lc</code></pre>\n<blockquote>\n<p>我查询了ld的手册试图查找原因，但并未发现为什么必须要使用—dynamic-linker指令</p>\n</blockquote>\n<div style=\"page-break-after: always;\"></div>\n\n\n<ul>\n<li><strong>—dynamic-linker=file</strong><blockquote>\n<p>   Set the name of the dynamic linker.  This is only meaningful when generating dynamically linked ELF executables.  <strong>The default dynamic linker is normally correct; don’t use this unless you know what you are doing.</strong></p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>接下去，我们的程序虽然能够运行起来了，但在 main 函数跑完之后会出现 <em>Segmentation fault (core dumped)</em> 提示，这也提示了我们对于 main 函数的初始化和结束可能并未正常执行。</p>\n</blockquote>\n<ul>\n<li><strong>GDB查看正常程序</strong></li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/15/DFeZOP.png\" alt></p>\n<blockquote>\n<p>通过 gdb 查看正常程序我们发现，正常的 main 函数执行栈中需要有两个函数为其保证环境 <em>__lib_csu_init</em> 和 <em>__libc_start_main</em></p>\n</blockquote>\n<ul>\n<li><strong>__libc_start_main</strong><br>我们需要知道，在linux中，main函数的初始化环境和参数传递以及返回值处理工作是由 __libc_start_main 来保证的。一个正常的程序执行需要包含以下要素。</li>\n</ul>\n<ol>\n<li>performing any necessary security checks if the effective user ID is not the same as the real user ID.</li>\n<li>initialize the threading subsystem.</li>\n<li>registering the <em>rtld_fini</em> to release resources when this dynamic shared object exits (or is unloaded).</li>\n<li>registering the <em>fini</em> handler to run at program exit.</li>\n<li>calling the initializer function <em>(</em>init)()*.</li>\n<li>calling <em>main()</em> with appropriate arguments.</li>\n<li>calling <em>exit()</em> with the return value from <em>main()</em>.</li>\n</ol>\n<blockquote>\n<p>具体的初始化和结束调用路径异常复杂，在此不多赘述，放一张图有待进一步研究。</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/15/DFemef.png\" alt></p>\n<p><em>图片来源: <a href=\"https://luomuxiaoxiao.com/?p=516\">https://luomuxiaoxiao.com/?p=516</a></em></p>\n<hr>\n<p>然后介绍完了主函数的初始化和返回，我们需要知道保证上述的两个函数在哪个动态链接库中，这就涉及到了 <em>crt1.o, crti.o, crtbegin.o, crtend.o, crtn.o</em> 这几个库<br><em>参考： <a href=\"https://blog.csdn.net/farmwang/article/details/73195951\">https://blog.csdn.net/farmwang/article/details/73195951</a></em></p>\n<blockquote>\n<p><strong>crt是c runtime 的缩写</strong>,用于执行进入main之前的初始化和退出main之后的扫尾工作。</p>\n</blockquote>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">目标文件</th>\n<th style=\"text-align:center\">crt1.o</th>\n<th style=\"text-align:center\">crti.o</th>\n<th style=\"text-align:center\">crtbegin.o</th>\n<th style=\"text-align:center\">crtend.o</th>\n<th style=\"text-align:center\">crtn.o</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">作用</td>\n<td style=\"text-align:center\">启动</td>\n<td style=\"text-align:center\">初始化</td>\n<td style=\"text-align:center\">构造</td>\n<td style=\"text-align:center\">析构</td>\n<td style=\"text-align:center\">结束</td>\n</tr>\n</tbody>\n</table>\n</div>\n<blockquote>\n<p>在标准的linux平台下,link的顺序是</p>\n</blockquote>\n<pre><code>ld crt1.o crti.o [user_objects] [system_libraries] crtn.o\n</code></pre><p>所以我们按照顺序进行链接有如下命令</p>\n<pre><code class=\"hljs makefile\"><span class=\"hljs-comment\"># 链接指令</span>\nld -dynamic-linker /lib64/ld-linux-x86-64.so.2 -o main /usr/lib/x86_64-linux-gnu/crt1.o main.o some.o -lc /usr/lib/x86_64-linux-gnu/crti.o /usr/lib/x86_64-linux-gnu/crtn.o</code></pre>\n<blockquote>\n<p>成功的手动完成了程序的链接工作。</p>\n</blockquote>\n<p>以上艰苦的工作告诉我们，不要轻易尝试手动链接，除非你知道你在干什么。平时好好用 gcc。</p>\n<ul>\n<li>动态链接器⼀个操作系统中只需要⼀个吗？为什么？<blockquote>\n<p>一般来说只要有一个支持的动态链接器即可，完成程序的动态链接工作。 但linux中可能有两个 ld 的版本</p>\n</blockquote>\n</li>\n</ul>\n<ol>\n<li>ld.so针对a.out格式的二进制可执行文件</li>\n<li>ld-linux.so针对ELF格式的二进制可执行文件</li>\n</ol>\n<p>a.out是旧版类Unix系统中用于执行档、目的码和后来系统中的函数库的一种文件格式，该版本的链接器仍被保留用以向前支持。</p>\n<hr>\n<h3 id=\"Task5-运行时打桩\"><a href=\"#Task5-运行时打桩\" class=\"headerlink\" title=\"Task5 - 运行时打桩\"></a>Task5 - 运行时打桩</h3><p>Task5 是一个典型的运行时打桩的 task，给了我们编译好的login程序，让我们改变其行为，让它能够输出 login_success.</p>\n<blockquote>\n<p>阅读源码，我们可以发现，login将我们输入的字符串做了hash，与已有某不明hash值，进行比较，如果相等则登陆成功。根据本 lab 的内容主要是讲 make 和链接的，让我们碰撞这个hash显然不是本意。那另一种方法就是通过运行时打桩，改变标准库的链接方式，让strcmp 链接到我们自己写的 strcmp 版本上去，从而我们可以控制其返回值让其返回0使得登陆成功。</p>\n</blockquote>\n<p><em>首先要注意 strcmp 并非只有判断密码时的一次唯一调用，在别处还有调用，所以我们要保证 strcmp 函数的基本功能正确</em><br><pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// mystrcmp.c</span>\n<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">define</span> _GNU_SOURCE</span>\n<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span>\n<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;dlfcn.h&gt;</span></span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">strcmp</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">char</span> *lhs, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">char</span> *rhs)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span>(*strcmpp)(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">char</span> *lhs, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">char</span> *rhs);\n    strcmpp = dlsym(RTLD_NEXT, <span class=\"hljs-string\">&quot;strcmp&quot;</span>);\n\n    <span class=\"hljs-keyword\">char</span> tmp[] = <span class=\"hljs-string\">&quot;3983709877683599140&quot;</span>;\n    <span class=\"hljs-keyword\">if</span>(strcmpp(tmp, rhs) == <span class=\"hljs-number\">0</span>)\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">return</span> strcmpp(lhs, rhs);\n&#125;</code></pre></p>\n<blockquote>\n<p>我们直接写一个自己的 strcmp 版本，用 dlsym 可以获取在运行时 strcmp 函数的指针 <em>（不这样做也可以，可以直接自己重写一遍strcmp程序）</em>，相当于可以直接使用 <strong>真实的标准库中的 strcmp</strong>，然后我们稍微改写一下，让它和我们的hash值比较的时候直接返回0，能够让我们不管输入什么密码都能够 login_success。</p>\n</blockquote>\n<p>接下来我们先将我们写的strcmp编译成动态链接库</p>\n<pre><code class=\"hljs shell\">gcc -shared -fpic -o mystrcmp.so mystrcmp.c -ldl</code></pre>\n<blockquote>\n<p>然后使用 <strong>LD_PRELOAD=”./mystrcmp.so”</strong> 指令，从而在 strcmp 动态链接到标准库之前让其优先匹配我们写的动态链接库中的 strcmp 符号。</p>\n</blockquote>\n<p>这里需要注意由于是要直接运行 ./login, 所以我们需要把LD_PRELOAD的效果全局化，也既在前面加上 export 标记。</p>\n<pre><code class=\"hljs shell\">export LD_PRELOAD=&quot;./mystrcmp.so&quot;</code></pre>\n<p>最后注意不要忘记卸载全局 preload， 不然之后所有程序都 preload 这个strcmp。</p>\n<pre><code class=\"hljs shell\">export LD_PRELOAD=NULL</code></pre>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Task0-简单链接\"><a href=\"#Task0-简单链接\" class=\"headerlink\" title=\"Task0 - 简单链接\"></a>Task0 - 简单链接</h3><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&quot;some.h&quot;</span></span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;\n    testPrint();\n    testPrint(<span class=\"hljs-number\">5</span>);\n    notATest();\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n&#125;</code></pre>\n<ul>\n<li><strong>错误分析</strong></li>\n</ul>\n<blockquote>\n<p>我们可以看到main函数中调用了三个函数，全是外部的，在链接时，符号表会进行搜索匹配。我们再来看some.h中定义了哪些函数.</p>\n</blockquote>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;cstdio&gt;</span></span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">testPrint</span><span class=\"hljs-params\">()</span></span>;\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">testPrint</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> num)</span></span>;</code></pre>\n<blockquote>\n<p>发现只有两个test函数,而没有notATest定义的函数，根据这个离谱的名字我们可以断定在cstdio中也没有同名函数。<br>所以最后符号表中没有匹配上，会引发链接错误。</p>\n</blockquote>\n<ul>\n<li><strong>解决方法</strong></li>\n</ul>\n<blockquote>\n<p>直接将 notATest() 注释掉, 再在 makefile 中使用<br><pre><code class=\"hljs css\"><span class=\"hljs-selector-tag\">g</span>++ <span class=\"hljs-selector-tag\">main</span><span class=\"hljs-selector-class\">.cpp</span> <span class=\"hljs-selector-tag\">some</span><span class=\"hljs-selector-class\">.cpp</span> <span class=\"hljs-selector-tag\">-o</span> <span class=\"hljs-selector-tag\">main</span></code></pre></p>\n</blockquote>\n<hr>\n<h3 id=\"Task1-链接与重复包含问题\"><a href=\"#Task1-链接与重复包含问题\" class=\"headerlink\" title=\"Task1 - 链接与重复包含问题\"></a>Task1 - 链接与重复包含问题</h3><ul>\n<li><strong>解题过程</strong></li>\n</ul>\n<p>通过阅读代码，我们可以发现改题的代码会根据宏DEBUG是否被定义而有不同的行为，决定是否打印更加详细的内容</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&quot;function0.h&quot;</span></span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">func0</span><span class=\"hljs-params\">()</span></span>&#123;\n    <span class=\"hljs-meta\"># <span class=\"hljs-meta-keyword\">ifdef</span> DEBUG</span>\n    printDebug(); <span class=\"hljs-comment\">//打印debug信息 (详细操作在shared.cpp中)</span>\n    <span class=\"hljs-meta\"># <span class=\"hljs-meta-keyword\">else</span></span>\n    print(); <span class=\"hljs-comment\">//打印正常信息</span>\n    <span class=\"hljs-meta\"># <span class=\"hljs-meta-keyword\">endif</span></span>\n&#125;</code></pre>\n<blockquote>\n<p>根据题意，我们需要在 Makefile 中,对于要求的 main1 需要做一个相等的条件判断</p>\n</blockquote>\n<pre><code class=\"hljs makefile\"><span class=\"hljs-section\">main0:</span>\n    g++ main0.cpp function0.cpp function1.cpp shared.cpp -o main0\ndebug = False\n<span class=\"hljs-section\">main1:</span>\n<span class=\"hljs-keyword\">ifeq</span> (<span class=\"hljs-variable\">$(debug)</span>,True) \n\tg++ main1.cpp -DDEBUG function0.cpp function1.cpp shared.cpp -o main1\n<span class=\"hljs-keyword\">else</span>\n\tg++ main1.cpp function0.cpp function1.cpp shared.cpp -o main1\n<span class=\"hljs-keyword\">endif</span></code></pre>\n<p><em>值得注意的是，makefile中 if 语句前不能有 tab 或者空格</em></p>\n<p><strong>Include 路径</strong><br><img src=\"https://s3.ax1x.com/2020/11/15/DFeVyt.png\" alt></p>\n<ul>\n<li><strong>问题</strong></li>\n</ul>\n<ol>\n<li>为什么两个function.h都引⽤了shared.h⽽没有出问题？本来有可能出什么问题。</li>\n</ol>\n<blockquote>\n<p>因为 shared.h 中仅包含函数声明，而不包含函数的定义，因而不会有重定义问题。如果 #include shared.cpp 则会出现重定义问题。</p>\n</blockquote>\n<ol>\n<li>如果把shared.h中注释掉的变量定义取消注释会出什么问题？为什么？</li>\n</ol>\n<blockquote>\n<p>会出现变量重定义问题，由于全局变量 string 被两次 include 到func0 和 func1 中，最后被同时引用至 main 中，导致重定义。在符号表中产生冲突，报错。</p>\n</blockquote>\n<ol>\n<li>通常使⽤shared.h中另外被注释掉的宏命令(#开头的那些⾏)来规避重复引⽤的⻛险，原理是什么？取消这些注释之后上⼀题的问题解除了吗？背后的原因是什么？</li>\n</ol>\n<blockquote>\n<p>通过宏定义，在第一次 include 的时候定义宏为函数名，之后再次include 的时候由于已经 define 就不再次 include。这种方式的缺点是如果有已有宏名与函数名重复时，将会报错。使用 #pragama once 则是由c++编译器保证 include 一次，不会有宏名重复问题。</p>\n<p>上题的问题并没有解决，因为FOO是全局变量，其赋了初值，被链接器标记为strong，被重复 include 到了 main 中，两个 strong 标记冲突报错。</p>\n</blockquote>\n<hr>\n<h3 id=\"Task2-静态链接库\"><a href=\"#Task2-静态链接库\" class=\"headerlink\" title=\"Task2 - 静态链接库\"></a>Task2 - 静态链接库</h3><p>在这个 Task 中我们需要编译2个静态链接库，并链接3个静态链接库，完成编译。</p>\n<p><strong>A Makefile</strong><br><pre><code class=\"hljs makefile\"><span class=\"hljs-section\">libA:\t</span>\n\tg++ -c A.cpp \n\tar -r libA.a A.o</code></pre></p>\n<blockquote>\n<p>先用g++ -c编译出A.o可重定位目标文件，再通过 ar 命令编译静态链接库。（libC 同理）</p>\n</blockquote>\n<p><strong>Main Makefile</strong><br><pre><code class=\"hljs makefile\">main : \n\tcd A &amp;&amp; make libA\n\tcd C &amp;&amp; make libC\n\tg++ main.cpp B/libB.a A/libA.a C/libC.a -o main</code></pre></p>\n<blockquote>\n<p>再 CD 入每个目录进行 make 编译， 最后把静态链接库进行链接。 </p>\n</blockquote>\n<ul>\n<li><strong>静态库链接搜索路径顺序：</strong></li>\n</ul>\n<ol>\n<li>ld会去找GCC命令中的参数-L</li>\n<li>再找gcc的环境变量LIBRARY_PATH</li>\n<li>再找内定目录 /lib /usr/lib /usr/local/lib </li>\n</ol>\n<ul>\n<li><strong>问题</strong></li>\n</ul>\n<ol>\n<li><p>若有多个静态链接库需要链接，写命令时需要考虑静态链接库和源⽂件在命令中的顺序吗？是否需要考虑是由什么决定的？</p>\n<blockquote>\n<p><strong>需要考虑</strong>，链接器在链接过程中按命令中输入的顺序进行符号表匹配，可以将这个匹配过程抽象的看作链接器在维护三个集合 E(待合并文件), U(被引用且尚未匹配), D（已匹配），根据顺序动态更新E, 和U,D, 最后如果 U 为空则正常整合 E 生成可执行文件，不然则报错有符号被引用了但未能匹配。所以如果我们的静态库都是相互独立的，那么顺序是没关系的。但如果互相依赖，那么我们必须保证在对某个符号的引用的库后，必然有一个库中存在对其的定义，不然则会报错。</p>\n</blockquote>\n</li>\n<li><p>可以使⽤size main命令来查看可执⾏⽂件所占的空间，输出结果的每⼀项是什么意思？</p>\n</li>\n</ol>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">text</th>\n<th style=\"text-align:center\">data</th>\n<th style=\"text-align:center\">bss</th>\n<th style=\"text-align:center\">dec</th>\n<th style=\"text-align:center\">hex</th>\n<th style=\"text-align:center\">filename</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">22721</td>\n<td style=\"text-align:center\">712</td>\n<td style=\"text-align:center\">288</td>\n<td style=\"text-align:center\">23721</td>\n<td style=\"text-align:center\">5ca9</td>\n<td style=\"text-align:center\">main</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><strong>text:</strong> 机器代码字节</li>\n<li><strong>data:</strong> 包含静态变量和已经初始化的全局变量的数据段字节数大小</li>\n<li><strong>bss:</strong> Block Started by Symbol (better save space) 存放程序中未初始化的全局变量的字节数大小，BBS段属于静态内存分配, 不占真实内存空间（仅占位符）</li>\n<li><strong>dec:</strong> = test + data + bss</li>\n<li><strong>hex:</strong> 16进制的dec</li>\n<li><strong>filename:</strong> 顾名思义，文件名</li>\n</ul>\n<hr>\n<h3 id=\"Task3-动态链接库\"><a href=\"#Task3-动态链接库\" class=\"headerlink\" title=\"Task3 - 动态链接库\"></a>Task3 - 动态链接库</h3><p>整体操作和上一个Task很像，只是链接的是动态链接库 .so</p>\n<p><strong>A Makefile</strong><br><pre><code class=\"hljs makefile\"><span class=\"hljs-section\">libA:</span>\n\tg++ -fPIC -c A.cpp\n\tg++ -shared -fPIC A.o -o libA.so</code></pre></p>\n<blockquote>\n<p>在 A 中先编译出 A.o 再用 -shared 编译出动态链接库 .so</p>\n</blockquote>\n<p><strong>Main Makefile</strong><br><pre><code class=\"hljs makefile\">main : \n\tcd A &amp;&amp; make libA\n\tcd C &amp;&amp; make libC\n\tg++ main.cpp A/libA.so ./libB.so C/libC.so -o main</code></pre></p>\n<blockquote>\n<p>直接 cd 进去 make 出动态链接库后，再进行链接。</p>\n</blockquote>\n<ul>\n<li><strong>问题</strong></li>\n</ul>\n<ol>\n<li><p>动态链接库在运⾏时也需要查找库的位置，在Linux中，运⾏时动态链接库的查找顺序是怎样的？</p>\n<blockquote>\n<p><strong>动态链接时、执行时搜索路径顺序:</strong></p>\n<ol>\n<li>编译目标代码时指定的动态库搜索路径</li>\n<li>环境变量LD_LIBRARY_PATH指定的动态库搜索路径</li>\n<li>配置文件/etc/ld.so.conf中指定的动态库搜索路径</li>\n<li>默认的动态库搜索路径/lib</li>\n<li>默认的动态库搜索路径/usr/lib</li>\n</ol>\n</blockquote>\n</li>\n<li><p>使⽤size main查看编译出的可执⾏⽂件占据的空间，与使⽤静态链接库相⽐占⽤空间有何变化？哪些部分的哪些代码（也要具体到本task）会导致编译出⽂件的占⽤空间发⽣这种变化？</p>\n</li>\n</ol>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">text</th>\n<th style=\"text-align:center\">data</th>\n<th style=\"text-align:center\">bss</th>\n<th style=\"text-align:center\">dec</th>\n<th style=\"text-align:center\">hex</th>\n<th style=\"text-align:center\">filename</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">3089</td>\n<td style=\"text-align:center\">720</td>\n<td style=\"text-align:center\">96</td>\n<td style=\"text-align:center\">3905</td>\n<td style=\"text-align:center\">f41</td>\n<td style=\"text-align:center\">main</td>\n</tr>\n</tbody>\n</table>\n</div>\n<blockquote>\n<p><strong>占用空间变小了</strong>，因为不同于静态链接库将所有的静态库都整合入可执行文件中，动态链接库是在程序开始或正在运行时被链接加载的，所有可执行文件本身的空间占用会大幅缩小。</p>\n<p>main 中调用了 A, B, C 函数，所以其中的函数以及静态全局变量 A_name, B_name 会被被置于动态链接库.so中动态加载</p>\n</blockquote>\n<ol>\n<li>编译动态链接库时-fPIC的作⽤是什么，不加会有什么后果？<br>-fPIC 含义是 Generate position-independent code (PIC)，例如在汇编的 jmp 语句中通常使用的是固定的内部地址<pre><code class=\"hljs angelscript\"><span class=\"hljs-number\">100</span>: COMPARE REG1, REG2\n<span class=\"hljs-number\">101</span>: JUMP_IF_EQUAL <span class=\"hljs-number\">111</span>\n...\n<span class=\"hljs-number\">111</span>: NOP</code></pre>\n<blockquote>\n<p>而通过 -fPIC 参数 jmp 语句所指向的是相对地址<br>使用的是代码段和数据段的OFFSET，从而实现位置无关，可以动态加载到内存中，不同进程可以共享。</p>\n</blockquote>\n</li>\n</ol>\n<pre><code class=\"hljs angelscript\"><span class=\"hljs-number\">100</span>: COMPARE REG1, REG2\n<span class=\"hljs-number\">101</span>: JUMP_IF_EQUAL CURRENT+<span class=\"hljs-number\">10</span>\n...\n<span class=\"hljs-number\">111</span>: NOP</code></pre>\n<blockquote>\n<p>如果不加，在某些系统下不会有很大的问题，但一般在 -shared 后面最好加上 -fPIC 来保证动态链接库是位置无关的，不然无法实现动态链接（由于位置相关即分配绝对内存地址，导致多个副本存在于内存中，无法实现动态链接）</p>\n</blockquote>\n<p><strong>info in gcc manual</strong></p>\n<ul>\n<li><strong>-shared:</strong>  Produce a shared object which can then be linked with other objects to forman executable. Not all systems support this option. For predictable results,<br>you must also specify the same set of options used for compilation (‘-fpic’,‘-fPIC’, or model suboptions) when you specify this linker option.*</li>\n</ul>\n<ol>\n<li>现在被⼴泛使⽤的公开的动态链接库如何进⾏版本替换或共存（以linux系统为例）？</li>\n</ol>\n<blockquote>\n<p>通过动态链接，如果开发者需要维护程序的某一部分（某几个功能的函数），仅需要维护修改所在的动态链接库即可，然后将其发布。用户只需要替换动态链接库，在程序运行的时候自然会动态链接到新的链接库，<strong>在接口保持不变</strong>的情况下完成很自然流畅的版本更新。</p>\n</blockquote>\n<hr>\n<h3 id=\"Task4-ld手动链接\"><a href=\"#Task4-ld手动链接\" class=\"headerlink\" title=\"Task4 - ld手动链接\"></a>Task4 - ld手动链接</h3><ul>\n<li><strong>解题过程</strong><br>这题要求我们用ld链接器，进行手动链接，我们先试一下直接链接会发生什么</li>\n</ul>\n<pre><code class=\"hljs makefile\"><span class=\"hljs-comment\">#链接代码</span>\nld -o main main.o some.o</code></pre>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">//报错信息</span>\nld: warning: cannot find entry symbol _start; defaulting to <span class=\"hljs-number\">00000000004000b</span>0\nsome.o: In function `notATest()<span class=\"hljs-string\">&#x27;:</span>\nsome.cpp:(.text+0xc): undefined reference to `puts&#x27;\nsome.o: In function `testPrint()<span class=\"hljs-string\">&#x27;:</span>\nsome.cpp:(.text+0x1f): undefined reference to `puts&#x27;\nsome.o: In function `testPrint(<span class=\"hljs-keyword\">int</span>)<span class=\"hljs-string\">&#x27;:</span>\nsome.cpp:(.text+0x52): undefined reference to `printf&#x27;\nMakefile:2: recipe for target &#x27;main&#x27; failed\nmake: *** [main] Error <span class=\"hljs-number\">1</span></code></pre>\n<blockquote>\n<p>发现主要报错信息是 undefined reference to ‘puts’, ‘printf’, 说明标准库中的函数符号没有被成功匹配，我们需要把 stdc 加进去</p>\n</blockquote>\n<pre><code class=\"hljs makefile\"><span class=\"hljs-comment\"># 链接代码</span>\nld -o main main.o some.o -lc\n<span class=\"hljs-comment\"># 通过 -lc 命令直接添加标准库，也可以自行指定libc.so路径</span></code></pre>\n<blockquote>\n<p>可以发现main被成功编译出来，但运行时候发现bash报目录中无此文件<br><pre><code class=\"hljs bash\">bash: ./main: No such file or directory</code></pre></p>\n<p>也就是我们并不能运行这个可执行文件，查找资料之后我们尝试指定使用的动态链接器再进行编译，就可以运行了</p>\n</blockquote>\n<pre><code class=\"hljs makefile\">ld -dynamic-linker /lib64/ld-linux-x86-64.so.2 -o main main.o some.o -lc</code></pre>\n<blockquote>\n<p>我查询了ld的手册试图查找原因，但并未发现为什么必须要使用—dynamic-linker指令</p>\n</blockquote>\n<div style=\"page-break-after: always;\"></div>\n\n\n<ul>\n<li><strong>—dynamic-linker=file</strong><blockquote>\n<p>   Set the name of the dynamic linker.  This is only meaningful when generating dynamically linked ELF executables.  <strong>The default dynamic linker is normally correct; don’t use this unless you know what you are doing.</strong></p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>接下去，我们的程序虽然能够运行起来了，但在 main 函数跑完之后会出现 <em>Segmentation fault (core dumped)</em> 提示，这也提示了我们对于 main 函数的初始化和结束可能并未正常执行。</p>\n</blockquote>\n<ul>\n<li><strong>GDB查看正常程序</strong></li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/15/DFeZOP.png\" alt></p>\n<blockquote>\n<p>通过 gdb 查看正常程序我们发现，正常的 main 函数执行栈中需要有两个函数为其保证环境 <em>__lib_csu_init</em> 和 <em>__libc_start_main</em></p>\n</blockquote>\n<ul>\n<li><strong>__libc_start_main</strong><br>我们需要知道，在linux中，main函数的初始化环境和参数传递以及返回值处理工作是由 __libc_start_main 来保证的。一个正常的程序执行需要包含以下要素。</li>\n</ul>\n<ol>\n<li>performing any necessary security checks if the effective user ID is not the same as the real user ID.</li>\n<li>initialize the threading subsystem.</li>\n<li>registering the <em>rtld_fini</em> to release resources when this dynamic shared object exits (or is unloaded).</li>\n<li>registering the <em>fini</em> handler to run at program exit.</li>\n<li>calling the initializer function <em>(</em>init)()*.</li>\n<li>calling <em>main()</em> with appropriate arguments.</li>\n<li>calling <em>exit()</em> with the return value from <em>main()</em>.</li>\n</ol>\n<blockquote>\n<p>具体的初始化和结束调用路径异常复杂，在此不多赘述，放一张图有待进一步研究。</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/15/DFemef.png\" alt></p>\n<p><em>图片来源: <a href=\"https://luomuxiaoxiao.com/?p=516\">https://luomuxiaoxiao.com/?p=516</a></em></p>\n<hr>\n<p>然后介绍完了主函数的初始化和返回，我们需要知道保证上述的两个函数在哪个动态链接库中，这就涉及到了 <em>crt1.o, crti.o, crtbegin.o, crtend.o, crtn.o</em> 这几个库<br><em>参考： <a href=\"https://blog.csdn.net/farmwang/article/details/73195951\">https://blog.csdn.net/farmwang/article/details/73195951</a></em></p>\n<blockquote>\n<p><strong>crt是c runtime 的缩写</strong>,用于执行进入main之前的初始化和退出main之后的扫尾工作。</p>\n</blockquote>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">目标文件</th>\n<th style=\"text-align:center\">crt1.o</th>\n<th style=\"text-align:center\">crti.o</th>\n<th style=\"text-align:center\">crtbegin.o</th>\n<th style=\"text-align:center\">crtend.o</th>\n<th style=\"text-align:center\">crtn.o</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">作用</td>\n<td style=\"text-align:center\">启动</td>\n<td style=\"text-align:center\">初始化</td>\n<td style=\"text-align:center\">构造</td>\n<td style=\"text-align:center\">析构</td>\n<td style=\"text-align:center\">结束</td>\n</tr>\n</tbody>\n</table>\n</div>\n<blockquote>\n<p>在标准的linux平台下,link的顺序是</p>\n</blockquote>\n<pre><code>ld crt1.o crti.o [user_objects] [system_libraries] crtn.o\n</code></pre><p>所以我们按照顺序进行链接有如下命令</p>\n<pre><code class=\"hljs makefile\"><span class=\"hljs-comment\"># 链接指令</span>\nld -dynamic-linker /lib64/ld-linux-x86-64.so.2 -o main /usr/lib/x86_64-linux-gnu/crt1.o main.o some.o -lc /usr/lib/x86_64-linux-gnu/crti.o /usr/lib/x86_64-linux-gnu/crtn.o</code></pre>\n<blockquote>\n<p>成功的手动完成了程序的链接工作。</p>\n</blockquote>\n<p>以上艰苦的工作告诉我们，不要轻易尝试手动链接，除非你知道你在干什么。平时好好用 gcc。</p>\n<ul>\n<li>动态链接器⼀个操作系统中只需要⼀个吗？为什么？<blockquote>\n<p>一般来说只要有一个支持的动态链接器即可，完成程序的动态链接工作。 但linux中可能有两个 ld 的版本</p>\n</blockquote>\n</li>\n</ul>\n<ol>\n<li>ld.so针对a.out格式的二进制可执行文件</li>\n<li>ld-linux.so针对ELF格式的二进制可执行文件</li>\n</ol>\n<p>a.out是旧版类Unix系统中用于执行档、目的码和后来系统中的函数库的一种文件格式，该版本的链接器仍被保留用以向前支持。</p>\n<hr>\n<h3 id=\"Task5-运行时打桩\"><a href=\"#Task5-运行时打桩\" class=\"headerlink\" title=\"Task5 - 运行时打桩\"></a>Task5 - 运行时打桩</h3><p>Task5 是一个典型的运行时打桩的 task，给了我们编译好的login程序，让我们改变其行为，让它能够输出 login_success.</p>\n<blockquote>\n<p>阅读源码，我们可以发现，login将我们输入的字符串做了hash，与已有某不明hash值，进行比较，如果相等则登陆成功。根据本 lab 的内容主要是讲 make 和链接的，让我们碰撞这个hash显然不是本意。那另一种方法就是通过运行时打桩，改变标准库的链接方式，让strcmp 链接到我们自己写的 strcmp 版本上去，从而我们可以控制其返回值让其返回0使得登陆成功。</p>\n</blockquote>\n<p><em>首先要注意 strcmp 并非只有判断密码时的一次唯一调用，在别处还有调用，所以我们要保证 strcmp 函数的基本功能正确</em><br><pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// mystrcmp.c</span>\n<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">define</span> _GNU_SOURCE</span>\n<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span>\n<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;dlfcn.h&gt;</span></span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">strcmp</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">char</span> *lhs, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">char</span> *rhs)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span>(*strcmpp)(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">char</span> *lhs, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">char</span> *rhs);\n    strcmpp = dlsym(RTLD_NEXT, <span class=\"hljs-string\">&quot;strcmp&quot;</span>);\n\n    <span class=\"hljs-keyword\">char</span> tmp[] = <span class=\"hljs-string\">&quot;3983709877683599140&quot;</span>;\n    <span class=\"hljs-keyword\">if</span>(strcmpp(tmp, rhs) == <span class=\"hljs-number\">0</span>)\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">return</span> strcmpp(lhs, rhs);\n&#125;</code></pre></p>\n<blockquote>\n<p>我们直接写一个自己的 strcmp 版本，用 dlsym 可以获取在运行时 strcmp 函数的指针 <em>（不这样做也可以，可以直接自己重写一遍strcmp程序）</em>，相当于可以直接使用 <strong>真实的标准库中的 strcmp</strong>，然后我们稍微改写一下，让它和我们的hash值比较的时候直接返回0，能够让我们不管输入什么密码都能够 login_success。</p>\n</blockquote>\n<p>接下来我们先将我们写的strcmp编译成动态链接库</p>\n<pre><code class=\"hljs shell\">gcc -shared -fpic -o mystrcmp.so mystrcmp.c -ldl</code></pre>\n<blockquote>\n<p>然后使用 <strong>LD_PRELOAD=”./mystrcmp.so”</strong> 指令，从而在 strcmp 动态链接到标准库之前让其优先匹配我们写的动态链接库中的 strcmp 符号。</p>\n</blockquote>\n<p>这里需要注意由于是要直接运行 ./login, 所以我们需要把LD_PRELOAD的效果全局化，也既在前面加上 export 标记。</p>\n<pre><code class=\"hljs shell\">export LD_PRELOAD=&quot;./mystrcmp.so&quot;</code></pre>\n<p>最后注意不要忘记卸载全局 preload， 不然之后所有程序都 preload 这个strcmp。</p>\n<pre><code class=\"hljs shell\">export LD_PRELOAD=NULL</code></pre>"},{"title":"排序算法及编译器优化效果对比","date":"2021-03-09T06:11:52.000Z","index_img":"/img/ICS_Lab1/top.jpg","_content":"\n\n\n## *ICS (Normal) 第一周作业*\n\n\n\n### 冒泡与快排用时对比\n\n\n\n![冒泡排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocut0coevj31do0sggpl.jpg)\n\n\n\n### 相同算法在 GCC 编译优化下用时对比\n\n\n\n![冒泡排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocvbzmuy0j31cy0s842c.jpg)\n\n\n\n![快速排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocut5qwjwj31a80smjvj.jpg)\n\n\n\n![优化快速排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutaoylej31b40sqtcm.jpg)\n\n\n\n\n\n### 不同排序算法在不同GCC优化下的变化\n\n\n\n![冒泡排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutf9rb3j31cs0s8dih.jpg)\n\n\n\n![快速排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocuthxygzj31b20t4jtt.jpg)\n\n\n\n![优化快速排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutkvifhj31b20swdi8.jpg)\n\n\n\n---\n\n\n\n### 改进快速排序\n\n\n\n对于快速排序的改进策略一般有两种\n\n\n\n- ***Pivot 三值取中***\n\n快速排序最坏情况是枢纽元为最大或者最小数字，那么所有数都划分到一个序列去了时间复杂度为O(n^2)，为了保证最坏情况不出现，尽量使pivot能够二分序列，我们采用三值取中法，既开头、中间、结尾三个元素选取大小中等的元素与首元交换成为Pivot，避免最坏情况出现。\n\n\n\n**效果：**在应用三值取中后可以发现优化快排的排序速度变得较为稳定，不像普通版本一样依赖于序列的形态。\n\n\n\n- ***小规模插入排序***\n\n即当快速排序所划分的子序列的长度小于某个定值k时，该子序列基本有序，可以采用插入排序的办法对子序列进行排序，从而使整体算法的时间复杂度的期望下降为 $O(nk+nlg(\\frac{n}{k}))$\n\n\n\n### 实验效果\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocuto6qwgj317w0t076c.jpg)\n\n\n\n可以看到在同等数据量下，对于快速排序具有一定优化效果\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutsrs9ij31au0sctcp.jpg)\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutvjlj6j31bg0rkwig.jpg)\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutym2uij31bm0sotct.jpg)\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocuu1tn5uj31b20swdk0.jpg)\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocuu4kk90j31b20s4n1a.jpg)\n\n\n\n可以看到，随着优化等级的增加，优化的快排几乎成线性，更加稳定，而普通快排有所波动。","source":"_posts/ICS/ICS_Normal.md","raw":"---\ntitle: 排序算法及编译器优化效果对比\ndate: 2021-03-08 22:11:52\nindex_img: /img/ICS_Lab1/top.jpg\ncategory: [ICS]\ntags: [Sort]\n---\n\n\n\n## *ICS (Normal) 第一周作业*\n\n\n\n### 冒泡与快排用时对比\n\n\n\n![冒泡排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocut0coevj31do0sggpl.jpg)\n\n\n\n### 相同算法在 GCC 编译优化下用时对比\n\n\n\n![冒泡排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocvbzmuy0j31cy0s842c.jpg)\n\n\n\n![快速排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocut5qwjwj31a80smjvj.jpg)\n\n\n\n![优化快速排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutaoylej31b40sqtcm.jpg)\n\n\n\n\n\n### 不同排序算法在不同GCC优化下的变化\n\n\n\n![冒泡排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutf9rb3j31cs0s8dih.jpg)\n\n\n\n![快速排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocuthxygzj31b20t4jtt.jpg)\n\n\n\n![优化快速排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutkvifhj31b20swdi8.jpg)\n\n\n\n---\n\n\n\n### 改进快速排序\n\n\n\n对于快速排序的改进策略一般有两种\n\n\n\n- ***Pivot 三值取中***\n\n快速排序最坏情况是枢纽元为最大或者最小数字，那么所有数都划分到一个序列去了时间复杂度为O(n^2)，为了保证最坏情况不出现，尽量使pivot能够二分序列，我们采用三值取中法，既开头、中间、结尾三个元素选取大小中等的元素与首元交换成为Pivot，避免最坏情况出现。\n\n\n\n**效果：**在应用三值取中后可以发现优化快排的排序速度变得较为稳定，不像普通版本一样依赖于序列的形态。\n\n\n\n- ***小规模插入排序***\n\n即当快速排序所划分的子序列的长度小于某个定值k时，该子序列基本有序，可以采用插入排序的办法对子序列进行排序，从而使整体算法的时间复杂度的期望下降为 $O(nk+nlg(\\frac{n}{k}))$\n\n\n\n### 实验效果\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocuto6qwgj317w0t076c.jpg)\n\n\n\n可以看到在同等数据量下，对于快速排序具有一定优化效果\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutsrs9ij31au0sctcp.jpg)\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutvjlj6j31bg0rkwig.jpg)\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutym2uij31bm0sotct.jpg)\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocuu1tn5uj31b20swdk0.jpg)\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocuu4kk90j31b20s4n1a.jpg)\n\n\n\n可以看到，随着优化等级的增加，优化的快排几乎成线性，更加稳定，而普通快排有所波动。","slug":"ICS/ICS_Normal","published":1,"updated":"2026-02-03T05:42:14.433Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvh002y7uit08f05aa8","content":"<h2 id=\"ICS-Normal-第一周作业\"><a href=\"#ICS-Normal-第一周作业\" class=\"headerlink\" title=\"ICS (Normal) 第一周作业\"></a><em>ICS (Normal) 第一周作业</em></h2><h3 id=\"冒泡与快排用时对比\"><a href=\"#冒泡与快排用时对比\" class=\"headerlink\" title=\"冒泡与快排用时对比\"></a>冒泡与快排用时对比</h3><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocut0coevj31do0sggpl.jpg\" alt=\"冒泡排序\"></p>\n<h3 id=\"相同算法在-GCC-编译优化下用时对比\"><a href=\"#相同算法在-GCC-编译优化下用时对比\" class=\"headerlink\" title=\"相同算法在 GCC 编译优化下用时对比\"></a>相同算法在 GCC 编译优化下用时对比</h3><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocvbzmuy0j31cy0s842c.jpg\" alt=\"冒泡排序\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocut5qwjwj31a80smjvj.jpg\" alt=\"快速排序\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutaoylej31b40sqtcm.jpg\" alt=\"优化快速排序\"></p>\n<h3 id=\"不同排序算法在不同GCC优化下的变化\"><a href=\"#不同排序算法在不同GCC优化下的变化\" class=\"headerlink\" title=\"不同排序算法在不同GCC优化下的变化\"></a>不同排序算法在不同GCC优化下的变化</h3><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutf9rb3j31cs0s8dih.jpg\" alt=\"冒泡排序\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocuthxygzj31b20t4jtt.jpg\" alt=\"快速排序\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutkvifhj31b20swdi8.jpg\" alt=\"优化快速排序\"></p>\n<hr>\n<h3 id=\"改进快速排序\"><a href=\"#改进快速排序\" class=\"headerlink\" title=\"改进快速排序\"></a>改进快速排序</h3><p>对于快速排序的改进策略一般有两种</p>\n<ul>\n<li><strong><em>Pivot 三值取中</em></strong></li>\n</ul>\n<p>快速排序最坏情况是枢纽元为最大或者最小数字，那么所有数都划分到一个序列去了时间复杂度为O(n^2)，为了保证最坏情况不出现，尽量使pivot能够二分序列，我们采用三值取中法，既开头、中间、结尾三个元素选取大小中等的元素与首元交换成为Pivot，避免最坏情况出现。</p>\n<p><strong>效果：</strong>在应用三值取中后可以发现优化快排的排序速度变得较为稳定，不像普通版本一样依赖于序列的形态。</p>\n<ul>\n<li><strong><em>小规模插入排序</em></strong></li>\n</ul>\n<p>即当快速排序所划分的子序列的长度小于某个定值k时，该子序列基本有序，可以采用插入排序的办法对子序列进行排序，从而使整体算法的时间复杂度的期望下降为 $O(nk+nlg(\\frac{n}{k}))$</p>\n<h3 id=\"实验效果\"><a href=\"#实验效果\" class=\"headerlink\" title=\"实验效果\"></a>实验效果</h3><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocuto6qwgj317w0t076c.jpg\" alt></p>\n<p>可以看到在同等数据量下，对于快速排序具有一定优化效果</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutsrs9ij31au0sctcp.jpg\" alt></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutvjlj6j31bg0rkwig.jpg\" alt></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutym2uij31bm0sotct.jpg\" alt></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocuu1tn5uj31b20swdk0.jpg\" alt></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocuu4kk90j31b20s4n1a.jpg\" alt></p>\n<p>可以看到，随着优化等级的增加，优化的快排几乎成线性，更加稳定，而普通快排有所波动。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"ICS-Normal-第一周作业\"><a href=\"#ICS-Normal-第一周作业\" class=\"headerlink\" title=\"ICS (Normal) 第一周作业\"></a><em>ICS (Normal) 第一周作业</em></h2><h3 id=\"冒泡与快排用时对比\"><a href=\"#冒泡与快排用时对比\" class=\"headerlink\" title=\"冒泡与快排用时对比\"></a>冒泡与快排用时对比</h3><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocut0coevj31do0sggpl.jpg\" alt=\"冒泡排序\"></p>\n<h3 id=\"相同算法在-GCC-编译优化下用时对比\"><a href=\"#相同算法在-GCC-编译优化下用时对比\" class=\"headerlink\" title=\"相同算法在 GCC 编译优化下用时对比\"></a>相同算法在 GCC 编译优化下用时对比</h3><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocvbzmuy0j31cy0s842c.jpg\" alt=\"冒泡排序\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocut5qwjwj31a80smjvj.jpg\" alt=\"快速排序\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutaoylej31b40sqtcm.jpg\" alt=\"优化快速排序\"></p>\n<h3 id=\"不同排序算法在不同GCC优化下的变化\"><a href=\"#不同排序算法在不同GCC优化下的变化\" class=\"headerlink\" title=\"不同排序算法在不同GCC优化下的变化\"></a>不同排序算法在不同GCC优化下的变化</h3><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutf9rb3j31cs0s8dih.jpg\" alt=\"冒泡排序\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocuthxygzj31b20t4jtt.jpg\" alt=\"快速排序\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutkvifhj31b20swdi8.jpg\" alt=\"优化快速排序\"></p>\n<hr>\n<h3 id=\"改进快速排序\"><a href=\"#改进快速排序\" class=\"headerlink\" title=\"改进快速排序\"></a>改进快速排序</h3><p>对于快速排序的改进策略一般有两种</p>\n<ul>\n<li><strong><em>Pivot 三值取中</em></strong></li>\n</ul>\n<p>快速排序最坏情况是枢纽元为最大或者最小数字，那么所有数都划分到一个序列去了时间复杂度为O(n^2)，为了保证最坏情况不出现，尽量使pivot能够二分序列，我们采用三值取中法，既开头、中间、结尾三个元素选取大小中等的元素与首元交换成为Pivot，避免最坏情况出现。</p>\n<p><strong>效果：</strong>在应用三值取中后可以发现优化快排的排序速度变得较为稳定，不像普通版本一样依赖于序列的形态。</p>\n<ul>\n<li><strong><em>小规模插入排序</em></strong></li>\n</ul>\n<p>即当快速排序所划分的子序列的长度小于某个定值k时，该子序列基本有序，可以采用插入排序的办法对子序列进行排序，从而使整体算法的时间复杂度的期望下降为 $O(nk+nlg(\\frac{n}{k}))$</p>\n<h3 id=\"实验效果\"><a href=\"#实验效果\" class=\"headerlink\" title=\"实验效果\"></a>实验效果</h3><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocuto6qwgj317w0t076c.jpg\" alt></p>\n<p>可以看到在同等数据量下，对于快速排序具有一定优化效果</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutsrs9ij31au0sctcp.jpg\" alt></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutvjlj6j31bg0rkwig.jpg\" alt></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutym2uij31bm0sotct.jpg\" alt></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocuu1tn5uj31b20swdk0.jpg\" alt></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocuu4kk90j31b20s4n1a.jpg\" alt></p>\n<p>可以看到，随着优化等级的增加，优化的快排几乎成线性，更加稳定，而普通快排有所波动。</p>\n"},{"title":"ICS_PJ Y86 Extended CPU","date":"2021-01-06T18:23:45.000Z","index_img":"/img/ICS_Lab1/top.jpg","_content":"\n*项目地址： https://github.com/fdu2019xzy/ICS_Y86*\n\n---\n\n## 一、项目基本信息\n\n### 1. 项目简介\n\nY86-Extended 是由谢子飏和王少文组队合作完成的项目，作为复旦大学 ICS (上) 的期末PJ，\n本项目在实现了本项目在基础流水线处理器架构之上添加了**更高级的分支预测**、**硬件栈**、 **y86 指令集扩展**，并编写了一个**汇编器** yyas (支持宏定义)，以及其他特殊功能。结合精美的前端，根据上传文件性质不同 (yo/ys) 可以在普通模式和编译模式下运行程序, 具有较高的鲁棒性, 能够直观的看到基本信息、所有的寄存器信息 (包括流水线寄存器)、运行进度、当前指令和其他信息。\n\n支持任意**前进回溯**、**设置断点**、**终端输出** (包含**彩色矩阵**)等扩展功能\n\n### 2. 项目分工\n\n王少文：后端 CPU 主体设计及汇编器\n谢子飏： (中) 前端及测试\n\n### 3. 项目架构及设计思路\n\n我们的项目使用**前后端分离**开发策略，考虑到运行速度后端由 C++ 编写，中前端使用 Python, Vue.js, Js 开发。\n\n- 项目架构图\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvtMV.png\" style=\"width:500px\"/>\n\n- 交互逻辑和运行过程\n\n整个交互逻辑和运行过程分为，前端上传 ys/yo 文件 post 到中端的 lauch.py 的flask服务器，flask驱动编译器编译并将编译好的yo文件传到 CPU 中。CPU 按设计跑完输出 data.json 文件，前端 fetch 后端 CPU 生成的 data.json 在前端按操作逻辑进行展示。\n\n由于后端 C++ 跑的非常快，我们前端在上传后几乎能够即时获得 data, 而这样前后端分离的好处在于，我们前端可以非常自由的展现数据，所有的前进回溯甚至跳跃，都可以在 O(1) 内实现，不会出现很大的限制。\n\n---\n\n## 二、使用方式及功能详解\n\n### 1. 具体使用方法\n(见项目目录下 README.md)\n\n### 2. 功能详解\n\n- 主体功能介绍图\n\n![](https://s3.ax1x.com/2021/01/06/sAv8Gn.png)\n\n![](https://s3.ax1x.com/2021/01/06/sAv3Ps.png)\n\n- 当前指令模块\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvV2t.png\" style=\"width:250px\"/>\n\n当前指令显示我们当前运行到的指令 (PC 所指)，并包含前后文2条指令的信息。\n\n**隐藏断点设置**\n\n为了前端的布局美观和统一性，断点设置被隐藏进了当前指令卡片中，点击当前指令卡片即可设置断点。\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvE8I.png\" style=\"width:400px\"/>\n\n可以任意设置增删断点\n\n- **终端字符及彩色矩阵输出**\n\n根据后端的内存映射，我们可以让终端输出字符以及彩色矩阵。\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvJx0.png\" style=\"width:300px\"/>\n\n\n- 附带我们编写的 YYAS 汇编器，能够实现 ys 到 yo 的编译\n\n\n---\n\n\n## 三、代码详解\n\n### 1. 前端代码架构分析\n\n- 前端代码架构图\n\n![](https://s3.ax1x.com/2021/01/06/sAvl5j.png)\n\n前端设计采用 Vue.js 和前端框架 iView 设计，由于 Vue 的**响应式渲染**性质，非常适合我们本次的前端要求，同时为了保持多平台使用的可能性，Vue并没有使用脚手架，所有的 Vue.js、jQuery 都采用了 **CDN 引入**模式。\n\n其中 Index 是主页面入口，Index.js 包括 Vue app 的创建和 Vue 页面路由， Index.html 包含主页面的 DOM 树\n\nPages 里面包含了主要的界面，主页面是 main.js 包含 cpu 的主要功能。\n所有的 Pages 作为 export 模块被引入到 Index.js 中进行路由。\nmain.js 里面包含了 main 页面所有**逻辑函数**，**声明周期钩子**，以及 main 页面的 DOM 树， 其他页面也是同样架构。\n\n（由于是 CDN 引入 main 页面要插入路由的话， DOM 树应当是字符串形式传入 template 中）\n\nCSS 里面包含了所有主要的样式表，对功能和作用区域的不同做了简单的分类。\n\nStatic 里面包含了需要读取的 Json data 信息，以及当前处理编译文件放置在 Source 中。\n\n- **中台前后端链接代码**\n\n前后端连接使用的是 python flask 服务器，通过接前端上传表单的 post，将获得的文件传入编译器编译之后喂入 CPU 中，获得 data.json 前端再 getData。\n\n### 2. 后端代码架构分析\n\n- 后端代码架构图\n\n![](https://s3.ax1x.com/2021/01/06/sAvQaQ.png)\n\n- 汇编器部分\n  - 汇编器的可执行文件为yyas.py，这是包含了所有代码（不需要import）的最终文件，试试./yyas -v 和 ./yyas -h，有惊喜\n  - instr.py为Y86所有指令的信息（不含Y86 Extended的扩展部分）\n  - striper.py为Stage1时，将yo文件转化为yoraw的脚本，目前已经被弃用，仅作为存档提交。现在实现相同功能请使用./yyas -r -np\n- CPU部分\n  - Controller.cpp 为CPU的控制器，主要包含了流水线的控制逻辑\n  - Device.cpp 为CPU流水线的核心，包含了FDEMW五个阶段的运行逻辑\n  - Output.cpp 有一些用于输出的函数，用于Stage1输出至命令行或Stage2输出至json文件\n  - Util.cpp包含了一些辅助的函数，例如In函数和Format函数（这里用了很多modern cpp的魔法）\n\n\n---\n\n<div style=\"page-break-after: always;\"></div>\n\n## 四、 实现细节\n\n#### 前端细节\n\n前端搭建了 anywhere 服务器 (用于解决跨域问题, 踩坑经历可以看第五节)，主要函数在 main.js 文件中， 通过各类声明周期函数和写的 handle 来处理上传，运行，停止，重置，以及断点设置等功能，此处不展开细讲，主要是后端。\n\n（前端使用了 anywhere 服务器 + 中端 flask 服务器的双服务器架构，其主要是因为我们前端在 import 模块时不开本地服务器会产生跨域问题。对于跨域问题我们最开始遇到是在获取 data.json 的时候，踩坑过程中我们曾尝试通过jsonp 解决跨域问题，并且成功了，但在 import 模块时再次遇到了跨域问题，为了一劳永逸，我们直接使用了 anywhere 直接开了一个本地服。）\n\n#### 后端细节\n\n1. **关于流水线**：为了尽可能的靠近实际的硬件架构，我们的CPU核心实现分成了**wire**和**reg**两种struct，用来模拟verilog硬件语言中的wire和reg，reg是实际存在的寄存器，而wire只是用于逻辑中转。为了模拟CPU的并行化，我们采用了如下的逻辑\n\n   1. 利用Reg中的数据计算F D E M W，写入wire变量（实际不存在）\n   2. 利用现在的wire上的值，更新流水线及其他状态\n   3. 将wire的值写入下一个Reg，例如f_wire写入D_Reg，当流水线状态为NORMAL时回到a\n\n2. 每个阶段的具体实现逻辑， 与CSAPP上的电路实现差别不大，此处不再赘述\n\n3. **关于扩展指令集**：我们的指令集扩展见**ISA.md**，具体到流水线上只需少许修改各个阶段的逻辑，与官方设计思路差不太多，依次修改FDEMW就行。\n\n4. **关于分支预测策略**：我们的分支预测采用的是**2比特溢出预测器**，该预测器采用的逻辑如下图\n\n   ![预测器](https://s3.ax1x.com/2021/01/06/sAvG2q.png)\n\n   1. 当JXX的信号不是Jmp时，更新上述的状态机\n   2. 若状态机信号为3或者2，则进行跳转\n   3. 若状态机信号为1或者0，则不进行跳转\n\n   除此之外，我们也需要相应的改变分支错判的逻辑，需要加一个IfJump信号，当E阶段输出的信号与IfJump信号不同，说明分支预测错误，需要清空流水线。\n\n   这样的分支预测器，据统计可以达到90%的正确率（https://en.wikipedia.org/wiki/Branch_predictor），在我们的测试中，一般情况下可以提升10%-30%的性能\n\n5. **关于复杂指令**：在我们增加的指令中，有一些指令如mulq、divq和remq都是很耗时的指令，如果强行让他们在一个周期内完成，我们的CPU时钟频率就会非常低。因此我们假定这部分指令所需要的时间为其他指令最长耗时的10倍，在E阶段设置一个counter，建立一个递减的状态机，使用下面的控制逻辑\n\n   1. 如果指令属于上述复杂指令，将状态机置于10\n   2. 如果状态机不为0，则使F D阶段进入STALL阶段，E阶段继续计算，但阻断E到M的输入，状态机减1\n   3. 如果状态机为0，则流水线继续执行\n\n   这样就可以实现维持较高CPU频率的同时，实现复杂指令。（即不会因为加了这个指令使其他指令的执行变慢）\n\n6. **关于硬件栈**：为了避免每次调用ret指令时两个时钟周期的浪费，我们采用了CSAPP上的硬件栈。在硬件上，硬件栈可以由多路选择器和多个寄存器构成，在这里我们简单的使用Stack实现（大小为0x20）。采用如下的控制逻辑：\n\n   1. 如果调用call指令，在栈没有满时，将地址载入硬件栈\n   2. 如果调用ret指令，在栈非空时，弹栈，将值读出\n   3. 在M阶段执行后，判断硬件栈的预测是否正确\n      1. 若正确，则继续执行\n      2. 若不正确，则清空 F D E的流水线\n\n   使用硬件栈后，最差的情况即是与无硬件栈情况相同，最好情况在我们的测试中，可以增加30%+的性能。\n\n7. 关于指令不可写和非指令不可读保护：我们的汇编器会计算yo文件中，最后一个是指令的位置，在CPU运行时，会进行动态的判断\n\n   1. 在Fetch阶段读取不可读的位置，会产生INS错误\n   2. 在其他阶段写入不可写的位置，会产生ADR错误\n\n8. 关于宏定义：为了CPU的扩展性和兼容性，我们使用了宏定义来动态的开关某些特性，例如 ```OUTPUT_JSON``` 宏定义后即可输出 data_json 供前端使用。\n\n#### 汇编器细节\n\n我们的汇编器采用了依次处理的方式，如下(Code Explains itself)\n\n```python\n    lines = gen_list(lines) #解析关键词\n    lines = remove_single_line_annot(lines) #去除单行注释\n    lines = remove_multi_line_annot(lines) #去除多行注释\n    lines = detach_label(lines) #找到对应的label\n    lines_ref = copy.deepcopy(lines) #复制一份用于输出\n    mem = get_memaddr(lines) #找到内存对应的地址\n    labels = get_def_label(lines) #处理.define\n    lines = replace_label(lines, mem, labels) #处理label\n    byte_code = gen_byte_code(lines) #产生yo代码\n```\n\n\n\n#### 测试细节\n\n我们采用Google Test 和 Python Unitest来辅助我们进行我们的程序测试。其在我们项目文件的 test 文件夹下，我们通过 shell 脚本和 python 脚本将模拟器的输出进行处理，转换成 gtest 代码以便于我们进行测试。\n\n基本语句即为 ```EXPECT_EQ(x, y)```\n\n- 测试代码结构\n\n![](asset/测试代码架构.png)\n\n使用 Google Test 我们能够清晰的看到测试点信息。\n\n- 普通 yo_test\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvZxP.png\" style=\"width:300px\"/>\n\n- Hornor 测试\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvmKf.png\" style=\"width:300px\"/>\n\n- 附加测试\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvMVg.png\" style=\"width:400px\"/>\n\n---\n\n<div style=\"page-break-after: always;\"></div>\n\n\n### 五、特点和创新\n\n1. **汇编器创新**：我们兼容现有的所有ys文件的基础上，还添加了一些伪指令和语法\n\n   1. 不需要写逗号了：现在所有的ys指令操作数之间可以使用空格隔开\n   2. mrmovq和rmmovq：现在不需要强制写括号，可以直接mov至常数地址（此时寄存器为RNONE，我们的CPU也做了相应的修改）如rmmovq %rax $800\n   3. 伪指令\n      1. .define 类似C语言的宏定义\n      2. .string \"mystring\" 将后面的mystring转化为对应的ASCII码写入\n      3. .byte .hword .word支持\n   4. 能够生成yo文件和yoraw文件，生成的yo文件比官方的yo文件漂亮不少，完全对齐\n   5. 有完整的命令行参数\n\n   ```\n   usage: yyas [-h] [-o OUTFILE] [-r] [-np] [-v] sourcefile\n   \n   yyas: Assemble .ys file to .yo file or/and .yo file to raw byte file\n   \n   positional arguments:\n     sourcefile            The source file to be assembled\n   \n   optional arguments:\n     -h, --help            show this help message and exit\n     -o OUTFILE, --output OUTFILE\n                           Assign the output file\n     -r, --raw             Generate raw byte file\n     -np, --noprefix       Do not generate prefix in raw output\n     -v, --version         show version\n   ```\n\n2. **处理器创新**（见具体实现）\n\n   1. 更好的分支预测器\n   2. 硬件栈\n   3. 几乎三倍的指令集支持（及其扩展含义）\n   4. 复杂指令集的多周期支持\n\n---\n\n### 六、总结与回顾\n\n#### PJ 心得总结及致谢\n\n本次 PJ 让我们更加深入的理解了现代流水线处理器的原理，各种硬件栈，扩展指令集的设计也拓展了我们的技术边缘，非常不错的体验。最后非常感谢助教和金老师一学期的辛苦工作。在很多方面帮助了我们，助教的 Lab 非常精彩有趣，金老师的课十分幽默风趣，非常感谢各位的付出。","source":"_posts/ICS/ICS_PJ.md","raw":"---\ntitle: ICS_PJ Y86 Extended CPU\ndate: 2021-01-06 10:23:45\nindex_img: /img/ICS_Lab1/top.jpg\ncategory: [ICS]\ntags: [CPU]\n---\n\n*项目地址： https://github.com/fdu2019xzy/ICS_Y86*\n\n---\n\n## 一、项目基本信息\n\n### 1. 项目简介\n\nY86-Extended 是由谢子飏和王少文组队合作完成的项目，作为复旦大学 ICS (上) 的期末PJ，\n本项目在实现了本项目在基础流水线处理器架构之上添加了**更高级的分支预测**、**硬件栈**、 **y86 指令集扩展**，并编写了一个**汇编器** yyas (支持宏定义)，以及其他特殊功能。结合精美的前端，根据上传文件性质不同 (yo/ys) 可以在普通模式和编译模式下运行程序, 具有较高的鲁棒性, 能够直观的看到基本信息、所有的寄存器信息 (包括流水线寄存器)、运行进度、当前指令和其他信息。\n\n支持任意**前进回溯**、**设置断点**、**终端输出** (包含**彩色矩阵**)等扩展功能\n\n### 2. 项目分工\n\n王少文：后端 CPU 主体设计及汇编器\n谢子飏： (中) 前端及测试\n\n### 3. 项目架构及设计思路\n\n我们的项目使用**前后端分离**开发策略，考虑到运行速度后端由 C++ 编写，中前端使用 Python, Vue.js, Js 开发。\n\n- 项目架构图\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvtMV.png\" style=\"width:500px\"/>\n\n- 交互逻辑和运行过程\n\n整个交互逻辑和运行过程分为，前端上传 ys/yo 文件 post 到中端的 lauch.py 的flask服务器，flask驱动编译器编译并将编译好的yo文件传到 CPU 中。CPU 按设计跑完输出 data.json 文件，前端 fetch 后端 CPU 生成的 data.json 在前端按操作逻辑进行展示。\n\n由于后端 C++ 跑的非常快，我们前端在上传后几乎能够即时获得 data, 而这样前后端分离的好处在于，我们前端可以非常自由的展现数据，所有的前进回溯甚至跳跃，都可以在 O(1) 内实现，不会出现很大的限制。\n\n---\n\n## 二、使用方式及功能详解\n\n### 1. 具体使用方法\n(见项目目录下 README.md)\n\n### 2. 功能详解\n\n- 主体功能介绍图\n\n![](https://s3.ax1x.com/2021/01/06/sAv8Gn.png)\n\n![](https://s3.ax1x.com/2021/01/06/sAv3Ps.png)\n\n- 当前指令模块\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvV2t.png\" style=\"width:250px\"/>\n\n当前指令显示我们当前运行到的指令 (PC 所指)，并包含前后文2条指令的信息。\n\n**隐藏断点设置**\n\n为了前端的布局美观和统一性，断点设置被隐藏进了当前指令卡片中，点击当前指令卡片即可设置断点。\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvE8I.png\" style=\"width:400px\"/>\n\n可以任意设置增删断点\n\n- **终端字符及彩色矩阵输出**\n\n根据后端的内存映射，我们可以让终端输出字符以及彩色矩阵。\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvJx0.png\" style=\"width:300px\"/>\n\n\n- 附带我们编写的 YYAS 汇编器，能够实现 ys 到 yo 的编译\n\n\n---\n\n\n## 三、代码详解\n\n### 1. 前端代码架构分析\n\n- 前端代码架构图\n\n![](https://s3.ax1x.com/2021/01/06/sAvl5j.png)\n\n前端设计采用 Vue.js 和前端框架 iView 设计，由于 Vue 的**响应式渲染**性质，非常适合我们本次的前端要求，同时为了保持多平台使用的可能性，Vue并没有使用脚手架，所有的 Vue.js、jQuery 都采用了 **CDN 引入**模式。\n\n其中 Index 是主页面入口，Index.js 包括 Vue app 的创建和 Vue 页面路由， Index.html 包含主页面的 DOM 树\n\nPages 里面包含了主要的界面，主页面是 main.js 包含 cpu 的主要功能。\n所有的 Pages 作为 export 模块被引入到 Index.js 中进行路由。\nmain.js 里面包含了 main 页面所有**逻辑函数**，**声明周期钩子**，以及 main 页面的 DOM 树， 其他页面也是同样架构。\n\n（由于是 CDN 引入 main 页面要插入路由的话， DOM 树应当是字符串形式传入 template 中）\n\nCSS 里面包含了所有主要的样式表，对功能和作用区域的不同做了简单的分类。\n\nStatic 里面包含了需要读取的 Json data 信息，以及当前处理编译文件放置在 Source 中。\n\n- **中台前后端链接代码**\n\n前后端连接使用的是 python flask 服务器，通过接前端上传表单的 post，将获得的文件传入编译器编译之后喂入 CPU 中，获得 data.json 前端再 getData。\n\n### 2. 后端代码架构分析\n\n- 后端代码架构图\n\n![](https://s3.ax1x.com/2021/01/06/sAvQaQ.png)\n\n- 汇编器部分\n  - 汇编器的可执行文件为yyas.py，这是包含了所有代码（不需要import）的最终文件，试试./yyas -v 和 ./yyas -h，有惊喜\n  - instr.py为Y86所有指令的信息（不含Y86 Extended的扩展部分）\n  - striper.py为Stage1时，将yo文件转化为yoraw的脚本，目前已经被弃用，仅作为存档提交。现在实现相同功能请使用./yyas -r -np\n- CPU部分\n  - Controller.cpp 为CPU的控制器，主要包含了流水线的控制逻辑\n  - Device.cpp 为CPU流水线的核心，包含了FDEMW五个阶段的运行逻辑\n  - Output.cpp 有一些用于输出的函数，用于Stage1输出至命令行或Stage2输出至json文件\n  - Util.cpp包含了一些辅助的函数，例如In函数和Format函数（这里用了很多modern cpp的魔法）\n\n\n---\n\n<div style=\"page-break-after: always;\"></div>\n\n## 四、 实现细节\n\n#### 前端细节\n\n前端搭建了 anywhere 服务器 (用于解决跨域问题, 踩坑经历可以看第五节)，主要函数在 main.js 文件中， 通过各类声明周期函数和写的 handle 来处理上传，运行，停止，重置，以及断点设置等功能，此处不展开细讲，主要是后端。\n\n（前端使用了 anywhere 服务器 + 中端 flask 服务器的双服务器架构，其主要是因为我们前端在 import 模块时不开本地服务器会产生跨域问题。对于跨域问题我们最开始遇到是在获取 data.json 的时候，踩坑过程中我们曾尝试通过jsonp 解决跨域问题，并且成功了，但在 import 模块时再次遇到了跨域问题，为了一劳永逸，我们直接使用了 anywhere 直接开了一个本地服。）\n\n#### 后端细节\n\n1. **关于流水线**：为了尽可能的靠近实际的硬件架构，我们的CPU核心实现分成了**wire**和**reg**两种struct，用来模拟verilog硬件语言中的wire和reg，reg是实际存在的寄存器，而wire只是用于逻辑中转。为了模拟CPU的并行化，我们采用了如下的逻辑\n\n   1. 利用Reg中的数据计算F D E M W，写入wire变量（实际不存在）\n   2. 利用现在的wire上的值，更新流水线及其他状态\n   3. 将wire的值写入下一个Reg，例如f_wire写入D_Reg，当流水线状态为NORMAL时回到a\n\n2. 每个阶段的具体实现逻辑， 与CSAPP上的电路实现差别不大，此处不再赘述\n\n3. **关于扩展指令集**：我们的指令集扩展见**ISA.md**，具体到流水线上只需少许修改各个阶段的逻辑，与官方设计思路差不太多，依次修改FDEMW就行。\n\n4. **关于分支预测策略**：我们的分支预测采用的是**2比特溢出预测器**，该预测器采用的逻辑如下图\n\n   ![预测器](https://s3.ax1x.com/2021/01/06/sAvG2q.png)\n\n   1. 当JXX的信号不是Jmp时，更新上述的状态机\n   2. 若状态机信号为3或者2，则进行跳转\n   3. 若状态机信号为1或者0，则不进行跳转\n\n   除此之外，我们也需要相应的改变分支错判的逻辑，需要加一个IfJump信号，当E阶段输出的信号与IfJump信号不同，说明分支预测错误，需要清空流水线。\n\n   这样的分支预测器，据统计可以达到90%的正确率（https://en.wikipedia.org/wiki/Branch_predictor），在我们的测试中，一般情况下可以提升10%-30%的性能\n\n5. **关于复杂指令**：在我们增加的指令中，有一些指令如mulq、divq和remq都是很耗时的指令，如果强行让他们在一个周期内完成，我们的CPU时钟频率就会非常低。因此我们假定这部分指令所需要的时间为其他指令最长耗时的10倍，在E阶段设置一个counter，建立一个递减的状态机，使用下面的控制逻辑\n\n   1. 如果指令属于上述复杂指令，将状态机置于10\n   2. 如果状态机不为0，则使F D阶段进入STALL阶段，E阶段继续计算，但阻断E到M的输入，状态机减1\n   3. 如果状态机为0，则流水线继续执行\n\n   这样就可以实现维持较高CPU频率的同时，实现复杂指令。（即不会因为加了这个指令使其他指令的执行变慢）\n\n6. **关于硬件栈**：为了避免每次调用ret指令时两个时钟周期的浪费，我们采用了CSAPP上的硬件栈。在硬件上，硬件栈可以由多路选择器和多个寄存器构成，在这里我们简单的使用Stack实现（大小为0x20）。采用如下的控制逻辑：\n\n   1. 如果调用call指令，在栈没有满时，将地址载入硬件栈\n   2. 如果调用ret指令，在栈非空时，弹栈，将值读出\n   3. 在M阶段执行后，判断硬件栈的预测是否正确\n      1. 若正确，则继续执行\n      2. 若不正确，则清空 F D E的流水线\n\n   使用硬件栈后，最差的情况即是与无硬件栈情况相同，最好情况在我们的测试中，可以增加30%+的性能。\n\n7. 关于指令不可写和非指令不可读保护：我们的汇编器会计算yo文件中，最后一个是指令的位置，在CPU运行时，会进行动态的判断\n\n   1. 在Fetch阶段读取不可读的位置，会产生INS错误\n   2. 在其他阶段写入不可写的位置，会产生ADR错误\n\n8. 关于宏定义：为了CPU的扩展性和兼容性，我们使用了宏定义来动态的开关某些特性，例如 ```OUTPUT_JSON``` 宏定义后即可输出 data_json 供前端使用。\n\n#### 汇编器细节\n\n我们的汇编器采用了依次处理的方式，如下(Code Explains itself)\n\n```python\n    lines = gen_list(lines) #解析关键词\n    lines = remove_single_line_annot(lines) #去除单行注释\n    lines = remove_multi_line_annot(lines) #去除多行注释\n    lines = detach_label(lines) #找到对应的label\n    lines_ref = copy.deepcopy(lines) #复制一份用于输出\n    mem = get_memaddr(lines) #找到内存对应的地址\n    labels = get_def_label(lines) #处理.define\n    lines = replace_label(lines, mem, labels) #处理label\n    byte_code = gen_byte_code(lines) #产生yo代码\n```\n\n\n\n#### 测试细节\n\n我们采用Google Test 和 Python Unitest来辅助我们进行我们的程序测试。其在我们项目文件的 test 文件夹下，我们通过 shell 脚本和 python 脚本将模拟器的输出进行处理，转换成 gtest 代码以便于我们进行测试。\n\n基本语句即为 ```EXPECT_EQ(x, y)```\n\n- 测试代码结构\n\n![](asset/测试代码架构.png)\n\n使用 Google Test 我们能够清晰的看到测试点信息。\n\n- 普通 yo_test\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvZxP.png\" style=\"width:300px\"/>\n\n- Hornor 测试\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvmKf.png\" style=\"width:300px\"/>\n\n- 附加测试\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvMVg.png\" style=\"width:400px\"/>\n\n---\n\n<div style=\"page-break-after: always;\"></div>\n\n\n### 五、特点和创新\n\n1. **汇编器创新**：我们兼容现有的所有ys文件的基础上，还添加了一些伪指令和语法\n\n   1. 不需要写逗号了：现在所有的ys指令操作数之间可以使用空格隔开\n   2. mrmovq和rmmovq：现在不需要强制写括号，可以直接mov至常数地址（此时寄存器为RNONE，我们的CPU也做了相应的修改）如rmmovq %rax $800\n   3. 伪指令\n      1. .define 类似C语言的宏定义\n      2. .string \"mystring\" 将后面的mystring转化为对应的ASCII码写入\n      3. .byte .hword .word支持\n   4. 能够生成yo文件和yoraw文件，生成的yo文件比官方的yo文件漂亮不少，完全对齐\n   5. 有完整的命令行参数\n\n   ```\n   usage: yyas [-h] [-o OUTFILE] [-r] [-np] [-v] sourcefile\n   \n   yyas: Assemble .ys file to .yo file or/and .yo file to raw byte file\n   \n   positional arguments:\n     sourcefile            The source file to be assembled\n   \n   optional arguments:\n     -h, --help            show this help message and exit\n     -o OUTFILE, --output OUTFILE\n                           Assign the output file\n     -r, --raw             Generate raw byte file\n     -np, --noprefix       Do not generate prefix in raw output\n     -v, --version         show version\n   ```\n\n2. **处理器创新**（见具体实现）\n\n   1. 更好的分支预测器\n   2. 硬件栈\n   3. 几乎三倍的指令集支持（及其扩展含义）\n   4. 复杂指令集的多周期支持\n\n---\n\n### 六、总结与回顾\n\n#### PJ 心得总结及致谢\n\n本次 PJ 让我们更加深入的理解了现代流水线处理器的原理，各种硬件栈，扩展指令集的设计也拓展了我们的技术边缘，非常不错的体验。最后非常感谢助教和金老师一学期的辛苦工作。在很多方面帮助了我们，助教的 Lab 非常精彩有趣，金老师的课十分幽默风趣，非常感谢各位的付出。","slug":"ICS/ICS_PJ","published":1,"updated":"2026-02-03T05:42:14.436Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvh002z7uith8mu3usp","content":"<p><em>项目地址： <a href=\"https://github.com/fdu2019xzy/ICS_Y86\">https://github.com/fdu2019xzy/ICS_Y86</a></em></p>\n<hr>\n<h2 id=\"一、项目基本信息\"><a href=\"#一、项目基本信息\" class=\"headerlink\" title=\"一、项目基本信息\"></a>一、项目基本信息</h2><h3 id=\"1-项目简介\"><a href=\"#1-项目简介\" class=\"headerlink\" title=\"1. 项目简介\"></a>1. 项目简介</h3><p>Y86-Extended 是由谢子飏和王少文组队合作完成的项目，作为复旦大学 ICS (上) 的期末PJ，<br>本项目在实现了本项目在基础流水线处理器架构之上添加了<strong>更高级的分支预测</strong>、<strong>硬件栈</strong>、 <strong>y86 指令集扩展</strong>，并编写了一个<strong>汇编器</strong> yyas (支持宏定义)，以及其他特殊功能。结合精美的前端，根据上传文件性质不同 (yo/ys) 可以在普通模式和编译模式下运行程序, 具有较高的鲁棒性, 能够直观的看到基本信息、所有的寄存器信息 (包括流水线寄存器)、运行进度、当前指令和其他信息。</p>\n<p>支持任意<strong>前进回溯</strong>、<strong>设置断点</strong>、<strong>终端输出</strong> (包含<strong>彩色矩阵</strong>)等扩展功能</p>\n<h3 id=\"2-项目分工\"><a href=\"#2-项目分工\" class=\"headerlink\" title=\"2. 项目分工\"></a>2. 项目分工</h3><p>王少文：后端 CPU 主体设计及汇编器<br>谢子飏： (中) 前端及测试</p>\n<h3 id=\"3-项目架构及设计思路\"><a href=\"#3-项目架构及设计思路\" class=\"headerlink\" title=\"3. 项目架构及设计思路\"></a>3. 项目架构及设计思路</h3><p>我们的项目使用<strong>前后端分离</strong>开发策略，考虑到运行速度后端由 C++ 编写，中前端使用 Python, Vue.js, Js 开发。</p>\n<ul>\n<li>项目架构图</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvtMV.png\" style=\"width:500px\"></p>\n<ul>\n<li>交互逻辑和运行过程</li>\n</ul>\n<p>整个交互逻辑和运行过程分为，前端上传 ys/yo 文件 post 到中端的 lauch.py 的flask服务器，flask驱动编译器编译并将编译好的yo文件传到 CPU 中。CPU 按设计跑完输出 data.json 文件，前端 fetch 后端 CPU 生成的 data.json 在前端按操作逻辑进行展示。</p>\n<p>由于后端 C++ 跑的非常快，我们前端在上传后几乎能够即时获得 data, 而这样前后端分离的好处在于，我们前端可以非常自由的展现数据，所有的前进回溯甚至跳跃，都可以在 O(1) 内实现，不会出现很大的限制。</p>\n<hr>\n<h2 id=\"二、使用方式及功能详解\"><a href=\"#二、使用方式及功能详解\" class=\"headerlink\" title=\"二、使用方式及功能详解\"></a>二、使用方式及功能详解</h2><h3 id=\"1-具体使用方法\"><a href=\"#1-具体使用方法\" class=\"headerlink\" title=\"1. 具体使用方法\"></a>1. 具体使用方法</h3><p>(见项目目录下 README.md)</p>\n<h3 id=\"2-功能详解\"><a href=\"#2-功能详解\" class=\"headerlink\" title=\"2. 功能详解\"></a>2. 功能详解</h3><ul>\n<li>主体功能介绍图</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAv8Gn.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAv3Ps.png\" alt></p>\n<ul>\n<li>当前指令模块</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvV2t.png\" style=\"width:250px\"></p>\n<p>当前指令显示我们当前运行到的指令 (PC 所指)，并包含前后文2条指令的信息。</p>\n<p><strong>隐藏断点设置</strong></p>\n<p>为了前端的布局美观和统一性，断点设置被隐藏进了当前指令卡片中，点击当前指令卡片即可设置断点。</p>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvE8I.png\" style=\"width:400px\"></p>\n<p>可以任意设置增删断点</p>\n<ul>\n<li><strong>终端字符及彩色矩阵输出</strong></li>\n</ul>\n<p>根据后端的内存映射，我们可以让终端输出字符以及彩色矩阵。</p>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvJx0.png\" style=\"width:300px\"></p>\n<ul>\n<li>附带我们编写的 YYAS 汇编器，能够实现 ys 到 yo 的编译</li>\n</ul>\n<hr>\n<h2 id=\"三、代码详解\"><a href=\"#三、代码详解\" class=\"headerlink\" title=\"三、代码详解\"></a>三、代码详解</h2><h3 id=\"1-前端代码架构分析\"><a href=\"#1-前端代码架构分析\" class=\"headerlink\" title=\"1. 前端代码架构分析\"></a>1. 前端代码架构分析</h3><ul>\n<li>前端代码架构图</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvl5j.png\" alt></p>\n<p>前端设计采用 Vue.js 和前端框架 iView 设计，由于 Vue 的<strong>响应式渲染</strong>性质，非常适合我们本次的前端要求，同时为了保持多平台使用的可能性，Vue并没有使用脚手架，所有的 Vue.js、jQuery 都采用了 <strong>CDN 引入</strong>模式。</p>\n<p>其中 Index 是主页面入口，Index.js 包括 Vue app 的创建和 Vue 页面路由， Index.html 包含主页面的 DOM 树</p>\n<p>Pages 里面包含了主要的界面，主页面是 main.js 包含 cpu 的主要功能。<br>所有的 Pages 作为 export 模块被引入到 Index.js 中进行路由。<br>main.js 里面包含了 main 页面所有<strong>逻辑函数</strong>，<strong>声明周期钩子</strong>，以及 main 页面的 DOM 树， 其他页面也是同样架构。</p>\n<p>（由于是 CDN 引入 main 页面要插入路由的话， DOM 树应当是字符串形式传入 template 中）</p>\n<p>CSS 里面包含了所有主要的样式表，对功能和作用区域的不同做了简单的分类。</p>\n<p>Static 里面包含了需要读取的 Json data 信息，以及当前处理编译文件放置在 Source 中。</p>\n<ul>\n<li><strong>中台前后端链接代码</strong></li>\n</ul>\n<p>前后端连接使用的是 python flask 服务器，通过接前端上传表单的 post，将获得的文件传入编译器编译之后喂入 CPU 中，获得 data.json 前端再 getData。</p>\n<h3 id=\"2-后端代码架构分析\"><a href=\"#2-后端代码架构分析\" class=\"headerlink\" title=\"2. 后端代码架构分析\"></a>2. 后端代码架构分析</h3><ul>\n<li>后端代码架构图</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvQaQ.png\" alt></p>\n<ul>\n<li>汇编器部分<ul>\n<li>汇编器的可执行文件为yyas.py，这是包含了所有代码（不需要import）的最终文件，试试./yyas -v 和 ./yyas -h，有惊喜</li>\n<li>instr.py为Y86所有指令的信息（不含Y86 Extended的扩展部分）</li>\n<li>striper.py为Stage1时，将yo文件转化为yoraw的脚本，目前已经被弃用，仅作为存档提交。现在实现相同功能请使用./yyas -r -np</li>\n</ul>\n</li>\n<li>CPU部分<ul>\n<li>Controller.cpp 为CPU的控制器，主要包含了流水线的控制逻辑</li>\n<li>Device.cpp 为CPU流水线的核心，包含了FDEMW五个阶段的运行逻辑</li>\n<li>Output.cpp 有一些用于输出的函数，用于Stage1输出至命令行或Stage2输出至json文件</li>\n<li>Util.cpp包含了一些辅助的函数，例如In函数和Format函数（这里用了很多modern cpp的魔法）</li>\n</ul>\n</li>\n</ul>\n<hr>\n<div style=\"page-break-after: always;\"></div>\n\n<h2 id=\"四、-实现细节\"><a href=\"#四、-实现细节\" class=\"headerlink\" title=\"四、 实现细节\"></a>四、 实现细节</h2><h4 id=\"前端细节\"><a href=\"#前端细节\" class=\"headerlink\" title=\"前端细节\"></a>前端细节</h4><p>前端搭建了 anywhere 服务器 (用于解决跨域问题, 踩坑经历可以看第五节)，主要函数在 main.js 文件中， 通过各类声明周期函数和写的 handle 来处理上传，运行，停止，重置，以及断点设置等功能，此处不展开细讲，主要是后端。</p>\n<p>（前端使用了 anywhere 服务器 + 中端 flask 服务器的双服务器架构，其主要是因为我们前端在 import 模块时不开本地服务器会产生跨域问题。对于跨域问题我们最开始遇到是在获取 data.json 的时候，踩坑过程中我们曾尝试通过jsonp 解决跨域问题，并且成功了，但在 import 模块时再次遇到了跨域问题，为了一劳永逸，我们直接使用了 anywhere 直接开了一个本地服。）</p>\n<h4 id=\"后端细节\"><a href=\"#后端细节\" class=\"headerlink\" title=\"后端细节\"></a>后端细节</h4><ol>\n<li><p><strong>关于流水线</strong>：为了尽可能的靠近实际的硬件架构，我们的CPU核心实现分成了<strong>wire</strong>和<strong>reg</strong>两种struct，用来模拟verilog硬件语言中的wire和reg，reg是实际存在的寄存器，而wire只是用于逻辑中转。为了模拟CPU的并行化，我们采用了如下的逻辑</p>\n<ol>\n<li>利用Reg中的数据计算F D E M W，写入wire变量（实际不存在）</li>\n<li>利用现在的wire上的值，更新流水线及其他状态</li>\n<li>将wire的值写入下一个Reg，例如f_wire写入D_Reg，当流水线状态为NORMAL时回到a</li>\n</ol>\n</li>\n<li><p>每个阶段的具体实现逻辑， 与CSAPP上的电路实现差别不大，此处不再赘述</p>\n</li>\n<li><p><strong>关于扩展指令集</strong>：我们的指令集扩展见<strong>ISA.md</strong>，具体到流水线上只需少许修改各个阶段的逻辑，与官方设计思路差不太多，依次修改FDEMW就行。</p>\n</li>\n<li><p><strong>关于分支预测策略</strong>：我们的分支预测采用的是<strong>2比特溢出预测器</strong>，该预测器采用的逻辑如下图</p>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvG2q.png\" alt=\"预测器\"></p>\n<ol>\n<li>当JXX的信号不是Jmp时，更新上述的状态机</li>\n<li>若状态机信号为3或者2，则进行跳转</li>\n<li>若状态机信号为1或者0，则不进行跳转</li>\n</ol>\n<p>除此之外，我们也需要相应的改变分支错判的逻辑，需要加一个IfJump信号，当E阶段输出的信号与IfJump信号不同，说明分支预测错误，需要清空流水线。</p>\n<p>这样的分支预测器，据统计可以达到90%的正确率（<a href=\"https://en.wikipedia.org/wiki/Branch_predictor），在我们的测试中，一般情况下可以提升10%-30%的性能\">https://en.wikipedia.org/wiki/Branch_predictor），在我们的测试中，一般情况下可以提升10%-30%的性能</a></p>\n</li>\n<li><p><strong>关于复杂指令</strong>：在我们增加的指令中，有一些指令如mulq、divq和remq都是很耗时的指令，如果强行让他们在一个周期内完成，我们的CPU时钟频率就会非常低。因此我们假定这部分指令所需要的时间为其他指令最长耗时的10倍，在E阶段设置一个counter，建立一个递减的状态机，使用下面的控制逻辑</p>\n<ol>\n<li>如果指令属于上述复杂指令，将状态机置于10</li>\n<li>如果状态机不为0，则使F D阶段进入STALL阶段，E阶段继续计算，但阻断E到M的输入，状态机减1</li>\n<li>如果状态机为0，则流水线继续执行</li>\n</ol>\n<p>这样就可以实现维持较高CPU频率的同时，实现复杂指令。（即不会因为加了这个指令使其他指令的执行变慢）</p>\n</li>\n<li><p><strong>关于硬件栈</strong>：为了避免每次调用ret指令时两个时钟周期的浪费，我们采用了CSAPP上的硬件栈。在硬件上，硬件栈可以由多路选择器和多个寄存器构成，在这里我们简单的使用Stack实现（大小为0x20）。采用如下的控制逻辑：</p>\n<ol>\n<li>如果调用call指令，在栈没有满时，将地址载入硬件栈</li>\n<li>如果调用ret指令，在栈非空时，弹栈，将值读出</li>\n<li>在M阶段执行后，判断硬件栈的预测是否正确<ol>\n<li>若正确，则继续执行</li>\n<li>若不正确，则清空 F D E的流水线</li>\n</ol>\n</li>\n</ol>\n<p>使用硬件栈后，最差的情况即是与无硬件栈情况相同，最好情况在我们的测试中，可以增加30%+的性能。</p>\n</li>\n<li><p>关于指令不可写和非指令不可读保护：我们的汇编器会计算yo文件中，最后一个是指令的位置，在CPU运行时，会进行动态的判断</p>\n<ol>\n<li>在Fetch阶段读取不可读的位置，会产生INS错误</li>\n<li>在其他阶段写入不可写的位置，会产生ADR错误</li>\n</ol>\n</li>\n<li><p>关于宏定义：为了CPU的扩展性和兼容性，我们使用了宏定义来动态的开关某些特性，例如 <code>OUTPUT_JSON</code> 宏定义后即可输出 data_json 供前端使用。</p>\n</li>\n</ol>\n<h4 id=\"汇编器细节\"><a href=\"#汇编器细节\" class=\"headerlink\" title=\"汇编器细节\"></a>汇编器细节</h4><p>我们的汇编器采用了依次处理的方式，如下(Code Explains itself)</p>\n<pre><code class=\"hljs python\">lines = gen_list(lines) <span class=\"hljs-comment\">#解析关键词</span>\nlines = remove_single_line_annot(lines) <span class=\"hljs-comment\">#去除单行注释</span>\nlines = remove_multi_line_annot(lines) <span class=\"hljs-comment\">#去除多行注释</span>\nlines = detach_label(lines) <span class=\"hljs-comment\">#找到对应的label</span>\nlines_ref = copy.deepcopy(lines) <span class=\"hljs-comment\">#复制一份用于输出</span>\nmem = get_memaddr(lines) <span class=\"hljs-comment\">#找到内存对应的地址</span>\nlabels = get_def_label(lines) <span class=\"hljs-comment\">#处理.define</span>\nlines = replace_label(lines, mem, labels) <span class=\"hljs-comment\">#处理label</span>\nbyte_code = gen_byte_code(lines) <span class=\"hljs-comment\">#产生yo代码</span></code></pre>\n<h4 id=\"测试细节\"><a href=\"#测试细节\" class=\"headerlink\" title=\"测试细节\"></a>测试细节</h4><p>我们采用Google Test 和 Python Unitest来辅助我们进行我们的程序测试。其在我们项目文件的 test 文件夹下，我们通过 shell 脚本和 python 脚本将模拟器的输出进行处理，转换成 gtest 代码以便于我们进行测试。</p>\n<p>基本语句即为 <code>EXPECT_EQ(x, y)</code></p>\n<ul>\n<li>测试代码结构</li>\n</ul>\n<p><img src=\"/CsBlog/CsBlog/2021/01/06/ICS/ICS_PJ/测试代码架构.png\" alt></p>\n<p>使用 Google Test 我们能够清晰的看到测试点信息。</p>\n<ul>\n<li>普通 yo_test</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvZxP.png\" style=\"width:300px\"></p>\n<ul>\n<li>Hornor 测试</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvmKf.png\" style=\"width:300px\"></p>\n<ul>\n<li>附加测试</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvMVg.png\" style=\"width:400px\"></p>\n<hr>\n<div style=\"page-break-after: always;\"></div>\n\n\n<h3 id=\"五、特点和创新\"><a href=\"#五、特点和创新\" class=\"headerlink\" title=\"五、特点和创新\"></a>五、特点和创新</h3><ol>\n<li><p><strong>汇编器创新</strong>：我们兼容现有的所有ys文件的基础上，还添加了一些伪指令和语法</p>\n<ol>\n<li>不需要写逗号了：现在所有的ys指令操作数之间可以使用空格隔开</li>\n<li>mrmovq和rmmovq：现在不需要强制写括号，可以直接mov至常数地址（此时寄存器为RNONE，我们的CPU也做了相应的修改）如rmmovq %rax $800</li>\n<li>伪指令<ol>\n<li>.define 类似C语言的宏定义</li>\n<li>.string “mystring” 将后面的mystring转化为对应的ASCII码写入</li>\n<li>.byte .hword .word支持</li>\n</ol>\n</li>\n<li>能够生成yo文件和yoraw文件，生成的yo文件比官方的yo文件漂亮不少，完全对齐</li>\n<li>有完整的命令行参数</li>\n</ol>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">usage</span>: yyas [-h] [-o OUTFILE] [-r] [-np] [-v] sourcefile\n\n<span class=\"hljs-attribute\">yyas</span>: Assemble .ys file to .yo file or/and .yo file to raw byte file\n\npositional arguments:\n  sourcefile            The source file to be assembled\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -o OUTFILE, --output OUTFILE\n                        Assign the output file\n  -r, --raw             Generate raw byte file\n  -np, --noprefix       Do not generate prefix in raw output\n  -v, --version         show version</code></pre>\n</li>\n<li><p><strong>处理器创新</strong>（见具体实现）</p>\n<ol>\n<li>更好的分支预测器</li>\n<li>硬件栈</li>\n<li>几乎三倍的指令集支持（及其扩展含义）</li>\n<li>复杂指令集的多周期支持</li>\n</ol>\n</li>\n</ol>\n<hr>\n<h3 id=\"六、总结与回顾\"><a href=\"#六、总结与回顾\" class=\"headerlink\" title=\"六、总结与回顾\"></a>六、总结与回顾</h3><h4 id=\"PJ-心得总结及致谢\"><a href=\"#PJ-心得总结及致谢\" class=\"headerlink\" title=\"PJ 心得总结及致谢\"></a>PJ 心得总结及致谢</h4><p>本次 PJ 让我们更加深入的理解了现代流水线处理器的原理，各种硬件栈，扩展指令集的设计也拓展了我们的技术边缘，非常不错的体验。最后非常感谢助教和金老师一学期的辛苦工作。在很多方面帮助了我们，助教的 Lab 非常精彩有趣，金老师的课十分幽默风趣，非常感谢各位的付出。</p>\n","site":{"data":{}},"excerpt":"","more":"<p><em>项目地址： <a href=\"https://github.com/fdu2019xzy/ICS_Y86\">https://github.com/fdu2019xzy/ICS_Y86</a></em></p>\n<hr>\n<h2 id=\"一、项目基本信息\"><a href=\"#一、项目基本信息\" class=\"headerlink\" title=\"一、项目基本信息\"></a>一、项目基本信息</h2><h3 id=\"1-项目简介\"><a href=\"#1-项目简介\" class=\"headerlink\" title=\"1. 项目简介\"></a>1. 项目简介</h3><p>Y86-Extended 是由谢子飏和王少文组队合作完成的项目，作为复旦大学 ICS (上) 的期末PJ，<br>本项目在实现了本项目在基础流水线处理器架构之上添加了<strong>更高级的分支预测</strong>、<strong>硬件栈</strong>、 <strong>y86 指令集扩展</strong>，并编写了一个<strong>汇编器</strong> yyas (支持宏定义)，以及其他特殊功能。结合精美的前端，根据上传文件性质不同 (yo/ys) 可以在普通模式和编译模式下运行程序, 具有较高的鲁棒性, 能够直观的看到基本信息、所有的寄存器信息 (包括流水线寄存器)、运行进度、当前指令和其他信息。</p>\n<p>支持任意<strong>前进回溯</strong>、<strong>设置断点</strong>、<strong>终端输出</strong> (包含<strong>彩色矩阵</strong>)等扩展功能</p>\n<h3 id=\"2-项目分工\"><a href=\"#2-项目分工\" class=\"headerlink\" title=\"2. 项目分工\"></a>2. 项目分工</h3><p>王少文：后端 CPU 主体设计及汇编器<br>谢子飏： (中) 前端及测试</p>\n<h3 id=\"3-项目架构及设计思路\"><a href=\"#3-项目架构及设计思路\" class=\"headerlink\" title=\"3. 项目架构及设计思路\"></a>3. 项目架构及设计思路</h3><p>我们的项目使用<strong>前后端分离</strong>开发策略，考虑到运行速度后端由 C++ 编写，中前端使用 Python, Vue.js, Js 开发。</p>\n<ul>\n<li>项目架构图</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvtMV.png\" style=\"width:500px\"></p>\n<ul>\n<li>交互逻辑和运行过程</li>\n</ul>\n<p>整个交互逻辑和运行过程分为，前端上传 ys/yo 文件 post 到中端的 lauch.py 的flask服务器，flask驱动编译器编译并将编译好的yo文件传到 CPU 中。CPU 按设计跑完输出 data.json 文件，前端 fetch 后端 CPU 生成的 data.json 在前端按操作逻辑进行展示。</p>\n<p>由于后端 C++ 跑的非常快，我们前端在上传后几乎能够即时获得 data, 而这样前后端分离的好处在于，我们前端可以非常自由的展现数据，所有的前进回溯甚至跳跃，都可以在 O(1) 内实现，不会出现很大的限制。</p>\n<hr>\n<h2 id=\"二、使用方式及功能详解\"><a href=\"#二、使用方式及功能详解\" class=\"headerlink\" title=\"二、使用方式及功能详解\"></a>二、使用方式及功能详解</h2><h3 id=\"1-具体使用方法\"><a href=\"#1-具体使用方法\" class=\"headerlink\" title=\"1. 具体使用方法\"></a>1. 具体使用方法</h3><p>(见项目目录下 README.md)</p>\n<h3 id=\"2-功能详解\"><a href=\"#2-功能详解\" class=\"headerlink\" title=\"2. 功能详解\"></a>2. 功能详解</h3><ul>\n<li>主体功能介绍图</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAv8Gn.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAv3Ps.png\" alt></p>\n<ul>\n<li>当前指令模块</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvV2t.png\" style=\"width:250px\"></p>\n<p>当前指令显示我们当前运行到的指令 (PC 所指)，并包含前后文2条指令的信息。</p>\n<p><strong>隐藏断点设置</strong></p>\n<p>为了前端的布局美观和统一性，断点设置被隐藏进了当前指令卡片中，点击当前指令卡片即可设置断点。</p>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvE8I.png\" style=\"width:400px\"></p>\n<p>可以任意设置增删断点</p>\n<ul>\n<li><strong>终端字符及彩色矩阵输出</strong></li>\n</ul>\n<p>根据后端的内存映射，我们可以让终端输出字符以及彩色矩阵。</p>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvJx0.png\" style=\"width:300px\"></p>\n<ul>\n<li>附带我们编写的 YYAS 汇编器，能够实现 ys 到 yo 的编译</li>\n</ul>\n<hr>\n<h2 id=\"三、代码详解\"><a href=\"#三、代码详解\" class=\"headerlink\" title=\"三、代码详解\"></a>三、代码详解</h2><h3 id=\"1-前端代码架构分析\"><a href=\"#1-前端代码架构分析\" class=\"headerlink\" title=\"1. 前端代码架构分析\"></a>1. 前端代码架构分析</h3><ul>\n<li>前端代码架构图</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvl5j.png\" alt></p>\n<p>前端设计采用 Vue.js 和前端框架 iView 设计，由于 Vue 的<strong>响应式渲染</strong>性质，非常适合我们本次的前端要求，同时为了保持多平台使用的可能性，Vue并没有使用脚手架，所有的 Vue.js、jQuery 都采用了 <strong>CDN 引入</strong>模式。</p>\n<p>其中 Index 是主页面入口，Index.js 包括 Vue app 的创建和 Vue 页面路由， Index.html 包含主页面的 DOM 树</p>\n<p>Pages 里面包含了主要的界面，主页面是 main.js 包含 cpu 的主要功能。<br>所有的 Pages 作为 export 模块被引入到 Index.js 中进行路由。<br>main.js 里面包含了 main 页面所有<strong>逻辑函数</strong>，<strong>声明周期钩子</strong>，以及 main 页面的 DOM 树， 其他页面也是同样架构。</p>\n<p>（由于是 CDN 引入 main 页面要插入路由的话， DOM 树应当是字符串形式传入 template 中）</p>\n<p>CSS 里面包含了所有主要的样式表，对功能和作用区域的不同做了简单的分类。</p>\n<p>Static 里面包含了需要读取的 Json data 信息，以及当前处理编译文件放置在 Source 中。</p>\n<ul>\n<li><strong>中台前后端链接代码</strong></li>\n</ul>\n<p>前后端连接使用的是 python flask 服务器，通过接前端上传表单的 post，将获得的文件传入编译器编译之后喂入 CPU 中，获得 data.json 前端再 getData。</p>\n<h3 id=\"2-后端代码架构分析\"><a href=\"#2-后端代码架构分析\" class=\"headerlink\" title=\"2. 后端代码架构分析\"></a>2. 后端代码架构分析</h3><ul>\n<li>后端代码架构图</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvQaQ.png\" alt></p>\n<ul>\n<li>汇编器部分<ul>\n<li>汇编器的可执行文件为yyas.py，这是包含了所有代码（不需要import）的最终文件，试试./yyas -v 和 ./yyas -h，有惊喜</li>\n<li>instr.py为Y86所有指令的信息（不含Y86 Extended的扩展部分）</li>\n<li>striper.py为Stage1时，将yo文件转化为yoraw的脚本，目前已经被弃用，仅作为存档提交。现在实现相同功能请使用./yyas -r -np</li>\n</ul>\n</li>\n<li>CPU部分<ul>\n<li>Controller.cpp 为CPU的控制器，主要包含了流水线的控制逻辑</li>\n<li>Device.cpp 为CPU流水线的核心，包含了FDEMW五个阶段的运行逻辑</li>\n<li>Output.cpp 有一些用于输出的函数，用于Stage1输出至命令行或Stage2输出至json文件</li>\n<li>Util.cpp包含了一些辅助的函数，例如In函数和Format函数（这里用了很多modern cpp的魔法）</li>\n</ul>\n</li>\n</ul>\n<hr>\n<div style=\"page-break-after: always;\"></div>\n\n<h2 id=\"四、-实现细节\"><a href=\"#四、-实现细节\" class=\"headerlink\" title=\"四、 实现细节\"></a>四、 实现细节</h2><h4 id=\"前端细节\"><a href=\"#前端细节\" class=\"headerlink\" title=\"前端细节\"></a>前端细节</h4><p>前端搭建了 anywhere 服务器 (用于解决跨域问题, 踩坑经历可以看第五节)，主要函数在 main.js 文件中， 通过各类声明周期函数和写的 handle 来处理上传，运行，停止，重置，以及断点设置等功能，此处不展开细讲，主要是后端。</p>\n<p>（前端使用了 anywhere 服务器 + 中端 flask 服务器的双服务器架构，其主要是因为我们前端在 import 模块时不开本地服务器会产生跨域问题。对于跨域问题我们最开始遇到是在获取 data.json 的时候，踩坑过程中我们曾尝试通过jsonp 解决跨域问题，并且成功了，但在 import 模块时再次遇到了跨域问题，为了一劳永逸，我们直接使用了 anywhere 直接开了一个本地服。）</p>\n<h4 id=\"后端细节\"><a href=\"#后端细节\" class=\"headerlink\" title=\"后端细节\"></a>后端细节</h4><ol>\n<li><p><strong>关于流水线</strong>：为了尽可能的靠近实际的硬件架构，我们的CPU核心实现分成了<strong>wire</strong>和<strong>reg</strong>两种struct，用来模拟verilog硬件语言中的wire和reg，reg是实际存在的寄存器，而wire只是用于逻辑中转。为了模拟CPU的并行化，我们采用了如下的逻辑</p>\n<ol>\n<li>利用Reg中的数据计算F D E M W，写入wire变量（实际不存在）</li>\n<li>利用现在的wire上的值，更新流水线及其他状态</li>\n<li>将wire的值写入下一个Reg，例如f_wire写入D_Reg，当流水线状态为NORMAL时回到a</li>\n</ol>\n</li>\n<li><p>每个阶段的具体实现逻辑， 与CSAPP上的电路实现差别不大，此处不再赘述</p>\n</li>\n<li><p><strong>关于扩展指令集</strong>：我们的指令集扩展见<strong>ISA.md</strong>，具体到流水线上只需少许修改各个阶段的逻辑，与官方设计思路差不太多，依次修改FDEMW就行。</p>\n</li>\n<li><p><strong>关于分支预测策略</strong>：我们的分支预测采用的是<strong>2比特溢出预测器</strong>，该预测器采用的逻辑如下图</p>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvG2q.png\" alt=\"预测器\"></p>\n<ol>\n<li>当JXX的信号不是Jmp时，更新上述的状态机</li>\n<li>若状态机信号为3或者2，则进行跳转</li>\n<li>若状态机信号为1或者0，则不进行跳转</li>\n</ol>\n<p>除此之外，我们也需要相应的改变分支错判的逻辑，需要加一个IfJump信号，当E阶段输出的信号与IfJump信号不同，说明分支预测错误，需要清空流水线。</p>\n<p>这样的分支预测器，据统计可以达到90%的正确率（<a href=\"https://en.wikipedia.org/wiki/Branch_predictor），在我们的测试中，一般情况下可以提升10%-30%的性能\">https://en.wikipedia.org/wiki/Branch_predictor），在我们的测试中，一般情况下可以提升10%-30%的性能</a></p>\n</li>\n<li><p><strong>关于复杂指令</strong>：在我们增加的指令中，有一些指令如mulq、divq和remq都是很耗时的指令，如果强行让他们在一个周期内完成，我们的CPU时钟频率就会非常低。因此我们假定这部分指令所需要的时间为其他指令最长耗时的10倍，在E阶段设置一个counter，建立一个递减的状态机，使用下面的控制逻辑</p>\n<ol>\n<li>如果指令属于上述复杂指令，将状态机置于10</li>\n<li>如果状态机不为0，则使F D阶段进入STALL阶段，E阶段继续计算，但阻断E到M的输入，状态机减1</li>\n<li>如果状态机为0，则流水线继续执行</li>\n</ol>\n<p>这样就可以实现维持较高CPU频率的同时，实现复杂指令。（即不会因为加了这个指令使其他指令的执行变慢）</p>\n</li>\n<li><p><strong>关于硬件栈</strong>：为了避免每次调用ret指令时两个时钟周期的浪费，我们采用了CSAPP上的硬件栈。在硬件上，硬件栈可以由多路选择器和多个寄存器构成，在这里我们简单的使用Stack实现（大小为0x20）。采用如下的控制逻辑：</p>\n<ol>\n<li>如果调用call指令，在栈没有满时，将地址载入硬件栈</li>\n<li>如果调用ret指令，在栈非空时，弹栈，将值读出</li>\n<li>在M阶段执行后，判断硬件栈的预测是否正确<ol>\n<li>若正确，则继续执行</li>\n<li>若不正确，则清空 F D E的流水线</li>\n</ol>\n</li>\n</ol>\n<p>使用硬件栈后，最差的情况即是与无硬件栈情况相同，最好情况在我们的测试中，可以增加30%+的性能。</p>\n</li>\n<li><p>关于指令不可写和非指令不可读保护：我们的汇编器会计算yo文件中，最后一个是指令的位置，在CPU运行时，会进行动态的判断</p>\n<ol>\n<li>在Fetch阶段读取不可读的位置，会产生INS错误</li>\n<li>在其他阶段写入不可写的位置，会产生ADR错误</li>\n</ol>\n</li>\n<li><p>关于宏定义：为了CPU的扩展性和兼容性，我们使用了宏定义来动态的开关某些特性，例如 <code>OUTPUT_JSON</code> 宏定义后即可输出 data_json 供前端使用。</p>\n</li>\n</ol>\n<h4 id=\"汇编器细节\"><a href=\"#汇编器细节\" class=\"headerlink\" title=\"汇编器细节\"></a>汇编器细节</h4><p>我们的汇编器采用了依次处理的方式，如下(Code Explains itself)</p>\n<pre><code class=\"hljs python\">lines = gen_list(lines) <span class=\"hljs-comment\">#解析关键词</span>\nlines = remove_single_line_annot(lines) <span class=\"hljs-comment\">#去除单行注释</span>\nlines = remove_multi_line_annot(lines) <span class=\"hljs-comment\">#去除多行注释</span>\nlines = detach_label(lines) <span class=\"hljs-comment\">#找到对应的label</span>\nlines_ref = copy.deepcopy(lines) <span class=\"hljs-comment\">#复制一份用于输出</span>\nmem = get_memaddr(lines) <span class=\"hljs-comment\">#找到内存对应的地址</span>\nlabels = get_def_label(lines) <span class=\"hljs-comment\">#处理.define</span>\nlines = replace_label(lines, mem, labels) <span class=\"hljs-comment\">#处理label</span>\nbyte_code = gen_byte_code(lines) <span class=\"hljs-comment\">#产生yo代码</span></code></pre>\n<h4 id=\"测试细节\"><a href=\"#测试细节\" class=\"headerlink\" title=\"测试细节\"></a>测试细节</h4><p>我们采用Google Test 和 Python Unitest来辅助我们进行我们的程序测试。其在我们项目文件的 test 文件夹下，我们通过 shell 脚本和 python 脚本将模拟器的输出进行处理，转换成 gtest 代码以便于我们进行测试。</p>\n<p>基本语句即为 <code>EXPECT_EQ(x, y)</code></p>\n<ul>\n<li>测试代码结构</li>\n</ul>\n<p><img src=\"/CsBlog/CsBlog/2021/01/06/ICS/ICS_PJ/测试代码架构.png\" alt></p>\n<p>使用 Google Test 我们能够清晰的看到测试点信息。</p>\n<ul>\n<li>普通 yo_test</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvZxP.png\" style=\"width:300px\"></p>\n<ul>\n<li>Hornor 测试</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvmKf.png\" style=\"width:300px\"></p>\n<ul>\n<li>附加测试</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvMVg.png\" style=\"width:400px\"></p>\n<hr>\n<div style=\"page-break-after: always;\"></div>\n\n\n<h3 id=\"五、特点和创新\"><a href=\"#五、特点和创新\" class=\"headerlink\" title=\"五、特点和创新\"></a>五、特点和创新</h3><ol>\n<li><p><strong>汇编器创新</strong>：我们兼容现有的所有ys文件的基础上，还添加了一些伪指令和语法</p>\n<ol>\n<li>不需要写逗号了：现在所有的ys指令操作数之间可以使用空格隔开</li>\n<li>mrmovq和rmmovq：现在不需要强制写括号，可以直接mov至常数地址（此时寄存器为RNONE，我们的CPU也做了相应的修改）如rmmovq %rax $800</li>\n<li>伪指令<ol>\n<li>.define 类似C语言的宏定义</li>\n<li>.string “mystring” 将后面的mystring转化为对应的ASCII码写入</li>\n<li>.byte .hword .word支持</li>\n</ol>\n</li>\n<li>能够生成yo文件和yoraw文件，生成的yo文件比官方的yo文件漂亮不少，完全对齐</li>\n<li>有完整的命令行参数</li>\n</ol>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">usage</span>: yyas [-h] [-o OUTFILE] [-r] [-np] [-v] sourcefile\n\n<span class=\"hljs-attribute\">yyas</span>: Assemble .ys file to .yo file or/and .yo file to raw byte file\n\npositional arguments:\n  sourcefile            The source file to be assembled\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -o OUTFILE, --output OUTFILE\n                        Assign the output file\n  -r, --raw             Generate raw byte file\n  -np, --noprefix       Do not generate prefix in raw output\n  -v, --version         show version</code></pre>\n</li>\n<li><p><strong>处理器创新</strong>（见具体实现）</p>\n<ol>\n<li>更好的分支预测器</li>\n<li>硬件栈</li>\n<li>几乎三倍的指令集支持（及其扩展含义）</li>\n<li>复杂指令集的多周期支持</li>\n</ol>\n</li>\n</ol>\n<hr>\n<h3 id=\"六、总结与回顾\"><a href=\"#六、总结与回顾\" class=\"headerlink\" title=\"六、总结与回顾\"></a>六、总结与回顾</h3><h4 id=\"PJ-心得总结及致谢\"><a href=\"#PJ-心得总结及致谢\" class=\"headerlink\" title=\"PJ 心得总结及致谢\"></a>PJ 心得总结及致谢</h4><p>本次 PJ 让我们更加深入的理解了现代流水线处理器的原理，各种硬件栈，扩展指令集的设计也拓展了我们的技术边缘，非常不错的体验。最后非常感谢助教和金老师一学期的辛苦工作。在很多方面帮助了我们，助教的 Lab 非常精彩有趣，金老师的课十分幽默风趣，非常感谢各位的付出。</p>\n"},{"title":"Malloc Lab 动态内存分配器","date":"2021-05-23T05:58:57.000Z","index_img":"/img/ICS_Lab1/top.jpg","_content":"\n# Malloc Lab \n\n​\t个人的实验报告，放上来给大家参考。\n\n​\tMalloc lab 需要我们编写一个类似 libc malloc 的动态内存分配器，其主要考察动态内存分配器的原理设计以及堆内存的结构组织，同时需要比较强的 DEBUG 能力。最后在不使用BST以及其他全局数据结构的情况下我的方法达到了 97/100 的分数\n\n[ZiYang-xie/Malloc_Lab: CMU Malloc Lab Repo (github.com)](https://github.com/ZiYang-xie/Malloc_Lab)\n\n## 一、空闲块组织结构\n\n​\t在结构设计上我采用了分离存储的显示链表形式来进行组织空闲块，在书上说明了分离存储的思想，但没有具体说明实现方法。在此我使用称为 **Segregated Free List** 的空闲块组织设计，即在堆的低地址分配数量等于 ```SEG_LEN``` 的指针，每个指针分别对应着一个大小类，指向正式堆块中的空闲块，相当于 ```SEG_LEN``` 个链表。\n\n![Segregated Free List](https://tva1.sinaimg.cn/large/008i3skNly1gquqskpijgj30ff07cdg2.jpg)\n\n​\t在我的代码设计中，我以2的幂次分割大小类，由于空闲块最小块大小为16 bytes （包括头尾标记以及前后指针）因此其设计为 {2^4 ~ 2^5} \\ {2^5 ~ 2^6} \\ {2^6 ~ 2^7} ...(类推)\n\n 为了区分某一空闲块应该被放置在哪个类中，我们需要一个 **get_index** 函数，正常设计也十分简单，即通过一个循环右移，计算位数。在这里我参考了 **Bit twiddling hacks** 著名位运算*奇技淫巧* 网站，采用了一个位运算的 log2 方式，其可以在 O(1) 的复杂度计算出 log2(x)\n\n```c\nstatic int get_index(size_t v) \n{\n    // 本质上是位运算的 log 2, O(1)复杂度\n    // 参考 'Bit twiddling hacks'\n    // Linking: https://graphics.stanford.edu/~seander/bithacks.html#IntegerLogLookup\n    \n    size_t r, shift;\n    r = (v > 0xFFFF)   << 4; v >>= r;\n    shift = (v > 0xFF) << 3; v >>= shift; r |= shift;\n    shift = (v > 0xF)  << 2; v >>= shift; r |= shift;\n    shift = (v > 0x3)  << 1; v >>= shift; r |= shift;\n                                          r |= (v >> 1);\n    // 从 2^4 开始 (空闲块最小 16 bytes)\n    int x = (int)r - 4;\n    if(x < 0) \n        x = 0;\n    if(x >= SEG_LEN) \n        x = SEG_LEN - 1;\n    return x;\n}\n```\n\n\n\n## 二、堆内存设计\n\n​\t在空闲块指针之上，分配正常的堆块，正常的堆块由**序言块** （一个已分配大小为8的块），以及**结尾块**（一个已分配大小为0的块）前后包围，这样可以很方便的检验边界情况，当后继块大小为0，那么便可判断其达到了结尾。之后便记录下全局的开始地址 ```global_list_start_ptr``` 即可\n\n```c\n/* 空闲块 */\nfor(i = 0; i < SEG_LEN; ++i)\n  PUT(heap_listp + i*WSIZE, NULL);\t            // 初始化空闲块大小类头指针\n\n/* 分配块 */\nPUT(heap_listp + (i+0)*WSIZE, PACK(DSIZE, ALLOCATED));  /* 序言块头部 */\nPUT(heap_listp + (i+1)*WSIZE, PACK(DSIZE, ALLOCATED));  /* 序言块尾部 */\nPUT(heap_listp + (i+2)*WSIZE, PACK(0, ALLOCATED));      /* 结尾块头部 */\n\nglobal_list_start_ptr = heap_listp;\nheap_listp += (i+1)*WSIZE; // 对齐到起始块有效载荷\n```\n\n\n\n## 三、具体设计\n\n​\t接下来以函数为单位详细介绍实现过程\n\n\t### mm_init 初始化堆\n\n​\t堆内存设计块节中以及包含大部分，mm_init 代码，在组织完堆初始化的指针之后就可以进行分配栈空间以一个初始化的空闲块，这涉及到了 extend_heap 函数\n\n```c\n/* 扩展空栈至 CHUNKSIZE bytes */\n    if(extend_heap(CHUNKSIZE) == NULL)\n        return -1;\n    return 0;\n```\n\n\n\n### extend_heap 堆扩展\n\n​\t对于堆扩展，我们调用 mm_sbrk 函数将lab中设计好的抽象 program breaker 上移扩展堆大小，其返回空闲块的头指针，我们设置好它的头尾标记，并通过 coalesce 函数在进行前后空闲块合并之后插入到空闲块链表中。\n\n```c\nstatic void *extend_heap(size_t asize)\n{\n    char *bp;\n    if((long)(bp = mem_sbrk(asize)) == -1)\n        return NULL;\n    \n    /* 初始化空闲块的头尾和结尾块的头部 */\n    PUT(HDRP(bp), PACK(asize, FREE));                /* 空闲块头部 */\n    PUT(FTRP(bp), PACK(asize, FREE));                /* 空闲块尾部 */\n    PUT(HDRP(NEXT_BLKP(bp)), PACK(0, ALLOCATED));    /* 结尾块头部 */\n\n    return coalesce(bp);\n}\n```\n\n\n\n### coalesce 合并块\n\n​\t合并块的模式包含四种情况，并且在我的设计模式中，在合并后将空闲块插入到空闲链表中去，形成一体化操作。\n\n- **Case1: 前后均不空闲**\n\n```c\nif(prev_alloc && next_alloc){                   /* 前后非空闲 */\n  insert_free_block(bp);\n  return bp;\n}\n```\n\n前后均不空闲的时候就直接插入当前空闲块，并返回bp\n\n- **Case2: 后空闲**\n\n```c\nelse if(prev_alloc && !next_alloc){             /* 后空闲 */\n  size += NEXT_BLKSZ(bp);\n  delete_free_block(NEXT_BLKP(bp));\n  PUT(HDRP(bp), PACK(size, FREE));\n  PUT(FTRP(bp), PACK(size, FREE));\n  PUT(PRED(bp), NULL);\n  PUT(SUCC(bp), NULL);\n}\n```\n\n​\t后空闲的时候就从空闲链表中删除后方空闲块，并把当前块的头部和后部块的尾部大小设计为扩展后大小 *( 由于 FTRP 中调用了 HDRP，所以先设计HDRP的size之后FTRP能够正确定位到尾部 )* 并且设置空闲块前驱后继指针为NULL做好清理。\n\n- **Case3:** 前空闲\n\n```c\nif(!prev_alloc && next_alloc) {            /* 前空闲 */\n  size += PREV_BLKSZ(bp);\n  delete_free_block(PREV_BLKP(bp));\n\n  PUT(FTRP(bp), PACK(size, FREE));\n  PUT(HDRP(PREV_BLKP(bp)), PACK(size, FREE));\n\n  bp = PREV_BLKP(bp);\n  PUT(PRED(bp), NULL);\n  PUT(SUCC(bp), NULL);\n}\n```\n\n​\t前空闲就从空闲链表中删除前方空闲块，并且注意分配的头部标记是前一块的头部标记，其余逻辑和 Case2类似\n\n- **Case4:** 前后均非空闲\n\n```c\nelse{\t/* 前后均空闲 */\n  size += NEXT_BLKSZ(bp) + PREV_BLKSZ(bp);\n  delete_free_block(PREV_BLKP(bp));\n  delete_free_block(NEXT_BLKP(bp));\n  PUT(HDRP(PREV_BLKP(bp)), PACK(size, FREE));\n  PUT(FTRP(NEXT_BLKP(bp)), PACK(size, FREE));\n  bp = PREV_BLKP(bp);\n  PUT(PRED(bp), NULL);\n  PUT(SUCC(bp), NULL);\n}\n```\n\n​\t前两种的结合，不多赘述\n\n\n\n### insert_free_block 插入空闲链表\n\n​\t插入空闲链表算是一个比较重要的函数，其关乎着空闲块的组织结构，在这里我采用的是**地址排序**的策略。\n\n```c\nstatic void insert_free_block(char *fbp)\n{\n    // 地址排序 - Address Order\n    void *succ = root;\n    \n    while(SUCC_BLKP(succ)){\n        succ = (char *)SUCC_BLKP(succ);\n        if((unsigned int)succ >= (unsigned int)fbp){\n            // 安装地址顺序插入空闲块\n            // PRED_BLKP(succ) <-> fbp <-> succ\n            char *tmp = succ;\n            succ = (char *)PRED_BLKP(succ);\n            PUT(SUCC(succ), fbp);\n            PUT(PRED(fbp), succ);\n            PUT(SUCC(fbp), tmp);\n            PUT(PRED(tmp), fbp);\n            #ifdef INDEBUG\n                printf(\"succ(PRE): %p \\t tmp(SUCC): %p \\t\", succ, tmp);\n                print_free_list(\"Insert\");\n            #endif\n            return;\n        }\n    }\n    \n    // Base Case & Last Case \n    // 当前大小类无空闲块 或者 在地址分配时当前空闲块地址最大被分配在最后\n    PUT(SUCC(succ), fbp);\n    PUT(PRED(fbp), succ);\n    PUT(SUCC(fbp), NULL);\n}\n```\n\n​\t首先获得目标块的 index，即属于二的几次幂，之后通过 ```global_list_start_ptr``` 加上 index 偏移定位到其属于的大小类链表的 root 指针，如果root指针有指向就进行地址顺序的排序，如果找到后部块地址大于插入块，就把该插入块插到上述块的前部。\n\n​\t如果root没有指向，即当前该大小类中没有空闲块，或者按地址序，该块地址大小最大则进行直接的分配在succ之后。\n\n\n\n### delete_free_block 删除空闲块\n\n​\t删除空闲块要注意，这里常见的bug是和 insert_free_block 一同出现的指针维护不良，导致删除不存在的块，或者访问 nullptr 的前后继以及指针越界问题。\n\n```c\nstatic void delete_free_block(char *fbp)\n{\n    // NORMAL: GOT A SUCCESSOR AND PREDECESSOR\n    if(SUCC_BLKP(fbp) && PRED_BLKP(fbp)){\n        PUT(SUCC(PRED_BLKP(fbp)), SUCC_BLKP(fbp));\n        PUT(PRED(SUCC_BLKP(fbp)), PRED_BLKP(fbp));\n    }\n    else if(PRED_BLKP(fbp)){ // LAST BLOCK\n        PUT(SUCC(PRED_BLKP(fbp)), NULL);\n    }\n\n    PUT(SUCC(fbp), NULL);\n    PUT(PRED(fbp), NULL);\n}\n```\n\n​\t正常情况是当前块是链表中间节点，重新连接好前后，把其从链表上脱离即可。如果是最后一个节点，就直接把前继节点的后继指针置为空。最后做好当前删除块的清理工作，把其前后继指针置为NULL\n\n\n\n### mm_malloc 分配空闲块\n\n​\tmm_malloc 是该lab中的主要函数，用于控制分配内存块的工作。\n\n```c\nvoid *mm_malloc(size_t size)\n{\n    size_t asize = align_size(size);    /* 调整后的块大小 */\n    size_t extendsize;                  /* 扩展堆大小 */\n    char *bp;\n\n    /* Trivial Case */\n    if(size == 0)\n        return NULL;\n\n    /* 寻找适配 */\n    if((bp = find_fit(asize, get_index(asize))) != NULL)\n        return place(bp, asize);\n\n    /* 未找到适配，分配更多堆空间 */\n    extendsize = MAX(asize, CHUNKSIZE);\n    if((bp = extend_heap(extendsize)) == NULL)\n        return NULL;\n\n    return place(bp, asize);\n}\n```\n\n​\t首先要做好分配大小的对齐，这里定义了一个util函数 align_size 用来对齐块大小。\n\n```c\nstatic size_t align_size(size_t size)\n{\n    /* 调整块大小 */\n    if(size <= DSIZE) return 2*DSIZE;\n    else return DSIZE * ((size + (DSIZE) + (DSIZE - 1)) / DSIZE);\n\n    // Code Never Went Here\n    return 0;\n}\n```\n\n​\t之后逻辑就是通过 find_fit 在空闲链表中寻找适配，如果没找到适配就进行 heap_extend，每次最小扩展 ```CHUNKSIZE``` bytes，这里我将 ```CHUNKSIZE``` 设为 512\n\n **(有讲究，如果大于520就会导致realloc2的第一次分配 512 就能够成功，这样之后alloc的块就跟在512块后，就不能成功的将 realloc 的 0 号 block 安排在块位，导致无法通过 extend_heap 来提高性能)**\n\n最后放置空闲块，使用place函数进行分配和分割\n\n\n\n### find_fit 寻找适配\n\n​\t我使用的是简单的首次适配，即从小到大遍历分离空闲链表，找到第一块适合的空闲块。由于每个空闲链表内部是按地址顺序排列而非大小排列，所以其效果并非严格等同于 best_fit 但是由于大小分块的组织结构，其效果又好于完全不按空间大小排序的适配方式。\n\n```c\nstatic void *find_fit(size_t size, int seg_idx)\n{\n    // First Fit\n    char* res;\n    while(seg_idx < SEG_LEN){\n        char *root = global_list_start_ptr + seg_idx * WSIZE;\n        char *bp = (char *)SUCC_BLKP(root);\n        while(bp){\n            if((size_t)CRT_BLKSZ(bp) >= size)\n                return bp;\n            \n            bp = (char *)SUCC_BLKP(bp);\n        }\n        // 在这类中未找到适合，在更大类中寻找\n        seg_idx++;\n    }\n    return NULL;\n}\n```\n\n\n\n### place 分配块\n\n​\t分配块这里有说法了，第一层是分配空闲块的时候，如果当前适配的块大小比需要分配的大很多（超出最小空闲块大小 16bytes）那么我们就可以通过分割来减小内部碎片。\n\n​\t并且这个分割也是很有讲究，我们可以设计当需要分配的空间较大时例如大于64 bytes，我们就将其分配在空闲块的后部，将前部分割出来作为新的空闲块。如果小于就直接分配在当前空闲块的前部，将后部分割出来作为新的空闲块。这样的组织方式有两方面好处，\n\n- 一方面是其进行了大小分类，有利于块的合并\n- 另一方面是对于 realloc2 的测试 trace，我们通过前部切分的方式，使 512 块后再次分配的两 128 块占用前部空间，这样可以使 512 块始终是最后一块即其后继块是结尾块，那么在 realloc 它的时候我们就可以直接通过 extend_heap 达到如此一来可以大大提高内存利用率，**将realloc1、2的util提升至近100%！**\n\n```c\nstatic void *place(char *bp, size_t asize)\n{\n    size_t blk_size = CRT_BLKSZ(bp);\n    size_t rm_size = blk_size - asize;\n\n    if(!GET_ALLOC(HDRP(bp)))\n        delete_free_block(bp);\n    // 剩余空间大于最小块大小的可分割的情况\n    if(rm_size >= 2*DSIZE){\n        // 当块大小大于 64 时将其有效载荷放在空闲块后部，前部切分出来作为空闲块\n        if(asize > 64){\n            PUT(HDRP(bp), PACK(rm_size, FREE));\n            PUT(FTRP(bp), PACK(rm_size, FREE));\n            PUT(HDRP(NEXT_BLKP(bp)), PACK(asize, ALLOCATED));\n            PUT(FTRP(NEXT_BLKP(bp)), PACK(asize, ALLOCATED));\n            coalesce(bp);\n            return NEXT_BLKP(bp);\n        }\n        else{\n            PUT(HDRP(bp), PACK(asize, ALLOCATED));\n            PUT(FTRP(bp), PACK(asize, ALLOCATED));\n            PUT(HDRP(NEXT_BLKP(bp)), PACK(rm_size, FREE));\n            PUT(FTRP(NEXT_BLKP(bp)), PACK(rm_size, FREE));\n\n            coalesce(NEXT_BLKP(bp));\n        }\n    }\n    // 不可分割情况\n    else{\n        PUT(HDRP(bp), PACK(blk_size, ALLOCATED));\n        PUT(FTRP(bp), PACK(blk_size, ALLOCATED));\n    }\n    return bp;\n}\n```\n\n\n\n### mm_free 释放块\n\n​\t直接设置空闲，并释放同时合并，没什么好说的\n\n```c\nvoid mm_free(void *ptr)\n{\n    #ifdef DEBUG\n        printf(\"Freeing.....\\n\");\n    #endif\n    char *bp = ptr;\n    size_t size = CRT_BLKSZ(bp);\n\n    PUT(HDRP(bp), PACK(size, FREE));\n    PUT(FTRP(bp), PACK(size, FREE));\n    coalesce(bp);\n}\n```\n\n\n\n### mm_realloc 重分配块\n\n​\tmm_realloc 能否做好是分数能否上 90 的关键，其主要策略有两个\n\n- **空闲块融合**\n\n  一在重分配的时候，如果后方有空闲块可以进行融合，再看空间够不够，如果够了就不用释放再分配了。\n\n  （同时前融合也应当有相应的效果，前融合要注意内部载荷数据的移动，但其实观察 trace 文件下的block组织表现，发现其实前融合很少甚至没有，对性能影响不大，之后便在代码中删除了）\n\n- **尾部堆扩展**\n\n  就是之前提到的如果要重分配的块是尾部块就执行 extend_heap 就行了，不需要释放再分配。同时注意到了 trace 文件中反复 realloc 首次分配的块，于是和 place 中提到的策略相互结合可以达到将首次分配的块移动到末尾的效果。\n\n其余就是一些基础写法，在注释中已经体现，还有需要注意一下**分配大小的对齐**和特殊情况\n\n```c\nvoid *mm_realloc(void *ptr, size_t size)\n{\n    // 如果 ptr == NULL 直接分配\n    if(ptr == NULL)    \n        return mm_malloc(size);\n    // 如果 size == 0 就释放\n    else if(size == 0){\n        mm_free(ptr);\n        return NULL;\n    }\n    size_t asize = align_size(size), old_size = CRT_BLKSZ(ptr);\n    size_t mv_size = MIN(asize, old_size);\n    char *oldptr = ptr;\n    char *newptr;\n\n    if(old_size == asize)\n        return ptr;\n    \n    size_t prev_alloc =  GET_ALLOC(FTRP(PREV_BLKP(ptr)));\n    size_t next_alloc =  GET_ALLOC(HDRP(NEXT_BLKP(ptr)));\n    size_t next_size = NEXT_BLKSZ(ptr);\n    char *next_bp = NEXT_BLKP(ptr);\n    size_t total_size = old_size;\n\n    if(prev_alloc && !next_alloc && (old_size + next_size >= asize)){    // 后空闲  \n        total_size += next_size;\n        delete_free_block(next_bp);\n        PUT(HDRP(ptr), PACK(total_size, ALLOCATED));\n        PUT(FTRP(ptr), PACK(total_size, ALLOCATED));\n        place(ptr, total_size);\n    }\n    else if(!next_size && asize >= old_size){   // 如果后部是结尾块，则直接 extend_heap\n        size_t extend_size = asize - old_size;\n        if((long)(mem_sbrk(extend_size)) == -1)\n            return NULL; \n        \n        PUT(HDRP(ptr), PACK(total_size + extend_size, ALLOCATED));\n        PUT(FTRP(ptr), PACK(total_size + extend_size, ALLOCATED));\n        PUT(HDRP(NEXT_BLKP(ptr)), PACK(0, ALLOCATED)); \n        place(ptr, asize);\n    }\n    else{   // 直接分配\n        newptr = mm_malloc(asize);\n        if(newptr == NULL)\n            return NULL;\n        memcpy(newptr, ptr, MIN(old_size, size));\n        mm_free(ptr);\n        return newptr;\n    }\n    return ptr;\n}\n```\n\n\n\n## 关于DEBUG\n\n​\t代码中为了 DEBUG 定义了大量 debug util 函数和 Error Handler，如果想清晰的看清楚堆块的组织结构，调用它们是很有帮助的。还有 debug 要善用 gdb...\n\n\n\n## 四、实验结果\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gqqcdfltwxj309s088aal.jpg)\n\n​\t在不使用BST和全局数据结构的情况下达到了 97/100 的分数，还不错。\n\n\n\n## 五、结语\n\n​\t这个Lab用了我2、3天的时间，是比较难的，需要用心 DEBUG 考验 gdb的使用。Malloc Lab 还是很好玩的，ddl之后我可能会考虑进一步优化，采用BST结构尽量做到接近 100/100\n","source":"_posts/ICS/MallocLab.md","raw":"---\ntitle: Malloc Lab 动态内存分配器\ndate: 2021-05-22 22:58:57\nindex_img: /img/ICS_Lab1/top.jpg\ncategory: [ICS]\ntags: [Malloc, VM]\n---\n\n# Malloc Lab \n\n​\t个人的实验报告，放上来给大家参考。\n\n​\tMalloc lab 需要我们编写一个类似 libc malloc 的动态内存分配器，其主要考察动态内存分配器的原理设计以及堆内存的结构组织，同时需要比较强的 DEBUG 能力。最后在不使用BST以及其他全局数据结构的情况下我的方法达到了 97/100 的分数\n\n[ZiYang-xie/Malloc_Lab: CMU Malloc Lab Repo (github.com)](https://github.com/ZiYang-xie/Malloc_Lab)\n\n## 一、空闲块组织结构\n\n​\t在结构设计上我采用了分离存储的显示链表形式来进行组织空闲块，在书上说明了分离存储的思想，但没有具体说明实现方法。在此我使用称为 **Segregated Free List** 的空闲块组织设计，即在堆的低地址分配数量等于 ```SEG_LEN``` 的指针，每个指针分别对应着一个大小类，指向正式堆块中的空闲块，相当于 ```SEG_LEN``` 个链表。\n\n![Segregated Free List](https://tva1.sinaimg.cn/large/008i3skNly1gquqskpijgj30ff07cdg2.jpg)\n\n​\t在我的代码设计中，我以2的幂次分割大小类，由于空闲块最小块大小为16 bytes （包括头尾标记以及前后指针）因此其设计为 {2^4 ~ 2^5} \\ {2^5 ~ 2^6} \\ {2^6 ~ 2^7} ...(类推)\n\n 为了区分某一空闲块应该被放置在哪个类中，我们需要一个 **get_index** 函数，正常设计也十分简单，即通过一个循环右移，计算位数。在这里我参考了 **Bit twiddling hacks** 著名位运算*奇技淫巧* 网站，采用了一个位运算的 log2 方式，其可以在 O(1) 的复杂度计算出 log2(x)\n\n```c\nstatic int get_index(size_t v) \n{\n    // 本质上是位运算的 log 2, O(1)复杂度\n    // 参考 'Bit twiddling hacks'\n    // Linking: https://graphics.stanford.edu/~seander/bithacks.html#IntegerLogLookup\n    \n    size_t r, shift;\n    r = (v > 0xFFFF)   << 4; v >>= r;\n    shift = (v > 0xFF) << 3; v >>= shift; r |= shift;\n    shift = (v > 0xF)  << 2; v >>= shift; r |= shift;\n    shift = (v > 0x3)  << 1; v >>= shift; r |= shift;\n                                          r |= (v >> 1);\n    // 从 2^4 开始 (空闲块最小 16 bytes)\n    int x = (int)r - 4;\n    if(x < 0) \n        x = 0;\n    if(x >= SEG_LEN) \n        x = SEG_LEN - 1;\n    return x;\n}\n```\n\n\n\n## 二、堆内存设计\n\n​\t在空闲块指针之上，分配正常的堆块，正常的堆块由**序言块** （一个已分配大小为8的块），以及**结尾块**（一个已分配大小为0的块）前后包围，这样可以很方便的检验边界情况，当后继块大小为0，那么便可判断其达到了结尾。之后便记录下全局的开始地址 ```global_list_start_ptr``` 即可\n\n```c\n/* 空闲块 */\nfor(i = 0; i < SEG_LEN; ++i)\n  PUT(heap_listp + i*WSIZE, NULL);\t            // 初始化空闲块大小类头指针\n\n/* 分配块 */\nPUT(heap_listp + (i+0)*WSIZE, PACK(DSIZE, ALLOCATED));  /* 序言块头部 */\nPUT(heap_listp + (i+1)*WSIZE, PACK(DSIZE, ALLOCATED));  /* 序言块尾部 */\nPUT(heap_listp + (i+2)*WSIZE, PACK(0, ALLOCATED));      /* 结尾块头部 */\n\nglobal_list_start_ptr = heap_listp;\nheap_listp += (i+1)*WSIZE; // 对齐到起始块有效载荷\n```\n\n\n\n## 三、具体设计\n\n​\t接下来以函数为单位详细介绍实现过程\n\n\t### mm_init 初始化堆\n\n​\t堆内存设计块节中以及包含大部分，mm_init 代码，在组织完堆初始化的指针之后就可以进行分配栈空间以一个初始化的空闲块，这涉及到了 extend_heap 函数\n\n```c\n/* 扩展空栈至 CHUNKSIZE bytes */\n    if(extend_heap(CHUNKSIZE) == NULL)\n        return -1;\n    return 0;\n```\n\n\n\n### extend_heap 堆扩展\n\n​\t对于堆扩展，我们调用 mm_sbrk 函数将lab中设计好的抽象 program breaker 上移扩展堆大小，其返回空闲块的头指针，我们设置好它的头尾标记，并通过 coalesce 函数在进行前后空闲块合并之后插入到空闲块链表中。\n\n```c\nstatic void *extend_heap(size_t asize)\n{\n    char *bp;\n    if((long)(bp = mem_sbrk(asize)) == -1)\n        return NULL;\n    \n    /* 初始化空闲块的头尾和结尾块的头部 */\n    PUT(HDRP(bp), PACK(asize, FREE));                /* 空闲块头部 */\n    PUT(FTRP(bp), PACK(asize, FREE));                /* 空闲块尾部 */\n    PUT(HDRP(NEXT_BLKP(bp)), PACK(0, ALLOCATED));    /* 结尾块头部 */\n\n    return coalesce(bp);\n}\n```\n\n\n\n### coalesce 合并块\n\n​\t合并块的模式包含四种情况，并且在我的设计模式中，在合并后将空闲块插入到空闲链表中去，形成一体化操作。\n\n- **Case1: 前后均不空闲**\n\n```c\nif(prev_alloc && next_alloc){                   /* 前后非空闲 */\n  insert_free_block(bp);\n  return bp;\n}\n```\n\n前后均不空闲的时候就直接插入当前空闲块，并返回bp\n\n- **Case2: 后空闲**\n\n```c\nelse if(prev_alloc && !next_alloc){             /* 后空闲 */\n  size += NEXT_BLKSZ(bp);\n  delete_free_block(NEXT_BLKP(bp));\n  PUT(HDRP(bp), PACK(size, FREE));\n  PUT(FTRP(bp), PACK(size, FREE));\n  PUT(PRED(bp), NULL);\n  PUT(SUCC(bp), NULL);\n}\n```\n\n​\t后空闲的时候就从空闲链表中删除后方空闲块，并把当前块的头部和后部块的尾部大小设计为扩展后大小 *( 由于 FTRP 中调用了 HDRP，所以先设计HDRP的size之后FTRP能够正确定位到尾部 )* 并且设置空闲块前驱后继指针为NULL做好清理。\n\n- **Case3:** 前空闲\n\n```c\nif(!prev_alloc && next_alloc) {            /* 前空闲 */\n  size += PREV_BLKSZ(bp);\n  delete_free_block(PREV_BLKP(bp));\n\n  PUT(FTRP(bp), PACK(size, FREE));\n  PUT(HDRP(PREV_BLKP(bp)), PACK(size, FREE));\n\n  bp = PREV_BLKP(bp);\n  PUT(PRED(bp), NULL);\n  PUT(SUCC(bp), NULL);\n}\n```\n\n​\t前空闲就从空闲链表中删除前方空闲块，并且注意分配的头部标记是前一块的头部标记，其余逻辑和 Case2类似\n\n- **Case4:** 前后均非空闲\n\n```c\nelse{\t/* 前后均空闲 */\n  size += NEXT_BLKSZ(bp) + PREV_BLKSZ(bp);\n  delete_free_block(PREV_BLKP(bp));\n  delete_free_block(NEXT_BLKP(bp));\n  PUT(HDRP(PREV_BLKP(bp)), PACK(size, FREE));\n  PUT(FTRP(NEXT_BLKP(bp)), PACK(size, FREE));\n  bp = PREV_BLKP(bp);\n  PUT(PRED(bp), NULL);\n  PUT(SUCC(bp), NULL);\n}\n```\n\n​\t前两种的结合，不多赘述\n\n\n\n### insert_free_block 插入空闲链表\n\n​\t插入空闲链表算是一个比较重要的函数，其关乎着空闲块的组织结构，在这里我采用的是**地址排序**的策略。\n\n```c\nstatic void insert_free_block(char *fbp)\n{\n    // 地址排序 - Address Order\n    void *succ = root;\n    \n    while(SUCC_BLKP(succ)){\n        succ = (char *)SUCC_BLKP(succ);\n        if((unsigned int)succ >= (unsigned int)fbp){\n            // 安装地址顺序插入空闲块\n            // PRED_BLKP(succ) <-> fbp <-> succ\n            char *tmp = succ;\n            succ = (char *)PRED_BLKP(succ);\n            PUT(SUCC(succ), fbp);\n            PUT(PRED(fbp), succ);\n            PUT(SUCC(fbp), tmp);\n            PUT(PRED(tmp), fbp);\n            #ifdef INDEBUG\n                printf(\"succ(PRE): %p \\t tmp(SUCC): %p \\t\", succ, tmp);\n                print_free_list(\"Insert\");\n            #endif\n            return;\n        }\n    }\n    \n    // Base Case & Last Case \n    // 当前大小类无空闲块 或者 在地址分配时当前空闲块地址最大被分配在最后\n    PUT(SUCC(succ), fbp);\n    PUT(PRED(fbp), succ);\n    PUT(SUCC(fbp), NULL);\n}\n```\n\n​\t首先获得目标块的 index，即属于二的几次幂，之后通过 ```global_list_start_ptr``` 加上 index 偏移定位到其属于的大小类链表的 root 指针，如果root指针有指向就进行地址顺序的排序，如果找到后部块地址大于插入块，就把该插入块插到上述块的前部。\n\n​\t如果root没有指向，即当前该大小类中没有空闲块，或者按地址序，该块地址大小最大则进行直接的分配在succ之后。\n\n\n\n### delete_free_block 删除空闲块\n\n​\t删除空闲块要注意，这里常见的bug是和 insert_free_block 一同出现的指针维护不良，导致删除不存在的块，或者访问 nullptr 的前后继以及指针越界问题。\n\n```c\nstatic void delete_free_block(char *fbp)\n{\n    // NORMAL: GOT A SUCCESSOR AND PREDECESSOR\n    if(SUCC_BLKP(fbp) && PRED_BLKP(fbp)){\n        PUT(SUCC(PRED_BLKP(fbp)), SUCC_BLKP(fbp));\n        PUT(PRED(SUCC_BLKP(fbp)), PRED_BLKP(fbp));\n    }\n    else if(PRED_BLKP(fbp)){ // LAST BLOCK\n        PUT(SUCC(PRED_BLKP(fbp)), NULL);\n    }\n\n    PUT(SUCC(fbp), NULL);\n    PUT(PRED(fbp), NULL);\n}\n```\n\n​\t正常情况是当前块是链表中间节点，重新连接好前后，把其从链表上脱离即可。如果是最后一个节点，就直接把前继节点的后继指针置为空。最后做好当前删除块的清理工作，把其前后继指针置为NULL\n\n\n\n### mm_malloc 分配空闲块\n\n​\tmm_malloc 是该lab中的主要函数，用于控制分配内存块的工作。\n\n```c\nvoid *mm_malloc(size_t size)\n{\n    size_t asize = align_size(size);    /* 调整后的块大小 */\n    size_t extendsize;                  /* 扩展堆大小 */\n    char *bp;\n\n    /* Trivial Case */\n    if(size == 0)\n        return NULL;\n\n    /* 寻找适配 */\n    if((bp = find_fit(asize, get_index(asize))) != NULL)\n        return place(bp, asize);\n\n    /* 未找到适配，分配更多堆空间 */\n    extendsize = MAX(asize, CHUNKSIZE);\n    if((bp = extend_heap(extendsize)) == NULL)\n        return NULL;\n\n    return place(bp, asize);\n}\n```\n\n​\t首先要做好分配大小的对齐，这里定义了一个util函数 align_size 用来对齐块大小。\n\n```c\nstatic size_t align_size(size_t size)\n{\n    /* 调整块大小 */\n    if(size <= DSIZE) return 2*DSIZE;\n    else return DSIZE * ((size + (DSIZE) + (DSIZE - 1)) / DSIZE);\n\n    // Code Never Went Here\n    return 0;\n}\n```\n\n​\t之后逻辑就是通过 find_fit 在空闲链表中寻找适配，如果没找到适配就进行 heap_extend，每次最小扩展 ```CHUNKSIZE``` bytes，这里我将 ```CHUNKSIZE``` 设为 512\n\n **(有讲究，如果大于520就会导致realloc2的第一次分配 512 就能够成功，这样之后alloc的块就跟在512块后，就不能成功的将 realloc 的 0 号 block 安排在块位，导致无法通过 extend_heap 来提高性能)**\n\n最后放置空闲块，使用place函数进行分配和分割\n\n\n\n### find_fit 寻找适配\n\n​\t我使用的是简单的首次适配，即从小到大遍历分离空闲链表，找到第一块适合的空闲块。由于每个空闲链表内部是按地址顺序排列而非大小排列，所以其效果并非严格等同于 best_fit 但是由于大小分块的组织结构，其效果又好于完全不按空间大小排序的适配方式。\n\n```c\nstatic void *find_fit(size_t size, int seg_idx)\n{\n    // First Fit\n    char* res;\n    while(seg_idx < SEG_LEN){\n        char *root = global_list_start_ptr + seg_idx * WSIZE;\n        char *bp = (char *)SUCC_BLKP(root);\n        while(bp){\n            if((size_t)CRT_BLKSZ(bp) >= size)\n                return bp;\n            \n            bp = (char *)SUCC_BLKP(bp);\n        }\n        // 在这类中未找到适合，在更大类中寻找\n        seg_idx++;\n    }\n    return NULL;\n}\n```\n\n\n\n### place 分配块\n\n​\t分配块这里有说法了，第一层是分配空闲块的时候，如果当前适配的块大小比需要分配的大很多（超出最小空闲块大小 16bytes）那么我们就可以通过分割来减小内部碎片。\n\n​\t并且这个分割也是很有讲究，我们可以设计当需要分配的空间较大时例如大于64 bytes，我们就将其分配在空闲块的后部，将前部分割出来作为新的空闲块。如果小于就直接分配在当前空闲块的前部，将后部分割出来作为新的空闲块。这样的组织方式有两方面好处，\n\n- 一方面是其进行了大小分类，有利于块的合并\n- 另一方面是对于 realloc2 的测试 trace，我们通过前部切分的方式，使 512 块后再次分配的两 128 块占用前部空间，这样可以使 512 块始终是最后一块即其后继块是结尾块，那么在 realloc 它的时候我们就可以直接通过 extend_heap 达到如此一来可以大大提高内存利用率，**将realloc1、2的util提升至近100%！**\n\n```c\nstatic void *place(char *bp, size_t asize)\n{\n    size_t blk_size = CRT_BLKSZ(bp);\n    size_t rm_size = blk_size - asize;\n\n    if(!GET_ALLOC(HDRP(bp)))\n        delete_free_block(bp);\n    // 剩余空间大于最小块大小的可分割的情况\n    if(rm_size >= 2*DSIZE){\n        // 当块大小大于 64 时将其有效载荷放在空闲块后部，前部切分出来作为空闲块\n        if(asize > 64){\n            PUT(HDRP(bp), PACK(rm_size, FREE));\n            PUT(FTRP(bp), PACK(rm_size, FREE));\n            PUT(HDRP(NEXT_BLKP(bp)), PACK(asize, ALLOCATED));\n            PUT(FTRP(NEXT_BLKP(bp)), PACK(asize, ALLOCATED));\n            coalesce(bp);\n            return NEXT_BLKP(bp);\n        }\n        else{\n            PUT(HDRP(bp), PACK(asize, ALLOCATED));\n            PUT(FTRP(bp), PACK(asize, ALLOCATED));\n            PUT(HDRP(NEXT_BLKP(bp)), PACK(rm_size, FREE));\n            PUT(FTRP(NEXT_BLKP(bp)), PACK(rm_size, FREE));\n\n            coalesce(NEXT_BLKP(bp));\n        }\n    }\n    // 不可分割情况\n    else{\n        PUT(HDRP(bp), PACK(blk_size, ALLOCATED));\n        PUT(FTRP(bp), PACK(blk_size, ALLOCATED));\n    }\n    return bp;\n}\n```\n\n\n\n### mm_free 释放块\n\n​\t直接设置空闲，并释放同时合并，没什么好说的\n\n```c\nvoid mm_free(void *ptr)\n{\n    #ifdef DEBUG\n        printf(\"Freeing.....\\n\");\n    #endif\n    char *bp = ptr;\n    size_t size = CRT_BLKSZ(bp);\n\n    PUT(HDRP(bp), PACK(size, FREE));\n    PUT(FTRP(bp), PACK(size, FREE));\n    coalesce(bp);\n}\n```\n\n\n\n### mm_realloc 重分配块\n\n​\tmm_realloc 能否做好是分数能否上 90 的关键，其主要策略有两个\n\n- **空闲块融合**\n\n  一在重分配的时候，如果后方有空闲块可以进行融合，再看空间够不够，如果够了就不用释放再分配了。\n\n  （同时前融合也应当有相应的效果，前融合要注意内部载荷数据的移动，但其实观察 trace 文件下的block组织表现，发现其实前融合很少甚至没有，对性能影响不大，之后便在代码中删除了）\n\n- **尾部堆扩展**\n\n  就是之前提到的如果要重分配的块是尾部块就执行 extend_heap 就行了，不需要释放再分配。同时注意到了 trace 文件中反复 realloc 首次分配的块，于是和 place 中提到的策略相互结合可以达到将首次分配的块移动到末尾的效果。\n\n其余就是一些基础写法，在注释中已经体现，还有需要注意一下**分配大小的对齐**和特殊情况\n\n```c\nvoid *mm_realloc(void *ptr, size_t size)\n{\n    // 如果 ptr == NULL 直接分配\n    if(ptr == NULL)    \n        return mm_malloc(size);\n    // 如果 size == 0 就释放\n    else if(size == 0){\n        mm_free(ptr);\n        return NULL;\n    }\n    size_t asize = align_size(size), old_size = CRT_BLKSZ(ptr);\n    size_t mv_size = MIN(asize, old_size);\n    char *oldptr = ptr;\n    char *newptr;\n\n    if(old_size == asize)\n        return ptr;\n    \n    size_t prev_alloc =  GET_ALLOC(FTRP(PREV_BLKP(ptr)));\n    size_t next_alloc =  GET_ALLOC(HDRP(NEXT_BLKP(ptr)));\n    size_t next_size = NEXT_BLKSZ(ptr);\n    char *next_bp = NEXT_BLKP(ptr);\n    size_t total_size = old_size;\n\n    if(prev_alloc && !next_alloc && (old_size + next_size >= asize)){    // 后空闲  \n        total_size += next_size;\n        delete_free_block(next_bp);\n        PUT(HDRP(ptr), PACK(total_size, ALLOCATED));\n        PUT(FTRP(ptr), PACK(total_size, ALLOCATED));\n        place(ptr, total_size);\n    }\n    else if(!next_size && asize >= old_size){   // 如果后部是结尾块，则直接 extend_heap\n        size_t extend_size = asize - old_size;\n        if((long)(mem_sbrk(extend_size)) == -1)\n            return NULL; \n        \n        PUT(HDRP(ptr), PACK(total_size + extend_size, ALLOCATED));\n        PUT(FTRP(ptr), PACK(total_size + extend_size, ALLOCATED));\n        PUT(HDRP(NEXT_BLKP(ptr)), PACK(0, ALLOCATED)); \n        place(ptr, asize);\n    }\n    else{   // 直接分配\n        newptr = mm_malloc(asize);\n        if(newptr == NULL)\n            return NULL;\n        memcpy(newptr, ptr, MIN(old_size, size));\n        mm_free(ptr);\n        return newptr;\n    }\n    return ptr;\n}\n```\n\n\n\n## 关于DEBUG\n\n​\t代码中为了 DEBUG 定义了大量 debug util 函数和 Error Handler，如果想清晰的看清楚堆块的组织结构，调用它们是很有帮助的。还有 debug 要善用 gdb...\n\n\n\n## 四、实验结果\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gqqcdfltwxj309s088aal.jpg)\n\n​\t在不使用BST和全局数据结构的情况下达到了 97/100 的分数，还不错。\n\n\n\n## 五、结语\n\n​\t这个Lab用了我2、3天的时间，是比较难的，需要用心 DEBUG 考验 gdb的使用。Malloc Lab 还是很好玩的，ddl之后我可能会考虑进一步优化，采用BST结构尽量做到接近 100/100\n","slug":"ICS/MallocLab","published":1,"updated":"2026-02-03T05:42:14.436Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvi00317uitff3qc72p","content":"<h1 id=\"Malloc-Lab\"><a href=\"#Malloc-Lab\" class=\"headerlink\" title=\"Malloc Lab\"></a>Malloc Lab</h1><p>​    个人的实验报告，放上来给大家参考。</p>\n<p>​    Malloc lab 需要我们编写一个类似 libc malloc 的动态内存分配器，其主要考察动态内存分配器的原理设计以及堆内存的结构组织，同时需要比较强的 DEBUG 能力。最后在不使用BST以及其他全局数据结构的情况下我的方法达到了 97/100 的分数</p>\n<p><a href=\"https://github.com/ZiYang-xie/Malloc_Lab\">ZiYang-xie/Malloc_Lab: CMU Malloc Lab Repo (github.com)</a></p>\n<h2 id=\"一、空闲块组织结构\"><a href=\"#一、空闲块组织结构\" class=\"headerlink\" title=\"一、空闲块组织结构\"></a>一、空闲块组织结构</h2><p>​    在结构设计上我采用了分离存储的显示链表形式来进行组织空闲块，在书上说明了分离存储的思想，但没有具体说明实现方法。在此我使用称为 <strong>Segregated Free List</strong> 的空闲块组织设计，即在堆的低地址分配数量等于 <code>SEG_LEN</code> 的指针，每个指针分别对应着一个大小类，指向正式堆块中的空闲块，相当于 <code>SEG_LEN</code> 个链表。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gquqskpijgj30ff07cdg2.jpg\" alt=\"Segregated Free List\"></p>\n<p>​    在我的代码设计中，我以2的幂次分割大小类，由于空闲块最小块大小为16 bytes （包括头尾标记以及前后指针）因此其设计为 {2^4 ~ 2^5} \\ {2^5 ~ 2^6} \\ {2^6 ~ 2^7} …(类推)</p>\n<p> 为了区分某一空闲块应该被放置在哪个类中，我们需要一个 <strong>get_index</strong> 函数，正常设计也十分简单，即通过一个循环右移，计算位数。在这里我参考了 <strong>Bit twiddling hacks</strong> 著名位运算<em>奇技淫巧</em> 网站，采用了一个位运算的 log2 方式，其可以在 O(1) 的复杂度计算出 log2(x)</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">get_index</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">size_t</span> v)</span> </span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-comment\">// 本质上是位运算的 log 2, O(1)复杂度</span>\n    <span class=\"hljs-comment\">// 参考 &#x27;Bit twiddling hacks&#x27;</span>\n    <span class=\"hljs-comment\">// Linking: https://graphics.stanford.edu/~seander/bithacks.html#IntegerLogLookup</span>\n    \n    <span class=\"hljs-keyword\">size_t</span> r, shift;\n    r = (v &gt; <span class=\"hljs-number\">0xFFFF</span>)   &lt;&lt; <span class=\"hljs-number\">4</span>; v &gt;&gt;= r;\n    shift = (v &gt; <span class=\"hljs-number\">0xFF</span>) &lt;&lt; <span class=\"hljs-number\">3</span>; v &gt;&gt;= shift; r |= shift;\n    shift = (v &gt; <span class=\"hljs-number\">0xF</span>)  &lt;&lt; <span class=\"hljs-number\">2</span>; v &gt;&gt;= shift; r |= shift;\n    shift = (v &gt; <span class=\"hljs-number\">0x3</span>)  &lt;&lt; <span class=\"hljs-number\">1</span>; v &gt;&gt;= shift; r |= shift;\n                                          r |= (v &gt;&gt; <span class=\"hljs-number\">1</span>);\n    <span class=\"hljs-comment\">// 从 2^4 开始 (空闲块最小 16 bytes)</span>\n    <span class=\"hljs-keyword\">int</span> x = (<span class=\"hljs-keyword\">int</span>)r - <span class=\"hljs-number\">4</span>;\n    <span class=\"hljs-keyword\">if</span>(x &lt; <span class=\"hljs-number\">0</span>) \n        x = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">if</span>(x &gt;= SEG_LEN) \n        x = SEG_LEN - <span class=\"hljs-number\">1</span>;\n    <span class=\"hljs-keyword\">return</span> x;\n&#125;</code></pre>\n<h2 id=\"二、堆内存设计\"><a href=\"#二、堆内存设计\" class=\"headerlink\" title=\"二、堆内存设计\"></a>二、堆内存设计</h2><p>​    在空闲块指针之上，分配正常的堆块，正常的堆块由<strong>序言块</strong> （一个已分配大小为8的块），以及<strong>结尾块</strong>（一个已分配大小为0的块）前后包围，这样可以很方便的检验边界情况，当后继块大小为0，那么便可判断其达到了结尾。之后便记录下全局的开始地址 <code>global_list_start_ptr</code> 即可</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">/* 空闲块 */</span>\n<span class=\"hljs-keyword\">for</span>(i = <span class=\"hljs-number\">0</span>; i &lt; SEG_LEN; ++i)\n  PUT(heap_listp + i*WSIZE, <span class=\"hljs-literal\">NULL</span>);\t            <span class=\"hljs-comment\">// 初始化空闲块大小类头指针</span>\n\n<span class=\"hljs-comment\">/* 分配块 */</span>\nPUT(heap_listp + (i+<span class=\"hljs-number\">0</span>)*WSIZE, PACK(DSIZE, ALLOCATED));  <span class=\"hljs-comment\">/* 序言块头部 */</span>\nPUT(heap_listp + (i+<span class=\"hljs-number\">1</span>)*WSIZE, PACK(DSIZE, ALLOCATED));  <span class=\"hljs-comment\">/* 序言块尾部 */</span>\nPUT(heap_listp + (i+<span class=\"hljs-number\">2</span>)*WSIZE, PACK(<span class=\"hljs-number\">0</span>, ALLOCATED));      <span class=\"hljs-comment\">/* 结尾块头部 */</span>\n\nglobal_list_start_ptr = heap_listp;\nheap_listp += (i+<span class=\"hljs-number\">1</span>)*WSIZE; <span class=\"hljs-comment\">// 对齐到起始块有效载荷</span></code></pre>\n<h2 id=\"三、具体设计\"><a href=\"#三、具体设计\" class=\"headerlink\" title=\"三、具体设计\"></a>三、具体设计</h2><p>​    接下来以函数为单位详细介绍实现过程</p>\n<pre><code>### mm_init 初始化堆\n</code></pre><p>​    堆内存设计块节中以及包含大部分，mm_init 代码，在组织完堆初始化的指针之后就可以进行分配栈空间以一个初始化的空闲块，这涉及到了 extend_heap 函数</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">/* 扩展空栈至 CHUNKSIZE bytes */</span>\n    <span class=\"hljs-keyword\">if</span>(extend_heap(CHUNKSIZE) == <span class=\"hljs-literal\">NULL</span>)\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">-1</span>;\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;</code></pre>\n<h3 id=\"extend-heap-堆扩展\"><a href=\"#extend-heap-堆扩展\" class=\"headerlink\" title=\"extend_heap 堆扩展\"></a>extend_heap 堆扩展</h3><p>​    对于堆扩展，我们调用 mm_sbrk 函数将lab中设计好的抽象 program breaker 上移扩展堆大小，其返回空闲块的头指针，我们设置好它的头尾标记，并通过 coalesce 函数在进行前后空闲块合并之后插入到空闲块链表中。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">void</span> *<span class=\"hljs-title\">extend_heap</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">size_t</span> asize)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">char</span> *bp;\n    <span class=\"hljs-keyword\">if</span>((<span class=\"hljs-keyword\">long</span>)(bp = mem_sbrk(asize)) == <span class=\"hljs-number\">-1</span>)\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">NULL</span>;\n    \n    <span class=\"hljs-comment\">/* 初始化空闲块的头尾和结尾块的头部 */</span>\n    PUT(HDRP(bp), PACK(asize, FREE));                <span class=\"hljs-comment\">/* 空闲块头部 */</span>\n    PUT(FTRP(bp), PACK(asize, FREE));                <span class=\"hljs-comment\">/* 空闲块尾部 */</span>\n    PUT(HDRP(NEXT_BLKP(bp)), PACK(<span class=\"hljs-number\">0</span>, ALLOCATED));    <span class=\"hljs-comment\">/* 结尾块头部 */</span>\n\n    <span class=\"hljs-keyword\">return</span> coalesce(bp);\n&#125;</code></pre>\n<h3 id=\"coalesce-合并块\"><a href=\"#coalesce-合并块\" class=\"headerlink\" title=\"coalesce 合并块\"></a>coalesce 合并块</h3><p>​    合并块的模式包含四种情况，并且在我的设计模式中，在合并后将空闲块插入到空闲链表中去，形成一体化操作。</p>\n<ul>\n<li><strong>Case1: 前后均不空闲</strong></li>\n</ul>\n<pre><code class=\"hljs c\"><span class=\"hljs-keyword\">if</span>(prev_alloc &amp;&amp; next_alloc)&#123;                   <span class=\"hljs-comment\">/* 前后非空闲 */</span>\n  insert_free_block(bp);\n  <span class=\"hljs-keyword\">return</span> bp;\n&#125;</code></pre>\n<p>前后均不空闲的时候就直接插入当前空闲块，并返回bp</p>\n<ul>\n<li><strong>Case2: 后空闲</strong></li>\n</ul>\n<pre><code class=\"hljs c\"><span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(prev_alloc &amp;&amp; !next_alloc)&#123;             <span class=\"hljs-comment\">/* 后空闲 */</span>\n  size += NEXT_BLKSZ(bp);\n  delete_free_block(NEXT_BLKP(bp));\n  PUT(HDRP(bp), PACK(size, FREE));\n  PUT(FTRP(bp), PACK(size, FREE));\n  PUT(PRED(bp), <span class=\"hljs-literal\">NULL</span>);\n  PUT(SUCC(bp), <span class=\"hljs-literal\">NULL</span>);\n&#125;</code></pre>\n<p>​    后空闲的时候就从空闲链表中删除后方空闲块，并把当前块的头部和后部块的尾部大小设计为扩展后大小 <em>( 由于 FTRP 中调用了 HDRP，所以先设计HDRP的size之后FTRP能够正确定位到尾部 )</em> 并且设置空闲块前驱后继指针为NULL做好清理。</p>\n<ul>\n<li><strong>Case3:</strong> 前空闲</li>\n</ul>\n<pre><code class=\"hljs c\"><span class=\"hljs-keyword\">if</span>(!prev_alloc &amp;&amp; next_alloc) &#123;            <span class=\"hljs-comment\">/* 前空闲 */</span>\n  size += PREV_BLKSZ(bp);\n  delete_free_block(PREV_BLKP(bp));\n\n  PUT(FTRP(bp), PACK(size, FREE));\n  PUT(HDRP(PREV_BLKP(bp)), PACK(size, FREE));\n\n  bp = PREV_BLKP(bp);\n  PUT(PRED(bp), <span class=\"hljs-literal\">NULL</span>);\n  PUT(SUCC(bp), <span class=\"hljs-literal\">NULL</span>);\n&#125;</code></pre>\n<p>​    前空闲就从空闲链表中删除前方空闲块，并且注意分配的头部标记是前一块的头部标记，其余逻辑和 Case2类似</p>\n<ul>\n<li><strong>Case4:</strong> 前后均非空闲</li>\n</ul>\n<pre><code class=\"hljs c\"><span class=\"hljs-keyword\">else</span>&#123;\t<span class=\"hljs-comment\">/* 前后均空闲 */</span>\n  size += NEXT_BLKSZ(bp) + PREV_BLKSZ(bp);\n  delete_free_block(PREV_BLKP(bp));\n  delete_free_block(NEXT_BLKP(bp));\n  PUT(HDRP(PREV_BLKP(bp)), PACK(size, FREE));\n  PUT(FTRP(NEXT_BLKP(bp)), PACK(size, FREE));\n  bp = PREV_BLKP(bp);\n  PUT(PRED(bp), <span class=\"hljs-literal\">NULL</span>);\n  PUT(SUCC(bp), <span class=\"hljs-literal\">NULL</span>);\n&#125;</code></pre>\n<p>​    前两种的结合，不多赘述</p>\n<h3 id=\"insert-free-block-插入空闲链表\"><a href=\"#insert-free-block-插入空闲链表\" class=\"headerlink\" title=\"insert_free_block 插入空闲链表\"></a>insert_free_block 插入空闲链表</h3><p>​    插入空闲链表算是一个比较重要的函数，其关乎着空闲块的组织结构，在这里我采用的是<strong>地址排序</strong>的策略。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">insert_free_block</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">char</span> *fbp)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-comment\">// 地址排序 - Address Order</span>\n    <span class=\"hljs-keyword\">void</span> *succ = root;\n    \n    <span class=\"hljs-keyword\">while</span>(SUCC_BLKP(succ))&#123;\n        succ = (<span class=\"hljs-keyword\">char</span> *)SUCC_BLKP(succ);\n        <span class=\"hljs-keyword\">if</span>((<span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">int</span>)succ &gt;= (<span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">int</span>)fbp)&#123;\n            <span class=\"hljs-comment\">// 安装地址顺序插入空闲块</span>\n            <span class=\"hljs-comment\">// PRED_BLKP(succ) &lt;-&gt; fbp &lt;-&gt; succ</span>\n            <span class=\"hljs-keyword\">char</span> *tmp = succ;\n            succ = (<span class=\"hljs-keyword\">char</span> *)PRED_BLKP(succ);\n            PUT(SUCC(succ), fbp);\n            PUT(PRED(fbp), succ);\n            PUT(SUCC(fbp), tmp);\n            PUT(PRED(tmp), fbp);\n            <span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">ifdef</span> INDEBUG</span>\n                <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;succ(PRE): %p \\t tmp(SUCC): %p \\t&quot;</span>, succ, tmp);\n                print_free_list(<span class=\"hljs-string\">&quot;Insert&quot;</span>);\n            <span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">endif</span></span>\n            <span class=\"hljs-keyword\">return</span>;\n        &#125;\n    &#125;\n    \n    <span class=\"hljs-comment\">// Base Case &amp; Last Case </span>\n    <span class=\"hljs-comment\">// 当前大小类无空闲块 或者 在地址分配时当前空闲块地址最大被分配在最后</span>\n    PUT(SUCC(succ), fbp);\n    PUT(PRED(fbp), succ);\n    PUT(SUCC(fbp), <span class=\"hljs-literal\">NULL</span>);\n&#125;</code></pre>\n<p>​    首先获得目标块的 index，即属于二的几次幂，之后通过 <code>global_list_start_ptr</code> 加上 index 偏移定位到其属于的大小类链表的 root 指针，如果root指针有指向就进行地址顺序的排序，如果找到后部块地址大于插入块，就把该插入块插到上述块的前部。</p>\n<p>​    如果root没有指向，即当前该大小类中没有空闲块，或者按地址序，该块地址大小最大则进行直接的分配在succ之后。</p>\n<h3 id=\"delete-free-block-删除空闲块\"><a href=\"#delete-free-block-删除空闲块\" class=\"headerlink\" title=\"delete_free_block 删除空闲块\"></a>delete_free_block 删除空闲块</h3><p>​    删除空闲块要注意，这里常见的bug是和 insert_free_block 一同出现的指针维护不良，导致删除不存在的块，或者访问 nullptr 的前后继以及指针越界问题。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">delete_free_block</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">char</span> *fbp)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-comment\">// NORMAL: GOT A SUCCESSOR AND PREDECESSOR</span>\n    <span class=\"hljs-keyword\">if</span>(SUCC_BLKP(fbp) &amp;&amp; PRED_BLKP(fbp))&#123;\n        PUT(SUCC(PRED_BLKP(fbp)), SUCC_BLKP(fbp));\n        PUT(PRED(SUCC_BLKP(fbp)), PRED_BLKP(fbp));\n    &#125;\n    <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(PRED_BLKP(fbp))&#123; <span class=\"hljs-comment\">// LAST BLOCK</span>\n        PUT(SUCC(PRED_BLKP(fbp)), <span class=\"hljs-literal\">NULL</span>);\n    &#125;\n\n    PUT(SUCC(fbp), <span class=\"hljs-literal\">NULL</span>);\n    PUT(PRED(fbp), <span class=\"hljs-literal\">NULL</span>);\n&#125;</code></pre>\n<p>​    正常情况是当前块是链表中间节点，重新连接好前后，把其从链表上脱离即可。如果是最后一个节点，就直接把前继节点的后继指针置为空。最后做好当前删除块的清理工作，把其前后继指针置为NULL</p>\n<h3 id=\"mm-malloc-分配空闲块\"><a href=\"#mm-malloc-分配空闲块\" class=\"headerlink\" title=\"mm_malloc 分配空闲块\"></a>mm_malloc 分配空闲块</h3><p>​    mm_malloc 是该lab中的主要函数，用于控制分配内存块的工作。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> *<span class=\"hljs-title\">mm_malloc</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">size_t</span> size)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">size_t</span> asize = align_size(size);    <span class=\"hljs-comment\">/* 调整后的块大小 */</span>\n    <span class=\"hljs-keyword\">size_t</span> extendsize;                  <span class=\"hljs-comment\">/* 扩展堆大小 */</span>\n    <span class=\"hljs-keyword\">char</span> *bp;\n\n    <span class=\"hljs-comment\">/* Trivial Case */</span>\n    <span class=\"hljs-keyword\">if</span>(size == <span class=\"hljs-number\">0</span>)\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">NULL</span>;\n\n    <span class=\"hljs-comment\">/* 寻找适配 */</span>\n    <span class=\"hljs-keyword\">if</span>((bp = find_fit(asize, get_index(asize))) != <span class=\"hljs-literal\">NULL</span>)\n        <span class=\"hljs-keyword\">return</span> place(bp, asize);\n\n    <span class=\"hljs-comment\">/* 未找到适配，分配更多堆空间 */</span>\n    extendsize = MAX(asize, CHUNKSIZE);\n    <span class=\"hljs-keyword\">if</span>((bp = extend_heap(extendsize)) == <span class=\"hljs-literal\">NULL</span>)\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">NULL</span>;\n\n    <span class=\"hljs-keyword\">return</span> place(bp, asize);\n&#125;</code></pre>\n<p>​    首先要做好分配大小的对齐，这里定义了一个util函数 align_size 用来对齐块大小。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">size_t</span> <span class=\"hljs-title\">align_size</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">size_t</span> size)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-comment\">/* 调整块大小 */</span>\n    <span class=\"hljs-keyword\">if</span>(size &lt;= DSIZE) <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">2</span>*DSIZE;\n    <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">return</span> DSIZE * ((size + (DSIZE) + (DSIZE - <span class=\"hljs-number\">1</span>)) / DSIZE);\n\n    <span class=\"hljs-comment\">// Code Never Went Here</span>\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n&#125;</code></pre>\n<p>​    之后逻辑就是通过 find_fit 在空闲链表中寻找适配，如果没找到适配就进行 heap_extend，每次最小扩展 <code>CHUNKSIZE</code> bytes，这里我将 <code>CHUNKSIZE</code> 设为 512</p>\n<p> <strong>(有讲究，如果大于520就会导致realloc2的第一次分配 512 就能够成功，这样之后alloc的块就跟在512块后，就不能成功的将 realloc 的 0 号 block 安排在块位，导致无法通过 extend_heap 来提高性能)</strong></p>\n<p>最后放置空闲块，使用place函数进行分配和分割</p>\n<h3 id=\"find-fit-寻找适配\"><a href=\"#find-fit-寻找适配\" class=\"headerlink\" title=\"find_fit 寻找适配\"></a>find_fit 寻找适配</h3><p>​    我使用的是简单的首次适配，即从小到大遍历分离空闲链表，找到第一块适合的空闲块。由于每个空闲链表内部是按地址顺序排列而非大小排列，所以其效果并非严格等同于 best_fit 但是由于大小分块的组织结构，其效果又好于完全不按空间大小排序的适配方式。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">void</span> *<span class=\"hljs-title\">find_fit</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">size_t</span> size, <span class=\"hljs-keyword\">int</span> seg_idx)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-comment\">// First Fit</span>\n    <span class=\"hljs-keyword\">char</span>* res;\n    <span class=\"hljs-keyword\">while</span>(seg_idx &lt; SEG_LEN)&#123;\n        <span class=\"hljs-keyword\">char</span> *root = global_list_start_ptr + seg_idx * WSIZE;\n        <span class=\"hljs-keyword\">char</span> *bp = (<span class=\"hljs-keyword\">char</span> *)SUCC_BLKP(root);\n        <span class=\"hljs-keyword\">while</span>(bp)&#123;\n            <span class=\"hljs-keyword\">if</span>((<span class=\"hljs-keyword\">size_t</span>)CRT_BLKSZ(bp) &gt;= size)\n                <span class=\"hljs-keyword\">return</span> bp;\n            \n            bp = (<span class=\"hljs-keyword\">char</span> *)SUCC_BLKP(bp);\n        &#125;\n        <span class=\"hljs-comment\">// 在这类中未找到适合，在更大类中寻找</span>\n        seg_idx++;\n    &#125;\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">NULL</span>;\n&#125;</code></pre>\n<h3 id=\"place-分配块\"><a href=\"#place-分配块\" class=\"headerlink\" title=\"place 分配块\"></a>place 分配块</h3><p>​    分配块这里有说法了，第一层是分配空闲块的时候，如果当前适配的块大小比需要分配的大很多（超出最小空闲块大小 16bytes）那么我们就可以通过分割来减小内部碎片。</p>\n<p>​    并且这个分割也是很有讲究，我们可以设计当需要分配的空间较大时例如大于64 bytes，我们就将其分配在空闲块的后部，将前部分割出来作为新的空闲块。如果小于就直接分配在当前空闲块的前部，将后部分割出来作为新的空闲块。这样的组织方式有两方面好处，</p>\n<ul>\n<li>一方面是其进行了大小分类，有利于块的合并</li>\n<li>另一方面是对于 realloc2 的测试 trace，我们通过前部切分的方式，使 512 块后再次分配的两 128 块占用前部空间，这样可以使 512 块始终是最后一块即其后继块是结尾块，那么在 realloc 它的时候我们就可以直接通过 extend_heap 达到如此一来可以大大提高内存利用率，<strong>将realloc1、2的util提升至近100%！</strong></li>\n</ul>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">void</span> *<span class=\"hljs-title\">place</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">char</span> *bp, <span class=\"hljs-keyword\">size_t</span> asize)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">size_t</span> blk_size = CRT_BLKSZ(bp);\n    <span class=\"hljs-keyword\">size_t</span> rm_size = blk_size - asize;\n\n    <span class=\"hljs-keyword\">if</span>(!GET_ALLOC(HDRP(bp)))\n        delete_free_block(bp);\n    <span class=\"hljs-comment\">// 剩余空间大于最小块大小的可分割的情况</span>\n    <span class=\"hljs-keyword\">if</span>(rm_size &gt;= <span class=\"hljs-number\">2</span>*DSIZE)&#123;\n        <span class=\"hljs-comment\">// 当块大小大于 64 时将其有效载荷放在空闲块后部，前部切分出来作为空闲块</span>\n        <span class=\"hljs-keyword\">if</span>(asize &gt; <span class=\"hljs-number\">64</span>)&#123;\n            PUT(HDRP(bp), PACK(rm_size, FREE));\n            PUT(FTRP(bp), PACK(rm_size, FREE));\n            PUT(HDRP(NEXT_BLKP(bp)), PACK(asize, ALLOCATED));\n            PUT(FTRP(NEXT_BLKP(bp)), PACK(asize, ALLOCATED));\n            coalesce(bp);\n            <span class=\"hljs-keyword\">return</span> NEXT_BLKP(bp);\n        &#125;\n        <span class=\"hljs-keyword\">else</span>&#123;\n            PUT(HDRP(bp), PACK(asize, ALLOCATED));\n            PUT(FTRP(bp), PACK(asize, ALLOCATED));\n            PUT(HDRP(NEXT_BLKP(bp)), PACK(rm_size, FREE));\n            PUT(FTRP(NEXT_BLKP(bp)), PACK(rm_size, FREE));\n\n            coalesce(NEXT_BLKP(bp));\n        &#125;\n    &#125;\n    <span class=\"hljs-comment\">// 不可分割情况</span>\n    <span class=\"hljs-keyword\">else</span>&#123;\n        PUT(HDRP(bp), PACK(blk_size, ALLOCATED));\n        PUT(FTRP(bp), PACK(blk_size, ALLOCATED));\n    &#125;\n    <span class=\"hljs-keyword\">return</span> bp;\n&#125;</code></pre>\n<h3 id=\"mm-free-释放块\"><a href=\"#mm-free-释放块\" class=\"headerlink\" title=\"mm_free 释放块\"></a>mm_free 释放块</h3><p>​    直接设置空闲，并释放同时合并，没什么好说的</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">mm_free</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span> *ptr)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">ifdef</span> DEBUG</span>\n        <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Freeing.....\\n&quot;</span>);\n    <span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">endif</span></span>\n    <span class=\"hljs-keyword\">char</span> *bp = ptr;\n    <span class=\"hljs-keyword\">size_t</span> size = CRT_BLKSZ(bp);\n\n    PUT(HDRP(bp), PACK(size, FREE));\n    PUT(FTRP(bp), PACK(size, FREE));\n    coalesce(bp);\n&#125;</code></pre>\n<h3 id=\"mm-realloc-重分配块\"><a href=\"#mm-realloc-重分配块\" class=\"headerlink\" title=\"mm_realloc 重分配块\"></a>mm_realloc 重分配块</h3><p>​    mm_realloc 能否做好是分数能否上 90 的关键，其主要策略有两个</p>\n<ul>\n<li><p><strong>空闲块融合</strong></p>\n<p>一在重分配的时候，如果后方有空闲块可以进行融合，再看空间够不够，如果够了就不用释放再分配了。</p>\n<p>（同时前融合也应当有相应的效果，前融合要注意内部载荷数据的移动，但其实观察 trace 文件下的block组织表现，发现其实前融合很少甚至没有，对性能影响不大，之后便在代码中删除了）</p>\n</li>\n<li><p><strong>尾部堆扩展</strong></p>\n<p>就是之前提到的如果要重分配的块是尾部块就执行 extend_heap 就行了，不需要释放再分配。同时注意到了 trace 文件中反复 realloc 首次分配的块，于是和 place 中提到的策略相互结合可以达到将首次分配的块移动到末尾的效果。</p>\n</li>\n</ul>\n<p>其余就是一些基础写法，在注释中已经体现，还有需要注意一下<strong>分配大小的对齐</strong>和特殊情况</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> *<span class=\"hljs-title\">mm_realloc</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span> *ptr, <span class=\"hljs-keyword\">size_t</span> size)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-comment\">// 如果 ptr == NULL 直接分配</span>\n    <span class=\"hljs-keyword\">if</span>(ptr == <span class=\"hljs-literal\">NULL</span>)    \n        <span class=\"hljs-keyword\">return</span> mm_malloc(size);\n    <span class=\"hljs-comment\">// 如果 size == 0 就释放</span>\n    <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(size == <span class=\"hljs-number\">0</span>)&#123;\n        mm_free(ptr);\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">NULL</span>;\n    &#125;\n    <span class=\"hljs-keyword\">size_t</span> asize = align_size(size), old_size = CRT_BLKSZ(ptr);\n    <span class=\"hljs-keyword\">size_t</span> mv_size = MIN(asize, old_size);\n    <span class=\"hljs-keyword\">char</span> *oldptr = ptr;\n    <span class=\"hljs-keyword\">char</span> *newptr;\n\n    <span class=\"hljs-keyword\">if</span>(old_size == asize)\n        <span class=\"hljs-keyword\">return</span> ptr;\n    \n    <span class=\"hljs-keyword\">size_t</span> prev_alloc =  GET_ALLOC(FTRP(PREV_BLKP(ptr)));\n    <span class=\"hljs-keyword\">size_t</span> next_alloc =  GET_ALLOC(HDRP(NEXT_BLKP(ptr)));\n    <span class=\"hljs-keyword\">size_t</span> next_size = NEXT_BLKSZ(ptr);\n    <span class=\"hljs-keyword\">char</span> *next_bp = NEXT_BLKP(ptr);\n    <span class=\"hljs-keyword\">size_t</span> total_size = old_size;\n\n    <span class=\"hljs-keyword\">if</span>(prev_alloc &amp;&amp; !next_alloc &amp;&amp; (old_size + next_size &gt;= asize))&#123;    <span class=\"hljs-comment\">// 后空闲  </span>\n        total_size += next_size;\n        delete_free_block(next_bp);\n        PUT(HDRP(ptr), PACK(total_size, ALLOCATED));\n        PUT(FTRP(ptr), PACK(total_size, ALLOCATED));\n        place(ptr, total_size);\n    &#125;\n    <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(!next_size &amp;&amp; asize &gt;= old_size)&#123;   <span class=\"hljs-comment\">// 如果后部是结尾块，则直接 extend_heap</span>\n        <span class=\"hljs-keyword\">size_t</span> extend_size = asize - old_size;\n        <span class=\"hljs-keyword\">if</span>((<span class=\"hljs-keyword\">long</span>)(mem_sbrk(extend_size)) == <span class=\"hljs-number\">-1</span>)\n            <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">NULL</span>; \n        \n        PUT(HDRP(ptr), PACK(total_size + extend_size, ALLOCATED));\n        PUT(FTRP(ptr), PACK(total_size + extend_size, ALLOCATED));\n        PUT(HDRP(NEXT_BLKP(ptr)), PACK(<span class=\"hljs-number\">0</span>, ALLOCATED)); \n        place(ptr, asize);\n    &#125;\n    <span class=\"hljs-keyword\">else</span>&#123;   <span class=\"hljs-comment\">// 直接分配</span>\n        newptr = mm_malloc(asize);\n        <span class=\"hljs-keyword\">if</span>(newptr == <span class=\"hljs-literal\">NULL</span>)\n            <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">NULL</span>;\n        <span class=\"hljs-built_in\">memcpy</span>(newptr, ptr, MIN(old_size, size));\n        mm_free(ptr);\n        <span class=\"hljs-keyword\">return</span> newptr;\n    &#125;\n    <span class=\"hljs-keyword\">return</span> ptr;\n&#125;</code></pre>\n<h2 id=\"关于DEBUG\"><a href=\"#关于DEBUG\" class=\"headerlink\" title=\"关于DEBUG\"></a>关于DEBUG</h2><p>​    代码中为了 DEBUG 定义了大量 debug util 函数和 Error Handler，如果想清晰的看清楚堆块的组织结构，调用它们是很有帮助的。还有 debug 要善用 gdb…</p>\n<h2 id=\"四、实验结果\"><a href=\"#四、实验结果\" class=\"headerlink\" title=\"四、实验结果\"></a>四、实验结果</h2><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gqqcdfltwxj309s088aal.jpg\" alt></p>\n<p>​    在不使用BST和全局数据结构的情况下达到了 97/100 的分数，还不错。</p>\n<h2 id=\"五、结语\"><a href=\"#五、结语\" class=\"headerlink\" title=\"五、结语\"></a>五、结语</h2><p>​    这个Lab用了我2、3天的时间，是比较难的，需要用心 DEBUG 考验 gdb的使用。Malloc Lab 还是很好玩的，ddl之后我可能会考虑进一步优化，采用BST结构尽量做到接近 100/100</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Malloc-Lab\"><a href=\"#Malloc-Lab\" class=\"headerlink\" title=\"Malloc Lab\"></a>Malloc Lab</h1><p>​    个人的实验报告，放上来给大家参考。</p>\n<p>​    Malloc lab 需要我们编写一个类似 libc malloc 的动态内存分配器，其主要考察动态内存分配器的原理设计以及堆内存的结构组织，同时需要比较强的 DEBUG 能力。最后在不使用BST以及其他全局数据结构的情况下我的方法达到了 97/100 的分数</p>\n<p><a href=\"https://github.com/ZiYang-xie/Malloc_Lab\">ZiYang-xie/Malloc_Lab: CMU Malloc Lab Repo (github.com)</a></p>\n<h2 id=\"一、空闲块组织结构\"><a href=\"#一、空闲块组织结构\" class=\"headerlink\" title=\"一、空闲块组织结构\"></a>一、空闲块组织结构</h2><p>​    在结构设计上我采用了分离存储的显示链表形式来进行组织空闲块，在书上说明了分离存储的思想，但没有具体说明实现方法。在此我使用称为 <strong>Segregated Free List</strong> 的空闲块组织设计，即在堆的低地址分配数量等于 <code>SEG_LEN</code> 的指针，每个指针分别对应着一个大小类，指向正式堆块中的空闲块，相当于 <code>SEG_LEN</code> 个链表。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gquqskpijgj30ff07cdg2.jpg\" alt=\"Segregated Free List\"></p>\n<p>​    在我的代码设计中，我以2的幂次分割大小类，由于空闲块最小块大小为16 bytes （包括头尾标记以及前后指针）因此其设计为 {2^4 ~ 2^5} \\ {2^5 ~ 2^6} \\ {2^6 ~ 2^7} …(类推)</p>\n<p> 为了区分某一空闲块应该被放置在哪个类中，我们需要一个 <strong>get_index</strong> 函数，正常设计也十分简单，即通过一个循环右移，计算位数。在这里我参考了 <strong>Bit twiddling hacks</strong> 著名位运算<em>奇技淫巧</em> 网站，采用了一个位运算的 log2 方式，其可以在 O(1) 的复杂度计算出 log2(x)</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">get_index</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">size_t</span> v)</span> </span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-comment\">// 本质上是位运算的 log 2, O(1)复杂度</span>\n    <span class=\"hljs-comment\">// 参考 &#x27;Bit twiddling hacks&#x27;</span>\n    <span class=\"hljs-comment\">// Linking: https://graphics.stanford.edu/~seander/bithacks.html#IntegerLogLookup</span>\n    \n    <span class=\"hljs-keyword\">size_t</span> r, shift;\n    r = (v &gt; <span class=\"hljs-number\">0xFFFF</span>)   &lt;&lt; <span class=\"hljs-number\">4</span>; v &gt;&gt;= r;\n    shift = (v &gt; <span class=\"hljs-number\">0xFF</span>) &lt;&lt; <span class=\"hljs-number\">3</span>; v &gt;&gt;= shift; r |= shift;\n    shift = (v &gt; <span class=\"hljs-number\">0xF</span>)  &lt;&lt; <span class=\"hljs-number\">2</span>; v &gt;&gt;= shift; r |= shift;\n    shift = (v &gt; <span class=\"hljs-number\">0x3</span>)  &lt;&lt; <span class=\"hljs-number\">1</span>; v &gt;&gt;= shift; r |= shift;\n                                          r |= (v &gt;&gt; <span class=\"hljs-number\">1</span>);\n    <span class=\"hljs-comment\">// 从 2^4 开始 (空闲块最小 16 bytes)</span>\n    <span class=\"hljs-keyword\">int</span> x = (<span class=\"hljs-keyword\">int</span>)r - <span class=\"hljs-number\">4</span>;\n    <span class=\"hljs-keyword\">if</span>(x &lt; <span class=\"hljs-number\">0</span>) \n        x = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">if</span>(x &gt;= SEG_LEN) \n        x = SEG_LEN - <span class=\"hljs-number\">1</span>;\n    <span class=\"hljs-keyword\">return</span> x;\n&#125;</code></pre>\n<h2 id=\"二、堆内存设计\"><a href=\"#二、堆内存设计\" class=\"headerlink\" title=\"二、堆内存设计\"></a>二、堆内存设计</h2><p>​    在空闲块指针之上，分配正常的堆块，正常的堆块由<strong>序言块</strong> （一个已分配大小为8的块），以及<strong>结尾块</strong>（一个已分配大小为0的块）前后包围，这样可以很方便的检验边界情况，当后继块大小为0，那么便可判断其达到了结尾。之后便记录下全局的开始地址 <code>global_list_start_ptr</code> 即可</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">/* 空闲块 */</span>\n<span class=\"hljs-keyword\">for</span>(i = <span class=\"hljs-number\">0</span>; i &lt; SEG_LEN; ++i)\n  PUT(heap_listp + i*WSIZE, <span class=\"hljs-literal\">NULL</span>);\t            <span class=\"hljs-comment\">// 初始化空闲块大小类头指针</span>\n\n<span class=\"hljs-comment\">/* 分配块 */</span>\nPUT(heap_listp + (i+<span class=\"hljs-number\">0</span>)*WSIZE, PACK(DSIZE, ALLOCATED));  <span class=\"hljs-comment\">/* 序言块头部 */</span>\nPUT(heap_listp + (i+<span class=\"hljs-number\">1</span>)*WSIZE, PACK(DSIZE, ALLOCATED));  <span class=\"hljs-comment\">/* 序言块尾部 */</span>\nPUT(heap_listp + (i+<span class=\"hljs-number\">2</span>)*WSIZE, PACK(<span class=\"hljs-number\">0</span>, ALLOCATED));      <span class=\"hljs-comment\">/* 结尾块头部 */</span>\n\nglobal_list_start_ptr = heap_listp;\nheap_listp += (i+<span class=\"hljs-number\">1</span>)*WSIZE; <span class=\"hljs-comment\">// 对齐到起始块有效载荷</span></code></pre>\n<h2 id=\"三、具体设计\"><a href=\"#三、具体设计\" class=\"headerlink\" title=\"三、具体设计\"></a>三、具体设计</h2><p>​    接下来以函数为单位详细介绍实现过程</p>\n<pre><code>### mm_init 初始化堆\n</code></pre><p>​    堆内存设计块节中以及包含大部分，mm_init 代码，在组织完堆初始化的指针之后就可以进行分配栈空间以一个初始化的空闲块，这涉及到了 extend_heap 函数</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">/* 扩展空栈至 CHUNKSIZE bytes */</span>\n    <span class=\"hljs-keyword\">if</span>(extend_heap(CHUNKSIZE) == <span class=\"hljs-literal\">NULL</span>)\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">-1</span>;\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;</code></pre>\n<h3 id=\"extend-heap-堆扩展\"><a href=\"#extend-heap-堆扩展\" class=\"headerlink\" title=\"extend_heap 堆扩展\"></a>extend_heap 堆扩展</h3><p>​    对于堆扩展，我们调用 mm_sbrk 函数将lab中设计好的抽象 program breaker 上移扩展堆大小，其返回空闲块的头指针，我们设置好它的头尾标记，并通过 coalesce 函数在进行前后空闲块合并之后插入到空闲块链表中。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">void</span> *<span class=\"hljs-title\">extend_heap</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">size_t</span> asize)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">char</span> *bp;\n    <span class=\"hljs-keyword\">if</span>((<span class=\"hljs-keyword\">long</span>)(bp = mem_sbrk(asize)) == <span class=\"hljs-number\">-1</span>)\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">NULL</span>;\n    \n    <span class=\"hljs-comment\">/* 初始化空闲块的头尾和结尾块的头部 */</span>\n    PUT(HDRP(bp), PACK(asize, FREE));                <span class=\"hljs-comment\">/* 空闲块头部 */</span>\n    PUT(FTRP(bp), PACK(asize, FREE));                <span class=\"hljs-comment\">/* 空闲块尾部 */</span>\n    PUT(HDRP(NEXT_BLKP(bp)), PACK(<span class=\"hljs-number\">0</span>, ALLOCATED));    <span class=\"hljs-comment\">/* 结尾块头部 */</span>\n\n    <span class=\"hljs-keyword\">return</span> coalesce(bp);\n&#125;</code></pre>\n<h3 id=\"coalesce-合并块\"><a href=\"#coalesce-合并块\" class=\"headerlink\" title=\"coalesce 合并块\"></a>coalesce 合并块</h3><p>​    合并块的模式包含四种情况，并且在我的设计模式中，在合并后将空闲块插入到空闲链表中去，形成一体化操作。</p>\n<ul>\n<li><strong>Case1: 前后均不空闲</strong></li>\n</ul>\n<pre><code class=\"hljs c\"><span class=\"hljs-keyword\">if</span>(prev_alloc &amp;&amp; next_alloc)&#123;                   <span class=\"hljs-comment\">/* 前后非空闲 */</span>\n  insert_free_block(bp);\n  <span class=\"hljs-keyword\">return</span> bp;\n&#125;</code></pre>\n<p>前后均不空闲的时候就直接插入当前空闲块，并返回bp</p>\n<ul>\n<li><strong>Case2: 后空闲</strong></li>\n</ul>\n<pre><code class=\"hljs c\"><span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(prev_alloc &amp;&amp; !next_alloc)&#123;             <span class=\"hljs-comment\">/* 后空闲 */</span>\n  size += NEXT_BLKSZ(bp);\n  delete_free_block(NEXT_BLKP(bp));\n  PUT(HDRP(bp), PACK(size, FREE));\n  PUT(FTRP(bp), PACK(size, FREE));\n  PUT(PRED(bp), <span class=\"hljs-literal\">NULL</span>);\n  PUT(SUCC(bp), <span class=\"hljs-literal\">NULL</span>);\n&#125;</code></pre>\n<p>​    后空闲的时候就从空闲链表中删除后方空闲块，并把当前块的头部和后部块的尾部大小设计为扩展后大小 <em>( 由于 FTRP 中调用了 HDRP，所以先设计HDRP的size之后FTRP能够正确定位到尾部 )</em> 并且设置空闲块前驱后继指针为NULL做好清理。</p>\n<ul>\n<li><strong>Case3:</strong> 前空闲</li>\n</ul>\n<pre><code class=\"hljs c\"><span class=\"hljs-keyword\">if</span>(!prev_alloc &amp;&amp; next_alloc) &#123;            <span class=\"hljs-comment\">/* 前空闲 */</span>\n  size += PREV_BLKSZ(bp);\n  delete_free_block(PREV_BLKP(bp));\n\n  PUT(FTRP(bp), PACK(size, FREE));\n  PUT(HDRP(PREV_BLKP(bp)), PACK(size, FREE));\n\n  bp = PREV_BLKP(bp);\n  PUT(PRED(bp), <span class=\"hljs-literal\">NULL</span>);\n  PUT(SUCC(bp), <span class=\"hljs-literal\">NULL</span>);\n&#125;</code></pre>\n<p>​    前空闲就从空闲链表中删除前方空闲块，并且注意分配的头部标记是前一块的头部标记，其余逻辑和 Case2类似</p>\n<ul>\n<li><strong>Case4:</strong> 前后均非空闲</li>\n</ul>\n<pre><code class=\"hljs c\"><span class=\"hljs-keyword\">else</span>&#123;\t<span class=\"hljs-comment\">/* 前后均空闲 */</span>\n  size += NEXT_BLKSZ(bp) + PREV_BLKSZ(bp);\n  delete_free_block(PREV_BLKP(bp));\n  delete_free_block(NEXT_BLKP(bp));\n  PUT(HDRP(PREV_BLKP(bp)), PACK(size, FREE));\n  PUT(FTRP(NEXT_BLKP(bp)), PACK(size, FREE));\n  bp = PREV_BLKP(bp);\n  PUT(PRED(bp), <span class=\"hljs-literal\">NULL</span>);\n  PUT(SUCC(bp), <span class=\"hljs-literal\">NULL</span>);\n&#125;</code></pre>\n<p>​    前两种的结合，不多赘述</p>\n<h3 id=\"insert-free-block-插入空闲链表\"><a href=\"#insert-free-block-插入空闲链表\" class=\"headerlink\" title=\"insert_free_block 插入空闲链表\"></a>insert_free_block 插入空闲链表</h3><p>​    插入空闲链表算是一个比较重要的函数，其关乎着空闲块的组织结构，在这里我采用的是<strong>地址排序</strong>的策略。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">insert_free_block</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">char</span> *fbp)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-comment\">// 地址排序 - Address Order</span>\n    <span class=\"hljs-keyword\">void</span> *succ = root;\n    \n    <span class=\"hljs-keyword\">while</span>(SUCC_BLKP(succ))&#123;\n        succ = (<span class=\"hljs-keyword\">char</span> *)SUCC_BLKP(succ);\n        <span class=\"hljs-keyword\">if</span>((<span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">int</span>)succ &gt;= (<span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">int</span>)fbp)&#123;\n            <span class=\"hljs-comment\">// 安装地址顺序插入空闲块</span>\n            <span class=\"hljs-comment\">// PRED_BLKP(succ) &lt;-&gt; fbp &lt;-&gt; succ</span>\n            <span class=\"hljs-keyword\">char</span> *tmp = succ;\n            succ = (<span class=\"hljs-keyword\">char</span> *)PRED_BLKP(succ);\n            PUT(SUCC(succ), fbp);\n            PUT(PRED(fbp), succ);\n            PUT(SUCC(fbp), tmp);\n            PUT(PRED(tmp), fbp);\n            <span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">ifdef</span> INDEBUG</span>\n                <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;succ(PRE): %p \\t tmp(SUCC): %p \\t&quot;</span>, succ, tmp);\n                print_free_list(<span class=\"hljs-string\">&quot;Insert&quot;</span>);\n            <span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">endif</span></span>\n            <span class=\"hljs-keyword\">return</span>;\n        &#125;\n    &#125;\n    \n    <span class=\"hljs-comment\">// Base Case &amp; Last Case </span>\n    <span class=\"hljs-comment\">// 当前大小类无空闲块 或者 在地址分配时当前空闲块地址最大被分配在最后</span>\n    PUT(SUCC(succ), fbp);\n    PUT(PRED(fbp), succ);\n    PUT(SUCC(fbp), <span class=\"hljs-literal\">NULL</span>);\n&#125;</code></pre>\n<p>​    首先获得目标块的 index，即属于二的几次幂，之后通过 <code>global_list_start_ptr</code> 加上 index 偏移定位到其属于的大小类链表的 root 指针，如果root指针有指向就进行地址顺序的排序，如果找到后部块地址大于插入块，就把该插入块插到上述块的前部。</p>\n<p>​    如果root没有指向，即当前该大小类中没有空闲块，或者按地址序，该块地址大小最大则进行直接的分配在succ之后。</p>\n<h3 id=\"delete-free-block-删除空闲块\"><a href=\"#delete-free-block-删除空闲块\" class=\"headerlink\" title=\"delete_free_block 删除空闲块\"></a>delete_free_block 删除空闲块</h3><p>​    删除空闲块要注意，这里常见的bug是和 insert_free_block 一同出现的指针维护不良，导致删除不存在的块，或者访问 nullptr 的前后继以及指针越界问题。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">delete_free_block</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">char</span> *fbp)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-comment\">// NORMAL: GOT A SUCCESSOR AND PREDECESSOR</span>\n    <span class=\"hljs-keyword\">if</span>(SUCC_BLKP(fbp) &amp;&amp; PRED_BLKP(fbp))&#123;\n        PUT(SUCC(PRED_BLKP(fbp)), SUCC_BLKP(fbp));\n        PUT(PRED(SUCC_BLKP(fbp)), PRED_BLKP(fbp));\n    &#125;\n    <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(PRED_BLKP(fbp))&#123; <span class=\"hljs-comment\">// LAST BLOCK</span>\n        PUT(SUCC(PRED_BLKP(fbp)), <span class=\"hljs-literal\">NULL</span>);\n    &#125;\n\n    PUT(SUCC(fbp), <span class=\"hljs-literal\">NULL</span>);\n    PUT(PRED(fbp), <span class=\"hljs-literal\">NULL</span>);\n&#125;</code></pre>\n<p>​    正常情况是当前块是链表中间节点，重新连接好前后，把其从链表上脱离即可。如果是最后一个节点，就直接把前继节点的后继指针置为空。最后做好当前删除块的清理工作，把其前后继指针置为NULL</p>\n<h3 id=\"mm-malloc-分配空闲块\"><a href=\"#mm-malloc-分配空闲块\" class=\"headerlink\" title=\"mm_malloc 分配空闲块\"></a>mm_malloc 分配空闲块</h3><p>​    mm_malloc 是该lab中的主要函数，用于控制分配内存块的工作。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> *<span class=\"hljs-title\">mm_malloc</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">size_t</span> size)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">size_t</span> asize = align_size(size);    <span class=\"hljs-comment\">/* 调整后的块大小 */</span>\n    <span class=\"hljs-keyword\">size_t</span> extendsize;                  <span class=\"hljs-comment\">/* 扩展堆大小 */</span>\n    <span class=\"hljs-keyword\">char</span> *bp;\n\n    <span class=\"hljs-comment\">/* Trivial Case */</span>\n    <span class=\"hljs-keyword\">if</span>(size == <span class=\"hljs-number\">0</span>)\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">NULL</span>;\n\n    <span class=\"hljs-comment\">/* 寻找适配 */</span>\n    <span class=\"hljs-keyword\">if</span>((bp = find_fit(asize, get_index(asize))) != <span class=\"hljs-literal\">NULL</span>)\n        <span class=\"hljs-keyword\">return</span> place(bp, asize);\n\n    <span class=\"hljs-comment\">/* 未找到适配，分配更多堆空间 */</span>\n    extendsize = MAX(asize, CHUNKSIZE);\n    <span class=\"hljs-keyword\">if</span>((bp = extend_heap(extendsize)) == <span class=\"hljs-literal\">NULL</span>)\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">NULL</span>;\n\n    <span class=\"hljs-keyword\">return</span> place(bp, asize);\n&#125;</code></pre>\n<p>​    首先要做好分配大小的对齐，这里定义了一个util函数 align_size 用来对齐块大小。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">size_t</span> <span class=\"hljs-title\">align_size</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">size_t</span> size)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-comment\">/* 调整块大小 */</span>\n    <span class=\"hljs-keyword\">if</span>(size &lt;= DSIZE) <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">2</span>*DSIZE;\n    <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">return</span> DSIZE * ((size + (DSIZE) + (DSIZE - <span class=\"hljs-number\">1</span>)) / DSIZE);\n\n    <span class=\"hljs-comment\">// Code Never Went Here</span>\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n&#125;</code></pre>\n<p>​    之后逻辑就是通过 find_fit 在空闲链表中寻找适配，如果没找到适配就进行 heap_extend，每次最小扩展 <code>CHUNKSIZE</code> bytes，这里我将 <code>CHUNKSIZE</code> 设为 512</p>\n<p> <strong>(有讲究，如果大于520就会导致realloc2的第一次分配 512 就能够成功，这样之后alloc的块就跟在512块后，就不能成功的将 realloc 的 0 号 block 安排在块位，导致无法通过 extend_heap 来提高性能)</strong></p>\n<p>最后放置空闲块，使用place函数进行分配和分割</p>\n<h3 id=\"find-fit-寻找适配\"><a href=\"#find-fit-寻找适配\" class=\"headerlink\" title=\"find_fit 寻找适配\"></a>find_fit 寻找适配</h3><p>​    我使用的是简单的首次适配，即从小到大遍历分离空闲链表，找到第一块适合的空闲块。由于每个空闲链表内部是按地址顺序排列而非大小排列，所以其效果并非严格等同于 best_fit 但是由于大小分块的组织结构，其效果又好于完全不按空间大小排序的适配方式。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">void</span> *<span class=\"hljs-title\">find_fit</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">size_t</span> size, <span class=\"hljs-keyword\">int</span> seg_idx)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-comment\">// First Fit</span>\n    <span class=\"hljs-keyword\">char</span>* res;\n    <span class=\"hljs-keyword\">while</span>(seg_idx &lt; SEG_LEN)&#123;\n        <span class=\"hljs-keyword\">char</span> *root = global_list_start_ptr + seg_idx * WSIZE;\n        <span class=\"hljs-keyword\">char</span> *bp = (<span class=\"hljs-keyword\">char</span> *)SUCC_BLKP(root);\n        <span class=\"hljs-keyword\">while</span>(bp)&#123;\n            <span class=\"hljs-keyword\">if</span>((<span class=\"hljs-keyword\">size_t</span>)CRT_BLKSZ(bp) &gt;= size)\n                <span class=\"hljs-keyword\">return</span> bp;\n            \n            bp = (<span class=\"hljs-keyword\">char</span> *)SUCC_BLKP(bp);\n        &#125;\n        <span class=\"hljs-comment\">// 在这类中未找到适合，在更大类中寻找</span>\n        seg_idx++;\n    &#125;\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">NULL</span>;\n&#125;</code></pre>\n<h3 id=\"place-分配块\"><a href=\"#place-分配块\" class=\"headerlink\" title=\"place 分配块\"></a>place 分配块</h3><p>​    分配块这里有说法了，第一层是分配空闲块的时候，如果当前适配的块大小比需要分配的大很多（超出最小空闲块大小 16bytes）那么我们就可以通过分割来减小内部碎片。</p>\n<p>​    并且这个分割也是很有讲究，我们可以设计当需要分配的空间较大时例如大于64 bytes，我们就将其分配在空闲块的后部，将前部分割出来作为新的空闲块。如果小于就直接分配在当前空闲块的前部，将后部分割出来作为新的空闲块。这样的组织方式有两方面好处，</p>\n<ul>\n<li>一方面是其进行了大小分类，有利于块的合并</li>\n<li>另一方面是对于 realloc2 的测试 trace，我们通过前部切分的方式，使 512 块后再次分配的两 128 块占用前部空间，这样可以使 512 块始终是最后一块即其后继块是结尾块，那么在 realloc 它的时候我们就可以直接通过 extend_heap 达到如此一来可以大大提高内存利用率，<strong>将realloc1、2的util提升至近100%！</strong></li>\n</ul>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">void</span> *<span class=\"hljs-title\">place</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">char</span> *bp, <span class=\"hljs-keyword\">size_t</span> asize)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">size_t</span> blk_size = CRT_BLKSZ(bp);\n    <span class=\"hljs-keyword\">size_t</span> rm_size = blk_size - asize;\n\n    <span class=\"hljs-keyword\">if</span>(!GET_ALLOC(HDRP(bp)))\n        delete_free_block(bp);\n    <span class=\"hljs-comment\">// 剩余空间大于最小块大小的可分割的情况</span>\n    <span class=\"hljs-keyword\">if</span>(rm_size &gt;= <span class=\"hljs-number\">2</span>*DSIZE)&#123;\n        <span class=\"hljs-comment\">// 当块大小大于 64 时将其有效载荷放在空闲块后部，前部切分出来作为空闲块</span>\n        <span class=\"hljs-keyword\">if</span>(asize &gt; <span class=\"hljs-number\">64</span>)&#123;\n            PUT(HDRP(bp), PACK(rm_size, FREE));\n            PUT(FTRP(bp), PACK(rm_size, FREE));\n            PUT(HDRP(NEXT_BLKP(bp)), PACK(asize, ALLOCATED));\n            PUT(FTRP(NEXT_BLKP(bp)), PACK(asize, ALLOCATED));\n            coalesce(bp);\n            <span class=\"hljs-keyword\">return</span> NEXT_BLKP(bp);\n        &#125;\n        <span class=\"hljs-keyword\">else</span>&#123;\n            PUT(HDRP(bp), PACK(asize, ALLOCATED));\n            PUT(FTRP(bp), PACK(asize, ALLOCATED));\n            PUT(HDRP(NEXT_BLKP(bp)), PACK(rm_size, FREE));\n            PUT(FTRP(NEXT_BLKP(bp)), PACK(rm_size, FREE));\n\n            coalesce(NEXT_BLKP(bp));\n        &#125;\n    &#125;\n    <span class=\"hljs-comment\">// 不可分割情况</span>\n    <span class=\"hljs-keyword\">else</span>&#123;\n        PUT(HDRP(bp), PACK(blk_size, ALLOCATED));\n        PUT(FTRP(bp), PACK(blk_size, ALLOCATED));\n    &#125;\n    <span class=\"hljs-keyword\">return</span> bp;\n&#125;</code></pre>\n<h3 id=\"mm-free-释放块\"><a href=\"#mm-free-释放块\" class=\"headerlink\" title=\"mm_free 释放块\"></a>mm_free 释放块</h3><p>​    直接设置空闲，并释放同时合并，没什么好说的</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">mm_free</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span> *ptr)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">ifdef</span> DEBUG</span>\n        <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;Freeing.....\\n&quot;</span>);\n    <span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">endif</span></span>\n    <span class=\"hljs-keyword\">char</span> *bp = ptr;\n    <span class=\"hljs-keyword\">size_t</span> size = CRT_BLKSZ(bp);\n\n    PUT(HDRP(bp), PACK(size, FREE));\n    PUT(FTRP(bp), PACK(size, FREE));\n    coalesce(bp);\n&#125;</code></pre>\n<h3 id=\"mm-realloc-重分配块\"><a href=\"#mm-realloc-重分配块\" class=\"headerlink\" title=\"mm_realloc 重分配块\"></a>mm_realloc 重分配块</h3><p>​    mm_realloc 能否做好是分数能否上 90 的关键，其主要策略有两个</p>\n<ul>\n<li><p><strong>空闲块融合</strong></p>\n<p>一在重分配的时候，如果后方有空闲块可以进行融合，再看空间够不够，如果够了就不用释放再分配了。</p>\n<p>（同时前融合也应当有相应的效果，前融合要注意内部载荷数据的移动，但其实观察 trace 文件下的block组织表现，发现其实前融合很少甚至没有，对性能影响不大，之后便在代码中删除了）</p>\n</li>\n<li><p><strong>尾部堆扩展</strong></p>\n<p>就是之前提到的如果要重分配的块是尾部块就执行 extend_heap 就行了，不需要释放再分配。同时注意到了 trace 文件中反复 realloc 首次分配的块，于是和 place 中提到的策略相互结合可以达到将首次分配的块移动到末尾的效果。</p>\n</li>\n</ul>\n<p>其余就是一些基础写法，在注释中已经体现，还有需要注意一下<strong>分配大小的对齐</strong>和特殊情况</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> *<span class=\"hljs-title\">mm_realloc</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span> *ptr, <span class=\"hljs-keyword\">size_t</span> size)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-comment\">// 如果 ptr == NULL 直接分配</span>\n    <span class=\"hljs-keyword\">if</span>(ptr == <span class=\"hljs-literal\">NULL</span>)    \n        <span class=\"hljs-keyword\">return</span> mm_malloc(size);\n    <span class=\"hljs-comment\">// 如果 size == 0 就释放</span>\n    <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(size == <span class=\"hljs-number\">0</span>)&#123;\n        mm_free(ptr);\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">NULL</span>;\n    &#125;\n    <span class=\"hljs-keyword\">size_t</span> asize = align_size(size), old_size = CRT_BLKSZ(ptr);\n    <span class=\"hljs-keyword\">size_t</span> mv_size = MIN(asize, old_size);\n    <span class=\"hljs-keyword\">char</span> *oldptr = ptr;\n    <span class=\"hljs-keyword\">char</span> *newptr;\n\n    <span class=\"hljs-keyword\">if</span>(old_size == asize)\n        <span class=\"hljs-keyword\">return</span> ptr;\n    \n    <span class=\"hljs-keyword\">size_t</span> prev_alloc =  GET_ALLOC(FTRP(PREV_BLKP(ptr)));\n    <span class=\"hljs-keyword\">size_t</span> next_alloc =  GET_ALLOC(HDRP(NEXT_BLKP(ptr)));\n    <span class=\"hljs-keyword\">size_t</span> next_size = NEXT_BLKSZ(ptr);\n    <span class=\"hljs-keyword\">char</span> *next_bp = NEXT_BLKP(ptr);\n    <span class=\"hljs-keyword\">size_t</span> total_size = old_size;\n\n    <span class=\"hljs-keyword\">if</span>(prev_alloc &amp;&amp; !next_alloc &amp;&amp; (old_size + next_size &gt;= asize))&#123;    <span class=\"hljs-comment\">// 后空闲  </span>\n        total_size += next_size;\n        delete_free_block(next_bp);\n        PUT(HDRP(ptr), PACK(total_size, ALLOCATED));\n        PUT(FTRP(ptr), PACK(total_size, ALLOCATED));\n        place(ptr, total_size);\n    &#125;\n    <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(!next_size &amp;&amp; asize &gt;= old_size)&#123;   <span class=\"hljs-comment\">// 如果后部是结尾块，则直接 extend_heap</span>\n        <span class=\"hljs-keyword\">size_t</span> extend_size = asize - old_size;\n        <span class=\"hljs-keyword\">if</span>((<span class=\"hljs-keyword\">long</span>)(mem_sbrk(extend_size)) == <span class=\"hljs-number\">-1</span>)\n            <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">NULL</span>; \n        \n        PUT(HDRP(ptr), PACK(total_size + extend_size, ALLOCATED));\n        PUT(FTRP(ptr), PACK(total_size + extend_size, ALLOCATED));\n        PUT(HDRP(NEXT_BLKP(ptr)), PACK(<span class=\"hljs-number\">0</span>, ALLOCATED)); \n        place(ptr, asize);\n    &#125;\n    <span class=\"hljs-keyword\">else</span>&#123;   <span class=\"hljs-comment\">// 直接分配</span>\n        newptr = mm_malloc(asize);\n        <span class=\"hljs-keyword\">if</span>(newptr == <span class=\"hljs-literal\">NULL</span>)\n            <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">NULL</span>;\n        <span class=\"hljs-built_in\">memcpy</span>(newptr, ptr, MIN(old_size, size));\n        mm_free(ptr);\n        <span class=\"hljs-keyword\">return</span> newptr;\n    &#125;\n    <span class=\"hljs-keyword\">return</span> ptr;\n&#125;</code></pre>\n<h2 id=\"关于DEBUG\"><a href=\"#关于DEBUG\" class=\"headerlink\" title=\"关于DEBUG\"></a>关于DEBUG</h2><p>​    代码中为了 DEBUG 定义了大量 debug util 函数和 Error Handler，如果想清晰的看清楚堆块的组织结构，调用它们是很有帮助的。还有 debug 要善用 gdb…</p>\n<h2 id=\"四、实验结果\"><a href=\"#四、实验结果\" class=\"headerlink\" title=\"四、实验结果\"></a>四、实验结果</h2><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gqqcdfltwxj309s088aal.jpg\" alt></p>\n<p>​    在不使用BST和全局数据结构的情况下达到了 97/100 的分数，还不错。</p>\n<h2 id=\"五、结语\"><a href=\"#五、结语\" class=\"headerlink\" title=\"五、结语\"></a>五、结语</h2><p>​    这个Lab用了我2、3天的时间，是比较难的，需要用心 DEBUG 考验 gdb的使用。Malloc Lab 还是很好玩的，ddl之后我可能会考虑进一步优化，采用BST结构尽量做到接近 100/100</p>\n"},{"title":"Locality Principle","date":"2021-10-15T17:29:48.000Z","index_img":"/img/OS/banner.png","math":true,"_content":"\n### 1.1 Intro\n\n​\tLocality Principle is a profound law of computing and has a wide application in many modern areas in computer science — virtual memory, cache, database, etc.  It is the combination of two locality aspects: \n\n- *(1) temporal locality*\n- *(2) spatial locality*\n\n​\tThe success of the locality principle attributes to the fact that locality works aline with human cognitive and coordinative behavior. *Divide and conquer* is the most common practice for humans when dealing with complex problems. We tend to break it into some small parts and work on them separately. Here is where the locality lies in. \n\n​\tUnderstanding the locality principle can benefit a lot, including making better use of cache, predicting the phase boundaries, and extending to many different aspects in computer science, even our daily lives.\n\n### 1.2 History\n\n​\tLooking backward, locality has emerged from the design of virtual memory systems back to 1959, the Atlas system. There were two main performance problems at that time. One is the address location problem, which is quickly solved by page table and TLB, while the another hard nut is the replacement problem of  the demand-paged virtual memory. Replacing the page that will not be used again for the longest time is a common belief, but obviously people can't estimate the next-use time for sure. \n\n​\t1966 Belady's study pointed out that the performance under certain replacement strategy primarily depended on the way how compiler grouped the code blocks onto pages. Shortly after that, thrashing problem was discovered and swiftly became the nightmare for companies using virtual memory. IBM OS360 even excluded the virtual memory, for example.\n\n​\tBy 1966,in Watson Lab, Belady and his partners had tested every replacement policy, and found the LRU (least recently used) replacement got the best performance, because of the reference clustering locality behavior. By using locality notion, MIT Project MAC defined the Intrinsic demand, the first kind of \"*Working Set*\" at the same year.\n\n​\tAs it is explained in Denning's paper[^1]\n\n> The working-set idea worked because the pages observed in the backward window were highly likely to be used again in the immediate future.\n\n​\t The underlying mechanism of it is temporal and spatial locality.\n\n### 1.3 Core \n\n​\tLocality principle hit the key of general program behavior, which is strongly connected with people's coding style when solving a problem — *Divide and Conquer*. This coding style is shown as temporal and spatial clustering on data structures. \n\n​\tFor instance, when people doing a loop, the variables inside the  loop are often changed constantly, which is a kind of temporal clustering. In terms of spatial clustering, Array is an example when we put data into it and access it sequentially. \n\n​\tThe Locality principle can be applied through a distance function $D(x,t)$ to measure temporal of spatial locality, and we use $D(x, t) < T$ to describe the locality set of $x$ at time $t$, and the working set model can be expressed by $W(t, T)$ , $T$ is the time window from the current time $t$. It is a efficient way to track the phases of a program in a dynamic manner, instead of the traditional *static representation* following *Zipf Law*\n\n​\tThe modern model of locality are more about context-awareness with four key ideas\n\n- **An Observer:** Agent doing tasks with the help of software\n- **Neighborhoods:** Group of obejcts \n- **Inference:** Method measures the content of neighborhoods\n- **Optimal Actions:** actions performed by software \n\n### 1.4 Application\n\n​\tLocality principle has a wide-spread application in the computer field, for example, in the Search Engine area. Many search engine companies such as Google, using locality to arrange the outside data. Utilizing cache to speed up the searching process, sort the relative result and recent search log together, a typical example of the spatial and temporal locality.\n\n\n\n---\n\n\n\n## 2. Page Coloring\n\n​\tAfter wide application of virtual memory, people found that the Arbitrary Mapping between virtual page and physical page will cause the nonuniform use of Cache. Because of the locality principle, the data are mapping close to each other, resulting in the cache swap in and out constantly, causing thrashing.\n\n​\tBy 1985, MIPS raised the page coloring technique [^2]   to solve that problem. Simply put, Page coloring is a technique that splitting the pages into many groups with different color and using the middle bit of virtual mem block to represent the group and map it to the corresponding physical page. This method separates the interrelated data into different parts of memory and cache block, solving the thrashing problems.\n\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gvfslxmzuxj618v0u00xi02.jpg\" style=\"zoom:40%;\" />\n\n​\tPage coloring is easy to code, deploy and has a great improvement on system performance. After using page coloring the page non-assess correlation dropped significantly.[^3] today page coloring are being widely used in cache designing with different sample method.\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gvfsmp3635j60g50cw75c02.jpg\" style=\"zoom:60%;\" />\n\n\n\n## Reference\n\n[^1]: Denning, P. J. . Peter J. Denning. The Locality Principle. In Communication Networks and Computer Systems (J. Barria, Ed.). Imperial College Press (2006), 43-67. CHAPTER 4 The Locality Principle.\n[^2]: TAYLOR, G., DAVIES, P., ANDFARAWAY,D, M. The TLB slice—A low-cost high-speed address translation mechanism. In ISCA-1990.\n[^3]: Zhang, X., Dwarkadas, S., & Shen, K. (2009). Towards Practical Page Coloring-Based Multicore Cache Management. In *Proceedings of the 4th ACM European Conference on Computer Systems* (pp. 89–102). Association for Computing Machinery.\n\n","source":"_posts/OS/Locality_Principle.md","raw":"---\ntitle: Locality Principle\ndate: 2021-10-15 10:29:48\nindex_img: /img/OS/banner.png\ncategory: [OS]\ntags: [OS]\nmath: true\n---\n\n### 1.1 Intro\n\n​\tLocality Principle is a profound law of computing and has a wide application in many modern areas in computer science — virtual memory, cache, database, etc.  It is the combination of two locality aspects: \n\n- *(1) temporal locality*\n- *(2) spatial locality*\n\n​\tThe success of the locality principle attributes to the fact that locality works aline with human cognitive and coordinative behavior. *Divide and conquer* is the most common practice for humans when dealing with complex problems. We tend to break it into some small parts and work on them separately. Here is where the locality lies in. \n\n​\tUnderstanding the locality principle can benefit a lot, including making better use of cache, predicting the phase boundaries, and extending to many different aspects in computer science, even our daily lives.\n\n### 1.2 History\n\n​\tLooking backward, locality has emerged from the design of virtual memory systems back to 1959, the Atlas system. There were two main performance problems at that time. One is the address location problem, which is quickly solved by page table and TLB, while the another hard nut is the replacement problem of  the demand-paged virtual memory. Replacing the page that will not be used again for the longest time is a common belief, but obviously people can't estimate the next-use time for sure. \n\n​\t1966 Belady's study pointed out that the performance under certain replacement strategy primarily depended on the way how compiler grouped the code blocks onto pages. Shortly after that, thrashing problem was discovered and swiftly became the nightmare for companies using virtual memory. IBM OS360 even excluded the virtual memory, for example.\n\n​\tBy 1966,in Watson Lab, Belady and his partners had tested every replacement policy, and found the LRU (least recently used) replacement got the best performance, because of the reference clustering locality behavior. By using locality notion, MIT Project MAC defined the Intrinsic demand, the first kind of \"*Working Set*\" at the same year.\n\n​\tAs it is explained in Denning's paper[^1]\n\n> The working-set idea worked because the pages observed in the backward window were highly likely to be used again in the immediate future.\n\n​\t The underlying mechanism of it is temporal and spatial locality.\n\n### 1.3 Core \n\n​\tLocality principle hit the key of general program behavior, which is strongly connected with people's coding style when solving a problem — *Divide and Conquer*. This coding style is shown as temporal and spatial clustering on data structures. \n\n​\tFor instance, when people doing a loop, the variables inside the  loop are often changed constantly, which is a kind of temporal clustering. In terms of spatial clustering, Array is an example when we put data into it and access it sequentially. \n\n​\tThe Locality principle can be applied through a distance function $D(x,t)$ to measure temporal of spatial locality, and we use $D(x, t) < T$ to describe the locality set of $x$ at time $t$, and the working set model can be expressed by $W(t, T)$ , $T$ is the time window from the current time $t$. It is a efficient way to track the phases of a program in a dynamic manner, instead of the traditional *static representation* following *Zipf Law*\n\n​\tThe modern model of locality are more about context-awareness with four key ideas\n\n- **An Observer:** Agent doing tasks with the help of software\n- **Neighborhoods:** Group of obejcts \n- **Inference:** Method measures the content of neighborhoods\n- **Optimal Actions:** actions performed by software \n\n### 1.4 Application\n\n​\tLocality principle has a wide-spread application in the computer field, for example, in the Search Engine area. Many search engine companies such as Google, using locality to arrange the outside data. Utilizing cache to speed up the searching process, sort the relative result and recent search log together, a typical example of the spatial and temporal locality.\n\n\n\n---\n\n\n\n## 2. Page Coloring\n\n​\tAfter wide application of virtual memory, people found that the Arbitrary Mapping between virtual page and physical page will cause the nonuniform use of Cache. Because of the locality principle, the data are mapping close to each other, resulting in the cache swap in and out constantly, causing thrashing.\n\n​\tBy 1985, MIPS raised the page coloring technique [^2]   to solve that problem. Simply put, Page coloring is a technique that splitting the pages into many groups with different color and using the middle bit of virtual mem block to represent the group and map it to the corresponding physical page. This method separates the interrelated data into different parts of memory and cache block, solving the thrashing problems.\n\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gvfslxmzuxj618v0u00xi02.jpg\" style=\"zoom:40%;\" />\n\n​\tPage coloring is easy to code, deploy and has a great improvement on system performance. After using page coloring the page non-assess correlation dropped significantly.[^3] today page coloring are being widely used in cache designing with different sample method.\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gvfsmp3635j60g50cw75c02.jpg\" style=\"zoom:60%;\" />\n\n\n\n## Reference\n\n[^1]: Denning, P. J. . Peter J. Denning. The Locality Principle. In Communication Networks and Computer Systems (J. Barria, Ed.). Imperial College Press (2006), 43-67. CHAPTER 4 The Locality Principle.\n[^2]: TAYLOR, G., DAVIES, P., ANDFARAWAY,D, M. The TLB slice—A low-cost high-speed address translation mechanism. In ISCA-1990.\n[^3]: Zhang, X., Dwarkadas, S., & Shen, K. (2009). Towards Practical Page Coloring-Based Multicore Cache Management. In *Proceedings of the 4th ACM European Conference on Computer Systems* (pp. 89–102). Association for Computing Machinery.\n\n","slug":"OS/Locality_Principle","published":1,"updated":"2026-02-03T05:42:14.440Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvi00357uitbe5k5e6e","content":"<h3 id=\"1-1-Intro\"><a href=\"#1-1-Intro\" class=\"headerlink\" title=\"1.1 Intro\"></a>1.1 Intro</h3><p>​    Locality Principle is a profound law of computing and has a wide application in many modern areas in computer science — virtual memory, cache, database, etc.  It is the combination of two locality aspects: </p>\n<ul>\n<li><em>(1) temporal locality</em></li>\n<li><em>(2) spatial locality</em></li>\n</ul>\n<p>​    The success of the locality principle attributes to the fact that locality works aline with human cognitive and coordinative behavior. <em>Divide and conquer</em> is the most common practice for humans when dealing with complex problems. We tend to break it into some small parts and work on them separately. Here is where the locality lies in. </p>\n<p>​    Understanding the locality principle can benefit a lot, including making better use of cache, predicting the phase boundaries, and extending to many different aspects in computer science, even our daily lives.</p>\n<h3 id=\"1-2-History\"><a href=\"#1-2-History\" class=\"headerlink\" title=\"1.2 History\"></a>1.2 History</h3><p>​    Looking backward, locality has emerged from the design of virtual memory systems back to 1959, the Atlas system. There were two main performance problems at that time. One is the address location problem, which is quickly solved by page table and TLB, while the another hard nut is the replacement problem of  the demand-paged virtual memory. Replacing the page that will not be used again for the longest time is a common belief, but obviously people can’t estimate the next-use time for sure. </p>\n<p>​    1966 Belady’s study pointed out that the performance under certain replacement strategy primarily depended on the way how compiler grouped the code blocks onto pages. Shortly after that, thrashing problem was discovered and swiftly became the nightmare for companies using virtual memory. IBM OS360 even excluded the virtual memory, for example.</p>\n<p>​    By 1966,in Watson Lab, Belady and his partners had tested every replacement policy, and found the LRU (least recently used) replacement got the best performance, because of the reference clustering locality behavior. By using locality notion, MIT Project MAC defined the Intrinsic demand, the first kind of “<em>Working Set</em>“ at the same year.</p>\n<p>​    As it is explained in Denning’s paper<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Denning, P. J. . Peter J. Denning. The Locality Principle. In Communication Networks and Computer Systems (J. Barria, Ed.). Imperial College Press (2006), 43-67. CHAPTER 4 The Locality Principle.\n\">[1]</span></a></sup></p>\n<blockquote>\n<p>The working-set idea worked because the pages observed in the backward window were highly likely to be used again in the immediate future.</p>\n</blockquote>\n<p>​     The underlying mechanism of it is temporal and spatial locality.</p>\n<h3 id=\"1-3-Core\"><a href=\"#1-3-Core\" class=\"headerlink\" title=\"1.3 Core\"></a>1.3 Core</h3><p>​    Locality principle hit the key of general program behavior, which is strongly connected with people’s coding style when solving a problem — <em>Divide and Conquer</em>. This coding style is shown as temporal and spatial clustering on data structures. </p>\n<p>​    For instance, when people doing a loop, the variables inside the  loop are often changed constantly, which is a kind of temporal clustering. In terms of spatial clustering, Array is an example when we put data into it and access it sequentially. </p>\n<p>​    The Locality principle can be applied through a distance function $D(x,t)$ to measure temporal of spatial locality, and we use $D(x, t) &lt; T$ to describe the locality set of $x$ at time $t$, and the working set model can be expressed by $W(t, T)$ , $T$ is the time window from the current time $t$. It is a efficient way to track the phases of a program in a dynamic manner, instead of the traditional <em>static representation</em> following <em>Zipf Law</em></p>\n<p>​    The modern model of locality are more about context-awareness with four key ideas</p>\n<ul>\n<li><strong>An Observer:</strong> Agent doing tasks with the help of software</li>\n<li><strong>Neighborhoods:</strong> Group of obejcts </li>\n<li><strong>Inference:</strong> Method measures the content of neighborhoods</li>\n<li><strong>Optimal Actions:</strong> actions performed by software </li>\n</ul>\n<h3 id=\"1-4-Application\"><a href=\"#1-4-Application\" class=\"headerlink\" title=\"1.4 Application\"></a>1.4 Application</h3><p>​    Locality principle has a wide-spread application in the computer field, for example, in the Search Engine area. Many search engine companies such as Google, using locality to arrange the outside data. Utilizing cache to speed up the searching process, sort the relative result and recent search log together, a typical example of the spatial and temporal locality.</p>\n<hr>\n<h2 id=\"2-Page-Coloring\"><a href=\"#2-Page-Coloring\" class=\"headerlink\" title=\"2. Page Coloring\"></a>2. Page Coloring</h2><p>​    After wide application of virtual memory, people found that the Arbitrary Mapping between virtual page and physical page will cause the nonuniform use of Cache. Because of the locality principle, the data are mapping close to each other, resulting in the cache swap in and out constantly, causing thrashing.</p>\n<p>​    By 1985, MIPS raised the page coloring technique <sup id=\"fnref:2\" class=\"footnote-ref\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"TAYLOR, G., DAVIES, P., ANDFARAWAY,D, M. The TLB slice—A low-cost high-speed address translation mechanism. In ISCA-1990.\n\">[2]</span></a></sup>   to solve that problem. Simply put, Page coloring is a technique that splitting the pages into many groups with different color and using the middle bit of virtual mem block to represent the group and map it to the corresponding physical page. This method separates the interrelated data into different parts of memory and cache block, solving the thrashing problems.</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gvfslxmzuxj618v0u00xi02.jpg\" style=\"zoom:40%;\"></p>\n<p>​    Page coloring is easy to code, deploy and has a great improvement on system performance. After using page coloring the page non-assess correlation dropped significantly.<sup id=\"fnref:3\" class=\"footnote-ref\"><a href=\"#fn:3\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Zhang, X., Dwarkadas, S., &amp; Shen, K. (2009). Towards Practical Page Coloring-Based Multicore Cache Management. In Proceedings of the 4th ACM European Conference on Computer Systems (pp. 89–102). Association for Computing Machinery.\n\">[3]</span></a></sup> today page coloring are being widely used in cache designing with different sample method.</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gvfsmp3635j60g50cw75c02.jpg\" style=\"zoom:60%;\"></p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><section class=\"footnotes\"><div class=\"footnote-list\"><ol><li><span id=\"fn:1\" class=\"footnote-text\"><span>Denning, P. J. . Peter J. Denning. The Locality Principle. In Communication Networks and Computer Systems (J. Barria, Ed.). Imperial College Press (2006), 43-67. CHAPTER 4 The Locality Principle.\n<a href=\"#fnref:1\" rev=\"footnote\" class=\"footnote-backref\"> ↩</a></span></span></li><li><span id=\"fn:2\" class=\"footnote-text\"><span>TAYLOR, G., DAVIES, P., ANDFARAWAY,D, M. The TLB slice—A low-cost high-speed address translation mechanism. In ISCA-1990.\n<a href=\"#fnref:2\" rev=\"footnote\" class=\"footnote-backref\"> ↩</a></span></span></li><li><span id=\"fn:3\" class=\"footnote-text\"><span>Zhang, X., Dwarkadas, S., &amp; Shen, K. (2009). Towards Practical Page Coloring-Based Multicore Cache Management. In <em>Proceedings of the 4th ACM European Conference on Computer Systems</em> (pp. 89–102). Association for Computing Machinery.\n<a href=\"#fnref:3\" rev=\"footnote\" class=\"footnote-backref\"> ↩</a></span></span></li></ol></div></section>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"1-1-Intro\"><a href=\"#1-1-Intro\" class=\"headerlink\" title=\"1.1 Intro\"></a>1.1 Intro</h3><p>​    Locality Principle is a profound law of computing and has a wide application in many modern areas in computer science — virtual memory, cache, database, etc.  It is the combination of two locality aspects: </p>\n<ul>\n<li><em>(1) temporal locality</em></li>\n<li><em>(2) spatial locality</em></li>\n</ul>\n<p>​    The success of the locality principle attributes to the fact that locality works aline with human cognitive and coordinative behavior. <em>Divide and conquer</em> is the most common practice for humans when dealing with complex problems. We tend to break it into some small parts and work on them separately. Here is where the locality lies in. </p>\n<p>​    Understanding the locality principle can benefit a lot, including making better use of cache, predicting the phase boundaries, and extending to many different aspects in computer science, even our daily lives.</p>\n<h3 id=\"1-2-History\"><a href=\"#1-2-History\" class=\"headerlink\" title=\"1.2 History\"></a>1.2 History</h3><p>​    Looking backward, locality has emerged from the design of virtual memory systems back to 1959, the Atlas system. There were two main performance problems at that time. One is the address location problem, which is quickly solved by page table and TLB, while the another hard nut is the replacement problem of  the demand-paged virtual memory. Replacing the page that will not be used again for the longest time is a common belief, but obviously people can’t estimate the next-use time for sure. </p>\n<p>​    1966 Belady’s study pointed out that the performance under certain replacement strategy primarily depended on the way how compiler grouped the code blocks onto pages. Shortly after that, thrashing problem was discovered and swiftly became the nightmare for companies using virtual memory. IBM OS360 even excluded the virtual memory, for example.</p>\n<p>​    By 1966,in Watson Lab, Belady and his partners had tested every replacement policy, and found the LRU (least recently used) replacement got the best performance, because of the reference clustering locality behavior. By using locality notion, MIT Project MAC defined the Intrinsic demand, the first kind of “<em>Working Set</em>“ at the same year.</p>\n<p>​    As it is explained in Denning’s paper<sup id=\"fnref:1\" class=\"footnote-ref\"><a href=\"#fn:1\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Denning, P. J. . Peter J. Denning. The Locality Principle. In Communication Networks and Computer Systems (J. Barria, Ed.). Imperial College Press (2006), 43-67. CHAPTER 4 The Locality Principle.\n\">[1]</span></a></sup></p>\n<blockquote>\n<p>The working-set idea worked because the pages observed in the backward window were highly likely to be used again in the immediate future.</p>\n</blockquote>\n<p>​     The underlying mechanism of it is temporal and spatial locality.</p>\n<h3 id=\"1-3-Core\"><a href=\"#1-3-Core\" class=\"headerlink\" title=\"1.3 Core\"></a>1.3 Core</h3><p>​    Locality principle hit the key of general program behavior, which is strongly connected with people’s coding style when solving a problem — <em>Divide and Conquer</em>. This coding style is shown as temporal and spatial clustering on data structures. </p>\n<p>​    For instance, when people doing a loop, the variables inside the  loop are often changed constantly, which is a kind of temporal clustering. In terms of spatial clustering, Array is an example when we put data into it and access it sequentially. </p>\n<p>​    The Locality principle can be applied through a distance function $D(x,t)$ to measure temporal of spatial locality, and we use $D(x, t) &lt; T$ to describe the locality set of $x$ at time $t$, and the working set model can be expressed by $W(t, T)$ , $T$ is the time window from the current time $t$. It is a efficient way to track the phases of a program in a dynamic manner, instead of the traditional <em>static representation</em> following <em>Zipf Law</em></p>\n<p>​    The modern model of locality are more about context-awareness with four key ideas</p>\n<ul>\n<li><strong>An Observer:</strong> Agent doing tasks with the help of software</li>\n<li><strong>Neighborhoods:</strong> Group of obejcts </li>\n<li><strong>Inference:</strong> Method measures the content of neighborhoods</li>\n<li><strong>Optimal Actions:</strong> actions performed by software </li>\n</ul>\n<h3 id=\"1-4-Application\"><a href=\"#1-4-Application\" class=\"headerlink\" title=\"1.4 Application\"></a>1.4 Application</h3><p>​    Locality principle has a wide-spread application in the computer field, for example, in the Search Engine area. Many search engine companies such as Google, using locality to arrange the outside data. Utilizing cache to speed up the searching process, sort the relative result and recent search log together, a typical example of the spatial and temporal locality.</p>\n<hr>\n<h2 id=\"2-Page-Coloring\"><a href=\"#2-Page-Coloring\" class=\"headerlink\" title=\"2. Page Coloring\"></a>2. Page Coloring</h2><p>​    After wide application of virtual memory, people found that the Arbitrary Mapping between virtual page and physical page will cause the nonuniform use of Cache. Because of the locality principle, the data are mapping close to each other, resulting in the cache swap in and out constantly, causing thrashing.</p>\n<p>​    By 1985, MIPS raised the page coloring technique <sup id=\"fnref:2\" class=\"footnote-ref\"><a href=\"#fn:2\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"TAYLOR, G., DAVIES, P., ANDFARAWAY,D, M. The TLB slice—A low-cost high-speed address translation mechanism. In ISCA-1990.\n\">[2]</span></a></sup>   to solve that problem. Simply put, Page coloring is a technique that splitting the pages into many groups with different color and using the middle bit of virtual mem block to represent the group and map it to the corresponding physical page. This method separates the interrelated data into different parts of memory and cache block, solving the thrashing problems.</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gvfslxmzuxj618v0u00xi02.jpg\" style=\"zoom:40%;\"></p>\n<p>​    Page coloring is easy to code, deploy and has a great improvement on system performance. After using page coloring the page non-assess correlation dropped significantly.<sup id=\"fnref:3\" class=\"footnote-ref\"><a href=\"#fn:3\" rel=\"footnote\"><span class=\"hint--top hint--rounded\" aria-label=\"Zhang, X., Dwarkadas, S., &amp; Shen, K. (2009). Towards Practical Page Coloring-Based Multicore Cache Management. In Proceedings of the 4th ACM European Conference on Computer Systems (pp. 89–102). Association for Computing Machinery.\n\">[3]</span></a></sup> today page coloring are being widely used in cache designing with different sample method.</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gvfsmp3635j60g50cw75c02.jpg\" style=\"zoom:60%;\"></p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><section class=\"footnotes\"><div class=\"footnote-list\"><ol><li><span id=\"fn:1\" class=\"footnote-text\"><span>Denning, P. J. . Peter J. Denning. The Locality Principle. In Communication Networks and Computer Systems (J. Barria, Ed.). Imperial College Press (2006), 43-67. CHAPTER 4 The Locality Principle.\n<a href=\"#fnref:1\" rev=\"footnote\" class=\"footnote-backref\"> ↩</a></span></span></li><li><span id=\"fn:2\" class=\"footnote-text\"><span>TAYLOR, G., DAVIES, P., ANDFARAWAY,D, M. The TLB slice—A low-cost high-speed address translation mechanism. In ISCA-1990.\n<a href=\"#fnref:2\" rev=\"footnote\" class=\"footnote-backref\"> ↩</a></span></span></li><li><span id=\"fn:3\" class=\"footnote-text\"><span>Zhang, X., Dwarkadas, S., &amp; Shen, K. (2009). Towards Practical Page Coloring-Based Multicore Cache Management. In <em>Proceedings of the 4th ACM European Conference on Computer Systems</em> (pp. 89–102). Association for Computing Machinery.\n<a href=\"#fnref:3\" rev=\"footnote\" class=\"footnote-backref\"> ↩</a></span></span></li></ol></div></section>"},{"title":"计算理论基础笔记","date":"2021-07-06T01:42:20.000Z","index_img":"/img/PNP.webp","math":true,"_content":"\n# 计算理论基础\n\n## 第一章 预备知识\n\n重点：\n- 符号表示，可能在问答题里面出现\n\n### 1.1 定理及其证明方法\n\n- 形式系统\n1. **基本符号** *（常量符号、变量符号、运算符等抽象字符）*\n2. **形成规则** *(构造各种语言的方法规则)*\n3. **公理** *（无需经过证明，正确性得到公认的语句）*\n4. **推理规则** *（用于得到新的合法语句）*\n\n- *如何证明一个语句为真*\n\n1. 每个语句或者是公理，或者由前面的语句自然导出\n2. 最后一个语句就是所要证明的语句\n\n- **定理证明方法**\n\n1. 演绎法\n2. 反证法/归谬法\n3. 归纳法、第二归纳法\n\n### 1.2 集合及其基本运算\n\n1. 集合描述方法\n\n- 列举法 $A=\\{a,b,c,d\\}$\n- 模式表示法 $\\{x|P(x)\\}$\n\n2. 集合运算及定理\n\n- 定理1.9 德摩根定理\n\n$\\quad \\quad \\bar{A \\cap B} = \\bar A \\cup \\bar B$\n$\\quad \\quad \\bar{A \\cup B} = \\bar A \\cap \\bar B$\n\n### 1.3 图和树简介\n\n- **图** ：顶点集合以及边集合\n- 有向图、无向图\n- 通路、回路\n- 邻接矩阵\n\n- **树** \n- 树中每一个顶点到另一个顶点均有一条通路，称该顶点为树的根\n- 树中一定没有回路\n- 仅一个顶点(根节点)没有前导顶点\n- 一定存在没有后继的顶点\n\n### 1.4 字母表、字符串和语言\n\n- 自然语言\n-- 人类彼此相互交流的工具，由基本符号构成，如日语俄语等\n- **形式语言**\n-- 用于需要严格描述的领域，构成基础为“符号”\n\n\n\n- **字符表**是符号的集合，记为 $\\Sigma$\n- $\\Sigma$ 上的符号串\n-- $\\Sigma$ 上的符号以任意顺序拼接起来构成\n-- 任何符号可以重复出现\n- **定义1.23**\n-- 对于任何给定的字符表 $\\Sigma$，$\\Sigma$ 上的字符串集合称作 $\\Sigma$ 上的语言\n- **定义1.24**\n-- 设$L$是某个字母表上的一个语言，若 $L$ 中任何字符串都不是另一个字符串的真前缀，则$L$ 具有**前缀性质**\n- **定义1.25**\n-- 设 $L_{1}$ 为 $\\Sigma_{1}$ 的语言, $L_{2}$ 为 $\\Sigma_{2}$ 的语言，则  $L_{1}$ 和 $L_{2}$ 的连接 $L_{1}L_{2} = \\{xy | x \\in L_{1} and \\ y \\in L_{2}\\}$\n- **定义1.26**\n-- **语言 $L$ 的闭包 $L^{*}$ **\n-- 以任意次序连接L中任意多个字符串所组成的集合\n-- 只要 $L$ 中包含至少一个元素, $L^{*}$ 就为无穷集\n\n\n---\n\n\n## 第二章 文法理论\n重点：\n- ⽂法分类（给定⼀个语⾔集合，判定是0123型⽂法，熟悉每个⽂法的判定⽅法）（最重要） \n- 上下⽂有关⽂法上下⽂信息的获得,1'型⽂法如何转化为1型⽂法\n\n### 2.1 文法定义\n- 四元组 $G=(V,T,P,S)$\n1. V是变元符有限集 Variables\n2. T是终结符有限集 Termination\n3. P是生成式有限集 (Production?)\n4. S∈V，为文法G的开始符 Start\n\n### 2.2 派生\n**直接派生**\n若 $\\alpha = \\alpha_{1} A \\alpha_{2}, \\ \\gamma=\\alpha_{1}\\beta\\alpha_{2}$ ，且 $A\\to\\beta$ 为P中一个生成式，则 $\\alpha \\mathop{\\Rightarrow}\\limits_{G}^{}\\gamma$\n，称由 $\\alpha$ 直接派生出 $\\gamma$\n\n**派生**\n将 $\\mathop{\\Rightarrow}\\limits_{G}^{}$ 扩充为 $\\hat{\\mathop{\\Rightarrow}\\limits_{G}^{}}$，则为派生\n\n$\\quad (\\hat{\\mathop{\\Rightarrow}\\limits_{}} 表示多步直接派生)$\n\n\n\n### 2.3 文法分类\n**1. 短语结构文法 PSG (0型文法)**\n- **特点：** 不加限制\n- **对应语言：** 短语结构语言 PSL\n- **对应自动机：** 图灵机 TM\n- **形式：** $\\alpha\\to\\beta,\\ \\alpha,\\beta\\in(V \\cup T)^{*}$ 且 $\\alpha\\ne\\epsilon$\n\n**2. 上下文有关文法 CSG (1型文法)**\n- **特点：** 每个终结符$\\to$终结符，满足前者偏序后者 ($\\leq$)\n- **对应语言：** 上下文有关语言 CSL\n- **对应自动机:** 线性有界自动机 LBA\n- **形式：** $\\forall \\alpha\\to\\beta\\in P$ , 满足 $|\\alpha|\\leq |\\beta|$ 并且 $\\alpha,\\beta\\in(V \\cup T)^{*}$ 且 $\\alpha\\ne\\epsilon$\n\n**3. 上下文无关文法 CFG (2型文法)**\n- **特点：** 都有变元推出变元或终结符或者变元与终结符的连接\n- **对应语言：** 上下文无关语言 CFL\n- **对应自动机：** 下推自动机 PDA\n- **形式：** 对所有P中生成式都有，$A\\to\\beta \\quad \\beta\\in(V \\cup T)^{*},\\ A \\in V$\n\n**4. 正规文法 RG (3型文法)**\n- **特点 ：** 变元推出终结符或推出终结符+变元\n- **对应语言：** 正规语言 RL\n- **对应自动机：** 有穷自动机 DFA\n- **形式：** 对所有P中生成式都有，$A\\to a\\ 或\\ A\\to aB \\quad a\\in T \\cup {\\epsilon},\\ A,B \\in V$\n\n\n\n\n### 2.4 文法等价\n\n对于两个文法 $G_{1}=(V_{1},\\ T_1,\\ P_1,\\ S_1)$ 与 $G_{2}=(V_{2},\\ T_2,\\ P_2,\\ S_2)$，若$L(G_1)=L(G_2)$，则文法等价\n\n\n### 2.5 1°型文法\n- **特点：** 看形式\n- **形式：** 对文法 $G=(V,\\ T,\\ P,\\ S)$，若P中每个生成式都有 $\\alpha_1 A \\alpha_2 \\to \\alpha_1 \\beta \\alpha_2$形式，$A \\in V, \\ \\alpha_1,\\alpha_2\\in(V \\cup T)^{*}$, $\\beta \\in {(V \\cup T)}^{+}$ \n\n\n#### 1、 1型文法和1°型文法转换\n\n- 定理：对于任何1型文法G，一定存在一个 $1^{°}$ 型文法G',使得L(G)=L(G') 反之亦然。\n\n- $\\Rightarrow$ \n对于任何生成式 $\\alpha_1 A \\alpha_2 \\to \\alpha_1 \\beta \\alpha_2$ ,恒有 $|\\alpha_1 A \\alpha_2| \\leq |\\alpha_1 \\beta \\alpha_2|$ \n即 $1^{°}$ 型文法一定是1型文法\n\n- $\\Leftarrow$ \n- 第一步：将G变为G''\n    - 这一步构造出生成式只有两种形式的G''\n    - 其中 $V^{''}=V \\cup M, M=\\{[a] | a\\in T\\}$\n    - $P^{''}=\\overline{P} \\cup \\{ [a] \\to a | a \\in T \\}$\n\n- 第二步：G'' 中生成式形式分类讨论\n    - （1） $A\\to\\beta$ (A∈V，或为新引入变元[a])，其已经是1°文法\n    - （2）$A_1A_2...A_n\\to B_1B_2...B_n,\\quad (n\\ge 2,\\ m\\ge n)$ \n        - 解决方法：引入一组新变元用于过渡\n        - 1. $A_1A_2...A_n \\to C_1A_2...A_n$ \n        - 2. $C_1A_2...A_n \\to C_1C_2...A_n$ \n        - 3. $C_1C_2...C_{n-1}A_n \\to C_1C_2...C_n$ \n        - 4. $C_1C_2...C_n \\to B_1C_2...C_n$ \n        - 5. $B_1C_2...C_n \\to B_1B_2...C_n$ \n        - 6. $B_1B_2...B_{n-1}C_n \\to B_1B_2...B_n$\n        - 完成 $A_1A_2...A_n\\to B_1B_2...B_n$\n\n\n\n### 2.6 上下文在文法中的体现\n#### 上下文有关文法（1型文法）的上下文\n- 可用1°型文法解释，$\\alpha_1 A \\alpha_2 \\to \\alpha_1 \\beta \\alpha_2$，其中$\\alpha_1\\ 和\\ \\alpha_2$ 是A的上下文，在该上下文语境中A可替换为β\n- 在另外上下文语境中可替换为别的字符串，例如另有生成式 $\\alpha_{1'} A \\alpha_{2'} \\to \\alpha_{1'} \\gamma \\alpha_{2'}$ \n\n#### 上下文无关文法（2型文法）的上下文\n- $A\\to \\beta$ 变元A不管出现在任何地方都可替换为β，与上下文无关\n\n\n### 2.7 语法分析树\n- 定义：//TODO\n\n\n#### 边缘\n- 对于派生树，其叶节点标记从左到右收集起来的字符串，称为该派生树的边缘\n\n- **相关定理：** G为上下文无关文法，那么S可以派生出α当且仅当在G中存在一颗边缘为α的派生树\n证明: //TODO\n\n#### 多义和固有多义\n不重要 TODO\n\n\n----\n\n\n## 第三章 有穷自动机和正规表达式\n重点\n- 掌握⼏类⾃动机的特点（FM, NFM, 有空动作的FM），⼏种FM之间如何进⾏变换（等价性），例：如何进⾏ 空动作的消除（空闭包的转换） \n- 掌握正则表达式和正规集，正规集和有穷⾃动机的关系（实际上在第四章） \n- 了解摩尔机和米里机的定义和功能（⾮重点）\n\n\n\n### 3.1 确定有穷自动机 DFA\n#### 1. 定义\n- 有穷自动机（FA or DFA）是一个五元组 $M=(Q,\\ \\Sigma, \\delta,\\ q_0, F)$\n    - 1. Q是有穷状态集\n    - 2. $\\Sigma$ 是有穷的输入字符表\n    - 3. $\\delta$ 是转移函数，将 $Q\\times \\Sigma$ 映射到Q\n    - 4. $q_0\\in Q$ 是初始状态\n    - 5. $F\\subset Q 是终结状态$\n\n#### 2.扩充转移函数\n对于 FA $M=(Q,\\ \\Sigma, \\delta,\\ q_0, F)$ 其扩充转移函数是 $\\hat\\delta$ 是$Q\\times\\Sigma^*$ 到 Q 的映射\n- 1. $\\hat{\\delta}(q,\\epsilon) = q$ \n- 2. $\\hat\\delta(q,wa)=\\delta(\\hat\\delta(q,w),a)$ \n\n- 递归定义\n接受一个输入，然后进行状态转移，再接受下一个。输入一个串得到最后状态。\n\n#### 3.有穷自动机接受语言\n\n$L(M)=\\{x| \\delta(q_0,x)\\in F\\}$\n若 $\\delta(q_0,x)=p\\in F$ ，则称字符串x，被M接受，意义上来理解，就是输入x，M从q0转移到终结状态F\n\n\n\n### 3.2 非确定有穷自动机 NFA\n#### 1. 定义\n- 非确定的有穷自动机（NFA）五元组 $G=(Q,\\Sigma,\\delta,q_0,F)$\n    - 1. Q是有穷状态集\n    - 2. $\\Sigma$ 是有穷输入字符表\n    - 3. $\\delta$ 是非确定的状态转移函数，$Q\\times \\Sigma$到$2^Q$ 上的映射\n    - 4. $q_0\\in Q$ 是初始状态\n    - 5. $F \\subset Q$ 是终结状态集\n\n#### 2. 转移函数一般形式：\n$\\delta(q,a)=\\{p_1,.....,p_k\\} \\quad p_i\\in Q$ 或者 $\\delta(q,a)=\\emptyset$\n    \n#### 3. 扩充转移函数\n类似有穷自动机定义，输入一个串，对每个字符进行状态转移，最后得出的最终状态**集合**\n\n#### 4. 接受条件\n如果 $\\delta(q_0,\\ x)\\cap F$ 非空，则称字符串 $x$ 被 $M$ 接受\n\n\n\n### 3.3 NFA与DFA的等价性\n- 当给定某类中的一个有穷自动机，一定存在另一类中的一个有穷自动机，两者接受同样集合，则称二者等价。\n\n#### 1. NFA与DFA等价\n- 证明： 构造法 构造 DFA，其定义为\n    - 对于Q',其将NFA中Q的每一个子集作为Q'中的一个状态，若子集为 $\\{q_1,q_2,..,q_n\\}$ ，则Q'中状态记为 $[q_1,q_2,..,q_n]$ \n    - 对于 $\\delta^{'}$ ，定义为$$\\delta^{'}([q_1,q_2,..,q_n],a) = p_1,p_2,..,p_n \\\\ iff \\\\ \\delta(\\{q_1,q_2,..,q_n\\},a) = p_1,p_2,..,p_n $$ \n\n进一步证明 TODO\n\n#### 2. NFA至DFA的转换\n构造方法，从NFA出发，并不需要直接一步写出Q的幂集，而是看NFA中存在哪些状态。\n例题3.4\n\n#### 3. 具有$\\epsilon$动作的有穷自动机\n在不接受输入符号，输入为$\\epsilon$ 时能做转移动作\n即转移函数 $\\delta$ 扩充至$Q\\times (\\Sigma \\cup \\{\\epsilon\\})$ 到 $2^Q$ 的映射\n\n- $\\epsilon -CLOSURE(q)$\n直白的说，就是如果NFA只接受空动作能够到达的状态集合\n\n- 定义\n    - 1. $q\\in \\epsilon -CLOSURE(q)$\n    - 2. 递归，若$p\\in \\epsilon -CLOSURE(q)$，则$\\delta(q, \\epsilon)\\in \\epsilon -CLOSURE(q)$\n    - 规定：$\\epsilon -CLOSURE(P) = \\mathop{\\cup}\\limits_{q\\in P}\\epsilon -CLOSURE(q)$\n\n- 扩充函数\n非简单扩充，就是说 $\\hat\\delta(q,a) \\neq \\delta(q,a)$，因为空输入也可以转移状态，其他差不多\n\n- 接受语言\n$L(M)=\\{w|\\hat\\delta(q_0,w) \\cap F \\}$ 非空\n*增加空动作没有增加表达能力，即有空动作和没有空动作的NFA等价*\n\n- 空动作NFA与NFA等价\n构造法，对具有空动作的NFA M构造 $M'=(Q',\\Sigma^{'},\\delta^{'},q_0,F^{'})$，\n\n$\\hat \\delta(q,a)$ 即 $\\delta(\\epsilon -CLOSURE(q), a)$\n- $\\delta^{'}(q,a) = \\hat\\delta(q,a)$\n- $$ F^{'}=\\left\\{\n    \\begin{array}{rcl}\n        F\\cup \\{q_0\\} && {如果\\epsilon-CLOSURE(q_0)\\cap F非空}\\\\\n        F && {否则}\n    \\end{array} \\right. $$\n证明对 |x| 进行归纳 TODO\n\n\n\n### 3.4 正规表达式和正规集\n- 正规表达式递归定义\n    - 1. $\\phi$ 是一个正规表达式，代表空集\n    - 2. $\\epsilon$ 是一个正规表达式，代表集合 $\\{\\epsilon\\}$ \n    - 3. 对于 $\\Sigma$ 中每个符号a，a是正规表达式，代表集合{a}\n    - 4. 如果r和s是正规表达式，分别表示集合R和S，则(r+s),(rs)和(r*)是正规表达式，分别表示 $R \\cup S$、$RS$ 和 $R^*$ \n\n正规表达式代表的集合称为正规集\n\n<img src=\"/uploads/upload_e70fbfc8866d389b084873dd20ba2e72.png\" style=\"height: 300px;\">\n\n- 运算优先级\n$* > 连接 > +$\n\n- 对应自动机\n有穷自动机 DFA\n有穷自动机所能接受的集合类和正规表达式所能表示的集合类统称为正规集类\n\n- 定理3.3 r为正规表达式，则有一个具有空动作的NFA接受L(r)\n归纳法证明，归纳r的构造次数\n- 基础：r构造次数为0，即r是 $\\epsilon$ 、$\\phi$ 、$\\Sigma$ 中某个元素a\n- 归纳\n    - r = r1 + r2\n    归纳假设有 M1 接受 r1, M2 接受 r2\n    则构造一个M将两个M1,M2并起即可，形式说明TODO\n    - r = r1r2\n    归纳假设有 M1 接受 r1, M2 接受 r2\n    则构造一个M先过M1再过M2即可，形式说明TODO\n    - r = r1*\n    归纳假设有 M1 接受 r1,\n    则扩展一下M1，让其终结状态可以回到开始状态重复判断即可，形式说明TODO\n    \n- 定理3.4 如果L被DFA接受，则L可用正规表达式表示\n对各状态进行编号，记 $R_{ij}^k=\\{x\\mid \\delta(q_i,x)=q_j，中间不经过编号大于k的状态 \\}$ ，有递推式 $R_{ij}^k=R_{ik}^{k-1}(R_{kk}^{k-1})^*R_{kj}^{k-1}\\cup R_{ij}^{k-1}$  ，然后归纳证明 $R_{ij}^k$ 可用正规表达式表示\n\n\n\n### 3.5 具有输出的有穷自动机\n1. 摩尔机\n2. 米里机\n\n非重点\n\n\n\n---\n\n\n\n## 第四章 正规文法与正规集的性质(重要)\n- 缩胀定理（重点），反证法证明 \n- 极⼩化的处理，掌握极⼩化的算法（过程）（明示了快背），如何优化有穷⾃动机 \n- ⻨⻄尔-尼诺德定理，需要掌握 \n\n\n### 4.1 正规文法与有穷自动机的关系\n\n- **Th4.1**\n-- 设 $L$ 被某个正规文法 $G$ 产生，则 $L$ 可被某个有穷自动机接受\n\n\n- **Th4.2**\n-- 设 $L$ 被某个DFA $M$ 接受， 则 $L$ 可被某个正规文法产生\n\n构造方法：\n- $A\\to aB$ 对应 $\\delta(A,a)=B$\n- $A\\to a$ 对应 $\\delta(A,a)=f\\in F$\n\n### 4.2 正规集的缩胀定理\n\n1. **有穷自动机表达能力有限**\n\n2. **Th4.3 正规集的缩胀定理(pumping Lemma)：存在整数 $k \\geq 0$ ，对于任意串 $x, y, z$ 这里 $xyz \\in A$， 只要$|y| \\ge k$ ，就可以将 $y$ 写成 $y=uvw, \\quad v \\ne \\sigma$ ，并且对于任何 $i \\ge 0$，都有 $xuv^{i}wz \\in A$**\n- 证明：定理的直观含义为：如果 $A$ 是正规集，那么当它的元素含有**足够长**的子串 $y$ 时（x与y的长短不重要）， $y$ 就一定包含一个非空的子串 $v$ （$u, w$ 的长短不重要），这个子串 $v$ 可以“膨胀”任意多次 （$i > 0$），或者被“删除” （$i = 0$），而 $xuv^{i}wz$ 仍然属于 $A$\n\n- 设 $k$ 是接受正规集 $A$ 的 $DFA$ 状态数，因为 $y$ 的长度大于或等于k， 则 $DFA$ 在扫视 $y$ 的过程中，必然出现重复的状态，串 $v$ 就是该状态相邻的两次出现过程中扫视过的子串。\n\n$$\n\\sigma(q_{1}, u)=p, \\sigma(p, v)=p, \\sigma(p, w)=q_2\n$$\n\n其余的推理过程与例2.10的分析相同\n\n- *正规集的缩胀定理经常用来指明某些集合不是正规集，通常就是反证法，大家都懂的。*\n\n### 4.3 正规集的封闭性质与判定算法\n\n- 在并、连接和闭包运算下是封闭的\n- 在补运算下封闭，即若 $L$ 是正规集，且 $L\\subseteq\\Sigma^{*}$ ， 则 $\\Sigma^{*}-L$ 也是正规的\n- 在交运算下封闭\n- 在商运算下封闭（暂且理解：两个正规集做商运算，其结果必然是正规集）\n\n\n\n- *Th4.9*\n具有n个状态的有穷自动机具有如下性质：\n    - 1)它接受的集合非空，当且仅当它接受一个长度小于n的字符串 \n    - 2）它接受的集合是无穷的，当且仅当它接受一个长度为1的字符串，这里 $n \\leq l < 2n$\n- *两个有穷自动机是否等价是可判定的*\n\n### 4.4 有穷自动机的最小化\n\n**一个减少状态数的思路：给定 $DFA \\ =(Q, \\Sigma, \\delta, q_{0}, F)$，根据等价关系构造出一个 $DFA M/ \\equiv$，该 $DFA$称为 $M$的商自动机**\n\n- **判断两个状态等价：** 对于 $p, q \\in Q$， 若对于每个 $x \\in \\Sigma^{*}, \\quad \\delta(p, x) \\in F$当且仅当 $\\delta(q,x) \\in F$， 就称 $p, q$ 等价，记作 $p \\equiv q$\n\n**极小化算法过程：**\n-- *在 $DFA$ 的状态集上确定所有的状态对是否等价*\n1. 对所有状态对 ${p, q}  (p, q \\in Q)$画一张表，开始时中每个格子均为空白（未做标记）\n2. 对一切 $p \\in F, q \\notin F$ 的 ${p, q}$，在相应格子上做标记（例如画一个X）\n3. 重复下述步骤，直到表中内容不再改变为止：如果对于某个 $a \\in \\Sigma$， 存在一个未被标记的状态对 $\\{p, q\\}$，使得 $\\{\\delta(p,a),\\delta(q,a)\\}$已做标记，则将 $\\{p, q\\}$ 做标记\n4. 完成1，2，3之后，所有未被标记的状态对都是等价的，即 $p \\equiv q$\n\n### Myhill-Nerode 关系\n**判定方式**\n- 对某个集合$A \\subset \\Sigma^*,\\quad$ R为$\\Sigma^*$上的等价关系。若R满足\n    - 1. 是右不变的\n    - 2. 细分A\n    - 3. 具有有穷指数\n\n- 则称R为A的 Myhill-Nerode 关系\n\n### Myhill-Nerode 定理\n- A是一个正规集\n- $\\Sigma^*上存在关于A的MN关系$\n- $R_A$ 具有有穷指数\n\n\n\n---\n\n\n## 第五章 上下文无关文法与下推自动机\n重点:\n- 了解化简（作业题） \n- ⼀定要会两种范式（乔姆斯基范式&葛雷巴赫范式） \n- 构造下推⾃动机（作业题）\n\n### 5.1 上下文无关文法的化简\n检验文法$G=(V, T, P, S)$中是否有无用符号 （变元或终结符），若有，则将其消除。\n#### 无用符号\n- $X \\in V \\cup T$ 但X不出现在任何由S派生出的字符串中。\n- $X \\in V$ 但X不能派生出任何终结符号串\n\n- Th5.1 不带无用符号的CFG可生成所有非空CFL\n \n    化简思路\n    - 1. 找到无用符号（一类二类）\n    - 2. 删除无用符号\n    - 3. 返回1继续检查，直到不产生无用符号为止\n    \n    PPT思路\n    - 1. 首先删除二类无用符号 \n    - 2. 接着删除一类无用符号\n    - 3. 返回1检查，直到不产生无用符号\n\n\n#### $\\epsilon$ -生成式\n形如 $A \\to \\epsilon$ 的生成式，如果 $\\epsilon \\in L(G)$ 那么不能删，其余都可以删除。\n- 可为零\n如果在CFG中，A属于变元集合，如果有A派生出$\\epsilon$则称A为可为零的。\n\n- Th5.3 可为零的可判定性\n对于CFG中任意变元是否可为零是可判定的\n判定思路：\n\n-  1. 对$A \\to \\epsilon$ 即trivial的本来就可为零的，将A加入Z\n- 2. 对于一切生成式 B，有$B \\to \\alpha$ 如果 $\\alpha \\in V^+$在中所有变元均在Z中，将B加入Z\n- 3. 重复1，直至没有元素加入Z为止\n    \nZ 中元素均为可为零的元素\n\n- Th5.2 不带无用符号且没有$\\epsilon$-生成式的CFG可以生成所有不包含空串的CFL\n**不会证 ；）**\n\n\n#### 单一生成式\n形如 $A \\to B$ （A、B皆为变元）的生成式\n\n#### 结论\n上面说的三个都可以消掉\n\n\n\n### 5.2 上下文无关文法的范式\n\n#### 乔姆斯基范式 Chomsky （CNF定理）\n任何不包含$\\epsilon$的CFL，都可由生成式仅为 $A \\to BC$ 或 $A \\to a$ （A，B，C为变元，a为终结符）形式的文法产生\n（化为乔姆斯基范式，例题5.3）\na\n\n#### 格雷巴赫范式 Greibach (GNF定理)\n任何不包含$\\epsilon$的CFL，都可由生成式仅为$A \\to a\\alpha$ (a为终结符,$\\alpha$ 为变元串，包含空串）形式的文法产生\n\n//TODO\n\n\n\n### 5.3 下推自动机\n下推自动机（简称PDA）是一个七元组 $M=(Q,\\Sigma,\\Gamma, \\delta, q_0, Z_0, F)$\n- Q是有穷状态集\n- $\\Sigma$是有穷的输入字母表\n- $\\Gamma$是有穷的栈符号表\n- $\\delta$是转移函数，将$Q \\times (\\Sigma \\cup \\{epsilon\\} \\times \\Gamma)$ 映射到$(Q\\times \\Gamma^*)$ 的有穷子集\n- $q_0 \\in Q$ 是初始状态\n- $Z_0 \\in \\Gamma$ 是栈底符号\n- $F \\subset Q$ 是终结状态集\n\n#### 转移函数\n三元组 $\\delta(q,a,Z) = \\{(p_1,\\gamma_1), (p_2, \\gamma_2),...,(p_m, \\gamma_m)\\}$ 其中 q, a 一个状态一个输入字符，Z为栈顶符号\n\n状态由 $q \\to p$，栈顶符号由 $Z \\to \\gamma$\n转移动作不确定\n- 函数值有m种选择 （m可以为0）\n- 读头不动也可以有函数值\n\n#### 瞬时描述\n\n$(q_0,w,Z_0) \\mathop{\\vdash}\\limits_{M}^*\\ (p, \\epsilon, \\gamma)$ 表示从状态 $(p, \\gamma) \\in \\delta(q_o, w, Z_0)$，上一个字符为w，下一个字符为 $\\epsilon$\n\n即由一个瞬时描述 ID 转移到下一个 ID\n\n#### 按终结方式接受\n\n若M是一个PDA，集合$L(M)=\\{w|(q_0,w,Z_0) \\mathop{\\vdash}\\limits_{M}^*\\ (p, \\epsilon, \\gamma)\\}$\n则称M按终结状态方式接受的语言\n\n- 接受状态\n还是由初始状态到接受状态，和栈中符号没什么关系，栈符号只影响状态转移\n*不过如果输入串未读完栈就变空，无法进行状态转移，则w不可能被接受。*\n\n\n#### 按栈空方式接受\n- 接受状态\n顾名思义，读完之后栈空了就接受了，终结状态则不影响是否接受。\n\n构造PDA接受$0^n1^n$，例题5.5\n- 例题 5.6、5.7\n\n\n\n\n### 5.4 下推自动机与上下文无关文法的关系\n- 下推自动机接受的语言类是上下文无关文法 CFL (2型文法)\n\n\n\n\n---\n\n\n## 第六章 上下文无关语言的性质\n重点\n- 缩胀定理/ogden定理（尤其考察后者）\n- 考察给⼀个语⾔判断是否是上下⽂⽆关语⾔ 封闭属性 \n- 成员资格判定问题（PPT）,CYK算法\n\n### 6.1 CFL缩胀定理\n回忆一下正规集缩胀定理\n正规集中每个足够长的字符串，都包含一个短子串可扩张任意多次，所得字符串仍然属于该正规集\n\n- CFL 缩胀定理\n在CFL中，每个足够长的字符串，都包含两个相距不远的短子串，两个子串可以扩充任意多次，所得子串仍然属于CFL\n\n**形式描述：**\n对于每个CFL，都存在正整数 $k \\ge 0$ 使得对每个$z \\in L$ 只要 $|z| \\ge k$ 就可将z划分为5个子串，\n满足以下三个条件\n1. 对任何的$i \\ge 0$ 都有$uv^iwx^iy \\in L$\n2. $|vx| \\ge 1$\n3. $|vwx| \\le k$\n\n（其中 k = $b^{|V| + 1}$，其中b是生成式右侧符号数的最大值）\n看计算理论导引P77，写的很清楚\n\n\n### 6.2 Ogden定理\n**形式描述：**\nL为CFL，存在整数$k \\ge 0$，使得对每个$z \\in L$，并且在z中标出k个或多于k个特别符号，将z写成z=uvwxy，且满足\n1. v和x一起至少包含一个特别符号\n2. vwx之多包含k个特别符号\n则对任何$i \\ge 0,\\ uv^iwx^iy \\in L$\n\n例题6.4 \n\n\n### 6.3 CFL封闭性质\n\n回忆一下RL的封闭性质，RL在以下运算下封闭\n- 交并补\n- 连接\n- 闭包\n- 商\n\n**CFL在以下运算下封闭**\n- 并 \n对G1,G2，生成式的开始元S1，S2\n构造 G3 $S \\to S1 | S2$\n\n- 连接\n对G1,G2，生成式的开始元S1，S2\n构造 G3 $S \\to S1S2$\n\n- 闭包\n对G1,G2，生成式的开始元S1\n构造 G3 $S \\to S1S|\\epsilon$\n\n**注意 CFL 在 *交* $\\cap$ 和 *补* $\\hat{ }$ 运算下不封闭**\n- 交\n$L1= {a^ib^ic^j|i \\ge 1, j \\ge 1}$, $L2= {a^ib^jc^j|i \\ge 1, j \\ge 1}$\n两者是CFL\n但其交集$L1 \\cap L2= {a^ib^ic^i|i \\ge 1}$ 不是CFL，可由Pumping LEmma 证得\n\n- 补运算\n交运算，可化为补+并的形式，若补运算封闭，则由于并运算封闭，可证得交运算封闭，推出矛盾。\n\n#### CFL和正规集的交是CFL\n- 定理6.6 若L是CFL，R是正规集，则$L\\cap R$是CFL\n\n\n### 6.4 CFL判定算法\n\n#### 给出CFG G=(V, T, P, S), L(G)是否为空和是否有穷问题是可判定的\n- L(G) 是否为空\n    - 检验S是否能派生出终结符号串\n    - 若能，则L(G)非空；不能则为空\n- L(G)是否有穷\n    - 对G的Chomsky范式，以变元为顶点画出有向图\n    - 原问题 $\\Leftrightarrow$ 该有向图是否有回路\n    - 即X的最长路径长度为l，则从X派生出的终结符号串长度不超过$2^l$ (归纳假设)\n\n图论算法判定一个有向图是否有回路，所以L(G')是否有穷，是可判定的\n\n### 6.5 成员资格问题\n**给定一个CFG G和一个终结符串x，问x是否属于L(G)**\n暴力算法思想，对于G的Greibach范式文法，从S生成式推出右侧的第一个终结变元和x串的第一个符号比较，如果对应就把右侧第二个变元的推出式拿出重复上述操作，直到接受或拒绝为止，时间复杂度$O(m^n)$\n\n#### CYK算法\n时间复杂度 $O({|x|}^3)$\n倒着的树，看Vij表，懂的都懂\n（区间DP）\n![](/uploads/upload_e2b3e93174f7cd571038ce381a21f95c.png)\n\n\n---\n\n\n## 第七章 图灵机\n重点\n- 构造语⾔的图灵机（会考的稍微复杂）\n- 图灵机构造技术 其他类型的图灵机（多带的、⾮确定、双栈机） \n- 枚举器，正则次序，对偶产生器\n\n### 7.1 图灵机基本模型\n确定单带图灵机是一个9元组 $M=(Q,\\Sigma,\\Gamma,\\vdash, \\diamond,\\delta,s,t,r)$\n- 1. Q有穷状态集\n- 2. $\\Sigma$有穷输入字母表\n- 3. $\\Gamma$有穷的带字母表\n- 4. $\\vdash$ 左端标记\n- 5. $\\diamond$ 空白符号\n- 6. $\\delta$ 转移函数\n- 7. $s \\in Q$ 开始状态\n- 8. $t \\in Q$ 接受状态\n- 9. $r \\in Q$ 拒绝状态\n\nL 表示读写头左移，R表示右移，对于左端标记，永远有$\\delta(p,\\vdash)=(q,\\vdash,R)$\n\n- 递归可枚举集\nTM M接受的语言，称为递归可枚举集\n\n- 递归集\n被完全 TM M 接受的语言，称为递归集\n\n- 完全TM\n对一切输入均能停机（达到接受或拒绝状态）\n\n例题做做做\n\n\n### 7.2 图灵机构造技术\n\n#### 有限控制器中的存储\n- 元组表示状态，将带上符号吸收到状态中\n\n#### 移动\n- 将带上符号不断吸收到状态中，不断写下，达到整体移动的目的\n\n#### 多道技术\n- 保存处理更复杂的数据，例如计算$n^2$\n\n#### 查讫符号\n- 即给带上符号打标记，利用到多道技术\n- 常用于区分某个符号是否查过\n- 例7.7 构造一个识别 $l={wcw|w \\in \\{a,b\\}^+}$的 $TM$\n\n#### 子程序技术\n- 懂的都懂，大概不考\n构造TM M实现乘法运算\n\n\n### 7.3 图灵机的变型\n\n#### 双向无限带\n- 将图灵机的单向无限延伸扩大到双向无限延伸\n    - 无左端标记$\\vdash$\n    - 其余符号和功能均与单向无限带TM相同\n\n并没增加其表达能力，和单带相同\n- 可以构造一个双带单向无限图灵机，识别能力与双向无限图灵机相同（定理7.1）\n\n#### 多带\n- 用一个控制器控制k条带，在每条带上有独立的读写头\n**和多道技术的区别**\n多道技术是一个控制器多个带，这个是多个控制器多个带。\n- 给一些证明带来许多方便\n- 并没增加其表达能力，和单带相同\n\n\n#### 非确定图灵机\n**确定的图灵机 $\\delta$ 是单值函数，非确定性图灵机增加非确定性动作，并未改变其识别能力**\n- 可以证明确定型图灵机与非确定型图灵机的等价性\n定理7.3 若L被一个非确定的TM $M_1$ 接受，则L也被某个确定的TM $M_2$ 接受。\n\n#### 双栈机\n其是特殊的三带图灵机\n一个带用于输入，只读不写\n另外两个用来模拟栈\n- 读头右移，可写任意符号 （进栈）\n- 读头左移，只能写空白符 （退栈）\n读头指向为栈顶，左端标记右边那个为栈底\n\n- 任意的单带图灵机能被双栈机给模拟\n右移时，右栈弹栈，左栈压栈。反之类似\n\n**下推自动机是单栈机，所以其能力比图灵机小， 即$PDA < TM$**\n**图灵机是下推自动机的扩充，能接受其不能接受的语言**\n\n#### 带字母最少的图灵机\n- 限制带字母表上只有 $0,\\ 1,\\ \\diamond$ 三个符号\n- 和任何TM等价\n\n#### 作为枚举器的图灵机\n- 用一条带专门作为输出带，带上符号一旦写上就不改动，带头一直往右，永不回头。\n\n#### 枚举器和TM的等价\n- 设对某个枚举器 $M_1,\\ L=G(M_1)$, 则存在TM $M_2$ 使得 $L(M_2) = L$\n    - 构造M2，M2比M1多一条输入带，比较M2的输入和M1产生的串，如果相等则接受，不相等则与M1产生的下一个串继续比较，这样进行。\n    - 因为M1产生的串都是M2能接受的，M1不能产生的串都是M2不能接受的（不停机）所以 L(M2)=G(M1)=L\n\n#### 对偶产生器\n- 一个过程，以i+j不减的顺序列出正整数对(i,j)\n\n#### 字母表 $\\Sigma$ 上串的正则次序\n- 先按长度排序\n- 再按字典序\n\n\n### 7.4 图灵机与0型文法的关系\n图灵机对应0型文法\n\n\n\n---\n\n\n## 第八章 不可判定性\n重点\n- 递归集和递归可枚举集的属性 \n- 两个不可判定问题（停机问题+成员资格问题） \n- 通⽤图灵机的概念，图灵机的⼆进制编码 \n- Rice定理\n\n### 8.1 递归集和递归可枚举集性质\n#### **补集**\n- 一个递归集的补集仍然是递归集\n因为完全TM\n调换接受拒绝状态\n\n#### **并集**\n- 递归集的并是递归的，递归可枚举集的并是递归可枚举的\n    - 对于递归集，其是由完全TM生成的语言集合那么对于输入串，可先经M1进行验证，若接受则接受，若不接受则进第二个M2，重复上述过程。 （这里的保证是因为他们是完全TM，可以停机）\n    - 对于递归可枚举集，构造非确定M3',对输入分别在M1，和M2上验证，如果有一个接受则接受，可见M3‘的停机问题也是不可判定的，为一般TM。\n\n#### **交集**\n- 递归集的交是递归的，递归可枚举集的交是递归可枚举的\n\n看ppt的图，应该很清楚\n\n- 若语言 L 和 L补 都是递归可枚举的，则L（和L补）是递归的\n\n\n\n### 8.2 通用图灵机和两个不可判定问题\n\n#### 通用图灵机\n模拟任何图灵机的图灵机，将某个TM作为通用图灵机的输入来看待\n- 需要对TM有统一的、合理的编码\n- 在给定输入串上，模拟TM的动作\n- 给定TM接受，则该TM接受这个TM和这个输入的二元组\n\n#### 图灵机编码\nM#w\n\n#### 关于停机问题的不可判定性\n- 没有一个算法在有限步之内能够判断一个TM M在给定的输入串x上是否能停机。\n    -  1. 接受状态\n    -  2. 拒绝状态\n    -  3. 无限循环\n\n- **任意给定TM M对任意给定输入串x是否停机的问题是不可判定的**\n自指悖论（类似**罗素悖论**的方法）\n\n**证明**\n\n- **Step 1 TM编码**\n    - 由于可对TM进行编码，所以任何TM可以表示为01串\n    - 而我们可以把任何零一串看作一个TM\n    - 在上述规定下，可按正则次序列出所有TM \n    $M_{\\epsilon},\\ M_0,\\ M_1\\ ,M_{00},\\ M_{01}...$\n    显然真正的TM一定出现在此序列中至少一次\n    \n\n- **Step 2 二维表标记**\n    - 考虑无穷维的二维表，其顶端遍历 $\\{0, 1\\}^*$ 的正则序列，左端遍历 TM，用H (Halt) 表示停机，用L (Loop) 表示不停机，在对应位置做上标记\n\n- **Step 3 开始证明**\n    - 假设存在完全TM K，以Mx#y为输入，能够判断Mx在y上是否能够停机。如果停机，则 K 接受 Mx#y；否则，拒绝\n    - 构造另一个TM N，其输入为 $x \\in \\{0, 1\\}^*$ 其完成以下任务\n        - 从x找到Mx，将Mx#x写到其带上\n        - 在 Mx#x 上模拟K的动作，如果K接受，则其就进入循环（不停机），如果K拒绝，他就接受。\n    - 那么根据N的定义，如果N在x上停机，则代表K拒绝，则代表Mx在y上不停机。\n\n- **Step 4 推出矛盾**\n    - 因为N也是图灵机，假设其编码为y，在正则序列中出现为My，如果N在y上停机，则代表My在y上不停机，而My就是N，导致矛盾。矛盾起因是K的存在性\n所以不存在这样的TM能够判断M在任何输入下是否停机，即停机问题是不可判定的\n\n#### 成员资格问题的不可判定性\n- **对于任意给定 TM M 和输入串x，M是否接受x的问题是不可判定的**\n\n    - 1. 存在完全的 TM K，它能对任意的M和x，判断x是否属于L(M)。若$x \\in L(M)$，则K接受$M\\#x$；否则拒绝\n\n    - 2. 构造N，使得如果x在M上达到接受或拒绝的停机状态，则N接受。可以看出N是判断M在x上是否停机的TM。\n\n    - 3. 现在对M输入N#x，则N是否接受x等价于x在M上是否停机，而停机问题是不可判定的，所以成员资格问题也不可判定。\n\n\n\n\n### 8.3 归约方法和Rice定理\n- **给定TM M其是否接受空串的问题是不可判定的**\n\n将HP的不可判定性导出问题B的不可判定性\n- HP Halt Problem 停机问题\n- B 其他问题\n\n\n#### Rice定理\n- r.e.集合类的任何一个非平凡性质都是不可判定的\n\n- **Step 1 准备** \n    - 设 P 是 r.e. 集合类上的一个非平凡性质，不失一般性，假设空集不具有性质P，则因为P的非平凡性，必定存在一个集合A满足P，即P(A) = T设K是接受A的TM\n\n- **Step 2 归约HP到集合 $\\{M|P(L(M)) = T\\}$**\n    给定M#x, 构造TM M'，其按以下步骤进行\n    - 对于TM的输入y，将其放在一个道上\n    - 将x写在另一个道上\n    - 在M上模拟x的动作\n    - 如果M在x上停机，则在K上模拟y的动作\n    - 如果K接受y，则M'接受y\n\n- **Step 3 推出矛盾**\n    - 显然，M和M'的停机问题相关联，如果停机有 M' 和 K 接受一样的集合。\n    - 所以有 M 在 x 上停机，可推出，L(M') = A，可推出 P(L(M')) = T\n    - 反之则不停机，P(L(M')) = F\n    - 这就得出了停机问题到该问题的归约，但停机问题不可判定，所以其非平凡性质也不可判定。\n\n\n\n\n### 8.4 关于CFL的不可判定问题\n\n\n### 8.5 Post对应问题的不可判定性及其应用\n\n\n\n---\n\n\n## 第九章 线性有界自动机和上下文有关语言\n重点\n- 给定语⾔，构造LBA \n- LBA对停机问题的判定问题\n\n各种机器对应的不同⽂法，⽐如FA对应CFG，图灵机对应0型，PDA对应CFL\n\n### 9.1 线性有界自动机 LBA\n- 对TM的读写头范围加以限制\n- 左右端都有标记\n- 接收机和小于TM接受的集合类\n\n线性有界自动机 LBA 是9元组 $M=(Q,\\ \\Sigma, \\Gamma, \\vdash,\\ \\dashv, \\delta,\\ s,\\ t,\\ r)$\n- 1. Q 有穷状态集\n- 2. $\\Sigma$ 有穷输入字母表\n- 3. $\\Gamma$ 有穷带上字母表\n- 4. $\\vdash$ 左端符号\n- 5. $\\dashv$ 右端符号\n- 6. $\\delta$ 状态转移函数\n- 7. s 开始状态\n- 8. t 接受状态\n- 9. r 拒绝状态\n\n***例题9.1***\n思路：\n- 1. 查讫符号打标记后找到中心\n- 2. 对消\n\n### 9.2 LBA 和 CSL 的关系\n- 若L是CSL，则L可被某个LBA接受\n\n将S派生出来的各种字符串（在下道），与上道的w比较，若相等则接受\n\n### 9.3 CSL的性质及其和递归集的关系\n#### CSL封闭性\n- 并\n- 连接\n- 正闭包（因为CSL不包含 $\\epsilon$，所以L1为CSL则其闭包 $L_1^*$ 不是CSL）\n- 交运算\n\n#### 每个CSL都是递归的\n思路：\n因为输入串长度有限，并且两端封闭，所以总的情况数是有限的为$k(n+2)l^n$ 种，那么用双带，一带正常执行，令一带计算执行步数，如果超出则说明进入循环，则拒绝。所以有CSL是递归的\n\n#### 存在递归集，不是CSL\n\n\n### 9.4 语言类之间的关系\n\n1. RL(3型文法RG)\n2. DCFL\n3. CFL(2型文法CFG)\n4. CSL∪\\{ε\\}(1型文法CSG)\n5. 递归集\n6. r.e.集（递归可枚举集）(0型文法PSG),如成员问题所对应的字符串\n7. 非r.e.集，如FIN\n\n\n\n---\n\n\n\n## 第十一章\n重点\n- 给定语⾔：判断是P还是NP\n- P与NP的封闭性证明 常⻅的NPC问题的推导和证明(重点)\n    - 证NP问题\n    - 证归约性 \n- P NP NPC NPHARD的概念 \n- PSPACE==NPSPACE-NPSPACEhard \n- L-NL（构造：利⽤指针） \n- 后⾯的层次定理&布尔电路不考\n\n### 层次概览\n\n![](https://codimd.s3.shivering-isles.com/demo/uploads/upload_81564f07be5cb20ec62f5761169626dc.png)\n\n![](https://codimd.s3.shivering-isles.com/demo/uploads/upload_aeeccf9bef7be94af30f6875bdf5d5e1.png)\n\n$$L \\subset NL = coNL \\subset P \\subset NP \\subset PSPACE = NPSPACE \\subset EXPTIME$$\n\n### P类\n- 定义： P是确定型单带图灵机在多项式时间内可判定的语言类\n\n$$P = \\mathop\\cup\\limits_{k} TIME(n^k)$$\n\n#### **PATH $\\in$ P**\nPATH 问题，即G（有向图）中两点判定是否存在有向路径\n用BFS算法，O(m)\n或者dijkstra算法\n\n#### **RELPRIME $\\in$ P**\nRELPRIME 问题，即判定两数互素\n辗转相除法（欧几里得算法）\n\n#### **每个CFL都是P**\nCYK 复杂度$O(n^3)$\n\n### NP类\n\n#### **引理：NP是具有多项式时间验证机的语言**\n- 用于验证该问题的额外信息称为证书\n    - HAMPATH 中两点之间的哈密顿路径\n    - COMPOSITES 中 x 一个不等于1的因子\n\n#### **一个语言在NP中，当且仅当其能够被某个非确定型多项式时间图灵机判定**\n\n#### **NTIME(t(n)) = {L| L 是一个被O(t(n))时间的非确定型图灵机判定的语言}**\n$$NP = \\cup_k NTIME(n^k)$$\n\n\n#### **CLIQUE $\\in$ NP**\nCLIQUE = {(G,k)| G是包含k团的无向图}\n- 验证机角度\n        证书：团，记为c\n        V为CLIQUE的验证机\n        V = 对输入((G,k), c)\n        1. 检查c是否是G中k个点的集合\n        2. 检查G是否包含连接c中节点的所有边\n        3. 若均通过则接受，否则拒绝\n        \n- 非确定型TM角度\n        N = 对于输入(G,k)\n        1. 非确定的选择G中k个节点的子集c\n        2. 检查G是否包含连接c中节点的所有边\n        3. 若是则接受，否则拒绝\n\n\n#### **SUBSET-SUM $\\in$ NP**\nSUBSET-SUM，给定集合s和t，判定是否有s的子集y，使得子集y中元素之和等于t\n- 验证机角度\n        证书：子集\n        V = 对输入((s,t),c)\n        1. 验证c中元素之和是否等于t\n        2. 验证s是否包含c中所有元素\n        3. 若均通过则接受，否则拒绝\n        \n- 非确定型TM角度\n        N = 对于输入(s,t)\n        1. 非确定的选择s中的子集c\n        2. 验证c的元素之和是否等于t\n        3. 若是则接受，否则拒绝\n        \n- co-NP\n\n### P与NP问题\n- P = NP ?\n$$NP \\subset EXPTIME = \\mathop\\cup\\limits_{k} TIME(2^{n^k})$$\n\n### NP完全性\n\n- 定义\n    - 1. B属于NP（多项式时间内被非确定图灵机判定）\n    - 2. NP中每一个A都可在多项式时间内归约到B（归约，重要步骤）\n    - 则称B为NP完全问题\n\n\n- 证明P=NP的一类思路\n    - 证明某个NPC $\\in$ P\n\n#### **库克-列文定理**\nSAT 问题，给定一个布尔公式$\\phi$判断其是否可满足\n$$SAT \\in P，当且仅当 P=NP$$\n\n证明：\n- 第一步：非确定图灵机可以在多项式时间内猜测变量的赋值，然后判断其是否可满足，因此 $SAT \\subset NP$\n- 第二步：\n    - 假设从$NP$取出任意语言$A$，非确定$TM N$在$n^k-3$判定\n    - 考虑$N$对应的$n^k\\times n^k$画面$\\omega$\n    - 设计一个$\\phi$,使得变量的一个满足赋值确实对应$N$在$\\omega$上的接受画面\n    - //todo\n\n#### **SAT $\\in$ NPC**\n\n为NP中的每一个语言A，构造一个到SAT的多项式时间归约\n书P170~173\n\n#### **3SAT $\\in$ NPC**\n\n#### **CLIQUE $\\in$ NPC**\n\n- **证明NPC**\n    - 先证明NP\n    - 再证明某个已知NPC问题可在多项式时间内归约到他\n\n\n#### 顶点覆盖问题 VERTEX-COVER\nVERTEX-COVER 判定G是具有k个顶点的顶点覆盖的无向图\nNP完全\n3SAT 到 VERTEX-COVER 的归约\n书P174\n- 证明思路：将一个$3nf$公式$\\phi$转化成一个图$G$和数值$k$，只要能找到覆盖，$\\phi$就被相应地满足\n\n#### 哈密顿路径问题 HAMPATH\nHAMPATH $\\in$ NPC\n3SAT 到 HAMPATH 的归约\n\n书p175~177\n\n#### 子集和问题 SUBSET-SUM\nSUBSET-SUM $\\in$ NPC\n3SAT 到 SUBSET-SUM 的归约\n\n书p178~180\n\n---\n\n### 萨维奇定理\n任何消耗$f(n)$空间的非确定型TM都可以转变为仅消耗$f^2(n)$空间的确定型TM\n\n$$NSPACE(f(n)) \\subset SPACE(f^2(n))$$\n\n方法：利用中间格局递归二分\nCANYIELD = 对于输入 c1，c2，t\n1. t=1 直接检查是否有c1 = c2 或根据N规则，检查c1是否能够一步只能产生c2，其中之一成立则接受，否则拒绝\n2. 若 t > 1，则对于N在w上消耗空间f(n)的每一个格局cm\n3. 运行CANYIELD(c1, cm, t/2)\n4. 运行CANYIELD(cm, c2, t/2)\n5. 两个都接受则接受，否则拒绝\n\n对输入 $c_{start}$，$c_{accept}$，$2^{df(n)}$\n\n递归深度$O(log2^{df(n)})$，所以总消耗空间$O(f^2(n))$\n\n### PSPACE类\nPSPACE是在确定型图灵机上，在多项式空间内可判定的语言类\n$$PSPACE = \\mathop\\cup\\limits_{k}SPACE(n^k)$$\n\n- SAT $\\in$ SPACE(n)\n- $ALL_{NFA} \\in coNSPACE(n) \\Rightarrow ALL_{NFA} \\in SPACE(n^2)$\n- 其都在PSPACE中\n\n- $P \\subset PSPACE$\n因为运行n步的程序，最多消耗n的空间\n\n- $NP \\subset NPSPACE$\n同理\n\n由于 NPSPACE = PSPACE\n所以有 $NP \\subset PSPACE$\n\n\n### PSPACE完全性\n定义 若B是PSPACE-C则其满足以下两个条件\n- 1. $B \\in PSPACE$\n- 2. PSPACE中每个语言A可多项式时间内归约到B\n- 只满足2类似NP难称其为PSPACE难的\n\n\n#### TQBF问题\n判定$\\phi$是真的全量词化布尔公式\n其是PSPACE完全的\n- 先给出一个线性空间的复杂度算法，证明其属于PSPACE\n- 再给出归约方式，类似萨维奇定理证明方法\n书 P192\n\n#### 博弈必胜\n$FORMULA_GAME = {<\\phi> | 在与\\phi相关联的公式博弈中选手E有必胜策略}$\n其是PSPACE完全的\n**因为其等价于TQBF**\n\n#### 广义地理学\n$GG = {<G,b> | 在图G上以结点b起始的广义地理学游戏中，选手I有必胜策略}$\n其是PSPACE完全的\n证明方法类似TQBF的递归算法\n\n### L和NL类\n亚线性空间界限，类似工作主存上是亚线性空间，其余放在外存（只读）。\n\n#### L类\n- L是确定型图灵机在对数空间内可判定的语言类\n$$L=SPACE(logn)$$\n\n#### NL类\n- NL是非确定性图灵机在对数空间内可判定的语言类集合\n$$NL=NSPACE(logn)$$\n\n- 例题 8.13\n$A = \\{0^k1^k| k \\ge 0\\} \\in L$\n在工作带上用二进制数0、1的数目，两个计数器消耗对数级别空间，所以$A \\in L$\n\n- $PATH \\in NL$\n非确定的猜测从s到t的每一步，工作带上只记录每一步当前节点的位置，非确定的选择下一个节点，反复执行，直到到达t接受。或执行m步后拒绝，m是节点数。由此得到了PATH的被非确定型图灵机在亚线性空间内接受。\n\n### NL完全性\n定义 若语言B是NL完全的，则其满足\n- 1. $B \\in NL$ \n- 2. NL中的每个A**对数空间**内可归约到B\n\n\n#### PATH是NL完全的\n证明方法，把输入字符串w对应为图，图中节点对应NTM在输入w上的一个格局。一个结点能指向另一个结点的调节时，其对应的格局能在NTM的一步内产生第二个结点对应的格局，因此，NTM对输入w是否接受就对应着初始格局到接受格局的PATH\n更详细的对数空间归约证明情况书 p199~200\n\n\n#### $NL \\subset P$\n- 1. 因为PATH是NL完全的，所以NL中任何语言可对数空间内归约到PATH\n- 2. 由此，NL中任何语言也可对数时间内归约到PATH\n- 3. 因为多项式时间内归约到P中语言的语言本身也属于P\n- 4. 所以 $NL \\in P$\n\n### NL = coNL\n\n\n\n\n\n\n\n\n","source":"_posts/Computation_Theory/note.md","raw":"---\ntitle: 计算理论基础笔记\ndate: 2021-07-05 18:42:20\nindex_img: /img/PNP.webp\ncategory: [Computation Theory]\ntags: [P=NP?, Computation Complexity]\nmath: true\n---\n\n# 计算理论基础\n\n## 第一章 预备知识\n\n重点：\n- 符号表示，可能在问答题里面出现\n\n### 1.1 定理及其证明方法\n\n- 形式系统\n1. **基本符号** *（常量符号、变量符号、运算符等抽象字符）*\n2. **形成规则** *(构造各种语言的方法规则)*\n3. **公理** *（无需经过证明，正确性得到公认的语句）*\n4. **推理规则** *（用于得到新的合法语句）*\n\n- *如何证明一个语句为真*\n\n1. 每个语句或者是公理，或者由前面的语句自然导出\n2. 最后一个语句就是所要证明的语句\n\n- **定理证明方法**\n\n1. 演绎法\n2. 反证法/归谬法\n3. 归纳法、第二归纳法\n\n### 1.2 集合及其基本运算\n\n1. 集合描述方法\n\n- 列举法 $A=\\{a,b,c,d\\}$\n- 模式表示法 $\\{x|P(x)\\}$\n\n2. 集合运算及定理\n\n- 定理1.9 德摩根定理\n\n$\\quad \\quad \\bar{A \\cap B} = \\bar A \\cup \\bar B$\n$\\quad \\quad \\bar{A \\cup B} = \\bar A \\cap \\bar B$\n\n### 1.3 图和树简介\n\n- **图** ：顶点集合以及边集合\n- 有向图、无向图\n- 通路、回路\n- 邻接矩阵\n\n- **树** \n- 树中每一个顶点到另一个顶点均有一条通路，称该顶点为树的根\n- 树中一定没有回路\n- 仅一个顶点(根节点)没有前导顶点\n- 一定存在没有后继的顶点\n\n### 1.4 字母表、字符串和语言\n\n- 自然语言\n-- 人类彼此相互交流的工具，由基本符号构成，如日语俄语等\n- **形式语言**\n-- 用于需要严格描述的领域，构成基础为“符号”\n\n\n\n- **字符表**是符号的集合，记为 $\\Sigma$\n- $\\Sigma$ 上的符号串\n-- $\\Sigma$ 上的符号以任意顺序拼接起来构成\n-- 任何符号可以重复出现\n- **定义1.23**\n-- 对于任何给定的字符表 $\\Sigma$，$\\Sigma$ 上的字符串集合称作 $\\Sigma$ 上的语言\n- **定义1.24**\n-- 设$L$是某个字母表上的一个语言，若 $L$ 中任何字符串都不是另一个字符串的真前缀，则$L$ 具有**前缀性质**\n- **定义1.25**\n-- 设 $L_{1}$ 为 $\\Sigma_{1}$ 的语言, $L_{2}$ 为 $\\Sigma_{2}$ 的语言，则  $L_{1}$ 和 $L_{2}$ 的连接 $L_{1}L_{2} = \\{xy | x \\in L_{1} and \\ y \\in L_{2}\\}$\n- **定义1.26**\n-- **语言 $L$ 的闭包 $L^{*}$ **\n-- 以任意次序连接L中任意多个字符串所组成的集合\n-- 只要 $L$ 中包含至少一个元素, $L^{*}$ 就为无穷集\n\n\n---\n\n\n## 第二章 文法理论\n重点：\n- ⽂法分类（给定⼀个语⾔集合，判定是0123型⽂法，熟悉每个⽂法的判定⽅法）（最重要） \n- 上下⽂有关⽂法上下⽂信息的获得,1'型⽂法如何转化为1型⽂法\n\n### 2.1 文法定义\n- 四元组 $G=(V,T,P,S)$\n1. V是变元符有限集 Variables\n2. T是终结符有限集 Termination\n3. P是生成式有限集 (Production?)\n4. S∈V，为文法G的开始符 Start\n\n### 2.2 派生\n**直接派生**\n若 $\\alpha = \\alpha_{1} A \\alpha_{2}, \\ \\gamma=\\alpha_{1}\\beta\\alpha_{2}$ ，且 $A\\to\\beta$ 为P中一个生成式，则 $\\alpha \\mathop{\\Rightarrow}\\limits_{G}^{}\\gamma$\n，称由 $\\alpha$ 直接派生出 $\\gamma$\n\n**派生**\n将 $\\mathop{\\Rightarrow}\\limits_{G}^{}$ 扩充为 $\\hat{\\mathop{\\Rightarrow}\\limits_{G}^{}}$，则为派生\n\n$\\quad (\\hat{\\mathop{\\Rightarrow}\\limits_{}} 表示多步直接派生)$\n\n\n\n### 2.3 文法分类\n**1. 短语结构文法 PSG (0型文法)**\n- **特点：** 不加限制\n- **对应语言：** 短语结构语言 PSL\n- **对应自动机：** 图灵机 TM\n- **形式：** $\\alpha\\to\\beta,\\ \\alpha,\\beta\\in(V \\cup T)^{*}$ 且 $\\alpha\\ne\\epsilon$\n\n**2. 上下文有关文法 CSG (1型文法)**\n- **特点：** 每个终结符$\\to$终结符，满足前者偏序后者 ($\\leq$)\n- **对应语言：** 上下文有关语言 CSL\n- **对应自动机:** 线性有界自动机 LBA\n- **形式：** $\\forall \\alpha\\to\\beta\\in P$ , 满足 $|\\alpha|\\leq |\\beta|$ 并且 $\\alpha,\\beta\\in(V \\cup T)^{*}$ 且 $\\alpha\\ne\\epsilon$\n\n**3. 上下文无关文法 CFG (2型文法)**\n- **特点：** 都有变元推出变元或终结符或者变元与终结符的连接\n- **对应语言：** 上下文无关语言 CFL\n- **对应自动机：** 下推自动机 PDA\n- **形式：** 对所有P中生成式都有，$A\\to\\beta \\quad \\beta\\in(V \\cup T)^{*},\\ A \\in V$\n\n**4. 正规文法 RG (3型文法)**\n- **特点 ：** 变元推出终结符或推出终结符+变元\n- **对应语言：** 正规语言 RL\n- **对应自动机：** 有穷自动机 DFA\n- **形式：** 对所有P中生成式都有，$A\\to a\\ 或\\ A\\to aB \\quad a\\in T \\cup {\\epsilon},\\ A,B \\in V$\n\n\n\n\n### 2.4 文法等价\n\n对于两个文法 $G_{1}=(V_{1},\\ T_1,\\ P_1,\\ S_1)$ 与 $G_{2}=(V_{2},\\ T_2,\\ P_2,\\ S_2)$，若$L(G_1)=L(G_2)$，则文法等价\n\n\n### 2.5 1°型文法\n- **特点：** 看形式\n- **形式：** 对文法 $G=(V,\\ T,\\ P,\\ S)$，若P中每个生成式都有 $\\alpha_1 A \\alpha_2 \\to \\alpha_1 \\beta \\alpha_2$形式，$A \\in V, \\ \\alpha_1,\\alpha_2\\in(V \\cup T)^{*}$, $\\beta \\in {(V \\cup T)}^{+}$ \n\n\n#### 1、 1型文法和1°型文法转换\n\n- 定理：对于任何1型文法G，一定存在一个 $1^{°}$ 型文法G',使得L(G)=L(G') 反之亦然。\n\n- $\\Rightarrow$ \n对于任何生成式 $\\alpha_1 A \\alpha_2 \\to \\alpha_1 \\beta \\alpha_2$ ,恒有 $|\\alpha_1 A \\alpha_2| \\leq |\\alpha_1 \\beta \\alpha_2|$ \n即 $1^{°}$ 型文法一定是1型文法\n\n- $\\Leftarrow$ \n- 第一步：将G变为G''\n    - 这一步构造出生成式只有两种形式的G''\n    - 其中 $V^{''}=V \\cup M, M=\\{[a] | a\\in T\\}$\n    - $P^{''}=\\overline{P} \\cup \\{ [a] \\to a | a \\in T \\}$\n\n- 第二步：G'' 中生成式形式分类讨论\n    - （1） $A\\to\\beta$ (A∈V，或为新引入变元[a])，其已经是1°文法\n    - （2）$A_1A_2...A_n\\to B_1B_2...B_n,\\quad (n\\ge 2,\\ m\\ge n)$ \n        - 解决方法：引入一组新变元用于过渡\n        - 1. $A_1A_2...A_n \\to C_1A_2...A_n$ \n        - 2. $C_1A_2...A_n \\to C_1C_2...A_n$ \n        - 3. $C_1C_2...C_{n-1}A_n \\to C_1C_2...C_n$ \n        - 4. $C_1C_2...C_n \\to B_1C_2...C_n$ \n        - 5. $B_1C_2...C_n \\to B_1B_2...C_n$ \n        - 6. $B_1B_2...B_{n-1}C_n \\to B_1B_2...B_n$\n        - 完成 $A_1A_2...A_n\\to B_1B_2...B_n$\n\n\n\n### 2.6 上下文在文法中的体现\n#### 上下文有关文法（1型文法）的上下文\n- 可用1°型文法解释，$\\alpha_1 A \\alpha_2 \\to \\alpha_1 \\beta \\alpha_2$，其中$\\alpha_1\\ 和\\ \\alpha_2$ 是A的上下文，在该上下文语境中A可替换为β\n- 在另外上下文语境中可替换为别的字符串，例如另有生成式 $\\alpha_{1'} A \\alpha_{2'} \\to \\alpha_{1'} \\gamma \\alpha_{2'}$ \n\n#### 上下文无关文法（2型文法）的上下文\n- $A\\to \\beta$ 变元A不管出现在任何地方都可替换为β，与上下文无关\n\n\n### 2.7 语法分析树\n- 定义：//TODO\n\n\n#### 边缘\n- 对于派生树，其叶节点标记从左到右收集起来的字符串，称为该派生树的边缘\n\n- **相关定理：** G为上下文无关文法，那么S可以派生出α当且仅当在G中存在一颗边缘为α的派生树\n证明: //TODO\n\n#### 多义和固有多义\n不重要 TODO\n\n\n----\n\n\n## 第三章 有穷自动机和正规表达式\n重点\n- 掌握⼏类⾃动机的特点（FM, NFM, 有空动作的FM），⼏种FM之间如何进⾏变换（等价性），例：如何进⾏ 空动作的消除（空闭包的转换） \n- 掌握正则表达式和正规集，正规集和有穷⾃动机的关系（实际上在第四章） \n- 了解摩尔机和米里机的定义和功能（⾮重点）\n\n\n\n### 3.1 确定有穷自动机 DFA\n#### 1. 定义\n- 有穷自动机（FA or DFA）是一个五元组 $M=(Q,\\ \\Sigma, \\delta,\\ q_0, F)$\n    - 1. Q是有穷状态集\n    - 2. $\\Sigma$ 是有穷的输入字符表\n    - 3. $\\delta$ 是转移函数，将 $Q\\times \\Sigma$ 映射到Q\n    - 4. $q_0\\in Q$ 是初始状态\n    - 5. $F\\subset Q 是终结状态$\n\n#### 2.扩充转移函数\n对于 FA $M=(Q,\\ \\Sigma, \\delta,\\ q_0, F)$ 其扩充转移函数是 $\\hat\\delta$ 是$Q\\times\\Sigma^*$ 到 Q 的映射\n- 1. $\\hat{\\delta}(q,\\epsilon) = q$ \n- 2. $\\hat\\delta(q,wa)=\\delta(\\hat\\delta(q,w),a)$ \n\n- 递归定义\n接受一个输入，然后进行状态转移，再接受下一个。输入一个串得到最后状态。\n\n#### 3.有穷自动机接受语言\n\n$L(M)=\\{x| \\delta(q_0,x)\\in F\\}$\n若 $\\delta(q_0,x)=p\\in F$ ，则称字符串x，被M接受，意义上来理解，就是输入x，M从q0转移到终结状态F\n\n\n\n### 3.2 非确定有穷自动机 NFA\n#### 1. 定义\n- 非确定的有穷自动机（NFA）五元组 $G=(Q,\\Sigma,\\delta,q_0,F)$\n    - 1. Q是有穷状态集\n    - 2. $\\Sigma$ 是有穷输入字符表\n    - 3. $\\delta$ 是非确定的状态转移函数，$Q\\times \\Sigma$到$2^Q$ 上的映射\n    - 4. $q_0\\in Q$ 是初始状态\n    - 5. $F \\subset Q$ 是终结状态集\n\n#### 2. 转移函数一般形式：\n$\\delta(q,a)=\\{p_1,.....,p_k\\} \\quad p_i\\in Q$ 或者 $\\delta(q,a)=\\emptyset$\n    \n#### 3. 扩充转移函数\n类似有穷自动机定义，输入一个串，对每个字符进行状态转移，最后得出的最终状态**集合**\n\n#### 4. 接受条件\n如果 $\\delta(q_0,\\ x)\\cap F$ 非空，则称字符串 $x$ 被 $M$ 接受\n\n\n\n### 3.3 NFA与DFA的等价性\n- 当给定某类中的一个有穷自动机，一定存在另一类中的一个有穷自动机，两者接受同样集合，则称二者等价。\n\n#### 1. NFA与DFA等价\n- 证明： 构造法 构造 DFA，其定义为\n    - 对于Q',其将NFA中Q的每一个子集作为Q'中的一个状态，若子集为 $\\{q_1,q_2,..,q_n\\}$ ，则Q'中状态记为 $[q_1,q_2,..,q_n]$ \n    - 对于 $\\delta^{'}$ ，定义为$$\\delta^{'}([q_1,q_2,..,q_n],a) = p_1,p_2,..,p_n \\\\ iff \\\\ \\delta(\\{q_1,q_2,..,q_n\\},a) = p_1,p_2,..,p_n $$ \n\n进一步证明 TODO\n\n#### 2. NFA至DFA的转换\n构造方法，从NFA出发，并不需要直接一步写出Q的幂集，而是看NFA中存在哪些状态。\n例题3.4\n\n#### 3. 具有$\\epsilon$动作的有穷自动机\n在不接受输入符号，输入为$\\epsilon$ 时能做转移动作\n即转移函数 $\\delta$ 扩充至$Q\\times (\\Sigma \\cup \\{\\epsilon\\})$ 到 $2^Q$ 的映射\n\n- $\\epsilon -CLOSURE(q)$\n直白的说，就是如果NFA只接受空动作能够到达的状态集合\n\n- 定义\n    - 1. $q\\in \\epsilon -CLOSURE(q)$\n    - 2. 递归，若$p\\in \\epsilon -CLOSURE(q)$，则$\\delta(q, \\epsilon)\\in \\epsilon -CLOSURE(q)$\n    - 规定：$\\epsilon -CLOSURE(P) = \\mathop{\\cup}\\limits_{q\\in P}\\epsilon -CLOSURE(q)$\n\n- 扩充函数\n非简单扩充，就是说 $\\hat\\delta(q,a) \\neq \\delta(q,a)$，因为空输入也可以转移状态，其他差不多\n\n- 接受语言\n$L(M)=\\{w|\\hat\\delta(q_0,w) \\cap F \\}$ 非空\n*增加空动作没有增加表达能力，即有空动作和没有空动作的NFA等价*\n\n- 空动作NFA与NFA等价\n构造法，对具有空动作的NFA M构造 $M'=(Q',\\Sigma^{'},\\delta^{'},q_0,F^{'})$，\n\n$\\hat \\delta(q,a)$ 即 $\\delta(\\epsilon -CLOSURE(q), a)$\n- $\\delta^{'}(q,a) = \\hat\\delta(q,a)$\n- $$ F^{'}=\\left\\{\n    \\begin{array}{rcl}\n        F\\cup \\{q_0\\} && {如果\\epsilon-CLOSURE(q_0)\\cap F非空}\\\\\n        F && {否则}\n    \\end{array} \\right. $$\n证明对 |x| 进行归纳 TODO\n\n\n\n### 3.4 正规表达式和正规集\n- 正规表达式递归定义\n    - 1. $\\phi$ 是一个正规表达式，代表空集\n    - 2. $\\epsilon$ 是一个正规表达式，代表集合 $\\{\\epsilon\\}$ \n    - 3. 对于 $\\Sigma$ 中每个符号a，a是正规表达式，代表集合{a}\n    - 4. 如果r和s是正规表达式，分别表示集合R和S，则(r+s),(rs)和(r*)是正规表达式，分别表示 $R \\cup S$、$RS$ 和 $R^*$ \n\n正规表达式代表的集合称为正规集\n\n<img src=\"/uploads/upload_e70fbfc8866d389b084873dd20ba2e72.png\" style=\"height: 300px;\">\n\n- 运算优先级\n$* > 连接 > +$\n\n- 对应自动机\n有穷自动机 DFA\n有穷自动机所能接受的集合类和正规表达式所能表示的集合类统称为正规集类\n\n- 定理3.3 r为正规表达式，则有一个具有空动作的NFA接受L(r)\n归纳法证明，归纳r的构造次数\n- 基础：r构造次数为0，即r是 $\\epsilon$ 、$\\phi$ 、$\\Sigma$ 中某个元素a\n- 归纳\n    - r = r1 + r2\n    归纳假设有 M1 接受 r1, M2 接受 r2\n    则构造一个M将两个M1,M2并起即可，形式说明TODO\n    - r = r1r2\n    归纳假设有 M1 接受 r1, M2 接受 r2\n    则构造一个M先过M1再过M2即可，形式说明TODO\n    - r = r1*\n    归纳假设有 M1 接受 r1,\n    则扩展一下M1，让其终结状态可以回到开始状态重复判断即可，形式说明TODO\n    \n- 定理3.4 如果L被DFA接受，则L可用正规表达式表示\n对各状态进行编号，记 $R_{ij}^k=\\{x\\mid \\delta(q_i,x)=q_j，中间不经过编号大于k的状态 \\}$ ，有递推式 $R_{ij}^k=R_{ik}^{k-1}(R_{kk}^{k-1})^*R_{kj}^{k-1}\\cup R_{ij}^{k-1}$  ，然后归纳证明 $R_{ij}^k$ 可用正规表达式表示\n\n\n\n### 3.5 具有输出的有穷自动机\n1. 摩尔机\n2. 米里机\n\n非重点\n\n\n\n---\n\n\n\n## 第四章 正规文法与正规集的性质(重要)\n- 缩胀定理（重点），反证法证明 \n- 极⼩化的处理，掌握极⼩化的算法（过程）（明示了快背），如何优化有穷⾃动机 \n- ⻨⻄尔-尼诺德定理，需要掌握 \n\n\n### 4.1 正规文法与有穷自动机的关系\n\n- **Th4.1**\n-- 设 $L$ 被某个正规文法 $G$ 产生，则 $L$ 可被某个有穷自动机接受\n\n\n- **Th4.2**\n-- 设 $L$ 被某个DFA $M$ 接受， 则 $L$ 可被某个正规文法产生\n\n构造方法：\n- $A\\to aB$ 对应 $\\delta(A,a)=B$\n- $A\\to a$ 对应 $\\delta(A,a)=f\\in F$\n\n### 4.2 正规集的缩胀定理\n\n1. **有穷自动机表达能力有限**\n\n2. **Th4.3 正规集的缩胀定理(pumping Lemma)：存在整数 $k \\geq 0$ ，对于任意串 $x, y, z$ 这里 $xyz \\in A$， 只要$|y| \\ge k$ ，就可以将 $y$ 写成 $y=uvw, \\quad v \\ne \\sigma$ ，并且对于任何 $i \\ge 0$，都有 $xuv^{i}wz \\in A$**\n- 证明：定理的直观含义为：如果 $A$ 是正规集，那么当它的元素含有**足够长**的子串 $y$ 时（x与y的长短不重要）， $y$ 就一定包含一个非空的子串 $v$ （$u, w$ 的长短不重要），这个子串 $v$ 可以“膨胀”任意多次 （$i > 0$），或者被“删除” （$i = 0$），而 $xuv^{i}wz$ 仍然属于 $A$\n\n- 设 $k$ 是接受正规集 $A$ 的 $DFA$ 状态数，因为 $y$ 的长度大于或等于k， 则 $DFA$ 在扫视 $y$ 的过程中，必然出现重复的状态，串 $v$ 就是该状态相邻的两次出现过程中扫视过的子串。\n\n$$\n\\sigma(q_{1}, u)=p, \\sigma(p, v)=p, \\sigma(p, w)=q_2\n$$\n\n其余的推理过程与例2.10的分析相同\n\n- *正规集的缩胀定理经常用来指明某些集合不是正规集，通常就是反证法，大家都懂的。*\n\n### 4.3 正规集的封闭性质与判定算法\n\n- 在并、连接和闭包运算下是封闭的\n- 在补运算下封闭，即若 $L$ 是正规集，且 $L\\subseteq\\Sigma^{*}$ ， 则 $\\Sigma^{*}-L$ 也是正规的\n- 在交运算下封闭\n- 在商运算下封闭（暂且理解：两个正规集做商运算，其结果必然是正规集）\n\n\n\n- *Th4.9*\n具有n个状态的有穷自动机具有如下性质：\n    - 1)它接受的集合非空，当且仅当它接受一个长度小于n的字符串 \n    - 2）它接受的集合是无穷的，当且仅当它接受一个长度为1的字符串，这里 $n \\leq l < 2n$\n- *两个有穷自动机是否等价是可判定的*\n\n### 4.4 有穷自动机的最小化\n\n**一个减少状态数的思路：给定 $DFA \\ =(Q, \\Sigma, \\delta, q_{0}, F)$，根据等价关系构造出一个 $DFA M/ \\equiv$，该 $DFA$称为 $M$的商自动机**\n\n- **判断两个状态等价：** 对于 $p, q \\in Q$， 若对于每个 $x \\in \\Sigma^{*}, \\quad \\delta(p, x) \\in F$当且仅当 $\\delta(q,x) \\in F$， 就称 $p, q$ 等价，记作 $p \\equiv q$\n\n**极小化算法过程：**\n-- *在 $DFA$ 的状态集上确定所有的状态对是否等价*\n1. 对所有状态对 ${p, q}  (p, q \\in Q)$画一张表，开始时中每个格子均为空白（未做标记）\n2. 对一切 $p \\in F, q \\notin F$ 的 ${p, q}$，在相应格子上做标记（例如画一个X）\n3. 重复下述步骤，直到表中内容不再改变为止：如果对于某个 $a \\in \\Sigma$， 存在一个未被标记的状态对 $\\{p, q\\}$，使得 $\\{\\delta(p,a),\\delta(q,a)\\}$已做标记，则将 $\\{p, q\\}$ 做标记\n4. 完成1，2，3之后，所有未被标记的状态对都是等价的，即 $p \\equiv q$\n\n### Myhill-Nerode 关系\n**判定方式**\n- 对某个集合$A \\subset \\Sigma^*,\\quad$ R为$\\Sigma^*$上的等价关系。若R满足\n    - 1. 是右不变的\n    - 2. 细分A\n    - 3. 具有有穷指数\n\n- 则称R为A的 Myhill-Nerode 关系\n\n### Myhill-Nerode 定理\n- A是一个正规集\n- $\\Sigma^*上存在关于A的MN关系$\n- $R_A$ 具有有穷指数\n\n\n\n---\n\n\n## 第五章 上下文无关文法与下推自动机\n重点:\n- 了解化简（作业题） \n- ⼀定要会两种范式（乔姆斯基范式&葛雷巴赫范式） \n- 构造下推⾃动机（作业题）\n\n### 5.1 上下文无关文法的化简\n检验文法$G=(V, T, P, S)$中是否有无用符号 （变元或终结符），若有，则将其消除。\n#### 无用符号\n- $X \\in V \\cup T$ 但X不出现在任何由S派生出的字符串中。\n- $X \\in V$ 但X不能派生出任何终结符号串\n\n- Th5.1 不带无用符号的CFG可生成所有非空CFL\n \n    化简思路\n    - 1. 找到无用符号（一类二类）\n    - 2. 删除无用符号\n    - 3. 返回1继续检查，直到不产生无用符号为止\n    \n    PPT思路\n    - 1. 首先删除二类无用符号 \n    - 2. 接着删除一类无用符号\n    - 3. 返回1检查，直到不产生无用符号\n\n\n#### $\\epsilon$ -生成式\n形如 $A \\to \\epsilon$ 的生成式，如果 $\\epsilon \\in L(G)$ 那么不能删，其余都可以删除。\n- 可为零\n如果在CFG中，A属于变元集合，如果有A派生出$\\epsilon$则称A为可为零的。\n\n- Th5.3 可为零的可判定性\n对于CFG中任意变元是否可为零是可判定的\n判定思路：\n\n-  1. 对$A \\to \\epsilon$ 即trivial的本来就可为零的，将A加入Z\n- 2. 对于一切生成式 B，有$B \\to \\alpha$ 如果 $\\alpha \\in V^+$在中所有变元均在Z中，将B加入Z\n- 3. 重复1，直至没有元素加入Z为止\n    \nZ 中元素均为可为零的元素\n\n- Th5.2 不带无用符号且没有$\\epsilon$-生成式的CFG可以生成所有不包含空串的CFL\n**不会证 ；）**\n\n\n#### 单一生成式\n形如 $A \\to B$ （A、B皆为变元）的生成式\n\n#### 结论\n上面说的三个都可以消掉\n\n\n\n### 5.2 上下文无关文法的范式\n\n#### 乔姆斯基范式 Chomsky （CNF定理）\n任何不包含$\\epsilon$的CFL，都可由生成式仅为 $A \\to BC$ 或 $A \\to a$ （A，B，C为变元，a为终结符）形式的文法产生\n（化为乔姆斯基范式，例题5.3）\na\n\n#### 格雷巴赫范式 Greibach (GNF定理)\n任何不包含$\\epsilon$的CFL，都可由生成式仅为$A \\to a\\alpha$ (a为终结符,$\\alpha$ 为变元串，包含空串）形式的文法产生\n\n//TODO\n\n\n\n### 5.3 下推自动机\n下推自动机（简称PDA）是一个七元组 $M=(Q,\\Sigma,\\Gamma, \\delta, q_0, Z_0, F)$\n- Q是有穷状态集\n- $\\Sigma$是有穷的输入字母表\n- $\\Gamma$是有穷的栈符号表\n- $\\delta$是转移函数，将$Q \\times (\\Sigma \\cup \\{epsilon\\} \\times \\Gamma)$ 映射到$(Q\\times \\Gamma^*)$ 的有穷子集\n- $q_0 \\in Q$ 是初始状态\n- $Z_0 \\in \\Gamma$ 是栈底符号\n- $F \\subset Q$ 是终结状态集\n\n#### 转移函数\n三元组 $\\delta(q,a,Z) = \\{(p_1,\\gamma_1), (p_2, \\gamma_2),...,(p_m, \\gamma_m)\\}$ 其中 q, a 一个状态一个输入字符，Z为栈顶符号\n\n状态由 $q \\to p$，栈顶符号由 $Z \\to \\gamma$\n转移动作不确定\n- 函数值有m种选择 （m可以为0）\n- 读头不动也可以有函数值\n\n#### 瞬时描述\n\n$(q_0,w,Z_0) \\mathop{\\vdash}\\limits_{M}^*\\ (p, \\epsilon, \\gamma)$ 表示从状态 $(p, \\gamma) \\in \\delta(q_o, w, Z_0)$，上一个字符为w，下一个字符为 $\\epsilon$\n\n即由一个瞬时描述 ID 转移到下一个 ID\n\n#### 按终结方式接受\n\n若M是一个PDA，集合$L(M)=\\{w|(q_0,w,Z_0) \\mathop{\\vdash}\\limits_{M}^*\\ (p, \\epsilon, \\gamma)\\}$\n则称M按终结状态方式接受的语言\n\n- 接受状态\n还是由初始状态到接受状态，和栈中符号没什么关系，栈符号只影响状态转移\n*不过如果输入串未读完栈就变空，无法进行状态转移，则w不可能被接受。*\n\n\n#### 按栈空方式接受\n- 接受状态\n顾名思义，读完之后栈空了就接受了，终结状态则不影响是否接受。\n\n构造PDA接受$0^n1^n$，例题5.5\n- 例题 5.6、5.7\n\n\n\n\n### 5.4 下推自动机与上下文无关文法的关系\n- 下推自动机接受的语言类是上下文无关文法 CFL (2型文法)\n\n\n\n\n---\n\n\n## 第六章 上下文无关语言的性质\n重点\n- 缩胀定理/ogden定理（尤其考察后者）\n- 考察给⼀个语⾔判断是否是上下⽂⽆关语⾔ 封闭属性 \n- 成员资格判定问题（PPT）,CYK算法\n\n### 6.1 CFL缩胀定理\n回忆一下正规集缩胀定理\n正规集中每个足够长的字符串，都包含一个短子串可扩张任意多次，所得字符串仍然属于该正规集\n\n- CFL 缩胀定理\n在CFL中，每个足够长的字符串，都包含两个相距不远的短子串，两个子串可以扩充任意多次，所得子串仍然属于CFL\n\n**形式描述：**\n对于每个CFL，都存在正整数 $k \\ge 0$ 使得对每个$z \\in L$ 只要 $|z| \\ge k$ 就可将z划分为5个子串，\n满足以下三个条件\n1. 对任何的$i \\ge 0$ 都有$uv^iwx^iy \\in L$\n2. $|vx| \\ge 1$\n3. $|vwx| \\le k$\n\n（其中 k = $b^{|V| + 1}$，其中b是生成式右侧符号数的最大值）\n看计算理论导引P77，写的很清楚\n\n\n### 6.2 Ogden定理\n**形式描述：**\nL为CFL，存在整数$k \\ge 0$，使得对每个$z \\in L$，并且在z中标出k个或多于k个特别符号，将z写成z=uvwxy，且满足\n1. v和x一起至少包含一个特别符号\n2. vwx之多包含k个特别符号\n则对任何$i \\ge 0,\\ uv^iwx^iy \\in L$\n\n例题6.4 \n\n\n### 6.3 CFL封闭性质\n\n回忆一下RL的封闭性质，RL在以下运算下封闭\n- 交并补\n- 连接\n- 闭包\n- 商\n\n**CFL在以下运算下封闭**\n- 并 \n对G1,G2，生成式的开始元S1，S2\n构造 G3 $S \\to S1 | S2$\n\n- 连接\n对G1,G2，生成式的开始元S1，S2\n构造 G3 $S \\to S1S2$\n\n- 闭包\n对G1,G2，生成式的开始元S1\n构造 G3 $S \\to S1S|\\epsilon$\n\n**注意 CFL 在 *交* $\\cap$ 和 *补* $\\hat{ }$ 运算下不封闭**\n- 交\n$L1= {a^ib^ic^j|i \\ge 1, j \\ge 1}$, $L2= {a^ib^jc^j|i \\ge 1, j \\ge 1}$\n两者是CFL\n但其交集$L1 \\cap L2= {a^ib^ic^i|i \\ge 1}$ 不是CFL，可由Pumping LEmma 证得\n\n- 补运算\n交运算，可化为补+并的形式，若补运算封闭，则由于并运算封闭，可证得交运算封闭，推出矛盾。\n\n#### CFL和正规集的交是CFL\n- 定理6.6 若L是CFL，R是正规集，则$L\\cap R$是CFL\n\n\n### 6.4 CFL判定算法\n\n#### 给出CFG G=(V, T, P, S), L(G)是否为空和是否有穷问题是可判定的\n- L(G) 是否为空\n    - 检验S是否能派生出终结符号串\n    - 若能，则L(G)非空；不能则为空\n- L(G)是否有穷\n    - 对G的Chomsky范式，以变元为顶点画出有向图\n    - 原问题 $\\Leftrightarrow$ 该有向图是否有回路\n    - 即X的最长路径长度为l，则从X派生出的终结符号串长度不超过$2^l$ (归纳假设)\n\n图论算法判定一个有向图是否有回路，所以L(G')是否有穷，是可判定的\n\n### 6.5 成员资格问题\n**给定一个CFG G和一个终结符串x，问x是否属于L(G)**\n暴力算法思想，对于G的Greibach范式文法，从S生成式推出右侧的第一个终结变元和x串的第一个符号比较，如果对应就把右侧第二个变元的推出式拿出重复上述操作，直到接受或拒绝为止，时间复杂度$O(m^n)$\n\n#### CYK算法\n时间复杂度 $O({|x|}^3)$\n倒着的树，看Vij表，懂的都懂\n（区间DP）\n![](/uploads/upload_e2b3e93174f7cd571038ce381a21f95c.png)\n\n\n---\n\n\n## 第七章 图灵机\n重点\n- 构造语⾔的图灵机（会考的稍微复杂）\n- 图灵机构造技术 其他类型的图灵机（多带的、⾮确定、双栈机） \n- 枚举器，正则次序，对偶产生器\n\n### 7.1 图灵机基本模型\n确定单带图灵机是一个9元组 $M=(Q,\\Sigma,\\Gamma,\\vdash, \\diamond,\\delta,s,t,r)$\n- 1. Q有穷状态集\n- 2. $\\Sigma$有穷输入字母表\n- 3. $\\Gamma$有穷的带字母表\n- 4. $\\vdash$ 左端标记\n- 5. $\\diamond$ 空白符号\n- 6. $\\delta$ 转移函数\n- 7. $s \\in Q$ 开始状态\n- 8. $t \\in Q$ 接受状态\n- 9. $r \\in Q$ 拒绝状态\n\nL 表示读写头左移，R表示右移，对于左端标记，永远有$\\delta(p,\\vdash)=(q,\\vdash,R)$\n\n- 递归可枚举集\nTM M接受的语言，称为递归可枚举集\n\n- 递归集\n被完全 TM M 接受的语言，称为递归集\n\n- 完全TM\n对一切输入均能停机（达到接受或拒绝状态）\n\n例题做做做\n\n\n### 7.2 图灵机构造技术\n\n#### 有限控制器中的存储\n- 元组表示状态，将带上符号吸收到状态中\n\n#### 移动\n- 将带上符号不断吸收到状态中，不断写下，达到整体移动的目的\n\n#### 多道技术\n- 保存处理更复杂的数据，例如计算$n^2$\n\n#### 查讫符号\n- 即给带上符号打标记，利用到多道技术\n- 常用于区分某个符号是否查过\n- 例7.7 构造一个识别 $l={wcw|w \\in \\{a,b\\}^+}$的 $TM$\n\n#### 子程序技术\n- 懂的都懂，大概不考\n构造TM M实现乘法运算\n\n\n### 7.3 图灵机的变型\n\n#### 双向无限带\n- 将图灵机的单向无限延伸扩大到双向无限延伸\n    - 无左端标记$\\vdash$\n    - 其余符号和功能均与单向无限带TM相同\n\n并没增加其表达能力，和单带相同\n- 可以构造一个双带单向无限图灵机，识别能力与双向无限图灵机相同（定理7.1）\n\n#### 多带\n- 用一个控制器控制k条带，在每条带上有独立的读写头\n**和多道技术的区别**\n多道技术是一个控制器多个带，这个是多个控制器多个带。\n- 给一些证明带来许多方便\n- 并没增加其表达能力，和单带相同\n\n\n#### 非确定图灵机\n**确定的图灵机 $\\delta$ 是单值函数，非确定性图灵机增加非确定性动作，并未改变其识别能力**\n- 可以证明确定型图灵机与非确定型图灵机的等价性\n定理7.3 若L被一个非确定的TM $M_1$ 接受，则L也被某个确定的TM $M_2$ 接受。\n\n#### 双栈机\n其是特殊的三带图灵机\n一个带用于输入，只读不写\n另外两个用来模拟栈\n- 读头右移，可写任意符号 （进栈）\n- 读头左移，只能写空白符 （退栈）\n读头指向为栈顶，左端标记右边那个为栈底\n\n- 任意的单带图灵机能被双栈机给模拟\n右移时，右栈弹栈，左栈压栈。反之类似\n\n**下推自动机是单栈机，所以其能力比图灵机小， 即$PDA < TM$**\n**图灵机是下推自动机的扩充，能接受其不能接受的语言**\n\n#### 带字母最少的图灵机\n- 限制带字母表上只有 $0,\\ 1,\\ \\diamond$ 三个符号\n- 和任何TM等价\n\n#### 作为枚举器的图灵机\n- 用一条带专门作为输出带，带上符号一旦写上就不改动，带头一直往右，永不回头。\n\n#### 枚举器和TM的等价\n- 设对某个枚举器 $M_1,\\ L=G(M_1)$, 则存在TM $M_2$ 使得 $L(M_2) = L$\n    - 构造M2，M2比M1多一条输入带，比较M2的输入和M1产生的串，如果相等则接受，不相等则与M1产生的下一个串继续比较，这样进行。\n    - 因为M1产生的串都是M2能接受的，M1不能产生的串都是M2不能接受的（不停机）所以 L(M2)=G(M1)=L\n\n#### 对偶产生器\n- 一个过程，以i+j不减的顺序列出正整数对(i,j)\n\n#### 字母表 $\\Sigma$ 上串的正则次序\n- 先按长度排序\n- 再按字典序\n\n\n### 7.4 图灵机与0型文法的关系\n图灵机对应0型文法\n\n\n\n---\n\n\n## 第八章 不可判定性\n重点\n- 递归集和递归可枚举集的属性 \n- 两个不可判定问题（停机问题+成员资格问题） \n- 通⽤图灵机的概念，图灵机的⼆进制编码 \n- Rice定理\n\n### 8.1 递归集和递归可枚举集性质\n#### **补集**\n- 一个递归集的补集仍然是递归集\n因为完全TM\n调换接受拒绝状态\n\n#### **并集**\n- 递归集的并是递归的，递归可枚举集的并是递归可枚举的\n    - 对于递归集，其是由完全TM生成的语言集合那么对于输入串，可先经M1进行验证，若接受则接受，若不接受则进第二个M2，重复上述过程。 （这里的保证是因为他们是完全TM，可以停机）\n    - 对于递归可枚举集，构造非确定M3',对输入分别在M1，和M2上验证，如果有一个接受则接受，可见M3‘的停机问题也是不可判定的，为一般TM。\n\n#### **交集**\n- 递归集的交是递归的，递归可枚举集的交是递归可枚举的\n\n看ppt的图，应该很清楚\n\n- 若语言 L 和 L补 都是递归可枚举的，则L（和L补）是递归的\n\n\n\n### 8.2 通用图灵机和两个不可判定问题\n\n#### 通用图灵机\n模拟任何图灵机的图灵机，将某个TM作为通用图灵机的输入来看待\n- 需要对TM有统一的、合理的编码\n- 在给定输入串上，模拟TM的动作\n- 给定TM接受，则该TM接受这个TM和这个输入的二元组\n\n#### 图灵机编码\nM#w\n\n#### 关于停机问题的不可判定性\n- 没有一个算法在有限步之内能够判断一个TM M在给定的输入串x上是否能停机。\n    -  1. 接受状态\n    -  2. 拒绝状态\n    -  3. 无限循环\n\n- **任意给定TM M对任意给定输入串x是否停机的问题是不可判定的**\n自指悖论（类似**罗素悖论**的方法）\n\n**证明**\n\n- **Step 1 TM编码**\n    - 由于可对TM进行编码，所以任何TM可以表示为01串\n    - 而我们可以把任何零一串看作一个TM\n    - 在上述规定下，可按正则次序列出所有TM \n    $M_{\\epsilon},\\ M_0,\\ M_1\\ ,M_{00},\\ M_{01}...$\n    显然真正的TM一定出现在此序列中至少一次\n    \n\n- **Step 2 二维表标记**\n    - 考虑无穷维的二维表，其顶端遍历 $\\{0, 1\\}^*$ 的正则序列，左端遍历 TM，用H (Halt) 表示停机，用L (Loop) 表示不停机，在对应位置做上标记\n\n- **Step 3 开始证明**\n    - 假设存在完全TM K，以Mx#y为输入，能够判断Mx在y上是否能够停机。如果停机，则 K 接受 Mx#y；否则，拒绝\n    - 构造另一个TM N，其输入为 $x \\in \\{0, 1\\}^*$ 其完成以下任务\n        - 从x找到Mx，将Mx#x写到其带上\n        - 在 Mx#x 上模拟K的动作，如果K接受，则其就进入循环（不停机），如果K拒绝，他就接受。\n    - 那么根据N的定义，如果N在x上停机，则代表K拒绝，则代表Mx在y上不停机。\n\n- **Step 4 推出矛盾**\n    - 因为N也是图灵机，假设其编码为y，在正则序列中出现为My，如果N在y上停机，则代表My在y上不停机，而My就是N，导致矛盾。矛盾起因是K的存在性\n所以不存在这样的TM能够判断M在任何输入下是否停机，即停机问题是不可判定的\n\n#### 成员资格问题的不可判定性\n- **对于任意给定 TM M 和输入串x，M是否接受x的问题是不可判定的**\n\n    - 1. 存在完全的 TM K，它能对任意的M和x，判断x是否属于L(M)。若$x \\in L(M)$，则K接受$M\\#x$；否则拒绝\n\n    - 2. 构造N，使得如果x在M上达到接受或拒绝的停机状态，则N接受。可以看出N是判断M在x上是否停机的TM。\n\n    - 3. 现在对M输入N#x，则N是否接受x等价于x在M上是否停机，而停机问题是不可判定的，所以成员资格问题也不可判定。\n\n\n\n\n### 8.3 归约方法和Rice定理\n- **给定TM M其是否接受空串的问题是不可判定的**\n\n将HP的不可判定性导出问题B的不可判定性\n- HP Halt Problem 停机问题\n- B 其他问题\n\n\n#### Rice定理\n- r.e.集合类的任何一个非平凡性质都是不可判定的\n\n- **Step 1 准备** \n    - 设 P 是 r.e. 集合类上的一个非平凡性质，不失一般性，假设空集不具有性质P，则因为P的非平凡性，必定存在一个集合A满足P，即P(A) = T设K是接受A的TM\n\n- **Step 2 归约HP到集合 $\\{M|P(L(M)) = T\\}$**\n    给定M#x, 构造TM M'，其按以下步骤进行\n    - 对于TM的输入y，将其放在一个道上\n    - 将x写在另一个道上\n    - 在M上模拟x的动作\n    - 如果M在x上停机，则在K上模拟y的动作\n    - 如果K接受y，则M'接受y\n\n- **Step 3 推出矛盾**\n    - 显然，M和M'的停机问题相关联，如果停机有 M' 和 K 接受一样的集合。\n    - 所以有 M 在 x 上停机，可推出，L(M') = A，可推出 P(L(M')) = T\n    - 反之则不停机，P(L(M')) = F\n    - 这就得出了停机问题到该问题的归约，但停机问题不可判定，所以其非平凡性质也不可判定。\n\n\n\n\n### 8.4 关于CFL的不可判定问题\n\n\n### 8.5 Post对应问题的不可判定性及其应用\n\n\n\n---\n\n\n## 第九章 线性有界自动机和上下文有关语言\n重点\n- 给定语⾔，构造LBA \n- LBA对停机问题的判定问题\n\n各种机器对应的不同⽂法，⽐如FA对应CFG，图灵机对应0型，PDA对应CFL\n\n### 9.1 线性有界自动机 LBA\n- 对TM的读写头范围加以限制\n- 左右端都有标记\n- 接收机和小于TM接受的集合类\n\n线性有界自动机 LBA 是9元组 $M=(Q,\\ \\Sigma, \\Gamma, \\vdash,\\ \\dashv, \\delta,\\ s,\\ t,\\ r)$\n- 1. Q 有穷状态集\n- 2. $\\Sigma$ 有穷输入字母表\n- 3. $\\Gamma$ 有穷带上字母表\n- 4. $\\vdash$ 左端符号\n- 5. $\\dashv$ 右端符号\n- 6. $\\delta$ 状态转移函数\n- 7. s 开始状态\n- 8. t 接受状态\n- 9. r 拒绝状态\n\n***例题9.1***\n思路：\n- 1. 查讫符号打标记后找到中心\n- 2. 对消\n\n### 9.2 LBA 和 CSL 的关系\n- 若L是CSL，则L可被某个LBA接受\n\n将S派生出来的各种字符串（在下道），与上道的w比较，若相等则接受\n\n### 9.3 CSL的性质及其和递归集的关系\n#### CSL封闭性\n- 并\n- 连接\n- 正闭包（因为CSL不包含 $\\epsilon$，所以L1为CSL则其闭包 $L_1^*$ 不是CSL）\n- 交运算\n\n#### 每个CSL都是递归的\n思路：\n因为输入串长度有限，并且两端封闭，所以总的情况数是有限的为$k(n+2)l^n$ 种，那么用双带，一带正常执行，令一带计算执行步数，如果超出则说明进入循环，则拒绝。所以有CSL是递归的\n\n#### 存在递归集，不是CSL\n\n\n### 9.4 语言类之间的关系\n\n1. RL(3型文法RG)\n2. DCFL\n3. CFL(2型文法CFG)\n4. CSL∪\\{ε\\}(1型文法CSG)\n5. 递归集\n6. r.e.集（递归可枚举集）(0型文法PSG),如成员问题所对应的字符串\n7. 非r.e.集，如FIN\n\n\n\n---\n\n\n\n## 第十一章\n重点\n- 给定语⾔：判断是P还是NP\n- P与NP的封闭性证明 常⻅的NPC问题的推导和证明(重点)\n    - 证NP问题\n    - 证归约性 \n- P NP NPC NPHARD的概念 \n- PSPACE==NPSPACE-NPSPACEhard \n- L-NL（构造：利⽤指针） \n- 后⾯的层次定理&布尔电路不考\n\n### 层次概览\n\n![](https://codimd.s3.shivering-isles.com/demo/uploads/upload_81564f07be5cb20ec62f5761169626dc.png)\n\n![](https://codimd.s3.shivering-isles.com/demo/uploads/upload_aeeccf9bef7be94af30f6875bdf5d5e1.png)\n\n$$L \\subset NL = coNL \\subset P \\subset NP \\subset PSPACE = NPSPACE \\subset EXPTIME$$\n\n### P类\n- 定义： P是确定型单带图灵机在多项式时间内可判定的语言类\n\n$$P = \\mathop\\cup\\limits_{k} TIME(n^k)$$\n\n#### **PATH $\\in$ P**\nPATH 问题，即G（有向图）中两点判定是否存在有向路径\n用BFS算法，O(m)\n或者dijkstra算法\n\n#### **RELPRIME $\\in$ P**\nRELPRIME 问题，即判定两数互素\n辗转相除法（欧几里得算法）\n\n#### **每个CFL都是P**\nCYK 复杂度$O(n^3)$\n\n### NP类\n\n#### **引理：NP是具有多项式时间验证机的语言**\n- 用于验证该问题的额外信息称为证书\n    - HAMPATH 中两点之间的哈密顿路径\n    - COMPOSITES 中 x 一个不等于1的因子\n\n#### **一个语言在NP中，当且仅当其能够被某个非确定型多项式时间图灵机判定**\n\n#### **NTIME(t(n)) = {L| L 是一个被O(t(n))时间的非确定型图灵机判定的语言}**\n$$NP = \\cup_k NTIME(n^k)$$\n\n\n#### **CLIQUE $\\in$ NP**\nCLIQUE = {(G,k)| G是包含k团的无向图}\n- 验证机角度\n        证书：团，记为c\n        V为CLIQUE的验证机\n        V = 对输入((G,k), c)\n        1. 检查c是否是G中k个点的集合\n        2. 检查G是否包含连接c中节点的所有边\n        3. 若均通过则接受，否则拒绝\n        \n- 非确定型TM角度\n        N = 对于输入(G,k)\n        1. 非确定的选择G中k个节点的子集c\n        2. 检查G是否包含连接c中节点的所有边\n        3. 若是则接受，否则拒绝\n\n\n#### **SUBSET-SUM $\\in$ NP**\nSUBSET-SUM，给定集合s和t，判定是否有s的子集y，使得子集y中元素之和等于t\n- 验证机角度\n        证书：子集\n        V = 对输入((s,t),c)\n        1. 验证c中元素之和是否等于t\n        2. 验证s是否包含c中所有元素\n        3. 若均通过则接受，否则拒绝\n        \n- 非确定型TM角度\n        N = 对于输入(s,t)\n        1. 非确定的选择s中的子集c\n        2. 验证c的元素之和是否等于t\n        3. 若是则接受，否则拒绝\n        \n- co-NP\n\n### P与NP问题\n- P = NP ?\n$$NP \\subset EXPTIME = \\mathop\\cup\\limits_{k} TIME(2^{n^k})$$\n\n### NP完全性\n\n- 定义\n    - 1. B属于NP（多项式时间内被非确定图灵机判定）\n    - 2. NP中每一个A都可在多项式时间内归约到B（归约，重要步骤）\n    - 则称B为NP完全问题\n\n\n- 证明P=NP的一类思路\n    - 证明某个NPC $\\in$ P\n\n#### **库克-列文定理**\nSAT 问题，给定一个布尔公式$\\phi$判断其是否可满足\n$$SAT \\in P，当且仅当 P=NP$$\n\n证明：\n- 第一步：非确定图灵机可以在多项式时间内猜测变量的赋值，然后判断其是否可满足，因此 $SAT \\subset NP$\n- 第二步：\n    - 假设从$NP$取出任意语言$A$，非确定$TM N$在$n^k-3$判定\n    - 考虑$N$对应的$n^k\\times n^k$画面$\\omega$\n    - 设计一个$\\phi$,使得变量的一个满足赋值确实对应$N$在$\\omega$上的接受画面\n    - //todo\n\n#### **SAT $\\in$ NPC**\n\n为NP中的每一个语言A，构造一个到SAT的多项式时间归约\n书P170~173\n\n#### **3SAT $\\in$ NPC**\n\n#### **CLIQUE $\\in$ NPC**\n\n- **证明NPC**\n    - 先证明NP\n    - 再证明某个已知NPC问题可在多项式时间内归约到他\n\n\n#### 顶点覆盖问题 VERTEX-COVER\nVERTEX-COVER 判定G是具有k个顶点的顶点覆盖的无向图\nNP完全\n3SAT 到 VERTEX-COVER 的归约\n书P174\n- 证明思路：将一个$3nf$公式$\\phi$转化成一个图$G$和数值$k$，只要能找到覆盖，$\\phi$就被相应地满足\n\n#### 哈密顿路径问题 HAMPATH\nHAMPATH $\\in$ NPC\n3SAT 到 HAMPATH 的归约\n\n书p175~177\n\n#### 子集和问题 SUBSET-SUM\nSUBSET-SUM $\\in$ NPC\n3SAT 到 SUBSET-SUM 的归约\n\n书p178~180\n\n---\n\n### 萨维奇定理\n任何消耗$f(n)$空间的非确定型TM都可以转变为仅消耗$f^2(n)$空间的确定型TM\n\n$$NSPACE(f(n)) \\subset SPACE(f^2(n))$$\n\n方法：利用中间格局递归二分\nCANYIELD = 对于输入 c1，c2，t\n1. t=1 直接检查是否有c1 = c2 或根据N规则，检查c1是否能够一步只能产生c2，其中之一成立则接受，否则拒绝\n2. 若 t > 1，则对于N在w上消耗空间f(n)的每一个格局cm\n3. 运行CANYIELD(c1, cm, t/2)\n4. 运行CANYIELD(cm, c2, t/2)\n5. 两个都接受则接受，否则拒绝\n\n对输入 $c_{start}$，$c_{accept}$，$2^{df(n)}$\n\n递归深度$O(log2^{df(n)})$，所以总消耗空间$O(f^2(n))$\n\n### PSPACE类\nPSPACE是在确定型图灵机上，在多项式空间内可判定的语言类\n$$PSPACE = \\mathop\\cup\\limits_{k}SPACE(n^k)$$\n\n- SAT $\\in$ SPACE(n)\n- $ALL_{NFA} \\in coNSPACE(n) \\Rightarrow ALL_{NFA} \\in SPACE(n^2)$\n- 其都在PSPACE中\n\n- $P \\subset PSPACE$\n因为运行n步的程序，最多消耗n的空间\n\n- $NP \\subset NPSPACE$\n同理\n\n由于 NPSPACE = PSPACE\n所以有 $NP \\subset PSPACE$\n\n\n### PSPACE完全性\n定义 若B是PSPACE-C则其满足以下两个条件\n- 1. $B \\in PSPACE$\n- 2. PSPACE中每个语言A可多项式时间内归约到B\n- 只满足2类似NP难称其为PSPACE难的\n\n\n#### TQBF问题\n判定$\\phi$是真的全量词化布尔公式\n其是PSPACE完全的\n- 先给出一个线性空间的复杂度算法，证明其属于PSPACE\n- 再给出归约方式，类似萨维奇定理证明方法\n书 P192\n\n#### 博弈必胜\n$FORMULA_GAME = {<\\phi> | 在与\\phi相关联的公式博弈中选手E有必胜策略}$\n其是PSPACE完全的\n**因为其等价于TQBF**\n\n#### 广义地理学\n$GG = {<G,b> | 在图G上以结点b起始的广义地理学游戏中，选手I有必胜策略}$\n其是PSPACE完全的\n证明方法类似TQBF的递归算法\n\n### L和NL类\n亚线性空间界限，类似工作主存上是亚线性空间，其余放在外存（只读）。\n\n#### L类\n- L是确定型图灵机在对数空间内可判定的语言类\n$$L=SPACE(logn)$$\n\n#### NL类\n- NL是非确定性图灵机在对数空间内可判定的语言类集合\n$$NL=NSPACE(logn)$$\n\n- 例题 8.13\n$A = \\{0^k1^k| k \\ge 0\\} \\in L$\n在工作带上用二进制数0、1的数目，两个计数器消耗对数级别空间，所以$A \\in L$\n\n- $PATH \\in NL$\n非确定的猜测从s到t的每一步，工作带上只记录每一步当前节点的位置，非确定的选择下一个节点，反复执行，直到到达t接受。或执行m步后拒绝，m是节点数。由此得到了PATH的被非确定型图灵机在亚线性空间内接受。\n\n### NL完全性\n定义 若语言B是NL完全的，则其满足\n- 1. $B \\in NL$ \n- 2. NL中的每个A**对数空间**内可归约到B\n\n\n#### PATH是NL完全的\n证明方法，把输入字符串w对应为图，图中节点对应NTM在输入w上的一个格局。一个结点能指向另一个结点的调节时，其对应的格局能在NTM的一步内产生第二个结点对应的格局，因此，NTM对输入w是否接受就对应着初始格局到接受格局的PATH\n更详细的对数空间归约证明情况书 p199~200\n\n\n#### $NL \\subset P$\n- 1. 因为PATH是NL完全的，所以NL中任何语言可对数空间内归约到PATH\n- 2. 由此，NL中任何语言也可对数时间内归约到PATH\n- 3. 因为多项式时间内归约到P中语言的语言本身也属于P\n- 4. 所以 $NL \\in P$\n\n### NL = coNL\n\n\n\n\n\n\n\n\n","slug":"Computation_Theory/note","published":1,"updated":"2026-02-03T05:42:14.427Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvi00387uit5f2n2noa","content":"<h1 id=\"计算理论基础\"><a href=\"#计算理论基础\" class=\"headerlink\" title=\"计算理论基础\"></a>计算理论基础</h1><h2 id=\"第一章-预备知识\"><a href=\"#第一章-预备知识\" class=\"headerlink\" title=\"第一章 预备知识\"></a>第一章 预备知识</h2><p>重点：</p>\n<ul>\n<li>符号表示，可能在问答题里面出现</li>\n</ul>\n<h3 id=\"1-1-定理及其证明方法\"><a href=\"#1-1-定理及其证明方法\" class=\"headerlink\" title=\"1.1 定理及其证明方法\"></a>1.1 定理及其证明方法</h3><ul>\n<li>形式系统</li>\n</ul>\n<ol>\n<li><strong>基本符号</strong> <em>（常量符号、变量符号、运算符等抽象字符）</em></li>\n<li><strong>形成规则</strong> <em>(构造各种语言的方法规则)</em></li>\n<li><strong>公理</strong> <em>（无需经过证明，正确性得到公认的语句）</em></li>\n<li><strong>推理规则</strong> <em>（用于得到新的合法语句）</em></li>\n</ol>\n<ul>\n<li><em>如何证明一个语句为真</em></li>\n</ul>\n<ol>\n<li>每个语句或者是公理，或者由前面的语句自然导出</li>\n<li>最后一个语句就是所要证明的语句</li>\n</ol>\n<ul>\n<li><strong>定理证明方法</strong></li>\n</ul>\n<ol>\n<li>演绎法</li>\n<li>反证法/归谬法</li>\n<li>归纳法、第二归纳法</li>\n</ol>\n<h3 id=\"1-2-集合及其基本运算\"><a href=\"#1-2-集合及其基本运算\" class=\"headerlink\" title=\"1.2 集合及其基本运算\"></a>1.2 集合及其基本运算</h3><ol>\n<li>集合描述方法</li>\n</ol>\n<ul>\n<li>列举法 $A={a,b,c,d}$</li>\n<li>模式表示法 ${x|P(x)}$</li>\n</ul>\n<ol>\n<li>集合运算及定理</li>\n</ol>\n<ul>\n<li>定理1.9 德摩根定理</li>\n</ul>\n<p>$\\quad \\quad \\bar{A \\cap B} = \\bar A \\cup \\bar B$<br>$\\quad \\quad \\bar{A \\cup B} = \\bar A \\cap \\bar B$</p>\n<h3 id=\"1-3-图和树简介\"><a href=\"#1-3-图和树简介\" class=\"headerlink\" title=\"1.3 图和树简介\"></a>1.3 图和树简介</h3><ul>\n<li><strong>图</strong> ：顶点集合以及边集合</li>\n<li>有向图、无向图</li>\n<li>通路、回路</li>\n<li><p>邻接矩阵</p>\n</li>\n<li><p><strong>树</strong> </p>\n</li>\n<li>树中每一个顶点到另一个顶点均有一条通路，称该顶点为树的根</li>\n<li>树中一定没有回路</li>\n<li>仅一个顶点(根节点)没有前导顶点</li>\n<li>一定存在没有后继的顶点</li>\n</ul>\n<h3 id=\"1-4-字母表、字符串和语言\"><a href=\"#1-4-字母表、字符串和语言\" class=\"headerlink\" title=\"1.4 字母表、字符串和语言\"></a>1.4 字母表、字符串和语言</h3><ul>\n<li>自然语言<br>— 人类彼此相互交流的工具，由基本符号构成，如日语俄语等</li>\n<li><strong>形式语言</strong><br>— 用于需要严格描述的领域，构成基础为“符号”</li>\n</ul>\n<ul>\n<li><strong>字符表</strong>是符号的集合，记为 $\\Sigma$</li>\n<li>$\\Sigma$ 上的符号串<br>— $\\Sigma$ 上的符号以任意顺序拼接起来构成<br>— 任何符号可以重复出现</li>\n<li><strong>定义1.23</strong><br>— 对于任何给定的字符表 $\\Sigma$，$\\Sigma$ 上的字符串集合称作 $\\Sigma$ 上的语言</li>\n<li><strong>定义1.24</strong><br>— 设$L$是某个字母表上的一个语言，若 $L$ 中任何字符串都不是另一个字符串的真前缀，则$L$ 具有<strong>前缀性质</strong></li>\n<li><strong>定义1.25</strong><br>— 设 $L<em>{1}$ 为 $\\Sigma</em>{1}$ 的语言, $L<em>{2}$ 为 $\\Sigma</em>{2}$ 的语言，则  $L<em>{1}$ 和 $L</em>{2}$ 的连接 $L<em>{1}L</em>{2} = {xy | x \\in L<em>{1} and \\ y \\in L</em>{2}}$</li>\n<li><strong>定义1.26</strong><br>— <strong>语言 $L$ 的闭包 $L^{*}$ </strong><br>— 以任意次序连接L中任意多个字符串所组成的集合<br>— 只要 $L$ 中包含至少一个元素, $L^{*}$ 就为无穷集</li>\n</ul>\n<hr>\n<h2 id=\"第二章-文法理论\"><a href=\"#第二章-文法理论\" class=\"headerlink\" title=\"第二章 文法理论\"></a>第二章 文法理论</h2><p>重点：</p>\n<ul>\n<li>⽂法分类（给定⼀个语⾔集合，判定是0123型⽂法，熟悉每个⽂法的判定⽅法）（最重要） </li>\n<li>上下⽂有关⽂法上下⽂信息的获得,1’型⽂法如何转化为1型⽂法</li>\n</ul>\n<h3 id=\"2-1-文法定义\"><a href=\"#2-1-文法定义\" class=\"headerlink\" title=\"2.1 文法定义\"></a>2.1 文法定义</h3><ul>\n<li>四元组 $G=(V,T,P,S)$</li>\n</ul>\n<ol>\n<li>V是变元符有限集 Variables</li>\n<li>T是终结符有限集 Termination</li>\n<li>P是生成式有限集 (Production?)</li>\n<li>S∈V，为文法G的开始符 Start</li>\n</ol>\n<h3 id=\"2-2-派生\"><a href=\"#2-2-派生\" class=\"headerlink\" title=\"2.2 派生\"></a>2.2 派生</h3><p><strong>直接派生</strong><br>若 $\\alpha = \\alpha<em>{1} A \\alpha</em>{2}, \\ \\gamma=\\alpha<em>{1}\\beta\\alpha</em>{2}$ ，且 $A\\to\\beta$ 为P中一个生成式，则 $\\alpha \\mathop{\\Rightarrow}\\limits_{G}^{}\\gamma$<br>，称由 $\\alpha$ 直接派生出 $\\gamma$</p>\n<p><strong>派生</strong><br>将 $\\mathop{\\Rightarrow}\\limits<em>{G}^{}$ 扩充为 $\\hat{\\mathop{\\Rightarrow}\\limits</em>{G}^{}}$，则为派生</p>\n<p>$\\quad (\\hat{\\mathop{\\Rightarrow}\\limits_{}} 表示多步直接派生)$</p>\n<h3 id=\"2-3-文法分类\"><a href=\"#2-3-文法分类\" class=\"headerlink\" title=\"2.3 文法分类\"></a>2.3 文法分类</h3><p><strong>1. 短语结构文法 PSG (0型文法)</strong></p>\n<ul>\n<li><strong>特点：</strong> 不加限制</li>\n<li><strong>对应语言：</strong> 短语结构语言 PSL</li>\n<li><strong>对应自动机：</strong> 图灵机 TM</li>\n<li><strong>形式：</strong> $\\alpha\\to\\beta,\\ \\alpha,\\beta\\in(V \\cup T)^{*}$ 且 $\\alpha\\ne\\epsilon$</li>\n</ul>\n<p><strong>2. 上下文有关文法 CSG (1型文法)</strong></p>\n<ul>\n<li><strong>特点：</strong> 每个终结符$\\to$终结符，满足前者偏序后者 ($\\leq$)</li>\n<li><strong>对应语言：</strong> 上下文有关语言 CSL</li>\n<li><strong>对应自动机:</strong> 线性有界自动机 LBA</li>\n<li><strong>形式：</strong> $\\forall \\alpha\\to\\beta\\in P$ , 满足 $|\\alpha|\\leq |\\beta|$ 并且 $\\alpha,\\beta\\in(V \\cup T)^{*}$ 且 $\\alpha\\ne\\epsilon$</li>\n</ul>\n<p><strong>3. 上下文无关文法 CFG (2型文法)</strong></p>\n<ul>\n<li><strong>特点：</strong> 都有变元推出变元或终结符或者变元与终结符的连接</li>\n<li><strong>对应语言：</strong> 上下文无关语言 CFL</li>\n<li><strong>对应自动机：</strong> 下推自动机 PDA</li>\n<li><strong>形式：</strong> 对所有P中生成式都有，$A\\to\\beta \\quad \\beta\\in(V \\cup T)^{*},\\ A \\in V$</li>\n</ul>\n<p><strong>4. 正规文法 RG (3型文法)</strong></p>\n<ul>\n<li><strong>特点 ：</strong> 变元推出终结符或推出终结符+变元</li>\n<li><strong>对应语言：</strong> 正规语言 RL</li>\n<li><strong>对应自动机：</strong> 有穷自动机 DFA</li>\n<li><strong>形式：</strong> 对所有P中生成式都有，$A\\to a\\ 或\\ A\\to aB \\quad a\\in T \\cup {\\epsilon},\\ A,B \\in V$</li>\n</ul>\n<h3 id=\"2-4-文法等价\"><a href=\"#2-4-文法等价\" class=\"headerlink\" title=\"2.4 文法等价\"></a>2.4 文法等价</h3><p>对于两个文法 $G<em>{1}=(V</em>{1},\\ T<em>1,\\ P_1,\\ S_1)$ 与 $G</em>{2}=(V_{2},\\ T_2,\\ P_2,\\ S_2)$，若$L(G_1)=L(G_2)$，则文法等价</p>\n<h3 id=\"2-5-1°型文法\"><a href=\"#2-5-1°型文法\" class=\"headerlink\" title=\"2.5 1°型文法\"></a>2.5 1°型文法</h3><ul>\n<li><strong>特点：</strong> 看形式</li>\n<li><strong>形式：</strong> 对文法 $G=(V,\\ T,\\ P,\\ S)$，若P中每个生成式都有 $\\alpha_1 A \\alpha_2 \\to \\alpha_1 \\beta \\alpha_2$形式，$A \\in V, \\ \\alpha_1,\\alpha_2\\in(V \\cup T)^{*}$, $\\beta \\in {(V \\cup T)}^{+}$ </li>\n</ul>\n<h4 id=\"1、-1型文法和1°型文法转换\"><a href=\"#1、-1型文法和1°型文法转换\" class=\"headerlink\" title=\"1、 1型文法和1°型文法转换\"></a>1、 1型文法和1°型文法转换</h4><ul>\n<li><p>定理：对于任何1型文法G，一定存在一个 $1^{°}$ 型文法G’,使得L(G)=L(G’) 反之亦然。</p>\n</li>\n<li><p>$\\Rightarrow$<br>对于任何生成式 $\\alpha_1 A \\alpha_2 \\to \\alpha_1 \\beta \\alpha_2$ ,恒有 $|\\alpha_1 A \\alpha_2| \\leq |\\alpha_1 \\beta \\alpha_2|$<br>即 $1^{°}$ 型文法一定是1型文法</p>\n</li>\n<li><p>$\\Leftarrow$ </p>\n</li>\n<li><p>第一步：将G变为G’’</p>\n<ul>\n<li>这一步构造出生成式只有两种形式的G’’</li>\n<li>其中 $V^{‘’}=V \\cup M, M={[a] | a\\in T}$</li>\n<li>$P^{‘’}=\\overline{P} \\cup { [a] \\to a | a \\in T }$</li>\n</ul>\n</li>\n<li><p>第二步：G’’ 中生成式形式分类讨论</p>\n<ul>\n<li>（1） $A\\to\\beta$ (A∈V，或为新引入变元[a])，其已经是1°文法</li>\n<li>（2）$A_1A_2…A_n\\to B_1B_2…B_n,\\quad (n\\ge 2,\\ m\\ge n)$ <ul>\n<li>解决方法：引入一组新变元用于过渡</li>\n<li><ol>\n<li>$A_1A_2…A_n \\to C_1A_2…A_n$ </li>\n</ol>\n</li>\n<li><ol>\n<li>$C_1A_2…A_n \\to C_1C_2…A_n$ </li>\n</ol>\n</li>\n<li><ol>\n<li>$C<em>1C_2…C</em>{n-1}A_n \\to C_1C_2…C_n$ </li>\n</ol>\n</li>\n<li><ol>\n<li>$C_1C_2…C_n \\to B_1C_2…C_n$ </li>\n</ol>\n</li>\n<li><ol>\n<li>$B_1C_2…C_n \\to B_1B_2…C_n$ </li>\n</ol>\n</li>\n<li><ol>\n<li>$B<em>1B_2…B</em>{n-1}C_n \\to B_1B_2…B_n$</li>\n</ol>\n</li>\n<li>完成 $A_1A_2…A_n\\to B_1B_2…B_n$</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"2-6-上下文在文法中的体现\"><a href=\"#2-6-上下文在文法中的体现\" class=\"headerlink\" title=\"2.6 上下文在文法中的体现\"></a>2.6 上下文在文法中的体现</h3><h4 id=\"上下文有关文法（1型文法）的上下文\"><a href=\"#上下文有关文法（1型文法）的上下文\" class=\"headerlink\" title=\"上下文有关文法（1型文法）的上下文\"></a>上下文有关文法（1型文法）的上下文</h4><ul>\n<li>可用1°型文法解释，$\\alpha_1 A \\alpha_2 \\to \\alpha_1 \\beta \\alpha_2$，其中$\\alpha_1\\ 和\\ \\alpha_2$ 是A的上下文，在该上下文语境中A可替换为β</li>\n<li>在另外上下文语境中可替换为别的字符串，例如另有生成式 $\\alpha<em>{1’} A \\alpha</em>{2’} \\to \\alpha<em>{1’} \\gamma \\alpha</em>{2’}$ </li>\n</ul>\n<h4 id=\"上下文无关文法（2型文法）的上下文\"><a href=\"#上下文无关文法（2型文法）的上下文\" class=\"headerlink\" title=\"上下文无关文法（2型文法）的上下文\"></a>上下文无关文法（2型文法）的上下文</h4><ul>\n<li>$A\\to \\beta$ 变元A不管出现在任何地方都可替换为β，与上下文无关</li>\n</ul>\n<h3 id=\"2-7-语法分析树\"><a href=\"#2-7-语法分析树\" class=\"headerlink\" title=\"2.7 语法分析树\"></a>2.7 语法分析树</h3><ul>\n<li>定义：//TODO</li>\n</ul>\n<h4 id=\"边缘\"><a href=\"#边缘\" class=\"headerlink\" title=\"边缘\"></a>边缘</h4><ul>\n<li><p>对于派生树，其叶节点标记从左到右收集起来的字符串，称为该派生树的边缘</p>\n</li>\n<li><p><strong>相关定理：</strong> G为上下文无关文法，那么S可以派生出α当且仅当在G中存在一颗边缘为α的派生树<br>证明: //TODO</p>\n</li>\n</ul>\n<h4 id=\"多义和固有多义\"><a href=\"#多义和固有多义\" class=\"headerlink\" title=\"多义和固有多义\"></a>多义和固有多义</h4><p>不重要 TODO</p>\n<hr>\n<h2 id=\"第三章-有穷自动机和正规表达式\"><a href=\"#第三章-有穷自动机和正规表达式\" class=\"headerlink\" title=\"第三章 有穷自动机和正规表达式\"></a>第三章 有穷自动机和正规表达式</h2><p>重点</p>\n<ul>\n<li>掌握⼏类⾃动机的特点（FM, NFM, 有空动作的FM），⼏种FM之间如何进⾏变换（等价性），例：如何进⾏ 空动作的消除（空闭包的转换） </li>\n<li>掌握正则表达式和正规集，正规集和有穷⾃动机的关系（实际上在第四章） </li>\n<li>了解摩尔机和米里机的定义和功能（⾮重点）</li>\n</ul>\n<h3 id=\"3-1-确定有穷自动机-DFA\"><a href=\"#3-1-确定有穷自动机-DFA\" class=\"headerlink\" title=\"3.1 确定有穷自动机 DFA\"></a>3.1 确定有穷自动机 DFA</h3><h4 id=\"1-定义\"><a href=\"#1-定义\" class=\"headerlink\" title=\"1. 定义\"></a>1. 定义</h4><ul>\n<li>有穷自动机（FA or DFA）是一个五元组 $M=(Q,\\ \\Sigma, \\delta,\\ q_0, F)$<ul>\n<li><ol>\n<li>Q是有穷状态集</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\Sigma$ 是有穷的输入字符表</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\delta$ 是转移函数，将 $Q\\times \\Sigma$ 映射到Q</li>\n</ol>\n</li>\n<li><ol>\n<li>$q_0\\in Q$ 是初始状态</li>\n</ol>\n</li>\n<li><ol>\n<li>$F\\subset Q 是终结状态$</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"2-扩充转移函数\"><a href=\"#2-扩充转移函数\" class=\"headerlink\" title=\"2.扩充转移函数\"></a>2.扩充转移函数</h4><p>对于 FA $M=(Q,\\ \\Sigma, \\delta,\\ q_0, F)$ 其扩充转移函数是 $\\hat\\delta$ 是$Q\\times\\Sigma^*$ 到 Q 的映射</p>\n<ul>\n<li><ol>\n<li>$\\hat{\\delta}(q,\\epsilon) = q$ </li>\n</ol>\n</li>\n<li><ol>\n<li>$\\hat\\delta(q,wa)=\\delta(\\hat\\delta(q,w),a)$ </li>\n</ol>\n</li>\n<li><p>递归定义<br>接受一个输入，然后进行状态转移，再接受下一个。输入一个串得到最后状态。</p>\n</li>\n</ul>\n<h4 id=\"3-有穷自动机接受语言\"><a href=\"#3-有穷自动机接受语言\" class=\"headerlink\" title=\"3.有穷自动机接受语言\"></a>3.有穷自动机接受语言</h4><p>$L(M)={x| \\delta(q_0,x)\\in F}$<br>若 $\\delta(q_0,x)=p\\in F$ ，则称字符串x，被M接受，意义上来理解，就是输入x，M从q0转移到终结状态F</p>\n<h3 id=\"3-2-非确定有穷自动机-NFA\"><a href=\"#3-2-非确定有穷自动机-NFA\" class=\"headerlink\" title=\"3.2 非确定有穷自动机 NFA\"></a>3.2 非确定有穷自动机 NFA</h3><h4 id=\"1-定义-1\"><a href=\"#1-定义-1\" class=\"headerlink\" title=\"1. 定义\"></a>1. 定义</h4><ul>\n<li>非确定的有穷自动机（NFA）五元组 $G=(Q,\\Sigma,\\delta,q_0,F)$<ul>\n<li><ol>\n<li>Q是有穷状态集</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\Sigma$ 是有穷输入字符表</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\delta$ 是非确定的状态转移函数，$Q\\times \\Sigma$到$2^Q$ 上的映射</li>\n</ol>\n</li>\n<li><ol>\n<li>$q_0\\in Q$ 是初始状态</li>\n</ol>\n</li>\n<li><ol>\n<li>$F \\subset Q$ 是终结状态集</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"2-转移函数一般形式：\"><a href=\"#2-转移函数一般形式：\" class=\"headerlink\" title=\"2. 转移函数一般形式：\"></a>2. 转移函数一般形式：</h4><p>$\\delta(q,a)={p_1,…..,p_k} \\quad p_i\\in Q$ 或者 $\\delta(q,a)=\\emptyset$</p>\n<h4 id=\"3-扩充转移函数\"><a href=\"#3-扩充转移函数\" class=\"headerlink\" title=\"3. 扩充转移函数\"></a>3. 扩充转移函数</h4><p>类似有穷自动机定义，输入一个串，对每个字符进行状态转移，最后得出的最终状态<strong>集合</strong></p>\n<h4 id=\"4-接受条件\"><a href=\"#4-接受条件\" class=\"headerlink\" title=\"4. 接受条件\"></a>4. 接受条件</h4><p>如果 $\\delta(q_0,\\ x)\\cap F$ 非空，则称字符串 $x$ 被 $M$ 接受</p>\n<h3 id=\"3-3-NFA与DFA的等价性\"><a href=\"#3-3-NFA与DFA的等价性\" class=\"headerlink\" title=\"3.3 NFA与DFA的等价性\"></a>3.3 NFA与DFA的等价性</h3><ul>\n<li>当给定某类中的一个有穷自动机，一定存在另一类中的一个有穷自动机，两者接受同样集合，则称二者等价。</li>\n</ul>\n<h4 id=\"1-NFA与DFA等价\"><a href=\"#1-NFA与DFA等价\" class=\"headerlink\" title=\"1. NFA与DFA等价\"></a>1. NFA与DFA等价</h4><ul>\n<li>证明： 构造法 构造 DFA，其定义为<ul>\n<li>对于Q’,其将NFA中Q的每一个子集作为Q’中的一个状态，若子集为 ${q_1,q_2,..,q_n}$ ，则Q’中状态记为 $[q_1,q_2,..,q_n]$ </li>\n<li>对于 $\\delta^{‘}$ ，定义为<script type=\"math/tex\">\\delta^{'}([q_1,q_2,..,q_n],a) = p_1,p_2,..,p_n \\\\ iff \\\\ \\delta(\\{q_1,q_2,..,q_n\\},a) = p_1,p_2,..,p_n</script> </li>\n</ul>\n</li>\n</ul>\n<p>进一步证明 TODO</p>\n<h4 id=\"2-NFA至DFA的转换\"><a href=\"#2-NFA至DFA的转换\" class=\"headerlink\" title=\"2. NFA至DFA的转换\"></a>2. NFA至DFA的转换</h4><p>构造方法，从NFA出发，并不需要直接一步写出Q的幂集，而是看NFA中存在哪些状态。<br>例题3.4</p>\n<h4 id=\"3-具有-epsilon-动作的有穷自动机\"><a href=\"#3-具有-epsilon-动作的有穷自动机\" class=\"headerlink\" title=\"3. 具有$\\epsilon$动作的有穷自动机\"></a>3. 具有$\\epsilon$动作的有穷自动机</h4><p>在不接受输入符号，输入为$\\epsilon$ 时能做转移动作<br>即转移函数 $\\delta$ 扩充至$Q\\times (\\Sigma \\cup {\\epsilon})$ 到 $2^Q$ 的映射</p>\n<ul>\n<li><p>$\\epsilon -CLOSURE(q)$<br>直白的说，就是如果NFA只接受空动作能够到达的状态集合</p>\n</li>\n<li><p>定义</p>\n<ul>\n<li><ol>\n<li>$q\\in \\epsilon -CLOSURE(q)$</li>\n</ol>\n</li>\n<li><ol>\n<li>递归，若$p\\in \\epsilon -CLOSURE(q)$，则$\\delta(q, \\epsilon)\\in \\epsilon -CLOSURE(q)$</li>\n</ol>\n</li>\n<li>规定：$\\epsilon -CLOSURE(P) = \\mathop{\\cup}\\limits_{q\\in P}\\epsilon -CLOSURE(q)$</li>\n</ul>\n</li>\n<li><p>扩充函数<br>非简单扩充，就是说 $\\hat\\delta(q,a) \\neq \\delta(q,a)$，因为空输入也可以转移状态，其他差不多</p>\n</li>\n<li><p>接受语言<br>$L(M)={w|\\hat\\delta(q_0,w) \\cap F }$ 非空<br><em>增加空动作没有增加表达能力，即有空动作和没有空动作的NFA等价</em></p>\n</li>\n<li><p>空动作NFA与NFA等价<br>构造法，对具有空动作的NFA M构造 $M’=(Q’,\\Sigma^{‘},\\delta^{‘},q_0,F^{‘})$，</p>\n</li>\n</ul>\n<p>$\\hat \\delta(q,a)$ 即 $\\delta(\\epsilon -CLOSURE(q), a)$</p>\n<ul>\n<li>$\\delta^{‘}(q,a) = \\hat\\delta(q,a)$</li>\n<li><script type=\"math/tex; mode=display\">F^{'}=\\left\\{\n  \\begin{array}{rcl}\n      F\\cup \\{q_0\\} && {如果\\epsilon-CLOSURE(q_0)\\cap F非空}\\\\\n      F && {否则}\n  \\end{array} \\right.</script>证明对 |x| 进行归纳 TODO</li>\n</ul>\n<h3 id=\"3-4-正规表达式和正规集\"><a href=\"#3-4-正规表达式和正规集\" class=\"headerlink\" title=\"3.4 正规表达式和正规集\"></a>3.4 正规表达式和正规集</h3><ul>\n<li>正规表达式递归定义<ul>\n<li><ol>\n<li>$\\phi$ 是一个正规表达式，代表空集</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\epsilon$ 是一个正规表达式，代表集合 ${\\epsilon}$ </li>\n</ol>\n</li>\n<li><ol>\n<li>对于 $\\Sigma$ 中每个符号a，a是正规表达式，代表集合{a}</li>\n</ol>\n</li>\n<li><ol>\n<li>如果r和s是正规表达式，分别表示集合R和S，则(r+s),(rs)和(r<em>)是正规表达式，分别表示 $R \\cup S$、$RS$ 和 $R^</em>$ </li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<p>正规表达式代表的集合称为正规集</p>\n<p><img src=\"/uploads/upload_e70fbfc8866d389b084873dd20ba2e72.png\" style=\"height: 300px;\"></p>\n<ul>\n<li><p>运算优先级<br>$* &gt; 连接 &gt; +$</p>\n</li>\n<li><p>对应自动机<br>有穷自动机 DFA<br>有穷自动机所能接受的集合类和正规表达式所能表示的集合类统称为正规集类</p>\n</li>\n<li><p>定理3.3 r为正规表达式，则有一个具有空动作的NFA接受L(r)<br>归纳法证明，归纳r的构造次数</p>\n</li>\n<li>基础：r构造次数为0，即r是 $\\epsilon$ 、$\\phi$ 、$\\Sigma$ 中某个元素a</li>\n<li><p>归纳</p>\n<ul>\n<li>r = r1 + r2<br>归纳假设有 M1 接受 r1, M2 接受 r2<br>则构造一个M将两个M1,M2并起即可，形式说明TODO</li>\n<li>r = r1r2<br>归纳假设有 M1 接受 r1, M2 接受 r2<br>则构造一个M先过M1再过M2即可，形式说明TODO</li>\n<li>r = r1*<br>归纳假设有 M1 接受 r1,<br>则扩展一下M1，让其终结状态可以回到开始状态重复判断即可，形式说明TODO</li>\n</ul>\n</li>\n<li><p>定理3.4 如果L被DFA接受，则L可用正规表达式表示<br>对各状态进行编号，记 $R<em>{ij}^k={x\\mid \\delta(q_i,x)=q_j，中间不经过编号大于k的状态 }$ ，有递推式 $R</em>{ij}^k=R<em>{ik}^{k-1}(R</em>{kk}^{k-1})^*R<em>{kj}^{k-1}\\cup R</em>{ij}^{k-1}$  ，然后归纳证明 $R_{ij}^k$ 可用正规表达式表示</p>\n</li>\n</ul>\n<h3 id=\"3-5-具有输出的有穷自动机\"><a href=\"#3-5-具有输出的有穷自动机\" class=\"headerlink\" title=\"3.5 具有输出的有穷自动机\"></a>3.5 具有输出的有穷自动机</h3><ol>\n<li>摩尔机</li>\n<li>米里机</li>\n</ol>\n<p>非重点</p>\n<hr>\n<h2 id=\"第四章-正规文法与正规集的性质-重要\"><a href=\"#第四章-正规文法与正规集的性质-重要\" class=\"headerlink\" title=\"第四章 正规文法与正规集的性质(重要)\"></a>第四章 正规文法与正规集的性质(重要)</h2><ul>\n<li>缩胀定理（重点），反证法证明 </li>\n<li>极⼩化的处理，掌握极⼩化的算法（过程）（明示了快背），如何优化有穷⾃动机 </li>\n<li>⻨⻄尔-尼诺德定理，需要掌握 </li>\n</ul>\n<h3 id=\"4-1-正规文法与有穷自动机的关系\"><a href=\"#4-1-正规文法与有穷自动机的关系\" class=\"headerlink\" title=\"4.1 正规文法与有穷自动机的关系\"></a>4.1 正规文法与有穷自动机的关系</h3><ul>\n<li><strong>Th4.1</strong><br>— 设 $L$ 被某个正规文法 $G$ 产生，则 $L$ 可被某个有穷自动机接受</li>\n</ul>\n<ul>\n<li><strong>Th4.2</strong><br>— 设 $L$ 被某个DFA $M$ 接受， 则 $L$ 可被某个正规文法产生</li>\n</ul>\n<p>构造方法：</p>\n<ul>\n<li>$A\\to aB$ 对应 $\\delta(A,a)=B$</li>\n<li>$A\\to a$ 对应 $\\delta(A,a)=f\\in F$</li>\n</ul>\n<h3 id=\"4-2-正规集的缩胀定理\"><a href=\"#4-2-正规集的缩胀定理\" class=\"headerlink\" title=\"4.2 正规集的缩胀定理\"></a>4.2 正规集的缩胀定理</h3><ol>\n<li><p><strong>有穷自动机表达能力有限</strong></p>\n</li>\n<li><p><strong>Th4.3 正规集的缩胀定理(pumping Lemma)：存在整数 $k \\geq 0$ ，对于任意串 $x, y, z$ 这里 $xyz \\in A$， 只要$|y| \\ge k$ ，就可以将 $y$ 写成 $y=uvw, \\quad v \\ne \\sigma$ ，并且对于任何 $i \\ge 0$，都有 $xuv^{i}wz \\in A$</strong></p>\n</li>\n</ol>\n<ul>\n<li><p>证明：定理的直观含义为：如果 $A$ 是正规集，那么当它的元素含有<strong>足够长</strong>的子串 $y$ 时（x与y的长短不重要）， $y$ 就一定包含一个非空的子串 $v$ （$u, w$ 的长短不重要），这个子串 $v$ 可以“膨胀”任意多次 （$i &gt; 0$），或者被“删除” （$i = 0$），而 $xuv^{i}wz$ 仍然属于 $A$</p>\n</li>\n<li><p>设 $k$ 是接受正规集 $A$ 的 $DFA$ 状态数，因为 $y$ 的长度大于或等于k， 则 $DFA$ 在扫视 $y$ 的过程中，必然出现重复的状态，串 $v$ 就是该状态相邻的两次出现过程中扫视过的子串。</p>\n</li>\n</ul>\n<script type=\"math/tex; mode=display\">\n\\sigma(q_{1}, u)=p, \\sigma(p, v)=p, \\sigma(p, w)=q_2</script><p>其余的推理过程与例2.10的分析相同</p>\n<ul>\n<li><em>正规集的缩胀定理经常用来指明某些集合不是正规集，通常就是反证法，大家都懂的。</em></li>\n</ul>\n<h3 id=\"4-3-正规集的封闭性质与判定算法\"><a href=\"#4-3-正规集的封闭性质与判定算法\" class=\"headerlink\" title=\"4.3 正规集的封闭性质与判定算法\"></a>4.3 正规集的封闭性质与判定算法</h3><ul>\n<li>在并、连接和闭包运算下是封闭的</li>\n<li>在补运算下封闭，即若 $L$ 是正规集，且 $L\\subseteq\\Sigma^{<em>}$ ， 则 $\\Sigma^{</em>}-L$ 也是正规的</li>\n<li>在交运算下封闭</li>\n<li>在商运算下封闭（暂且理解：两个正规集做商运算，其结果必然是正规集）</li>\n</ul>\n<ul>\n<li><em>Th4.9</em><br>具有n个状态的有穷自动机具有如下性质：<ul>\n<li>1)它接受的集合非空，当且仅当它接受一个长度小于n的字符串 </li>\n<li>2）它接受的集合是无穷的，当且仅当它接受一个长度为1的字符串，这里 $n \\leq l &lt; 2n$</li>\n</ul>\n</li>\n<li><em>两个有穷自动机是否等价是可判定的</em></li>\n</ul>\n<h3 id=\"4-4-有穷自动机的最小化\"><a href=\"#4-4-有穷自动机的最小化\" class=\"headerlink\" title=\"4.4 有穷自动机的最小化\"></a>4.4 有穷自动机的最小化</h3><p><strong>一个减少状态数的思路：给定 $DFA \\ =(Q, \\Sigma, \\delta, q_{0}, F)$，根据等价关系构造出一个 $DFA M/ \\equiv$，该 $DFA$称为 $M$的商自动机</strong></p>\n<ul>\n<li><strong>判断两个状态等价：</strong> 对于 $p, q \\in Q$， 若对于每个 $x \\in \\Sigma^{*}, \\quad \\delta(p, x) \\in F$当且仅当 $\\delta(q,x) \\in F$， 就称 $p, q$ 等价，记作 $p \\equiv q$</li>\n</ul>\n<p><strong>极小化算法过程：</strong><br>— <em>在 $DFA$ 的状态集上确定所有的状态对是否等价</em></p>\n<ol>\n<li>对所有状态对 ${p, q}  (p, q \\in Q)$画一张表，开始时中每个格子均为空白（未做标记）</li>\n<li>对一切 $p \\in F, q \\notin F$ 的 ${p, q}$，在相应格子上做标记（例如画一个X）</li>\n<li>重复下述步骤，直到表中内容不再改变为止：如果对于某个 $a \\in \\Sigma$， 存在一个未被标记的状态对 ${p, q}$，使得 ${\\delta(p,a),\\delta(q,a)}$已做标记，则将 ${p, q}$ 做标记</li>\n<li>完成1，2，3之后，所有未被标记的状态对都是等价的，即 $p \\equiv q$</li>\n</ol>\n<h3 id=\"Myhill-Nerode-关系\"><a href=\"#Myhill-Nerode-关系\" class=\"headerlink\" title=\"Myhill-Nerode 关系\"></a>Myhill-Nerode 关系</h3><p><strong>判定方式</strong></p>\n<ul>\n<li><p>对某个集合$A \\subset \\Sigma^<em>,\\quad$ R为$\\Sigma^</em>$上的等价关系。若R满足</p>\n<ul>\n<li><ol>\n<li>是右不变的</li>\n</ol>\n</li>\n<li><ol>\n<li>细分A</li>\n</ol>\n</li>\n<li><ol>\n<li>具有有穷指数</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><p>则称R为A的 Myhill-Nerode 关系</p>\n</li>\n</ul>\n<h3 id=\"Myhill-Nerode-定理\"><a href=\"#Myhill-Nerode-定理\" class=\"headerlink\" title=\"Myhill-Nerode 定理\"></a>Myhill-Nerode 定理</h3><ul>\n<li>A是一个正规集</li>\n<li>$\\Sigma^*上存在关于A的MN关系$</li>\n<li>$R_A$ 具有有穷指数</li>\n</ul>\n<hr>\n<h2 id=\"第五章-上下文无关文法与下推自动机\"><a href=\"#第五章-上下文无关文法与下推自动机\" class=\"headerlink\" title=\"第五章 上下文无关文法与下推自动机\"></a>第五章 上下文无关文法与下推自动机</h2><p>重点:</p>\n<ul>\n<li>了解化简（作业题） </li>\n<li>⼀定要会两种范式（乔姆斯基范式&amp;葛雷巴赫范式） </li>\n<li>构造下推⾃动机（作业题）</li>\n</ul>\n<h3 id=\"5-1-上下文无关文法的化简\"><a href=\"#5-1-上下文无关文法的化简\" class=\"headerlink\" title=\"5.1 上下文无关文法的化简\"></a>5.1 上下文无关文法的化简</h3><p>检验文法$G=(V, T, P, S)$中是否有无用符号 （变元或终结符），若有，则将其消除。</p>\n<h4 id=\"无用符号\"><a href=\"#无用符号\" class=\"headerlink\" title=\"无用符号\"></a>无用符号</h4><ul>\n<li>$X \\in V \\cup T$ 但X不出现在任何由S派生出的字符串中。</li>\n<li><p>$X \\in V$ 但X不能派生出任何终结符号串</p>\n</li>\n<li><p>Th5.1 不带无用符号的CFG可生成所有非空CFL</p>\n<p>  化简思路</p>\n<ul>\n<li><ol>\n<li>找到无用符号（一类二类）</li>\n</ol>\n</li>\n<li><ol>\n<li>删除无用符号</li>\n</ol>\n</li>\n<li><ol>\n<li>返回1继续检查，直到不产生无用符号为止</li>\n</ol>\n<p>PPT思路</p>\n</li>\n<li><ol>\n<li>首先删除二类无用符号 </li>\n</ol>\n</li>\n<li><ol>\n<li>接着删除一类无用符号</li>\n</ol>\n</li>\n<li><ol>\n<li>返回1检查，直到不产生无用符号</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"epsilon-生成式\"><a href=\"#epsilon-生成式\" class=\"headerlink\" title=\"$\\epsilon$ -生成式\"></a>$\\epsilon$ -生成式</h4><p>形如 $A \\to \\epsilon$ 的生成式，如果 $\\epsilon \\in L(G)$ 那么不能删，其余都可以删除。</p>\n<ul>\n<li><p>可为零<br>如果在CFG中，A属于变元集合，如果有A派生出$\\epsilon$则称A为可为零的。</p>\n</li>\n<li><p>Th5.3 可为零的可判定性<br>对于CFG中任意变元是否可为零是可判定的<br>判定思路：</p>\n</li>\n<li><ol>\n<li>对$A \\to \\epsilon$ 即trivial的本来就可为零的，将A加入Z</li>\n</ol>\n</li>\n<li><ol>\n<li>对于一切生成式 B，有$B \\to \\alpha$ 如果 $\\alpha \\in V^+$在中所有变元均在Z中，将B加入Z</li>\n</ol>\n</li>\n<li><ol>\n<li>重复1，直至没有元素加入Z为止</li>\n</ol>\n</li>\n</ul>\n<p>Z 中元素均为可为零的元素</p>\n<ul>\n<li>Th5.2 不带无用符号且没有$\\epsilon$-生成式的CFG可以生成所有不包含空串的CFL<br><strong>不会证 ；）</strong></li>\n</ul>\n<h4 id=\"单一生成式\"><a href=\"#单一生成式\" class=\"headerlink\" title=\"单一生成式\"></a>单一生成式</h4><p>形如 $A \\to B$ （A、B皆为变元）的生成式</p>\n<h4 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h4><p>上面说的三个都可以消掉</p>\n<h3 id=\"5-2-上下文无关文法的范式\"><a href=\"#5-2-上下文无关文法的范式\" class=\"headerlink\" title=\"5.2 上下文无关文法的范式\"></a>5.2 上下文无关文法的范式</h3><h4 id=\"乔姆斯基范式-Chomsky-（CNF定理）\"><a href=\"#乔姆斯基范式-Chomsky-（CNF定理）\" class=\"headerlink\" title=\"乔姆斯基范式 Chomsky （CNF定理）\"></a>乔姆斯基范式 Chomsky （CNF定理）</h4><p>任何不包含$\\epsilon$的CFL，都可由生成式仅为 $A \\to BC$ 或 $A \\to a$ （A，B，C为变元，a为终结符）形式的文法产生<br>（化为乔姆斯基范式，例题5.3）<br>a</p>\n<h4 id=\"格雷巴赫范式-Greibach-GNF定理\"><a href=\"#格雷巴赫范式-Greibach-GNF定理\" class=\"headerlink\" title=\"格雷巴赫范式 Greibach (GNF定理)\"></a>格雷巴赫范式 Greibach (GNF定理)</h4><p>任何不包含$\\epsilon$的CFL，都可由生成式仅为$A \\to a\\alpha$ (a为终结符,$\\alpha$ 为变元串，包含空串）形式的文法产生</p>\n<p>//TODO</p>\n<h3 id=\"5-3-下推自动机\"><a href=\"#5-3-下推自动机\" class=\"headerlink\" title=\"5.3 下推自动机\"></a>5.3 下推自动机</h3><p>下推自动机（简称PDA）是一个七元组 $M=(Q,\\Sigma,\\Gamma, \\delta, q_0, Z_0, F)$</p>\n<ul>\n<li>Q是有穷状态集</li>\n<li>$\\Sigma$是有穷的输入字母表</li>\n<li>$\\Gamma$是有穷的栈符号表</li>\n<li>$\\delta$是转移函数，将$Q \\times (\\Sigma \\cup {epsilon} \\times \\Gamma)$ 映射到$(Q\\times \\Gamma^*)$ 的有穷子集</li>\n<li>$q_0 \\in Q$ 是初始状态</li>\n<li>$Z_0 \\in \\Gamma$ 是栈底符号</li>\n<li>$F \\subset Q$ 是终结状态集</li>\n</ul>\n<h4 id=\"转移函数\"><a href=\"#转移函数\" class=\"headerlink\" title=\"转移函数\"></a>转移函数</h4><p>三元组 $\\delta(q,a,Z) = {(p_1,\\gamma_1), (p_2, \\gamma_2),…,(p_m, \\gamma_m)}$ 其中 q, a 一个状态一个输入字符，Z为栈顶符号</p>\n<p>状态由 $q \\to p$，栈顶符号由 $Z \\to \\gamma$<br>转移动作不确定</p>\n<ul>\n<li>函数值有m种选择 （m可以为0）</li>\n<li>读头不动也可以有函数值</li>\n</ul>\n<h4 id=\"瞬时描述\"><a href=\"#瞬时描述\" class=\"headerlink\" title=\"瞬时描述\"></a>瞬时描述</h4><p>$(q<em>0,w,Z_0) \\mathop{\\vdash}\\limits</em>{M}^*\\ (p, \\epsilon, \\gamma)$ 表示从状态 $(p, \\gamma) \\in \\delta(q_o, w, Z_0)$，上一个字符为w，下一个字符为 $\\epsilon$</p>\n<p>即由一个瞬时描述 ID 转移到下一个 ID</p>\n<h4 id=\"按终结方式接受\"><a href=\"#按终结方式接受\" class=\"headerlink\" title=\"按终结方式接受\"></a>按终结方式接受</h4><p>若M是一个PDA，集合$L(M)={w|(q<em>0,w,Z_0) \\mathop{\\vdash}\\limits</em>{M}^*\\ (p, \\epsilon, \\gamma)}$<br>则称M按终结状态方式接受的语言</p>\n<ul>\n<li>接受状态<br>还是由初始状态到接受状态，和栈中符号没什么关系，栈符号只影响状态转移<br><em>不过如果输入串未读完栈就变空，无法进行状态转移，则w不可能被接受。</em></li>\n</ul>\n<h4 id=\"按栈空方式接受\"><a href=\"#按栈空方式接受\" class=\"headerlink\" title=\"按栈空方式接受\"></a>按栈空方式接受</h4><ul>\n<li>接受状态<br>顾名思义，读完之后栈空了就接受了，终结状态则不影响是否接受。</li>\n</ul>\n<p>构造PDA接受$0^n1^n$，例题5.5</p>\n<ul>\n<li>例题 5.6、5.7</li>\n</ul>\n<h3 id=\"5-4-下推自动机与上下文无关文法的关系\"><a href=\"#5-4-下推自动机与上下文无关文法的关系\" class=\"headerlink\" title=\"5.4 下推自动机与上下文无关文法的关系\"></a>5.4 下推自动机与上下文无关文法的关系</h3><ul>\n<li>下推自动机接受的语言类是上下文无关文法 CFL (2型文法)</li>\n</ul>\n<hr>\n<h2 id=\"第六章-上下文无关语言的性质\"><a href=\"#第六章-上下文无关语言的性质\" class=\"headerlink\" title=\"第六章 上下文无关语言的性质\"></a>第六章 上下文无关语言的性质</h2><p>重点</p>\n<ul>\n<li>缩胀定理/ogden定理（尤其考察后者）</li>\n<li>考察给⼀个语⾔判断是否是上下⽂⽆关语⾔ 封闭属性 </li>\n<li>成员资格判定问题（PPT）,CYK算法</li>\n</ul>\n<h3 id=\"6-1-CFL缩胀定理\"><a href=\"#6-1-CFL缩胀定理\" class=\"headerlink\" title=\"6.1 CFL缩胀定理\"></a>6.1 CFL缩胀定理</h3><p>回忆一下正规集缩胀定理<br>正规集中每个足够长的字符串，都包含一个短子串可扩张任意多次，所得字符串仍然属于该正规集</p>\n<ul>\n<li>CFL 缩胀定理<br>在CFL中，每个足够长的字符串，都包含两个相距不远的短子串，两个子串可以扩充任意多次，所得子串仍然属于CFL</li>\n</ul>\n<p><strong>形式描述：</strong><br>对于每个CFL，都存在正整数 $k \\ge 0$ 使得对每个$z \\in L$ 只要 $|z| \\ge k$ 就可将z划分为5个子串，<br>满足以下三个条件</p>\n<ol>\n<li>对任何的$i \\ge 0$ 都有$uv^iwx^iy \\in L$</li>\n<li>$|vx| \\ge 1$</li>\n<li>$|vwx| \\le k$</li>\n</ol>\n<p>（其中 k = $b^{|V| + 1}$，其中b是生成式右侧符号数的最大值）<br>看计算理论导引P77，写的很清楚</p>\n<h3 id=\"6-2-Ogden定理\"><a href=\"#6-2-Ogden定理\" class=\"headerlink\" title=\"6.2 Ogden定理\"></a>6.2 Ogden定理</h3><p><strong>形式描述：</strong><br>L为CFL，存在整数$k \\ge 0$，使得对每个$z \\in L$，并且在z中标出k个或多于k个特别符号，将z写成z=uvwxy，且满足</p>\n<ol>\n<li>v和x一起至少包含一个特别符号</li>\n<li>vwx之多包含k个特别符号<br>则对任何$i \\ge 0,\\ uv^iwx^iy \\in L$</li>\n</ol>\n<p>例题6.4 </p>\n<h3 id=\"6-3-CFL封闭性质\"><a href=\"#6-3-CFL封闭性质\" class=\"headerlink\" title=\"6.3 CFL封闭性质\"></a>6.3 CFL封闭性质</h3><p>回忆一下RL的封闭性质，RL在以下运算下封闭</p>\n<ul>\n<li>交并补</li>\n<li>连接</li>\n<li>闭包</li>\n<li>商</li>\n</ul>\n<p><strong>CFL在以下运算下封闭</strong></p>\n<ul>\n<li><p>并<br>对G1,G2，生成式的开始元S1，S2<br>构造 G3 $S \\to S1 | S2$</p>\n</li>\n<li><p>连接<br>对G1,G2，生成式的开始元S1，S2<br>构造 G3 $S \\to S1S2$</p>\n</li>\n<li><p>闭包<br>对G1,G2，生成式的开始元S1<br>构造 G3 $S \\to S1S|\\epsilon$</p>\n</li>\n</ul>\n<p><strong>注意 CFL 在 <em>交</em> $\\cap$ 和 <em>补</em> $\\hat{ }$ 运算下不封闭</strong></p>\n<ul>\n<li><p>交<br>$L1= {a^ib^ic^j|i \\ge 1, j \\ge 1}$, $L2= {a^ib^jc^j|i \\ge 1, j \\ge 1}$<br>两者是CFL<br>但其交集$L1 \\cap L2= {a^ib^ic^i|i \\ge 1}$ 不是CFL，可由Pumping LEmma 证得</p>\n</li>\n<li><p>补运算<br>交运算，可化为补+并的形式，若补运算封闭，则由于并运算封闭，可证得交运算封闭，推出矛盾。</p>\n</li>\n</ul>\n<h4 id=\"CFL和正规集的交是CFL\"><a href=\"#CFL和正规集的交是CFL\" class=\"headerlink\" title=\"CFL和正规集的交是CFL\"></a>CFL和正规集的交是CFL</h4><ul>\n<li>定理6.6 若L是CFL，R是正规集，则$L\\cap R$是CFL</li>\n</ul>\n<h3 id=\"6-4-CFL判定算法\"><a href=\"#6-4-CFL判定算法\" class=\"headerlink\" title=\"6.4 CFL判定算法\"></a>6.4 CFL判定算法</h3><h4 id=\"给出CFG-G-V-T-P-S-L-G-是否为空和是否有穷问题是可判定的\"><a href=\"#给出CFG-G-V-T-P-S-L-G-是否为空和是否有穷问题是可判定的\" class=\"headerlink\" title=\"给出CFG G=(V, T, P, S), L(G)是否为空和是否有穷问题是可判定的\"></a>给出CFG G=(V, T, P, S), L(G)是否为空和是否有穷问题是可判定的</h4><ul>\n<li>L(G) 是否为空<ul>\n<li>检验S是否能派生出终结符号串</li>\n<li>若能，则L(G)非空；不能则为空</li>\n</ul>\n</li>\n<li>L(G)是否有穷<ul>\n<li>对G的Chomsky范式，以变元为顶点画出有向图</li>\n<li>原问题 $\\Leftrightarrow$ 该有向图是否有回路</li>\n<li>即X的最长路径长度为l，则从X派生出的终结符号串长度不超过$2^l$ (归纳假设)</li>\n</ul>\n</li>\n</ul>\n<p>图论算法判定一个有向图是否有回路，所以L(G’)是否有穷，是可判定的</p>\n<h3 id=\"6-5-成员资格问题\"><a href=\"#6-5-成员资格问题\" class=\"headerlink\" title=\"6.5 成员资格问题\"></a>6.5 成员资格问题</h3><p><strong>给定一个CFG G和一个终结符串x，问x是否属于L(G)</strong><br>暴力算法思想，对于G的Greibach范式文法，从S生成式推出右侧的第一个终结变元和x串的第一个符号比较，如果对应就把右侧第二个变元的推出式拿出重复上述操作，直到接受或拒绝为止，时间复杂度$O(m^n)$</p>\n<h4 id=\"CYK算法\"><a href=\"#CYK算法\" class=\"headerlink\" title=\"CYK算法\"></a>CYK算法</h4><p>时间复杂度 $O({|x|}^3)$<br>倒着的树，看Vij表，懂的都懂<br>（区间DP）<br><img src=\"/uploads/upload_e2b3e93174f7cd571038ce381a21f95c.png\" alt></p>\n<hr>\n<h2 id=\"第七章-图灵机\"><a href=\"#第七章-图灵机\" class=\"headerlink\" title=\"第七章 图灵机\"></a>第七章 图灵机</h2><p>重点</p>\n<ul>\n<li>构造语⾔的图灵机（会考的稍微复杂）</li>\n<li>图灵机构造技术 其他类型的图灵机（多带的、⾮确定、双栈机） </li>\n<li>枚举器，正则次序，对偶产生器</li>\n</ul>\n<h3 id=\"7-1-图灵机基本模型\"><a href=\"#7-1-图灵机基本模型\" class=\"headerlink\" title=\"7.1 图灵机基本模型\"></a>7.1 图灵机基本模型</h3><p>确定单带图灵机是一个9元组 $M=(Q,\\Sigma,\\Gamma,\\vdash, \\diamond,\\delta,s,t,r)$</p>\n<ul>\n<li><ol>\n<li>Q有穷状态集</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\Sigma$有穷输入字母表</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\Gamma$有穷的带字母表</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\vdash$ 左端标记</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\diamond$ 空白符号</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\delta$ 转移函数</li>\n</ol>\n</li>\n<li><ol>\n<li>$s \\in Q$ 开始状态</li>\n</ol>\n</li>\n<li><ol>\n<li>$t \\in Q$ 接受状态</li>\n</ol>\n</li>\n<li><ol>\n<li>$r \\in Q$ 拒绝状态</li>\n</ol>\n</li>\n</ul>\n<p>L 表示读写头左移，R表示右移，对于左端标记，永远有$\\delta(p,\\vdash)=(q,\\vdash,R)$</p>\n<ul>\n<li><p>递归可枚举集<br>TM M接受的语言，称为递归可枚举集</p>\n</li>\n<li><p>递归集<br>被完全 TM M 接受的语言，称为递归集</p>\n</li>\n<li><p>完全TM<br>对一切输入均能停机（达到接受或拒绝状态）</p>\n</li>\n</ul>\n<p>例题做做做</p>\n<h3 id=\"7-2-图灵机构造技术\"><a href=\"#7-2-图灵机构造技术\" class=\"headerlink\" title=\"7.2 图灵机构造技术\"></a>7.2 图灵机构造技术</h3><h4 id=\"有限控制器中的存储\"><a href=\"#有限控制器中的存储\" class=\"headerlink\" title=\"有限控制器中的存储\"></a>有限控制器中的存储</h4><ul>\n<li>元组表示状态，将带上符号吸收到状态中</li>\n</ul>\n<h4 id=\"移动\"><a href=\"#移动\" class=\"headerlink\" title=\"移动\"></a>移动</h4><ul>\n<li>将带上符号不断吸收到状态中，不断写下，达到整体移动的目的</li>\n</ul>\n<h4 id=\"多道技术\"><a href=\"#多道技术\" class=\"headerlink\" title=\"多道技术\"></a>多道技术</h4><ul>\n<li>保存处理更复杂的数据，例如计算$n^2$</li>\n</ul>\n<h4 id=\"查讫符号\"><a href=\"#查讫符号\" class=\"headerlink\" title=\"查讫符号\"></a>查讫符号</h4><ul>\n<li>即给带上符号打标记，利用到多道技术</li>\n<li>常用于区分某个符号是否查过</li>\n<li>例7.7 构造一个识别 $l={wcw|w \\in {a,b}^+}$的 $TM$</li>\n</ul>\n<h4 id=\"子程序技术\"><a href=\"#子程序技术\" class=\"headerlink\" title=\"子程序技术\"></a>子程序技术</h4><ul>\n<li>懂的都懂，大概不考<br>构造TM M实现乘法运算</li>\n</ul>\n<h3 id=\"7-3-图灵机的变型\"><a href=\"#7-3-图灵机的变型\" class=\"headerlink\" title=\"7.3 图灵机的变型\"></a>7.3 图灵机的变型</h3><h4 id=\"双向无限带\"><a href=\"#双向无限带\" class=\"headerlink\" title=\"双向无限带\"></a>双向无限带</h4><ul>\n<li>将图灵机的单向无限延伸扩大到双向无限延伸<ul>\n<li>无左端标记$\\vdash$</li>\n<li>其余符号和功能均与单向无限带TM相同</li>\n</ul>\n</li>\n</ul>\n<p>并没增加其表达能力，和单带相同</p>\n<ul>\n<li>可以构造一个双带单向无限图灵机，识别能力与双向无限图灵机相同（定理7.1）</li>\n</ul>\n<h4 id=\"多带\"><a href=\"#多带\" class=\"headerlink\" title=\"多带\"></a>多带</h4><ul>\n<li>用一个控制器控制k条带，在每条带上有独立的读写头<br><strong>和多道技术的区别</strong><br>多道技术是一个控制器多个带，这个是多个控制器多个带。</li>\n<li>给一些证明带来许多方便</li>\n<li>并没增加其表达能力，和单带相同</li>\n</ul>\n<h4 id=\"非确定图灵机\"><a href=\"#非确定图灵机\" class=\"headerlink\" title=\"非确定图灵机\"></a>非确定图灵机</h4><p><strong>确定的图灵机 $\\delta$ 是单值函数，非确定性图灵机增加非确定性动作，并未改变其识别能力</strong></p>\n<ul>\n<li>可以证明确定型图灵机与非确定型图灵机的等价性<br>定理7.3 若L被一个非确定的TM $M_1$ 接受，则L也被某个确定的TM $M_2$ 接受。</li>\n</ul>\n<h4 id=\"双栈机\"><a href=\"#双栈机\" class=\"headerlink\" title=\"双栈机\"></a>双栈机</h4><p>其是特殊的三带图灵机<br>一个带用于输入，只读不写<br>另外两个用来模拟栈</p>\n<ul>\n<li>读头右移，可写任意符号 （进栈）</li>\n<li><p>读头左移，只能写空白符 （退栈）<br>读头指向为栈顶，左端标记右边那个为栈底</p>\n</li>\n<li><p>任意的单带图灵机能被双栈机给模拟<br>右移时，右栈弹栈，左栈压栈。反之类似</p>\n</li>\n</ul>\n<p><strong>下推自动机是单栈机，所以其能力比图灵机小， 即$PDA &lt; TM$</strong><br><strong>图灵机是下推自动机的扩充，能接受其不能接受的语言</strong></p>\n<h4 id=\"带字母最少的图灵机\"><a href=\"#带字母最少的图灵机\" class=\"headerlink\" title=\"带字母最少的图灵机\"></a>带字母最少的图灵机</h4><ul>\n<li>限制带字母表上只有 $0,\\ 1,\\ \\diamond$ 三个符号</li>\n<li>和任何TM等价</li>\n</ul>\n<h4 id=\"作为枚举器的图灵机\"><a href=\"#作为枚举器的图灵机\" class=\"headerlink\" title=\"作为枚举器的图灵机\"></a>作为枚举器的图灵机</h4><ul>\n<li>用一条带专门作为输出带，带上符号一旦写上就不改动，带头一直往右，永不回头。</li>\n</ul>\n<h4 id=\"枚举器和TM的等价\"><a href=\"#枚举器和TM的等价\" class=\"headerlink\" title=\"枚举器和TM的等价\"></a>枚举器和TM的等价</h4><ul>\n<li>设对某个枚举器 $M_1,\\ L=G(M_1)$, 则存在TM $M_2$ 使得 $L(M_2) = L$<ul>\n<li>构造M2，M2比M1多一条输入带，比较M2的输入和M1产生的串，如果相等则接受，不相等则与M1产生的下一个串继续比较，这样进行。</li>\n<li>因为M1产生的串都是M2能接受的，M1不能产生的串都是M2不能接受的（不停机）所以 L(M2)=G(M1)=L</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"对偶产生器\"><a href=\"#对偶产生器\" class=\"headerlink\" title=\"对偶产生器\"></a>对偶产生器</h4><ul>\n<li>一个过程，以i+j不减的顺序列出正整数对(i,j)</li>\n</ul>\n<h4 id=\"字母表-Sigma-上串的正则次序\"><a href=\"#字母表-Sigma-上串的正则次序\" class=\"headerlink\" title=\"字母表 $\\Sigma$ 上串的正则次序\"></a>字母表 $\\Sigma$ 上串的正则次序</h4><ul>\n<li>先按长度排序</li>\n<li>再按字典序</li>\n</ul>\n<h3 id=\"7-4-图灵机与0型文法的关系\"><a href=\"#7-4-图灵机与0型文法的关系\" class=\"headerlink\" title=\"7.4 图灵机与0型文法的关系\"></a>7.4 图灵机与0型文法的关系</h3><p>图灵机对应0型文法</p>\n<hr>\n<h2 id=\"第八章-不可判定性\"><a href=\"#第八章-不可判定性\" class=\"headerlink\" title=\"第八章 不可判定性\"></a>第八章 不可判定性</h2><p>重点</p>\n<ul>\n<li>递归集和递归可枚举集的属性 </li>\n<li>两个不可判定问题（停机问题+成员资格问题） </li>\n<li>通⽤图灵机的概念，图灵机的⼆进制编码 </li>\n<li>Rice定理</li>\n</ul>\n<h3 id=\"8-1-递归集和递归可枚举集性质\"><a href=\"#8-1-递归集和递归可枚举集性质\" class=\"headerlink\" title=\"8.1 递归集和递归可枚举集性质\"></a>8.1 递归集和递归可枚举集性质</h3><h4 id=\"补集\"><a href=\"#补集\" class=\"headerlink\" title=\"补集\"></a><strong>补集</strong></h4><ul>\n<li>一个递归集的补集仍然是递归集<br>因为完全TM<br>调换接受拒绝状态</li>\n</ul>\n<h4 id=\"并集\"><a href=\"#并集\" class=\"headerlink\" title=\"并集\"></a><strong>并集</strong></h4><ul>\n<li>递归集的并是递归的，递归可枚举集的并是递归可枚举的<ul>\n<li>对于递归集，其是由完全TM生成的语言集合那么对于输入串，可先经M1进行验证，若接受则接受，若不接受则进第二个M2，重复上述过程。 （这里的保证是因为他们是完全TM，可以停机）</li>\n<li>对于递归可枚举集，构造非确定M3’,对输入分别在M1，和M2上验证，如果有一个接受则接受，可见M3‘的停机问题也是不可判定的，为一般TM。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"交集\"><a href=\"#交集\" class=\"headerlink\" title=\"交集\"></a><strong>交集</strong></h4><ul>\n<li>递归集的交是递归的，递归可枚举集的交是递归可枚举的</li>\n</ul>\n<p>看ppt的图，应该很清楚</p>\n<ul>\n<li>若语言 L 和 L补 都是递归可枚举的，则L（和L补）是递归的</li>\n</ul>\n<h3 id=\"8-2-通用图灵机和两个不可判定问题\"><a href=\"#8-2-通用图灵机和两个不可判定问题\" class=\"headerlink\" title=\"8.2 通用图灵机和两个不可判定问题\"></a>8.2 通用图灵机和两个不可判定问题</h3><h4 id=\"通用图灵机\"><a href=\"#通用图灵机\" class=\"headerlink\" title=\"通用图灵机\"></a>通用图灵机</h4><p>模拟任何图灵机的图灵机，将某个TM作为通用图灵机的输入来看待</p>\n<ul>\n<li>需要对TM有统一的、合理的编码</li>\n<li>在给定输入串上，模拟TM的动作</li>\n<li>给定TM接受，则该TM接受这个TM和这个输入的二元组</li>\n</ul>\n<h4 id=\"图灵机编码\"><a href=\"#图灵机编码\" class=\"headerlink\" title=\"图灵机编码\"></a>图灵机编码</h4><p>M#w</p>\n<h4 id=\"关于停机问题的不可判定性\"><a href=\"#关于停机问题的不可判定性\" class=\"headerlink\" title=\"关于停机问题的不可判定性\"></a>关于停机问题的不可判定性</h4><ul>\n<li><p>没有一个算法在有限步之内能够判断一个TM M在给定的输入串x上是否能停机。</p>\n<ul>\n<li><ol>\n<li>接受状态</li>\n</ol>\n</li>\n<li><ol>\n<li>拒绝状态</li>\n</ol>\n</li>\n<li><ol>\n<li>无限循环</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><p><strong>任意给定TM M对任意给定输入串x是否停机的问题是不可判定的</strong><br>自指悖论（类似<strong>罗素悖论</strong>的方法）</p>\n</li>\n</ul>\n<p><strong>证明</strong></p>\n<ul>\n<li><strong>Step 1 TM编码</strong><ul>\n<li>由于可对TM进行编码，所以任何TM可以表示为01串</li>\n<li>而我们可以把任何零一串看作一个TM</li>\n<li>在上述规定下，可按正则次序列出所有TM<br>$M<em>{\\epsilon},\\ M_0,\\ M_1\\ ,M</em>{00},\\ M_{01}…$<br>显然真正的TM一定出现在此序列中至少一次</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p><strong>Step 2 二维表标记</strong></p>\n<ul>\n<li>考虑无穷维的二维表，其顶端遍历 ${0, 1}^*$ 的正则序列，左端遍历 TM，用H (Halt) 表示停机，用L (Loop) 表示不停机，在对应位置做上标记</li>\n</ul>\n</li>\n<li><p><strong>Step 3 开始证明</strong></p>\n<ul>\n<li>假设存在完全TM K，以Mx#y为输入，能够判断Mx在y上是否能够停机。如果停机，则 K 接受 Mx#y；否则，拒绝</li>\n<li>构造另一个TM N，其输入为 $x \\in {0, 1}^*$ 其完成以下任务<ul>\n<li>从x找到Mx，将Mx#x写到其带上</li>\n<li>在 Mx#x 上模拟K的动作，如果K接受，则其就进入循环（不停机），如果K拒绝，他就接受。</li>\n</ul>\n</li>\n<li>那么根据N的定义，如果N在x上停机，则代表K拒绝，则代表Mx在y上不停机。</li>\n</ul>\n</li>\n<li><p><strong>Step 4 推出矛盾</strong></p>\n<ul>\n<li>因为N也是图灵机，假设其编码为y，在正则序列中出现为My，如果N在y上停机，则代表My在y上不停机，而My就是N，导致矛盾。矛盾起因是K的存在性<br>所以不存在这样的TM能够判断M在任何输入下是否停机，即停机问题是不可判定的</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"成员资格问题的不可判定性\"><a href=\"#成员资格问题的不可判定性\" class=\"headerlink\" title=\"成员资格问题的不可判定性\"></a>成员资格问题的不可判定性</h4><ul>\n<li><p><strong>对于任意给定 TM M 和输入串x，M是否接受x的问题是不可判定的</strong></p>\n<ul>\n<li><ol>\n<li>存在完全的 TM K，它能对任意的M和x，判断x是否属于L(M)。若$x \\in L(M)$，则K接受$M#x$；否则拒绝</li>\n</ol>\n</li>\n<li><ol>\n<li>构造N，使得如果x在M上达到接受或拒绝的停机状态，则N接受。可以看出N是判断M在x上是否停机的TM。</li>\n</ol>\n</li>\n<li><ol>\n<li>现在对M输入N#x，则N是否接受x等价于x在M上是否停机，而停机问题是不可判定的，所以成员资格问题也不可判定。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"8-3-归约方法和Rice定理\"><a href=\"#8-3-归约方法和Rice定理\" class=\"headerlink\" title=\"8.3 归约方法和Rice定理\"></a>8.3 归约方法和Rice定理</h3><ul>\n<li><strong>给定TM M其是否接受空串的问题是不可判定的</strong></li>\n</ul>\n<p>将HP的不可判定性导出问题B的不可判定性</p>\n<ul>\n<li>HP Halt Problem 停机问题</li>\n<li>B 其他问题</li>\n</ul>\n<h4 id=\"Rice定理\"><a href=\"#Rice定理\" class=\"headerlink\" title=\"Rice定理\"></a>Rice定理</h4><ul>\n<li><p>r.e.集合类的任何一个非平凡性质都是不可判定的</p>\n</li>\n<li><p><strong>Step 1 准备</strong> </p>\n<ul>\n<li>设 P 是 r.e. 集合类上的一个非平凡性质，不失一般性，假设空集不具有性质P，则因为P的非平凡性，必定存在一个集合A满足P，即P(A) = T设K是接受A的TM</li>\n</ul>\n</li>\n<li><p><strong>Step 2 归约HP到集合 ${M|P(L(M)) = T}$</strong><br>  给定M#x, 构造TM M’，其按以下步骤进行</p>\n<ul>\n<li>对于TM的输入y，将其放在一个道上</li>\n<li>将x写在另一个道上</li>\n<li>在M上模拟x的动作</li>\n<li>如果M在x上停机，则在K上模拟y的动作</li>\n<li>如果K接受y，则M’接受y</li>\n</ul>\n</li>\n<li><p><strong>Step 3 推出矛盾</strong></p>\n<ul>\n<li>显然，M和M’的停机问题相关联，如果停机有 M’ 和 K 接受一样的集合。</li>\n<li>所以有 M 在 x 上停机，可推出，L(M’) = A，可推出 P(L(M’)) = T</li>\n<li>反之则不停机，P(L(M’)) = F</li>\n<li>这就得出了停机问题到该问题的归约，但停机问题不可判定，所以其非平凡性质也不可判定。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"8-4-关于CFL的不可判定问题\"><a href=\"#8-4-关于CFL的不可判定问题\" class=\"headerlink\" title=\"8.4 关于CFL的不可判定问题\"></a>8.4 关于CFL的不可判定问题</h3><h3 id=\"8-5-Post对应问题的不可判定性及其应用\"><a href=\"#8-5-Post对应问题的不可判定性及其应用\" class=\"headerlink\" title=\"8.5 Post对应问题的不可判定性及其应用\"></a>8.5 Post对应问题的不可判定性及其应用</h3><hr>\n<h2 id=\"第九章-线性有界自动机和上下文有关语言\"><a href=\"#第九章-线性有界自动机和上下文有关语言\" class=\"headerlink\" title=\"第九章 线性有界自动机和上下文有关语言\"></a>第九章 线性有界自动机和上下文有关语言</h2><p>重点</p>\n<ul>\n<li>给定语⾔，构造LBA </li>\n<li>LBA对停机问题的判定问题</li>\n</ul>\n<p>各种机器对应的不同⽂法，⽐如FA对应CFG，图灵机对应0型，PDA对应CFL</p>\n<h3 id=\"9-1-线性有界自动机-LBA\"><a href=\"#9-1-线性有界自动机-LBA\" class=\"headerlink\" title=\"9.1 线性有界自动机 LBA\"></a>9.1 线性有界自动机 LBA</h3><ul>\n<li>对TM的读写头范围加以限制</li>\n<li>左右端都有标记</li>\n<li>接收机和小于TM接受的集合类</li>\n</ul>\n<p>线性有界自动机 LBA 是9元组 $M=(Q,\\ \\Sigma, \\Gamma, \\vdash,\\ \\dashv, \\delta,\\ s,\\ t,\\ r)$</p>\n<ul>\n<li><ol>\n<li>Q 有穷状态集</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\Sigma$ 有穷输入字母表</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\Gamma$ 有穷带上字母表</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\vdash$ 左端符号</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\dashv$ 右端符号</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\delta$ 状态转移函数</li>\n</ol>\n</li>\n<li><ol>\n<li>s 开始状态</li>\n</ol>\n</li>\n<li><ol>\n<li>t 接受状态</li>\n</ol>\n</li>\n<li><ol>\n<li>r 拒绝状态</li>\n</ol>\n</li>\n</ul>\n<p><strong><em>例题9.1</em></strong><br>思路：</p>\n<ul>\n<li><ol>\n<li>查讫符号打标记后找到中心</li>\n</ol>\n</li>\n<li><ol>\n<li>对消</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"9-2-LBA-和-CSL-的关系\"><a href=\"#9-2-LBA-和-CSL-的关系\" class=\"headerlink\" title=\"9.2 LBA 和 CSL 的关系\"></a>9.2 LBA 和 CSL 的关系</h3><ul>\n<li>若L是CSL，则L可被某个LBA接受</li>\n</ul>\n<p>将S派生出来的各种字符串（在下道），与上道的w比较，若相等则接受</p>\n<h3 id=\"9-3-CSL的性质及其和递归集的关系\"><a href=\"#9-3-CSL的性质及其和递归集的关系\" class=\"headerlink\" title=\"9.3 CSL的性质及其和递归集的关系\"></a>9.3 CSL的性质及其和递归集的关系</h3><h4 id=\"CSL封闭性\"><a href=\"#CSL封闭性\" class=\"headerlink\" title=\"CSL封闭性\"></a>CSL封闭性</h4><ul>\n<li>并</li>\n<li>连接</li>\n<li>正闭包（因为CSL不包含 $\\epsilon$，所以L1为CSL则其闭包 $L_1^*$ 不是CSL）</li>\n<li>交运算</li>\n</ul>\n<h4 id=\"每个CSL都是递归的\"><a href=\"#每个CSL都是递归的\" class=\"headerlink\" title=\"每个CSL都是递归的\"></a>每个CSL都是递归的</h4><p>思路：<br>因为输入串长度有限，并且两端封闭，所以总的情况数是有限的为$k(n+2)l^n$ 种，那么用双带，一带正常执行，令一带计算执行步数，如果超出则说明进入循环，则拒绝。所以有CSL是递归的</p>\n<h4 id=\"存在递归集，不是CSL\"><a href=\"#存在递归集，不是CSL\" class=\"headerlink\" title=\"存在递归集，不是CSL\"></a>存在递归集，不是CSL</h4><h3 id=\"9-4-语言类之间的关系\"><a href=\"#9-4-语言类之间的关系\" class=\"headerlink\" title=\"9.4 语言类之间的关系\"></a>9.4 语言类之间的关系</h3><ol>\n<li>RL(3型文法RG)</li>\n<li>DCFL</li>\n<li>CFL(2型文法CFG)</li>\n<li>CSL∪{ε}(1型文法CSG)</li>\n<li>递归集</li>\n<li>r.e.集（递归可枚举集）(0型文法PSG),如成员问题所对应的字符串</li>\n<li>非r.e.集，如FIN</li>\n</ol>\n<hr>\n<h2 id=\"第十一章\"><a href=\"#第十一章\" class=\"headerlink\" title=\"第十一章\"></a>第十一章</h2><p>重点</p>\n<ul>\n<li>给定语⾔：判断是P还是NP</li>\n<li>P与NP的封闭性证明 常⻅的NPC问题的推导和证明(重点)<ul>\n<li>证NP问题</li>\n<li>证归约性 </li>\n</ul>\n</li>\n<li>P NP NPC NPHARD的概念 </li>\n<li>PSPACE==NPSPACE-NPSPACEhard </li>\n<li>L-NL（构造：利⽤指针） </li>\n<li>后⾯的层次定理&amp;布尔电路不考</li>\n</ul>\n<h3 id=\"层次概览\"><a href=\"#层次概览\" class=\"headerlink\" title=\"层次概览\"></a>层次概览</h3><p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_81564f07be5cb20ec62f5761169626dc.png\" alt></p>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_aeeccf9bef7be94af30f6875bdf5d5e1.png\" alt></p>\n<script type=\"math/tex; mode=display\">L \\subset NL = coNL \\subset P \\subset NP \\subset PSPACE = NPSPACE \\subset EXPTIME</script><h3 id=\"P类\"><a href=\"#P类\" class=\"headerlink\" title=\"P类\"></a>P类</h3><ul>\n<li>定义： P是确定型单带图灵机在多项式时间内可判定的语言类</li>\n</ul>\n<script type=\"math/tex; mode=display\">P = \\mathop\\cup\\limits_{k} TIME(n^k)</script><h4 id=\"PATH-in-P\"><a href=\"#PATH-in-P\" class=\"headerlink\" title=\"PATH $\\in$ P\"></a><strong>PATH $\\in$ P</strong></h4><p>PATH 问题，即G（有向图）中两点判定是否存在有向路径<br>用BFS算法，O(m)<br>或者dijkstra算法</p>\n<h4 id=\"RELPRIME-in-P\"><a href=\"#RELPRIME-in-P\" class=\"headerlink\" title=\"RELPRIME $\\in$ P\"></a><strong>RELPRIME $\\in$ P</strong></h4><p>RELPRIME 问题，即判定两数互素<br>辗转相除法（欧几里得算法）</p>\n<h4 id=\"每个CFL都是P\"><a href=\"#每个CFL都是P\" class=\"headerlink\" title=\"每个CFL都是P\"></a><strong>每个CFL都是P</strong></h4><p>CYK 复杂度$O(n^3)$</p>\n<h3 id=\"NP类\"><a href=\"#NP类\" class=\"headerlink\" title=\"NP类\"></a>NP类</h3><h4 id=\"引理：NP是具有多项式时间验证机的语言\"><a href=\"#引理：NP是具有多项式时间验证机的语言\" class=\"headerlink\" title=\"引理：NP是具有多项式时间验证机的语言\"></a><strong>引理：NP是具有多项式时间验证机的语言</strong></h4><ul>\n<li>用于验证该问题的额外信息称为证书<ul>\n<li>HAMPATH 中两点之间的哈密顿路径</li>\n<li>COMPOSITES 中 x 一个不等于1的因子</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"一个语言在NP中，当且仅当其能够被某个非确定型多项式时间图灵机判定\"><a href=\"#一个语言在NP中，当且仅当其能够被某个非确定型多项式时间图灵机判定\" class=\"headerlink\" title=\"一个语言在NP中，当且仅当其能够被某个非确定型多项式时间图灵机判定\"></a><strong>一个语言在NP中，当且仅当其能够被某个非确定型多项式时间图灵机判定</strong></h4><h4 id=\"NTIME-t-n-L-L-是一个被O-t-n-时间的非确定型图灵机判定的语言\"><a href=\"#NTIME-t-n-L-L-是一个被O-t-n-时间的非确定型图灵机判定的语言\" class=\"headerlink\" title=\"NTIME(t(n)) = {L| L 是一个被O(t(n))时间的非确定型图灵机判定的语言}\"></a><strong>NTIME(t(n)) = {L| L 是一个被O(t(n))时间的非确定型图灵机判定的语言}</strong></h4><script type=\"math/tex; mode=display\">NP = \\cup_k NTIME(n^k)</script><h4 id=\"CLIQUE-in-NP\"><a href=\"#CLIQUE-in-NP\" class=\"headerlink\" title=\"CLIQUE $\\in$ NP\"></a><strong>CLIQUE $\\in$ NP</strong></h4><p>CLIQUE = {(G,k)| G是包含k团的无向图}</p>\n<ul>\n<li><p>验证机角度</p>\n<pre><code>  证书：团，记为c\n  V为CLIQUE的验证机\n  V = 对输入((G,k), c)\n  1. 检查c是否是G中k个点的集合\n  2. 检查G是否包含连接c中节点的所有边\n  3. 若均通过则接受，否则拒绝\n</code></pre></li>\n<li><p>非确定型TM角度</p>\n<pre><code>  N = 对于输入(G,k)\n  1. 非确定的选择G中k个节点的子集c\n  2. 检查G是否包含连接c中节点的所有边\n  3. 若是则接受，否则拒绝\n</code></pre></li>\n</ul>\n<h4 id=\"SUBSET-SUM-in-NP\"><a href=\"#SUBSET-SUM-in-NP\" class=\"headerlink\" title=\"SUBSET-SUM $\\in$ NP\"></a><strong>SUBSET-SUM $\\in$ NP</strong></h4><p>SUBSET-SUM，给定集合s和t，判定是否有s的子集y，使得子集y中元素之和等于t</p>\n<ul>\n<li><p>验证机角度</p>\n<pre><code>  证书：子集\n  V = 对输入((s,t),c)\n  1. 验证c中元素之和是否等于t\n  2. 验证s是否包含c中所有元素\n  3. 若均通过则接受，否则拒绝\n</code></pre></li>\n<li><p>非确定型TM角度</p>\n<pre><code>  N = 对于输入(s,t)\n  1. 非确定的选择s中的子集c\n  2. 验证c的元素之和是否等于t\n  3. 若是则接受，否则拒绝\n</code></pre></li>\n<li><p>co-NP</p>\n</li>\n</ul>\n<h3 id=\"P与NP问题\"><a href=\"#P与NP问题\" class=\"headerlink\" title=\"P与NP问题\"></a>P与NP问题</h3><ul>\n<li>P = NP ?<script type=\"math/tex; mode=display\">NP \\subset EXPTIME = \\mathop\\cup\\limits_{k} TIME(2^{n^k})</script></li>\n</ul>\n<h3 id=\"NP完全性\"><a href=\"#NP完全性\" class=\"headerlink\" title=\"NP完全性\"></a>NP完全性</h3><ul>\n<li>定义<ul>\n<li><ol>\n<li>B属于NP（多项式时间内被非确定图灵机判定）</li>\n</ol>\n</li>\n<li><ol>\n<li>NP中每一个A都可在多项式时间内归约到B（归约，重要步骤）</li>\n</ol>\n</li>\n<li>则称B为NP完全问题</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>证明P=NP的一类思路<ul>\n<li>证明某个NPC $\\in$ P</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"库克-列文定理\"><a href=\"#库克-列文定理\" class=\"headerlink\" title=\"库克-列文定理\"></a><strong>库克-列文定理</strong></h4><p>SAT 问题，给定一个布尔公式$\\phi$判断其是否可满足</p>\n<script type=\"math/tex; mode=display\">SAT \\in P，当且仅当 P=NP</script><p>证明：</p>\n<ul>\n<li>第一步：非确定图灵机可以在多项式时间内猜测变量的赋值，然后判断其是否可满足，因此 $SAT \\subset NP$</li>\n<li>第二步：<ul>\n<li>假设从$NP$取出任意语言$A$，非确定$TM N$在$n^k-3$判定</li>\n<li>考虑$N$对应的$n^k\\times n^k$画面$\\omega$</li>\n<li>设计一个$\\phi$,使得变量的一个满足赋值确实对应$N$在$\\omega$上的接受画面</li>\n<li>//todo</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"SAT-in-NPC\"><a href=\"#SAT-in-NPC\" class=\"headerlink\" title=\"SAT $\\in$ NPC\"></a><strong>SAT $\\in$ NPC</strong></h4><p>为NP中的每一个语言A，构造一个到SAT的多项式时间归约<br>书P170~173</p>\n<h4 id=\"3SAT-in-NPC\"><a href=\"#3SAT-in-NPC\" class=\"headerlink\" title=\"3SAT $\\in$ NPC\"></a><strong>3SAT $\\in$ NPC</strong></h4><h4 id=\"CLIQUE-in-NPC\"><a href=\"#CLIQUE-in-NPC\" class=\"headerlink\" title=\"CLIQUE $\\in$ NPC\"></a><strong>CLIQUE $\\in$ NPC</strong></h4><ul>\n<li><strong>证明NPC</strong><ul>\n<li>先证明NP</li>\n<li>再证明某个已知NPC问题可在多项式时间内归约到他</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"顶点覆盖问题-VERTEX-COVER\"><a href=\"#顶点覆盖问题-VERTEX-COVER\" class=\"headerlink\" title=\"顶点覆盖问题 VERTEX-COVER\"></a>顶点覆盖问题 VERTEX-COVER</h4><p>VERTEX-COVER 判定G是具有k个顶点的顶点覆盖的无向图<br>NP完全<br>3SAT 到 VERTEX-COVER 的归约<br>书P174</p>\n<ul>\n<li>证明思路：将一个$3nf$公式$\\phi$转化成一个图$G$和数值$k$，只要能找到覆盖，$\\phi$就被相应地满足</li>\n</ul>\n<h4 id=\"哈密顿路径问题-HAMPATH\"><a href=\"#哈密顿路径问题-HAMPATH\" class=\"headerlink\" title=\"哈密顿路径问题 HAMPATH\"></a>哈密顿路径问题 HAMPATH</h4><p>HAMPATH $\\in$ NPC<br>3SAT 到 HAMPATH 的归约</p>\n<p>书p175~177</p>\n<h4 id=\"子集和问题-SUBSET-SUM\"><a href=\"#子集和问题-SUBSET-SUM\" class=\"headerlink\" title=\"子集和问题 SUBSET-SUM\"></a>子集和问题 SUBSET-SUM</h4><p>SUBSET-SUM $\\in$ NPC<br>3SAT 到 SUBSET-SUM 的归约</p>\n<p>书p178~180</p>\n<hr>\n<h3 id=\"萨维奇定理\"><a href=\"#萨维奇定理\" class=\"headerlink\" title=\"萨维奇定理\"></a>萨维奇定理</h3><p>任何消耗$f(n)$空间的非确定型TM都可以转变为仅消耗$f^2(n)$空间的确定型TM</p>\n<script type=\"math/tex; mode=display\">NSPACE(f(n)) \\subset SPACE(f^2(n))</script><p>方法：利用中间格局递归二分<br>CANYIELD = 对于输入 c1，c2，t</p>\n<ol>\n<li>t=1 直接检查是否有c1 = c2 或根据N规则，检查c1是否能够一步只能产生c2，其中之一成立则接受，否则拒绝</li>\n<li>若 t &gt; 1，则对于N在w上消耗空间f(n)的每一个格局cm</li>\n<li>运行CANYIELD(c1, cm, t/2)</li>\n<li>运行CANYIELD(cm, c2, t/2)</li>\n<li>两个都接受则接受，否则拒绝</li>\n</ol>\n<p>对输入 $c<em>{start}$，$c</em>{accept}$，$2^{df(n)}$</p>\n<p>递归深度$O(log2^{df(n)})$，所以总消耗空间$O(f^2(n))$</p>\n<h3 id=\"PSPACE类\"><a href=\"#PSPACE类\" class=\"headerlink\" title=\"PSPACE类\"></a>PSPACE类</h3><p>PSPACE是在确定型图灵机上，在多项式空间内可判定的语言类</p>\n<script type=\"math/tex; mode=display\">PSPACE = \\mathop\\cup\\limits_{k}SPACE(n^k)</script><ul>\n<li>SAT $\\in$ SPACE(n)</li>\n<li>$ALL<em>{NFA} \\in coNSPACE(n) \\Rightarrow ALL</em>{NFA} \\in SPACE(n^2)$</li>\n<li><p>其都在PSPACE中</p>\n</li>\n<li><p>$P \\subset PSPACE$<br>因为运行n步的程序，最多消耗n的空间</p>\n</li>\n<li><p>$NP \\subset NPSPACE$<br>同理</p>\n</li>\n</ul>\n<p>由于 NPSPACE = PSPACE<br>所以有 $NP \\subset PSPACE$</p>\n<h3 id=\"PSPACE完全性\"><a href=\"#PSPACE完全性\" class=\"headerlink\" title=\"PSPACE完全性\"></a>PSPACE完全性</h3><p>定义 若B是PSPACE-C则其满足以下两个条件</p>\n<ul>\n<li><ol>\n<li>$B \\in PSPACE$</li>\n</ol>\n</li>\n<li><ol>\n<li>PSPACE中每个语言A可多项式时间内归约到B</li>\n</ol>\n</li>\n<li>只满足2类似NP难称其为PSPACE难的</li>\n</ul>\n<h4 id=\"TQBF问题\"><a href=\"#TQBF问题\" class=\"headerlink\" title=\"TQBF问题\"></a>TQBF问题</h4><p>判定$\\phi$是真的全量词化布尔公式<br>其是PSPACE完全的</p>\n<ul>\n<li>先给出一个线性空间的复杂度算法，证明其属于PSPACE</li>\n<li>再给出归约方式，类似萨维奇定理证明方法<br>书 P192</li>\n</ul>\n<h4 id=\"博弈必胜\"><a href=\"#博弈必胜\" class=\"headerlink\" title=\"博弈必胜\"></a>博弈必胜</h4><p>$FORMULA_GAME = {&lt;\\phi&gt; | 在与\\phi相关联的公式博弈中选手E有必胜策略}$<br>其是PSPACE完全的<br><strong>因为其等价于TQBF</strong></p>\n<h4 id=\"广义地理学\"><a href=\"#广义地理学\" class=\"headerlink\" title=\"广义地理学\"></a>广义地理学</h4><p>$GG = {<G,b> | 在图G上以结点b起始的广义地理学游戏中，选手I有必胜策略}$<br>其是PSPACE完全的<br>证明方法类似TQBF的递归算法</G,b></p>\n<h3 id=\"L和NL类\"><a href=\"#L和NL类\" class=\"headerlink\" title=\"L和NL类\"></a>L和NL类</h3><p>亚线性空间界限，类似工作主存上是亚线性空间，其余放在外存（只读）。</p>\n<h4 id=\"L类\"><a href=\"#L类\" class=\"headerlink\" title=\"L类\"></a>L类</h4><ul>\n<li>L是确定型图灵机在对数空间内可判定的语言类<script type=\"math/tex; mode=display\">L=SPACE(logn)</script></li>\n</ul>\n<h4 id=\"NL类\"><a href=\"#NL类\" class=\"headerlink\" title=\"NL类\"></a>NL类</h4><ul>\n<li><p>NL是非确定性图灵机在对数空间内可判定的语言类集合</p>\n<script type=\"math/tex; mode=display\">NL=NSPACE(logn)</script></li>\n<li><p>例题 8.13<br>$A = {0^k1^k| k \\ge 0} \\in L$<br>在工作带上用二进制数0、1的数目，两个计数器消耗对数级别空间，所以$A \\in L$</p>\n</li>\n<li><p>$PATH \\in NL$<br>非确定的猜测从s到t的每一步，工作带上只记录每一步当前节点的位置，非确定的选择下一个节点，反复执行，直到到达t接受。或执行m步后拒绝，m是节点数。由此得到了PATH的被非确定型图灵机在亚线性空间内接受。</p>\n</li>\n</ul>\n<h3 id=\"NL完全性\"><a href=\"#NL完全性\" class=\"headerlink\" title=\"NL完全性\"></a>NL完全性</h3><p>定义 若语言B是NL完全的，则其满足</p>\n<ul>\n<li><ol>\n<li>$B \\in NL$ </li>\n</ol>\n</li>\n<li><ol>\n<li>NL中的每个A<strong>对数空间</strong>内可归约到B</li>\n</ol>\n</li>\n</ul>\n<h4 id=\"PATH是NL完全的\"><a href=\"#PATH是NL完全的\" class=\"headerlink\" title=\"PATH是NL完全的\"></a>PATH是NL完全的</h4><p>证明方法，把输入字符串w对应为图，图中节点对应NTM在输入w上的一个格局。一个结点能指向另一个结点的调节时，其对应的格局能在NTM的一步内产生第二个结点对应的格局，因此，NTM对输入w是否接受就对应着初始格局到接受格局的PATH<br>更详细的对数空间归约证明情况书 p199~200</p>\n<h4 id=\"NL-subset-P\"><a href=\"#NL-subset-P\" class=\"headerlink\" title=\"$NL \\subset P$\"></a>$NL \\subset P$</h4><ul>\n<li><ol>\n<li>因为PATH是NL完全的，所以NL中任何语言可对数空间内归约到PATH</li>\n</ol>\n</li>\n<li><ol>\n<li>由此，NL中任何语言也可对数时间内归约到PATH</li>\n</ol>\n</li>\n<li><ol>\n<li>因为多项式时间内归约到P中语言的语言本身也属于P</li>\n</ol>\n</li>\n<li><ol>\n<li>所以 $NL \\in P$</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"NL-coNL\"><a href=\"#NL-coNL\" class=\"headerlink\" title=\"NL = coNL\"></a>NL = coNL</h3>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"计算理论基础\"><a href=\"#计算理论基础\" class=\"headerlink\" title=\"计算理论基础\"></a>计算理论基础</h1><h2 id=\"第一章-预备知识\"><a href=\"#第一章-预备知识\" class=\"headerlink\" title=\"第一章 预备知识\"></a>第一章 预备知识</h2><p>重点：</p>\n<ul>\n<li>符号表示，可能在问答题里面出现</li>\n</ul>\n<h3 id=\"1-1-定理及其证明方法\"><a href=\"#1-1-定理及其证明方法\" class=\"headerlink\" title=\"1.1 定理及其证明方法\"></a>1.1 定理及其证明方法</h3><ul>\n<li>形式系统</li>\n</ul>\n<ol>\n<li><strong>基本符号</strong> <em>（常量符号、变量符号、运算符等抽象字符）</em></li>\n<li><strong>形成规则</strong> <em>(构造各种语言的方法规则)</em></li>\n<li><strong>公理</strong> <em>（无需经过证明，正确性得到公认的语句）</em></li>\n<li><strong>推理规则</strong> <em>（用于得到新的合法语句）</em></li>\n</ol>\n<ul>\n<li><em>如何证明一个语句为真</em></li>\n</ul>\n<ol>\n<li>每个语句或者是公理，或者由前面的语句自然导出</li>\n<li>最后一个语句就是所要证明的语句</li>\n</ol>\n<ul>\n<li><strong>定理证明方法</strong></li>\n</ul>\n<ol>\n<li>演绎法</li>\n<li>反证法/归谬法</li>\n<li>归纳法、第二归纳法</li>\n</ol>\n<h3 id=\"1-2-集合及其基本运算\"><a href=\"#1-2-集合及其基本运算\" class=\"headerlink\" title=\"1.2 集合及其基本运算\"></a>1.2 集合及其基本运算</h3><ol>\n<li>集合描述方法</li>\n</ol>\n<ul>\n<li>列举法 $A={a,b,c,d}$</li>\n<li>模式表示法 ${x|P(x)}$</li>\n</ul>\n<ol>\n<li>集合运算及定理</li>\n</ol>\n<ul>\n<li>定理1.9 德摩根定理</li>\n</ul>\n<p>$\\quad \\quad \\bar{A \\cap B} = \\bar A \\cup \\bar B$<br>$\\quad \\quad \\bar{A \\cup B} = \\bar A \\cap \\bar B$</p>\n<h3 id=\"1-3-图和树简介\"><a href=\"#1-3-图和树简介\" class=\"headerlink\" title=\"1.3 图和树简介\"></a>1.3 图和树简介</h3><ul>\n<li><strong>图</strong> ：顶点集合以及边集合</li>\n<li>有向图、无向图</li>\n<li>通路、回路</li>\n<li><p>邻接矩阵</p>\n</li>\n<li><p><strong>树</strong> </p>\n</li>\n<li>树中每一个顶点到另一个顶点均有一条通路，称该顶点为树的根</li>\n<li>树中一定没有回路</li>\n<li>仅一个顶点(根节点)没有前导顶点</li>\n<li>一定存在没有后继的顶点</li>\n</ul>\n<h3 id=\"1-4-字母表、字符串和语言\"><a href=\"#1-4-字母表、字符串和语言\" class=\"headerlink\" title=\"1.4 字母表、字符串和语言\"></a>1.4 字母表、字符串和语言</h3><ul>\n<li>自然语言<br>— 人类彼此相互交流的工具，由基本符号构成，如日语俄语等</li>\n<li><strong>形式语言</strong><br>— 用于需要严格描述的领域，构成基础为“符号”</li>\n</ul>\n<ul>\n<li><strong>字符表</strong>是符号的集合，记为 $\\Sigma$</li>\n<li>$\\Sigma$ 上的符号串<br>— $\\Sigma$ 上的符号以任意顺序拼接起来构成<br>— 任何符号可以重复出现</li>\n<li><strong>定义1.23</strong><br>— 对于任何给定的字符表 $\\Sigma$，$\\Sigma$ 上的字符串集合称作 $\\Sigma$ 上的语言</li>\n<li><strong>定义1.24</strong><br>— 设$L$是某个字母表上的一个语言，若 $L$ 中任何字符串都不是另一个字符串的真前缀，则$L$ 具有<strong>前缀性质</strong></li>\n<li><strong>定义1.25</strong><br>— 设 $L<em>{1}$ 为 $\\Sigma</em>{1}$ 的语言, $L<em>{2}$ 为 $\\Sigma</em>{2}$ 的语言，则  $L<em>{1}$ 和 $L</em>{2}$ 的连接 $L<em>{1}L</em>{2} = {xy | x \\in L<em>{1} and \\ y \\in L</em>{2}}$</li>\n<li><strong>定义1.26</strong><br>— <strong>语言 $L$ 的闭包 $L^{*}$ </strong><br>— 以任意次序连接L中任意多个字符串所组成的集合<br>— 只要 $L$ 中包含至少一个元素, $L^{*}$ 就为无穷集</li>\n</ul>\n<hr>\n<h2 id=\"第二章-文法理论\"><a href=\"#第二章-文法理论\" class=\"headerlink\" title=\"第二章 文法理论\"></a>第二章 文法理论</h2><p>重点：</p>\n<ul>\n<li>⽂法分类（给定⼀个语⾔集合，判定是0123型⽂法，熟悉每个⽂法的判定⽅法）（最重要） </li>\n<li>上下⽂有关⽂法上下⽂信息的获得,1’型⽂法如何转化为1型⽂法</li>\n</ul>\n<h3 id=\"2-1-文法定义\"><a href=\"#2-1-文法定义\" class=\"headerlink\" title=\"2.1 文法定义\"></a>2.1 文法定义</h3><ul>\n<li>四元组 $G=(V,T,P,S)$</li>\n</ul>\n<ol>\n<li>V是变元符有限集 Variables</li>\n<li>T是终结符有限集 Termination</li>\n<li>P是生成式有限集 (Production?)</li>\n<li>S∈V，为文法G的开始符 Start</li>\n</ol>\n<h3 id=\"2-2-派生\"><a href=\"#2-2-派生\" class=\"headerlink\" title=\"2.2 派生\"></a>2.2 派生</h3><p><strong>直接派生</strong><br>若 $\\alpha = \\alpha<em>{1} A \\alpha</em>{2}, \\ \\gamma=\\alpha<em>{1}\\beta\\alpha</em>{2}$ ，且 $A\\to\\beta$ 为P中一个生成式，则 $\\alpha \\mathop{\\Rightarrow}\\limits_{G}^{}\\gamma$<br>，称由 $\\alpha$ 直接派生出 $\\gamma$</p>\n<p><strong>派生</strong><br>将 $\\mathop{\\Rightarrow}\\limits<em>{G}^{}$ 扩充为 $\\hat{\\mathop{\\Rightarrow}\\limits</em>{G}^{}}$，则为派生</p>\n<p>$\\quad (\\hat{\\mathop{\\Rightarrow}\\limits_{}} 表示多步直接派生)$</p>\n<h3 id=\"2-3-文法分类\"><a href=\"#2-3-文法分类\" class=\"headerlink\" title=\"2.3 文法分类\"></a>2.3 文法分类</h3><p><strong>1. 短语结构文法 PSG (0型文法)</strong></p>\n<ul>\n<li><strong>特点：</strong> 不加限制</li>\n<li><strong>对应语言：</strong> 短语结构语言 PSL</li>\n<li><strong>对应自动机：</strong> 图灵机 TM</li>\n<li><strong>形式：</strong> $\\alpha\\to\\beta,\\ \\alpha,\\beta\\in(V \\cup T)^{*}$ 且 $\\alpha\\ne\\epsilon$</li>\n</ul>\n<p><strong>2. 上下文有关文法 CSG (1型文法)</strong></p>\n<ul>\n<li><strong>特点：</strong> 每个终结符$\\to$终结符，满足前者偏序后者 ($\\leq$)</li>\n<li><strong>对应语言：</strong> 上下文有关语言 CSL</li>\n<li><strong>对应自动机:</strong> 线性有界自动机 LBA</li>\n<li><strong>形式：</strong> $\\forall \\alpha\\to\\beta\\in P$ , 满足 $|\\alpha|\\leq |\\beta|$ 并且 $\\alpha,\\beta\\in(V \\cup T)^{*}$ 且 $\\alpha\\ne\\epsilon$</li>\n</ul>\n<p><strong>3. 上下文无关文法 CFG (2型文法)</strong></p>\n<ul>\n<li><strong>特点：</strong> 都有变元推出变元或终结符或者变元与终结符的连接</li>\n<li><strong>对应语言：</strong> 上下文无关语言 CFL</li>\n<li><strong>对应自动机：</strong> 下推自动机 PDA</li>\n<li><strong>形式：</strong> 对所有P中生成式都有，$A\\to\\beta \\quad \\beta\\in(V \\cup T)^{*},\\ A \\in V$</li>\n</ul>\n<p><strong>4. 正规文法 RG (3型文法)</strong></p>\n<ul>\n<li><strong>特点 ：</strong> 变元推出终结符或推出终结符+变元</li>\n<li><strong>对应语言：</strong> 正规语言 RL</li>\n<li><strong>对应自动机：</strong> 有穷自动机 DFA</li>\n<li><strong>形式：</strong> 对所有P中生成式都有，$A\\to a\\ 或\\ A\\to aB \\quad a\\in T \\cup {\\epsilon},\\ A,B \\in V$</li>\n</ul>\n<h3 id=\"2-4-文法等价\"><a href=\"#2-4-文法等价\" class=\"headerlink\" title=\"2.4 文法等价\"></a>2.4 文法等价</h3><p>对于两个文法 $G<em>{1}=(V</em>{1},\\ T<em>1,\\ P_1,\\ S_1)$ 与 $G</em>{2}=(V_{2},\\ T_2,\\ P_2,\\ S_2)$，若$L(G_1)=L(G_2)$，则文法等价</p>\n<h3 id=\"2-5-1°型文法\"><a href=\"#2-5-1°型文法\" class=\"headerlink\" title=\"2.5 1°型文法\"></a>2.5 1°型文法</h3><ul>\n<li><strong>特点：</strong> 看形式</li>\n<li><strong>形式：</strong> 对文法 $G=(V,\\ T,\\ P,\\ S)$，若P中每个生成式都有 $\\alpha_1 A \\alpha_2 \\to \\alpha_1 \\beta \\alpha_2$形式，$A \\in V, \\ \\alpha_1,\\alpha_2\\in(V \\cup T)^{*}$, $\\beta \\in {(V \\cup T)}^{+}$ </li>\n</ul>\n<h4 id=\"1、-1型文法和1°型文法转换\"><a href=\"#1、-1型文法和1°型文法转换\" class=\"headerlink\" title=\"1、 1型文法和1°型文法转换\"></a>1、 1型文法和1°型文法转换</h4><ul>\n<li><p>定理：对于任何1型文法G，一定存在一个 $1^{°}$ 型文法G’,使得L(G)=L(G’) 反之亦然。</p>\n</li>\n<li><p>$\\Rightarrow$<br>对于任何生成式 $\\alpha_1 A \\alpha_2 \\to \\alpha_1 \\beta \\alpha_2$ ,恒有 $|\\alpha_1 A \\alpha_2| \\leq |\\alpha_1 \\beta \\alpha_2|$<br>即 $1^{°}$ 型文法一定是1型文法</p>\n</li>\n<li><p>$\\Leftarrow$ </p>\n</li>\n<li><p>第一步：将G变为G’’</p>\n<ul>\n<li>这一步构造出生成式只有两种形式的G’’</li>\n<li>其中 $V^{‘’}=V \\cup M, M={[a] | a\\in T}$</li>\n<li>$P^{‘’}=\\overline{P} \\cup { [a] \\to a | a \\in T }$</li>\n</ul>\n</li>\n<li><p>第二步：G’’ 中生成式形式分类讨论</p>\n<ul>\n<li>（1） $A\\to\\beta$ (A∈V，或为新引入变元[a])，其已经是1°文法</li>\n<li>（2）$A_1A_2…A_n\\to B_1B_2…B_n,\\quad (n\\ge 2,\\ m\\ge n)$ <ul>\n<li>解决方法：引入一组新变元用于过渡</li>\n<li><ol>\n<li>$A_1A_2…A_n \\to C_1A_2…A_n$ </li>\n</ol>\n</li>\n<li><ol>\n<li>$C_1A_2…A_n \\to C_1C_2…A_n$ </li>\n</ol>\n</li>\n<li><ol>\n<li>$C<em>1C_2…C</em>{n-1}A_n \\to C_1C_2…C_n$ </li>\n</ol>\n</li>\n<li><ol>\n<li>$C_1C_2…C_n \\to B_1C_2…C_n$ </li>\n</ol>\n</li>\n<li><ol>\n<li>$B_1C_2…C_n \\to B_1B_2…C_n$ </li>\n</ol>\n</li>\n<li><ol>\n<li>$B<em>1B_2…B</em>{n-1}C_n \\to B_1B_2…B_n$</li>\n</ol>\n</li>\n<li>完成 $A_1A_2…A_n\\to B_1B_2…B_n$</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"2-6-上下文在文法中的体现\"><a href=\"#2-6-上下文在文法中的体现\" class=\"headerlink\" title=\"2.6 上下文在文法中的体现\"></a>2.6 上下文在文法中的体现</h3><h4 id=\"上下文有关文法（1型文法）的上下文\"><a href=\"#上下文有关文法（1型文法）的上下文\" class=\"headerlink\" title=\"上下文有关文法（1型文法）的上下文\"></a>上下文有关文法（1型文法）的上下文</h4><ul>\n<li>可用1°型文法解释，$\\alpha_1 A \\alpha_2 \\to \\alpha_1 \\beta \\alpha_2$，其中$\\alpha_1\\ 和\\ \\alpha_2$ 是A的上下文，在该上下文语境中A可替换为β</li>\n<li>在另外上下文语境中可替换为别的字符串，例如另有生成式 $\\alpha<em>{1’} A \\alpha</em>{2’} \\to \\alpha<em>{1’} \\gamma \\alpha</em>{2’}$ </li>\n</ul>\n<h4 id=\"上下文无关文法（2型文法）的上下文\"><a href=\"#上下文无关文法（2型文法）的上下文\" class=\"headerlink\" title=\"上下文无关文法（2型文法）的上下文\"></a>上下文无关文法（2型文法）的上下文</h4><ul>\n<li>$A\\to \\beta$ 变元A不管出现在任何地方都可替换为β，与上下文无关</li>\n</ul>\n<h3 id=\"2-7-语法分析树\"><a href=\"#2-7-语法分析树\" class=\"headerlink\" title=\"2.7 语法分析树\"></a>2.7 语法分析树</h3><ul>\n<li>定义：//TODO</li>\n</ul>\n<h4 id=\"边缘\"><a href=\"#边缘\" class=\"headerlink\" title=\"边缘\"></a>边缘</h4><ul>\n<li><p>对于派生树，其叶节点标记从左到右收集起来的字符串，称为该派生树的边缘</p>\n</li>\n<li><p><strong>相关定理：</strong> G为上下文无关文法，那么S可以派生出α当且仅当在G中存在一颗边缘为α的派生树<br>证明: //TODO</p>\n</li>\n</ul>\n<h4 id=\"多义和固有多义\"><a href=\"#多义和固有多义\" class=\"headerlink\" title=\"多义和固有多义\"></a>多义和固有多义</h4><p>不重要 TODO</p>\n<hr>\n<h2 id=\"第三章-有穷自动机和正规表达式\"><a href=\"#第三章-有穷自动机和正规表达式\" class=\"headerlink\" title=\"第三章 有穷自动机和正规表达式\"></a>第三章 有穷自动机和正规表达式</h2><p>重点</p>\n<ul>\n<li>掌握⼏类⾃动机的特点（FM, NFM, 有空动作的FM），⼏种FM之间如何进⾏变换（等价性），例：如何进⾏ 空动作的消除（空闭包的转换） </li>\n<li>掌握正则表达式和正规集，正规集和有穷⾃动机的关系（实际上在第四章） </li>\n<li>了解摩尔机和米里机的定义和功能（⾮重点）</li>\n</ul>\n<h3 id=\"3-1-确定有穷自动机-DFA\"><a href=\"#3-1-确定有穷自动机-DFA\" class=\"headerlink\" title=\"3.1 确定有穷自动机 DFA\"></a>3.1 确定有穷自动机 DFA</h3><h4 id=\"1-定义\"><a href=\"#1-定义\" class=\"headerlink\" title=\"1. 定义\"></a>1. 定义</h4><ul>\n<li>有穷自动机（FA or DFA）是一个五元组 $M=(Q,\\ \\Sigma, \\delta,\\ q_0, F)$<ul>\n<li><ol>\n<li>Q是有穷状态集</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\Sigma$ 是有穷的输入字符表</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\delta$ 是转移函数，将 $Q\\times \\Sigma$ 映射到Q</li>\n</ol>\n</li>\n<li><ol>\n<li>$q_0\\in Q$ 是初始状态</li>\n</ol>\n</li>\n<li><ol>\n<li>$F\\subset Q 是终结状态$</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"2-扩充转移函数\"><a href=\"#2-扩充转移函数\" class=\"headerlink\" title=\"2.扩充转移函数\"></a>2.扩充转移函数</h4><p>对于 FA $M=(Q,\\ \\Sigma, \\delta,\\ q_0, F)$ 其扩充转移函数是 $\\hat\\delta$ 是$Q\\times\\Sigma^*$ 到 Q 的映射</p>\n<ul>\n<li><ol>\n<li>$\\hat{\\delta}(q,\\epsilon) = q$ </li>\n</ol>\n</li>\n<li><ol>\n<li>$\\hat\\delta(q,wa)=\\delta(\\hat\\delta(q,w),a)$ </li>\n</ol>\n</li>\n<li><p>递归定义<br>接受一个输入，然后进行状态转移，再接受下一个。输入一个串得到最后状态。</p>\n</li>\n</ul>\n<h4 id=\"3-有穷自动机接受语言\"><a href=\"#3-有穷自动机接受语言\" class=\"headerlink\" title=\"3.有穷自动机接受语言\"></a>3.有穷自动机接受语言</h4><p>$L(M)={x| \\delta(q_0,x)\\in F}$<br>若 $\\delta(q_0,x)=p\\in F$ ，则称字符串x，被M接受，意义上来理解，就是输入x，M从q0转移到终结状态F</p>\n<h3 id=\"3-2-非确定有穷自动机-NFA\"><a href=\"#3-2-非确定有穷自动机-NFA\" class=\"headerlink\" title=\"3.2 非确定有穷自动机 NFA\"></a>3.2 非确定有穷自动机 NFA</h3><h4 id=\"1-定义-1\"><a href=\"#1-定义-1\" class=\"headerlink\" title=\"1. 定义\"></a>1. 定义</h4><ul>\n<li>非确定的有穷自动机（NFA）五元组 $G=(Q,\\Sigma,\\delta,q_0,F)$<ul>\n<li><ol>\n<li>Q是有穷状态集</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\Sigma$ 是有穷输入字符表</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\delta$ 是非确定的状态转移函数，$Q\\times \\Sigma$到$2^Q$ 上的映射</li>\n</ol>\n</li>\n<li><ol>\n<li>$q_0\\in Q$ 是初始状态</li>\n</ol>\n</li>\n<li><ol>\n<li>$F \\subset Q$ 是终结状态集</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"2-转移函数一般形式：\"><a href=\"#2-转移函数一般形式：\" class=\"headerlink\" title=\"2. 转移函数一般形式：\"></a>2. 转移函数一般形式：</h4><p>$\\delta(q,a)={p_1,…..,p_k} \\quad p_i\\in Q$ 或者 $\\delta(q,a)=\\emptyset$</p>\n<h4 id=\"3-扩充转移函数\"><a href=\"#3-扩充转移函数\" class=\"headerlink\" title=\"3. 扩充转移函数\"></a>3. 扩充转移函数</h4><p>类似有穷自动机定义，输入一个串，对每个字符进行状态转移，最后得出的最终状态<strong>集合</strong></p>\n<h4 id=\"4-接受条件\"><a href=\"#4-接受条件\" class=\"headerlink\" title=\"4. 接受条件\"></a>4. 接受条件</h4><p>如果 $\\delta(q_0,\\ x)\\cap F$ 非空，则称字符串 $x$ 被 $M$ 接受</p>\n<h3 id=\"3-3-NFA与DFA的等价性\"><a href=\"#3-3-NFA与DFA的等价性\" class=\"headerlink\" title=\"3.3 NFA与DFA的等价性\"></a>3.3 NFA与DFA的等价性</h3><ul>\n<li>当给定某类中的一个有穷自动机，一定存在另一类中的一个有穷自动机，两者接受同样集合，则称二者等价。</li>\n</ul>\n<h4 id=\"1-NFA与DFA等价\"><a href=\"#1-NFA与DFA等价\" class=\"headerlink\" title=\"1. NFA与DFA等价\"></a>1. NFA与DFA等价</h4><ul>\n<li>证明： 构造法 构造 DFA，其定义为<ul>\n<li>对于Q’,其将NFA中Q的每一个子集作为Q’中的一个状态，若子集为 ${q_1,q_2,..,q_n}$ ，则Q’中状态记为 $[q_1,q_2,..,q_n]$ </li>\n<li>对于 $\\delta^{‘}$ ，定义为<script type=\"math/tex\">\\delta^{'}([q_1,q_2,..,q_n],a) = p_1,p_2,..,p_n \\\\ iff \\\\ \\delta(\\{q_1,q_2,..,q_n\\},a) = p_1,p_2,..,p_n</script> </li>\n</ul>\n</li>\n</ul>\n<p>进一步证明 TODO</p>\n<h4 id=\"2-NFA至DFA的转换\"><a href=\"#2-NFA至DFA的转换\" class=\"headerlink\" title=\"2. NFA至DFA的转换\"></a>2. NFA至DFA的转换</h4><p>构造方法，从NFA出发，并不需要直接一步写出Q的幂集，而是看NFA中存在哪些状态。<br>例题3.4</p>\n<h4 id=\"3-具有-epsilon-动作的有穷自动机\"><a href=\"#3-具有-epsilon-动作的有穷自动机\" class=\"headerlink\" title=\"3. 具有$\\epsilon$动作的有穷自动机\"></a>3. 具有$\\epsilon$动作的有穷自动机</h4><p>在不接受输入符号，输入为$\\epsilon$ 时能做转移动作<br>即转移函数 $\\delta$ 扩充至$Q\\times (\\Sigma \\cup {\\epsilon})$ 到 $2^Q$ 的映射</p>\n<ul>\n<li><p>$\\epsilon -CLOSURE(q)$<br>直白的说，就是如果NFA只接受空动作能够到达的状态集合</p>\n</li>\n<li><p>定义</p>\n<ul>\n<li><ol>\n<li>$q\\in \\epsilon -CLOSURE(q)$</li>\n</ol>\n</li>\n<li><ol>\n<li>递归，若$p\\in \\epsilon -CLOSURE(q)$，则$\\delta(q, \\epsilon)\\in \\epsilon -CLOSURE(q)$</li>\n</ol>\n</li>\n<li>规定：$\\epsilon -CLOSURE(P) = \\mathop{\\cup}\\limits_{q\\in P}\\epsilon -CLOSURE(q)$</li>\n</ul>\n</li>\n<li><p>扩充函数<br>非简单扩充，就是说 $\\hat\\delta(q,a) \\neq \\delta(q,a)$，因为空输入也可以转移状态，其他差不多</p>\n</li>\n<li><p>接受语言<br>$L(M)={w|\\hat\\delta(q_0,w) \\cap F }$ 非空<br><em>增加空动作没有增加表达能力，即有空动作和没有空动作的NFA等价</em></p>\n</li>\n<li><p>空动作NFA与NFA等价<br>构造法，对具有空动作的NFA M构造 $M’=(Q’,\\Sigma^{‘},\\delta^{‘},q_0,F^{‘})$，</p>\n</li>\n</ul>\n<p>$\\hat \\delta(q,a)$ 即 $\\delta(\\epsilon -CLOSURE(q), a)$</p>\n<ul>\n<li>$\\delta^{‘}(q,a) = \\hat\\delta(q,a)$</li>\n<li><script type=\"math/tex; mode=display\">F^{'}=\\left\\{\n  \\begin{array}{rcl}\n      F\\cup \\{q_0\\} && {如果\\epsilon-CLOSURE(q_0)\\cap F非空}\\\\\n      F && {否则}\n  \\end{array} \\right.</script>证明对 |x| 进行归纳 TODO</li>\n</ul>\n<h3 id=\"3-4-正规表达式和正规集\"><a href=\"#3-4-正规表达式和正规集\" class=\"headerlink\" title=\"3.4 正规表达式和正规集\"></a>3.4 正规表达式和正规集</h3><ul>\n<li>正规表达式递归定义<ul>\n<li><ol>\n<li>$\\phi$ 是一个正规表达式，代表空集</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\epsilon$ 是一个正规表达式，代表集合 ${\\epsilon}$ </li>\n</ol>\n</li>\n<li><ol>\n<li>对于 $\\Sigma$ 中每个符号a，a是正规表达式，代表集合{a}</li>\n</ol>\n</li>\n<li><ol>\n<li>如果r和s是正规表达式，分别表示集合R和S，则(r+s),(rs)和(r<em>)是正规表达式，分别表示 $R \\cup S$、$RS$ 和 $R^</em>$ </li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<p>正规表达式代表的集合称为正规集</p>\n<p><img src=\"/uploads/upload_e70fbfc8866d389b084873dd20ba2e72.png\" style=\"height: 300px;\"></p>\n<ul>\n<li><p>运算优先级<br>$* &gt; 连接 &gt; +$</p>\n</li>\n<li><p>对应自动机<br>有穷自动机 DFA<br>有穷自动机所能接受的集合类和正规表达式所能表示的集合类统称为正规集类</p>\n</li>\n<li><p>定理3.3 r为正规表达式，则有一个具有空动作的NFA接受L(r)<br>归纳法证明，归纳r的构造次数</p>\n</li>\n<li>基础：r构造次数为0，即r是 $\\epsilon$ 、$\\phi$ 、$\\Sigma$ 中某个元素a</li>\n<li><p>归纳</p>\n<ul>\n<li>r = r1 + r2<br>归纳假设有 M1 接受 r1, M2 接受 r2<br>则构造一个M将两个M1,M2并起即可，形式说明TODO</li>\n<li>r = r1r2<br>归纳假设有 M1 接受 r1, M2 接受 r2<br>则构造一个M先过M1再过M2即可，形式说明TODO</li>\n<li>r = r1*<br>归纳假设有 M1 接受 r1,<br>则扩展一下M1，让其终结状态可以回到开始状态重复判断即可，形式说明TODO</li>\n</ul>\n</li>\n<li><p>定理3.4 如果L被DFA接受，则L可用正规表达式表示<br>对各状态进行编号，记 $R<em>{ij}^k={x\\mid \\delta(q_i,x)=q_j，中间不经过编号大于k的状态 }$ ，有递推式 $R</em>{ij}^k=R<em>{ik}^{k-1}(R</em>{kk}^{k-1})^*R<em>{kj}^{k-1}\\cup R</em>{ij}^{k-1}$  ，然后归纳证明 $R_{ij}^k$ 可用正规表达式表示</p>\n</li>\n</ul>\n<h3 id=\"3-5-具有输出的有穷自动机\"><a href=\"#3-5-具有输出的有穷自动机\" class=\"headerlink\" title=\"3.5 具有输出的有穷自动机\"></a>3.5 具有输出的有穷自动机</h3><ol>\n<li>摩尔机</li>\n<li>米里机</li>\n</ol>\n<p>非重点</p>\n<hr>\n<h2 id=\"第四章-正规文法与正规集的性质-重要\"><a href=\"#第四章-正规文法与正规集的性质-重要\" class=\"headerlink\" title=\"第四章 正规文法与正规集的性质(重要)\"></a>第四章 正规文法与正规集的性质(重要)</h2><ul>\n<li>缩胀定理（重点），反证法证明 </li>\n<li>极⼩化的处理，掌握极⼩化的算法（过程）（明示了快背），如何优化有穷⾃动机 </li>\n<li>⻨⻄尔-尼诺德定理，需要掌握 </li>\n</ul>\n<h3 id=\"4-1-正规文法与有穷自动机的关系\"><a href=\"#4-1-正规文法与有穷自动机的关系\" class=\"headerlink\" title=\"4.1 正规文法与有穷自动机的关系\"></a>4.1 正规文法与有穷自动机的关系</h3><ul>\n<li><strong>Th4.1</strong><br>— 设 $L$ 被某个正规文法 $G$ 产生，则 $L$ 可被某个有穷自动机接受</li>\n</ul>\n<ul>\n<li><strong>Th4.2</strong><br>— 设 $L$ 被某个DFA $M$ 接受， 则 $L$ 可被某个正规文法产生</li>\n</ul>\n<p>构造方法：</p>\n<ul>\n<li>$A\\to aB$ 对应 $\\delta(A,a)=B$</li>\n<li>$A\\to a$ 对应 $\\delta(A,a)=f\\in F$</li>\n</ul>\n<h3 id=\"4-2-正规集的缩胀定理\"><a href=\"#4-2-正规集的缩胀定理\" class=\"headerlink\" title=\"4.2 正规集的缩胀定理\"></a>4.2 正规集的缩胀定理</h3><ol>\n<li><p><strong>有穷自动机表达能力有限</strong></p>\n</li>\n<li><p><strong>Th4.3 正规集的缩胀定理(pumping Lemma)：存在整数 $k \\geq 0$ ，对于任意串 $x, y, z$ 这里 $xyz \\in A$， 只要$|y| \\ge k$ ，就可以将 $y$ 写成 $y=uvw, \\quad v \\ne \\sigma$ ，并且对于任何 $i \\ge 0$，都有 $xuv^{i}wz \\in A$</strong></p>\n</li>\n</ol>\n<ul>\n<li><p>证明：定理的直观含义为：如果 $A$ 是正规集，那么当它的元素含有<strong>足够长</strong>的子串 $y$ 时（x与y的长短不重要）， $y$ 就一定包含一个非空的子串 $v$ （$u, w$ 的长短不重要），这个子串 $v$ 可以“膨胀”任意多次 （$i &gt; 0$），或者被“删除” （$i = 0$），而 $xuv^{i}wz$ 仍然属于 $A$</p>\n</li>\n<li><p>设 $k$ 是接受正规集 $A$ 的 $DFA$ 状态数，因为 $y$ 的长度大于或等于k， 则 $DFA$ 在扫视 $y$ 的过程中，必然出现重复的状态，串 $v$ 就是该状态相邻的两次出现过程中扫视过的子串。</p>\n</li>\n</ul>\n<script type=\"math/tex; mode=display\">\n\\sigma(q_{1}, u)=p, \\sigma(p, v)=p, \\sigma(p, w)=q_2</script><p>其余的推理过程与例2.10的分析相同</p>\n<ul>\n<li><em>正规集的缩胀定理经常用来指明某些集合不是正规集，通常就是反证法，大家都懂的。</em></li>\n</ul>\n<h3 id=\"4-3-正规集的封闭性质与判定算法\"><a href=\"#4-3-正规集的封闭性质与判定算法\" class=\"headerlink\" title=\"4.3 正规集的封闭性质与判定算法\"></a>4.3 正规集的封闭性质与判定算法</h3><ul>\n<li>在并、连接和闭包运算下是封闭的</li>\n<li>在补运算下封闭，即若 $L$ 是正规集，且 $L\\subseteq\\Sigma^{<em>}$ ， 则 $\\Sigma^{</em>}-L$ 也是正规的</li>\n<li>在交运算下封闭</li>\n<li>在商运算下封闭（暂且理解：两个正规集做商运算，其结果必然是正规集）</li>\n</ul>\n<ul>\n<li><em>Th4.9</em><br>具有n个状态的有穷自动机具有如下性质：<ul>\n<li>1)它接受的集合非空，当且仅当它接受一个长度小于n的字符串 </li>\n<li>2）它接受的集合是无穷的，当且仅当它接受一个长度为1的字符串，这里 $n \\leq l &lt; 2n$</li>\n</ul>\n</li>\n<li><em>两个有穷自动机是否等价是可判定的</em></li>\n</ul>\n<h3 id=\"4-4-有穷自动机的最小化\"><a href=\"#4-4-有穷自动机的最小化\" class=\"headerlink\" title=\"4.4 有穷自动机的最小化\"></a>4.4 有穷自动机的最小化</h3><p><strong>一个减少状态数的思路：给定 $DFA \\ =(Q, \\Sigma, \\delta, q_{0}, F)$，根据等价关系构造出一个 $DFA M/ \\equiv$，该 $DFA$称为 $M$的商自动机</strong></p>\n<ul>\n<li><strong>判断两个状态等价：</strong> 对于 $p, q \\in Q$， 若对于每个 $x \\in \\Sigma^{*}, \\quad \\delta(p, x) \\in F$当且仅当 $\\delta(q,x) \\in F$， 就称 $p, q$ 等价，记作 $p \\equiv q$</li>\n</ul>\n<p><strong>极小化算法过程：</strong><br>— <em>在 $DFA$ 的状态集上确定所有的状态对是否等价</em></p>\n<ol>\n<li>对所有状态对 ${p, q}  (p, q \\in Q)$画一张表，开始时中每个格子均为空白（未做标记）</li>\n<li>对一切 $p \\in F, q \\notin F$ 的 ${p, q}$，在相应格子上做标记（例如画一个X）</li>\n<li>重复下述步骤，直到表中内容不再改变为止：如果对于某个 $a \\in \\Sigma$， 存在一个未被标记的状态对 ${p, q}$，使得 ${\\delta(p,a),\\delta(q,a)}$已做标记，则将 ${p, q}$ 做标记</li>\n<li>完成1，2，3之后，所有未被标记的状态对都是等价的，即 $p \\equiv q$</li>\n</ol>\n<h3 id=\"Myhill-Nerode-关系\"><a href=\"#Myhill-Nerode-关系\" class=\"headerlink\" title=\"Myhill-Nerode 关系\"></a>Myhill-Nerode 关系</h3><p><strong>判定方式</strong></p>\n<ul>\n<li><p>对某个集合$A \\subset \\Sigma^<em>,\\quad$ R为$\\Sigma^</em>$上的等价关系。若R满足</p>\n<ul>\n<li><ol>\n<li>是右不变的</li>\n</ol>\n</li>\n<li><ol>\n<li>细分A</li>\n</ol>\n</li>\n<li><ol>\n<li>具有有穷指数</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><p>则称R为A的 Myhill-Nerode 关系</p>\n</li>\n</ul>\n<h3 id=\"Myhill-Nerode-定理\"><a href=\"#Myhill-Nerode-定理\" class=\"headerlink\" title=\"Myhill-Nerode 定理\"></a>Myhill-Nerode 定理</h3><ul>\n<li>A是一个正规集</li>\n<li>$\\Sigma^*上存在关于A的MN关系$</li>\n<li>$R_A$ 具有有穷指数</li>\n</ul>\n<hr>\n<h2 id=\"第五章-上下文无关文法与下推自动机\"><a href=\"#第五章-上下文无关文法与下推自动机\" class=\"headerlink\" title=\"第五章 上下文无关文法与下推自动机\"></a>第五章 上下文无关文法与下推自动机</h2><p>重点:</p>\n<ul>\n<li>了解化简（作业题） </li>\n<li>⼀定要会两种范式（乔姆斯基范式&amp;葛雷巴赫范式） </li>\n<li>构造下推⾃动机（作业题）</li>\n</ul>\n<h3 id=\"5-1-上下文无关文法的化简\"><a href=\"#5-1-上下文无关文法的化简\" class=\"headerlink\" title=\"5.1 上下文无关文法的化简\"></a>5.1 上下文无关文法的化简</h3><p>检验文法$G=(V, T, P, S)$中是否有无用符号 （变元或终结符），若有，则将其消除。</p>\n<h4 id=\"无用符号\"><a href=\"#无用符号\" class=\"headerlink\" title=\"无用符号\"></a>无用符号</h4><ul>\n<li>$X \\in V \\cup T$ 但X不出现在任何由S派生出的字符串中。</li>\n<li><p>$X \\in V$ 但X不能派生出任何终结符号串</p>\n</li>\n<li><p>Th5.1 不带无用符号的CFG可生成所有非空CFL</p>\n<p>  化简思路</p>\n<ul>\n<li><ol>\n<li>找到无用符号（一类二类）</li>\n</ol>\n</li>\n<li><ol>\n<li>删除无用符号</li>\n</ol>\n</li>\n<li><ol>\n<li>返回1继续检查，直到不产生无用符号为止</li>\n</ol>\n<p>PPT思路</p>\n</li>\n<li><ol>\n<li>首先删除二类无用符号 </li>\n</ol>\n</li>\n<li><ol>\n<li>接着删除一类无用符号</li>\n</ol>\n</li>\n<li><ol>\n<li>返回1检查，直到不产生无用符号</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"epsilon-生成式\"><a href=\"#epsilon-生成式\" class=\"headerlink\" title=\"$\\epsilon$ -生成式\"></a>$\\epsilon$ -生成式</h4><p>形如 $A \\to \\epsilon$ 的生成式，如果 $\\epsilon \\in L(G)$ 那么不能删，其余都可以删除。</p>\n<ul>\n<li><p>可为零<br>如果在CFG中，A属于变元集合，如果有A派生出$\\epsilon$则称A为可为零的。</p>\n</li>\n<li><p>Th5.3 可为零的可判定性<br>对于CFG中任意变元是否可为零是可判定的<br>判定思路：</p>\n</li>\n<li><ol>\n<li>对$A \\to \\epsilon$ 即trivial的本来就可为零的，将A加入Z</li>\n</ol>\n</li>\n<li><ol>\n<li>对于一切生成式 B，有$B \\to \\alpha$ 如果 $\\alpha \\in V^+$在中所有变元均在Z中，将B加入Z</li>\n</ol>\n</li>\n<li><ol>\n<li>重复1，直至没有元素加入Z为止</li>\n</ol>\n</li>\n</ul>\n<p>Z 中元素均为可为零的元素</p>\n<ul>\n<li>Th5.2 不带无用符号且没有$\\epsilon$-生成式的CFG可以生成所有不包含空串的CFL<br><strong>不会证 ；）</strong></li>\n</ul>\n<h4 id=\"单一生成式\"><a href=\"#单一生成式\" class=\"headerlink\" title=\"单一生成式\"></a>单一生成式</h4><p>形如 $A \\to B$ （A、B皆为变元）的生成式</p>\n<h4 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h4><p>上面说的三个都可以消掉</p>\n<h3 id=\"5-2-上下文无关文法的范式\"><a href=\"#5-2-上下文无关文法的范式\" class=\"headerlink\" title=\"5.2 上下文无关文法的范式\"></a>5.2 上下文无关文法的范式</h3><h4 id=\"乔姆斯基范式-Chomsky-（CNF定理）\"><a href=\"#乔姆斯基范式-Chomsky-（CNF定理）\" class=\"headerlink\" title=\"乔姆斯基范式 Chomsky （CNF定理）\"></a>乔姆斯基范式 Chomsky （CNF定理）</h4><p>任何不包含$\\epsilon$的CFL，都可由生成式仅为 $A \\to BC$ 或 $A \\to a$ （A，B，C为变元，a为终结符）形式的文法产生<br>（化为乔姆斯基范式，例题5.3）<br>a</p>\n<h4 id=\"格雷巴赫范式-Greibach-GNF定理\"><a href=\"#格雷巴赫范式-Greibach-GNF定理\" class=\"headerlink\" title=\"格雷巴赫范式 Greibach (GNF定理)\"></a>格雷巴赫范式 Greibach (GNF定理)</h4><p>任何不包含$\\epsilon$的CFL，都可由生成式仅为$A \\to a\\alpha$ (a为终结符,$\\alpha$ 为变元串，包含空串）形式的文法产生</p>\n<p>//TODO</p>\n<h3 id=\"5-3-下推自动机\"><a href=\"#5-3-下推自动机\" class=\"headerlink\" title=\"5.3 下推自动机\"></a>5.3 下推自动机</h3><p>下推自动机（简称PDA）是一个七元组 $M=(Q,\\Sigma,\\Gamma, \\delta, q_0, Z_0, F)$</p>\n<ul>\n<li>Q是有穷状态集</li>\n<li>$\\Sigma$是有穷的输入字母表</li>\n<li>$\\Gamma$是有穷的栈符号表</li>\n<li>$\\delta$是转移函数，将$Q \\times (\\Sigma \\cup {epsilon} \\times \\Gamma)$ 映射到$(Q\\times \\Gamma^*)$ 的有穷子集</li>\n<li>$q_0 \\in Q$ 是初始状态</li>\n<li>$Z_0 \\in \\Gamma$ 是栈底符号</li>\n<li>$F \\subset Q$ 是终结状态集</li>\n</ul>\n<h4 id=\"转移函数\"><a href=\"#转移函数\" class=\"headerlink\" title=\"转移函数\"></a>转移函数</h4><p>三元组 $\\delta(q,a,Z) = {(p_1,\\gamma_1), (p_2, \\gamma_2),…,(p_m, \\gamma_m)}$ 其中 q, a 一个状态一个输入字符，Z为栈顶符号</p>\n<p>状态由 $q \\to p$，栈顶符号由 $Z \\to \\gamma$<br>转移动作不确定</p>\n<ul>\n<li>函数值有m种选择 （m可以为0）</li>\n<li>读头不动也可以有函数值</li>\n</ul>\n<h4 id=\"瞬时描述\"><a href=\"#瞬时描述\" class=\"headerlink\" title=\"瞬时描述\"></a>瞬时描述</h4><p>$(q<em>0,w,Z_0) \\mathop{\\vdash}\\limits</em>{M}^*\\ (p, \\epsilon, \\gamma)$ 表示从状态 $(p, \\gamma) \\in \\delta(q_o, w, Z_0)$，上一个字符为w，下一个字符为 $\\epsilon$</p>\n<p>即由一个瞬时描述 ID 转移到下一个 ID</p>\n<h4 id=\"按终结方式接受\"><a href=\"#按终结方式接受\" class=\"headerlink\" title=\"按终结方式接受\"></a>按终结方式接受</h4><p>若M是一个PDA，集合$L(M)={w|(q<em>0,w,Z_0) \\mathop{\\vdash}\\limits</em>{M}^*\\ (p, \\epsilon, \\gamma)}$<br>则称M按终结状态方式接受的语言</p>\n<ul>\n<li>接受状态<br>还是由初始状态到接受状态，和栈中符号没什么关系，栈符号只影响状态转移<br><em>不过如果输入串未读完栈就变空，无法进行状态转移，则w不可能被接受。</em></li>\n</ul>\n<h4 id=\"按栈空方式接受\"><a href=\"#按栈空方式接受\" class=\"headerlink\" title=\"按栈空方式接受\"></a>按栈空方式接受</h4><ul>\n<li>接受状态<br>顾名思义，读完之后栈空了就接受了，终结状态则不影响是否接受。</li>\n</ul>\n<p>构造PDA接受$0^n1^n$，例题5.5</p>\n<ul>\n<li>例题 5.6、5.7</li>\n</ul>\n<h3 id=\"5-4-下推自动机与上下文无关文法的关系\"><a href=\"#5-4-下推自动机与上下文无关文法的关系\" class=\"headerlink\" title=\"5.4 下推自动机与上下文无关文法的关系\"></a>5.4 下推自动机与上下文无关文法的关系</h3><ul>\n<li>下推自动机接受的语言类是上下文无关文法 CFL (2型文法)</li>\n</ul>\n<hr>\n<h2 id=\"第六章-上下文无关语言的性质\"><a href=\"#第六章-上下文无关语言的性质\" class=\"headerlink\" title=\"第六章 上下文无关语言的性质\"></a>第六章 上下文无关语言的性质</h2><p>重点</p>\n<ul>\n<li>缩胀定理/ogden定理（尤其考察后者）</li>\n<li>考察给⼀个语⾔判断是否是上下⽂⽆关语⾔ 封闭属性 </li>\n<li>成员资格判定问题（PPT）,CYK算法</li>\n</ul>\n<h3 id=\"6-1-CFL缩胀定理\"><a href=\"#6-1-CFL缩胀定理\" class=\"headerlink\" title=\"6.1 CFL缩胀定理\"></a>6.1 CFL缩胀定理</h3><p>回忆一下正规集缩胀定理<br>正规集中每个足够长的字符串，都包含一个短子串可扩张任意多次，所得字符串仍然属于该正规集</p>\n<ul>\n<li>CFL 缩胀定理<br>在CFL中，每个足够长的字符串，都包含两个相距不远的短子串，两个子串可以扩充任意多次，所得子串仍然属于CFL</li>\n</ul>\n<p><strong>形式描述：</strong><br>对于每个CFL，都存在正整数 $k \\ge 0$ 使得对每个$z \\in L$ 只要 $|z| \\ge k$ 就可将z划分为5个子串，<br>满足以下三个条件</p>\n<ol>\n<li>对任何的$i \\ge 0$ 都有$uv^iwx^iy \\in L$</li>\n<li>$|vx| \\ge 1$</li>\n<li>$|vwx| \\le k$</li>\n</ol>\n<p>（其中 k = $b^{|V| + 1}$，其中b是生成式右侧符号数的最大值）<br>看计算理论导引P77，写的很清楚</p>\n<h3 id=\"6-2-Ogden定理\"><a href=\"#6-2-Ogden定理\" class=\"headerlink\" title=\"6.2 Ogden定理\"></a>6.2 Ogden定理</h3><p><strong>形式描述：</strong><br>L为CFL，存在整数$k \\ge 0$，使得对每个$z \\in L$，并且在z中标出k个或多于k个特别符号，将z写成z=uvwxy，且满足</p>\n<ol>\n<li>v和x一起至少包含一个特别符号</li>\n<li>vwx之多包含k个特别符号<br>则对任何$i \\ge 0,\\ uv^iwx^iy \\in L$</li>\n</ol>\n<p>例题6.4 </p>\n<h3 id=\"6-3-CFL封闭性质\"><a href=\"#6-3-CFL封闭性质\" class=\"headerlink\" title=\"6.3 CFL封闭性质\"></a>6.3 CFL封闭性质</h3><p>回忆一下RL的封闭性质，RL在以下运算下封闭</p>\n<ul>\n<li>交并补</li>\n<li>连接</li>\n<li>闭包</li>\n<li>商</li>\n</ul>\n<p><strong>CFL在以下运算下封闭</strong></p>\n<ul>\n<li><p>并<br>对G1,G2，生成式的开始元S1，S2<br>构造 G3 $S \\to S1 | S2$</p>\n</li>\n<li><p>连接<br>对G1,G2，生成式的开始元S1，S2<br>构造 G3 $S \\to S1S2$</p>\n</li>\n<li><p>闭包<br>对G1,G2，生成式的开始元S1<br>构造 G3 $S \\to S1S|\\epsilon$</p>\n</li>\n</ul>\n<p><strong>注意 CFL 在 <em>交</em> $\\cap$ 和 <em>补</em> $\\hat{ }$ 运算下不封闭</strong></p>\n<ul>\n<li><p>交<br>$L1= {a^ib^ic^j|i \\ge 1, j \\ge 1}$, $L2= {a^ib^jc^j|i \\ge 1, j \\ge 1}$<br>两者是CFL<br>但其交集$L1 \\cap L2= {a^ib^ic^i|i \\ge 1}$ 不是CFL，可由Pumping LEmma 证得</p>\n</li>\n<li><p>补运算<br>交运算，可化为补+并的形式，若补运算封闭，则由于并运算封闭，可证得交运算封闭，推出矛盾。</p>\n</li>\n</ul>\n<h4 id=\"CFL和正规集的交是CFL\"><a href=\"#CFL和正规集的交是CFL\" class=\"headerlink\" title=\"CFL和正规集的交是CFL\"></a>CFL和正规集的交是CFL</h4><ul>\n<li>定理6.6 若L是CFL，R是正规集，则$L\\cap R$是CFL</li>\n</ul>\n<h3 id=\"6-4-CFL判定算法\"><a href=\"#6-4-CFL判定算法\" class=\"headerlink\" title=\"6.4 CFL判定算法\"></a>6.4 CFL判定算法</h3><h4 id=\"给出CFG-G-V-T-P-S-L-G-是否为空和是否有穷问题是可判定的\"><a href=\"#给出CFG-G-V-T-P-S-L-G-是否为空和是否有穷问题是可判定的\" class=\"headerlink\" title=\"给出CFG G=(V, T, P, S), L(G)是否为空和是否有穷问题是可判定的\"></a>给出CFG G=(V, T, P, S), L(G)是否为空和是否有穷问题是可判定的</h4><ul>\n<li>L(G) 是否为空<ul>\n<li>检验S是否能派生出终结符号串</li>\n<li>若能，则L(G)非空；不能则为空</li>\n</ul>\n</li>\n<li>L(G)是否有穷<ul>\n<li>对G的Chomsky范式，以变元为顶点画出有向图</li>\n<li>原问题 $\\Leftrightarrow$ 该有向图是否有回路</li>\n<li>即X的最长路径长度为l，则从X派生出的终结符号串长度不超过$2^l$ (归纳假设)</li>\n</ul>\n</li>\n</ul>\n<p>图论算法判定一个有向图是否有回路，所以L(G’)是否有穷，是可判定的</p>\n<h3 id=\"6-5-成员资格问题\"><a href=\"#6-5-成员资格问题\" class=\"headerlink\" title=\"6.5 成员资格问题\"></a>6.5 成员资格问题</h3><p><strong>给定一个CFG G和一个终结符串x，问x是否属于L(G)</strong><br>暴力算法思想，对于G的Greibach范式文法，从S生成式推出右侧的第一个终结变元和x串的第一个符号比较，如果对应就把右侧第二个变元的推出式拿出重复上述操作，直到接受或拒绝为止，时间复杂度$O(m^n)$</p>\n<h4 id=\"CYK算法\"><a href=\"#CYK算法\" class=\"headerlink\" title=\"CYK算法\"></a>CYK算法</h4><p>时间复杂度 $O({|x|}^3)$<br>倒着的树，看Vij表，懂的都懂<br>（区间DP）<br><img src=\"/uploads/upload_e2b3e93174f7cd571038ce381a21f95c.png\" alt></p>\n<hr>\n<h2 id=\"第七章-图灵机\"><a href=\"#第七章-图灵机\" class=\"headerlink\" title=\"第七章 图灵机\"></a>第七章 图灵机</h2><p>重点</p>\n<ul>\n<li>构造语⾔的图灵机（会考的稍微复杂）</li>\n<li>图灵机构造技术 其他类型的图灵机（多带的、⾮确定、双栈机） </li>\n<li>枚举器，正则次序，对偶产生器</li>\n</ul>\n<h3 id=\"7-1-图灵机基本模型\"><a href=\"#7-1-图灵机基本模型\" class=\"headerlink\" title=\"7.1 图灵机基本模型\"></a>7.1 图灵机基本模型</h3><p>确定单带图灵机是一个9元组 $M=(Q,\\Sigma,\\Gamma,\\vdash, \\diamond,\\delta,s,t,r)$</p>\n<ul>\n<li><ol>\n<li>Q有穷状态集</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\Sigma$有穷输入字母表</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\Gamma$有穷的带字母表</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\vdash$ 左端标记</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\diamond$ 空白符号</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\delta$ 转移函数</li>\n</ol>\n</li>\n<li><ol>\n<li>$s \\in Q$ 开始状态</li>\n</ol>\n</li>\n<li><ol>\n<li>$t \\in Q$ 接受状态</li>\n</ol>\n</li>\n<li><ol>\n<li>$r \\in Q$ 拒绝状态</li>\n</ol>\n</li>\n</ul>\n<p>L 表示读写头左移，R表示右移，对于左端标记，永远有$\\delta(p,\\vdash)=(q,\\vdash,R)$</p>\n<ul>\n<li><p>递归可枚举集<br>TM M接受的语言，称为递归可枚举集</p>\n</li>\n<li><p>递归集<br>被完全 TM M 接受的语言，称为递归集</p>\n</li>\n<li><p>完全TM<br>对一切输入均能停机（达到接受或拒绝状态）</p>\n</li>\n</ul>\n<p>例题做做做</p>\n<h3 id=\"7-2-图灵机构造技术\"><a href=\"#7-2-图灵机构造技术\" class=\"headerlink\" title=\"7.2 图灵机构造技术\"></a>7.2 图灵机构造技术</h3><h4 id=\"有限控制器中的存储\"><a href=\"#有限控制器中的存储\" class=\"headerlink\" title=\"有限控制器中的存储\"></a>有限控制器中的存储</h4><ul>\n<li>元组表示状态，将带上符号吸收到状态中</li>\n</ul>\n<h4 id=\"移动\"><a href=\"#移动\" class=\"headerlink\" title=\"移动\"></a>移动</h4><ul>\n<li>将带上符号不断吸收到状态中，不断写下，达到整体移动的目的</li>\n</ul>\n<h4 id=\"多道技术\"><a href=\"#多道技术\" class=\"headerlink\" title=\"多道技术\"></a>多道技术</h4><ul>\n<li>保存处理更复杂的数据，例如计算$n^2$</li>\n</ul>\n<h4 id=\"查讫符号\"><a href=\"#查讫符号\" class=\"headerlink\" title=\"查讫符号\"></a>查讫符号</h4><ul>\n<li>即给带上符号打标记，利用到多道技术</li>\n<li>常用于区分某个符号是否查过</li>\n<li>例7.7 构造一个识别 $l={wcw|w \\in {a,b}^+}$的 $TM$</li>\n</ul>\n<h4 id=\"子程序技术\"><a href=\"#子程序技术\" class=\"headerlink\" title=\"子程序技术\"></a>子程序技术</h4><ul>\n<li>懂的都懂，大概不考<br>构造TM M实现乘法运算</li>\n</ul>\n<h3 id=\"7-3-图灵机的变型\"><a href=\"#7-3-图灵机的变型\" class=\"headerlink\" title=\"7.3 图灵机的变型\"></a>7.3 图灵机的变型</h3><h4 id=\"双向无限带\"><a href=\"#双向无限带\" class=\"headerlink\" title=\"双向无限带\"></a>双向无限带</h4><ul>\n<li>将图灵机的单向无限延伸扩大到双向无限延伸<ul>\n<li>无左端标记$\\vdash$</li>\n<li>其余符号和功能均与单向无限带TM相同</li>\n</ul>\n</li>\n</ul>\n<p>并没增加其表达能力，和单带相同</p>\n<ul>\n<li>可以构造一个双带单向无限图灵机，识别能力与双向无限图灵机相同（定理7.1）</li>\n</ul>\n<h4 id=\"多带\"><a href=\"#多带\" class=\"headerlink\" title=\"多带\"></a>多带</h4><ul>\n<li>用一个控制器控制k条带，在每条带上有独立的读写头<br><strong>和多道技术的区别</strong><br>多道技术是一个控制器多个带，这个是多个控制器多个带。</li>\n<li>给一些证明带来许多方便</li>\n<li>并没增加其表达能力，和单带相同</li>\n</ul>\n<h4 id=\"非确定图灵机\"><a href=\"#非确定图灵机\" class=\"headerlink\" title=\"非确定图灵机\"></a>非确定图灵机</h4><p><strong>确定的图灵机 $\\delta$ 是单值函数，非确定性图灵机增加非确定性动作，并未改变其识别能力</strong></p>\n<ul>\n<li>可以证明确定型图灵机与非确定型图灵机的等价性<br>定理7.3 若L被一个非确定的TM $M_1$ 接受，则L也被某个确定的TM $M_2$ 接受。</li>\n</ul>\n<h4 id=\"双栈机\"><a href=\"#双栈机\" class=\"headerlink\" title=\"双栈机\"></a>双栈机</h4><p>其是特殊的三带图灵机<br>一个带用于输入，只读不写<br>另外两个用来模拟栈</p>\n<ul>\n<li>读头右移，可写任意符号 （进栈）</li>\n<li><p>读头左移，只能写空白符 （退栈）<br>读头指向为栈顶，左端标记右边那个为栈底</p>\n</li>\n<li><p>任意的单带图灵机能被双栈机给模拟<br>右移时，右栈弹栈，左栈压栈。反之类似</p>\n</li>\n</ul>\n<p><strong>下推自动机是单栈机，所以其能力比图灵机小， 即$PDA &lt; TM$</strong><br><strong>图灵机是下推自动机的扩充，能接受其不能接受的语言</strong></p>\n<h4 id=\"带字母最少的图灵机\"><a href=\"#带字母最少的图灵机\" class=\"headerlink\" title=\"带字母最少的图灵机\"></a>带字母最少的图灵机</h4><ul>\n<li>限制带字母表上只有 $0,\\ 1,\\ \\diamond$ 三个符号</li>\n<li>和任何TM等价</li>\n</ul>\n<h4 id=\"作为枚举器的图灵机\"><a href=\"#作为枚举器的图灵机\" class=\"headerlink\" title=\"作为枚举器的图灵机\"></a>作为枚举器的图灵机</h4><ul>\n<li>用一条带专门作为输出带，带上符号一旦写上就不改动，带头一直往右，永不回头。</li>\n</ul>\n<h4 id=\"枚举器和TM的等价\"><a href=\"#枚举器和TM的等价\" class=\"headerlink\" title=\"枚举器和TM的等价\"></a>枚举器和TM的等价</h4><ul>\n<li>设对某个枚举器 $M_1,\\ L=G(M_1)$, 则存在TM $M_2$ 使得 $L(M_2) = L$<ul>\n<li>构造M2，M2比M1多一条输入带，比较M2的输入和M1产生的串，如果相等则接受，不相等则与M1产生的下一个串继续比较，这样进行。</li>\n<li>因为M1产生的串都是M2能接受的，M1不能产生的串都是M2不能接受的（不停机）所以 L(M2)=G(M1)=L</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"对偶产生器\"><a href=\"#对偶产生器\" class=\"headerlink\" title=\"对偶产生器\"></a>对偶产生器</h4><ul>\n<li>一个过程，以i+j不减的顺序列出正整数对(i,j)</li>\n</ul>\n<h4 id=\"字母表-Sigma-上串的正则次序\"><a href=\"#字母表-Sigma-上串的正则次序\" class=\"headerlink\" title=\"字母表 $\\Sigma$ 上串的正则次序\"></a>字母表 $\\Sigma$ 上串的正则次序</h4><ul>\n<li>先按长度排序</li>\n<li>再按字典序</li>\n</ul>\n<h3 id=\"7-4-图灵机与0型文法的关系\"><a href=\"#7-4-图灵机与0型文法的关系\" class=\"headerlink\" title=\"7.4 图灵机与0型文法的关系\"></a>7.4 图灵机与0型文法的关系</h3><p>图灵机对应0型文法</p>\n<hr>\n<h2 id=\"第八章-不可判定性\"><a href=\"#第八章-不可判定性\" class=\"headerlink\" title=\"第八章 不可判定性\"></a>第八章 不可判定性</h2><p>重点</p>\n<ul>\n<li>递归集和递归可枚举集的属性 </li>\n<li>两个不可判定问题（停机问题+成员资格问题） </li>\n<li>通⽤图灵机的概念，图灵机的⼆进制编码 </li>\n<li>Rice定理</li>\n</ul>\n<h3 id=\"8-1-递归集和递归可枚举集性质\"><a href=\"#8-1-递归集和递归可枚举集性质\" class=\"headerlink\" title=\"8.1 递归集和递归可枚举集性质\"></a>8.1 递归集和递归可枚举集性质</h3><h4 id=\"补集\"><a href=\"#补集\" class=\"headerlink\" title=\"补集\"></a><strong>补集</strong></h4><ul>\n<li>一个递归集的补集仍然是递归集<br>因为完全TM<br>调换接受拒绝状态</li>\n</ul>\n<h4 id=\"并集\"><a href=\"#并集\" class=\"headerlink\" title=\"并集\"></a><strong>并集</strong></h4><ul>\n<li>递归集的并是递归的，递归可枚举集的并是递归可枚举的<ul>\n<li>对于递归集，其是由完全TM生成的语言集合那么对于输入串，可先经M1进行验证，若接受则接受，若不接受则进第二个M2，重复上述过程。 （这里的保证是因为他们是完全TM，可以停机）</li>\n<li>对于递归可枚举集，构造非确定M3’,对输入分别在M1，和M2上验证，如果有一个接受则接受，可见M3‘的停机问题也是不可判定的，为一般TM。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"交集\"><a href=\"#交集\" class=\"headerlink\" title=\"交集\"></a><strong>交集</strong></h4><ul>\n<li>递归集的交是递归的，递归可枚举集的交是递归可枚举的</li>\n</ul>\n<p>看ppt的图，应该很清楚</p>\n<ul>\n<li>若语言 L 和 L补 都是递归可枚举的，则L（和L补）是递归的</li>\n</ul>\n<h3 id=\"8-2-通用图灵机和两个不可判定问题\"><a href=\"#8-2-通用图灵机和两个不可判定问题\" class=\"headerlink\" title=\"8.2 通用图灵机和两个不可判定问题\"></a>8.2 通用图灵机和两个不可判定问题</h3><h4 id=\"通用图灵机\"><a href=\"#通用图灵机\" class=\"headerlink\" title=\"通用图灵机\"></a>通用图灵机</h4><p>模拟任何图灵机的图灵机，将某个TM作为通用图灵机的输入来看待</p>\n<ul>\n<li>需要对TM有统一的、合理的编码</li>\n<li>在给定输入串上，模拟TM的动作</li>\n<li>给定TM接受，则该TM接受这个TM和这个输入的二元组</li>\n</ul>\n<h4 id=\"图灵机编码\"><a href=\"#图灵机编码\" class=\"headerlink\" title=\"图灵机编码\"></a>图灵机编码</h4><p>M#w</p>\n<h4 id=\"关于停机问题的不可判定性\"><a href=\"#关于停机问题的不可判定性\" class=\"headerlink\" title=\"关于停机问题的不可判定性\"></a>关于停机问题的不可判定性</h4><ul>\n<li><p>没有一个算法在有限步之内能够判断一个TM M在给定的输入串x上是否能停机。</p>\n<ul>\n<li><ol>\n<li>接受状态</li>\n</ol>\n</li>\n<li><ol>\n<li>拒绝状态</li>\n</ol>\n</li>\n<li><ol>\n<li>无限循环</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><p><strong>任意给定TM M对任意给定输入串x是否停机的问题是不可判定的</strong><br>自指悖论（类似<strong>罗素悖论</strong>的方法）</p>\n</li>\n</ul>\n<p><strong>证明</strong></p>\n<ul>\n<li><strong>Step 1 TM编码</strong><ul>\n<li>由于可对TM进行编码，所以任何TM可以表示为01串</li>\n<li>而我们可以把任何零一串看作一个TM</li>\n<li>在上述规定下，可按正则次序列出所有TM<br>$M<em>{\\epsilon},\\ M_0,\\ M_1\\ ,M</em>{00},\\ M_{01}…$<br>显然真正的TM一定出现在此序列中至少一次</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p><strong>Step 2 二维表标记</strong></p>\n<ul>\n<li>考虑无穷维的二维表，其顶端遍历 ${0, 1}^*$ 的正则序列，左端遍历 TM，用H (Halt) 表示停机，用L (Loop) 表示不停机，在对应位置做上标记</li>\n</ul>\n</li>\n<li><p><strong>Step 3 开始证明</strong></p>\n<ul>\n<li>假设存在完全TM K，以Mx#y为输入，能够判断Mx在y上是否能够停机。如果停机，则 K 接受 Mx#y；否则，拒绝</li>\n<li>构造另一个TM N，其输入为 $x \\in {0, 1}^*$ 其完成以下任务<ul>\n<li>从x找到Mx，将Mx#x写到其带上</li>\n<li>在 Mx#x 上模拟K的动作，如果K接受，则其就进入循环（不停机），如果K拒绝，他就接受。</li>\n</ul>\n</li>\n<li>那么根据N的定义，如果N在x上停机，则代表K拒绝，则代表Mx在y上不停机。</li>\n</ul>\n</li>\n<li><p><strong>Step 4 推出矛盾</strong></p>\n<ul>\n<li>因为N也是图灵机，假设其编码为y，在正则序列中出现为My，如果N在y上停机，则代表My在y上不停机，而My就是N，导致矛盾。矛盾起因是K的存在性<br>所以不存在这样的TM能够判断M在任何输入下是否停机，即停机问题是不可判定的</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"成员资格问题的不可判定性\"><a href=\"#成员资格问题的不可判定性\" class=\"headerlink\" title=\"成员资格问题的不可判定性\"></a>成员资格问题的不可判定性</h4><ul>\n<li><p><strong>对于任意给定 TM M 和输入串x，M是否接受x的问题是不可判定的</strong></p>\n<ul>\n<li><ol>\n<li>存在完全的 TM K，它能对任意的M和x，判断x是否属于L(M)。若$x \\in L(M)$，则K接受$M#x$；否则拒绝</li>\n</ol>\n</li>\n<li><ol>\n<li>构造N，使得如果x在M上达到接受或拒绝的停机状态，则N接受。可以看出N是判断M在x上是否停机的TM。</li>\n</ol>\n</li>\n<li><ol>\n<li>现在对M输入N#x，则N是否接受x等价于x在M上是否停机，而停机问题是不可判定的，所以成员资格问题也不可判定。</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"8-3-归约方法和Rice定理\"><a href=\"#8-3-归约方法和Rice定理\" class=\"headerlink\" title=\"8.3 归约方法和Rice定理\"></a>8.3 归约方法和Rice定理</h3><ul>\n<li><strong>给定TM M其是否接受空串的问题是不可判定的</strong></li>\n</ul>\n<p>将HP的不可判定性导出问题B的不可判定性</p>\n<ul>\n<li>HP Halt Problem 停机问题</li>\n<li>B 其他问题</li>\n</ul>\n<h4 id=\"Rice定理\"><a href=\"#Rice定理\" class=\"headerlink\" title=\"Rice定理\"></a>Rice定理</h4><ul>\n<li><p>r.e.集合类的任何一个非平凡性质都是不可判定的</p>\n</li>\n<li><p><strong>Step 1 准备</strong> </p>\n<ul>\n<li>设 P 是 r.e. 集合类上的一个非平凡性质，不失一般性，假设空集不具有性质P，则因为P的非平凡性，必定存在一个集合A满足P，即P(A) = T设K是接受A的TM</li>\n</ul>\n</li>\n<li><p><strong>Step 2 归约HP到集合 ${M|P(L(M)) = T}$</strong><br>  给定M#x, 构造TM M’，其按以下步骤进行</p>\n<ul>\n<li>对于TM的输入y，将其放在一个道上</li>\n<li>将x写在另一个道上</li>\n<li>在M上模拟x的动作</li>\n<li>如果M在x上停机，则在K上模拟y的动作</li>\n<li>如果K接受y，则M’接受y</li>\n</ul>\n</li>\n<li><p><strong>Step 3 推出矛盾</strong></p>\n<ul>\n<li>显然，M和M’的停机问题相关联，如果停机有 M’ 和 K 接受一样的集合。</li>\n<li>所以有 M 在 x 上停机，可推出，L(M’) = A，可推出 P(L(M’)) = T</li>\n<li>反之则不停机，P(L(M’)) = F</li>\n<li>这就得出了停机问题到该问题的归约，但停机问题不可判定，所以其非平凡性质也不可判定。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"8-4-关于CFL的不可判定问题\"><a href=\"#8-4-关于CFL的不可判定问题\" class=\"headerlink\" title=\"8.4 关于CFL的不可判定问题\"></a>8.4 关于CFL的不可判定问题</h3><h3 id=\"8-5-Post对应问题的不可判定性及其应用\"><a href=\"#8-5-Post对应问题的不可判定性及其应用\" class=\"headerlink\" title=\"8.5 Post对应问题的不可判定性及其应用\"></a>8.5 Post对应问题的不可判定性及其应用</h3><hr>\n<h2 id=\"第九章-线性有界自动机和上下文有关语言\"><a href=\"#第九章-线性有界自动机和上下文有关语言\" class=\"headerlink\" title=\"第九章 线性有界自动机和上下文有关语言\"></a>第九章 线性有界自动机和上下文有关语言</h2><p>重点</p>\n<ul>\n<li>给定语⾔，构造LBA </li>\n<li>LBA对停机问题的判定问题</li>\n</ul>\n<p>各种机器对应的不同⽂法，⽐如FA对应CFG，图灵机对应0型，PDA对应CFL</p>\n<h3 id=\"9-1-线性有界自动机-LBA\"><a href=\"#9-1-线性有界自动机-LBA\" class=\"headerlink\" title=\"9.1 线性有界自动机 LBA\"></a>9.1 线性有界自动机 LBA</h3><ul>\n<li>对TM的读写头范围加以限制</li>\n<li>左右端都有标记</li>\n<li>接收机和小于TM接受的集合类</li>\n</ul>\n<p>线性有界自动机 LBA 是9元组 $M=(Q,\\ \\Sigma, \\Gamma, \\vdash,\\ \\dashv, \\delta,\\ s,\\ t,\\ r)$</p>\n<ul>\n<li><ol>\n<li>Q 有穷状态集</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\Sigma$ 有穷输入字母表</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\Gamma$ 有穷带上字母表</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\vdash$ 左端符号</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\dashv$ 右端符号</li>\n</ol>\n</li>\n<li><ol>\n<li>$\\delta$ 状态转移函数</li>\n</ol>\n</li>\n<li><ol>\n<li>s 开始状态</li>\n</ol>\n</li>\n<li><ol>\n<li>t 接受状态</li>\n</ol>\n</li>\n<li><ol>\n<li>r 拒绝状态</li>\n</ol>\n</li>\n</ul>\n<p><strong><em>例题9.1</em></strong><br>思路：</p>\n<ul>\n<li><ol>\n<li>查讫符号打标记后找到中心</li>\n</ol>\n</li>\n<li><ol>\n<li>对消</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"9-2-LBA-和-CSL-的关系\"><a href=\"#9-2-LBA-和-CSL-的关系\" class=\"headerlink\" title=\"9.2 LBA 和 CSL 的关系\"></a>9.2 LBA 和 CSL 的关系</h3><ul>\n<li>若L是CSL，则L可被某个LBA接受</li>\n</ul>\n<p>将S派生出来的各种字符串（在下道），与上道的w比较，若相等则接受</p>\n<h3 id=\"9-3-CSL的性质及其和递归集的关系\"><a href=\"#9-3-CSL的性质及其和递归集的关系\" class=\"headerlink\" title=\"9.3 CSL的性质及其和递归集的关系\"></a>9.3 CSL的性质及其和递归集的关系</h3><h4 id=\"CSL封闭性\"><a href=\"#CSL封闭性\" class=\"headerlink\" title=\"CSL封闭性\"></a>CSL封闭性</h4><ul>\n<li>并</li>\n<li>连接</li>\n<li>正闭包（因为CSL不包含 $\\epsilon$，所以L1为CSL则其闭包 $L_1^*$ 不是CSL）</li>\n<li>交运算</li>\n</ul>\n<h4 id=\"每个CSL都是递归的\"><a href=\"#每个CSL都是递归的\" class=\"headerlink\" title=\"每个CSL都是递归的\"></a>每个CSL都是递归的</h4><p>思路：<br>因为输入串长度有限，并且两端封闭，所以总的情况数是有限的为$k(n+2)l^n$ 种，那么用双带，一带正常执行，令一带计算执行步数，如果超出则说明进入循环，则拒绝。所以有CSL是递归的</p>\n<h4 id=\"存在递归集，不是CSL\"><a href=\"#存在递归集，不是CSL\" class=\"headerlink\" title=\"存在递归集，不是CSL\"></a>存在递归集，不是CSL</h4><h3 id=\"9-4-语言类之间的关系\"><a href=\"#9-4-语言类之间的关系\" class=\"headerlink\" title=\"9.4 语言类之间的关系\"></a>9.4 语言类之间的关系</h3><ol>\n<li>RL(3型文法RG)</li>\n<li>DCFL</li>\n<li>CFL(2型文法CFG)</li>\n<li>CSL∪{ε}(1型文法CSG)</li>\n<li>递归集</li>\n<li>r.e.集（递归可枚举集）(0型文法PSG),如成员问题所对应的字符串</li>\n<li>非r.e.集，如FIN</li>\n</ol>\n<hr>\n<h2 id=\"第十一章\"><a href=\"#第十一章\" class=\"headerlink\" title=\"第十一章\"></a>第十一章</h2><p>重点</p>\n<ul>\n<li>给定语⾔：判断是P还是NP</li>\n<li>P与NP的封闭性证明 常⻅的NPC问题的推导和证明(重点)<ul>\n<li>证NP问题</li>\n<li>证归约性 </li>\n</ul>\n</li>\n<li>P NP NPC NPHARD的概念 </li>\n<li>PSPACE==NPSPACE-NPSPACEhard </li>\n<li>L-NL（构造：利⽤指针） </li>\n<li>后⾯的层次定理&amp;布尔电路不考</li>\n</ul>\n<h3 id=\"层次概览\"><a href=\"#层次概览\" class=\"headerlink\" title=\"层次概览\"></a>层次概览</h3><p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_81564f07be5cb20ec62f5761169626dc.png\" alt></p>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_aeeccf9bef7be94af30f6875bdf5d5e1.png\" alt></p>\n<script type=\"math/tex; mode=display\">L \\subset NL = coNL \\subset P \\subset NP \\subset PSPACE = NPSPACE \\subset EXPTIME</script><h3 id=\"P类\"><a href=\"#P类\" class=\"headerlink\" title=\"P类\"></a>P类</h3><ul>\n<li>定义： P是确定型单带图灵机在多项式时间内可判定的语言类</li>\n</ul>\n<script type=\"math/tex; mode=display\">P = \\mathop\\cup\\limits_{k} TIME(n^k)</script><h4 id=\"PATH-in-P\"><a href=\"#PATH-in-P\" class=\"headerlink\" title=\"PATH $\\in$ P\"></a><strong>PATH $\\in$ P</strong></h4><p>PATH 问题，即G（有向图）中两点判定是否存在有向路径<br>用BFS算法，O(m)<br>或者dijkstra算法</p>\n<h4 id=\"RELPRIME-in-P\"><a href=\"#RELPRIME-in-P\" class=\"headerlink\" title=\"RELPRIME $\\in$ P\"></a><strong>RELPRIME $\\in$ P</strong></h4><p>RELPRIME 问题，即判定两数互素<br>辗转相除法（欧几里得算法）</p>\n<h4 id=\"每个CFL都是P\"><a href=\"#每个CFL都是P\" class=\"headerlink\" title=\"每个CFL都是P\"></a><strong>每个CFL都是P</strong></h4><p>CYK 复杂度$O(n^3)$</p>\n<h3 id=\"NP类\"><a href=\"#NP类\" class=\"headerlink\" title=\"NP类\"></a>NP类</h3><h4 id=\"引理：NP是具有多项式时间验证机的语言\"><a href=\"#引理：NP是具有多项式时间验证机的语言\" class=\"headerlink\" title=\"引理：NP是具有多项式时间验证机的语言\"></a><strong>引理：NP是具有多项式时间验证机的语言</strong></h4><ul>\n<li>用于验证该问题的额外信息称为证书<ul>\n<li>HAMPATH 中两点之间的哈密顿路径</li>\n<li>COMPOSITES 中 x 一个不等于1的因子</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"一个语言在NP中，当且仅当其能够被某个非确定型多项式时间图灵机判定\"><a href=\"#一个语言在NP中，当且仅当其能够被某个非确定型多项式时间图灵机判定\" class=\"headerlink\" title=\"一个语言在NP中，当且仅当其能够被某个非确定型多项式时间图灵机判定\"></a><strong>一个语言在NP中，当且仅当其能够被某个非确定型多项式时间图灵机判定</strong></h4><h4 id=\"NTIME-t-n-L-L-是一个被O-t-n-时间的非确定型图灵机判定的语言\"><a href=\"#NTIME-t-n-L-L-是一个被O-t-n-时间的非确定型图灵机判定的语言\" class=\"headerlink\" title=\"NTIME(t(n)) = {L| L 是一个被O(t(n))时间的非确定型图灵机判定的语言}\"></a><strong>NTIME(t(n)) = {L| L 是一个被O(t(n))时间的非确定型图灵机判定的语言}</strong></h4><script type=\"math/tex; mode=display\">NP = \\cup_k NTIME(n^k)</script><h4 id=\"CLIQUE-in-NP\"><a href=\"#CLIQUE-in-NP\" class=\"headerlink\" title=\"CLIQUE $\\in$ NP\"></a><strong>CLIQUE $\\in$ NP</strong></h4><p>CLIQUE = {(G,k)| G是包含k团的无向图}</p>\n<ul>\n<li><p>验证机角度</p>\n<pre><code>  证书：团，记为c\n  V为CLIQUE的验证机\n  V = 对输入((G,k), c)\n  1. 检查c是否是G中k个点的集合\n  2. 检查G是否包含连接c中节点的所有边\n  3. 若均通过则接受，否则拒绝\n</code></pre></li>\n<li><p>非确定型TM角度</p>\n<pre><code>  N = 对于输入(G,k)\n  1. 非确定的选择G中k个节点的子集c\n  2. 检查G是否包含连接c中节点的所有边\n  3. 若是则接受，否则拒绝\n</code></pre></li>\n</ul>\n<h4 id=\"SUBSET-SUM-in-NP\"><a href=\"#SUBSET-SUM-in-NP\" class=\"headerlink\" title=\"SUBSET-SUM $\\in$ NP\"></a><strong>SUBSET-SUM $\\in$ NP</strong></h4><p>SUBSET-SUM，给定集合s和t，判定是否有s的子集y，使得子集y中元素之和等于t</p>\n<ul>\n<li><p>验证机角度</p>\n<pre><code>  证书：子集\n  V = 对输入((s,t),c)\n  1. 验证c中元素之和是否等于t\n  2. 验证s是否包含c中所有元素\n  3. 若均通过则接受，否则拒绝\n</code></pre></li>\n<li><p>非确定型TM角度</p>\n<pre><code>  N = 对于输入(s,t)\n  1. 非确定的选择s中的子集c\n  2. 验证c的元素之和是否等于t\n  3. 若是则接受，否则拒绝\n</code></pre></li>\n<li><p>co-NP</p>\n</li>\n</ul>\n<h3 id=\"P与NP问题\"><a href=\"#P与NP问题\" class=\"headerlink\" title=\"P与NP问题\"></a>P与NP问题</h3><ul>\n<li>P = NP ?<script type=\"math/tex; mode=display\">NP \\subset EXPTIME = \\mathop\\cup\\limits_{k} TIME(2^{n^k})</script></li>\n</ul>\n<h3 id=\"NP完全性\"><a href=\"#NP完全性\" class=\"headerlink\" title=\"NP完全性\"></a>NP完全性</h3><ul>\n<li>定义<ul>\n<li><ol>\n<li>B属于NP（多项式时间内被非确定图灵机判定）</li>\n</ol>\n</li>\n<li><ol>\n<li>NP中每一个A都可在多项式时间内归约到B（归约，重要步骤）</li>\n</ol>\n</li>\n<li>则称B为NP完全问题</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>证明P=NP的一类思路<ul>\n<li>证明某个NPC $\\in$ P</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"库克-列文定理\"><a href=\"#库克-列文定理\" class=\"headerlink\" title=\"库克-列文定理\"></a><strong>库克-列文定理</strong></h4><p>SAT 问题，给定一个布尔公式$\\phi$判断其是否可满足</p>\n<script type=\"math/tex; mode=display\">SAT \\in P，当且仅当 P=NP</script><p>证明：</p>\n<ul>\n<li>第一步：非确定图灵机可以在多项式时间内猜测变量的赋值，然后判断其是否可满足，因此 $SAT \\subset NP$</li>\n<li>第二步：<ul>\n<li>假设从$NP$取出任意语言$A$，非确定$TM N$在$n^k-3$判定</li>\n<li>考虑$N$对应的$n^k\\times n^k$画面$\\omega$</li>\n<li>设计一个$\\phi$,使得变量的一个满足赋值确实对应$N$在$\\omega$上的接受画面</li>\n<li>//todo</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"SAT-in-NPC\"><a href=\"#SAT-in-NPC\" class=\"headerlink\" title=\"SAT $\\in$ NPC\"></a><strong>SAT $\\in$ NPC</strong></h4><p>为NP中的每一个语言A，构造一个到SAT的多项式时间归约<br>书P170~173</p>\n<h4 id=\"3SAT-in-NPC\"><a href=\"#3SAT-in-NPC\" class=\"headerlink\" title=\"3SAT $\\in$ NPC\"></a><strong>3SAT $\\in$ NPC</strong></h4><h4 id=\"CLIQUE-in-NPC\"><a href=\"#CLIQUE-in-NPC\" class=\"headerlink\" title=\"CLIQUE $\\in$ NPC\"></a><strong>CLIQUE $\\in$ NPC</strong></h4><ul>\n<li><strong>证明NPC</strong><ul>\n<li>先证明NP</li>\n<li>再证明某个已知NPC问题可在多项式时间内归约到他</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"顶点覆盖问题-VERTEX-COVER\"><a href=\"#顶点覆盖问题-VERTEX-COVER\" class=\"headerlink\" title=\"顶点覆盖问题 VERTEX-COVER\"></a>顶点覆盖问题 VERTEX-COVER</h4><p>VERTEX-COVER 判定G是具有k个顶点的顶点覆盖的无向图<br>NP完全<br>3SAT 到 VERTEX-COVER 的归约<br>书P174</p>\n<ul>\n<li>证明思路：将一个$3nf$公式$\\phi$转化成一个图$G$和数值$k$，只要能找到覆盖，$\\phi$就被相应地满足</li>\n</ul>\n<h4 id=\"哈密顿路径问题-HAMPATH\"><a href=\"#哈密顿路径问题-HAMPATH\" class=\"headerlink\" title=\"哈密顿路径问题 HAMPATH\"></a>哈密顿路径问题 HAMPATH</h4><p>HAMPATH $\\in$ NPC<br>3SAT 到 HAMPATH 的归约</p>\n<p>书p175~177</p>\n<h4 id=\"子集和问题-SUBSET-SUM\"><a href=\"#子集和问题-SUBSET-SUM\" class=\"headerlink\" title=\"子集和问题 SUBSET-SUM\"></a>子集和问题 SUBSET-SUM</h4><p>SUBSET-SUM $\\in$ NPC<br>3SAT 到 SUBSET-SUM 的归约</p>\n<p>书p178~180</p>\n<hr>\n<h3 id=\"萨维奇定理\"><a href=\"#萨维奇定理\" class=\"headerlink\" title=\"萨维奇定理\"></a>萨维奇定理</h3><p>任何消耗$f(n)$空间的非确定型TM都可以转变为仅消耗$f^2(n)$空间的确定型TM</p>\n<script type=\"math/tex; mode=display\">NSPACE(f(n)) \\subset SPACE(f^2(n))</script><p>方法：利用中间格局递归二分<br>CANYIELD = 对于输入 c1，c2，t</p>\n<ol>\n<li>t=1 直接检查是否有c1 = c2 或根据N规则，检查c1是否能够一步只能产生c2，其中之一成立则接受，否则拒绝</li>\n<li>若 t &gt; 1，则对于N在w上消耗空间f(n)的每一个格局cm</li>\n<li>运行CANYIELD(c1, cm, t/2)</li>\n<li>运行CANYIELD(cm, c2, t/2)</li>\n<li>两个都接受则接受，否则拒绝</li>\n</ol>\n<p>对输入 $c<em>{start}$，$c</em>{accept}$，$2^{df(n)}$</p>\n<p>递归深度$O(log2^{df(n)})$，所以总消耗空间$O(f^2(n))$</p>\n<h3 id=\"PSPACE类\"><a href=\"#PSPACE类\" class=\"headerlink\" title=\"PSPACE类\"></a>PSPACE类</h3><p>PSPACE是在确定型图灵机上，在多项式空间内可判定的语言类</p>\n<script type=\"math/tex; mode=display\">PSPACE = \\mathop\\cup\\limits_{k}SPACE(n^k)</script><ul>\n<li>SAT $\\in$ SPACE(n)</li>\n<li>$ALL<em>{NFA} \\in coNSPACE(n) \\Rightarrow ALL</em>{NFA} \\in SPACE(n^2)$</li>\n<li><p>其都在PSPACE中</p>\n</li>\n<li><p>$P \\subset PSPACE$<br>因为运行n步的程序，最多消耗n的空间</p>\n</li>\n<li><p>$NP \\subset NPSPACE$<br>同理</p>\n</li>\n</ul>\n<p>由于 NPSPACE = PSPACE<br>所以有 $NP \\subset PSPACE$</p>\n<h3 id=\"PSPACE完全性\"><a href=\"#PSPACE完全性\" class=\"headerlink\" title=\"PSPACE完全性\"></a>PSPACE完全性</h3><p>定义 若B是PSPACE-C则其满足以下两个条件</p>\n<ul>\n<li><ol>\n<li>$B \\in PSPACE$</li>\n</ol>\n</li>\n<li><ol>\n<li>PSPACE中每个语言A可多项式时间内归约到B</li>\n</ol>\n</li>\n<li>只满足2类似NP难称其为PSPACE难的</li>\n</ul>\n<h4 id=\"TQBF问题\"><a href=\"#TQBF问题\" class=\"headerlink\" title=\"TQBF问题\"></a>TQBF问题</h4><p>判定$\\phi$是真的全量词化布尔公式<br>其是PSPACE完全的</p>\n<ul>\n<li>先给出一个线性空间的复杂度算法，证明其属于PSPACE</li>\n<li>再给出归约方式，类似萨维奇定理证明方法<br>书 P192</li>\n</ul>\n<h4 id=\"博弈必胜\"><a href=\"#博弈必胜\" class=\"headerlink\" title=\"博弈必胜\"></a>博弈必胜</h4><p>$FORMULA_GAME = {&lt;\\phi&gt; | 在与\\phi相关联的公式博弈中选手E有必胜策略}$<br>其是PSPACE完全的<br><strong>因为其等价于TQBF</strong></p>\n<h4 id=\"广义地理学\"><a href=\"#广义地理学\" class=\"headerlink\" title=\"广义地理学\"></a>广义地理学</h4><p>$GG = {<G,b> | 在图G上以结点b起始的广义地理学游戏中，选手I有必胜策略}$<br>其是PSPACE完全的<br>证明方法类似TQBF的递归算法</G,b></p>\n<h3 id=\"L和NL类\"><a href=\"#L和NL类\" class=\"headerlink\" title=\"L和NL类\"></a>L和NL类</h3><p>亚线性空间界限，类似工作主存上是亚线性空间，其余放在外存（只读）。</p>\n<h4 id=\"L类\"><a href=\"#L类\" class=\"headerlink\" title=\"L类\"></a>L类</h4><ul>\n<li>L是确定型图灵机在对数空间内可判定的语言类<script type=\"math/tex; mode=display\">L=SPACE(logn)</script></li>\n</ul>\n<h4 id=\"NL类\"><a href=\"#NL类\" class=\"headerlink\" title=\"NL类\"></a>NL类</h4><ul>\n<li><p>NL是非确定性图灵机在对数空间内可判定的语言类集合</p>\n<script type=\"math/tex; mode=display\">NL=NSPACE(logn)</script></li>\n<li><p>例题 8.13<br>$A = {0^k1^k| k \\ge 0} \\in L$<br>在工作带上用二进制数0、1的数目，两个计数器消耗对数级别空间，所以$A \\in L$</p>\n</li>\n<li><p>$PATH \\in NL$<br>非确定的猜测从s到t的每一步，工作带上只记录每一步当前节点的位置，非确定的选择下一个节点，反复执行，直到到达t接受。或执行m步后拒绝，m是节点数。由此得到了PATH的被非确定型图灵机在亚线性空间内接受。</p>\n</li>\n</ul>\n<h3 id=\"NL完全性\"><a href=\"#NL完全性\" class=\"headerlink\" title=\"NL完全性\"></a>NL完全性</h3><p>定义 若语言B是NL完全的，则其满足</p>\n<ul>\n<li><ol>\n<li>$B \\in NL$ </li>\n</ol>\n</li>\n<li><ol>\n<li>NL中的每个A<strong>对数空间</strong>内可归约到B</li>\n</ol>\n</li>\n</ul>\n<h4 id=\"PATH是NL完全的\"><a href=\"#PATH是NL完全的\" class=\"headerlink\" title=\"PATH是NL完全的\"></a>PATH是NL完全的</h4><p>证明方法，把输入字符串w对应为图，图中节点对应NTM在输入w上的一个格局。一个结点能指向另一个结点的调节时，其对应的格局能在NTM的一步内产生第二个结点对应的格局，因此，NTM对输入w是否接受就对应着初始格局到接受格局的PATH<br>更详细的对数空间归约证明情况书 p199~200</p>\n<h4 id=\"NL-subset-P\"><a href=\"#NL-subset-P\" class=\"headerlink\" title=\"$NL \\subset P$\"></a>$NL \\subset P$</h4><ul>\n<li><ol>\n<li>因为PATH是NL完全的，所以NL中任何语言可对数空间内归约到PATH</li>\n</ol>\n</li>\n<li><ol>\n<li>由此，NL中任何语言也可对数时间内归约到PATH</li>\n</ol>\n</li>\n<li><ol>\n<li>因为多项式时间内归约到P中语言的语言本身也属于P</li>\n</ol>\n</li>\n<li><ol>\n<li>所以 $NL \\in P$</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"NL-coNL\"><a href=\"#NL-coNL\" class=\"headerlink\" title=\"NL = coNL\"></a>NL = coNL</h3>"},{"title":"OS Evolution Report","date":"2021-10-15T17:29:48.000Z","index_img":"/img/OS/banner.png","math":true,"_content":"\n### 1. The Overall Summary of OS Evolution\n\n​\tThe operating system is an indispensable part of the modern computer. It serves as the central component between the hardware device and user programs, providing mainly three basic functionality —— Multiplex, Isolation, and Interaction. It was not until 1971. OS officially became part of the computer science core curriculum by the promotion of the *SOSP* (symposium on operating systems principles) according to Denning's writing [^Denning2016] *Fifty Years of Operating Systems*.\n\n​\tAlthough everything looks obvious today, it's necessary for us to go back decades ago, thinking from the standpoint of the pioneers. The evolution of the operating system is full of hardship and lessons. It can also guide current OS development.\n\n### 2. OS Evolution Stages\n\n​\tBatch systems, Interactive systems, Desktop systems, and Cloud-mobile systems four main stages are defined as the primary OS evolution Stages In Denning's writing from the user perspective.\n\n​\tOperating systems evolved with some features and came up with several OS principles. Denning classifies them as *Computation Law* and *Design Wisdom*, I prefer to call them engineering philosophy, and no matter how we define them, they should be *concise*, *timeless*, *effective*, and with *logical beauty*.\n\n​    More specific OS evolution stages from an engineering perspective are concluded by Hansen [^Hansen2001]*The Evolution of Operating systems*.\n\n​\tAs seven major phases are listed below.\n\n- **Open Shop**\n\n​\tBack to Open Shop time, the 1950s, at that time, there was no concrete concept of Operating system. The computer is just a machine offer to the user as an open shop. People spend a significant amount of time setting up the devices, only a fraction of time for real computing, which is a considerable waste of computation resources. From another aspect, the bottleneck is the imbalance between super slow manual I/O operation and fast CPU computation speed. The Representative Computer at that time was IBM 701.\n\n- **Batch Processing**\n\n​    To address these problems, people came up with the idea that was using the machine itself to schedule its own workload (I/O procedure). And the Open Shop gradually turns to Closed Shop with only a few operators and satellite computers to deal with the I/O tasks. Users only need to hand in their punched cards and waiting for the results. It is the beginning of Batch Processing Era.\n\n​\tInputting multiple jobs simultaneously is the advantage of Batch Processing, but the advantage also leads to its flaws. To reduce tape changing overhead, a large batch is needed, resulting in short jobs being bound with other jobs with FIFO output sequence to compute for a long time.\n\n- **Multiprogramming**\n\n​    OS evolution is not isolated. It is tightly connected to the rest parts of the computer to working as a system. In the 1960s, with hardware development, the large core memories, secondary storage with random access data channels, and hardware interrupt promoted OS's evolution, making multiprogramming practical.\n\n​\tSpooling technique tackles the inherent issue of Batch Processing, making the I/O devices sharing between jobs than exclusively owned by one specific job. A large random access buffer also makes the scheduling feasible. Using shortest-jobs-next to replace FIFO scheduling can deal with the short job waiting problem, however, It incurs some other problems, for example *Starvation* as well. \n\n- **Timesharing**\n\n​    It is the timesharing idea that the first time making the computer interactive. One of the core problems it has addressed is the **Inbalance**. One is the imbalance between jobs' priority and the computation resources it is assigned, and another is the imbalance between people's slow operating speed and the fast CPU speed. Timesharing enables the system to do in-execution scheduling and interact with users with a time slice mechanism. \n\n​\tUndeniably, Operating systems evolution is strongly connected with industry implementation. MIT CTSS and Multics verify the timesharing concept in engineering, and the business success of CTSS and other timesharing systems boost the evolution of OS in turn, one of the most outstanding contributions, *hierarchical file systems*. \n\n- **Concurrent Programming**\n\n​    In terms of Concurrent programming, *Dijkstra* is the right person. He raised the THE multiprogramming system concept and made it himself. With semaphores for process synchronization and communication, people can address the underlying ***deadlock*** problems shown in the Multiprogramming and Timesharing Era. THE design philosophy (hierarchical structure) became the basic principle to design a system for complex problems nowadays *(e.g. OSI Network Structure)*. Dijkstra laid a solid foundation for concurrent programming and the following development of OS.\n\n- **Personal Computing**\n\n​     Personal computing making the operating system more flexible and creative because there are different users with different demands, and the operating systems are becoming more powerful and diversified. GUI (Graphic User Interface) is one of the most explicit examples of it.\n\n- **Distributed Systems**\n\n​    The advent of networks promotes the development of OS, making distributed systems practical. With network connection, the operating system can be distributed on different machines. This brought some new challenges, for instance, ensuring the integrity of file systems and memory systems becoming super tricky.\n\n### 3. Conclusion \n\n​\tThe evolution of the Operating system is the result of the joint efforts of academia and industry field. From the beginning of Open Shop to the recent Distributed Systems, users' demand also plays a vital role in boosting the operating system design pattern, utilizing the hardware better and providing API to higher-level programs. Backing to the start point and looking at the OS development from a historical view, we can better understand the *5W* of OS. \n\nLearn the lessons, Start the future\n\n\n\n### Reference\n\n[^Denning2016]: Peter J. Denning. [Fifty Years of Operating Systems](./2016_CACM_Fifty Years of Operating Systems.pdf). *CACM* **59**(3): 30-32. 2016\n[^Hansen2001]: Per Brinch Hansen. [The Evolution of Operating Systems](./2001_The Evolution of Operating Systems.pdf). *Classic Operating Systems: From Batch Processing To Distributed Systems* : 1-34. Springer, 2001","source":"_posts/OS/OS-Evolution-01.md","raw":"---\ntitle: OS Evolution Report\ndate: 2021-10-15 10:29:48\nindex_img: /img/OS/banner.png\ncategory: [OS]\ntags: [OS]\nmath: true\n---\n\n### 1. The Overall Summary of OS Evolution\n\n​\tThe operating system is an indispensable part of the modern computer. It serves as the central component between the hardware device and user programs, providing mainly three basic functionality —— Multiplex, Isolation, and Interaction. It was not until 1971. OS officially became part of the computer science core curriculum by the promotion of the *SOSP* (symposium on operating systems principles) according to Denning's writing [^Denning2016] *Fifty Years of Operating Systems*.\n\n​\tAlthough everything looks obvious today, it's necessary for us to go back decades ago, thinking from the standpoint of the pioneers. The evolution of the operating system is full of hardship and lessons. It can also guide current OS development.\n\n### 2. OS Evolution Stages\n\n​\tBatch systems, Interactive systems, Desktop systems, and Cloud-mobile systems four main stages are defined as the primary OS evolution Stages In Denning's writing from the user perspective.\n\n​\tOperating systems evolved with some features and came up with several OS principles. Denning classifies them as *Computation Law* and *Design Wisdom*, I prefer to call them engineering philosophy, and no matter how we define them, they should be *concise*, *timeless*, *effective*, and with *logical beauty*.\n\n​    More specific OS evolution stages from an engineering perspective are concluded by Hansen [^Hansen2001]*The Evolution of Operating systems*.\n\n​\tAs seven major phases are listed below.\n\n- **Open Shop**\n\n​\tBack to Open Shop time, the 1950s, at that time, there was no concrete concept of Operating system. The computer is just a machine offer to the user as an open shop. People spend a significant amount of time setting up the devices, only a fraction of time for real computing, which is a considerable waste of computation resources. From another aspect, the bottleneck is the imbalance between super slow manual I/O operation and fast CPU computation speed. The Representative Computer at that time was IBM 701.\n\n- **Batch Processing**\n\n​    To address these problems, people came up with the idea that was using the machine itself to schedule its own workload (I/O procedure). And the Open Shop gradually turns to Closed Shop with only a few operators and satellite computers to deal with the I/O tasks. Users only need to hand in their punched cards and waiting for the results. It is the beginning of Batch Processing Era.\n\n​\tInputting multiple jobs simultaneously is the advantage of Batch Processing, but the advantage also leads to its flaws. To reduce tape changing overhead, a large batch is needed, resulting in short jobs being bound with other jobs with FIFO output sequence to compute for a long time.\n\n- **Multiprogramming**\n\n​    OS evolution is not isolated. It is tightly connected to the rest parts of the computer to working as a system. In the 1960s, with hardware development, the large core memories, secondary storage with random access data channels, and hardware interrupt promoted OS's evolution, making multiprogramming practical.\n\n​\tSpooling technique tackles the inherent issue of Batch Processing, making the I/O devices sharing between jobs than exclusively owned by one specific job. A large random access buffer also makes the scheduling feasible. Using shortest-jobs-next to replace FIFO scheduling can deal with the short job waiting problem, however, It incurs some other problems, for example *Starvation* as well. \n\n- **Timesharing**\n\n​    It is the timesharing idea that the first time making the computer interactive. One of the core problems it has addressed is the **Inbalance**. One is the imbalance between jobs' priority and the computation resources it is assigned, and another is the imbalance between people's slow operating speed and the fast CPU speed. Timesharing enables the system to do in-execution scheduling and interact with users with a time slice mechanism. \n\n​\tUndeniably, Operating systems evolution is strongly connected with industry implementation. MIT CTSS and Multics verify the timesharing concept in engineering, and the business success of CTSS and other timesharing systems boost the evolution of OS in turn, one of the most outstanding contributions, *hierarchical file systems*. \n\n- **Concurrent Programming**\n\n​    In terms of Concurrent programming, *Dijkstra* is the right person. He raised the THE multiprogramming system concept and made it himself. With semaphores for process synchronization and communication, people can address the underlying ***deadlock*** problems shown in the Multiprogramming and Timesharing Era. THE design philosophy (hierarchical structure) became the basic principle to design a system for complex problems nowadays *(e.g. OSI Network Structure)*. Dijkstra laid a solid foundation for concurrent programming and the following development of OS.\n\n- **Personal Computing**\n\n​     Personal computing making the operating system more flexible and creative because there are different users with different demands, and the operating systems are becoming more powerful and diversified. GUI (Graphic User Interface) is one of the most explicit examples of it.\n\n- **Distributed Systems**\n\n​    The advent of networks promotes the development of OS, making distributed systems practical. With network connection, the operating system can be distributed on different machines. This brought some new challenges, for instance, ensuring the integrity of file systems and memory systems becoming super tricky.\n\n### 3. Conclusion \n\n​\tThe evolution of the Operating system is the result of the joint efforts of academia and industry field. From the beginning of Open Shop to the recent Distributed Systems, users' demand also plays a vital role in boosting the operating system design pattern, utilizing the hardware better and providing API to higher-level programs. Backing to the start point and looking at the OS development from a historical view, we can better understand the *5W* of OS. \n\nLearn the lessons, Start the future\n\n\n\n### Reference\n\n[^Denning2016]: Peter J. Denning. [Fifty Years of Operating Systems](./2016_CACM_Fifty Years of Operating Systems.pdf). *CACM* **59**(3): 30-32. 2016\n[^Hansen2001]: Per Brinch Hansen. [The Evolution of Operating Systems](./2001_The Evolution of Operating Systems.pdf). *Classic Operating Systems: From Batch Processing To Distributed Systems* : 1-34. Springer, 2001","slug":"OS/OS-Evolution-01","published":1,"updated":"2026-02-03T05:42:14.443Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvj003d7uit28hsb678","content":"<h3 id=\"1-The-Overall-Summary-of-OS-Evolution\"><a href=\"#1-The-Overall-Summary-of-OS-Evolution\" class=\"headerlink\" title=\"1. The Overall Summary of OS Evolution\"></a>1. The Overall Summary of OS Evolution</h3><p>​    The operating system is an indispensable part of the modern computer. It serves as the central component between the hardware device and user programs, providing mainly three basic functionality —— Multiplex, Isolation, and Interaction. It was not until 1971. OS officially became part of the computer science core curriculum by the promotion of the <em>SOSP</em> (symposium on operating systems principles) according to Denning’s writing <sup><a href=\"#fn_Denning2016\" id=\"reffn_Denning2016\">Denning2016</a></sup> <em>Fifty Years of Operating Systems</em>.</p>\n<p>​    Although everything looks obvious today, it’s necessary for us to go back decades ago, thinking from the standpoint of the pioneers. The evolution of the operating system is full of hardship and lessons. It can also guide current OS development.</p>\n<h3 id=\"2-OS-Evolution-Stages\"><a href=\"#2-OS-Evolution-Stages\" class=\"headerlink\" title=\"2. OS Evolution Stages\"></a>2. OS Evolution Stages</h3><p>​    Batch systems, Interactive systems, Desktop systems, and Cloud-mobile systems four main stages are defined as the primary OS evolution Stages In Denning’s writing from the user perspective.</p>\n<p>​    Operating systems evolved with some features and came up with several OS principles. Denning classifies them as <em>Computation Law</em> and <em>Design Wisdom</em>, I prefer to call them engineering philosophy, and no matter how we define them, they should be <em>concise</em>, <em>timeless</em>, <em>effective</em>, and with <em>logical beauty</em>.</p>\n<p>​    More specific OS evolution stages from an engineering perspective are concluded by Hansen <sup><a href=\"#fn_Hansen2001\" id=\"reffn_Hansen2001\">Hansen2001</a></sup><em>The Evolution of Operating systems</em>.</p>\n<p>​    As seven major phases are listed below.</p>\n<ul>\n<li><strong>Open Shop</strong></li>\n</ul>\n<p>​    Back to Open Shop time, the 1950s, at that time, there was no concrete concept of Operating system. The computer is just a machine offer to the user as an open shop. People spend a significant amount of time setting up the devices, only a fraction of time for real computing, which is a considerable waste of computation resources. From another aspect, the bottleneck is the imbalance between super slow manual I/O operation and fast CPU computation speed. The Representative Computer at that time was IBM 701.</p>\n<ul>\n<li><strong>Batch Processing</strong></li>\n</ul>\n<p>​    To address these problems, people came up with the idea that was using the machine itself to schedule its own workload (I/O procedure). And the Open Shop gradually turns to Closed Shop with only a few operators and satellite computers to deal with the I/O tasks. Users only need to hand in their punched cards and waiting for the results. It is the beginning of Batch Processing Era.</p>\n<p>​    Inputting multiple jobs simultaneously is the advantage of Batch Processing, but the advantage also leads to its flaws. To reduce tape changing overhead, a large batch is needed, resulting in short jobs being bound with other jobs with FIFO output sequence to compute for a long time.</p>\n<ul>\n<li><strong>Multiprogramming</strong></li>\n</ul>\n<p>​    OS evolution is not isolated. It is tightly connected to the rest parts of the computer to working as a system. In the 1960s, with hardware development, the large core memories, secondary storage with random access data channels, and hardware interrupt promoted OS’s evolution, making multiprogramming practical.</p>\n<p>​    Spooling technique tackles the inherent issue of Batch Processing, making the I/O devices sharing between jobs than exclusively owned by one specific job. A large random access buffer also makes the scheduling feasible. Using shortest-jobs-next to replace FIFO scheduling can deal with the short job waiting problem, however, It incurs some other problems, for example <em>Starvation</em> as well. </p>\n<ul>\n<li><strong>Timesharing</strong></li>\n</ul>\n<p>​    It is the timesharing idea that the first time making the computer interactive. One of the core problems it has addressed is the <strong>Inbalance</strong>. One is the imbalance between jobs’ priority and the computation resources it is assigned, and another is the imbalance between people’s slow operating speed and the fast CPU speed. Timesharing enables the system to do in-execution scheduling and interact with users with a time slice mechanism. </p>\n<p>​    Undeniably, Operating systems evolution is strongly connected with industry implementation. MIT CTSS and Multics verify the timesharing concept in engineering, and the business success of CTSS and other timesharing systems boost the evolution of OS in turn, one of the most outstanding contributions, <em>hierarchical file systems</em>. </p>\n<ul>\n<li><strong>Concurrent Programming</strong></li>\n</ul>\n<p>​    In terms of Concurrent programming, <em>Dijkstra</em> is the right person. He raised the THE multiprogramming system concept and made it himself. With semaphores for process synchronization and communication, people can address the underlying <strong><em>deadlock</em></strong> problems shown in the Multiprogramming and Timesharing Era. THE design philosophy (hierarchical structure) became the basic principle to design a system for complex problems nowadays <em>(e.g. OSI Network Structure)</em>. Dijkstra laid a solid foundation for concurrent programming and the following development of OS.</p>\n<ul>\n<li><strong>Personal Computing</strong></li>\n</ul>\n<p>​     Personal computing making the operating system more flexible and creative because there are different users with different demands, and the operating systems are becoming more powerful and diversified. GUI (Graphic User Interface) is one of the most explicit examples of it.</p>\n<ul>\n<li><strong>Distributed Systems</strong></li>\n</ul>\n<p>​    The advent of networks promotes the development of OS, making distributed systems practical. With network connection, the operating system can be distributed on different machines. This brought some new challenges, for instance, ensuring the integrity of file systems and memory systems becoming super tricky.</p>\n<h3 id=\"3-Conclusion\"><a href=\"#3-Conclusion\" class=\"headerlink\" title=\"3. Conclusion\"></a>3. Conclusion</h3><p>​    The evolution of the Operating system is the result of the joint efforts of academia and industry field. From the beginning of Open Shop to the recent Distributed Systems, users’ demand also plays a vital role in boosting the operating system design pattern, utilizing the hardware better and providing API to higher-level programs. Backing to the start point and looking at the OS development from a historical view, we can better understand the <em>5W</em> of OS. </p>\n<p>Learn the lessons, Start the future</p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><blockquote id=\"fn_Denning2016\">\n<sup>Denning2016</sup>. Peter J. Denning. <a href=\"./2016_CACM_Fifty Years of Operating Systems.pdf\">Fifty Years of Operating Systems</a>. <em>CACM</em> <strong>59</strong>(3): 30-32. 2016<a href=\"#reffn_Denning2016\" title=\"Jump back to footnote [Denning2016] in the text.\"> &#8617;</a>\n</blockquote>\n<blockquote id=\"fn_Hansen2001\">\n<sup>Hansen2001</sup>. Per Brinch Hansen. <a href=\"./2001_The Evolution of Operating Systems.pdf\">The Evolution of Operating Systems</a>. <em>Classic Operating Systems: From Batch Processing To Distributed Systems</em> : 1-34. Springer, 2001<a href=\"#reffn_Hansen2001\" title=\"Jump back to footnote [Hansen2001] in the text.\"> &#8617;</a>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"1-The-Overall-Summary-of-OS-Evolution\"><a href=\"#1-The-Overall-Summary-of-OS-Evolution\" class=\"headerlink\" title=\"1. The Overall Summary of OS Evolution\"></a>1. The Overall Summary of OS Evolution</h3><p>​    The operating system is an indispensable part of the modern computer. It serves as the central component between the hardware device and user programs, providing mainly three basic functionality —— Multiplex, Isolation, and Interaction. It was not until 1971. OS officially became part of the computer science core curriculum by the promotion of the <em>SOSP</em> (symposium on operating systems principles) according to Denning’s writing <sup><a href=\"#fn_Denning2016\" id=\"reffn_Denning2016\">Denning2016</a></sup> <em>Fifty Years of Operating Systems</em>.</p>\n<p>​    Although everything looks obvious today, it’s necessary for us to go back decades ago, thinking from the standpoint of the pioneers. The evolution of the operating system is full of hardship and lessons. It can also guide current OS development.</p>\n<h3 id=\"2-OS-Evolution-Stages\"><a href=\"#2-OS-Evolution-Stages\" class=\"headerlink\" title=\"2. OS Evolution Stages\"></a>2. OS Evolution Stages</h3><p>​    Batch systems, Interactive systems, Desktop systems, and Cloud-mobile systems four main stages are defined as the primary OS evolution Stages In Denning’s writing from the user perspective.</p>\n<p>​    Operating systems evolved with some features and came up with several OS principles. Denning classifies them as <em>Computation Law</em> and <em>Design Wisdom</em>, I prefer to call them engineering philosophy, and no matter how we define them, they should be <em>concise</em>, <em>timeless</em>, <em>effective</em>, and with <em>logical beauty</em>.</p>\n<p>​    More specific OS evolution stages from an engineering perspective are concluded by Hansen <sup><a href=\"#fn_Hansen2001\" id=\"reffn_Hansen2001\">Hansen2001</a></sup><em>The Evolution of Operating systems</em>.</p>\n<p>​    As seven major phases are listed below.</p>\n<ul>\n<li><strong>Open Shop</strong></li>\n</ul>\n<p>​    Back to Open Shop time, the 1950s, at that time, there was no concrete concept of Operating system. The computer is just a machine offer to the user as an open shop. People spend a significant amount of time setting up the devices, only a fraction of time for real computing, which is a considerable waste of computation resources. From another aspect, the bottleneck is the imbalance between super slow manual I/O operation and fast CPU computation speed. The Representative Computer at that time was IBM 701.</p>\n<ul>\n<li><strong>Batch Processing</strong></li>\n</ul>\n<p>​    To address these problems, people came up with the idea that was using the machine itself to schedule its own workload (I/O procedure). And the Open Shop gradually turns to Closed Shop with only a few operators and satellite computers to deal with the I/O tasks. Users only need to hand in their punched cards and waiting for the results. It is the beginning of Batch Processing Era.</p>\n<p>​    Inputting multiple jobs simultaneously is the advantage of Batch Processing, but the advantage also leads to its flaws. To reduce tape changing overhead, a large batch is needed, resulting in short jobs being bound with other jobs with FIFO output sequence to compute for a long time.</p>\n<ul>\n<li><strong>Multiprogramming</strong></li>\n</ul>\n<p>​    OS evolution is not isolated. It is tightly connected to the rest parts of the computer to working as a system. In the 1960s, with hardware development, the large core memories, secondary storage with random access data channels, and hardware interrupt promoted OS’s evolution, making multiprogramming practical.</p>\n<p>​    Spooling technique tackles the inherent issue of Batch Processing, making the I/O devices sharing between jobs than exclusively owned by one specific job. A large random access buffer also makes the scheduling feasible. Using shortest-jobs-next to replace FIFO scheduling can deal with the short job waiting problem, however, It incurs some other problems, for example <em>Starvation</em> as well. </p>\n<ul>\n<li><strong>Timesharing</strong></li>\n</ul>\n<p>​    It is the timesharing idea that the first time making the computer interactive. One of the core problems it has addressed is the <strong>Inbalance</strong>. One is the imbalance between jobs’ priority and the computation resources it is assigned, and another is the imbalance between people’s slow operating speed and the fast CPU speed. Timesharing enables the system to do in-execution scheduling and interact with users with a time slice mechanism. </p>\n<p>​    Undeniably, Operating systems evolution is strongly connected with industry implementation. MIT CTSS and Multics verify the timesharing concept in engineering, and the business success of CTSS and other timesharing systems boost the evolution of OS in turn, one of the most outstanding contributions, <em>hierarchical file systems</em>. </p>\n<ul>\n<li><strong>Concurrent Programming</strong></li>\n</ul>\n<p>​    In terms of Concurrent programming, <em>Dijkstra</em> is the right person. He raised the THE multiprogramming system concept and made it himself. With semaphores for process synchronization and communication, people can address the underlying <strong><em>deadlock</em></strong> problems shown in the Multiprogramming and Timesharing Era. THE design philosophy (hierarchical structure) became the basic principle to design a system for complex problems nowadays <em>(e.g. OSI Network Structure)</em>. Dijkstra laid a solid foundation for concurrent programming and the following development of OS.</p>\n<ul>\n<li><strong>Personal Computing</strong></li>\n</ul>\n<p>​     Personal computing making the operating system more flexible and creative because there are different users with different demands, and the operating systems are becoming more powerful and diversified. GUI (Graphic User Interface) is one of the most explicit examples of it.</p>\n<ul>\n<li><strong>Distributed Systems</strong></li>\n</ul>\n<p>​    The advent of networks promotes the development of OS, making distributed systems practical. With network connection, the operating system can be distributed on different machines. This brought some new challenges, for instance, ensuring the integrity of file systems and memory systems becoming super tricky.</p>\n<h3 id=\"3-Conclusion\"><a href=\"#3-Conclusion\" class=\"headerlink\" title=\"3. Conclusion\"></a>3. Conclusion</h3><p>​    The evolution of the Operating system is the result of the joint efforts of academia and industry field. From the beginning of Open Shop to the recent Distributed Systems, users’ demand also plays a vital role in boosting the operating system design pattern, utilizing the hardware better and providing API to higher-level programs. Backing to the start point and looking at the OS development from a historical view, we can better understand the <em>5W</em> of OS. </p>\n<p>Learn the lessons, Start the future</p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><blockquote id=\"fn_Denning2016\">\n<sup>Denning2016</sup>. Peter J. Denning. <a href=\"./2016_CACM_Fifty Years of Operating Systems.pdf\">Fifty Years of Operating Systems</a>. <em>CACM</em> <strong>59</strong>(3): 30-32. 2016<a href=\"#reffn_Denning2016\" title=\"Jump back to footnote [Denning2016] in the text.\"> &#8617;</a>\n</blockquote>\n<blockquote id=\"fn_Hansen2001\">\n<sup>Hansen2001</sup>. Per Brinch Hansen. <a href=\"./2001_The Evolution of Operating Systems.pdf\">The Evolution of Operating Systems</a>. <em>Classic Operating Systems: From Batch Processing To Distributed Systems</em> : 1-34. Springer, 2001<a href=\"#reffn_Hansen2001\" title=\"Jump back to footnote [Hansen2001] in the text.\"> &#8617;</a>\n</blockquote>\n"},{"title":"深入理解Linux内核之内存寻址","date":"2021-07-10T22:21:20.000Z","index_img":"/img/OS/banner.png","math":true,"_content":"\n\n\n**说明：** *本文基于第三版《深入理解 Linux 内核》，该部分以 80x86 处理器为基准进行介绍，并且略过了原文中详细介绍32位扩展分页部分*\n\n## 一、内存地址\n\n### 1.1 逻辑地址 (logic address)\n\n​\t在机器语言指令中用来指定一个操作数或一条指令的地址，每一个逻辑地址都由以下两部分组成\n\n- 段 （segment）指明段位置\n\n- 偏移量 （offset）指明段开始处到实际地址的距离\n\n  \n\n### 1.2 虚拟地址 (virtual address)\n\n根据机器的位数不同而不同，32位机器即32位无符号整数、64位即64位无符号整数，这里取32位为例。\n\n- 可用于表达 $2^{32}$ 即 4GB 的地址空间\n\n- 通常用16进制表示，值的范围从 0x00000000 ~ 0xffffffff\n\n  \n\n### 1.3 物理地址 (physical address)\n\n​\t内存芯片级的内存单元寻址，从CPU的地址引脚发送到内存总线上的电信号相对应，由 32 位或 36 位无符号整数表示\n\n\n\n### 1.4 内存控制单元 MMU\n\n​\t内存控制单元以下简称MMU，其集成在CPU上进行地址翻译，转换过程为两阶段\n\n- **分段：**由逻辑地址到虚拟地址\n- **分页：**由虚拟地址到物理地址\n\n![图1 逻辑地址翻译过程](https://tva1.sinaimg.cn/large/008i3skNly1gsbz2jr0c4j319208475u.jpg)\n\n\n\n### 1.5 内存仲裁器 MA\n\n​\t在多核系统中，所有的CPU核心共享同一内存，则代表着CPU可以并发的访问内存。而内存的读写必须是串行执行，所以需要专用元器件对内存访问进行排序，其称为内存仲裁器。\n\n​\t内存仲裁器是在内存总线和RAM芯片之间的硬件电路\n\n- **若内存空闲：**允许访问\n- **若内存被占用：**延迟CPU访问\n\n*注：由于单处理器上存在一个叫做DMA控制器的特殊处理器，因此其实单处理器上也有内存仲裁器*\n\n\n\n### 1.6 分段和分页的意义\n\n分段和分页是用于划分进程的物理地址空间的\n\n- **分段：**每个进程分配不同的虚拟地址空间\n- **分页：**把同一虚拟地址空间映射到不同的物理地址\n\nLinux更多使用分页的方式\n\n- 不同进程共享同一组虚拟地址空间，内存管理简单\n- 跨平台，因为RISC体系结构对分段支持有限\n\n\n\n## 二、内存分段\n\n### 2.1 硬件分段\n\n#### 2.1.1 **实模式和保护模式**\n\n​\t从 80286 模型开始，Intel处理器采用两种不同方式进行地址转换，称为实模式（real mode）和保护模式（protected mode）\n\n - **实模式**\n\n   ​\t其作用是为维持处理器和早期模型的兼容，因为早期寄存器位数太少，物理地址有20位，最多1MB的内存空间。而段基址寄存器有16位，最多只能访问64kb。为了访问64kb以上的空间，需要对内存进行分段，使用段基址+段偏移的模式寻址。\n\n   ​\t通过 ```物理地址 = 段基址 << 4 + 段内偏移``` 的方式表示物理地址。这个实模式的 “实” 体现在其反应的是真实物理地址。\n\n   ​\t但是由于实模式没有区分代码和数据，如果用户程序的一个指针如果指向了系统程序区域或其他用户程序区域，并修改了内容，那么后果就很可能是灾难性的。\n\n- **保护模式**\n\n​\t随着寄存器硬件的扩展，地址位数和寄存器位数都变成了32/64位，现代CPU已经不需要使用上述实模式了，当然为了兼容老版本所以还是得支持实模式。\n\n​\t同时由于实模式不安全，我们通过一些手段来实现比较安全的寻址，这也是保护模式的命名的由来。\n\n1. **地址保护：**程序内部的地址(虚拟地址)要由操作系统转化为物理地址去访问，程序对此一无所知\n\n2. **边界保护：** 段寄存器中不再储存的是段地址而是段索引。我们将数据放在一个叫做**全局描述符表**（GDT) 的结构中，其中表项称为段描述符，段描述符存放了段基址、段界限、内存段类型属性，用来索引段地址和标记段边界。\n\n【Segmentation Fault 的出处】\n\n#### 2.1.2 **段选择符和段寄存器**\n\n- **段选择符**\n\n  逻辑地址 = 段标识符 (16位) + 段偏移量 (32位)，我们又将段标识符称为段选择符，其结构如下图所示\n\n  ![图二 段选择符](https://tva1.sinaimg.cn/large/008i3skNly1gsc0cxl28uj319a08egmn.jpg)\n\n  - index 描述符的入口，在2.1.4节中会详细讲解\n\n  - TI （Table Indicator）标明段在GDT还是LDT中，在GDT中为0，LDT中为1\n\n  - RPL 请求特权级，cs寄存器改变时指示出CPU当前特权级\n\n    \n\n- **段寄存器**\n\n  段寄存器存放段选择符，段寄存器共有 cs，ss，ds，es，fs和gs六个，其作用如图三所示。\n\n  注：cs寄存器中还有一个两位的字段，指明CPU当前特权级别（CPL）0~3，Linux只用0和3，代表内核态和用户态\t\n\n  <img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gscxuu0jeyj30go0cw74y.jpg\" style=\"zoom:50%;\" alt=\"图三 80x86段寄存器\" />\n\n  \n\n  <img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsd1lms0n9j31320re78r.jpg\" alt=\"图四 分级保护域\" style=\"zoom:30%;\" />\n\n#### 2.1.3 段描述符\n\n​\t每个段被一个8字节的段描述符（Segment Descriptor）表示，描述了段的特征。\n\n​\t其放在 *全局描述符表（GDT - Global Descriptor Table）* 或 *局部描述符表 （LDT - Local Descriptor Table）* 中\n\n - **全局描述符表（GDT - Global Descriptor Table）**\n   \t- 特点：进程共享\n      \t- 存放：gdtr寄存器（基址+大小）\n - **局部描述符表 （LDT - Local Descriptor Table）**\n    - 特点：进程独享\n    - 存放：ldtr寄存器（基址+大小）\n\n- **段描述符字段**\n\n|  字段名  | 描述                                                         |\n| :------: | :----------------------------------------------------------- |\n|   Base   | 包含段首字节的虚拟地址                                       |\n|    G     | 粒度标志，如果为0，则以字节为单位，否则以4096字节的倍数计算  |\n|  Limit   | 存放段中最后一个内存单元的偏移量，来决定段的长度。G为0则段在1到1MB，否则在4KB到4GB |\n|    S     | 系统标志，如果为0，则代表该段为系统段，储存LDT或其他关键数据结构，否则则是普通text或data段 |\n|   Type   | 描述段的类型特征和存取权限                                   |\n|   DPL    | 描述符特权级（DPL）字段；限制对该段的存取。表示访问该段需要的最小 CPL （Linux 0/3） |\n|    P     | Segement-Present标志，0代表不在主存中，Linux总将此设为1，因为整个段一直都会在主存中 |\n|  D or B  | 取决于是代码段还是数据段                                     |\n| AVL 标志 | 可被操作系统使用，但Linux忽略该标志                          |\n\n- **描述符段分类**\n\n  - 代码段描述符\n  - 数据段描述符\n  - 任务状态段描述符 （TSSD）\n    - 代表任务状态段（TSS）用于保存寄存器内容，仅在GDT中\n\n  <img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gscyouo50cj312s0u00yj.jpg\" alt=\"图五 段描述符格式\" style=\"zoom:50%;\" />\n\n\n\n#### 2.1.4 快速访问段描述符\n\n- **段描述符的索引规则：**\n\n  段基址 + 段选择符 index [13位] << 3\n\n  因此描述符最大数目为 $2^{13} - 1$\n\n\n\n#### 2.1.5 分段单元\n\n​\t图六已经较为清楚的展示了分段单元把逻辑地址转为虚拟地址的过程，段选择符在段寄存器中，offset存储在ip寄存器中\n\n​\t<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gscz202qbsj30yk0oqwgh.jpg\" alt=\"图六 逻辑地址翻译\" style=\"zoom:50%;\" />\n\n\n\n### 2.2 Linux 分段\n\n#### 2.2.1 Linux中的段结构\n\n​\t2.6版的Linux只有在 80x86 结构下才进行分段，下图为Linux的分段结构\t![图七 Linux分段](https://tva1.sinaimg.cn/large/008i3skNly1gsczhyx2exj31es0b2taa.jpg)\n\n​\t所有段都从0x00000000开始，**所以在Linux下，逻辑地址和虚拟地址相同**\n\n​\t相应端选择符由宏 ```__USER_CS```、```__USER_DS```、```__KERNEL_CS```、```__KERNEL_DS``` 定义\n\n​\tCPU的CPL存储在 cs 寄存器的 RPL 字段中，特权级别改变，某些段寄存器必须更新\n\n> 例如当CPL由 3 变为 0 时 ds寄存器必须从含有用户态数据段的段选择符变为含有内核数据段的段选择符，ss类似\n\n​\t\n\n####  2.2.2 Linux GDT\n\n​\t每个CPU对应一个GDT，所有的GDT都存放在 cpu_gdt_table 里，所有的GDT地址和大小被存放在 cpu_gdt_descr数组中。\n\n​\t这些符号在 arch/i386/kernel/head.S 中被定义\n\n​\t每个GDT包含 18个段描述符和14个空的保留项，保留项保证了常用的描述符可以在同一个32字节的 Cache 中，防止 Cache 抖动。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsczztgg7mj312w0smdlz.jpg\" alt=\"图八 Linux GDT结构\" style=\"zoom:50%;\" />\n\n​\t\t\n\n## 三、内存分页\n\n### 3.1 硬件分页\n\n​\t分页单元（Paging Unit）是将虚拟地址转化为物理地址\n\n​\t**关键任务：**是将所请求的访问类型和虚拟地址访问权限相比较，如果访问无效，则产生缺页异常\n\n​\t**页：**一组虚拟地址，又指包含在这组地址中的数据。把RAM分成固定长度的页框（Page Frame）每个页框*（结构）*包含一个页*（数据）*。\n\n​\t**页表：**将虚拟地址映射到物理地址的数据结构\n\n​\t**cr0寄存器：**PG标志为0，虚拟地址就解释为物理地址，否则如果 PG = 1 代表启用分页。\n\n\n\n### 3.2 Linux 分页\n\n​\tLinux采用4级分页模式，节省内存空间花费，页表基址寄存器cr3\n\n- 页全局目录 （Page Global Directory）\n- 页上级目录（Page Upper DIrectory）\n- 页中间目录（Page Middle Directory）\n- 页表 （Page Table）\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsd0c0i81mj313s0mw41q.jpg\" alt=\"图九 Linux多级页表\" style=\"zoom:50%;\" />\n\n​\t如图九所示，虚拟地址翻译过程，其将虚拟地址分为五部分，标准页大小4kb，所以offset占12位，剩下 52 位 每 13 位代表相应目录偏移量，先取出cr3寄存器中页全局目录的基址，和偏移量相加，索引到下级页上级目录的极致，如此重复，直到索引到页表取出 PPN，由于物理地址偏移量和虚拟地址相同，所以直接和虚拟地址偏移量 VPO 拼接得到物理地址\n\n#### 3.2.1 分页机制的优势\n\n​\t虚拟地址到物理地址的自动转换使得下述设计目标变得现实\n\n- 给每个进程分配不同的物理地址空间，防止寻址错误\n- 区别页和页框不同，允许页被装入不同的页框中，是虚拟内存机制的基本要素\n\n每个进程有自己的页全局目录和页表集合，每次进行进程上下文切换时，Linux内核把前一个进程的cr3寄存器值存入在前一个进程的进程描述符中，并载入新进程的全局目录基址进入cr3寄存器中。\n\n\n\n#### 3.2.2 进程页表\n\n进程的虚拟内存空间被分为两部分\n\n- 用户态寻址部分：0x00000000 ~ 0xbfffffff\n- 内核态寻址部分：0xc0000000 ~ 0xffffffff \n\n进程运行在用户态时，其产生的线性地址小于 0xc0000000，在内核态则随意\n\n\n\n#### 3.2.3 内核页表\n\n​\t内核有自己的一组页表，存放在主内核页全局目录中。主内核页全局目录的最高目录项部分作为参考模型，为系统中每个普通进程对应的页全局目录项提供参考模型。\n\nTODO","source":"_posts/OS/MemAddressing.md","raw":"---\ntitle: 深入理解Linux内核之内存寻址\ndate: 2021-07-10 15:21:20\nindex_img: /img/OS/banner.png\ncategory: [OS]\ntags: [kernel, memory addressing]\nmath: true\n---\n\n\n\n**说明：** *本文基于第三版《深入理解 Linux 内核》，该部分以 80x86 处理器为基准进行介绍，并且略过了原文中详细介绍32位扩展分页部分*\n\n## 一、内存地址\n\n### 1.1 逻辑地址 (logic address)\n\n​\t在机器语言指令中用来指定一个操作数或一条指令的地址，每一个逻辑地址都由以下两部分组成\n\n- 段 （segment）指明段位置\n\n- 偏移量 （offset）指明段开始处到实际地址的距离\n\n  \n\n### 1.2 虚拟地址 (virtual address)\n\n根据机器的位数不同而不同，32位机器即32位无符号整数、64位即64位无符号整数，这里取32位为例。\n\n- 可用于表达 $2^{32}$ 即 4GB 的地址空间\n\n- 通常用16进制表示，值的范围从 0x00000000 ~ 0xffffffff\n\n  \n\n### 1.3 物理地址 (physical address)\n\n​\t内存芯片级的内存单元寻址，从CPU的地址引脚发送到内存总线上的电信号相对应，由 32 位或 36 位无符号整数表示\n\n\n\n### 1.4 内存控制单元 MMU\n\n​\t内存控制单元以下简称MMU，其集成在CPU上进行地址翻译，转换过程为两阶段\n\n- **分段：**由逻辑地址到虚拟地址\n- **分页：**由虚拟地址到物理地址\n\n![图1 逻辑地址翻译过程](https://tva1.sinaimg.cn/large/008i3skNly1gsbz2jr0c4j319208475u.jpg)\n\n\n\n### 1.5 内存仲裁器 MA\n\n​\t在多核系统中，所有的CPU核心共享同一内存，则代表着CPU可以并发的访问内存。而内存的读写必须是串行执行，所以需要专用元器件对内存访问进行排序，其称为内存仲裁器。\n\n​\t内存仲裁器是在内存总线和RAM芯片之间的硬件电路\n\n- **若内存空闲：**允许访问\n- **若内存被占用：**延迟CPU访问\n\n*注：由于单处理器上存在一个叫做DMA控制器的特殊处理器，因此其实单处理器上也有内存仲裁器*\n\n\n\n### 1.6 分段和分页的意义\n\n分段和分页是用于划分进程的物理地址空间的\n\n- **分段：**每个进程分配不同的虚拟地址空间\n- **分页：**把同一虚拟地址空间映射到不同的物理地址\n\nLinux更多使用分页的方式\n\n- 不同进程共享同一组虚拟地址空间，内存管理简单\n- 跨平台，因为RISC体系结构对分段支持有限\n\n\n\n## 二、内存分段\n\n### 2.1 硬件分段\n\n#### 2.1.1 **实模式和保护模式**\n\n​\t从 80286 模型开始，Intel处理器采用两种不同方式进行地址转换，称为实模式（real mode）和保护模式（protected mode）\n\n - **实模式**\n\n   ​\t其作用是为维持处理器和早期模型的兼容，因为早期寄存器位数太少，物理地址有20位，最多1MB的内存空间。而段基址寄存器有16位，最多只能访问64kb。为了访问64kb以上的空间，需要对内存进行分段，使用段基址+段偏移的模式寻址。\n\n   ​\t通过 ```物理地址 = 段基址 << 4 + 段内偏移``` 的方式表示物理地址。这个实模式的 “实” 体现在其反应的是真实物理地址。\n\n   ​\t但是由于实模式没有区分代码和数据，如果用户程序的一个指针如果指向了系统程序区域或其他用户程序区域，并修改了内容，那么后果就很可能是灾难性的。\n\n- **保护模式**\n\n​\t随着寄存器硬件的扩展，地址位数和寄存器位数都变成了32/64位，现代CPU已经不需要使用上述实模式了，当然为了兼容老版本所以还是得支持实模式。\n\n​\t同时由于实模式不安全，我们通过一些手段来实现比较安全的寻址，这也是保护模式的命名的由来。\n\n1. **地址保护：**程序内部的地址(虚拟地址)要由操作系统转化为物理地址去访问，程序对此一无所知\n\n2. **边界保护：** 段寄存器中不再储存的是段地址而是段索引。我们将数据放在一个叫做**全局描述符表**（GDT) 的结构中，其中表项称为段描述符，段描述符存放了段基址、段界限、内存段类型属性，用来索引段地址和标记段边界。\n\n【Segmentation Fault 的出处】\n\n#### 2.1.2 **段选择符和段寄存器**\n\n- **段选择符**\n\n  逻辑地址 = 段标识符 (16位) + 段偏移量 (32位)，我们又将段标识符称为段选择符，其结构如下图所示\n\n  ![图二 段选择符](https://tva1.sinaimg.cn/large/008i3skNly1gsc0cxl28uj319a08egmn.jpg)\n\n  - index 描述符的入口，在2.1.4节中会详细讲解\n\n  - TI （Table Indicator）标明段在GDT还是LDT中，在GDT中为0，LDT中为1\n\n  - RPL 请求特权级，cs寄存器改变时指示出CPU当前特权级\n\n    \n\n- **段寄存器**\n\n  段寄存器存放段选择符，段寄存器共有 cs，ss，ds，es，fs和gs六个，其作用如图三所示。\n\n  注：cs寄存器中还有一个两位的字段，指明CPU当前特权级别（CPL）0~3，Linux只用0和3，代表内核态和用户态\t\n\n  <img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gscxuu0jeyj30go0cw74y.jpg\" style=\"zoom:50%;\" alt=\"图三 80x86段寄存器\" />\n\n  \n\n  <img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsd1lms0n9j31320re78r.jpg\" alt=\"图四 分级保护域\" style=\"zoom:30%;\" />\n\n#### 2.1.3 段描述符\n\n​\t每个段被一个8字节的段描述符（Segment Descriptor）表示，描述了段的特征。\n\n​\t其放在 *全局描述符表（GDT - Global Descriptor Table）* 或 *局部描述符表 （LDT - Local Descriptor Table）* 中\n\n - **全局描述符表（GDT - Global Descriptor Table）**\n   \t- 特点：进程共享\n      \t- 存放：gdtr寄存器（基址+大小）\n - **局部描述符表 （LDT - Local Descriptor Table）**\n    - 特点：进程独享\n    - 存放：ldtr寄存器（基址+大小）\n\n- **段描述符字段**\n\n|  字段名  | 描述                                                         |\n| :------: | :----------------------------------------------------------- |\n|   Base   | 包含段首字节的虚拟地址                                       |\n|    G     | 粒度标志，如果为0，则以字节为单位，否则以4096字节的倍数计算  |\n|  Limit   | 存放段中最后一个内存单元的偏移量，来决定段的长度。G为0则段在1到1MB，否则在4KB到4GB |\n|    S     | 系统标志，如果为0，则代表该段为系统段，储存LDT或其他关键数据结构，否则则是普通text或data段 |\n|   Type   | 描述段的类型特征和存取权限                                   |\n|   DPL    | 描述符特权级（DPL）字段；限制对该段的存取。表示访问该段需要的最小 CPL （Linux 0/3） |\n|    P     | Segement-Present标志，0代表不在主存中，Linux总将此设为1，因为整个段一直都会在主存中 |\n|  D or B  | 取决于是代码段还是数据段                                     |\n| AVL 标志 | 可被操作系统使用，但Linux忽略该标志                          |\n\n- **描述符段分类**\n\n  - 代码段描述符\n  - 数据段描述符\n  - 任务状态段描述符 （TSSD）\n    - 代表任务状态段（TSS）用于保存寄存器内容，仅在GDT中\n\n  <img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gscyouo50cj312s0u00yj.jpg\" alt=\"图五 段描述符格式\" style=\"zoom:50%;\" />\n\n\n\n#### 2.1.4 快速访问段描述符\n\n- **段描述符的索引规则：**\n\n  段基址 + 段选择符 index [13位] << 3\n\n  因此描述符最大数目为 $2^{13} - 1$\n\n\n\n#### 2.1.5 分段单元\n\n​\t图六已经较为清楚的展示了分段单元把逻辑地址转为虚拟地址的过程，段选择符在段寄存器中，offset存储在ip寄存器中\n\n​\t<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gscz202qbsj30yk0oqwgh.jpg\" alt=\"图六 逻辑地址翻译\" style=\"zoom:50%;\" />\n\n\n\n### 2.2 Linux 分段\n\n#### 2.2.1 Linux中的段结构\n\n​\t2.6版的Linux只有在 80x86 结构下才进行分段，下图为Linux的分段结构\t![图七 Linux分段](https://tva1.sinaimg.cn/large/008i3skNly1gsczhyx2exj31es0b2taa.jpg)\n\n​\t所有段都从0x00000000开始，**所以在Linux下，逻辑地址和虚拟地址相同**\n\n​\t相应端选择符由宏 ```__USER_CS```、```__USER_DS```、```__KERNEL_CS```、```__KERNEL_DS``` 定义\n\n​\tCPU的CPL存储在 cs 寄存器的 RPL 字段中，特权级别改变，某些段寄存器必须更新\n\n> 例如当CPL由 3 变为 0 时 ds寄存器必须从含有用户态数据段的段选择符变为含有内核数据段的段选择符，ss类似\n\n​\t\n\n####  2.2.2 Linux GDT\n\n​\t每个CPU对应一个GDT，所有的GDT都存放在 cpu_gdt_table 里，所有的GDT地址和大小被存放在 cpu_gdt_descr数组中。\n\n​\t这些符号在 arch/i386/kernel/head.S 中被定义\n\n​\t每个GDT包含 18个段描述符和14个空的保留项，保留项保证了常用的描述符可以在同一个32字节的 Cache 中，防止 Cache 抖动。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsczztgg7mj312w0smdlz.jpg\" alt=\"图八 Linux GDT结构\" style=\"zoom:50%;\" />\n\n​\t\t\n\n## 三、内存分页\n\n### 3.1 硬件分页\n\n​\t分页单元（Paging Unit）是将虚拟地址转化为物理地址\n\n​\t**关键任务：**是将所请求的访问类型和虚拟地址访问权限相比较，如果访问无效，则产生缺页异常\n\n​\t**页：**一组虚拟地址，又指包含在这组地址中的数据。把RAM分成固定长度的页框（Page Frame）每个页框*（结构）*包含一个页*（数据）*。\n\n​\t**页表：**将虚拟地址映射到物理地址的数据结构\n\n​\t**cr0寄存器：**PG标志为0，虚拟地址就解释为物理地址，否则如果 PG = 1 代表启用分页。\n\n\n\n### 3.2 Linux 分页\n\n​\tLinux采用4级分页模式，节省内存空间花费，页表基址寄存器cr3\n\n- 页全局目录 （Page Global Directory）\n- 页上级目录（Page Upper DIrectory）\n- 页中间目录（Page Middle Directory）\n- 页表 （Page Table）\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsd0c0i81mj313s0mw41q.jpg\" alt=\"图九 Linux多级页表\" style=\"zoom:50%;\" />\n\n​\t如图九所示，虚拟地址翻译过程，其将虚拟地址分为五部分，标准页大小4kb，所以offset占12位，剩下 52 位 每 13 位代表相应目录偏移量，先取出cr3寄存器中页全局目录的基址，和偏移量相加，索引到下级页上级目录的极致，如此重复，直到索引到页表取出 PPN，由于物理地址偏移量和虚拟地址相同，所以直接和虚拟地址偏移量 VPO 拼接得到物理地址\n\n#### 3.2.1 分页机制的优势\n\n​\t虚拟地址到物理地址的自动转换使得下述设计目标变得现实\n\n- 给每个进程分配不同的物理地址空间，防止寻址错误\n- 区别页和页框不同，允许页被装入不同的页框中，是虚拟内存机制的基本要素\n\n每个进程有自己的页全局目录和页表集合，每次进行进程上下文切换时，Linux内核把前一个进程的cr3寄存器值存入在前一个进程的进程描述符中，并载入新进程的全局目录基址进入cr3寄存器中。\n\n\n\n#### 3.2.2 进程页表\n\n进程的虚拟内存空间被分为两部分\n\n- 用户态寻址部分：0x00000000 ~ 0xbfffffff\n- 内核态寻址部分：0xc0000000 ~ 0xffffffff \n\n进程运行在用户态时，其产生的线性地址小于 0xc0000000，在内核态则随意\n\n\n\n#### 3.2.3 内核页表\n\n​\t内核有自己的一组页表，存放在主内核页全局目录中。主内核页全局目录的最高目录项部分作为参考模型，为系统中每个普通进程对应的页全局目录项提供参考模型。\n\nTODO","slug":"OS/MemAddressing","published":1,"updated":"2026-02-03T05:42:14.443Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvj003g7uit6a8aaq1d","content":"<p><strong>说明：</strong> <em>本文基于第三版《深入理解 Linux 内核》，该部分以 80x86 处理器为基准进行介绍，并且略过了原文中详细介绍32位扩展分页部分</em></p>\n<h2 id=\"一、内存地址\"><a href=\"#一、内存地址\" class=\"headerlink\" title=\"一、内存地址\"></a>一、内存地址</h2><h3 id=\"1-1-逻辑地址-logic-address\"><a href=\"#1-1-逻辑地址-logic-address\" class=\"headerlink\" title=\"1.1 逻辑地址 (logic address)\"></a>1.1 逻辑地址 (logic address)</h3><p>​    在机器语言指令中用来指定一个操作数或一条指令的地址，每一个逻辑地址都由以下两部分组成</p>\n<ul>\n<li><p>段 （segment）指明段位置</p>\n</li>\n<li><p>偏移量 （offset）指明段开始处到实际地址的距离</p>\n</li>\n</ul>\n<h3 id=\"1-2-虚拟地址-virtual-address\"><a href=\"#1-2-虚拟地址-virtual-address\" class=\"headerlink\" title=\"1.2 虚拟地址 (virtual address)\"></a>1.2 虚拟地址 (virtual address)</h3><p>根据机器的位数不同而不同，32位机器即32位无符号整数、64位即64位无符号整数，这里取32位为例。</p>\n<ul>\n<li><p>可用于表达 $2^{32}$ 即 4GB 的地址空间</p>\n</li>\n<li><p>通常用16进制表示，值的范围从 0x00000000 ~ 0xffffffff</p>\n</li>\n</ul>\n<h3 id=\"1-3-物理地址-physical-address\"><a href=\"#1-3-物理地址-physical-address\" class=\"headerlink\" title=\"1.3 物理地址 (physical address)\"></a>1.3 物理地址 (physical address)</h3><p>​    内存芯片级的内存单元寻址，从CPU的地址引脚发送到内存总线上的电信号相对应，由 32 位或 36 位无符号整数表示</p>\n<h3 id=\"1-4-内存控制单元-MMU\"><a href=\"#1-4-内存控制单元-MMU\" class=\"headerlink\" title=\"1.4 内存控制单元 MMU\"></a>1.4 内存控制单元 MMU</h3><p>​    内存控制单元以下简称MMU，其集成在CPU上进行地址翻译，转换过程为两阶段</p>\n<ul>\n<li><strong>分段：</strong>由逻辑地址到虚拟地址</li>\n<li><strong>分页：</strong>由虚拟地址到物理地址</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsbz2jr0c4j319208475u.jpg\" alt=\"图1 逻辑地址翻译过程\"></p>\n<h3 id=\"1-5-内存仲裁器-MA\"><a href=\"#1-5-内存仲裁器-MA\" class=\"headerlink\" title=\"1.5 内存仲裁器 MA\"></a>1.5 内存仲裁器 MA</h3><p>​    在多核系统中，所有的CPU核心共享同一内存，则代表着CPU可以并发的访问内存。而内存的读写必须是串行执行，所以需要专用元器件对内存访问进行排序，其称为内存仲裁器。</p>\n<p>​    内存仲裁器是在内存总线和RAM芯片之间的硬件电路</p>\n<ul>\n<li><strong>若内存空闲：</strong>允许访问</li>\n<li><strong>若内存被占用：</strong>延迟CPU访问</li>\n</ul>\n<p><em>注：由于单处理器上存在一个叫做DMA控制器的特殊处理器，因此其实单处理器上也有内存仲裁器</em></p>\n<h3 id=\"1-6-分段和分页的意义\"><a href=\"#1-6-分段和分页的意义\" class=\"headerlink\" title=\"1.6 分段和分页的意义\"></a>1.6 分段和分页的意义</h3><p>分段和分页是用于划分进程的物理地址空间的</p>\n<ul>\n<li><strong>分段：</strong>每个进程分配不同的虚拟地址空间</li>\n<li><strong>分页：</strong>把同一虚拟地址空间映射到不同的物理地址</li>\n</ul>\n<p>Linux更多使用分页的方式</p>\n<ul>\n<li>不同进程共享同一组虚拟地址空间，内存管理简单</li>\n<li>跨平台，因为RISC体系结构对分段支持有限</li>\n</ul>\n<h2 id=\"二、内存分段\"><a href=\"#二、内存分段\" class=\"headerlink\" title=\"二、内存分段\"></a>二、内存分段</h2><h3 id=\"2-1-硬件分段\"><a href=\"#2-1-硬件分段\" class=\"headerlink\" title=\"2.1 硬件分段\"></a>2.1 硬件分段</h3><h4 id=\"2-1-1-实模式和保护模式\"><a href=\"#2-1-1-实模式和保护模式\" class=\"headerlink\" title=\"2.1.1 实模式和保护模式\"></a>2.1.1 <strong>实模式和保护模式</strong></h4><p>​    从 80286 模型开始，Intel处理器采用两种不同方式进行地址转换，称为实模式（real mode）和保护模式（protected mode）</p>\n<ul>\n<li><p><strong>实模式</strong></p>\n<p>​    其作用是为维持处理器和早期模型的兼容，因为早期寄存器位数太少，物理地址有20位，最多1MB的内存空间。而段基址寄存器有16位，最多只能访问64kb。为了访问64kb以上的空间，需要对内存进行分段，使用段基址+段偏移的模式寻址。</p>\n<p>​    通过 <code>物理地址 = 段基址 &lt;&lt; 4 + 段内偏移</code> 的方式表示物理地址。这个实模式的 “实” 体现在其反应的是真实物理地址。</p>\n<p>​    但是由于实模式没有区分代码和数据，如果用户程序的一个指针如果指向了系统程序区域或其他用户程序区域，并修改了内容，那么后果就很可能是灾难性的。</p>\n</li>\n</ul>\n<ul>\n<li><strong>保护模式</strong></li>\n</ul>\n<p>​    随着寄存器硬件的扩展，地址位数和寄存器位数都变成了32/64位，现代CPU已经不需要使用上述实模式了，当然为了兼容老版本所以还是得支持实模式。</p>\n<p>​    同时由于实模式不安全，我们通过一些手段来实现比较安全的寻址，这也是保护模式的命名的由来。</p>\n<ol>\n<li><p><strong>地址保护：</strong>程序内部的地址(虚拟地址)要由操作系统转化为物理地址去访问，程序对此一无所知</p>\n</li>\n<li><p><strong>边界保护：</strong> 段寄存器中不再储存的是段地址而是段索引。我们将数据放在一个叫做<strong>全局描述符表</strong>（GDT) 的结构中，其中表项称为段描述符，段描述符存放了段基址、段界限、内存段类型属性，用来索引段地址和标记段边界。</p>\n</li>\n</ol>\n<p>【Segmentation Fault 的出处】</p>\n<h4 id=\"2-1-2-段选择符和段寄存器\"><a href=\"#2-1-2-段选择符和段寄存器\" class=\"headerlink\" title=\"2.1.2 段选择符和段寄存器\"></a>2.1.2 <strong>段选择符和段寄存器</strong></h4><ul>\n<li><p><strong>段选择符</strong></p>\n<p>逻辑地址 = 段标识符 (16位) + 段偏移量 (32位)，我们又将段标识符称为段选择符，其结构如下图所示</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsc0cxl28uj319a08egmn.jpg\" alt=\"图二 段选择符\"></p>\n<ul>\n<li><p>index 描述符的入口，在2.1.4节中会详细讲解</p>\n</li>\n<li><p>TI （Table Indicator）标明段在GDT还是LDT中，在GDT中为0，LDT中为1</p>\n</li>\n<li><p>RPL 请求特权级，cs寄存器改变时指示出CPU当前特权级</p>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p><strong>段寄存器</strong></p>\n<p>段寄存器存放段选择符，段寄存器共有 cs，ss，ds，es，fs和gs六个，其作用如图三所示。</p>\n<p>注：cs寄存器中还有一个两位的字段，指明CPU当前特权级别（CPL）0~3，Linux只用0和3，代表内核态和用户态    </p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gscxuu0jeyj30go0cw74y.jpg\" style=\"zoom:50%;\" alt=\"图三 80x86段寄存器\"></p>\n</li>\n</ul>\n<p>  <img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsd1lms0n9j31320re78r.jpg\" alt=\"图四 分级保护域\" style=\"zoom:30%;\"></p>\n<h4 id=\"2-1-3-段描述符\"><a href=\"#2-1-3-段描述符\" class=\"headerlink\" title=\"2.1.3 段描述符\"></a>2.1.3 段描述符</h4><p>​    每个段被一个8字节的段描述符（Segment Descriptor）表示，描述了段的特征。</p>\n<p>​    其放在 <em>全局描述符表（GDT - Global Descriptor Table）</em> 或 <em>局部描述符表 （LDT - Local Descriptor Table）</em> 中</p>\n<ul>\n<li><strong>全局描述符表（GDT - Global Descriptor Table）</strong><pre><code>- 特点：进程共享\n   - 存放：gdtr寄存器（基址+大小）\n</code></pre></li>\n<li><strong>局部描述符表 （LDT - Local Descriptor Table）</strong><ul>\n<li>特点：进程独享</li>\n<li>存放：ldtr寄存器（基址+大小）</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><strong>段描述符字段</strong></li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">字段名</th>\n<th style=\"text-align:left\">描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">Base</td>\n<td style=\"text-align:left\">包含段首字节的虚拟地址</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">G</td>\n<td style=\"text-align:left\">粒度标志，如果为0，则以字节为单位，否则以4096字节的倍数计算</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Limit</td>\n<td style=\"text-align:left\">存放段中最后一个内存单元的偏移量，来决定段的长度。G为0则段在1到1MB，否则在4KB到4GB</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">S</td>\n<td style=\"text-align:left\">系统标志，如果为0，则代表该段为系统段，储存LDT或其他关键数据结构，否则则是普通text或data段</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Type</td>\n<td style=\"text-align:left\">描述段的类型特征和存取权限</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">DPL</td>\n<td style=\"text-align:left\">描述符特权级（DPL）字段；限制对该段的存取。表示访问该段需要的最小 CPL （Linux 0/3）</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">P</td>\n<td style=\"text-align:left\">Segement-Present标志，0代表不在主存中，Linux总将此设为1，因为整个段一直都会在主存中</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">D or B</td>\n<td style=\"text-align:left\">取决于是代码段还是数据段</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">AVL 标志</td>\n<td style=\"text-align:left\">可被操作系统使用，但Linux忽略该标志</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><p><strong>描述符段分类</strong></p>\n<ul>\n<li>代码段描述符</li>\n<li>数据段描述符</li>\n<li>任务状态段描述符 （TSSD）<ul>\n<li>代表任务状态段（TSS）用于保存寄存器内容，仅在GDT中</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gscyouo50cj312s0u00yj.jpg\" alt=\"图五 段描述符格式\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n<h4 id=\"2-1-4-快速访问段描述符\"><a href=\"#2-1-4-快速访问段描述符\" class=\"headerlink\" title=\"2.1.4 快速访问段描述符\"></a>2.1.4 快速访问段描述符</h4><ul>\n<li><p><strong>段描述符的索引规则：</strong></p>\n<p>段基址 + 段选择符 index [13位] &lt;&lt; 3</p>\n<p>因此描述符最大数目为 $2^{13} - 1$</p>\n</li>\n</ul>\n<h4 id=\"2-1-5-分段单元\"><a href=\"#2-1-5-分段单元\" class=\"headerlink\" title=\"2.1.5 分段单元\"></a>2.1.5 分段单元</h4><p>​    图六已经较为清楚的展示了分段单元把逻辑地址转为虚拟地址的过程，段选择符在段寄存器中，offset存储在ip寄存器中</p>\n<p>​    <img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gscz202qbsj30yk0oqwgh.jpg\" alt=\"图六 逻辑地址翻译\" style=\"zoom:50%;\"></p>\n<h3 id=\"2-2-Linux-分段\"><a href=\"#2-2-Linux-分段\" class=\"headerlink\" title=\"2.2 Linux 分段\"></a>2.2 Linux 分段</h3><h4 id=\"2-2-1-Linux中的段结构\"><a href=\"#2-2-1-Linux中的段结构\" class=\"headerlink\" title=\"2.2.1 Linux中的段结构\"></a>2.2.1 Linux中的段结构</h4><p>​    2.6版的Linux只有在 80x86 结构下才进行分段，下图为Linux的分段结构    <img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsczhyx2exj31es0b2taa.jpg\" alt=\"图七 Linux分段\"></p>\n<p>​    所有段都从0x00000000开始，<strong>所以在Linux下，逻辑地址和虚拟地址相同</strong></p>\n<p>​    相应端选择符由宏 <code>__USER_CS</code>、<code>__USER_DS</code>、<code>__KERNEL_CS</code>、<code>__KERNEL_DS</code> 定义</p>\n<p>​    CPU的CPL存储在 cs 寄存器的 RPL 字段中，特权级别改变，某些段寄存器必须更新</p>\n<blockquote>\n<p>例如当CPL由 3 变为 0 时 ds寄存器必须从含有用户态数据段的段选择符变为含有内核数据段的段选择符，ss类似</p>\n</blockquote>\n<p>​    </p>\n<h4 id=\"2-2-2-Linux-GDT\"><a href=\"#2-2-2-Linux-GDT\" class=\"headerlink\" title=\"2.2.2 Linux GDT\"></a>2.2.2 Linux GDT</h4><p>​    每个CPU对应一个GDT，所有的GDT都存放在 cpu_gdt_table 里，所有的GDT地址和大小被存放在 cpu_gdt_descr数组中。</p>\n<p>​    这些符号在 arch/i386/kernel/head.S 中被定义</p>\n<p>​    每个GDT包含 18个段描述符和14个空的保留项，保留项保证了常用的描述符可以在同一个32字节的 Cache 中，防止 Cache 抖动。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsczztgg7mj312w0smdlz.jpg\" alt=\"图八 Linux GDT结构\" style=\"zoom:50%;\"></p>\n<p>​        </p>\n<h2 id=\"三、内存分页\"><a href=\"#三、内存分页\" class=\"headerlink\" title=\"三、内存分页\"></a>三、内存分页</h2><h3 id=\"3-1-硬件分页\"><a href=\"#3-1-硬件分页\" class=\"headerlink\" title=\"3.1 硬件分页\"></a>3.1 硬件分页</h3><p>​    分页单元（Paging Unit）是将虚拟地址转化为物理地址</p>\n<p>​    <strong>关键任务：</strong>是将所请求的访问类型和虚拟地址访问权限相比较，如果访问无效，则产生缺页异常</p>\n<p>​    <strong>页：</strong>一组虚拟地址，又指包含在这组地址中的数据。把RAM分成固定长度的页框（Page Frame）每个页框<em>（结构）</em>包含一个页<em>（数据）</em>。</p>\n<p>​    <strong>页表：</strong>将虚拟地址映射到物理地址的数据结构</p>\n<p>​    <strong>cr0寄存器：</strong>PG标志为0，虚拟地址就解释为物理地址，否则如果 PG = 1 代表启用分页。</p>\n<h3 id=\"3-2-Linux-分页\"><a href=\"#3-2-Linux-分页\" class=\"headerlink\" title=\"3.2 Linux 分页\"></a>3.2 Linux 分页</h3><p>​    Linux采用4级分页模式，节省内存空间花费，页表基址寄存器cr3</p>\n<ul>\n<li>页全局目录 （Page Global Directory）</li>\n<li>页上级目录（Page Upper DIrectory）</li>\n<li>页中间目录（Page Middle Directory）</li>\n<li>页表 （Page Table）</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsd0c0i81mj313s0mw41q.jpg\" alt=\"图九 Linux多级页表\" style=\"zoom:50%;\"></p>\n<p>​    如图九所示，虚拟地址翻译过程，其将虚拟地址分为五部分，标准页大小4kb，所以offset占12位，剩下 52 位 每 13 位代表相应目录偏移量，先取出cr3寄存器中页全局目录的基址，和偏移量相加，索引到下级页上级目录的极致，如此重复，直到索引到页表取出 PPN，由于物理地址偏移量和虚拟地址相同，所以直接和虚拟地址偏移量 VPO 拼接得到物理地址</p>\n<h4 id=\"3-2-1-分页机制的优势\"><a href=\"#3-2-1-分页机制的优势\" class=\"headerlink\" title=\"3.2.1 分页机制的优势\"></a>3.2.1 分页机制的优势</h4><p>​    虚拟地址到物理地址的自动转换使得下述设计目标变得现实</p>\n<ul>\n<li>给每个进程分配不同的物理地址空间，防止寻址错误</li>\n<li>区别页和页框不同，允许页被装入不同的页框中，是虚拟内存机制的基本要素</li>\n</ul>\n<p>每个进程有自己的页全局目录和页表集合，每次进行进程上下文切换时，Linux内核把前一个进程的cr3寄存器值存入在前一个进程的进程描述符中，并载入新进程的全局目录基址进入cr3寄存器中。</p>\n<h4 id=\"3-2-2-进程页表\"><a href=\"#3-2-2-进程页表\" class=\"headerlink\" title=\"3.2.2 进程页表\"></a>3.2.2 进程页表</h4><p>进程的虚拟内存空间被分为两部分</p>\n<ul>\n<li>用户态寻址部分：0x00000000 ~ 0xbfffffff</li>\n<li>内核态寻址部分：0xc0000000 ~ 0xffffffff </li>\n</ul>\n<p>进程运行在用户态时，其产生的线性地址小于 0xc0000000，在内核态则随意</p>\n<h4 id=\"3-2-3-内核页表\"><a href=\"#3-2-3-内核页表\" class=\"headerlink\" title=\"3.2.3 内核页表\"></a>3.2.3 内核页表</h4><p>​    内核有自己的一组页表，存放在主内核页全局目录中。主内核页全局目录的最高目录项部分作为参考模型，为系统中每个普通进程对应的页全局目录项提供参考模型。</p>\n<p>TODO</p>\n","site":{"data":{}},"excerpt":"","more":"<p><strong>说明：</strong> <em>本文基于第三版《深入理解 Linux 内核》，该部分以 80x86 处理器为基准进行介绍，并且略过了原文中详细介绍32位扩展分页部分</em></p>\n<h2 id=\"一、内存地址\"><a href=\"#一、内存地址\" class=\"headerlink\" title=\"一、内存地址\"></a>一、内存地址</h2><h3 id=\"1-1-逻辑地址-logic-address\"><a href=\"#1-1-逻辑地址-logic-address\" class=\"headerlink\" title=\"1.1 逻辑地址 (logic address)\"></a>1.1 逻辑地址 (logic address)</h3><p>​    在机器语言指令中用来指定一个操作数或一条指令的地址，每一个逻辑地址都由以下两部分组成</p>\n<ul>\n<li><p>段 （segment）指明段位置</p>\n</li>\n<li><p>偏移量 （offset）指明段开始处到实际地址的距离</p>\n</li>\n</ul>\n<h3 id=\"1-2-虚拟地址-virtual-address\"><a href=\"#1-2-虚拟地址-virtual-address\" class=\"headerlink\" title=\"1.2 虚拟地址 (virtual address)\"></a>1.2 虚拟地址 (virtual address)</h3><p>根据机器的位数不同而不同，32位机器即32位无符号整数、64位即64位无符号整数，这里取32位为例。</p>\n<ul>\n<li><p>可用于表达 $2^{32}$ 即 4GB 的地址空间</p>\n</li>\n<li><p>通常用16进制表示，值的范围从 0x00000000 ~ 0xffffffff</p>\n</li>\n</ul>\n<h3 id=\"1-3-物理地址-physical-address\"><a href=\"#1-3-物理地址-physical-address\" class=\"headerlink\" title=\"1.3 物理地址 (physical address)\"></a>1.3 物理地址 (physical address)</h3><p>​    内存芯片级的内存单元寻址，从CPU的地址引脚发送到内存总线上的电信号相对应，由 32 位或 36 位无符号整数表示</p>\n<h3 id=\"1-4-内存控制单元-MMU\"><a href=\"#1-4-内存控制单元-MMU\" class=\"headerlink\" title=\"1.4 内存控制单元 MMU\"></a>1.4 内存控制单元 MMU</h3><p>​    内存控制单元以下简称MMU，其集成在CPU上进行地址翻译，转换过程为两阶段</p>\n<ul>\n<li><strong>分段：</strong>由逻辑地址到虚拟地址</li>\n<li><strong>分页：</strong>由虚拟地址到物理地址</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsbz2jr0c4j319208475u.jpg\" alt=\"图1 逻辑地址翻译过程\"></p>\n<h3 id=\"1-5-内存仲裁器-MA\"><a href=\"#1-5-内存仲裁器-MA\" class=\"headerlink\" title=\"1.5 内存仲裁器 MA\"></a>1.5 内存仲裁器 MA</h3><p>​    在多核系统中，所有的CPU核心共享同一内存，则代表着CPU可以并发的访问内存。而内存的读写必须是串行执行，所以需要专用元器件对内存访问进行排序，其称为内存仲裁器。</p>\n<p>​    内存仲裁器是在内存总线和RAM芯片之间的硬件电路</p>\n<ul>\n<li><strong>若内存空闲：</strong>允许访问</li>\n<li><strong>若内存被占用：</strong>延迟CPU访问</li>\n</ul>\n<p><em>注：由于单处理器上存在一个叫做DMA控制器的特殊处理器，因此其实单处理器上也有内存仲裁器</em></p>\n<h3 id=\"1-6-分段和分页的意义\"><a href=\"#1-6-分段和分页的意义\" class=\"headerlink\" title=\"1.6 分段和分页的意义\"></a>1.6 分段和分页的意义</h3><p>分段和分页是用于划分进程的物理地址空间的</p>\n<ul>\n<li><strong>分段：</strong>每个进程分配不同的虚拟地址空间</li>\n<li><strong>分页：</strong>把同一虚拟地址空间映射到不同的物理地址</li>\n</ul>\n<p>Linux更多使用分页的方式</p>\n<ul>\n<li>不同进程共享同一组虚拟地址空间，内存管理简单</li>\n<li>跨平台，因为RISC体系结构对分段支持有限</li>\n</ul>\n<h2 id=\"二、内存分段\"><a href=\"#二、内存分段\" class=\"headerlink\" title=\"二、内存分段\"></a>二、内存分段</h2><h3 id=\"2-1-硬件分段\"><a href=\"#2-1-硬件分段\" class=\"headerlink\" title=\"2.1 硬件分段\"></a>2.1 硬件分段</h3><h4 id=\"2-1-1-实模式和保护模式\"><a href=\"#2-1-1-实模式和保护模式\" class=\"headerlink\" title=\"2.1.1 实模式和保护模式\"></a>2.1.1 <strong>实模式和保护模式</strong></h4><p>​    从 80286 模型开始，Intel处理器采用两种不同方式进行地址转换，称为实模式（real mode）和保护模式（protected mode）</p>\n<ul>\n<li><p><strong>实模式</strong></p>\n<p>​    其作用是为维持处理器和早期模型的兼容，因为早期寄存器位数太少，物理地址有20位，最多1MB的内存空间。而段基址寄存器有16位，最多只能访问64kb。为了访问64kb以上的空间，需要对内存进行分段，使用段基址+段偏移的模式寻址。</p>\n<p>​    通过 <code>物理地址 = 段基址 &lt;&lt; 4 + 段内偏移</code> 的方式表示物理地址。这个实模式的 “实” 体现在其反应的是真实物理地址。</p>\n<p>​    但是由于实模式没有区分代码和数据，如果用户程序的一个指针如果指向了系统程序区域或其他用户程序区域，并修改了内容，那么后果就很可能是灾难性的。</p>\n</li>\n</ul>\n<ul>\n<li><strong>保护模式</strong></li>\n</ul>\n<p>​    随着寄存器硬件的扩展，地址位数和寄存器位数都变成了32/64位，现代CPU已经不需要使用上述实模式了，当然为了兼容老版本所以还是得支持实模式。</p>\n<p>​    同时由于实模式不安全，我们通过一些手段来实现比较安全的寻址，这也是保护模式的命名的由来。</p>\n<ol>\n<li><p><strong>地址保护：</strong>程序内部的地址(虚拟地址)要由操作系统转化为物理地址去访问，程序对此一无所知</p>\n</li>\n<li><p><strong>边界保护：</strong> 段寄存器中不再储存的是段地址而是段索引。我们将数据放在一个叫做<strong>全局描述符表</strong>（GDT) 的结构中，其中表项称为段描述符，段描述符存放了段基址、段界限、内存段类型属性，用来索引段地址和标记段边界。</p>\n</li>\n</ol>\n<p>【Segmentation Fault 的出处】</p>\n<h4 id=\"2-1-2-段选择符和段寄存器\"><a href=\"#2-1-2-段选择符和段寄存器\" class=\"headerlink\" title=\"2.1.2 段选择符和段寄存器\"></a>2.1.2 <strong>段选择符和段寄存器</strong></h4><ul>\n<li><p><strong>段选择符</strong></p>\n<p>逻辑地址 = 段标识符 (16位) + 段偏移量 (32位)，我们又将段标识符称为段选择符，其结构如下图所示</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsc0cxl28uj319a08egmn.jpg\" alt=\"图二 段选择符\"></p>\n<ul>\n<li><p>index 描述符的入口，在2.1.4节中会详细讲解</p>\n</li>\n<li><p>TI （Table Indicator）标明段在GDT还是LDT中，在GDT中为0，LDT中为1</p>\n</li>\n<li><p>RPL 请求特权级，cs寄存器改变时指示出CPU当前特权级</p>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p><strong>段寄存器</strong></p>\n<p>段寄存器存放段选择符，段寄存器共有 cs，ss，ds，es，fs和gs六个，其作用如图三所示。</p>\n<p>注：cs寄存器中还有一个两位的字段，指明CPU当前特权级别（CPL）0~3，Linux只用0和3，代表内核态和用户态    </p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gscxuu0jeyj30go0cw74y.jpg\" style=\"zoom:50%;\" alt=\"图三 80x86段寄存器\"></p>\n</li>\n</ul>\n<p>  <img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsd1lms0n9j31320re78r.jpg\" alt=\"图四 分级保护域\" style=\"zoom:30%;\"></p>\n<h4 id=\"2-1-3-段描述符\"><a href=\"#2-1-3-段描述符\" class=\"headerlink\" title=\"2.1.3 段描述符\"></a>2.1.3 段描述符</h4><p>​    每个段被一个8字节的段描述符（Segment Descriptor）表示，描述了段的特征。</p>\n<p>​    其放在 <em>全局描述符表（GDT - Global Descriptor Table）</em> 或 <em>局部描述符表 （LDT - Local Descriptor Table）</em> 中</p>\n<ul>\n<li><strong>全局描述符表（GDT - Global Descriptor Table）</strong><pre><code>- 特点：进程共享\n   - 存放：gdtr寄存器（基址+大小）\n</code></pre></li>\n<li><strong>局部描述符表 （LDT - Local Descriptor Table）</strong><ul>\n<li>特点：进程独享</li>\n<li>存放：ldtr寄存器（基址+大小）</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><strong>段描述符字段</strong></li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">字段名</th>\n<th style=\"text-align:left\">描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">Base</td>\n<td style=\"text-align:left\">包含段首字节的虚拟地址</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">G</td>\n<td style=\"text-align:left\">粒度标志，如果为0，则以字节为单位，否则以4096字节的倍数计算</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Limit</td>\n<td style=\"text-align:left\">存放段中最后一个内存单元的偏移量，来决定段的长度。G为0则段在1到1MB，否则在4KB到4GB</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">S</td>\n<td style=\"text-align:left\">系统标志，如果为0，则代表该段为系统段，储存LDT或其他关键数据结构，否则则是普通text或data段</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Type</td>\n<td style=\"text-align:left\">描述段的类型特征和存取权限</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">DPL</td>\n<td style=\"text-align:left\">描述符特权级（DPL）字段；限制对该段的存取。表示访问该段需要的最小 CPL （Linux 0/3）</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">P</td>\n<td style=\"text-align:left\">Segement-Present标志，0代表不在主存中，Linux总将此设为1，因为整个段一直都会在主存中</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">D or B</td>\n<td style=\"text-align:left\">取决于是代码段还是数据段</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">AVL 标志</td>\n<td style=\"text-align:left\">可被操作系统使用，但Linux忽略该标志</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><p><strong>描述符段分类</strong></p>\n<ul>\n<li>代码段描述符</li>\n<li>数据段描述符</li>\n<li>任务状态段描述符 （TSSD）<ul>\n<li>代表任务状态段（TSS）用于保存寄存器内容，仅在GDT中</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gscyouo50cj312s0u00yj.jpg\" alt=\"图五 段描述符格式\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n<h4 id=\"2-1-4-快速访问段描述符\"><a href=\"#2-1-4-快速访问段描述符\" class=\"headerlink\" title=\"2.1.4 快速访问段描述符\"></a>2.1.4 快速访问段描述符</h4><ul>\n<li><p><strong>段描述符的索引规则：</strong></p>\n<p>段基址 + 段选择符 index [13位] &lt;&lt; 3</p>\n<p>因此描述符最大数目为 $2^{13} - 1$</p>\n</li>\n</ul>\n<h4 id=\"2-1-5-分段单元\"><a href=\"#2-1-5-分段单元\" class=\"headerlink\" title=\"2.1.5 分段单元\"></a>2.1.5 分段单元</h4><p>​    图六已经较为清楚的展示了分段单元把逻辑地址转为虚拟地址的过程，段选择符在段寄存器中，offset存储在ip寄存器中</p>\n<p>​    <img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gscz202qbsj30yk0oqwgh.jpg\" alt=\"图六 逻辑地址翻译\" style=\"zoom:50%;\"></p>\n<h3 id=\"2-2-Linux-分段\"><a href=\"#2-2-Linux-分段\" class=\"headerlink\" title=\"2.2 Linux 分段\"></a>2.2 Linux 分段</h3><h4 id=\"2-2-1-Linux中的段结构\"><a href=\"#2-2-1-Linux中的段结构\" class=\"headerlink\" title=\"2.2.1 Linux中的段结构\"></a>2.2.1 Linux中的段结构</h4><p>​    2.6版的Linux只有在 80x86 结构下才进行分段，下图为Linux的分段结构    <img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsczhyx2exj31es0b2taa.jpg\" alt=\"图七 Linux分段\"></p>\n<p>​    所有段都从0x00000000开始，<strong>所以在Linux下，逻辑地址和虚拟地址相同</strong></p>\n<p>​    相应端选择符由宏 <code>__USER_CS</code>、<code>__USER_DS</code>、<code>__KERNEL_CS</code>、<code>__KERNEL_DS</code> 定义</p>\n<p>​    CPU的CPL存储在 cs 寄存器的 RPL 字段中，特权级别改变，某些段寄存器必须更新</p>\n<blockquote>\n<p>例如当CPL由 3 变为 0 时 ds寄存器必须从含有用户态数据段的段选择符变为含有内核数据段的段选择符，ss类似</p>\n</blockquote>\n<p>​    </p>\n<h4 id=\"2-2-2-Linux-GDT\"><a href=\"#2-2-2-Linux-GDT\" class=\"headerlink\" title=\"2.2.2 Linux GDT\"></a>2.2.2 Linux GDT</h4><p>​    每个CPU对应一个GDT，所有的GDT都存放在 cpu_gdt_table 里，所有的GDT地址和大小被存放在 cpu_gdt_descr数组中。</p>\n<p>​    这些符号在 arch/i386/kernel/head.S 中被定义</p>\n<p>​    每个GDT包含 18个段描述符和14个空的保留项，保留项保证了常用的描述符可以在同一个32字节的 Cache 中，防止 Cache 抖动。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsczztgg7mj312w0smdlz.jpg\" alt=\"图八 Linux GDT结构\" style=\"zoom:50%;\"></p>\n<p>​        </p>\n<h2 id=\"三、内存分页\"><a href=\"#三、内存分页\" class=\"headerlink\" title=\"三、内存分页\"></a>三、内存分页</h2><h3 id=\"3-1-硬件分页\"><a href=\"#3-1-硬件分页\" class=\"headerlink\" title=\"3.1 硬件分页\"></a>3.1 硬件分页</h3><p>​    分页单元（Paging Unit）是将虚拟地址转化为物理地址</p>\n<p>​    <strong>关键任务：</strong>是将所请求的访问类型和虚拟地址访问权限相比较，如果访问无效，则产生缺页异常</p>\n<p>​    <strong>页：</strong>一组虚拟地址，又指包含在这组地址中的数据。把RAM分成固定长度的页框（Page Frame）每个页框<em>（结构）</em>包含一个页<em>（数据）</em>。</p>\n<p>​    <strong>页表：</strong>将虚拟地址映射到物理地址的数据结构</p>\n<p>​    <strong>cr0寄存器：</strong>PG标志为0，虚拟地址就解释为物理地址，否则如果 PG = 1 代表启用分页。</p>\n<h3 id=\"3-2-Linux-分页\"><a href=\"#3-2-Linux-分页\" class=\"headerlink\" title=\"3.2 Linux 分页\"></a>3.2 Linux 分页</h3><p>​    Linux采用4级分页模式，节省内存空间花费，页表基址寄存器cr3</p>\n<ul>\n<li>页全局目录 （Page Global Directory）</li>\n<li>页上级目录（Page Upper DIrectory）</li>\n<li>页中间目录（Page Middle Directory）</li>\n<li>页表 （Page Table）</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsd0c0i81mj313s0mw41q.jpg\" alt=\"图九 Linux多级页表\" style=\"zoom:50%;\"></p>\n<p>​    如图九所示，虚拟地址翻译过程，其将虚拟地址分为五部分，标准页大小4kb，所以offset占12位，剩下 52 位 每 13 位代表相应目录偏移量，先取出cr3寄存器中页全局目录的基址，和偏移量相加，索引到下级页上级目录的极致，如此重复，直到索引到页表取出 PPN，由于物理地址偏移量和虚拟地址相同，所以直接和虚拟地址偏移量 VPO 拼接得到物理地址</p>\n<h4 id=\"3-2-1-分页机制的优势\"><a href=\"#3-2-1-分页机制的优势\" class=\"headerlink\" title=\"3.2.1 分页机制的优势\"></a>3.2.1 分页机制的优势</h4><p>​    虚拟地址到物理地址的自动转换使得下述设计目标变得现实</p>\n<ul>\n<li>给每个进程分配不同的物理地址空间，防止寻址错误</li>\n<li>区别页和页框不同，允许页被装入不同的页框中，是虚拟内存机制的基本要素</li>\n</ul>\n<p>每个进程有自己的页全局目录和页表集合，每次进行进程上下文切换时，Linux内核把前一个进程的cr3寄存器值存入在前一个进程的进程描述符中，并载入新进程的全局目录基址进入cr3寄存器中。</p>\n<h4 id=\"3-2-2-进程页表\"><a href=\"#3-2-2-进程页表\" class=\"headerlink\" title=\"3.2.2 进程页表\"></a>3.2.2 进程页表</h4><p>进程的虚拟内存空间被分为两部分</p>\n<ul>\n<li>用户态寻址部分：0x00000000 ~ 0xbfffffff</li>\n<li>内核态寻址部分：0xc0000000 ~ 0xffffffff </li>\n</ul>\n<p>进程运行在用户态时，其产生的线性地址小于 0xc0000000，在内核态则随意</p>\n<h4 id=\"3-2-3-内核页表\"><a href=\"#3-2-3-内核页表\" class=\"headerlink\" title=\"3.2.3 内核页表\"></a>3.2.3 内核页表</h4><p>​    内核有自己的一组页表，存放在主内核页全局目录中。主内核页全局目录的最高目录项部分作为参考模型，为系统中每个普通进程对应的页全局目录项提供参考模型。</p>\n<p>TODO</p>\n"},{"title":"「论文阅读」The Unix Time-Sharing System","date":"2021-11-15T23:29:48.000Z","index_img":"/img/OS/banner.png","math":true,"_content":"\n# The Unix Time-Sharing System\n*DENNIS M. RITCHIE AND KEN THOMPSON*\n\n## 1. 基本介绍\n\n### 1.1 Unix 的历史进程\n\n​\tMultics，名称来自于多任务信息与计算系统（MULTiplexed Information and Computing System）的缩写，它是一套分时多任务，是1964年由贝尔实验室、MIT及美国通用电气公司所共同参与研发，其在GE 645上开发和部署。\n\n​\t1969 贝尔实验室退出 Multics 的开发，DENNIS M. RITCHIE & KEN THOMPSON 一同开发了 Unix，\n\n​\t一开始Unix是在 *Digital PDP-7*  使用汇编语言进行编写，*1971*年，*Ken Thompson* 申请到了一台 *PDP-11/24*的 机器，于是*Unix*第二版出来了。*1973* 用C重写了Unix，形成了Unix Version 4，第四版运行在更新的PDP-ll/40, /45上\n\n​\t直到*1974*年*7*月 DENNIS M. RITCHIE 和 KEN THOMPSON 在  *the Communications of the ACM* 发表了 *The Unix Time-Sharing System* 让Unix系统第一次广泛的为学界所了解。\n\n<img src=\"https://n3x0.com/wp-content/uploads/2019/10/unix-co-founder-ken-thompsons-bsd-password-has-finally-been-cracked.jpg\" style=\"zoom:50%;\" />\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwen89cbzej30pd0jft9z.jpg\" style=\"zoom:100%;\" />\n\n\n\n### 1.2 Unix 的特点\n\n​\tUNIX 是一个**多用途 (general-purpose)，多用户 (multi-user), 交互式(interactive)** 的操作系统\n\n- **层级**的文件系统\n- **兼容**的文件，设备和内部处理I/O\n- 初始化异步进程的能力\n- 对每个用户都可选的系统命令行语言\n- 用多种语言实现的超过100个子系统\n\n\n\n**[讨论问题1] 如何理解此处的 “初始化异步进程的能力” （the ability to initiate asynchronous processes）的含义**\n\n<p hidden>\n\t分时操作系统 (Time Sharing)\n  在上世纪50年代末60年代早期，很多操作系统还处于批处理时期（batch processing）\n  单一进程长时间独享CPU\n</p>\n\n### 1.3 关于Time Sharing \n\n​\t 其实Unix算是比较晚出现的分时操作系统，分时的概念最早在1954年被 [John Backus](https://en.wikipedia.org/wiki/John_Backus) 在 MIT提出\n\n> The computers would handle a number of problems concurrently. Organizations would have input-output equipment installed on their own premises and would **buy time** on the computer much the same way that the average household buys power and water from utility companies.\n\n​\t [John McCarthy](https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)) at MIT in 1959 第一个实现了分时操作系统, 并一开始部署在 IBM704上，后面该版本的一个分支被认为是最早的一个分时系统即 CTSS。\n\n\n\n## 2. 文件系统\n\n> Everything is a file\n\n​\tUNIX中最重要的的工作是提供了一个文件系统。从用户的角度看，一共有三种类型的文件：普通磁盘文件、目录、特殊文件\n\n### 2.1 普通文件\n\n​\t一个文件可以包含用户放置的任何类型的信息，例如符号或者二进制(对象)或程序。不需为系统指定特定的数据结构。\n\n**文本文件**：包含简单的、由换行符分隔段落的字符串。\n\n**二进制文件**：是当程序开始执行时，将会在出现在核心内存中的，按顺序存放的字的序列。\n\n少数用户程序以更多样的方式组织文件结构，来实现更多的功能。例如汇编生成器和加载器需要特定格式的对象文件。\n\n总之，普通文件的结构是由用户程序来管理的而非操作系统。\n\n\n\n### 2.2 目录\n\n> Directories provide the mapping between the names of files and the files themselves, and thus induce a structure on the file system as a whole.\n\n#### 2.2.1 目录性质\n\n​\t每个用户都有一个自己文件的目录；他还可以方便地创建包含文件群组的子目录。目录的行为与普通文件完全相同，不同之处在于目录无法由非特权程序写入，只有系统可以控制目录的内容。但是，具有合适权限的任何人都可以像读取其他任何文件一样读取目录。\n\n- 1. 层级架构\n\n- 2. 用户隔离\n- 3. 权限控制\n\n#### 2.2.2 目录内容\n\n​\t系统维护几个目录供自己使用。其中之一是根目录 *(root)*。通过跟踪目录链中的路径直到找到所需的文件，可以找到系统中的所有文件。\n\n​\t另一个系统目录*（/bin）*包含所有通常需要使用的程序，即所有的**命令**。但是就如将看到的，程序不必驻留在此目录中即可执行。\n\n#### 2.2.3 链接\n\n​\t同一个非目录文件可能会以不同的名称出现在多个目录中，就是我们熟知的链接。\n\n​\tUNIX与其他允许链接的系统不同，它与文件的所有链接都具有相同的状态。也就是说，文件在特定目录中不存在。文件的目录条目仅由其名称和指向实际描述文件的信息的指针组成，**因此，文件实际上独立于任何目录条目而存在，尽管实际上会使该文件与最后一个链接一起消失。**\n\n**[讨论问题2] 如何理解文件实际上独立于任何目录条目而存在，尽管实际上会使该文件与最后一个链接一起消失**\n\n其实就是文件inode的link count和文件描述符的reference count，当二者都掉为0的时候，文件就会被操作系统回收。\n\n​\t目录结构被限定为为有根树的形式。除特殊条目 `.` 和 `..` 外，每个目录必须作为另外一个目录（即其父目录）的条目出现，这是为了简化访问目录结构子树的程序的编写，更重要的是避免层次结构各部分的分离。如果允许链接到任意目录，则很难检测到从根到目录的最后一次连接何时断开。(即出现环)\n\n\n\n### 2.3 特殊文件\n\n> Special files constitute the most unusual feature of the UNiX file system.\n\n**将外部设备抽象成一种文件**\n\n​\tUNIX支持的每个 I/O 设备都与至少一个这样的文件相关联。特殊文件的读取和写入与普通磁盘文件一样，但是请求读取或写入会导致关联设备的激活。每个特殊文件的条目都位于目录/dev中，尽管可以像普通文件一样链接到其中一个文件。因此，例如要打孔纸带，可以在文件/dev/ppt上写。每个通信线路，每个磁盘，每个磁带驱动器以及物理核心内存都存在特殊文件。当然，活动磁盘和核心专用文件受到保护，不会受到任意访问。\n\n**[讨论问题3] 这样抽象有什么好处？**\n\n- 文件和I/O设备尽可能相似\n- 文件名和设备名具有相同的语法和含义，因此可以将以文件名作为参数的程序传递给设备名。\n- 权限控制（设备作为特殊文件可以和普通文件一样有权限控制机制）\n即程序不再需要关心他在和什么设备进行交互，只需要使用一个统一的文件接口即可。\n\n\n#### 2.3.1 可移除的文件系统\n\n​\t尽管文件系统的根目录始终存储在同一设备上，但是不必将整个文件系统层次结构都驻留在该设备上。\n\n​\tmount用一个全新的子树（存储在可移动卷上的层次结构）替换层次结构树（普通文件）的叶子。挂载之后，可移动卷上的文件与永久文件系统上的文件之间几乎没有区别。\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gweqa094umj30hd097mxw.jpg)\n\n**[讨论问题5] 我们说当mount之后子树的文件和原来的文件系统上的文件几乎没有区别，那么区别在哪？**\n\n我们不能跨越 mount point 创建 hard link，即不能创建从原来文件系统到挂载的文件树上的hard link\n\n\n#### 2.3.2 文件保护\n\n​\t系统的每个用户都分配有一个唯一的用户标识号（UID）。当创建文件后，将会使用文件所有者的用户ID对其进行标记，还会为新文件提供一个七比特的保护位，其中六个指定文件所有者和所有其他用户的独立读取，写入和执行权限。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gweq5c1xrhj30go0b4wf3.jpg\" style=\"zoom:67%;\" />\n\n- **SetUid位**\n\n  当文件或程序(统称为executable)被执行时, 操作系统会赋予文件**所有者的权限**\n\n  这个位可以用来提供特权程序，在特定规则下访问修改其不能修改的文件。\n\n**[讨论问题4] 能否举一个用到setuid的例子**\n\n类Unix系统的密码一般是放置在“/etc/paswd”和“/etc/shadow”中\n普通用户没有读写权限，用户如何更改密码？\n实际上就是利用 passwd 程序的 setuid 位为on，在执行过程中，将用户身份变为ROOT\n这样普通用户在执行“passwd”命令时，实际上以有效用户root的身份来执行的，并具有了相应的权限\n\n\n#### 2.3.3 I/O请求 \n\n​\t系统的I/O调用旨在消除各种设备和访问方式之间的差异。 “随机”和“顺序”的I/O之间没有区别，系统也不施加任何逻辑记录大小。普通文件的大小由写入文件的最高字节决定，不需要也不可能预先确定文件的大小。\n\n​\t文件系统中没有用户可见的锁，对于可以打开文件进行读取或写入的用户数量也没有任何限制；尽管当两个用户同时写入文件时文件的内容可能会被打乱，但实际上不会出现困难。他们是不必要且不足够的。\n\n**[讨论问题6] 为什么说给限制用户的读写加锁是不必要也不足够的？**\n\n不必要是因为我们并不是维护一个单进程管理的单文件的大数据库，我们不需要保证文件内容的一致性。只需要保证整个文件系统的逻辑一致即可。\n不足够是因为普通意义上的锁来说，即当一个用户在读的时候另一个用户不能写，但这样也无法完全避免混淆。\n[for example, both users are editing a file with an editor which makes a copy of the file being edited.]\n\n​\t应该说，当两个用户同时从事诸如写同一文件，在同一目录中创建文件或删除彼此的打开文件之类的不便活动时，该系统具有足够的内部联锁来维持文件系统的逻辑一致性。\n\n\n\n#### 2.3.4 文件系统的实现\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gwern4drsjj30cv08a3yw.jpg)\n\n​\t一个目录条目包含一个关联到文件的名字和一个指向自身的指针。这个指针是一个叫`i-number`的整型数。当文件被访问时，它的`i-number`被用作系统表(`i-list`)的索引\n\n1. 所有者 \n2. 保护位\n3. 文件内容的物理磁盘或磁带的地址\n4. 大小\n5. 上次修改时间\n6. 到文件的链接数，也就是文件在目录中出现的次数； \n7. 一个表示文件是否是目录的bit\n8. 一个表示文件是否属于特殊文件的bit\n9. 一个表示文件是大还是小的bit\n\n所有固定或可移除磁盘的空间都被划分为512字节的块，地址空间从0到设备本身的容量上限\n\n- **Inode**\n\n​\t每个文件的inode中都留有8个块的设备地址空间，一个小文件（即 $\\le512*8 bytes$) 可以直接被储存，大文件则是8个indirect block每个最多指向256个块，这样最大可以存储下 $8\\times256\\times512=2^{20} bytes$ 的最大文件容量\n\n- **Buffer Cache**\n\n​\t对于用户而言，文件的读写都是同步且没有缓存的。在read系统调用返回后，数据马上可用。而且很方便的是，在write系统调用之后，用户的工作空间可以重复使用。实际上系统维护了一个复杂的缓存机制，来大幅度降低访问文件所需要的I/O操作数。\n\n​\tUnix会查找缓冲区以确定受影响的磁盘块当前是否在主存中。如果不是，将从设备上读取。缓冲区中的对应的字节被替换，然后在待写入块列表中创建一个条目。write系统调用返回，尽管实际上I/O会晚一点才完成。相反的是，如果读取一个单独的字节，系统会确定该具有该字节是否已经在缓冲区中，如果是，该字节会被立刻返回。如果不是，这个块将被读取到缓冲区，然后取出该字节。\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gwew5xspc1j30bg083weq.jpg)\n\n- **I-list**\n\n> The notion of the i-list is an unusual feature of UNIX\n\n​\ti-list架构独立于目录的层级关系，只需要对线性的i-list做一系列操作就可以很好的组织维护文件系统。\n\n​\t但同时i-list的设计引起了一些奇怪的问题，例如，谁应该负责文件所占用的空间。*（既然一个文件的所有目录条目都具有相同的状态，文件的所有者负责是不公平的）*\n\n**[讨论问题5] 为什么说文件的所有者负责是不公平的？**\n\n一个用户可能会创建文件，另一个用户可能会链接到这个文件，而第一个用户可能会删除文件。第一个用户仍然是文件的所有者，但是他应该对第二个用户负责，这是不合理的。\n\n\n\n## 3. 进程和映像\n\n### 3.1 进程映像\n\n​\t映像（image）其实就是我们熟知的进程上下文。它包括核心映像，通用寄存器的值，打开的文件，当前目录等内容。\n\n<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20200514150923/process1.png\" style=\"zoom:80%;\" />\n\n​\t进程是一个映像的执行。当处理器代表一个进程去执行时，映像要驻留在核心内存中。在其他进程的执行过程中，它仍然驻留在核心内存中，除非一个高优先级的进程强制性的把它从内存中交换到固定磁头的磁盘驱动器上。\n\n从高地址到低地址分为三段\n\n- **栈段**（由上之下增长）\n\n- **数据段**\n\n  可写非共享，可向上扩展\n\n- **代码段**（写保护）\n\n  单一拷贝被执行所有相同程序的进程共享。\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gwetekcbeej309409mdg9.jpg)\n\n\n\n### 3.2 进程\n\n​\t除了Unix引导它自身进入运行中（init 进程），只能通过使用fork系统调用创建一个新的进程。\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gwetk06jscj30di049t8s.jpg)\n\n​\t当一个进程执行fork系统调用，它会被分离成两个独立的执行进程。这两个进程有各自独立的源印象的拷贝，并共享所有打开的文件。\n\n### 3.3 管道\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gwetv8ny0tj30e606dt8v.jpg)\n\n​\t非常聪明的IPC机制，A只要一端如同写普通文件一样写入，B在另一端准备读取即可。A,B可以并发的执行，并且相比临时文件，在内存中的buffer不会有额外的磁盘I/O消耗。\n\n## 4. Unix Shell\n\n> For most users, communication with UNIX is carried on with the aid of a program called the Shell. (Interactive)\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gweu4951cfj309a09h3ys.jpg)\n\n​\t在最简单的情况下，一个命令行由命令名和跟随的参数组成，命令名和参数之间通过空格分隔。\n\n```text\ncommand arg1 arg2 ... argn\n```\n\n​\tShell将命令名和参数分割为独立的字符串，这样就能找到名为command的文件。command可能是一个包含\"/\"的路径名以指出系统中的任何文件。如果command被找到，它将被引入到核心内存中被执行。Shell收集到的参数对于command是可访问的。Shell重新回到自己的执行当中，并立刻准备接受用户输入的下一条命令。\n\n### 4.1 标准I/O\n\n​\t设定 ```std_in = 0```、```std_out = 1```、```std_err = 2```，这样做有什么好处？\n\n​\t在Unix之前，很多程序没有建立输入输出的过程，而操作系统通常采用比较复杂的 [Job Control Language](https://en.wikipedia.org/wiki/Job_Control_Language) 脚本来建立输入输出的连接。\n\n​\t而Unix将输入输出默认连接到终端的键盘输入和终端的显示器上，以预定义的形式免去了很多不必要的工作。\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gweunbmq9rj30gv090756.jpg)\n\n## 5. 陷入\n\n### 5.1 故障\n\n​\tPDP-11硬件检测到程序错误，例如对不存在的内存的引用。此类故障会导致CPU陷入内核。当发现非法行为时，除非做出其他安排，否则系统会终止该进程，并将image 写入当前目录中。(Core Dump)\n\n### 5.2 中断 (interrupt)\n\n​\t程序产生了未预期的输出，可以通过键入“delete” 字符生成一个 `interrupt` 信号来停止程序，并且这个信号之后导致程序停止而不会 Core Dump。\n\n\n\n## 6. Unix 设计哲学\n\n### 6.1 简洁 (Simplicity)\n\n> First, since we are programmers, we naturally designed the system to make it easy to write, test, and run programs.\n\n- **User Friendly**\n\n  ​\t系统以使其易于编写，测试和运行程序。对编程便利性的渴望的最重要表达是该系统被安排用于交互 (interactive) 使用，即使原始版本仅支持一个用户。\n\n  ​\t我们认为，设计合理的交互式系统比“批处理”系统更具生产力和使用满意度。而且，这样的系统相当容易适应于非交互使用，而反之则不成立。\n\n- **File Tree**\n\n  层级的目录结构，让文件管理十分简洁清晰。\n\n- **File Abstract**\n\n  一切皆是文件，将外部设备和目录统一抽象为文件，统一管理，代码复用而高效。所谓 Less is More\n\n  \n\n### 6.2 易于部署 (Flexiblility)\n\n> UNIX can run on hardware costing as little as $40,000, and less than two man-years were spent on the main system software.\n\n​\t用于安装UNIX系统的 PDP-11/45 是一个16位字长（8-bit byte），具有144K字节(byte)核心内存的计算机；UNIX占用了其中的42kb。然而这个系统包括了大量的设备驱动并且为I/O缓冲区和系统表分配了足够的空间；一个能够运行上述软件的最小系统，最小总共只需要 50kb 的内核。\n\n\n\n### 6.3 可维护性 (Maintainable)\n\n> Third, nearly from the start, the system was able to, and did, maintain itself.\n\n​\t由于实现的简洁性，系统可维护性很好，从1972~1973年DENNIS M. RITCHIE AND KEN THOMPSON 用B和C相继重写了Unix内核后，用高级语言开发的Unix有着很好的可移植和迭代能力。\n\n\n\n**[讨论问题7] 你认为是什么让Unix如此成功？**\n1. 设计哲学\n  Unix 虽然不是最早的分时操作系统，但其提出的一系列颠覆性的概念可以说重塑了操作系统界很多实现的范式，包括层级的文件系统以及一切皆文件的思想，一直延续至今。在如今看来这些好似稀松平常的概念，在当时的视角下是绝不trivial的想法。\n2. 时代背景\n  在Multics的衬托下，Unix继承了Multics的功能，以其简单而有效的设计模式启发了大家，获得了商业上的巨大成功。\n\t可以说Unix的成功，是因为其出现在一个对的时间，并且做了对的事情。\n  同样我们在回顾 UNIX 的设计发展历程的时候，对我们当今设计和进一步优化目前的操作系统有指导意义，可以说是以史为鉴，让我们能够洞见未来的发展。\n\n\n### The Unix Family Tree\n\n![](http://www.netneurotic.net/mac/unix/images/UNIXthumb.png)\n\n\n\n\n\n\n\n## Reference\n\n[1] [Ritchie, D.M.](https://en.wikipedia.org/wiki/Dennis_Ritchie); [Thompson, K.](https://en.wikipedia.org/wiki/Ken_Thompson) (July–August 1978). [\"The UNIX Time-Sharing System\"](https://web.archive.org/web/20101103053325/http://bstj.bell-labs.com/oldfiles/year.1978/BSTJ.1978.5706-2.html). *[Bell System Technical Journal](https://en.wikipedia.org/wiki/Bell_System_Technical_Journal)*. **57** (6). Archived from [the original](http://bstj.bell-labs.com/oldfiles/year.1978/BSTJ.1978.5706-2.html) on November 3, 2010.\n\n[2] [\"UNIX History\"](http://www.levenez.com/unix/). *www.levenez.com*. Retrieved March 17, 2005.\n\n[3] [\"AIX, FreeBSD, HP-UX, Linux, Solaris, Tru64\"](http://www.unixguide.net/). *UNIXguide.net*. Retrieved March 17, 2005.\n\n[4] [\"Linux Weekly News, February 21, 2002\"](https://lwn.net/2002/0221/bigpage.php3). *lwn.net*. Retrieved April 7, 2006.\n\n[5] [Lions, John](https://en.wikipedia.org/wiki/John_Lions): *Lions' [\"Commentary on the Sixth Edition UNIX Operating System\"](http://www.lemis.com/grog/Documentation/Lions/). with Source Code*, Peer-to-Peer Communications, 1996; [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier)) [1-57398-013-7](https://en.wikipedia.org/wiki/Special:BookSources/1-57398-013-7)\n\n\n\n\n\n","source":"_posts/OS/Unix.md","raw":"---\ntitle: 「论文阅读」The Unix Time-Sharing System\ndate: 2021-11-15 15:29:48\nindex_img: /img/OS/banner.png\ncategory: [OS]\ntags: [OS]\nmath: true\n---\n\n# The Unix Time-Sharing System\n*DENNIS M. RITCHIE AND KEN THOMPSON*\n\n## 1. 基本介绍\n\n### 1.1 Unix 的历史进程\n\n​\tMultics，名称来自于多任务信息与计算系统（MULTiplexed Information and Computing System）的缩写，它是一套分时多任务，是1964年由贝尔实验室、MIT及美国通用电气公司所共同参与研发，其在GE 645上开发和部署。\n\n​\t1969 贝尔实验室退出 Multics 的开发，DENNIS M. RITCHIE & KEN THOMPSON 一同开发了 Unix，\n\n​\t一开始Unix是在 *Digital PDP-7*  使用汇编语言进行编写，*1971*年，*Ken Thompson* 申请到了一台 *PDP-11/24*的 机器，于是*Unix*第二版出来了。*1973* 用C重写了Unix，形成了Unix Version 4，第四版运行在更新的PDP-ll/40, /45上\n\n​\t直到*1974*年*7*月 DENNIS M. RITCHIE 和 KEN THOMPSON 在  *the Communications of the ACM* 发表了 *The Unix Time-Sharing System* 让Unix系统第一次广泛的为学界所了解。\n\n<img src=\"https://n3x0.com/wp-content/uploads/2019/10/unix-co-founder-ken-thompsons-bsd-password-has-finally-been-cracked.jpg\" style=\"zoom:50%;\" />\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwen89cbzej30pd0jft9z.jpg\" style=\"zoom:100%;\" />\n\n\n\n### 1.2 Unix 的特点\n\n​\tUNIX 是一个**多用途 (general-purpose)，多用户 (multi-user), 交互式(interactive)** 的操作系统\n\n- **层级**的文件系统\n- **兼容**的文件，设备和内部处理I/O\n- 初始化异步进程的能力\n- 对每个用户都可选的系统命令行语言\n- 用多种语言实现的超过100个子系统\n\n\n\n**[讨论问题1] 如何理解此处的 “初始化异步进程的能力” （the ability to initiate asynchronous processes）的含义**\n\n<p hidden>\n\t分时操作系统 (Time Sharing)\n  在上世纪50年代末60年代早期，很多操作系统还处于批处理时期（batch processing）\n  单一进程长时间独享CPU\n</p>\n\n### 1.3 关于Time Sharing \n\n​\t 其实Unix算是比较晚出现的分时操作系统，分时的概念最早在1954年被 [John Backus](https://en.wikipedia.org/wiki/John_Backus) 在 MIT提出\n\n> The computers would handle a number of problems concurrently. Organizations would have input-output equipment installed on their own premises and would **buy time** on the computer much the same way that the average household buys power and water from utility companies.\n\n​\t [John McCarthy](https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)) at MIT in 1959 第一个实现了分时操作系统, 并一开始部署在 IBM704上，后面该版本的一个分支被认为是最早的一个分时系统即 CTSS。\n\n\n\n## 2. 文件系统\n\n> Everything is a file\n\n​\tUNIX中最重要的的工作是提供了一个文件系统。从用户的角度看，一共有三种类型的文件：普通磁盘文件、目录、特殊文件\n\n### 2.1 普通文件\n\n​\t一个文件可以包含用户放置的任何类型的信息，例如符号或者二进制(对象)或程序。不需为系统指定特定的数据结构。\n\n**文本文件**：包含简单的、由换行符分隔段落的字符串。\n\n**二进制文件**：是当程序开始执行时，将会在出现在核心内存中的，按顺序存放的字的序列。\n\n少数用户程序以更多样的方式组织文件结构，来实现更多的功能。例如汇编生成器和加载器需要特定格式的对象文件。\n\n总之，普通文件的结构是由用户程序来管理的而非操作系统。\n\n\n\n### 2.2 目录\n\n> Directories provide the mapping between the names of files and the files themselves, and thus induce a structure on the file system as a whole.\n\n#### 2.2.1 目录性质\n\n​\t每个用户都有一个自己文件的目录；他还可以方便地创建包含文件群组的子目录。目录的行为与普通文件完全相同，不同之处在于目录无法由非特权程序写入，只有系统可以控制目录的内容。但是，具有合适权限的任何人都可以像读取其他任何文件一样读取目录。\n\n- 1. 层级架构\n\n- 2. 用户隔离\n- 3. 权限控制\n\n#### 2.2.2 目录内容\n\n​\t系统维护几个目录供自己使用。其中之一是根目录 *(root)*。通过跟踪目录链中的路径直到找到所需的文件，可以找到系统中的所有文件。\n\n​\t另一个系统目录*（/bin）*包含所有通常需要使用的程序，即所有的**命令**。但是就如将看到的，程序不必驻留在此目录中即可执行。\n\n#### 2.2.3 链接\n\n​\t同一个非目录文件可能会以不同的名称出现在多个目录中，就是我们熟知的链接。\n\n​\tUNIX与其他允许链接的系统不同，它与文件的所有链接都具有相同的状态。也就是说，文件在特定目录中不存在。文件的目录条目仅由其名称和指向实际描述文件的信息的指针组成，**因此，文件实际上独立于任何目录条目而存在，尽管实际上会使该文件与最后一个链接一起消失。**\n\n**[讨论问题2] 如何理解文件实际上独立于任何目录条目而存在，尽管实际上会使该文件与最后一个链接一起消失**\n\n其实就是文件inode的link count和文件描述符的reference count，当二者都掉为0的时候，文件就会被操作系统回收。\n\n​\t目录结构被限定为为有根树的形式。除特殊条目 `.` 和 `..` 外，每个目录必须作为另外一个目录（即其父目录）的条目出现，这是为了简化访问目录结构子树的程序的编写，更重要的是避免层次结构各部分的分离。如果允许链接到任意目录，则很难检测到从根到目录的最后一次连接何时断开。(即出现环)\n\n\n\n### 2.3 特殊文件\n\n> Special files constitute the most unusual feature of the UNiX file system.\n\n**将外部设备抽象成一种文件**\n\n​\tUNIX支持的每个 I/O 设备都与至少一个这样的文件相关联。特殊文件的读取和写入与普通磁盘文件一样，但是请求读取或写入会导致关联设备的激活。每个特殊文件的条目都位于目录/dev中，尽管可以像普通文件一样链接到其中一个文件。因此，例如要打孔纸带，可以在文件/dev/ppt上写。每个通信线路，每个磁盘，每个磁带驱动器以及物理核心内存都存在特殊文件。当然，活动磁盘和核心专用文件受到保护，不会受到任意访问。\n\n**[讨论问题3] 这样抽象有什么好处？**\n\n- 文件和I/O设备尽可能相似\n- 文件名和设备名具有相同的语法和含义，因此可以将以文件名作为参数的程序传递给设备名。\n- 权限控制（设备作为特殊文件可以和普通文件一样有权限控制机制）\n即程序不再需要关心他在和什么设备进行交互，只需要使用一个统一的文件接口即可。\n\n\n#### 2.3.1 可移除的文件系统\n\n​\t尽管文件系统的根目录始终存储在同一设备上，但是不必将整个文件系统层次结构都驻留在该设备上。\n\n​\tmount用一个全新的子树（存储在可移动卷上的层次结构）替换层次结构树（普通文件）的叶子。挂载之后，可移动卷上的文件与永久文件系统上的文件之间几乎没有区别。\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gweqa094umj30hd097mxw.jpg)\n\n**[讨论问题5] 我们说当mount之后子树的文件和原来的文件系统上的文件几乎没有区别，那么区别在哪？**\n\n我们不能跨越 mount point 创建 hard link，即不能创建从原来文件系统到挂载的文件树上的hard link\n\n\n#### 2.3.2 文件保护\n\n​\t系统的每个用户都分配有一个唯一的用户标识号（UID）。当创建文件后，将会使用文件所有者的用户ID对其进行标记，还会为新文件提供一个七比特的保护位，其中六个指定文件所有者和所有其他用户的独立读取，写入和执行权限。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gweq5c1xrhj30go0b4wf3.jpg\" style=\"zoom:67%;\" />\n\n- **SetUid位**\n\n  当文件或程序(统称为executable)被执行时, 操作系统会赋予文件**所有者的权限**\n\n  这个位可以用来提供特权程序，在特定规则下访问修改其不能修改的文件。\n\n**[讨论问题4] 能否举一个用到setuid的例子**\n\n类Unix系统的密码一般是放置在“/etc/paswd”和“/etc/shadow”中\n普通用户没有读写权限，用户如何更改密码？\n实际上就是利用 passwd 程序的 setuid 位为on，在执行过程中，将用户身份变为ROOT\n这样普通用户在执行“passwd”命令时，实际上以有效用户root的身份来执行的，并具有了相应的权限\n\n\n#### 2.3.3 I/O请求 \n\n​\t系统的I/O调用旨在消除各种设备和访问方式之间的差异。 “随机”和“顺序”的I/O之间没有区别，系统也不施加任何逻辑记录大小。普通文件的大小由写入文件的最高字节决定，不需要也不可能预先确定文件的大小。\n\n​\t文件系统中没有用户可见的锁，对于可以打开文件进行读取或写入的用户数量也没有任何限制；尽管当两个用户同时写入文件时文件的内容可能会被打乱，但实际上不会出现困难。他们是不必要且不足够的。\n\n**[讨论问题6] 为什么说给限制用户的读写加锁是不必要也不足够的？**\n\n不必要是因为我们并不是维护一个单进程管理的单文件的大数据库，我们不需要保证文件内容的一致性。只需要保证整个文件系统的逻辑一致即可。\n不足够是因为普通意义上的锁来说，即当一个用户在读的时候另一个用户不能写，但这样也无法完全避免混淆。\n[for example, both users are editing a file with an editor which makes a copy of the file being edited.]\n\n​\t应该说，当两个用户同时从事诸如写同一文件，在同一目录中创建文件或删除彼此的打开文件之类的不便活动时，该系统具有足够的内部联锁来维持文件系统的逻辑一致性。\n\n\n\n#### 2.3.4 文件系统的实现\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gwern4drsjj30cv08a3yw.jpg)\n\n​\t一个目录条目包含一个关联到文件的名字和一个指向自身的指针。这个指针是一个叫`i-number`的整型数。当文件被访问时，它的`i-number`被用作系统表(`i-list`)的索引\n\n1. 所有者 \n2. 保护位\n3. 文件内容的物理磁盘或磁带的地址\n4. 大小\n5. 上次修改时间\n6. 到文件的链接数，也就是文件在目录中出现的次数； \n7. 一个表示文件是否是目录的bit\n8. 一个表示文件是否属于特殊文件的bit\n9. 一个表示文件是大还是小的bit\n\n所有固定或可移除磁盘的空间都被划分为512字节的块，地址空间从0到设备本身的容量上限\n\n- **Inode**\n\n​\t每个文件的inode中都留有8个块的设备地址空间，一个小文件（即 $\\le512*8 bytes$) 可以直接被储存，大文件则是8个indirect block每个最多指向256个块，这样最大可以存储下 $8\\times256\\times512=2^{20} bytes$ 的最大文件容量\n\n- **Buffer Cache**\n\n​\t对于用户而言，文件的读写都是同步且没有缓存的。在read系统调用返回后，数据马上可用。而且很方便的是，在write系统调用之后，用户的工作空间可以重复使用。实际上系统维护了一个复杂的缓存机制，来大幅度降低访问文件所需要的I/O操作数。\n\n​\tUnix会查找缓冲区以确定受影响的磁盘块当前是否在主存中。如果不是，将从设备上读取。缓冲区中的对应的字节被替换，然后在待写入块列表中创建一个条目。write系统调用返回，尽管实际上I/O会晚一点才完成。相反的是，如果读取一个单独的字节，系统会确定该具有该字节是否已经在缓冲区中，如果是，该字节会被立刻返回。如果不是，这个块将被读取到缓冲区，然后取出该字节。\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gwew5xspc1j30bg083weq.jpg)\n\n- **I-list**\n\n> The notion of the i-list is an unusual feature of UNIX\n\n​\ti-list架构独立于目录的层级关系，只需要对线性的i-list做一系列操作就可以很好的组织维护文件系统。\n\n​\t但同时i-list的设计引起了一些奇怪的问题，例如，谁应该负责文件所占用的空间。*（既然一个文件的所有目录条目都具有相同的状态，文件的所有者负责是不公平的）*\n\n**[讨论问题5] 为什么说文件的所有者负责是不公平的？**\n\n一个用户可能会创建文件，另一个用户可能会链接到这个文件，而第一个用户可能会删除文件。第一个用户仍然是文件的所有者，但是他应该对第二个用户负责，这是不合理的。\n\n\n\n## 3. 进程和映像\n\n### 3.1 进程映像\n\n​\t映像（image）其实就是我们熟知的进程上下文。它包括核心映像，通用寄存器的值，打开的文件，当前目录等内容。\n\n<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20200514150923/process1.png\" style=\"zoom:80%;\" />\n\n​\t进程是一个映像的执行。当处理器代表一个进程去执行时，映像要驻留在核心内存中。在其他进程的执行过程中，它仍然驻留在核心内存中，除非一个高优先级的进程强制性的把它从内存中交换到固定磁头的磁盘驱动器上。\n\n从高地址到低地址分为三段\n\n- **栈段**（由上之下增长）\n\n- **数据段**\n\n  可写非共享，可向上扩展\n\n- **代码段**（写保护）\n\n  单一拷贝被执行所有相同程序的进程共享。\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gwetekcbeej309409mdg9.jpg)\n\n\n\n### 3.2 进程\n\n​\t除了Unix引导它自身进入运行中（init 进程），只能通过使用fork系统调用创建一个新的进程。\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gwetk06jscj30di049t8s.jpg)\n\n​\t当一个进程执行fork系统调用，它会被分离成两个独立的执行进程。这两个进程有各自独立的源印象的拷贝，并共享所有打开的文件。\n\n### 3.3 管道\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gwetv8ny0tj30e606dt8v.jpg)\n\n​\t非常聪明的IPC机制，A只要一端如同写普通文件一样写入，B在另一端准备读取即可。A,B可以并发的执行，并且相比临时文件，在内存中的buffer不会有额外的磁盘I/O消耗。\n\n## 4. Unix Shell\n\n> For most users, communication with UNIX is carried on with the aid of a program called the Shell. (Interactive)\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gweu4951cfj309a09h3ys.jpg)\n\n​\t在最简单的情况下，一个命令行由命令名和跟随的参数组成，命令名和参数之间通过空格分隔。\n\n```text\ncommand arg1 arg2 ... argn\n```\n\n​\tShell将命令名和参数分割为独立的字符串，这样就能找到名为command的文件。command可能是一个包含\"/\"的路径名以指出系统中的任何文件。如果command被找到，它将被引入到核心内存中被执行。Shell收集到的参数对于command是可访问的。Shell重新回到自己的执行当中，并立刻准备接受用户输入的下一条命令。\n\n### 4.1 标准I/O\n\n​\t设定 ```std_in = 0```、```std_out = 1```、```std_err = 2```，这样做有什么好处？\n\n​\t在Unix之前，很多程序没有建立输入输出的过程，而操作系统通常采用比较复杂的 [Job Control Language](https://en.wikipedia.org/wiki/Job_Control_Language) 脚本来建立输入输出的连接。\n\n​\t而Unix将输入输出默认连接到终端的键盘输入和终端的显示器上，以预定义的形式免去了很多不必要的工作。\n\n![](https://tva1.sinaimg.cn/large/008i3skNgy1gweunbmq9rj30gv090756.jpg)\n\n## 5. 陷入\n\n### 5.1 故障\n\n​\tPDP-11硬件检测到程序错误，例如对不存在的内存的引用。此类故障会导致CPU陷入内核。当发现非法行为时，除非做出其他安排，否则系统会终止该进程，并将image 写入当前目录中。(Core Dump)\n\n### 5.2 中断 (interrupt)\n\n​\t程序产生了未预期的输出，可以通过键入“delete” 字符生成一个 `interrupt` 信号来停止程序，并且这个信号之后导致程序停止而不会 Core Dump。\n\n\n\n## 6. Unix 设计哲学\n\n### 6.1 简洁 (Simplicity)\n\n> First, since we are programmers, we naturally designed the system to make it easy to write, test, and run programs.\n\n- **User Friendly**\n\n  ​\t系统以使其易于编写，测试和运行程序。对编程便利性的渴望的最重要表达是该系统被安排用于交互 (interactive) 使用，即使原始版本仅支持一个用户。\n\n  ​\t我们认为，设计合理的交互式系统比“批处理”系统更具生产力和使用满意度。而且，这样的系统相当容易适应于非交互使用，而反之则不成立。\n\n- **File Tree**\n\n  层级的目录结构，让文件管理十分简洁清晰。\n\n- **File Abstract**\n\n  一切皆是文件，将外部设备和目录统一抽象为文件，统一管理，代码复用而高效。所谓 Less is More\n\n  \n\n### 6.2 易于部署 (Flexiblility)\n\n> UNIX can run on hardware costing as little as $40,000, and less than two man-years were spent on the main system software.\n\n​\t用于安装UNIX系统的 PDP-11/45 是一个16位字长（8-bit byte），具有144K字节(byte)核心内存的计算机；UNIX占用了其中的42kb。然而这个系统包括了大量的设备驱动并且为I/O缓冲区和系统表分配了足够的空间；一个能够运行上述软件的最小系统，最小总共只需要 50kb 的内核。\n\n\n\n### 6.3 可维护性 (Maintainable)\n\n> Third, nearly from the start, the system was able to, and did, maintain itself.\n\n​\t由于实现的简洁性，系统可维护性很好，从1972~1973年DENNIS M. RITCHIE AND KEN THOMPSON 用B和C相继重写了Unix内核后，用高级语言开发的Unix有着很好的可移植和迭代能力。\n\n\n\n**[讨论问题7] 你认为是什么让Unix如此成功？**\n1. 设计哲学\n  Unix 虽然不是最早的分时操作系统，但其提出的一系列颠覆性的概念可以说重塑了操作系统界很多实现的范式，包括层级的文件系统以及一切皆文件的思想，一直延续至今。在如今看来这些好似稀松平常的概念，在当时的视角下是绝不trivial的想法。\n2. 时代背景\n  在Multics的衬托下，Unix继承了Multics的功能，以其简单而有效的设计模式启发了大家，获得了商业上的巨大成功。\n\t可以说Unix的成功，是因为其出现在一个对的时间，并且做了对的事情。\n  同样我们在回顾 UNIX 的设计发展历程的时候，对我们当今设计和进一步优化目前的操作系统有指导意义，可以说是以史为鉴，让我们能够洞见未来的发展。\n\n\n### The Unix Family Tree\n\n![](http://www.netneurotic.net/mac/unix/images/UNIXthumb.png)\n\n\n\n\n\n\n\n## Reference\n\n[1] [Ritchie, D.M.](https://en.wikipedia.org/wiki/Dennis_Ritchie); [Thompson, K.](https://en.wikipedia.org/wiki/Ken_Thompson) (July–August 1978). [\"The UNIX Time-Sharing System\"](https://web.archive.org/web/20101103053325/http://bstj.bell-labs.com/oldfiles/year.1978/BSTJ.1978.5706-2.html). *[Bell System Technical Journal](https://en.wikipedia.org/wiki/Bell_System_Technical_Journal)*. **57** (6). Archived from [the original](http://bstj.bell-labs.com/oldfiles/year.1978/BSTJ.1978.5706-2.html) on November 3, 2010.\n\n[2] [\"UNIX History\"](http://www.levenez.com/unix/). *www.levenez.com*. Retrieved March 17, 2005.\n\n[3] [\"AIX, FreeBSD, HP-UX, Linux, Solaris, Tru64\"](http://www.unixguide.net/). *UNIXguide.net*. Retrieved March 17, 2005.\n\n[4] [\"Linux Weekly News, February 21, 2002\"](https://lwn.net/2002/0221/bigpage.php3). *lwn.net*. Retrieved April 7, 2006.\n\n[5] [Lions, John](https://en.wikipedia.org/wiki/John_Lions): *Lions' [\"Commentary on the Sixth Edition UNIX Operating System\"](http://www.lemis.com/grog/Documentation/Lions/). with Source Code*, Peer-to-Peer Communications, 1996; [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier)) [1-57398-013-7](https://en.wikipedia.org/wiki/Special:BookSources/1-57398-013-7)\n\n\n\n\n\n","slug":"OS/Unix","published":1,"updated":"2026-02-03T05:42:14.444Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvj003i7uit9llo8yb2","content":"<h1 id=\"The-Unix-Time-Sharing-System\"><a href=\"#The-Unix-Time-Sharing-System\" class=\"headerlink\" title=\"The Unix Time-Sharing System\"></a>The Unix Time-Sharing System</h1><p><em>DENNIS M. RITCHIE AND KEN THOMPSON</em></p>\n<h2 id=\"1-基本介绍\"><a href=\"#1-基本介绍\" class=\"headerlink\" title=\"1. 基本介绍\"></a>1. 基本介绍</h2><h3 id=\"1-1-Unix-的历史进程\"><a href=\"#1-1-Unix-的历史进程\" class=\"headerlink\" title=\"1.1 Unix 的历史进程\"></a>1.1 Unix 的历史进程</h3><p>​    Multics，名称来自于多任务信息与计算系统（MULTiplexed Information and Computing System）的缩写，它是一套分时多任务，是1964年由贝尔实验室、MIT及美国通用电气公司所共同参与研发，其在GE 645上开发和部署。</p>\n<p>​    1969 贝尔实验室退出 Multics 的开发，DENNIS M. RITCHIE &amp; KEN THOMPSON 一同开发了 Unix，</p>\n<p>​    一开始Unix是在 <em>Digital PDP-7</em>  使用汇编语言进行编写，<em>1971</em>年，<em>Ken Thompson</em> 申请到了一台 <em>PDP-11/24</em>的 机器，于是<em>Unix</em>第二版出来了。<em>1973</em> 用C重写了Unix，形成了Unix Version 4，第四版运行在更新的PDP-ll/40, /45上</p>\n<p>​    直到<em>1974</em>年<em>7</em>月 DENNIS M. RITCHIE 和 KEN THOMPSON 在  <em>the Communications of the ACM</em> 发表了 <em>The Unix Time-Sharing System</em> 让Unix系统第一次广泛的为学界所了解。</p>\n<p><img src=\"https://n3x0.com/wp-content/uploads/2019/10/unix-co-founder-ken-thompsons-bsd-password-has-finally-been-cracked.jpg\" style=\"zoom:50%;\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwen89cbzej30pd0jft9z.jpg\" style=\"zoom:100%;\"></p>\n<h3 id=\"1-2-Unix-的特点\"><a href=\"#1-2-Unix-的特点\" class=\"headerlink\" title=\"1.2 Unix 的特点\"></a>1.2 Unix 的特点</h3><p>​    UNIX 是一个<strong>多用途 (general-purpose)，多用户 (multi-user), 交互式(interactive)</strong> 的操作系统</p>\n<ul>\n<li><strong>层级</strong>的文件系统</li>\n<li><strong>兼容</strong>的文件，设备和内部处理I/O</li>\n<li>初始化异步进程的能力</li>\n<li>对每个用户都可选的系统命令行语言</li>\n<li>用多种语言实现的超过100个子系统</li>\n</ul>\n<p><strong>[讨论问题1] 如何理解此处的 “初始化异步进程的能力” （the ability to initiate asynchronous processes）的含义</strong></p>\n<p hidden>\n    分时操作系统 (Time Sharing)\n  在上世纪50年代末60年代早期，很多操作系统还处于批处理时期（batch processing）\n  单一进程长时间独享CPU\n</p>\n\n<h3 id=\"1-3-关于Time-Sharing\"><a href=\"#1-3-关于Time-Sharing\" class=\"headerlink\" title=\"1.3 关于Time Sharing\"></a>1.3 关于Time Sharing</h3><p>​     其实Unix算是比较晚出现的分时操作系统，分时的概念最早在1954年被 <a href=\"https://en.wikipedia.org/wiki/John_Backus\">John Backus</a> 在 MIT提出</p>\n<blockquote>\n<p>The computers would handle a number of problems concurrently. Organizations would have input-output equipment installed on their own premises and would <strong>buy time</strong> on the computer much the same way that the average household buys power and water from utility companies.</p>\n</blockquote>\n<p>​     <a href=\"https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist\">John McCarthy</a>) at MIT in 1959 第一个实现了分时操作系统, 并一开始部署在 IBM704上，后面该版本的一个分支被认为是最早的一个分时系统即 CTSS。</p>\n<h2 id=\"2-文件系统\"><a href=\"#2-文件系统\" class=\"headerlink\" title=\"2. 文件系统\"></a>2. 文件系统</h2><blockquote>\n<p>Everything is a file</p>\n</blockquote>\n<p>​    UNIX中最重要的的工作是提供了一个文件系统。从用户的角度看，一共有三种类型的文件：普通磁盘文件、目录、特殊文件</p>\n<h3 id=\"2-1-普通文件\"><a href=\"#2-1-普通文件\" class=\"headerlink\" title=\"2.1 普通文件\"></a>2.1 普通文件</h3><p>​    一个文件可以包含用户放置的任何类型的信息，例如符号或者二进制(对象)或程序。不需为系统指定特定的数据结构。</p>\n<p><strong>文本文件</strong>：包含简单的、由换行符分隔段落的字符串。</p>\n<p><strong>二进制文件</strong>：是当程序开始执行时，将会在出现在核心内存中的，按顺序存放的字的序列。</p>\n<p>少数用户程序以更多样的方式组织文件结构，来实现更多的功能。例如汇编生成器和加载器需要特定格式的对象文件。</p>\n<p>总之，普通文件的结构是由用户程序来管理的而非操作系统。</p>\n<h3 id=\"2-2-目录\"><a href=\"#2-2-目录\" class=\"headerlink\" title=\"2.2 目录\"></a>2.2 目录</h3><blockquote>\n<p>Directories provide the mapping between the names of files and the files themselves, and thus induce a structure on the file system as a whole.</p>\n</blockquote>\n<h4 id=\"2-2-1-目录性质\"><a href=\"#2-2-1-目录性质\" class=\"headerlink\" title=\"2.2.1 目录性质\"></a>2.2.1 目录性质</h4><p>​    每个用户都有一个自己文件的目录；他还可以方便地创建包含文件群组的子目录。目录的行为与普通文件完全相同，不同之处在于目录无法由非特权程序写入，只有系统可以控制目录的内容。但是，具有合适权限的任何人都可以像读取其他任何文件一样读取目录。</p>\n<ul>\n<li><ol>\n<li>层级架构</li>\n</ol>\n</li>\n<li><ol>\n<li>用户隔离</li>\n</ol>\n</li>\n<li><ol>\n<li>权限控制</li>\n</ol>\n</li>\n</ul>\n<h4 id=\"2-2-2-目录内容\"><a href=\"#2-2-2-目录内容\" class=\"headerlink\" title=\"2.2.2 目录内容\"></a>2.2.2 目录内容</h4><p>​    系统维护几个目录供自己使用。其中之一是根目录 <em>(root)</em>。通过跟踪目录链中的路径直到找到所需的文件，可以找到系统中的所有文件。</p>\n<p>​    另一个系统目录<em>（/bin）</em>包含所有通常需要使用的程序，即所有的<strong>命令</strong>。但是就如将看到的，程序不必驻留在此目录中即可执行。</p>\n<h4 id=\"2-2-3-链接\"><a href=\"#2-2-3-链接\" class=\"headerlink\" title=\"2.2.3 链接\"></a>2.2.3 链接</h4><p>​    同一个非目录文件可能会以不同的名称出现在多个目录中，就是我们熟知的链接。</p>\n<p>​    UNIX与其他允许链接的系统不同，它与文件的所有链接都具有相同的状态。也就是说，文件在特定目录中不存在。文件的目录条目仅由其名称和指向实际描述文件的信息的指针组成，<strong>因此，文件实际上独立于任何目录条目而存在，尽管实际上会使该文件与最后一个链接一起消失。</strong></p>\n<p><strong>[讨论问题2] 如何理解文件实际上独立于任何目录条目而存在，尽管实际上会使该文件与最后一个链接一起消失</strong></p>\n<p>其实就是文件inode的link count和文件描述符的reference count，当二者都掉为0的时候，文件就会被操作系统回收。</p>\n<p>​    目录结构被限定为为有根树的形式。除特殊条目 <code>.</code> 和 <code>..</code> 外，每个目录必须作为另外一个目录（即其父目录）的条目出现，这是为了简化访问目录结构子树的程序的编写，更重要的是避免层次结构各部分的分离。如果允许链接到任意目录，则很难检测到从根到目录的最后一次连接何时断开。(即出现环)</p>\n<h3 id=\"2-3-特殊文件\"><a href=\"#2-3-特殊文件\" class=\"headerlink\" title=\"2.3 特殊文件\"></a>2.3 特殊文件</h3><blockquote>\n<p>Special files constitute the most unusual feature of the UNiX file system.</p>\n</blockquote>\n<p><strong>将外部设备抽象成一种文件</strong></p>\n<p>​    UNIX支持的每个 I/O 设备都与至少一个这样的文件相关联。特殊文件的读取和写入与普通磁盘文件一样，但是请求读取或写入会导致关联设备的激活。每个特殊文件的条目都位于目录/dev中，尽管可以像普通文件一样链接到其中一个文件。因此，例如要打孔纸带，可以在文件/dev/ppt上写。每个通信线路，每个磁盘，每个磁带驱动器以及物理核心内存都存在特殊文件。当然，活动磁盘和核心专用文件受到保护，不会受到任意访问。</p>\n<p><strong>[讨论问题3] 这样抽象有什么好处？</strong></p>\n<ul>\n<li>文件和I/O设备尽可能相似</li>\n<li>文件名和设备名具有相同的语法和含义，因此可以将以文件名作为参数的程序传递给设备名。</li>\n<li>权限控制（设备作为特殊文件可以和普通文件一样有权限控制机制）<br>即程序不再需要关心他在和什么设备进行交互，只需要使用一个统一的文件接口即可。</li>\n</ul>\n<h4 id=\"2-3-1-可移除的文件系统\"><a href=\"#2-3-1-可移除的文件系统\" class=\"headerlink\" title=\"2.3.1 可移除的文件系统\"></a>2.3.1 可移除的文件系统</h4><p>​    尽管文件系统的根目录始终存储在同一设备上，但是不必将整个文件系统层次结构都驻留在该设备上。</p>\n<p>​    mount用一个全新的子树（存储在可移动卷上的层次结构）替换层次结构树（普通文件）的叶子。挂载之后，可移动卷上的文件与永久文件系统上的文件之间几乎没有区别。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gweqa094umj30hd097mxw.jpg\" alt></p>\n<p><strong>[讨论问题5] 我们说当mount之后子树的文件和原来的文件系统上的文件几乎没有区别，那么区别在哪？</strong></p>\n<p>我们不能跨越 mount point 创建 hard link，即不能创建从原来文件系统到挂载的文件树上的hard link</p>\n<h4 id=\"2-3-2-文件保护\"><a href=\"#2-3-2-文件保护\" class=\"headerlink\" title=\"2.3.2 文件保护\"></a>2.3.2 文件保护</h4><p>​    系统的每个用户都分配有一个唯一的用户标识号（UID）。当创建文件后，将会使用文件所有者的用户ID对其进行标记，还会为新文件提供一个七比特的保护位，其中六个指定文件所有者和所有其他用户的独立读取，写入和执行权限。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gweq5c1xrhj30go0b4wf3.jpg\" style=\"zoom:67%;\"></p>\n<ul>\n<li><p><strong>SetUid位</strong></p>\n<p>当文件或程序(统称为executable)被执行时, 操作系统会赋予文件<strong>所有者的权限</strong></p>\n<p>这个位可以用来提供特权程序，在特定规则下访问修改其不能修改的文件。</p>\n</li>\n</ul>\n<p><strong>[讨论问题4] 能否举一个用到setuid的例子</strong></p>\n<p>类Unix系统的密码一般是放置在“/etc/paswd”和“/etc/shadow”中<br>普通用户没有读写权限，用户如何更改密码？<br>实际上就是利用 passwd 程序的 setuid 位为on，在执行过程中，将用户身份变为ROOT<br>这样普通用户在执行“passwd”命令时，实际上以有效用户root的身份来执行的，并具有了相应的权限</p>\n<h4 id=\"2-3-3-I-O请求\"><a href=\"#2-3-3-I-O请求\" class=\"headerlink\" title=\"2.3.3 I/O请求\"></a>2.3.3 I/O请求</h4><p>​    系统的I/O调用旨在消除各种设备和访问方式之间的差异。 “随机”和“顺序”的I/O之间没有区别，系统也不施加任何逻辑记录大小。普通文件的大小由写入文件的最高字节决定，不需要也不可能预先确定文件的大小。</p>\n<p>​    文件系统中没有用户可见的锁，对于可以打开文件进行读取或写入的用户数量也没有任何限制；尽管当两个用户同时写入文件时文件的内容可能会被打乱，但实际上不会出现困难。他们是不必要且不足够的。</p>\n<p><strong>[讨论问题6] 为什么说给限制用户的读写加锁是不必要也不足够的？</strong></p>\n<p>不必要是因为我们并不是维护一个单进程管理的单文件的大数据库，我们不需要保证文件内容的一致性。只需要保证整个文件系统的逻辑一致即可。<br>不足够是因为普通意义上的锁来说，即当一个用户在读的时候另一个用户不能写，但这样也无法完全避免混淆。<br>[for example, both users are editing a file with an editor which makes a copy of the file being edited.]</p>\n<p>​    应该说，当两个用户同时从事诸如写同一文件，在同一目录中创建文件或删除彼此的打开文件之类的不便活动时，该系统具有足够的内部联锁来维持文件系统的逻辑一致性。</p>\n<h4 id=\"2-3-4-文件系统的实现\"><a href=\"#2-3-4-文件系统的实现\" class=\"headerlink\" title=\"2.3.4 文件系统的实现\"></a>2.3.4 文件系统的实现</h4><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwern4drsjj30cv08a3yw.jpg\" alt></p>\n<p>​    一个目录条目包含一个关联到文件的名字和一个指向自身的指针。这个指针是一个叫<code>i-number</code>的整型数。当文件被访问时，它的<code>i-number</code>被用作系统表(<code>i-list</code>)的索引</p>\n<ol>\n<li>所有者 </li>\n<li>保护位</li>\n<li>文件内容的物理磁盘或磁带的地址</li>\n<li>大小</li>\n<li>上次修改时间</li>\n<li>到文件的链接数，也就是文件在目录中出现的次数； </li>\n<li>一个表示文件是否是目录的bit</li>\n<li>一个表示文件是否属于特殊文件的bit</li>\n<li>一个表示文件是大还是小的bit</li>\n</ol>\n<p>所有固定或可移除磁盘的空间都被划分为512字节的块，地址空间从0到设备本身的容量上限</p>\n<ul>\n<li><strong>Inode</strong></li>\n</ul>\n<p>​    每个文件的inode中都留有8个块的设备地址空间，一个小文件（即 $\\le512*8 bytes$) 可以直接被储存，大文件则是8个indirect block每个最多指向256个块，这样最大可以存储下 $8\\times256\\times512=2^{20} bytes$ 的最大文件容量</p>\n<ul>\n<li><strong>Buffer Cache</strong></li>\n</ul>\n<p>​    对于用户而言，文件的读写都是同步且没有缓存的。在read系统调用返回后，数据马上可用。而且很方便的是，在write系统调用之后，用户的工作空间可以重复使用。实际上系统维护了一个复杂的缓存机制，来大幅度降低访问文件所需要的I/O操作数。</p>\n<p>​    Unix会查找缓冲区以确定受影响的磁盘块当前是否在主存中。如果不是，将从设备上读取。缓冲区中的对应的字节被替换，然后在待写入块列表中创建一个条目。write系统调用返回，尽管实际上I/O会晚一点才完成。相反的是，如果读取一个单独的字节，系统会确定该具有该字节是否已经在缓冲区中，如果是，该字节会被立刻返回。如果不是，这个块将被读取到缓冲区，然后取出该字节。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwew5xspc1j30bg083weq.jpg\" alt></p>\n<ul>\n<li><strong>I-list</strong></li>\n</ul>\n<blockquote>\n<p>The notion of the i-list is an unusual feature of UNIX</p>\n</blockquote>\n<p>​    i-list架构独立于目录的层级关系，只需要对线性的i-list做一系列操作就可以很好的组织维护文件系统。</p>\n<p>​    但同时i-list的设计引起了一些奇怪的问题，例如，谁应该负责文件所占用的空间。<em>（既然一个文件的所有目录条目都具有相同的状态，文件的所有者负责是不公平的）</em></p>\n<p><strong>[讨论问题5] 为什么说文件的所有者负责是不公平的？</strong></p>\n<p>一个用户可能会创建文件，另一个用户可能会链接到这个文件，而第一个用户可能会删除文件。第一个用户仍然是文件的所有者，但是他应该对第二个用户负责，这是不合理的。</p>\n<h2 id=\"3-进程和映像\"><a href=\"#3-进程和映像\" class=\"headerlink\" title=\"3. 进程和映像\"></a>3. 进程和映像</h2><h3 id=\"3-1-进程映像\"><a href=\"#3-1-进程映像\" class=\"headerlink\" title=\"3.1 进程映像\"></a>3.1 进程映像</h3><p>​    映像（image）其实就是我们熟知的进程上下文。它包括核心映像，通用寄存器的值，打开的文件，当前目录等内容。</p>\n<p><img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20200514150923/process1.png\" style=\"zoom:80%;\"></p>\n<p>​    进程是一个映像的执行。当处理器代表一个进程去执行时，映像要驻留在核心内存中。在其他进程的执行过程中，它仍然驻留在核心内存中，除非一个高优先级的进程强制性的把它从内存中交换到固定磁头的磁盘驱动器上。</p>\n<p>从高地址到低地址分为三段</p>\n<ul>\n<li><p><strong>栈段</strong>（由上之下增长）</p>\n</li>\n<li><p><strong>数据段</strong></p>\n<p>可写非共享，可向上扩展</p>\n</li>\n<li><p><strong>代码段</strong>（写保护）</p>\n<p>单一拷贝被执行所有相同程序的进程共享。</p>\n</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwetekcbeej309409mdg9.jpg\" alt></p>\n<h3 id=\"3-2-进程\"><a href=\"#3-2-进程\" class=\"headerlink\" title=\"3.2 进程\"></a>3.2 进程</h3><p>​    除了Unix引导它自身进入运行中（init 进程），只能通过使用fork系统调用创建一个新的进程。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwetk06jscj30di049t8s.jpg\" alt></p>\n<p>​    当一个进程执行fork系统调用，它会被分离成两个独立的执行进程。这两个进程有各自独立的源印象的拷贝，并共享所有打开的文件。</p>\n<h3 id=\"3-3-管道\"><a href=\"#3-3-管道\" class=\"headerlink\" title=\"3.3 管道\"></a>3.3 管道</h3><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwetv8ny0tj30e606dt8v.jpg\" alt></p>\n<p>​    非常聪明的IPC机制，A只要一端如同写普通文件一样写入，B在另一端准备读取即可。A,B可以并发的执行，并且相比临时文件，在内存中的buffer不会有额外的磁盘I/O消耗。</p>\n<h2 id=\"4-Unix-Shell\"><a href=\"#4-Unix-Shell\" class=\"headerlink\" title=\"4. Unix Shell\"></a>4. Unix Shell</h2><blockquote>\n<p>For most users, communication with UNIX is carried on with the aid of a program called the Shell. (Interactive)</p>\n</blockquote>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gweu4951cfj309a09h3ys.jpg\" alt></p>\n<p>​    在最简单的情况下，一个命令行由命令名和跟随的参数组成，命令名和参数之间通过空格分隔。</p>\n<pre><code class=\"hljs text\">command arg1 arg2 ... argn</code></pre>\n<p>​    Shell将命令名和参数分割为独立的字符串，这样就能找到名为command的文件。command可能是一个包含”/“的路径名以指出系统中的任何文件。如果command被找到，它将被引入到核心内存中被执行。Shell收集到的参数对于command是可访问的。Shell重新回到自己的执行当中，并立刻准备接受用户输入的下一条命令。</p>\n<h3 id=\"4-1-标准I-O\"><a href=\"#4-1-标准I-O\" class=\"headerlink\" title=\"4.1 标准I/O\"></a>4.1 标准I/O</h3><p>​    设定 <code>std_in = 0</code>、<code>std_out = 1</code>、<code>std_err = 2</code>，这样做有什么好处？</p>\n<p>​    在Unix之前，很多程序没有建立输入输出的过程，而操作系统通常采用比较复杂的 <a href=\"https://en.wikipedia.org/wiki/Job_Control_Language\">Job Control Language</a> 脚本来建立输入输出的连接。</p>\n<p>​    而Unix将输入输出默认连接到终端的键盘输入和终端的显示器上，以预定义的形式免去了很多不必要的工作。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gweunbmq9rj30gv090756.jpg\" alt></p>\n<h2 id=\"5-陷入\"><a href=\"#5-陷入\" class=\"headerlink\" title=\"5. 陷入\"></a>5. 陷入</h2><h3 id=\"5-1-故障\"><a href=\"#5-1-故障\" class=\"headerlink\" title=\"5.1 故障\"></a>5.1 故障</h3><p>​    PDP-11硬件检测到程序错误，例如对不存在的内存的引用。此类故障会导致CPU陷入内核。当发现非法行为时，除非做出其他安排，否则系统会终止该进程，并将image 写入当前目录中。(Core Dump)</p>\n<h3 id=\"5-2-中断-interrupt\"><a href=\"#5-2-中断-interrupt\" class=\"headerlink\" title=\"5.2 中断 (interrupt)\"></a>5.2 中断 (interrupt)</h3><p>​    程序产生了未预期的输出，可以通过键入“delete” 字符生成一个 <code>interrupt</code> 信号来停止程序，并且这个信号之后导致程序停止而不会 Core Dump。</p>\n<h2 id=\"6-Unix-设计哲学\"><a href=\"#6-Unix-设计哲学\" class=\"headerlink\" title=\"6. Unix 设计哲学\"></a>6. Unix 设计哲学</h2><h3 id=\"6-1-简洁-Simplicity\"><a href=\"#6-1-简洁-Simplicity\" class=\"headerlink\" title=\"6.1 简洁 (Simplicity)\"></a>6.1 简洁 (Simplicity)</h3><blockquote>\n<p>First, since we are programmers, we naturally designed the system to make it easy to write, test, and run programs.</p>\n</blockquote>\n<ul>\n<li><p><strong>User Friendly</strong></p>\n<p>​    系统以使其易于编写，测试和运行程序。对编程便利性的渴望的最重要表达是该系统被安排用于交互 (interactive) 使用，即使原始版本仅支持一个用户。</p>\n<p>​    我们认为，设计合理的交互式系统比“批处理”系统更具生产力和使用满意度。而且，这样的系统相当容易适应于非交互使用，而反之则不成立。</p>\n</li>\n<li><p><strong>File Tree</strong></p>\n<p>层级的目录结构，让文件管理十分简洁清晰。</p>\n</li>\n<li><p><strong>File Abstract</strong></p>\n<p>一切皆是文件，将外部设备和目录统一抽象为文件，统一管理，代码复用而高效。所谓 Less is More</p>\n</li>\n</ul>\n<h3 id=\"6-2-易于部署-Flexiblility\"><a href=\"#6-2-易于部署-Flexiblility\" class=\"headerlink\" title=\"6.2 易于部署 (Flexiblility)\"></a>6.2 易于部署 (Flexiblility)</h3><blockquote>\n<p>UNIX can run on hardware costing as little as $40,000, and less than two man-years were spent on the main system software.</p>\n</blockquote>\n<p>​    用于安装UNIX系统的 PDP-11/45 是一个16位字长（8-bit byte），具有144K字节(byte)核心内存的计算机；UNIX占用了其中的42kb。然而这个系统包括了大量的设备驱动并且为I/O缓冲区和系统表分配了足够的空间；一个能够运行上述软件的最小系统，最小总共只需要 50kb 的内核。</p>\n<h3 id=\"6-3-可维护性-Maintainable\"><a href=\"#6-3-可维护性-Maintainable\" class=\"headerlink\" title=\"6.3 可维护性 (Maintainable)\"></a>6.3 可维护性 (Maintainable)</h3><blockquote>\n<p>Third, nearly from the start, the system was able to, and did, maintain itself.</p>\n</blockquote>\n<p>​    由于实现的简洁性，系统可维护性很好，从1972~1973年DENNIS M. RITCHIE AND KEN THOMPSON 用B和C相继重写了Unix内核后，用高级语言开发的Unix有着很好的可移植和迭代能力。</p>\n<p><strong>[讨论问题7] 你认为是什么让Unix如此成功？</strong></p>\n<ol>\n<li>设计哲学<br>Unix 虽然不是最早的分时操作系统，但其提出的一系列颠覆性的概念可以说重塑了操作系统界很多实现的范式，包括层级的文件系统以及一切皆文件的思想，一直延续至今。在如今看来这些好似稀松平常的概念，在当时的视角下是绝不trivial的想法。</li>\n<li>时代背景<br>在Multics的衬托下，Unix继承了Multics的功能，以其简单而有效的设计模式启发了大家，获得了商业上的巨大成功。<br> 可以说Unix的成功，是因为其出现在一个对的时间，并且做了对的事情。<br>同样我们在回顾 UNIX 的设计发展历程的时候，对我们当今设计和进一步优化目前的操作系统有指导意义，可以说是以史为鉴，让我们能够洞见未来的发展。</li>\n</ol>\n<h3 id=\"The-Unix-Family-Tree\"><a href=\"#The-Unix-Family-Tree\" class=\"headerlink\" title=\"The Unix Family Tree\"></a>The Unix Family Tree</h3><p><img src=\"http://www.netneurotic.net/mac/unix/images/UNIXthumb.png\" alt></p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>[1] <a href=\"https://en.wikipedia.org/wiki/Dennis_Ritchie\">Ritchie, D.M.</a>; <a href=\"https://en.wikipedia.org/wiki/Ken_Thompson\">Thompson, K.</a> (July–August 1978). <a href=\"https://web.archive.org/web/20101103053325/http://bstj.bell-labs.com/oldfiles/year.1978/BSTJ.1978.5706-2.html\">“The UNIX Time-Sharing System”</a>. <em><a href=\"https://en.wikipedia.org/wiki/Bell_System_Technical_Journal\">Bell System Technical Journal</a></em>. <strong>57</strong> (6). Archived from <a href=\"http://bstj.bell-labs.com/oldfiles/year.1978/BSTJ.1978.5706-2.html\">the original</a> on November 3, 2010.</p>\n<p>[2] <a href=\"http://www.levenez.com/unix/\">“UNIX History”</a>. <em>www.levenez.com</em>. Retrieved March 17, 2005.</p>\n<p>[3] <a href=\"http://www.unixguide.net/\">“AIX, FreeBSD, HP-UX, Linux, Solaris, Tru64”</a>. <em>UNIXguide.net</em>. Retrieved March 17, 2005.</p>\n<p>[4] <a href=\"https://lwn.net/2002/0221/bigpage.php3\">“Linux Weekly News, February 21, 2002”</a>. <em>lwn.net</em>. Retrieved April 7, 2006.</p>\n<p>[5] <a href=\"https://en.wikipedia.org/wiki/John_Lions\">Lions, John</a>: <em>Lions’ <a href=\"http://www.lemis.com/grog/Documentation/Lions/\">“Commentary on the Sixth Edition UNIX Operating System”</a>. with Source Code</em>, Peer-to-Peer Communications, 1996; <a href=\"https://en.wikipedia.org/wiki/ISBN_(identifier\">ISBN</a>) <a href=\"https://en.wikipedia.org/wiki/Special:BookSources/1-57398-013-7\">1-57398-013-7</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"The-Unix-Time-Sharing-System\"><a href=\"#The-Unix-Time-Sharing-System\" class=\"headerlink\" title=\"The Unix Time-Sharing System\"></a>The Unix Time-Sharing System</h1><p><em>DENNIS M. RITCHIE AND KEN THOMPSON</em></p>\n<h2 id=\"1-基本介绍\"><a href=\"#1-基本介绍\" class=\"headerlink\" title=\"1. 基本介绍\"></a>1. 基本介绍</h2><h3 id=\"1-1-Unix-的历史进程\"><a href=\"#1-1-Unix-的历史进程\" class=\"headerlink\" title=\"1.1 Unix 的历史进程\"></a>1.1 Unix 的历史进程</h3><p>​    Multics，名称来自于多任务信息与计算系统（MULTiplexed Information and Computing System）的缩写，它是一套分时多任务，是1964年由贝尔实验室、MIT及美国通用电气公司所共同参与研发，其在GE 645上开发和部署。</p>\n<p>​    1969 贝尔实验室退出 Multics 的开发，DENNIS M. RITCHIE &amp; KEN THOMPSON 一同开发了 Unix，</p>\n<p>​    一开始Unix是在 <em>Digital PDP-7</em>  使用汇编语言进行编写，<em>1971</em>年，<em>Ken Thompson</em> 申请到了一台 <em>PDP-11/24</em>的 机器，于是<em>Unix</em>第二版出来了。<em>1973</em> 用C重写了Unix，形成了Unix Version 4，第四版运行在更新的PDP-ll/40, /45上</p>\n<p>​    直到<em>1974</em>年<em>7</em>月 DENNIS M. RITCHIE 和 KEN THOMPSON 在  <em>the Communications of the ACM</em> 发表了 <em>The Unix Time-Sharing System</em> 让Unix系统第一次广泛的为学界所了解。</p>\n<p><img src=\"https://n3x0.com/wp-content/uploads/2019/10/unix-co-founder-ken-thompsons-bsd-password-has-finally-been-cracked.jpg\" style=\"zoom:50%;\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwen89cbzej30pd0jft9z.jpg\" style=\"zoom:100%;\"></p>\n<h3 id=\"1-2-Unix-的特点\"><a href=\"#1-2-Unix-的特点\" class=\"headerlink\" title=\"1.2 Unix 的特点\"></a>1.2 Unix 的特点</h3><p>​    UNIX 是一个<strong>多用途 (general-purpose)，多用户 (multi-user), 交互式(interactive)</strong> 的操作系统</p>\n<ul>\n<li><strong>层级</strong>的文件系统</li>\n<li><strong>兼容</strong>的文件，设备和内部处理I/O</li>\n<li>初始化异步进程的能力</li>\n<li>对每个用户都可选的系统命令行语言</li>\n<li>用多种语言实现的超过100个子系统</li>\n</ul>\n<p><strong>[讨论问题1] 如何理解此处的 “初始化异步进程的能力” （the ability to initiate asynchronous processes）的含义</strong></p>\n<p hidden>\n    分时操作系统 (Time Sharing)\n  在上世纪50年代末60年代早期，很多操作系统还处于批处理时期（batch processing）\n  单一进程长时间独享CPU\n</p>\n\n<h3 id=\"1-3-关于Time-Sharing\"><a href=\"#1-3-关于Time-Sharing\" class=\"headerlink\" title=\"1.3 关于Time Sharing\"></a>1.3 关于Time Sharing</h3><p>​     其实Unix算是比较晚出现的分时操作系统，分时的概念最早在1954年被 <a href=\"https://en.wikipedia.org/wiki/John_Backus\">John Backus</a> 在 MIT提出</p>\n<blockquote>\n<p>The computers would handle a number of problems concurrently. Organizations would have input-output equipment installed on their own premises and would <strong>buy time</strong> on the computer much the same way that the average household buys power and water from utility companies.</p>\n</blockquote>\n<p>​     <a href=\"https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist\">John McCarthy</a>) at MIT in 1959 第一个实现了分时操作系统, 并一开始部署在 IBM704上，后面该版本的一个分支被认为是最早的一个分时系统即 CTSS。</p>\n<h2 id=\"2-文件系统\"><a href=\"#2-文件系统\" class=\"headerlink\" title=\"2. 文件系统\"></a>2. 文件系统</h2><blockquote>\n<p>Everything is a file</p>\n</blockquote>\n<p>​    UNIX中最重要的的工作是提供了一个文件系统。从用户的角度看，一共有三种类型的文件：普通磁盘文件、目录、特殊文件</p>\n<h3 id=\"2-1-普通文件\"><a href=\"#2-1-普通文件\" class=\"headerlink\" title=\"2.1 普通文件\"></a>2.1 普通文件</h3><p>​    一个文件可以包含用户放置的任何类型的信息，例如符号或者二进制(对象)或程序。不需为系统指定特定的数据结构。</p>\n<p><strong>文本文件</strong>：包含简单的、由换行符分隔段落的字符串。</p>\n<p><strong>二进制文件</strong>：是当程序开始执行时，将会在出现在核心内存中的，按顺序存放的字的序列。</p>\n<p>少数用户程序以更多样的方式组织文件结构，来实现更多的功能。例如汇编生成器和加载器需要特定格式的对象文件。</p>\n<p>总之，普通文件的结构是由用户程序来管理的而非操作系统。</p>\n<h3 id=\"2-2-目录\"><a href=\"#2-2-目录\" class=\"headerlink\" title=\"2.2 目录\"></a>2.2 目录</h3><blockquote>\n<p>Directories provide the mapping between the names of files and the files themselves, and thus induce a structure on the file system as a whole.</p>\n</blockquote>\n<h4 id=\"2-2-1-目录性质\"><a href=\"#2-2-1-目录性质\" class=\"headerlink\" title=\"2.2.1 目录性质\"></a>2.2.1 目录性质</h4><p>​    每个用户都有一个自己文件的目录；他还可以方便地创建包含文件群组的子目录。目录的行为与普通文件完全相同，不同之处在于目录无法由非特权程序写入，只有系统可以控制目录的内容。但是，具有合适权限的任何人都可以像读取其他任何文件一样读取目录。</p>\n<ul>\n<li><ol>\n<li>层级架构</li>\n</ol>\n</li>\n<li><ol>\n<li>用户隔离</li>\n</ol>\n</li>\n<li><ol>\n<li>权限控制</li>\n</ol>\n</li>\n</ul>\n<h4 id=\"2-2-2-目录内容\"><a href=\"#2-2-2-目录内容\" class=\"headerlink\" title=\"2.2.2 目录内容\"></a>2.2.2 目录内容</h4><p>​    系统维护几个目录供自己使用。其中之一是根目录 <em>(root)</em>。通过跟踪目录链中的路径直到找到所需的文件，可以找到系统中的所有文件。</p>\n<p>​    另一个系统目录<em>（/bin）</em>包含所有通常需要使用的程序，即所有的<strong>命令</strong>。但是就如将看到的，程序不必驻留在此目录中即可执行。</p>\n<h4 id=\"2-2-3-链接\"><a href=\"#2-2-3-链接\" class=\"headerlink\" title=\"2.2.3 链接\"></a>2.2.3 链接</h4><p>​    同一个非目录文件可能会以不同的名称出现在多个目录中，就是我们熟知的链接。</p>\n<p>​    UNIX与其他允许链接的系统不同，它与文件的所有链接都具有相同的状态。也就是说，文件在特定目录中不存在。文件的目录条目仅由其名称和指向实际描述文件的信息的指针组成，<strong>因此，文件实际上独立于任何目录条目而存在，尽管实际上会使该文件与最后一个链接一起消失。</strong></p>\n<p><strong>[讨论问题2] 如何理解文件实际上独立于任何目录条目而存在，尽管实际上会使该文件与最后一个链接一起消失</strong></p>\n<p>其实就是文件inode的link count和文件描述符的reference count，当二者都掉为0的时候，文件就会被操作系统回收。</p>\n<p>​    目录结构被限定为为有根树的形式。除特殊条目 <code>.</code> 和 <code>..</code> 外，每个目录必须作为另外一个目录（即其父目录）的条目出现，这是为了简化访问目录结构子树的程序的编写，更重要的是避免层次结构各部分的分离。如果允许链接到任意目录，则很难检测到从根到目录的最后一次连接何时断开。(即出现环)</p>\n<h3 id=\"2-3-特殊文件\"><a href=\"#2-3-特殊文件\" class=\"headerlink\" title=\"2.3 特殊文件\"></a>2.3 特殊文件</h3><blockquote>\n<p>Special files constitute the most unusual feature of the UNiX file system.</p>\n</blockquote>\n<p><strong>将外部设备抽象成一种文件</strong></p>\n<p>​    UNIX支持的每个 I/O 设备都与至少一个这样的文件相关联。特殊文件的读取和写入与普通磁盘文件一样，但是请求读取或写入会导致关联设备的激活。每个特殊文件的条目都位于目录/dev中，尽管可以像普通文件一样链接到其中一个文件。因此，例如要打孔纸带，可以在文件/dev/ppt上写。每个通信线路，每个磁盘，每个磁带驱动器以及物理核心内存都存在特殊文件。当然，活动磁盘和核心专用文件受到保护，不会受到任意访问。</p>\n<p><strong>[讨论问题3] 这样抽象有什么好处？</strong></p>\n<ul>\n<li>文件和I/O设备尽可能相似</li>\n<li>文件名和设备名具有相同的语法和含义，因此可以将以文件名作为参数的程序传递给设备名。</li>\n<li>权限控制（设备作为特殊文件可以和普通文件一样有权限控制机制）<br>即程序不再需要关心他在和什么设备进行交互，只需要使用一个统一的文件接口即可。</li>\n</ul>\n<h4 id=\"2-3-1-可移除的文件系统\"><a href=\"#2-3-1-可移除的文件系统\" class=\"headerlink\" title=\"2.3.1 可移除的文件系统\"></a>2.3.1 可移除的文件系统</h4><p>​    尽管文件系统的根目录始终存储在同一设备上，但是不必将整个文件系统层次结构都驻留在该设备上。</p>\n<p>​    mount用一个全新的子树（存储在可移动卷上的层次结构）替换层次结构树（普通文件）的叶子。挂载之后，可移动卷上的文件与永久文件系统上的文件之间几乎没有区别。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gweqa094umj30hd097mxw.jpg\" alt></p>\n<p><strong>[讨论问题5] 我们说当mount之后子树的文件和原来的文件系统上的文件几乎没有区别，那么区别在哪？</strong></p>\n<p>我们不能跨越 mount point 创建 hard link，即不能创建从原来文件系统到挂载的文件树上的hard link</p>\n<h4 id=\"2-3-2-文件保护\"><a href=\"#2-3-2-文件保护\" class=\"headerlink\" title=\"2.3.2 文件保护\"></a>2.3.2 文件保护</h4><p>​    系统的每个用户都分配有一个唯一的用户标识号（UID）。当创建文件后，将会使用文件所有者的用户ID对其进行标记，还会为新文件提供一个七比特的保护位，其中六个指定文件所有者和所有其他用户的独立读取，写入和执行权限。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gweq5c1xrhj30go0b4wf3.jpg\" style=\"zoom:67%;\"></p>\n<ul>\n<li><p><strong>SetUid位</strong></p>\n<p>当文件或程序(统称为executable)被执行时, 操作系统会赋予文件<strong>所有者的权限</strong></p>\n<p>这个位可以用来提供特权程序，在特定规则下访问修改其不能修改的文件。</p>\n</li>\n</ul>\n<p><strong>[讨论问题4] 能否举一个用到setuid的例子</strong></p>\n<p>类Unix系统的密码一般是放置在“/etc/paswd”和“/etc/shadow”中<br>普通用户没有读写权限，用户如何更改密码？<br>实际上就是利用 passwd 程序的 setuid 位为on，在执行过程中，将用户身份变为ROOT<br>这样普通用户在执行“passwd”命令时，实际上以有效用户root的身份来执行的，并具有了相应的权限</p>\n<h4 id=\"2-3-3-I-O请求\"><a href=\"#2-3-3-I-O请求\" class=\"headerlink\" title=\"2.3.3 I/O请求\"></a>2.3.3 I/O请求</h4><p>​    系统的I/O调用旨在消除各种设备和访问方式之间的差异。 “随机”和“顺序”的I/O之间没有区别，系统也不施加任何逻辑记录大小。普通文件的大小由写入文件的最高字节决定，不需要也不可能预先确定文件的大小。</p>\n<p>​    文件系统中没有用户可见的锁，对于可以打开文件进行读取或写入的用户数量也没有任何限制；尽管当两个用户同时写入文件时文件的内容可能会被打乱，但实际上不会出现困难。他们是不必要且不足够的。</p>\n<p><strong>[讨论问题6] 为什么说给限制用户的读写加锁是不必要也不足够的？</strong></p>\n<p>不必要是因为我们并不是维护一个单进程管理的单文件的大数据库，我们不需要保证文件内容的一致性。只需要保证整个文件系统的逻辑一致即可。<br>不足够是因为普通意义上的锁来说，即当一个用户在读的时候另一个用户不能写，但这样也无法完全避免混淆。<br>[for example, both users are editing a file with an editor which makes a copy of the file being edited.]</p>\n<p>​    应该说，当两个用户同时从事诸如写同一文件，在同一目录中创建文件或删除彼此的打开文件之类的不便活动时，该系统具有足够的内部联锁来维持文件系统的逻辑一致性。</p>\n<h4 id=\"2-3-4-文件系统的实现\"><a href=\"#2-3-4-文件系统的实现\" class=\"headerlink\" title=\"2.3.4 文件系统的实现\"></a>2.3.4 文件系统的实现</h4><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwern4drsjj30cv08a3yw.jpg\" alt></p>\n<p>​    一个目录条目包含一个关联到文件的名字和一个指向自身的指针。这个指针是一个叫<code>i-number</code>的整型数。当文件被访问时，它的<code>i-number</code>被用作系统表(<code>i-list</code>)的索引</p>\n<ol>\n<li>所有者 </li>\n<li>保护位</li>\n<li>文件内容的物理磁盘或磁带的地址</li>\n<li>大小</li>\n<li>上次修改时间</li>\n<li>到文件的链接数，也就是文件在目录中出现的次数； </li>\n<li>一个表示文件是否是目录的bit</li>\n<li>一个表示文件是否属于特殊文件的bit</li>\n<li>一个表示文件是大还是小的bit</li>\n</ol>\n<p>所有固定或可移除磁盘的空间都被划分为512字节的块，地址空间从0到设备本身的容量上限</p>\n<ul>\n<li><strong>Inode</strong></li>\n</ul>\n<p>​    每个文件的inode中都留有8个块的设备地址空间，一个小文件（即 $\\le512*8 bytes$) 可以直接被储存，大文件则是8个indirect block每个最多指向256个块，这样最大可以存储下 $8\\times256\\times512=2^{20} bytes$ 的最大文件容量</p>\n<ul>\n<li><strong>Buffer Cache</strong></li>\n</ul>\n<p>​    对于用户而言，文件的读写都是同步且没有缓存的。在read系统调用返回后，数据马上可用。而且很方便的是，在write系统调用之后，用户的工作空间可以重复使用。实际上系统维护了一个复杂的缓存机制，来大幅度降低访问文件所需要的I/O操作数。</p>\n<p>​    Unix会查找缓冲区以确定受影响的磁盘块当前是否在主存中。如果不是，将从设备上读取。缓冲区中的对应的字节被替换，然后在待写入块列表中创建一个条目。write系统调用返回，尽管实际上I/O会晚一点才完成。相反的是，如果读取一个单独的字节，系统会确定该具有该字节是否已经在缓冲区中，如果是，该字节会被立刻返回。如果不是，这个块将被读取到缓冲区，然后取出该字节。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwew5xspc1j30bg083weq.jpg\" alt></p>\n<ul>\n<li><strong>I-list</strong></li>\n</ul>\n<blockquote>\n<p>The notion of the i-list is an unusual feature of UNIX</p>\n</blockquote>\n<p>​    i-list架构独立于目录的层级关系，只需要对线性的i-list做一系列操作就可以很好的组织维护文件系统。</p>\n<p>​    但同时i-list的设计引起了一些奇怪的问题，例如，谁应该负责文件所占用的空间。<em>（既然一个文件的所有目录条目都具有相同的状态，文件的所有者负责是不公平的）</em></p>\n<p><strong>[讨论问题5] 为什么说文件的所有者负责是不公平的？</strong></p>\n<p>一个用户可能会创建文件，另一个用户可能会链接到这个文件，而第一个用户可能会删除文件。第一个用户仍然是文件的所有者，但是他应该对第二个用户负责，这是不合理的。</p>\n<h2 id=\"3-进程和映像\"><a href=\"#3-进程和映像\" class=\"headerlink\" title=\"3. 进程和映像\"></a>3. 进程和映像</h2><h3 id=\"3-1-进程映像\"><a href=\"#3-1-进程映像\" class=\"headerlink\" title=\"3.1 进程映像\"></a>3.1 进程映像</h3><p>​    映像（image）其实就是我们熟知的进程上下文。它包括核心映像，通用寄存器的值，打开的文件，当前目录等内容。</p>\n<p><img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20200514150923/process1.png\" style=\"zoom:80%;\"></p>\n<p>​    进程是一个映像的执行。当处理器代表一个进程去执行时，映像要驻留在核心内存中。在其他进程的执行过程中，它仍然驻留在核心内存中，除非一个高优先级的进程强制性的把它从内存中交换到固定磁头的磁盘驱动器上。</p>\n<p>从高地址到低地址分为三段</p>\n<ul>\n<li><p><strong>栈段</strong>（由上之下增长）</p>\n</li>\n<li><p><strong>数据段</strong></p>\n<p>可写非共享，可向上扩展</p>\n</li>\n<li><p><strong>代码段</strong>（写保护）</p>\n<p>单一拷贝被执行所有相同程序的进程共享。</p>\n</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwetekcbeej309409mdg9.jpg\" alt></p>\n<h3 id=\"3-2-进程\"><a href=\"#3-2-进程\" class=\"headerlink\" title=\"3.2 进程\"></a>3.2 进程</h3><p>​    除了Unix引导它自身进入运行中（init 进程），只能通过使用fork系统调用创建一个新的进程。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwetk06jscj30di049t8s.jpg\" alt></p>\n<p>​    当一个进程执行fork系统调用，它会被分离成两个独立的执行进程。这两个进程有各自独立的源印象的拷贝，并共享所有打开的文件。</p>\n<h3 id=\"3-3-管道\"><a href=\"#3-3-管道\" class=\"headerlink\" title=\"3.3 管道\"></a>3.3 管道</h3><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gwetv8ny0tj30e606dt8v.jpg\" alt></p>\n<p>​    非常聪明的IPC机制，A只要一端如同写普通文件一样写入，B在另一端准备读取即可。A,B可以并发的执行，并且相比临时文件，在内存中的buffer不会有额外的磁盘I/O消耗。</p>\n<h2 id=\"4-Unix-Shell\"><a href=\"#4-Unix-Shell\" class=\"headerlink\" title=\"4. Unix Shell\"></a>4. Unix Shell</h2><blockquote>\n<p>For most users, communication with UNIX is carried on with the aid of a program called the Shell. (Interactive)</p>\n</blockquote>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gweu4951cfj309a09h3ys.jpg\" alt></p>\n<p>​    在最简单的情况下，一个命令行由命令名和跟随的参数组成，命令名和参数之间通过空格分隔。</p>\n<pre><code class=\"hljs text\">command arg1 arg2 ... argn</code></pre>\n<p>​    Shell将命令名和参数分割为独立的字符串，这样就能找到名为command的文件。command可能是一个包含”/“的路径名以指出系统中的任何文件。如果command被找到，它将被引入到核心内存中被执行。Shell收集到的参数对于command是可访问的。Shell重新回到自己的执行当中，并立刻准备接受用户输入的下一条命令。</p>\n<h3 id=\"4-1-标准I-O\"><a href=\"#4-1-标准I-O\" class=\"headerlink\" title=\"4.1 标准I/O\"></a>4.1 标准I/O</h3><p>​    设定 <code>std_in = 0</code>、<code>std_out = 1</code>、<code>std_err = 2</code>，这样做有什么好处？</p>\n<p>​    在Unix之前，很多程序没有建立输入输出的过程，而操作系统通常采用比较复杂的 <a href=\"https://en.wikipedia.org/wiki/Job_Control_Language\">Job Control Language</a> 脚本来建立输入输出的连接。</p>\n<p>​    而Unix将输入输出默认连接到终端的键盘输入和终端的显示器上，以预定义的形式免去了很多不必要的工作。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNgy1gweunbmq9rj30gv090756.jpg\" alt></p>\n<h2 id=\"5-陷入\"><a href=\"#5-陷入\" class=\"headerlink\" title=\"5. 陷入\"></a>5. 陷入</h2><h3 id=\"5-1-故障\"><a href=\"#5-1-故障\" class=\"headerlink\" title=\"5.1 故障\"></a>5.1 故障</h3><p>​    PDP-11硬件检测到程序错误，例如对不存在的内存的引用。此类故障会导致CPU陷入内核。当发现非法行为时，除非做出其他安排，否则系统会终止该进程，并将image 写入当前目录中。(Core Dump)</p>\n<h3 id=\"5-2-中断-interrupt\"><a href=\"#5-2-中断-interrupt\" class=\"headerlink\" title=\"5.2 中断 (interrupt)\"></a>5.2 中断 (interrupt)</h3><p>​    程序产生了未预期的输出，可以通过键入“delete” 字符生成一个 <code>interrupt</code> 信号来停止程序，并且这个信号之后导致程序停止而不会 Core Dump。</p>\n<h2 id=\"6-Unix-设计哲学\"><a href=\"#6-Unix-设计哲学\" class=\"headerlink\" title=\"6. Unix 设计哲学\"></a>6. Unix 设计哲学</h2><h3 id=\"6-1-简洁-Simplicity\"><a href=\"#6-1-简洁-Simplicity\" class=\"headerlink\" title=\"6.1 简洁 (Simplicity)\"></a>6.1 简洁 (Simplicity)</h3><blockquote>\n<p>First, since we are programmers, we naturally designed the system to make it easy to write, test, and run programs.</p>\n</blockquote>\n<ul>\n<li><p><strong>User Friendly</strong></p>\n<p>​    系统以使其易于编写，测试和运行程序。对编程便利性的渴望的最重要表达是该系统被安排用于交互 (interactive) 使用，即使原始版本仅支持一个用户。</p>\n<p>​    我们认为，设计合理的交互式系统比“批处理”系统更具生产力和使用满意度。而且，这样的系统相当容易适应于非交互使用，而反之则不成立。</p>\n</li>\n<li><p><strong>File Tree</strong></p>\n<p>层级的目录结构，让文件管理十分简洁清晰。</p>\n</li>\n<li><p><strong>File Abstract</strong></p>\n<p>一切皆是文件，将外部设备和目录统一抽象为文件，统一管理，代码复用而高效。所谓 Less is More</p>\n</li>\n</ul>\n<h3 id=\"6-2-易于部署-Flexiblility\"><a href=\"#6-2-易于部署-Flexiblility\" class=\"headerlink\" title=\"6.2 易于部署 (Flexiblility)\"></a>6.2 易于部署 (Flexiblility)</h3><blockquote>\n<p>UNIX can run on hardware costing as little as $40,000, and less than two man-years were spent on the main system software.</p>\n</blockquote>\n<p>​    用于安装UNIX系统的 PDP-11/45 是一个16位字长（8-bit byte），具有144K字节(byte)核心内存的计算机；UNIX占用了其中的42kb。然而这个系统包括了大量的设备驱动并且为I/O缓冲区和系统表分配了足够的空间；一个能够运行上述软件的最小系统，最小总共只需要 50kb 的内核。</p>\n<h3 id=\"6-3-可维护性-Maintainable\"><a href=\"#6-3-可维护性-Maintainable\" class=\"headerlink\" title=\"6.3 可维护性 (Maintainable)\"></a>6.3 可维护性 (Maintainable)</h3><blockquote>\n<p>Third, nearly from the start, the system was able to, and did, maintain itself.</p>\n</blockquote>\n<p>​    由于实现的简洁性，系统可维护性很好，从1972~1973年DENNIS M. RITCHIE AND KEN THOMPSON 用B和C相继重写了Unix内核后，用高级语言开发的Unix有着很好的可移植和迭代能力。</p>\n<p><strong>[讨论问题7] 你认为是什么让Unix如此成功？</strong></p>\n<ol>\n<li>设计哲学<br>Unix 虽然不是最早的分时操作系统，但其提出的一系列颠覆性的概念可以说重塑了操作系统界很多实现的范式，包括层级的文件系统以及一切皆文件的思想，一直延续至今。在如今看来这些好似稀松平常的概念，在当时的视角下是绝不trivial的想法。</li>\n<li>时代背景<br>在Multics的衬托下，Unix继承了Multics的功能，以其简单而有效的设计模式启发了大家，获得了商业上的巨大成功。<br> 可以说Unix的成功，是因为其出现在一个对的时间，并且做了对的事情。<br>同样我们在回顾 UNIX 的设计发展历程的时候，对我们当今设计和进一步优化目前的操作系统有指导意义，可以说是以史为鉴，让我们能够洞见未来的发展。</li>\n</ol>\n<h3 id=\"The-Unix-Family-Tree\"><a href=\"#The-Unix-Family-Tree\" class=\"headerlink\" title=\"The Unix Family Tree\"></a>The Unix Family Tree</h3><p><img src=\"http://www.netneurotic.net/mac/unix/images/UNIXthumb.png\" alt></p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>[1] <a href=\"https://en.wikipedia.org/wiki/Dennis_Ritchie\">Ritchie, D.M.</a>; <a href=\"https://en.wikipedia.org/wiki/Ken_Thompson\">Thompson, K.</a> (July–August 1978). <a href=\"https://web.archive.org/web/20101103053325/http://bstj.bell-labs.com/oldfiles/year.1978/BSTJ.1978.5706-2.html\">“The UNIX Time-Sharing System”</a>. <em><a href=\"https://en.wikipedia.org/wiki/Bell_System_Technical_Journal\">Bell System Technical Journal</a></em>. <strong>57</strong> (6). Archived from <a href=\"http://bstj.bell-labs.com/oldfiles/year.1978/BSTJ.1978.5706-2.html\">the original</a> on November 3, 2010.</p>\n<p>[2] <a href=\"http://www.levenez.com/unix/\">“UNIX History”</a>. <em>www.levenez.com</em>. Retrieved March 17, 2005.</p>\n<p>[3] <a href=\"http://www.unixguide.net/\">“AIX, FreeBSD, HP-UX, Linux, Solaris, Tru64”</a>. <em>UNIXguide.net</em>. Retrieved March 17, 2005.</p>\n<p>[4] <a href=\"https://lwn.net/2002/0221/bigpage.php3\">“Linux Weekly News, February 21, 2002”</a>. <em>lwn.net</em>. Retrieved April 7, 2006.</p>\n<p>[5] <a href=\"https://en.wikipedia.org/wiki/John_Lions\">Lions, John</a>: <em>Lions’ <a href=\"http://www.lemis.com/grog/Documentation/Lions/\">“Commentary on the Sixth Edition UNIX Operating System”</a>. with Source Code</em>, Peer-to-Peer Communications, 1996; <a href=\"https://en.wikipedia.org/wiki/ISBN_(identifier\">ISBN</a>) <a href=\"https://en.wikipedia.org/wiki/Special:BookSources/1-57398-013-7\">1-57398-013-7</a></p>\n"},{"title":"OS内核体系结构初探","date":"2021-07-10T22:21:20.000Z","index_img":"/img/OS/banner.png","_content":"\n## 一、内核体系结构\n\n### 基础概念\n- **操作系统内核**\n内核可以视作一个专门用于代理进程和硬件之间交互的程序，其调度进程来决定其什么时候可以使用硬件资源。其作为一种硬件抽象方法，防止了进程直接的和硬件进行交互，将软件和硬件隔离开来。资源的统一调度提高硬件资源的使用效率的同时，也保证了进程之间数据的相互隔离性和安全性。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsbxswmjhuj306404u3yf.jpg\" alt=\"计算机架构图\" style=\"zoom:150%;\" />\n\n- **内核层**\n\n  其可被理解为内核程序中实现不同功能的程序段，基本上有如下几个\n\n  1. 硬件驱动\n  2. 内存管理\n  3. 系统进程管理\n  4. 文件系统管理\n  5. 电源管理\n  6. USB等其余外部驱动接口  \n\n\n\n\n\n\n## 二、宏内核与微内核\n### 宏内核\n\n![宏内核示意图](https://tva1.sinaimg.cn/large/008i3skNly1gsbxbquhu6j308105k742.jpg)\n\n​\t所谓宏内核 (monolithic kernel)，就是所有的内核层都被集成到内核程序当中作为一个整体，代表当前进程在内核态下运行。大部分的Unix内核都是单块宏内核结构，linux也不例外。\n\n​\t宏内核因为所有的内核层都在内核程序中，所以内核代码具有高度的集成性，内核层之间可以直接通信而不需要依赖于慢速的IPC机制，但是缺点是整体内核显得较为臃肿，并且如果一个小模块出现bug，则整个系统都会崩溃。\n\n​\t为了解决这一问题，Linux通过模块动态链接机制来进行平衡，当需要用到相关服务之时再将其链接到内核当中，提高了内核的可扩展性。\n\n- **典型宏内核系统：**Linux\n\n### 微内核\n\n![微内核示意图](https://tva1.sinaimg.cn/large/008i3skNly1gsbxbo1wvvj308105kglf.jpg)\n\n​\t微内核（micro kernel）只要求整个内核程序中有所有内核层的一个子集 ——  几个同步语句、简单调度程序和IPC，其通过在微内核之上运行的几个系统进程实现内存层功能，例如内存分配、设备驱动、系统调用等。其目标是将系统服务的实现和系统的基本操作规则分离开来。\n\n​\t微内核将许多OS服务放入分离的系统进程实现、例如内存分配、设备驱动、文件系统等，使得整个内核大小较小、设计简单，且设计较为模块化。一个服务组件的失效不会导致整个系统的崩溃，内核只需重新启动该组件而不用影响其他部分。\n\n​\t同时因为每个系统层都是一个独立的程序，所以必须要定义明确而清晰的API和其他层级进行交互，迫使系统程序员采用模块化的方法，提高了内核的可移植性和可扩展性。\n\n​\t微内核比单块内核更充分的利用了RAM，因为暂不需要的系统进程可以被调出 (swap) 或销毁。\n\n​\t但同时，微内核的设计结构也注定系统进程之间的通信必须依赖于慢速的进程间通讯机制 （IPC），所以一般来说微内核运行的比宏内核慢。\n\n- **典型微内核系统：**Mac OS X （Mach）\n\n- **独特的应用场景**\n\n  因为微内核不会因为某个系统服务出错而导致整个系统的崩溃，其常常被应用于例如机器人、医疗器械的嵌入式设计、航天飞机上的机械手，还有研磨望远镜镜片的机器等特殊领域之中。在这些领域中，软件错误所造成的系统失效是非常致命的。\n\n\n\n## 三、激进的外内核\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsbxd3mxzmj317c0u0mz1.jpg\" alt=\"外内核架构\" style=\"zoom:25%;\" />\n\n​\t外内核系统，也被称为纵向结构操作系统，是一种比较极端的设计方法。其设计理念是让用户程序的设计者来决定硬件接口的设计，内核设计极简化，内核的唯一工作就是负责分配系统资源，并防止用户进程访问到其他进程的资源。\n\n​\t其目标是在于同时简化传统微内核的IPC机制以及宏内核的软件抽象层\n\n​\t理论上，这种设计可以让各种操作系统运行在一个外核之上，如Windows和Unix。并且设计人员可以根据运行效率调整系统的各部分功能。\n\n![外内核架构和普通内核对比](https://tva1.sinaimg.cn/large/008i3skNly1gsbxbkykvmj30cs095dgb.jpg)\n\n- **典型微内外系统：**未有商用操作系统，MIT exokernels\n\n  更多内容请见：[Exokernel - Wikipedia](https://en.wikipedia.org/wiki/Exokernel)\n\n","source":"_posts/OS/kernelArc.md","raw":"---\ntitle: OS内核体系结构初探\ndate: 2021-07-10 15:21:20\nindex_img: /img/OS/banner.png\ncategory: [OS]\ntags: [kernel]\n---\n\n## 一、内核体系结构\n\n### 基础概念\n- **操作系统内核**\n内核可以视作一个专门用于代理进程和硬件之间交互的程序，其调度进程来决定其什么时候可以使用硬件资源。其作为一种硬件抽象方法，防止了进程直接的和硬件进行交互，将软件和硬件隔离开来。资源的统一调度提高硬件资源的使用效率的同时，也保证了进程之间数据的相互隔离性和安全性。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsbxswmjhuj306404u3yf.jpg\" alt=\"计算机架构图\" style=\"zoom:150%;\" />\n\n- **内核层**\n\n  其可被理解为内核程序中实现不同功能的程序段，基本上有如下几个\n\n  1. 硬件驱动\n  2. 内存管理\n  3. 系统进程管理\n  4. 文件系统管理\n  5. 电源管理\n  6. USB等其余外部驱动接口  \n\n\n\n\n\n\n## 二、宏内核与微内核\n### 宏内核\n\n![宏内核示意图](https://tva1.sinaimg.cn/large/008i3skNly1gsbxbquhu6j308105k742.jpg)\n\n​\t所谓宏内核 (monolithic kernel)，就是所有的内核层都被集成到内核程序当中作为一个整体，代表当前进程在内核态下运行。大部分的Unix内核都是单块宏内核结构，linux也不例外。\n\n​\t宏内核因为所有的内核层都在内核程序中，所以内核代码具有高度的集成性，内核层之间可以直接通信而不需要依赖于慢速的IPC机制，但是缺点是整体内核显得较为臃肿，并且如果一个小模块出现bug，则整个系统都会崩溃。\n\n​\t为了解决这一问题，Linux通过模块动态链接机制来进行平衡，当需要用到相关服务之时再将其链接到内核当中，提高了内核的可扩展性。\n\n- **典型宏内核系统：**Linux\n\n### 微内核\n\n![微内核示意图](https://tva1.sinaimg.cn/large/008i3skNly1gsbxbo1wvvj308105kglf.jpg)\n\n​\t微内核（micro kernel）只要求整个内核程序中有所有内核层的一个子集 ——  几个同步语句、简单调度程序和IPC，其通过在微内核之上运行的几个系统进程实现内存层功能，例如内存分配、设备驱动、系统调用等。其目标是将系统服务的实现和系统的基本操作规则分离开来。\n\n​\t微内核将许多OS服务放入分离的系统进程实现、例如内存分配、设备驱动、文件系统等，使得整个内核大小较小、设计简单，且设计较为模块化。一个服务组件的失效不会导致整个系统的崩溃，内核只需重新启动该组件而不用影响其他部分。\n\n​\t同时因为每个系统层都是一个独立的程序，所以必须要定义明确而清晰的API和其他层级进行交互，迫使系统程序员采用模块化的方法，提高了内核的可移植性和可扩展性。\n\n​\t微内核比单块内核更充分的利用了RAM，因为暂不需要的系统进程可以被调出 (swap) 或销毁。\n\n​\t但同时，微内核的设计结构也注定系统进程之间的通信必须依赖于慢速的进程间通讯机制 （IPC），所以一般来说微内核运行的比宏内核慢。\n\n- **典型微内核系统：**Mac OS X （Mach）\n\n- **独特的应用场景**\n\n  因为微内核不会因为某个系统服务出错而导致整个系统的崩溃，其常常被应用于例如机器人、医疗器械的嵌入式设计、航天飞机上的机械手，还有研磨望远镜镜片的机器等特殊领域之中。在这些领域中，软件错误所造成的系统失效是非常致命的。\n\n\n\n## 三、激进的外内核\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsbxd3mxzmj317c0u0mz1.jpg\" alt=\"外内核架构\" style=\"zoom:25%;\" />\n\n​\t外内核系统，也被称为纵向结构操作系统，是一种比较极端的设计方法。其设计理念是让用户程序的设计者来决定硬件接口的设计，内核设计极简化，内核的唯一工作就是负责分配系统资源，并防止用户进程访问到其他进程的资源。\n\n​\t其目标是在于同时简化传统微内核的IPC机制以及宏内核的软件抽象层\n\n​\t理论上，这种设计可以让各种操作系统运行在一个外核之上，如Windows和Unix。并且设计人员可以根据运行效率调整系统的各部分功能。\n\n![外内核架构和普通内核对比](https://tva1.sinaimg.cn/large/008i3skNly1gsbxbkykvmj30cs095dgb.jpg)\n\n- **典型微内外系统：**未有商用操作系统，MIT exokernels\n\n  更多内容请见：[Exokernel - Wikipedia](https://en.wikipedia.org/wiki/Exokernel)\n\n","slug":"OS/kernelArc","published":1,"updated":"2026-02-03T05:42:14.444Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvj003l7uit0yzu7zv6","content":"<h2 id=\"一、内核体系结构\"><a href=\"#一、内核体系结构\" class=\"headerlink\" title=\"一、内核体系结构\"></a>一、内核体系结构</h2><h3 id=\"基础概念\"><a href=\"#基础概念\" class=\"headerlink\" title=\"基础概念\"></a>基础概念</h3><ul>\n<li><strong>操作系统内核</strong><br>内核可以视作一个专门用于代理进程和硬件之间交互的程序，其调度进程来决定其什么时候可以使用硬件资源。其作为一种硬件抽象方法，防止了进程直接的和硬件进行交互，将软件和硬件隔离开来。资源的统一调度提高硬件资源的使用效率的同时，也保证了进程之间数据的相互隔离性和安全性。</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsbxswmjhuj306404u3yf.jpg\" alt=\"计算机架构图\" style=\"zoom:150%;\"></p>\n<ul>\n<li><p><strong>内核层</strong></p>\n<p>其可被理解为内核程序中实现不同功能的程序段，基本上有如下几个</p>\n<ol>\n<li>硬件驱动</li>\n<li>内存管理</li>\n<li>系统进程管理</li>\n<li>文件系统管理</li>\n<li>电源管理</li>\n<li>USB等其余外部驱动接口  </li>\n</ol>\n</li>\n</ul>\n<h2 id=\"二、宏内核与微内核\"><a href=\"#二、宏内核与微内核\" class=\"headerlink\" title=\"二、宏内核与微内核\"></a>二、宏内核与微内核</h2><h3 id=\"宏内核\"><a href=\"#宏内核\" class=\"headerlink\" title=\"宏内核\"></a>宏内核</h3><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsbxbquhu6j308105k742.jpg\" alt=\"宏内核示意图\"></p>\n<p>​    所谓宏内核 (monolithic kernel)，就是所有的内核层都被集成到内核程序当中作为一个整体，代表当前进程在内核态下运行。大部分的Unix内核都是单块宏内核结构，linux也不例外。</p>\n<p>​    宏内核因为所有的内核层都在内核程序中，所以内核代码具有高度的集成性，内核层之间可以直接通信而不需要依赖于慢速的IPC机制，但是缺点是整体内核显得较为臃肿，并且如果一个小模块出现bug，则整个系统都会崩溃。</p>\n<p>​    为了解决这一问题，Linux通过模块动态链接机制来进行平衡，当需要用到相关服务之时再将其链接到内核当中，提高了内核的可扩展性。</p>\n<ul>\n<li><strong>典型宏内核系统：</strong>Linux</li>\n</ul>\n<h3 id=\"微内核\"><a href=\"#微内核\" class=\"headerlink\" title=\"微内核\"></a>微内核</h3><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsbxbo1wvvj308105kglf.jpg\" alt=\"微内核示意图\"></p>\n<p>​    微内核（micro kernel）只要求整个内核程序中有所有内核层的一个子集 ——  几个同步语句、简单调度程序和IPC，其通过在微内核之上运行的几个系统进程实现内存层功能，例如内存分配、设备驱动、系统调用等。其目标是将系统服务的实现和系统的基本操作规则分离开来。</p>\n<p>​    微内核将许多OS服务放入分离的系统进程实现、例如内存分配、设备驱动、文件系统等，使得整个内核大小较小、设计简单，且设计较为模块化。一个服务组件的失效不会导致整个系统的崩溃，内核只需重新启动该组件而不用影响其他部分。</p>\n<p>​    同时因为每个系统层都是一个独立的程序，所以必须要定义明确而清晰的API和其他层级进行交互，迫使系统程序员采用模块化的方法，提高了内核的可移植性和可扩展性。</p>\n<p>​    微内核比单块内核更充分的利用了RAM，因为暂不需要的系统进程可以被调出 (swap) 或销毁。</p>\n<p>​    但同时，微内核的设计结构也注定系统进程之间的通信必须依赖于慢速的进程间通讯机制 （IPC），所以一般来说微内核运行的比宏内核慢。</p>\n<ul>\n<li><p><strong>典型微内核系统：</strong>Mac OS X （Mach）</p>\n</li>\n<li><p><strong>独特的应用场景</strong></p>\n<p>因为微内核不会因为某个系统服务出错而导致整个系统的崩溃，其常常被应用于例如机器人、医疗器械的嵌入式设计、航天飞机上的机械手，还有研磨望远镜镜片的机器等特殊领域之中。在这些领域中，软件错误所造成的系统失效是非常致命的。</p>\n</li>\n</ul>\n<h2 id=\"三、激进的外内核\"><a href=\"#三、激进的外内核\" class=\"headerlink\" title=\"三、激进的外内核\"></a>三、激进的外内核</h2><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsbxd3mxzmj317c0u0mz1.jpg\" alt=\"外内核架构\" style=\"zoom:25%;\"></p>\n<p>​    外内核系统，也被称为纵向结构操作系统，是一种比较极端的设计方法。其设计理念是让用户程序的设计者来决定硬件接口的设计，内核设计极简化，内核的唯一工作就是负责分配系统资源，并防止用户进程访问到其他进程的资源。</p>\n<p>​    其目标是在于同时简化传统微内核的IPC机制以及宏内核的软件抽象层</p>\n<p>​    理论上，这种设计可以让各种操作系统运行在一个外核之上，如Windows和Unix。并且设计人员可以根据运行效率调整系统的各部分功能。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsbxbkykvmj30cs095dgb.jpg\" alt=\"外内核架构和普通内核对比\"></p>\n<ul>\n<li><p><strong>典型微内外系统：</strong>未有商用操作系统，MIT exokernels</p>\n<p>更多内容请见：<a href=\"https://en.wikipedia.org/wiki/Exokernel\">Exokernel - Wikipedia</a></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"一、内核体系结构\"><a href=\"#一、内核体系结构\" class=\"headerlink\" title=\"一、内核体系结构\"></a>一、内核体系结构</h2><h3 id=\"基础概念\"><a href=\"#基础概念\" class=\"headerlink\" title=\"基础概念\"></a>基础概念</h3><ul>\n<li><strong>操作系统内核</strong><br>内核可以视作一个专门用于代理进程和硬件之间交互的程序，其调度进程来决定其什么时候可以使用硬件资源。其作为一种硬件抽象方法，防止了进程直接的和硬件进行交互，将软件和硬件隔离开来。资源的统一调度提高硬件资源的使用效率的同时，也保证了进程之间数据的相互隔离性和安全性。</li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsbxswmjhuj306404u3yf.jpg\" alt=\"计算机架构图\" style=\"zoom:150%;\"></p>\n<ul>\n<li><p><strong>内核层</strong></p>\n<p>其可被理解为内核程序中实现不同功能的程序段，基本上有如下几个</p>\n<ol>\n<li>硬件驱动</li>\n<li>内存管理</li>\n<li>系统进程管理</li>\n<li>文件系统管理</li>\n<li>电源管理</li>\n<li>USB等其余外部驱动接口  </li>\n</ol>\n</li>\n</ul>\n<h2 id=\"二、宏内核与微内核\"><a href=\"#二、宏内核与微内核\" class=\"headerlink\" title=\"二、宏内核与微内核\"></a>二、宏内核与微内核</h2><h3 id=\"宏内核\"><a href=\"#宏内核\" class=\"headerlink\" title=\"宏内核\"></a>宏内核</h3><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsbxbquhu6j308105k742.jpg\" alt=\"宏内核示意图\"></p>\n<p>​    所谓宏内核 (monolithic kernel)，就是所有的内核层都被集成到内核程序当中作为一个整体，代表当前进程在内核态下运行。大部分的Unix内核都是单块宏内核结构，linux也不例外。</p>\n<p>​    宏内核因为所有的内核层都在内核程序中，所以内核代码具有高度的集成性，内核层之间可以直接通信而不需要依赖于慢速的IPC机制，但是缺点是整体内核显得较为臃肿，并且如果一个小模块出现bug，则整个系统都会崩溃。</p>\n<p>​    为了解决这一问题，Linux通过模块动态链接机制来进行平衡，当需要用到相关服务之时再将其链接到内核当中，提高了内核的可扩展性。</p>\n<ul>\n<li><strong>典型宏内核系统：</strong>Linux</li>\n</ul>\n<h3 id=\"微内核\"><a href=\"#微内核\" class=\"headerlink\" title=\"微内核\"></a>微内核</h3><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsbxbo1wvvj308105kglf.jpg\" alt=\"微内核示意图\"></p>\n<p>​    微内核（micro kernel）只要求整个内核程序中有所有内核层的一个子集 ——  几个同步语句、简单调度程序和IPC，其通过在微内核之上运行的几个系统进程实现内存层功能，例如内存分配、设备驱动、系统调用等。其目标是将系统服务的实现和系统的基本操作规则分离开来。</p>\n<p>​    微内核将许多OS服务放入分离的系统进程实现、例如内存分配、设备驱动、文件系统等，使得整个内核大小较小、设计简单，且设计较为模块化。一个服务组件的失效不会导致整个系统的崩溃，内核只需重新启动该组件而不用影响其他部分。</p>\n<p>​    同时因为每个系统层都是一个独立的程序，所以必须要定义明确而清晰的API和其他层级进行交互，迫使系统程序员采用模块化的方法，提高了内核的可移植性和可扩展性。</p>\n<p>​    微内核比单块内核更充分的利用了RAM，因为暂不需要的系统进程可以被调出 (swap) 或销毁。</p>\n<p>​    但同时，微内核的设计结构也注定系统进程之间的通信必须依赖于慢速的进程间通讯机制 （IPC），所以一般来说微内核运行的比宏内核慢。</p>\n<ul>\n<li><p><strong>典型微内核系统：</strong>Mac OS X （Mach）</p>\n</li>\n<li><p><strong>独特的应用场景</strong></p>\n<p>因为微内核不会因为某个系统服务出错而导致整个系统的崩溃，其常常被应用于例如机器人、医疗器械的嵌入式设计、航天飞机上的机械手，还有研磨望远镜镜片的机器等特殊领域之中。在这些领域中，软件错误所造成的系统失效是非常致命的。</p>\n</li>\n</ul>\n<h2 id=\"三、激进的外内核\"><a href=\"#三、激进的外内核\" class=\"headerlink\" title=\"三、激进的外内核\"></a>三、激进的外内核</h2><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsbxd3mxzmj317c0u0mz1.jpg\" alt=\"外内核架构\" style=\"zoom:25%;\"></p>\n<p>​    外内核系统，也被称为纵向结构操作系统，是一种比较极端的设计方法。其设计理念是让用户程序的设计者来决定硬件接口的设计，内核设计极简化，内核的唯一工作就是负责分配系统资源，并防止用户进程访问到其他进程的资源。</p>\n<p>​    其目标是在于同时简化传统微内核的IPC机制以及宏内核的软件抽象层</p>\n<p>​    理论上，这种设计可以让各种操作系统运行在一个外核之上，如Windows和Unix。并且设计人员可以根据运行效率调整系统的各部分功能。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gsbxbkykvmj30cs095dgb.jpg\" alt=\"外内核架构和普通内核对比\"></p>\n<ul>\n<li><p><strong>典型微内外系统：</strong>未有商用操作系统，MIT exokernels</p>\n<p>更多内容请见：<a href=\"https://en.wikipedia.org/wiki/Exokernel\">Exokernel - Wikipedia</a></p>\n</li>\n</ul>\n"},{"title":"CaDDN论文阅读","date":"2021-03-10T04:20:50.000Z","index_img":"/img/AI.png","math":true,"_content":"\n# **Categorical Depth Distribution Network for Monocular 3D Object Detection**\n\n**关键词： 单目3d检测、绝对深度分配网络**\n\n**论文链接：**https://arxiv.org/pdf/2103.01100.pdf\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1godx97xntnj30bl08p0wn.jpg)\n\n## 前言\n\n​\t单目3D检测的难点一直在于对深度的预测，实例从3D空间被映射到2D平面的图像上丢失了深度信息，对深度的处理一直是单目3D目标检测研究的重点方向，目前主流的方法主要分为三类。\n\n**1、直接检测  (Direct Methods)**\n\n​\t直接检测方法没有显式的对深度进行学习，比较有代表性的是关键点检测方法，通过关键点结合几何特征来帮助3D-Bbox的检测，好处是简单直接且高效，但这类方法由于没有显式的学习深度信息，往往导致深度预测的结果不尽理想。\n\n**2、基于深度  (Depth-Based Methods)**\n\n​\t基于深度的方法通常先会通过一个单目深度预测分支来得到一张深度图作为网络的输入从而辅助对深度的检测，由于有了深度信息其可被转换成点云来处理（可以用上3d检测的方法)。但由于其深度和目标检测分离训练的结构，导致其可能会丢失一些隐含的信息。\n\n**3、基于网格  (Grid-Based Methods)**\n\n​\t基于网格的方法避免了对深度的直接预测，而是通过预测一个 BEV grid 的表达来作为3D检测网络的输入，OFT[1]提出了一种体素网格，通过把体素投影到图像平面上进而采样图像特征将其转换成BEV的形式。但这也会导致大量体素和特征的重叠从而降低检测的准确性。\n\n\n\n​\t**CaDDN** 网络对上面三种情况的优点进行结合，整体网络结构是同时训练了深度预测和3D检测（jointly）以期待其能够解决方法2中的问题，同时利用也将图像平面转换成了BEV的形式来提高检测的准确性。\n\n![网络结构](https://tva1.sinaimg.cn/large/008eGmZEgy1godxz73f1jj30nm0dntcy.jpg)\n\n\n\n## 网络结构\n\n### Frustum Feature Network\n\n- **Depth Distribution Network**\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1godzoe00t7j30b908dabe.jpg)\n\n对于特征提取网络，其输出形似一个截角锥形，因而作者称其为Frustum feature Network，其输入是原始图像 $I \\in R^{W_1\\times H_1\\times 3}$ 输出 $G \\in R^{W_F\\times H_F\\times D \\times C}$ 其中 W和H是特征的宽高，D 是深度桶，用以深度预测，C 是特征的维度。图像特征被用以在每个像素上预测绝对的深度分布 $D \\in R^{W_F\\times H_F\\times D}$ 网络对每个像素预测其落入某一深度桶（深度离散化）的概率，总共D个。\n\n（这一网络其是从 DeepLabV3[2] 上魔改过来的。）\n\n- Image Channel Reduce\n\n同时在分配深度桶的同时，网络另一分支用1x1卷积 + BN + ReLU 把特征的维数从256降到了64。\n\n\n\n​\t经过这两个分支后，将预测出来的深度桶和特征像素做外积得到了带有深度信息的特征图（$G(u,v) = D(u,v) \\otimes F(u,v)$）且由于特征桶的结构，具有较高的容错性。称 G 为 frustum features\n\n\n\n### Frustum to Voxel Trans\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1godzokeng2j30b907ujsr.jpg)\n\n\n\n​\tG 之后将被转换成体素的形式，这里的问题是在第分辨率的frustum features进行高分辨率的体素采样会导致过采样，导致出现大量相同的体素特征，浪费算力不说还降低预测准确性。所以这边作者直接把降采样前的特征层拉了过来，来保证不会出现上述问题。\n\n\n\n ### Voxel Collapse to BEV -> Detection\n\n​\t由于BEV在保证同等检测效果的情况下能够节省计算资源，作者将体素的 Z 轴和 channels 直接连接起来，继续用1x1卷积 + BN + ReLU 将体素块压缩成 BEV的形式。然后接着在 BEV 特征块上连接检测头进行 3D目标检测。\n\n\n\n## 深度离散化\n\n​\t本文的主要亮点就是其对于深度的处理，其对每个像素位置分配了离散化的深度桶，预测其属于某一深度的概率。这里的深度离散化作者使用的是 LID (Linear-increasing discretization)[3] 因为其对不同深度之间提供了最为平衡的预测概率。对于检测任务的深度我们最需要的是检测目标的深度信息，而更少去在意背景点的深度。\n\n​\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t$$d_c = d_min + \\frac{d_{max}-d_{min}}{D(D+1)}\\cdot{d_i}{(d_1+1)}$$\n\n​\t*（其中 $d_c$ 是连续深度值，[$d_{min},d_{max}$]是离散化的上下界，D是深度桶的数量，$d_i$ 是下标）*\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1goe03wlr9sj30dn0bd0tp.jpg)\n\n\n\n## 实验效果\n\n![KITTI实验效果](https://tva1.sinaimg.cn/large/008eGmZEgy1goe0ckxhf6j30r10fgn17.jpg)\n\n​\t可以看到其在车辆和新人检测上都打破了目前最好的检测方法，对骑行者的检测不如 MonoPSR 但也大大超过了其余检测模型。\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1goe0gh8vyhj30dw07jdgw.jpg)\n\n这张表可以看出其将深度预测和特征融合所得到的 frustum features 确实有助于提升检测效果。\n\n\n\n## 结语\n\n​\t个人觉得这篇paper的主要成功点在于其对于单目深度预测的创新解决方法，不同于传统的深度预测模型，提出了离散化深度将每个像素的深度概率离散化分配在不同的深度桶中，避免了网络过度依赖于深度的准确检测。但同时其也没有从根本上解决深度预测的问题，同时其中间对于特征图进行体素化投影再转为 BEV 的过程较为复杂，虽然其把降采样前的特征层拿来转成体素形式但是仍然还是无法避免会有损失。\n\n​\t个人觉得可以借鉴该模型的深度预测方法，应用在现有的模型上或者对该模型的网络结构进行简化，可能会带来更好的效果。\n\n\n\n---\n\n### Reference\n\n[1]  Thomas Roddick, Alex Kendall, and Roberto Cipolla. Ortho\u0002 graphic feature transform for monocular 3D object detection.*BMVC*, 2018\n\n[2] Liang-Chieh Chen, George Papandreou, Florian Schroff, andHartwig Adam. Rethinking atrous convolution for semantic image segmentation. *arXiv preprint*, 2017\n\n[3] Yunlei Tang, Sebastian Dorn, and Chiragkumar Savani. Cen\u0002ter3d: Center-based monocular 3d object detection with joint depth understanding. *arXiv preprint*, 2020","source":"_posts/Research/CaDDN-Paper.md","raw":"---\ntitle: CaDDN论文阅读\ndate: 2021-03-09 20:20:50\nindex_img: /img/AI.png\ncategory: [Research, Object Detection]\ntags: [Monocular OD]\nmath: true\n---\n\n# **Categorical Depth Distribution Network for Monocular 3D Object Detection**\n\n**关键词： 单目3d检测、绝对深度分配网络**\n\n**论文链接：**https://arxiv.org/pdf/2103.01100.pdf\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1godx97xntnj30bl08p0wn.jpg)\n\n## 前言\n\n​\t单目3D检测的难点一直在于对深度的预测，实例从3D空间被映射到2D平面的图像上丢失了深度信息，对深度的处理一直是单目3D目标检测研究的重点方向，目前主流的方法主要分为三类。\n\n**1、直接检测  (Direct Methods)**\n\n​\t直接检测方法没有显式的对深度进行学习，比较有代表性的是关键点检测方法，通过关键点结合几何特征来帮助3D-Bbox的检测，好处是简单直接且高效，但这类方法由于没有显式的学习深度信息，往往导致深度预测的结果不尽理想。\n\n**2、基于深度  (Depth-Based Methods)**\n\n​\t基于深度的方法通常先会通过一个单目深度预测分支来得到一张深度图作为网络的输入从而辅助对深度的检测，由于有了深度信息其可被转换成点云来处理（可以用上3d检测的方法)。但由于其深度和目标检测分离训练的结构，导致其可能会丢失一些隐含的信息。\n\n**3、基于网格  (Grid-Based Methods)**\n\n​\t基于网格的方法避免了对深度的直接预测，而是通过预测一个 BEV grid 的表达来作为3D检测网络的输入，OFT[1]提出了一种体素网格，通过把体素投影到图像平面上进而采样图像特征将其转换成BEV的形式。但这也会导致大量体素和特征的重叠从而降低检测的准确性。\n\n\n\n​\t**CaDDN** 网络对上面三种情况的优点进行结合，整体网络结构是同时训练了深度预测和3D检测（jointly）以期待其能够解决方法2中的问题，同时利用也将图像平面转换成了BEV的形式来提高检测的准确性。\n\n![网络结构](https://tva1.sinaimg.cn/large/008eGmZEgy1godxz73f1jj30nm0dntcy.jpg)\n\n\n\n## 网络结构\n\n### Frustum Feature Network\n\n- **Depth Distribution Network**\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1godzoe00t7j30b908dabe.jpg)\n\n对于特征提取网络，其输出形似一个截角锥形，因而作者称其为Frustum feature Network，其输入是原始图像 $I \\in R^{W_1\\times H_1\\times 3}$ 输出 $G \\in R^{W_F\\times H_F\\times D \\times C}$ 其中 W和H是特征的宽高，D 是深度桶，用以深度预测，C 是特征的维度。图像特征被用以在每个像素上预测绝对的深度分布 $D \\in R^{W_F\\times H_F\\times D}$ 网络对每个像素预测其落入某一深度桶（深度离散化）的概率，总共D个。\n\n（这一网络其是从 DeepLabV3[2] 上魔改过来的。）\n\n- Image Channel Reduce\n\n同时在分配深度桶的同时，网络另一分支用1x1卷积 + BN + ReLU 把特征的维数从256降到了64。\n\n\n\n​\t经过这两个分支后，将预测出来的深度桶和特征像素做外积得到了带有深度信息的特征图（$G(u,v) = D(u,v) \\otimes F(u,v)$）且由于特征桶的结构，具有较高的容错性。称 G 为 frustum features\n\n\n\n### Frustum to Voxel Trans\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1godzokeng2j30b907ujsr.jpg)\n\n\n\n​\tG 之后将被转换成体素的形式，这里的问题是在第分辨率的frustum features进行高分辨率的体素采样会导致过采样，导致出现大量相同的体素特征，浪费算力不说还降低预测准确性。所以这边作者直接把降采样前的特征层拉了过来，来保证不会出现上述问题。\n\n\n\n ### Voxel Collapse to BEV -> Detection\n\n​\t由于BEV在保证同等检测效果的情况下能够节省计算资源，作者将体素的 Z 轴和 channels 直接连接起来，继续用1x1卷积 + BN + ReLU 将体素块压缩成 BEV的形式。然后接着在 BEV 特征块上连接检测头进行 3D目标检测。\n\n\n\n## 深度离散化\n\n​\t本文的主要亮点就是其对于深度的处理，其对每个像素位置分配了离散化的深度桶，预测其属于某一深度的概率。这里的深度离散化作者使用的是 LID (Linear-increasing discretization)[3] 因为其对不同深度之间提供了最为平衡的预测概率。对于检测任务的深度我们最需要的是检测目标的深度信息，而更少去在意背景点的深度。\n\n​\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t$$d_c = d_min + \\frac{d_{max}-d_{min}}{D(D+1)}\\cdot{d_i}{(d_1+1)}$$\n\n​\t*（其中 $d_c$ 是连续深度值，[$d_{min},d_{max}$]是离散化的上下界，D是深度桶的数量，$d_i$ 是下标）*\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1goe03wlr9sj30dn0bd0tp.jpg)\n\n\n\n## 实验效果\n\n![KITTI实验效果](https://tva1.sinaimg.cn/large/008eGmZEgy1goe0ckxhf6j30r10fgn17.jpg)\n\n​\t可以看到其在车辆和新人检测上都打破了目前最好的检测方法，对骑行者的检测不如 MonoPSR 但也大大超过了其余检测模型。\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1goe0gh8vyhj30dw07jdgw.jpg)\n\n这张表可以看出其将深度预测和特征融合所得到的 frustum features 确实有助于提升检测效果。\n\n\n\n## 结语\n\n​\t个人觉得这篇paper的主要成功点在于其对于单目深度预测的创新解决方法，不同于传统的深度预测模型，提出了离散化深度将每个像素的深度概率离散化分配在不同的深度桶中，避免了网络过度依赖于深度的准确检测。但同时其也没有从根本上解决深度预测的问题，同时其中间对于特征图进行体素化投影再转为 BEV 的过程较为复杂，虽然其把降采样前的特征层拿来转成体素形式但是仍然还是无法避免会有损失。\n\n​\t个人觉得可以借鉴该模型的深度预测方法，应用在现有的模型上或者对该模型的网络结构进行简化，可能会带来更好的效果。\n\n\n\n---\n\n### Reference\n\n[1]  Thomas Roddick, Alex Kendall, and Roberto Cipolla. Ortho\u0002 graphic feature transform for monocular 3D object detection.*BMVC*, 2018\n\n[2] Liang-Chieh Chen, George Papandreou, Florian Schroff, andHartwig Adam. Rethinking atrous convolution for semantic image segmentation. *arXiv preprint*, 2017\n\n[3] Yunlei Tang, Sebastian Dorn, and Chiragkumar Savani. Cen\u0002ter3d: Center-based monocular 3d object detection with joint depth understanding. *arXiv preprint*, 2020","slug":"Research/CaDDN-Paper","published":1,"updated":"2026-02-03T05:42:14.450Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvj003n7uit68fc4ywh","content":"<h1 id=\"Categorical-Depth-Distribution-Network-for-Monocular-3D-Object-Detection\"><a href=\"#Categorical-Depth-Distribution-Network-for-Monocular-3D-Object-Detection\" class=\"headerlink\" title=\"Categorical Depth Distribution Network for Monocular 3D Object Detection\"></a><strong>Categorical Depth Distribution Network for Monocular 3D Object Detection</strong></h1><p><strong>关键词： 单目3d检测、绝对深度分配网络</strong></p>\n<p><strong>论文链接：</strong><a href=\"https://arxiv.org/pdf/2103.01100.pdf\">https://arxiv.org/pdf/2103.01100.pdf</a></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1godx97xntnj30bl08p0wn.jpg\" alt></p>\n<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>​    单目3D检测的难点一直在于对深度的预测，实例从3D空间被映射到2D平面的图像上丢失了深度信息，对深度的处理一直是单目3D目标检测研究的重点方向，目前主流的方法主要分为三类。</p>\n<p><strong>1、直接检测  (Direct Methods)</strong></p>\n<p>​    直接检测方法没有显式的对深度进行学习，比较有代表性的是关键点检测方法，通过关键点结合几何特征来帮助3D-Bbox的检测，好处是简单直接且高效，但这类方法由于没有显式的学习深度信息，往往导致深度预测的结果不尽理想。</p>\n<p><strong>2、基于深度  (Depth-Based Methods)</strong></p>\n<p>​    基于深度的方法通常先会通过一个单目深度预测分支来得到一张深度图作为网络的输入从而辅助对深度的检测，由于有了深度信息其可被转换成点云来处理（可以用上3d检测的方法)。但由于其深度和目标检测分离训练的结构，导致其可能会丢失一些隐含的信息。</p>\n<p><strong>3、基于网格  (Grid-Based Methods)</strong></p>\n<p>​    基于网格的方法避免了对深度的直接预测，而是通过预测一个 BEV grid 的表达来作为3D检测网络的输入，OFT[1]提出了一种体素网格，通过把体素投影到图像平面上进而采样图像特征将其转换成BEV的形式。但这也会导致大量体素和特征的重叠从而降低检测的准确性。</p>\n<p>​    <strong>CaDDN</strong> 网络对上面三种情况的优点进行结合，整体网络结构是同时训练了深度预测和3D检测（jointly）以期待其能够解决方法2中的问题，同时利用也将图像平面转换成了BEV的形式来提高检测的准确性。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1godxz73f1jj30nm0dntcy.jpg\" alt=\"网络结构\"></p>\n<h2 id=\"网络结构\"><a href=\"#网络结构\" class=\"headerlink\" title=\"网络结构\"></a>网络结构</h2><h3 id=\"Frustum-Feature-Network\"><a href=\"#Frustum-Feature-Network\" class=\"headerlink\" title=\"Frustum Feature Network\"></a>Frustum Feature Network</h3><ul>\n<li><strong>Depth Distribution Network</strong></li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1godzoe00t7j30b908dabe.jpg\" alt></p>\n<p>对于特征提取网络，其输出形似一个截角锥形，因而作者称其为Frustum feature Network，其输入是原始图像 $I \\in R^{W_1\\times H_1\\times 3}$ 输出 $G \\in R^{W_F\\times H_F\\times D \\times C}$ 其中 W和H是特征的宽高，D 是深度桶，用以深度预测，C 是特征的维度。图像特征被用以在每个像素上预测绝对的深度分布 $D \\in R^{W_F\\times H_F\\times D}$ 网络对每个像素预测其落入某一深度桶（深度离散化）的概率，总共D个。</p>\n<p>（这一网络其是从 DeepLabV3[2] 上魔改过来的。）</p>\n<ul>\n<li>Image Channel Reduce</li>\n</ul>\n<p>同时在分配深度桶的同时，网络另一分支用1x1卷积 + BN + ReLU 把特征的维数从256降到了64。</p>\n<p>​    经过这两个分支后，将预测出来的深度桶和特征像素做外积得到了带有深度信息的特征图（$G(u,v) = D(u,v) \\otimes F(u,v)$）且由于特征桶的结构，具有较高的容错性。称 G 为 frustum features</p>\n<h3 id=\"Frustum-to-Voxel-Trans\"><a href=\"#Frustum-to-Voxel-Trans\" class=\"headerlink\" title=\"Frustum to Voxel Trans\"></a>Frustum to Voxel Trans</h3><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1godzokeng2j30b907ujsr.jpg\" alt></p>\n<p>​    G 之后将被转换成体素的形式，这里的问题是在第分辨率的frustum features进行高分辨率的体素采样会导致过采样，导致出现大量相同的体素特征，浪费算力不说还降低预测准确性。所以这边作者直接把降采样前的特征层拉了过来，来保证不会出现上述问题。</p>\n<h3 id=\"Voxel-Collapse-to-BEV-gt-Detection\"><a href=\"#Voxel-Collapse-to-BEV-gt-Detection\" class=\"headerlink\" title=\"Voxel Collapse to BEV -&gt; Detection\"></a>Voxel Collapse to BEV -&gt; Detection</h3><p>​    由于BEV在保证同等检测效果的情况下能够节省计算资源，作者将体素的 Z 轴和 channels 直接连接起来，继续用1x1卷积 + BN + ReLU 将体素块压缩成 BEV的形式。然后接着在 BEV 特征块上连接检测头进行 3D目标检测。</p>\n<h2 id=\"深度离散化\"><a href=\"#深度离散化\" class=\"headerlink\" title=\"深度离散化\"></a>深度离散化</h2><p>​    本文的主要亮点就是其对于深度的处理，其对每个像素位置分配了离散化的深度桶，预测其属于某一深度的概率。这里的深度离散化作者使用的是 LID (Linear-increasing discretization)[3] 因为其对不同深度之间提供了最为平衡的预测概率。对于检测任务的深度我们最需要的是检测目标的深度信息，而更少去在意背景点的深度。</p>\n<p>​                                                            <script type=\"math/tex\">d_c = d_min + \\frac{d_{max}-d_{min}}{D(D+1)}\\cdot{d_i}{(d_1+1)}</script></p>\n<p>​    <em>（其中 $d<em>c$ 是连续深度值，[$d</em>{min},d_{max}$]是离散化的上下界，D是深度桶的数量，$d_i$ 是下标）</em></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1goe03wlr9sj30dn0bd0tp.jpg\" alt></p>\n<h2 id=\"实验效果\"><a href=\"#实验效果\" class=\"headerlink\" title=\"实验效果\"></a>实验效果</h2><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1goe0ckxhf6j30r10fgn17.jpg\" alt=\"KITTI实验效果\"></p>\n<p>​    可以看到其在车辆和新人检测上都打破了目前最好的检测方法，对骑行者的检测不如 MonoPSR 但也大大超过了其余检测模型。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1goe0gh8vyhj30dw07jdgw.jpg\" alt></p>\n<p>这张表可以看出其将深度预测和特征融合所得到的 frustum features 确实有助于提升检测效果。</p>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>​    个人觉得这篇paper的主要成功点在于其对于单目深度预测的创新解决方法，不同于传统的深度预测模型，提出了离散化深度将每个像素的深度概率离散化分配在不同的深度桶中，避免了网络过度依赖于深度的准确检测。但同时其也没有从根本上解决深度预测的问题，同时其中间对于特征图进行体素化投影再转为 BEV 的过程较为复杂，虽然其把降采样前的特征层拿来转成体素形式但是仍然还是无法避免会有损失。</p>\n<p>​    个人觉得可以借鉴该模型的深度预测方法，应用在现有的模型上或者对该模型的网络结构进行简化，可能会带来更好的效果。</p>\n<hr>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><p>[1]  Thomas Roddick, Alex Kendall, and Roberto Cipolla. Ortho\u0002 graphic feature transform for monocular 3D object detection.<em>BMVC</em>, 2018</p>\n<p>[2] Liang-Chieh Chen, George Papandreou, Florian Schroff, andHartwig Adam. Rethinking atrous convolution for semantic image segmentation. <em>arXiv preprint</em>, 2017</p>\n<p>[3] Yunlei Tang, Sebastian Dorn, and Chiragkumar Savani. Cen\u0002ter3d: Center-based monocular 3d object detection with joint depth understanding. <em>arXiv preprint</em>, 2020</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Categorical-Depth-Distribution-Network-for-Monocular-3D-Object-Detection\"><a href=\"#Categorical-Depth-Distribution-Network-for-Monocular-3D-Object-Detection\" class=\"headerlink\" title=\"Categorical Depth Distribution Network for Monocular 3D Object Detection\"></a><strong>Categorical Depth Distribution Network for Monocular 3D Object Detection</strong></h1><p><strong>关键词： 单目3d检测、绝对深度分配网络</strong></p>\n<p><strong>论文链接：</strong><a href=\"https://arxiv.org/pdf/2103.01100.pdf\">https://arxiv.org/pdf/2103.01100.pdf</a></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1godx97xntnj30bl08p0wn.jpg\" alt></p>\n<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>​    单目3D检测的难点一直在于对深度的预测，实例从3D空间被映射到2D平面的图像上丢失了深度信息，对深度的处理一直是单目3D目标检测研究的重点方向，目前主流的方法主要分为三类。</p>\n<p><strong>1、直接检测  (Direct Methods)</strong></p>\n<p>​    直接检测方法没有显式的对深度进行学习，比较有代表性的是关键点检测方法，通过关键点结合几何特征来帮助3D-Bbox的检测，好处是简单直接且高效，但这类方法由于没有显式的学习深度信息，往往导致深度预测的结果不尽理想。</p>\n<p><strong>2、基于深度  (Depth-Based Methods)</strong></p>\n<p>​    基于深度的方法通常先会通过一个单目深度预测分支来得到一张深度图作为网络的输入从而辅助对深度的检测，由于有了深度信息其可被转换成点云来处理（可以用上3d检测的方法)。但由于其深度和目标检测分离训练的结构，导致其可能会丢失一些隐含的信息。</p>\n<p><strong>3、基于网格  (Grid-Based Methods)</strong></p>\n<p>​    基于网格的方法避免了对深度的直接预测，而是通过预测一个 BEV grid 的表达来作为3D检测网络的输入，OFT[1]提出了一种体素网格，通过把体素投影到图像平面上进而采样图像特征将其转换成BEV的形式。但这也会导致大量体素和特征的重叠从而降低检测的准确性。</p>\n<p>​    <strong>CaDDN</strong> 网络对上面三种情况的优点进行结合，整体网络结构是同时训练了深度预测和3D检测（jointly）以期待其能够解决方法2中的问题，同时利用也将图像平面转换成了BEV的形式来提高检测的准确性。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1godxz73f1jj30nm0dntcy.jpg\" alt=\"网络结构\"></p>\n<h2 id=\"网络结构\"><a href=\"#网络结构\" class=\"headerlink\" title=\"网络结构\"></a>网络结构</h2><h3 id=\"Frustum-Feature-Network\"><a href=\"#Frustum-Feature-Network\" class=\"headerlink\" title=\"Frustum Feature Network\"></a>Frustum Feature Network</h3><ul>\n<li><strong>Depth Distribution Network</strong></li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1godzoe00t7j30b908dabe.jpg\" alt></p>\n<p>对于特征提取网络，其输出形似一个截角锥形，因而作者称其为Frustum feature Network，其输入是原始图像 $I \\in R^{W_1\\times H_1\\times 3}$ 输出 $G \\in R^{W_F\\times H_F\\times D \\times C}$ 其中 W和H是特征的宽高，D 是深度桶，用以深度预测，C 是特征的维度。图像特征被用以在每个像素上预测绝对的深度分布 $D \\in R^{W_F\\times H_F\\times D}$ 网络对每个像素预测其落入某一深度桶（深度离散化）的概率，总共D个。</p>\n<p>（这一网络其是从 DeepLabV3[2] 上魔改过来的。）</p>\n<ul>\n<li>Image Channel Reduce</li>\n</ul>\n<p>同时在分配深度桶的同时，网络另一分支用1x1卷积 + BN + ReLU 把特征的维数从256降到了64。</p>\n<p>​    经过这两个分支后，将预测出来的深度桶和特征像素做外积得到了带有深度信息的特征图（$G(u,v) = D(u,v) \\otimes F(u,v)$）且由于特征桶的结构，具有较高的容错性。称 G 为 frustum features</p>\n<h3 id=\"Frustum-to-Voxel-Trans\"><a href=\"#Frustum-to-Voxel-Trans\" class=\"headerlink\" title=\"Frustum to Voxel Trans\"></a>Frustum to Voxel Trans</h3><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1godzokeng2j30b907ujsr.jpg\" alt></p>\n<p>​    G 之后将被转换成体素的形式，这里的问题是在第分辨率的frustum features进行高分辨率的体素采样会导致过采样，导致出现大量相同的体素特征，浪费算力不说还降低预测准确性。所以这边作者直接把降采样前的特征层拉了过来，来保证不会出现上述问题。</p>\n<h3 id=\"Voxel-Collapse-to-BEV-gt-Detection\"><a href=\"#Voxel-Collapse-to-BEV-gt-Detection\" class=\"headerlink\" title=\"Voxel Collapse to BEV -&gt; Detection\"></a>Voxel Collapse to BEV -&gt; Detection</h3><p>​    由于BEV在保证同等检测效果的情况下能够节省计算资源，作者将体素的 Z 轴和 channels 直接连接起来，继续用1x1卷积 + BN + ReLU 将体素块压缩成 BEV的形式。然后接着在 BEV 特征块上连接检测头进行 3D目标检测。</p>\n<h2 id=\"深度离散化\"><a href=\"#深度离散化\" class=\"headerlink\" title=\"深度离散化\"></a>深度离散化</h2><p>​    本文的主要亮点就是其对于深度的处理，其对每个像素位置分配了离散化的深度桶，预测其属于某一深度的概率。这里的深度离散化作者使用的是 LID (Linear-increasing discretization)[3] 因为其对不同深度之间提供了最为平衡的预测概率。对于检测任务的深度我们最需要的是检测目标的深度信息，而更少去在意背景点的深度。</p>\n<p>​                                                            <script type=\"math/tex\">d_c = d_min + \\frac{d_{max}-d_{min}}{D(D+1)}\\cdot{d_i}{(d_1+1)}</script></p>\n<p>​    <em>（其中 $d<em>c$ 是连续深度值，[$d</em>{min},d_{max}$]是离散化的上下界，D是深度桶的数量，$d_i$ 是下标）</em></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1goe03wlr9sj30dn0bd0tp.jpg\" alt></p>\n<h2 id=\"实验效果\"><a href=\"#实验效果\" class=\"headerlink\" title=\"实验效果\"></a>实验效果</h2><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1goe0ckxhf6j30r10fgn17.jpg\" alt=\"KITTI实验效果\"></p>\n<p>​    可以看到其在车辆和新人检测上都打破了目前最好的检测方法，对骑行者的检测不如 MonoPSR 但也大大超过了其余检测模型。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1goe0gh8vyhj30dw07jdgw.jpg\" alt></p>\n<p>这张表可以看出其将深度预测和特征融合所得到的 frustum features 确实有助于提升检测效果。</p>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>​    个人觉得这篇paper的主要成功点在于其对于单目深度预测的创新解决方法，不同于传统的深度预测模型，提出了离散化深度将每个像素的深度概率离散化分配在不同的深度桶中，避免了网络过度依赖于深度的准确检测。但同时其也没有从根本上解决深度预测的问题，同时其中间对于特征图进行体素化投影再转为 BEV 的过程较为复杂，虽然其把降采样前的特征层拿来转成体素形式但是仍然还是无法避免会有损失。</p>\n<p>​    个人觉得可以借鉴该模型的深度预测方法，应用在现有的模型上或者对该模型的网络结构进行简化，可能会带来更好的效果。</p>\n<hr>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><p>[1]  Thomas Roddick, Alex Kendall, and Roberto Cipolla. Ortho\u0002 graphic feature transform for monocular 3D object detection.<em>BMVC</em>, 2018</p>\n<p>[2] Liang-Chieh Chen, George Papandreou, Florian Schroff, andHartwig Adam. Rethinking atrous convolution for semantic image segmentation. <em>arXiv preprint</em>, 2017</p>\n<p>[3] Yunlei Tang, Sebastian Dorn, and Chiragkumar Savani. Cen\u0002ter3d: Center-based monocular 3d object detection with joint depth understanding. <em>arXiv preprint</em>, 2020</p>\n"},{"title":"深入理解Linux系统 —— 进程（上）","date":"2021-08-05T20:01:20.000Z","index_img":"/img/OS/banner.png","math":true,"_content":"\n\n\n## 一、进程、轻量级进程和线程\n\n### 1.1 进程 - Process\n\n​\t进程无疑是现代操作系统中最为成功的概念之一，其是程序执行时的实例抽象，现代操作系统以进程为抽象概念，使得每一个进程在运行时都好似独立的拥有CPU、内存等硬件。使得软件开发者不用过多关心底层硬件的调度和实现，便能够在较高的层次上进行程序开发。\n\n- **概念：**\n  - **程序角度：**程序运行时的实例\n  - **内核观点：**分配系统资源（CPU时间、内存）的实体\n\n**父子进程**\n\n​    当一个子进程被创建时，其拥有和父进程相同的代码段、数据段和用户堆栈，就像父进程把自己克隆了一遍。事实上，父进程只复制了自己的PCB *(Process Control Block)*。而代码段，数据段和用户堆栈内存空间并没有复制一份，而是与子进程共享。只有当子进程在运行中出现写操作时，才会产生中断，并为子进程分配内存空间。即**写时复制**\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt3l9prc3lj30i10b7js6.jpg\" style=\"zoom:80%;\" />\n\n### 1.2 轻量级进程 - Lightweight Process\n\n​\tLinux使用了轻量级进程，对多线程应用提供了更好的支持，其户型可以共享一些资源。例如地址空间和打开的文件，其中一个修改共享资源，另一个立即查看并且同步更新。\n\n​\t不过这需要依赖进程间通信（IPC）机制，肯定会比线程更慢\n\n### 1.3 线程 - Thread\n\n​\t线程是操作系统进行运算调度的最小单位，一个进程中可以有多个线程，其被共同维护在一个线程池中进行统一调度。可用线程数量应该取决于可用的并发处理器、处理器内核、内存、网络sockets等的数量。任务调度以执行线程的常见方法是使用同步队列，称作任务队列。池中的线程等待队列中的任务，并把执行完的任务放入完成队列中。\t\n\n​\t线程池一般使用生产者消费者模式或领导者追随者模式\n\n- **生产者消费者：**即一个简单buffer，主线程存入工作队列，工作线程从工作队列取出任务进入工作状态，如果工作队列为空则挂起。\n- **领导者追随者模式：**当事件到达，领导者线程将自身变为工作状态处理事件，并从追随者中选择一个来当继任领导者，处理完后将自身置为追随者模式。其避免了线程之间的任务数据交换，提高了性能\n\n## 二、进程描述符\n\n​\t进程描述符顾名思义就是用来描述一个进程的，从其数据结构中我们可以了解该进程有哪些权限、允许访问哪些文件等等。\n\n​\t其数据结构是 task_struct 类型，其不仅包含了许多进程属性，还包含了一些指向另外数据结构的指针。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt3mn4emosj30u00udtan.jpg\" style=\"zoom:50%;\" />\n\n​\t  下面我们讨论进程的状态和进程的父|子之间关系\n\n### 2.1 进程状态\n\n​\t进程描述符中的state描述进程所处的状态，其由一组标志组成，并且是互斥的\n\n**可运行状态 TASK_RUNNING**\n\n​\t进程要么在CPU上执行，要么准备执行\n\n**可中断的等待状态 TASK_INTERRUPTIBLE**\n\n​\t进程被挂起，直到某条件为真。产生一个硬件中断，释放系统资源，或通过信号唤醒进程\n\n**不可中断的等待状态 TASK_UNINTERRUPTIBLE**\n\n​\t即不可被信号中断，常常出现在需要原子性操作的过程（例如进程打开设备文件，相应的设备驱动开始探查硬件设备时）\n\n**暂停状态 TASK_STOPPED**\n\n​\t收到 SIGSTOP \\ SIGTSTP \\ SIGTTIN \\ SIGTTOU 时\n\n**跟踪状态 TASK_TRACED**\n\n​\t进程被debugger程序暂停，任何信号都可以把进程置为 TASK_TRACED 状态\n\n*另外两种状态即可在state也可在exit_state中*\n\n**僵死状态 EXIT_ZOMBIE**\n\n \t子进程结束但还未被父进程回收\n\n**僵死撤销状态 EXIT_DEAD**\n\n​\t已经被父进程waitpid回收，在系统回收过程中，而防止其他进程调用wait产生冲突而置于 EXIT_DEAD 状态\n\n\n\n### 2.2 进程标识符 Process ID\n\n​\t内核对进程的大部分引用是通过进程描述符指针完成的，而类UNIX操作系统允许用户采用一个进程标识符 pid 来标识进程，PID按顺序编号且进程数量有一定上限，其上限为 4194303 （PID_MAX_DEFAULT - 1）PID编号循环使用，内核通过管理一个 pidmap_array 位图来表示已经分配的PID和闲置的PID号。\n\n​\t很自然地我们知道不同的进程有着不同的pid号，而同一进程的线程的pid号相同，这是在POSIX 1003.1c 标准中就规定了的\n\n为此引入了线程组的表示，一个线程组中的所有线程和该线程组中的领头线程拥有相同的PID，其被存入了**tgid字段中**，我们调用getpid()返回的是当前进程的 tgid值而不是pid的值。由于绝大多数进程都属于一个线程组，包含单一成员，线程组的tgid值与进程pid值相同，因此getpid()系统调用对此类进程所起到的作用和一般进程相同。\n\n\n\n### 2.3 内核栈与thread_info数据结构\n\n​\t每个进程都有一个独立的内核栈，其位置被进程的task_struct中的stack指针所标记，长得像下图。内核栈和thread_info存放在连续的页框中，内核栈从高地址向低地址增长，底部存放thread_info数据结构。\n\n**结构大小：**一般来说这样一个结构所占为一个页框，在80x86结构中其占据两个页框即32位系统中的8kb，但如果当内存碎片较多时，可能无法找到这样的连续两个页框，导致效率低下。\n\n**指针关系：**其中task_struct的thread_info指针指向，内核态下esp栈指针指向内核栈栈顶，thread_info中的task指针指向进程的task_stuct\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt5qzama9uj319z0u0q5n.jpg\" style=\"zoom:45%;\" />\n\n**语言实现：**\n\nC语言用以下一个简单的union结构来实现上述数据结构\n\n```c\n// 80x86 32位系统\nunion thread_union {\n  struct thread_info thread_info\n  unsigned long stack[2048]\t/* 对4k的栈数组下标 1024*/\n}\n```\n\n内核使用alloc_thread_info和free_thread_info宏分配和释放储存thread_info结构和内核栈的内存区\n\n\n\n**效率考量：**从效率角度看，所说的thread_info结构与内核栈连续存放的好处是我们可以轻松的通过栈指针esp寄存器的值获得当前CPU上正在运行进程的thread_info结构的地址。其根据thread_union结构的大小，屏蔽掉esp低12位或13位的地址来获得thread_info结构的基地址，调用current_thread_info()产生以下汇编代码\n\n```assembly\nmovl $0xffffe000, %ecx /*或是用于4k堆栈的0xfffff000*/\nandl %esp, %ecx\nmovl %ecx, p\n```\n\n执行完后p就包含thread_info结构的指针，进而我们可以通过thread_info结构中的task指针获得进程描述符task_struct数据结构的地址\n\n调用 macro current 其等价于 current_thread_info()->task，产生如下汇编指令\n\n```assembly\nmovl $0xffffe000, %ecx /*或者是用于4k堆栈的0xfffff000*/\nandl %esp, %ecx\nmovl (%ecx), p\n```\n\n因为task在thread_info结构中偏移量为0，即储存在thread_info中的基地址，所以我们直接引用内存 (%ecx) 便可得到进程描述符地址\n\n\n\n### 2.4 进程链表\n\n​\tLinux操作系统通过进程链表把所有进程描述符连接起来，进程链表是一个循环双向链表，在linux内核中体现为list_head数据结构。每一个进程的task_struct结构都包含一个list_head类型的tasks字段，其prev前向指针和next后向指针分别指向前面和后面的的进程描述符数据结构\n\n​\t其头部是 init_task 描述符，即pid=0的0号进程，或swapper进程中的进程描述符，所以init_task中的prev指针指向最后插入 的进程描述符。\n\n**TASK_RUNNING 状态的进程链表：**\n\n​\t内核寻找新进程在CPU上运行时，必须保证其是可运行的，回忆我们前面说到过的进程状态，其必须是TASK_RUNNING状态的进程。\n\n**早期实现：**早期Linux将所有的可运行进程维护在一个运行队列的链表中，但由于按优先级排序维护的开销过大，因此每次选择最优可运行进程时都必须遍历整个链表，效率较低。\n\n​\t自Kernel 2.6版本开始，其做出来一些变动，使可以在固定时间内找出最优可运行进程，其方法是为每个优先级都建立一个可运行进程链表，list_head 优先级在 task_struct 中北 run_list 字段所标识，共分为140个list_head，被单独的一个prio_array_t数据结构来实现\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt5sf9zvmqj31jg0dwmzf.jpg\" style=\"zoom:50%;\" />\n\n通过 enqueue_task(p, array) 和 dequeue_task(p, array) 来从运行队列的链表中添加或删除 pd\n\n\n\n### 2.5 进程间的关系\n\n​\t进程fork出来的进程和原进程具有父子关系，如果一个进程创建多个进程，那么子进程之间具有兄弟关系。\n\n​\t**进程0和进程1由内核创建，进程1是所有进程的祖先。**\t<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt5sj34gm9j31iq0t6juf.jpg\" style=\"zoom:50%;\" />\n\n\n\n### 2.6 PIDHash表\n\n​\t在某些情况下，内核必须通过进程pid来索引其对应的进程描述符指针，其通过pidhash数据结构实现，即是一个pid与描述符指针对应的散列表。总共有四个。\n\n![](https://tva1.sinaimg.cn/large/008i3skNly1gt5tkx7g64j61iu0esmzj02.jpg)\n\n在Linux中很多散列函数都使用 hash_long()，在32位体系结构中其基本等价于\n\n```c\nunsigned long hash_long(unsigned long val, unsigned int bits) {\n  unsigned long hash = val * 0x93270001UL\n  return hash >> (32 - bits);\n}\n```\n\n其原理是通过一个数乘大数 0x93270001 (= 2654404609) 溢出，把保留在32位中的值的结果作为模数的操作。\n\n这个大数 0x93270001 是最接近与 2 的 32 次方黄金分割位置的一个素数。\n\n其等于 $2^{31}+2^{29}+2^{25}+2^{22}-2^{19}-2^{16}+1$\n\n利用散列表避免了直接映射带来的储存浪费，因为毕竟大多数时候系统中的进程数量都远远小于最大进程数量。对于 Hash 冲突的情况，Linux内核使用拉链法，且溢出链表为双向链表\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt5ttu88o4j30wa0u0q4z.jpg\" style=\"zoom:50%;\" />\n\nLinux内核进程详解的上半部分就讲到这，下节我们来讲进程的context switch、创建和撤销。\n\n## 参考文献\n\n[1] Daniel P. Bovet, Marco Cesati Understanding the Linux Kernel, 3rd Edition\n\n","source":"_posts/OS/Process.md","raw":"---\ntitle: 深入理解Linux系统 —— 进程（上）\ndate: 2021-08-05 13:01:20\nindex_img: /img/OS/banner.png\ncategory: [OS]\ntags: [kernel, process]\nmath: true\n---\n\n\n\n## 一、进程、轻量级进程和线程\n\n### 1.1 进程 - Process\n\n​\t进程无疑是现代操作系统中最为成功的概念之一，其是程序执行时的实例抽象，现代操作系统以进程为抽象概念，使得每一个进程在运行时都好似独立的拥有CPU、内存等硬件。使得软件开发者不用过多关心底层硬件的调度和实现，便能够在较高的层次上进行程序开发。\n\n- **概念：**\n  - **程序角度：**程序运行时的实例\n  - **内核观点：**分配系统资源（CPU时间、内存）的实体\n\n**父子进程**\n\n​    当一个子进程被创建时，其拥有和父进程相同的代码段、数据段和用户堆栈，就像父进程把自己克隆了一遍。事实上，父进程只复制了自己的PCB *(Process Control Block)*。而代码段，数据段和用户堆栈内存空间并没有复制一份，而是与子进程共享。只有当子进程在运行中出现写操作时，才会产生中断，并为子进程分配内存空间。即**写时复制**\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt3l9prc3lj30i10b7js6.jpg\" style=\"zoom:80%;\" />\n\n### 1.2 轻量级进程 - Lightweight Process\n\n​\tLinux使用了轻量级进程，对多线程应用提供了更好的支持，其户型可以共享一些资源。例如地址空间和打开的文件，其中一个修改共享资源，另一个立即查看并且同步更新。\n\n​\t不过这需要依赖进程间通信（IPC）机制，肯定会比线程更慢\n\n### 1.3 线程 - Thread\n\n​\t线程是操作系统进行运算调度的最小单位，一个进程中可以有多个线程，其被共同维护在一个线程池中进行统一调度。可用线程数量应该取决于可用的并发处理器、处理器内核、内存、网络sockets等的数量。任务调度以执行线程的常见方法是使用同步队列，称作任务队列。池中的线程等待队列中的任务，并把执行完的任务放入完成队列中。\t\n\n​\t线程池一般使用生产者消费者模式或领导者追随者模式\n\n- **生产者消费者：**即一个简单buffer，主线程存入工作队列，工作线程从工作队列取出任务进入工作状态，如果工作队列为空则挂起。\n- **领导者追随者模式：**当事件到达，领导者线程将自身变为工作状态处理事件，并从追随者中选择一个来当继任领导者，处理完后将自身置为追随者模式。其避免了线程之间的任务数据交换，提高了性能\n\n## 二、进程描述符\n\n​\t进程描述符顾名思义就是用来描述一个进程的，从其数据结构中我们可以了解该进程有哪些权限、允许访问哪些文件等等。\n\n​\t其数据结构是 task_struct 类型，其不仅包含了许多进程属性，还包含了一些指向另外数据结构的指针。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt3mn4emosj30u00udtan.jpg\" style=\"zoom:50%;\" />\n\n​\t  下面我们讨论进程的状态和进程的父|子之间关系\n\n### 2.1 进程状态\n\n​\t进程描述符中的state描述进程所处的状态，其由一组标志组成，并且是互斥的\n\n**可运行状态 TASK_RUNNING**\n\n​\t进程要么在CPU上执行，要么准备执行\n\n**可中断的等待状态 TASK_INTERRUPTIBLE**\n\n​\t进程被挂起，直到某条件为真。产生一个硬件中断，释放系统资源，或通过信号唤醒进程\n\n**不可中断的等待状态 TASK_UNINTERRUPTIBLE**\n\n​\t即不可被信号中断，常常出现在需要原子性操作的过程（例如进程打开设备文件，相应的设备驱动开始探查硬件设备时）\n\n**暂停状态 TASK_STOPPED**\n\n​\t收到 SIGSTOP \\ SIGTSTP \\ SIGTTIN \\ SIGTTOU 时\n\n**跟踪状态 TASK_TRACED**\n\n​\t进程被debugger程序暂停，任何信号都可以把进程置为 TASK_TRACED 状态\n\n*另外两种状态即可在state也可在exit_state中*\n\n**僵死状态 EXIT_ZOMBIE**\n\n \t子进程结束但还未被父进程回收\n\n**僵死撤销状态 EXIT_DEAD**\n\n​\t已经被父进程waitpid回收，在系统回收过程中，而防止其他进程调用wait产生冲突而置于 EXIT_DEAD 状态\n\n\n\n### 2.2 进程标识符 Process ID\n\n​\t内核对进程的大部分引用是通过进程描述符指针完成的，而类UNIX操作系统允许用户采用一个进程标识符 pid 来标识进程，PID按顺序编号且进程数量有一定上限，其上限为 4194303 （PID_MAX_DEFAULT - 1）PID编号循环使用，内核通过管理一个 pidmap_array 位图来表示已经分配的PID和闲置的PID号。\n\n​\t很自然地我们知道不同的进程有着不同的pid号，而同一进程的线程的pid号相同，这是在POSIX 1003.1c 标准中就规定了的\n\n为此引入了线程组的表示，一个线程组中的所有线程和该线程组中的领头线程拥有相同的PID，其被存入了**tgid字段中**，我们调用getpid()返回的是当前进程的 tgid值而不是pid的值。由于绝大多数进程都属于一个线程组，包含单一成员，线程组的tgid值与进程pid值相同，因此getpid()系统调用对此类进程所起到的作用和一般进程相同。\n\n\n\n### 2.3 内核栈与thread_info数据结构\n\n​\t每个进程都有一个独立的内核栈，其位置被进程的task_struct中的stack指针所标记，长得像下图。内核栈和thread_info存放在连续的页框中，内核栈从高地址向低地址增长，底部存放thread_info数据结构。\n\n**结构大小：**一般来说这样一个结构所占为一个页框，在80x86结构中其占据两个页框即32位系统中的8kb，但如果当内存碎片较多时，可能无法找到这样的连续两个页框，导致效率低下。\n\n**指针关系：**其中task_struct的thread_info指针指向，内核态下esp栈指针指向内核栈栈顶，thread_info中的task指针指向进程的task_stuct\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt5qzama9uj319z0u0q5n.jpg\" style=\"zoom:45%;\" />\n\n**语言实现：**\n\nC语言用以下一个简单的union结构来实现上述数据结构\n\n```c\n// 80x86 32位系统\nunion thread_union {\n  struct thread_info thread_info\n  unsigned long stack[2048]\t/* 对4k的栈数组下标 1024*/\n}\n```\n\n内核使用alloc_thread_info和free_thread_info宏分配和释放储存thread_info结构和内核栈的内存区\n\n\n\n**效率考量：**从效率角度看，所说的thread_info结构与内核栈连续存放的好处是我们可以轻松的通过栈指针esp寄存器的值获得当前CPU上正在运行进程的thread_info结构的地址。其根据thread_union结构的大小，屏蔽掉esp低12位或13位的地址来获得thread_info结构的基地址，调用current_thread_info()产生以下汇编代码\n\n```assembly\nmovl $0xffffe000, %ecx /*或是用于4k堆栈的0xfffff000*/\nandl %esp, %ecx\nmovl %ecx, p\n```\n\n执行完后p就包含thread_info结构的指针，进而我们可以通过thread_info结构中的task指针获得进程描述符task_struct数据结构的地址\n\n调用 macro current 其等价于 current_thread_info()->task，产生如下汇编指令\n\n```assembly\nmovl $0xffffe000, %ecx /*或者是用于4k堆栈的0xfffff000*/\nandl %esp, %ecx\nmovl (%ecx), p\n```\n\n因为task在thread_info结构中偏移量为0，即储存在thread_info中的基地址，所以我们直接引用内存 (%ecx) 便可得到进程描述符地址\n\n\n\n### 2.4 进程链表\n\n​\tLinux操作系统通过进程链表把所有进程描述符连接起来，进程链表是一个循环双向链表，在linux内核中体现为list_head数据结构。每一个进程的task_struct结构都包含一个list_head类型的tasks字段，其prev前向指针和next后向指针分别指向前面和后面的的进程描述符数据结构\n\n​\t其头部是 init_task 描述符，即pid=0的0号进程，或swapper进程中的进程描述符，所以init_task中的prev指针指向最后插入 的进程描述符。\n\n**TASK_RUNNING 状态的进程链表：**\n\n​\t内核寻找新进程在CPU上运行时，必须保证其是可运行的，回忆我们前面说到过的进程状态，其必须是TASK_RUNNING状态的进程。\n\n**早期实现：**早期Linux将所有的可运行进程维护在一个运行队列的链表中，但由于按优先级排序维护的开销过大，因此每次选择最优可运行进程时都必须遍历整个链表，效率较低。\n\n​\t自Kernel 2.6版本开始，其做出来一些变动，使可以在固定时间内找出最优可运行进程，其方法是为每个优先级都建立一个可运行进程链表，list_head 优先级在 task_struct 中北 run_list 字段所标识，共分为140个list_head，被单独的一个prio_array_t数据结构来实现\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt5sf9zvmqj31jg0dwmzf.jpg\" style=\"zoom:50%;\" />\n\n通过 enqueue_task(p, array) 和 dequeue_task(p, array) 来从运行队列的链表中添加或删除 pd\n\n\n\n### 2.5 进程间的关系\n\n​\t进程fork出来的进程和原进程具有父子关系，如果一个进程创建多个进程，那么子进程之间具有兄弟关系。\n\n​\t**进程0和进程1由内核创建，进程1是所有进程的祖先。**\t<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt5sj34gm9j31iq0t6juf.jpg\" style=\"zoom:50%;\" />\n\n\n\n### 2.6 PIDHash表\n\n​\t在某些情况下，内核必须通过进程pid来索引其对应的进程描述符指针，其通过pidhash数据结构实现，即是一个pid与描述符指针对应的散列表。总共有四个。\n\n![](https://tva1.sinaimg.cn/large/008i3skNly1gt5tkx7g64j61iu0esmzj02.jpg)\n\n在Linux中很多散列函数都使用 hash_long()，在32位体系结构中其基本等价于\n\n```c\nunsigned long hash_long(unsigned long val, unsigned int bits) {\n  unsigned long hash = val * 0x93270001UL\n  return hash >> (32 - bits);\n}\n```\n\n其原理是通过一个数乘大数 0x93270001 (= 2654404609) 溢出，把保留在32位中的值的结果作为模数的操作。\n\n这个大数 0x93270001 是最接近与 2 的 32 次方黄金分割位置的一个素数。\n\n其等于 $2^{31}+2^{29}+2^{25}+2^{22}-2^{19}-2^{16}+1$\n\n利用散列表避免了直接映射带来的储存浪费，因为毕竟大多数时候系统中的进程数量都远远小于最大进程数量。对于 Hash 冲突的情况，Linux内核使用拉链法，且溢出链表为双向链表\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt5ttu88o4j30wa0u0q4z.jpg\" style=\"zoom:50%;\" />\n\nLinux内核进程详解的上半部分就讲到这，下节我们来讲进程的context switch、创建和撤销。\n\n## 参考文献\n\n[1] Daniel P. Bovet, Marco Cesati Understanding the Linux Kernel, 3rd Edition\n\n","slug":"OS/Process","published":1,"updated":"2026-02-03T05:42:14.444Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvk003r7uitb3hzb3ax","content":"<h2 id=\"一、进程、轻量级进程和线程\"><a href=\"#一、进程、轻量级进程和线程\" class=\"headerlink\" title=\"一、进程、轻量级进程和线程\"></a>一、进程、轻量级进程和线程</h2><h3 id=\"1-1-进程-Process\"><a href=\"#1-1-进程-Process\" class=\"headerlink\" title=\"1.1 进程 - Process\"></a>1.1 进程 - Process</h3><p>​    进程无疑是现代操作系统中最为成功的概念之一，其是程序执行时的实例抽象，现代操作系统以进程为抽象概念，使得每一个进程在运行时都好似独立的拥有CPU、内存等硬件。使得软件开发者不用过多关心底层硬件的调度和实现，便能够在较高的层次上进行程序开发。</p>\n<ul>\n<li><strong>概念：</strong><ul>\n<li><strong>程序角度：</strong>程序运行时的实例</li>\n<li><strong>内核观点：</strong>分配系统资源（CPU时间、内存）的实体</li>\n</ul>\n</li>\n</ul>\n<p><strong>父子进程</strong></p>\n<p>​    当一个子进程被创建时，其拥有和父进程相同的代码段、数据段和用户堆栈，就像父进程把自己克隆了一遍。事实上，父进程只复制了自己的PCB <em>(Process Control Block)</em>。而代码段，数据段和用户堆栈内存空间并没有复制一份，而是与子进程共享。只有当子进程在运行中出现写操作时，才会产生中断，并为子进程分配内存空间。即<strong>写时复制</strong></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt3l9prc3lj30i10b7js6.jpg\" style=\"zoom:80%;\"></p>\n<h3 id=\"1-2-轻量级进程-Lightweight-Process\"><a href=\"#1-2-轻量级进程-Lightweight-Process\" class=\"headerlink\" title=\"1.2 轻量级进程 - Lightweight Process\"></a>1.2 轻量级进程 - Lightweight Process</h3><p>​    Linux使用了轻量级进程，对多线程应用提供了更好的支持，其户型可以共享一些资源。例如地址空间和打开的文件，其中一个修改共享资源，另一个立即查看并且同步更新。</p>\n<p>​    不过这需要依赖进程间通信（IPC）机制，肯定会比线程更慢</p>\n<h3 id=\"1-3-线程-Thread\"><a href=\"#1-3-线程-Thread\" class=\"headerlink\" title=\"1.3 线程 - Thread\"></a>1.3 线程 - Thread</h3><p>​    线程是操作系统进行运算调度的最小单位，一个进程中可以有多个线程，其被共同维护在一个线程池中进行统一调度。可用线程数量应该取决于可用的并发处理器、处理器内核、内存、网络sockets等的数量。任务调度以执行线程的常见方法是使用同步队列，称作任务队列。池中的线程等待队列中的任务，并把执行完的任务放入完成队列中。    </p>\n<p>​    线程池一般使用生产者消费者模式或领导者追随者模式</p>\n<ul>\n<li><strong>生产者消费者：</strong>即一个简单buffer，主线程存入工作队列，工作线程从工作队列取出任务进入工作状态，如果工作队列为空则挂起。</li>\n<li><strong>领导者追随者模式：</strong>当事件到达，领导者线程将自身变为工作状态处理事件，并从追随者中选择一个来当继任领导者，处理完后将自身置为追随者模式。其避免了线程之间的任务数据交换，提高了性能</li>\n</ul>\n<h2 id=\"二、进程描述符\"><a href=\"#二、进程描述符\" class=\"headerlink\" title=\"二、进程描述符\"></a>二、进程描述符</h2><p>​    进程描述符顾名思义就是用来描述一个进程的，从其数据结构中我们可以了解该进程有哪些权限、允许访问哪些文件等等。</p>\n<p>​    其数据结构是 task_struct 类型，其不仅包含了许多进程属性，还包含了一些指向另外数据结构的指针。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt3mn4emosj30u00udtan.jpg\" style=\"zoom:50%;\"></p>\n<p>​      下面我们讨论进程的状态和进程的父|子之间关系</p>\n<h3 id=\"2-1-进程状态\"><a href=\"#2-1-进程状态\" class=\"headerlink\" title=\"2.1 进程状态\"></a>2.1 进程状态</h3><p>​    进程描述符中的state描述进程所处的状态，其由一组标志组成，并且是互斥的</p>\n<p><strong>可运行状态 TASK_RUNNING</strong></p>\n<p>​    进程要么在CPU上执行，要么准备执行</p>\n<p><strong>可中断的等待状态 TASK_INTERRUPTIBLE</strong></p>\n<p>​    进程被挂起，直到某条件为真。产生一个硬件中断，释放系统资源，或通过信号唤醒进程</p>\n<p><strong>不可中断的等待状态 TASK_UNINTERRUPTIBLE</strong></p>\n<p>​    即不可被信号中断，常常出现在需要原子性操作的过程（例如进程打开设备文件，相应的设备驱动开始探查硬件设备时）</p>\n<p><strong>暂停状态 TASK_STOPPED</strong></p>\n<p>​    收到 SIGSTOP \\ SIGTSTP \\ SIGTTIN \\ SIGTTOU 时</p>\n<p><strong>跟踪状态 TASK_TRACED</strong></p>\n<p>​    进程被debugger程序暂停，任何信号都可以把进程置为 TASK_TRACED 状态</p>\n<p><em>另外两种状态即可在state也可在exit_state中</em></p>\n<p><strong>僵死状态 EXIT_ZOMBIE</strong></p>\n<pre><code> 子进程结束但还未被父进程回收\n</code></pre><p><strong>僵死撤销状态 EXIT_DEAD</strong></p>\n<p>​    已经被父进程waitpid回收，在系统回收过程中，而防止其他进程调用wait产生冲突而置于 EXIT_DEAD 状态</p>\n<h3 id=\"2-2-进程标识符-Process-ID\"><a href=\"#2-2-进程标识符-Process-ID\" class=\"headerlink\" title=\"2.2 进程标识符 Process ID\"></a>2.2 进程标识符 Process ID</h3><p>​    内核对进程的大部分引用是通过进程描述符指针完成的，而类UNIX操作系统允许用户采用一个进程标识符 pid 来标识进程，PID按顺序编号且进程数量有一定上限，其上限为 4194303 （PID_MAX_DEFAULT - 1）PID编号循环使用，内核通过管理一个 pidmap_array 位图来表示已经分配的PID和闲置的PID号。</p>\n<p>​    很自然地我们知道不同的进程有着不同的pid号，而同一进程的线程的pid号相同，这是在POSIX 1003.1c 标准中就规定了的</p>\n<p>为此引入了线程组的表示，一个线程组中的所有线程和该线程组中的领头线程拥有相同的PID，其被存入了<strong>tgid字段中</strong>，我们调用getpid()返回的是当前进程的 tgid值而不是pid的值。由于绝大多数进程都属于一个线程组，包含单一成员，线程组的tgid值与进程pid值相同，因此getpid()系统调用对此类进程所起到的作用和一般进程相同。</p>\n<h3 id=\"2-3-内核栈与thread-info数据结构\"><a href=\"#2-3-内核栈与thread-info数据结构\" class=\"headerlink\" title=\"2.3 内核栈与thread_info数据结构\"></a>2.3 内核栈与thread_info数据结构</h3><p>​    每个进程都有一个独立的内核栈，其位置被进程的task_struct中的stack指针所标记，长得像下图。内核栈和thread_info存放在连续的页框中，内核栈从高地址向低地址增长，底部存放thread_info数据结构。</p>\n<p><strong>结构大小：</strong>一般来说这样一个结构所占为一个页框，在80x86结构中其占据两个页框即32位系统中的8kb，但如果当内存碎片较多时，可能无法找到这样的连续两个页框，导致效率低下。</p>\n<p><strong>指针关系：</strong>其中task_struct的thread_info指针指向，内核态下esp栈指针指向内核栈栈顶，thread_info中的task指针指向进程的task_stuct</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt5qzama9uj319z0u0q5n.jpg\" style=\"zoom:45%;\"></p>\n<p><strong>语言实现：</strong></p>\n<p>C语言用以下一个简单的union结构来实现上述数据结构</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">// 80x86 32位系统</span>\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">union</span> <span class=\"hljs-title\">thread_union</span> &#123;</span>\n  <span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">thread_info</span> <span class=\"hljs-title\">thread_info</span></span>\n<span class=\"hljs-class\">  <span class=\"hljs-title\">unsigned</span> <span class=\"hljs-title\">long</span> <span class=\"hljs-title\">stack</span>[2048]\t/* 对4<span class=\"hljs-title\">k</span>的栈数组下标 1024*/</span>\n<span class=\"hljs-class\">&#125;</span></code></pre>\n<p>内核使用alloc_thread_info和free_thread_info宏分配和释放储存thread_info结构和内核栈的内存区</p>\n<p><strong>效率考量：</strong>从效率角度看，所说的thread_info结构与内核栈连续存放的好处是我们可以轻松的通过栈指针esp寄存器的值获得当前CPU上正在运行进程的thread_info结构的地址。其根据thread_union结构的大小，屏蔽掉esp低12位或13位的地址来获得thread_info结构的基地址，调用current_thread_info()产生以下汇编代码</p>\n<pre><code class=\"hljs assembly\">movl $0xffffe000, %ecx &#x2F;*或是用于4k堆栈的0xfffff000*&#x2F;\nandl %esp, %ecx\nmovl %ecx, p</code></pre>\n<p>执行完后p就包含thread_info结构的指针，进而我们可以通过thread_info结构中的task指针获得进程描述符task_struct数据结构的地址</p>\n<p>调用 macro current 其等价于 current_thread_info()-&gt;task，产生如下汇编指令</p>\n<pre><code class=\"hljs assembly\">movl $0xffffe000, %ecx &#x2F;*或者是用于4k堆栈的0xfffff000*&#x2F;\nandl %esp, %ecx\nmovl (%ecx), p</code></pre>\n<p>因为task在thread_info结构中偏移量为0，即储存在thread_info中的基地址，所以我们直接引用内存 (%ecx) 便可得到进程描述符地址</p>\n<h3 id=\"2-4-进程链表\"><a href=\"#2-4-进程链表\" class=\"headerlink\" title=\"2.4 进程链表\"></a>2.4 进程链表</h3><p>​    Linux操作系统通过进程链表把所有进程描述符连接起来，进程链表是一个循环双向链表，在linux内核中体现为list_head数据结构。每一个进程的task_struct结构都包含一个list_head类型的tasks字段，其prev前向指针和next后向指针分别指向前面和后面的的进程描述符数据结构</p>\n<p>​    其头部是 init_task 描述符，即pid=0的0号进程，或swapper进程中的进程描述符，所以init_task中的prev指针指向最后插入 的进程描述符。</p>\n<p><strong>TASK_RUNNING 状态的进程链表：</strong></p>\n<p>​    内核寻找新进程在CPU上运行时，必须保证其是可运行的，回忆我们前面说到过的进程状态，其必须是TASK_RUNNING状态的进程。</p>\n<p><strong>早期实现：</strong>早期Linux将所有的可运行进程维护在一个运行队列的链表中，但由于按优先级排序维护的开销过大，因此每次选择最优可运行进程时都必须遍历整个链表，效率较低。</p>\n<p>​    自Kernel 2.6版本开始，其做出来一些变动，使可以在固定时间内找出最优可运行进程，其方法是为每个优先级都建立一个可运行进程链表，list_head 优先级在 task_struct 中北 run_list 字段所标识，共分为140个list_head，被单独的一个prio_array_t数据结构来实现</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt5sf9zvmqj31jg0dwmzf.jpg\" style=\"zoom:50%;\"></p>\n<p>通过 enqueue_task(p, array) 和 dequeue_task(p, array) 来从运行队列的链表中添加或删除 pd</p>\n<h3 id=\"2-5-进程间的关系\"><a href=\"#2-5-进程间的关系\" class=\"headerlink\" title=\"2.5 进程间的关系\"></a>2.5 进程间的关系</h3><p>​    进程fork出来的进程和原进程具有父子关系，如果一个进程创建多个进程，那么子进程之间具有兄弟关系。</p>\n<p>​    <strong>进程0和进程1由内核创建，进程1是所有进程的祖先。</strong>    <img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt5sj34gm9j31iq0t6juf.jpg\" style=\"zoom:50%;\"></p>\n<h3 id=\"2-6-PIDHash表\"><a href=\"#2-6-PIDHash表\" class=\"headerlink\" title=\"2.6 PIDHash表\"></a>2.6 PIDHash表</h3><p>​    在某些情况下，内核必须通过进程pid来索引其对应的进程描述符指针，其通过pidhash数据结构实现，即是一个pid与描述符指针对应的散列表。总共有四个。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt5tkx7g64j61iu0esmzj02.jpg\" alt></p>\n<p>在Linux中很多散列函数都使用 hash_long()，在32位体系结构中其基本等价于</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">long</span> <span class=\"hljs-title\">hash_long</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">long</span> val, <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">int</span> bits)</span> </span>&#123;\n  <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">long</span> hash = val * <span class=\"hljs-number\">0x93270001</span>UL\n  <span class=\"hljs-keyword\">return</span> hash &gt;&gt; (<span class=\"hljs-number\">32</span> - bits);\n&#125;</code></pre>\n<p>其原理是通过一个数乘大数 0x93270001 (= 2654404609) 溢出，把保留在32位中的值的结果作为模数的操作。</p>\n<p>这个大数 0x93270001 是最接近与 2 的 32 次方黄金分割位置的一个素数。</p>\n<p>其等于 $2^{31}+2^{29}+2^{25}+2^{22}-2^{19}-2^{16}+1$</p>\n<p>利用散列表避免了直接映射带来的储存浪费，因为毕竟大多数时候系统中的进程数量都远远小于最大进程数量。对于 Hash 冲突的情况，Linux内核使用拉链法，且溢出链表为双向链表</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt5ttu88o4j30wa0u0q4z.jpg\" style=\"zoom:50%;\"></p>\n<p>Linux内核进程详解的上半部分就讲到这，下节我们来讲进程的context switch、创建和撤销。</p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><p>[1] Daniel P. Bovet, Marco Cesati Understanding the Linux Kernel, 3rd Edition</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"一、进程、轻量级进程和线程\"><a href=\"#一、进程、轻量级进程和线程\" class=\"headerlink\" title=\"一、进程、轻量级进程和线程\"></a>一、进程、轻量级进程和线程</h2><h3 id=\"1-1-进程-Process\"><a href=\"#1-1-进程-Process\" class=\"headerlink\" title=\"1.1 进程 - Process\"></a>1.1 进程 - Process</h3><p>​    进程无疑是现代操作系统中最为成功的概念之一，其是程序执行时的实例抽象，现代操作系统以进程为抽象概念，使得每一个进程在运行时都好似独立的拥有CPU、内存等硬件。使得软件开发者不用过多关心底层硬件的调度和实现，便能够在较高的层次上进行程序开发。</p>\n<ul>\n<li><strong>概念：</strong><ul>\n<li><strong>程序角度：</strong>程序运行时的实例</li>\n<li><strong>内核观点：</strong>分配系统资源（CPU时间、内存）的实体</li>\n</ul>\n</li>\n</ul>\n<p><strong>父子进程</strong></p>\n<p>​    当一个子进程被创建时，其拥有和父进程相同的代码段、数据段和用户堆栈，就像父进程把自己克隆了一遍。事实上，父进程只复制了自己的PCB <em>(Process Control Block)</em>。而代码段，数据段和用户堆栈内存空间并没有复制一份，而是与子进程共享。只有当子进程在运行中出现写操作时，才会产生中断，并为子进程分配内存空间。即<strong>写时复制</strong></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt3l9prc3lj30i10b7js6.jpg\" style=\"zoom:80%;\"></p>\n<h3 id=\"1-2-轻量级进程-Lightweight-Process\"><a href=\"#1-2-轻量级进程-Lightweight-Process\" class=\"headerlink\" title=\"1.2 轻量级进程 - Lightweight Process\"></a>1.2 轻量级进程 - Lightweight Process</h3><p>​    Linux使用了轻量级进程，对多线程应用提供了更好的支持，其户型可以共享一些资源。例如地址空间和打开的文件，其中一个修改共享资源，另一个立即查看并且同步更新。</p>\n<p>​    不过这需要依赖进程间通信（IPC）机制，肯定会比线程更慢</p>\n<h3 id=\"1-3-线程-Thread\"><a href=\"#1-3-线程-Thread\" class=\"headerlink\" title=\"1.3 线程 - Thread\"></a>1.3 线程 - Thread</h3><p>​    线程是操作系统进行运算调度的最小单位，一个进程中可以有多个线程，其被共同维护在一个线程池中进行统一调度。可用线程数量应该取决于可用的并发处理器、处理器内核、内存、网络sockets等的数量。任务调度以执行线程的常见方法是使用同步队列，称作任务队列。池中的线程等待队列中的任务，并把执行完的任务放入完成队列中。    </p>\n<p>​    线程池一般使用生产者消费者模式或领导者追随者模式</p>\n<ul>\n<li><strong>生产者消费者：</strong>即一个简单buffer，主线程存入工作队列，工作线程从工作队列取出任务进入工作状态，如果工作队列为空则挂起。</li>\n<li><strong>领导者追随者模式：</strong>当事件到达，领导者线程将自身变为工作状态处理事件，并从追随者中选择一个来当继任领导者，处理完后将自身置为追随者模式。其避免了线程之间的任务数据交换，提高了性能</li>\n</ul>\n<h2 id=\"二、进程描述符\"><a href=\"#二、进程描述符\" class=\"headerlink\" title=\"二、进程描述符\"></a>二、进程描述符</h2><p>​    进程描述符顾名思义就是用来描述一个进程的，从其数据结构中我们可以了解该进程有哪些权限、允许访问哪些文件等等。</p>\n<p>​    其数据结构是 task_struct 类型，其不仅包含了许多进程属性，还包含了一些指向另外数据结构的指针。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt3mn4emosj30u00udtan.jpg\" style=\"zoom:50%;\"></p>\n<p>​      下面我们讨论进程的状态和进程的父|子之间关系</p>\n<h3 id=\"2-1-进程状态\"><a href=\"#2-1-进程状态\" class=\"headerlink\" title=\"2.1 进程状态\"></a>2.1 进程状态</h3><p>​    进程描述符中的state描述进程所处的状态，其由一组标志组成，并且是互斥的</p>\n<p><strong>可运行状态 TASK_RUNNING</strong></p>\n<p>​    进程要么在CPU上执行，要么准备执行</p>\n<p><strong>可中断的等待状态 TASK_INTERRUPTIBLE</strong></p>\n<p>​    进程被挂起，直到某条件为真。产生一个硬件中断，释放系统资源，或通过信号唤醒进程</p>\n<p><strong>不可中断的等待状态 TASK_UNINTERRUPTIBLE</strong></p>\n<p>​    即不可被信号中断，常常出现在需要原子性操作的过程（例如进程打开设备文件，相应的设备驱动开始探查硬件设备时）</p>\n<p><strong>暂停状态 TASK_STOPPED</strong></p>\n<p>​    收到 SIGSTOP \\ SIGTSTP \\ SIGTTIN \\ SIGTTOU 时</p>\n<p><strong>跟踪状态 TASK_TRACED</strong></p>\n<p>​    进程被debugger程序暂停，任何信号都可以把进程置为 TASK_TRACED 状态</p>\n<p><em>另外两种状态即可在state也可在exit_state中</em></p>\n<p><strong>僵死状态 EXIT_ZOMBIE</strong></p>\n<pre><code> 子进程结束但还未被父进程回收\n</code></pre><p><strong>僵死撤销状态 EXIT_DEAD</strong></p>\n<p>​    已经被父进程waitpid回收，在系统回收过程中，而防止其他进程调用wait产生冲突而置于 EXIT_DEAD 状态</p>\n<h3 id=\"2-2-进程标识符-Process-ID\"><a href=\"#2-2-进程标识符-Process-ID\" class=\"headerlink\" title=\"2.2 进程标识符 Process ID\"></a>2.2 进程标识符 Process ID</h3><p>​    内核对进程的大部分引用是通过进程描述符指针完成的，而类UNIX操作系统允许用户采用一个进程标识符 pid 来标识进程，PID按顺序编号且进程数量有一定上限，其上限为 4194303 （PID_MAX_DEFAULT - 1）PID编号循环使用，内核通过管理一个 pidmap_array 位图来表示已经分配的PID和闲置的PID号。</p>\n<p>​    很自然地我们知道不同的进程有着不同的pid号，而同一进程的线程的pid号相同，这是在POSIX 1003.1c 标准中就规定了的</p>\n<p>为此引入了线程组的表示，一个线程组中的所有线程和该线程组中的领头线程拥有相同的PID，其被存入了<strong>tgid字段中</strong>，我们调用getpid()返回的是当前进程的 tgid值而不是pid的值。由于绝大多数进程都属于一个线程组，包含单一成员，线程组的tgid值与进程pid值相同，因此getpid()系统调用对此类进程所起到的作用和一般进程相同。</p>\n<h3 id=\"2-3-内核栈与thread-info数据结构\"><a href=\"#2-3-内核栈与thread-info数据结构\" class=\"headerlink\" title=\"2.3 内核栈与thread_info数据结构\"></a>2.3 内核栈与thread_info数据结构</h3><p>​    每个进程都有一个独立的内核栈，其位置被进程的task_struct中的stack指针所标记，长得像下图。内核栈和thread_info存放在连续的页框中，内核栈从高地址向低地址增长，底部存放thread_info数据结构。</p>\n<p><strong>结构大小：</strong>一般来说这样一个结构所占为一个页框，在80x86结构中其占据两个页框即32位系统中的8kb，但如果当内存碎片较多时，可能无法找到这样的连续两个页框，导致效率低下。</p>\n<p><strong>指针关系：</strong>其中task_struct的thread_info指针指向，内核态下esp栈指针指向内核栈栈顶，thread_info中的task指针指向进程的task_stuct</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt5qzama9uj319z0u0q5n.jpg\" style=\"zoom:45%;\"></p>\n<p><strong>语言实现：</strong></p>\n<p>C语言用以下一个简单的union结构来实现上述数据结构</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-comment\">// 80x86 32位系统</span>\n<span class=\"hljs-class\"><span class=\"hljs-keyword\">union</span> <span class=\"hljs-title\">thread_union</span> &#123;</span>\n  <span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">thread_info</span> <span class=\"hljs-title\">thread_info</span></span>\n<span class=\"hljs-class\">  <span class=\"hljs-title\">unsigned</span> <span class=\"hljs-title\">long</span> <span class=\"hljs-title\">stack</span>[2048]\t/* 对4<span class=\"hljs-title\">k</span>的栈数组下标 1024*/</span>\n<span class=\"hljs-class\">&#125;</span></code></pre>\n<p>内核使用alloc_thread_info和free_thread_info宏分配和释放储存thread_info结构和内核栈的内存区</p>\n<p><strong>效率考量：</strong>从效率角度看，所说的thread_info结构与内核栈连续存放的好处是我们可以轻松的通过栈指针esp寄存器的值获得当前CPU上正在运行进程的thread_info结构的地址。其根据thread_union结构的大小，屏蔽掉esp低12位或13位的地址来获得thread_info结构的基地址，调用current_thread_info()产生以下汇编代码</p>\n<pre><code class=\"hljs assembly\">movl $0xffffe000, %ecx &#x2F;*或是用于4k堆栈的0xfffff000*&#x2F;\nandl %esp, %ecx\nmovl %ecx, p</code></pre>\n<p>执行完后p就包含thread_info结构的指针，进而我们可以通过thread_info结构中的task指针获得进程描述符task_struct数据结构的地址</p>\n<p>调用 macro current 其等价于 current_thread_info()-&gt;task，产生如下汇编指令</p>\n<pre><code class=\"hljs assembly\">movl $0xffffe000, %ecx &#x2F;*或者是用于4k堆栈的0xfffff000*&#x2F;\nandl %esp, %ecx\nmovl (%ecx), p</code></pre>\n<p>因为task在thread_info结构中偏移量为0，即储存在thread_info中的基地址，所以我们直接引用内存 (%ecx) 便可得到进程描述符地址</p>\n<h3 id=\"2-4-进程链表\"><a href=\"#2-4-进程链表\" class=\"headerlink\" title=\"2.4 进程链表\"></a>2.4 进程链表</h3><p>​    Linux操作系统通过进程链表把所有进程描述符连接起来，进程链表是一个循环双向链表，在linux内核中体现为list_head数据结构。每一个进程的task_struct结构都包含一个list_head类型的tasks字段，其prev前向指针和next后向指针分别指向前面和后面的的进程描述符数据结构</p>\n<p>​    其头部是 init_task 描述符，即pid=0的0号进程，或swapper进程中的进程描述符，所以init_task中的prev指针指向最后插入 的进程描述符。</p>\n<p><strong>TASK_RUNNING 状态的进程链表：</strong></p>\n<p>​    内核寻找新进程在CPU上运行时，必须保证其是可运行的，回忆我们前面说到过的进程状态，其必须是TASK_RUNNING状态的进程。</p>\n<p><strong>早期实现：</strong>早期Linux将所有的可运行进程维护在一个运行队列的链表中，但由于按优先级排序维护的开销过大，因此每次选择最优可运行进程时都必须遍历整个链表，效率较低。</p>\n<p>​    自Kernel 2.6版本开始，其做出来一些变动，使可以在固定时间内找出最优可运行进程，其方法是为每个优先级都建立一个可运行进程链表，list_head 优先级在 task_struct 中北 run_list 字段所标识，共分为140个list_head，被单独的一个prio_array_t数据结构来实现</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt5sf9zvmqj31jg0dwmzf.jpg\" style=\"zoom:50%;\"></p>\n<p>通过 enqueue_task(p, array) 和 dequeue_task(p, array) 来从运行队列的链表中添加或删除 pd</p>\n<h3 id=\"2-5-进程间的关系\"><a href=\"#2-5-进程间的关系\" class=\"headerlink\" title=\"2.5 进程间的关系\"></a>2.5 进程间的关系</h3><p>​    进程fork出来的进程和原进程具有父子关系，如果一个进程创建多个进程，那么子进程之间具有兄弟关系。</p>\n<p>​    <strong>进程0和进程1由内核创建，进程1是所有进程的祖先。</strong>    <img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt5sj34gm9j31iq0t6juf.jpg\" style=\"zoom:50%;\"></p>\n<h3 id=\"2-6-PIDHash表\"><a href=\"#2-6-PIDHash表\" class=\"headerlink\" title=\"2.6 PIDHash表\"></a>2.6 PIDHash表</h3><p>​    在某些情况下，内核必须通过进程pid来索引其对应的进程描述符指针，其通过pidhash数据结构实现，即是一个pid与描述符指针对应的散列表。总共有四个。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt5tkx7g64j61iu0esmzj02.jpg\" alt></p>\n<p>在Linux中很多散列函数都使用 hash_long()，在32位体系结构中其基本等价于</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">long</span> <span class=\"hljs-title\">hash_long</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">long</span> val, <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">int</span> bits)</span> </span>&#123;\n  <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">long</span> hash = val * <span class=\"hljs-number\">0x93270001</span>UL\n  <span class=\"hljs-keyword\">return</span> hash &gt;&gt; (<span class=\"hljs-number\">32</span> - bits);\n&#125;</code></pre>\n<p>其原理是通过一个数乘大数 0x93270001 (= 2654404609) 溢出，把保留在32位中的值的结果作为模数的操作。</p>\n<p>这个大数 0x93270001 是最接近与 2 的 32 次方黄金分割位置的一个素数。</p>\n<p>其等于 $2^{31}+2^{29}+2^{25}+2^{22}-2^{19}-2^{16}+1$</p>\n<p>利用散列表避免了直接映射带来的储存浪费，因为毕竟大多数时候系统中的进程数量都远远小于最大进程数量。对于 Hash 冲突的情况，Linux内核使用拉链法，且溢出链表为双向链表</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gt5ttu88o4j30wa0u0q4z.jpg\" style=\"zoom:50%;\"></p>\n<p>Linux内核进程详解的上半部分就讲到这，下节我们来讲进程的context switch、创建和撤销。</p>\n<h2 id=\"参考文献\"><a href=\"#参考文献\" class=\"headerlink\" title=\"参考文献\"></a>参考文献</h2><p>[1] Daniel P. Bovet, Marco Cesati Understanding the Linux Kernel, 3rd Edition</p>\n"},{"title":"计网传输层 - 可靠传输协议实验","date":"2021-11-24T09:02:19.000Z","index_img":"/img/tcp.jpeg","math":true,"_content":"\n# 计网传输层 - 可靠传输协议实验\n\n*代码连接： [ZiYang-xie/RDT_protocol (github.com)](https://github.com/ZiYang-xie/RDT_protocol)*\n\n## 1. 实验简介\n\n​\t本次实验要求完成 rdt3.0 基础停等协议的模拟，以及进阶的GBN和SR协议的实现。我们知道网络层的IP协议是不保证报文段按顺序正确交付，其只是“尽力而为”，因此在传输层中TCP需要实现可靠的传输协议为上层应用层提供可靠的传输支持。RDT3.0是最基础的可靠传输协议，其可以保证报文按序正确交付。而GBN和SR则在RDT3.0基础上添加了流水线架构，并且支持顺序or乱序ACK，从而进一步提升协议的速度。\n\n\n\n## 2. 实验内容\n\n​\t实验的代码结构如下图所示，我们需要完成 A_output(), A_input(), A_timerinterrupt(), A_init(), B_input(), B_init()等函数的补充。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gwo9yfv0m8j30oc0dgjsk.jpg\" style=\"zoom:50%;\" />\n\n### 2.1 RDT3.0 (Alternating Bit)\n\n![image-20211122220544951](https://tva1.sinaimg.cn/large/008i3skNly1gwoa2hbtkaj31i40fyact.jpg)\n\n​\t 其基本逻辑如上图所示，在实现代码的时候需要注意的是，通过一个标识位来标记当前状态来实现状态机。如果在ACK的等待状态接受到了上层的调用，则需要把报文先缓存下来，再到接受到ACK的时候检查缓存，按顺序发送。\n\n```c\nif (STATE == WAIT){\n  \tinform(__FUNCTION__, \"Not yet acked, Buffer the Msg: %.20s\", message.data);\n  \tcache_msg(&message);\n  \treturn;\n}\n```\n\n​\t当 `checksum` 失败和收到重复的 `ACK` 的时候，需要重传上一次的分组。\n\n​\t报文的缓存使用循环队列模式，基础实现则是通过一个固定大小（足够大）的数组，加上循环的index实现。\n\n\n\n### 2.2 Go Back N\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gwoaepdhylj31800aamyj.jpg\" style=\"zoom:50%;\" />\n\n​\tGo Back N 需要注意**累计确认**， 即 ACK(n): ACKs 所有n之前(包含n)的分组，同时定时器对应最老的那个没被ACK的分组。如果仅 ACK 窗口最左边的分组，会出现如下情况。\n\n​\t\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gwoahl3tgfj30zy0qkdi5.jpg\" style=\"zoom:30%;\" />\n\n​\t在传送分组的时候丢失了两个ACK，但因为没有 ACK0 整个系统就会陷入无限循环的卡死状态。GBN需要注意累计确认，将窗口滑到对应的位置，接收端的ACK发送正常接收的最后一个分组。\n\n\n\n### 2.3 选择重传 (Selective Repeat)\n\n​\t\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gwoakrl3tnj31760owwhx.jpg\" style=\"zoom:50%;\" />\n\n​\t选择重传因为可以直接ACK乱序的分组，但是同时要保证交付到上层应用层的顺序，因此其在接收端也同样需要一个缓冲区，这个大小就为窗口大小，来暂存收到的报文段。当前面的报文全部被接受的时候就统一移动窗口，同样的对于发送端，当前面的报文全部被ACK之后可以移动窗口。\n\n​\t因此需要对缓冲区的内容进行标记，在实现中我是选用通过对传输报文的第一个字节标记 `\\0` 来实现的。对于发送方，在缓冲区中如果被标记 `\\0` 则说明该位置可写，即尚未存放分组或已经是离开窗口区域。\n\n```c\nvoid clean_pkt(char (*buffer)[20], uint32_t loc)\n{\n    buffer[loc][0] = '\\0';\n}\n```\n\n\n\n\n\n## 3. 性能测试\n\n### 3.0 参数设置\n\n```yaml\n#define TIMEOUT 20\n#define BUF_SZ 10000\n#define WINDOW_SZ 10\n```\n\n### 3.1 基础情况 (无丢包和损坏)\n\n- `参数: 10 0 0 10` \n\n> altBit: 139.041168ms\ngoBackN: 124.61444100000003ms\nselectiveRepeat: 119.80553200000004ms\n\n- ``` 参数: 100 0 0 10```\n\n> altBit: 1172.531616ms\ngoBackN: 1058.7275695000003ms\nselectiveRepeat: 1020.7928873333335ms\n\n​\t可以看到，在无丢包损坏的情况下，选择重传因为可以乱序ACK而占有优势，GBN因为流水线结构而速度较快，AltBit因为停等是速度最慢的。\n\n\n\n### 3.2 丢包差错情况 \n\n- 少量丢包和差错 `参数: 10 0.1 0.1 10` \n\n> altBit: 247.166718ms\ngoBackN: 219.95912200000004ms\nselectiveRepeat: 227.78014633333336m\n\n- 大量丢包和差错 `参数：10 0.5 0.5 10`\n\n> altBit: 3346.8271479999994ms\ngoBackN: 2001.064117ms\nselectiveRepeat: 2813.4893593333336ms\n\n​\t在丢包和损坏情况下，可以看到 GBN 和 SR 都起到了非常不错的作用，和 AltBit 拉开了差距。但我们同时可以看到 GBN 比 SR 的效果更好，这是因为在丢包的情况下，GBN可以直接重传全部，而性能损失较小。但SR因为要在接收端维护缓冲区，所以有一定的性能损失。\n\n\n\n### 3.3 快速大量发包情况\n\n我进而测试了较为极限情况下的大量快速发包的效果对比。可以发现选择重传在这种情况下比较占优。得益于其乱序 ACK 的设计\n\n- 快速大量包 `参数: 1000 0 0 0.1`\n\n> altBit: 11117.566406ms\ngoBackN: 8406.244140499999ms\nselectiveRepeat: 7456.902832000002ms\n\n\n\n\n\n## 4. 总结\n\n​\t本次实验中，通过代码模拟实现了可靠数据传输的基础版本 RDT3.0 以及其进阶GBN和SR协议的实现，更加深入的理解了可靠数据传输的工作原理。\n\n\n\n## 附录\n\n除了固定随机参数以外，测试代码中还提供了多次实验取均值的接口，以进一步测试。\n\n```python\ndef multi_test(N):\n    time_list = []\n    for protocol in protocol_list:\n        for i in range(N):\n            time = test_time(protocol, args)\n            time_list.append(float(time))\n        avg_time = np.mean(time_list)\n        print(f'[{protocol}]: {avg_time}ms')\n```\n\n- **部分实验截图**\n\n![](https://tva1.sinaimg.cn/large/008i3skNly1gwoc6uggs1j30e00g7gno.jpg)\n","source":"_posts/Network/rdt.md","raw":"---\ntitle: 计网传输层 - 可靠传输协议实验\ndate: 2021-11-24 01:02:19\nindex_img: /img/tcp.jpeg\ncategory: [Network]\ntags: [RDT, GBN, SR]\nmath: true\n---\n\n# 计网传输层 - 可靠传输协议实验\n\n*代码连接： [ZiYang-xie/RDT_protocol (github.com)](https://github.com/ZiYang-xie/RDT_protocol)*\n\n## 1. 实验简介\n\n​\t本次实验要求完成 rdt3.0 基础停等协议的模拟，以及进阶的GBN和SR协议的实现。我们知道网络层的IP协议是不保证报文段按顺序正确交付，其只是“尽力而为”，因此在传输层中TCP需要实现可靠的传输协议为上层应用层提供可靠的传输支持。RDT3.0是最基础的可靠传输协议，其可以保证报文按序正确交付。而GBN和SR则在RDT3.0基础上添加了流水线架构，并且支持顺序or乱序ACK，从而进一步提升协议的速度。\n\n\n\n## 2. 实验内容\n\n​\t实验的代码结构如下图所示，我们需要完成 A_output(), A_input(), A_timerinterrupt(), A_init(), B_input(), B_init()等函数的补充。\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gwo9yfv0m8j30oc0dgjsk.jpg\" style=\"zoom:50%;\" />\n\n### 2.1 RDT3.0 (Alternating Bit)\n\n![image-20211122220544951](https://tva1.sinaimg.cn/large/008i3skNly1gwoa2hbtkaj31i40fyact.jpg)\n\n​\t 其基本逻辑如上图所示，在实现代码的时候需要注意的是，通过一个标识位来标记当前状态来实现状态机。如果在ACK的等待状态接受到了上层的调用，则需要把报文先缓存下来，再到接受到ACK的时候检查缓存，按顺序发送。\n\n```c\nif (STATE == WAIT){\n  \tinform(__FUNCTION__, \"Not yet acked, Buffer the Msg: %.20s\", message.data);\n  \tcache_msg(&message);\n  \treturn;\n}\n```\n\n​\t当 `checksum` 失败和收到重复的 `ACK` 的时候，需要重传上一次的分组。\n\n​\t报文的缓存使用循环队列模式，基础实现则是通过一个固定大小（足够大）的数组，加上循环的index实现。\n\n\n\n### 2.2 Go Back N\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gwoaepdhylj31800aamyj.jpg\" style=\"zoom:50%;\" />\n\n​\tGo Back N 需要注意**累计确认**， 即 ACK(n): ACKs 所有n之前(包含n)的分组，同时定时器对应最老的那个没被ACK的分组。如果仅 ACK 窗口最左边的分组，会出现如下情况。\n\n​\t\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gwoahl3tgfj30zy0qkdi5.jpg\" style=\"zoom:30%;\" />\n\n​\t在传送分组的时候丢失了两个ACK，但因为没有 ACK0 整个系统就会陷入无限循环的卡死状态。GBN需要注意累计确认，将窗口滑到对应的位置，接收端的ACK发送正常接收的最后一个分组。\n\n\n\n### 2.3 选择重传 (Selective Repeat)\n\n​\t\n\n<img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gwoakrl3tnj31760owwhx.jpg\" style=\"zoom:50%;\" />\n\n​\t选择重传因为可以直接ACK乱序的分组，但是同时要保证交付到上层应用层的顺序，因此其在接收端也同样需要一个缓冲区，这个大小就为窗口大小，来暂存收到的报文段。当前面的报文全部被接受的时候就统一移动窗口，同样的对于发送端，当前面的报文全部被ACK之后可以移动窗口。\n\n​\t因此需要对缓冲区的内容进行标记，在实现中我是选用通过对传输报文的第一个字节标记 `\\0` 来实现的。对于发送方，在缓冲区中如果被标记 `\\0` 则说明该位置可写，即尚未存放分组或已经是离开窗口区域。\n\n```c\nvoid clean_pkt(char (*buffer)[20], uint32_t loc)\n{\n    buffer[loc][0] = '\\0';\n}\n```\n\n\n\n\n\n## 3. 性能测试\n\n### 3.0 参数设置\n\n```yaml\n#define TIMEOUT 20\n#define BUF_SZ 10000\n#define WINDOW_SZ 10\n```\n\n### 3.1 基础情况 (无丢包和损坏)\n\n- `参数: 10 0 0 10` \n\n> altBit: 139.041168ms\ngoBackN: 124.61444100000003ms\nselectiveRepeat: 119.80553200000004ms\n\n- ``` 参数: 100 0 0 10```\n\n> altBit: 1172.531616ms\ngoBackN: 1058.7275695000003ms\nselectiveRepeat: 1020.7928873333335ms\n\n​\t可以看到，在无丢包损坏的情况下，选择重传因为可以乱序ACK而占有优势，GBN因为流水线结构而速度较快，AltBit因为停等是速度最慢的。\n\n\n\n### 3.2 丢包差错情况 \n\n- 少量丢包和差错 `参数: 10 0.1 0.1 10` \n\n> altBit: 247.166718ms\ngoBackN: 219.95912200000004ms\nselectiveRepeat: 227.78014633333336m\n\n- 大量丢包和差错 `参数：10 0.5 0.5 10`\n\n> altBit: 3346.8271479999994ms\ngoBackN: 2001.064117ms\nselectiveRepeat: 2813.4893593333336ms\n\n​\t在丢包和损坏情况下，可以看到 GBN 和 SR 都起到了非常不错的作用，和 AltBit 拉开了差距。但我们同时可以看到 GBN 比 SR 的效果更好，这是因为在丢包的情况下，GBN可以直接重传全部，而性能损失较小。但SR因为要在接收端维护缓冲区，所以有一定的性能损失。\n\n\n\n### 3.3 快速大量发包情况\n\n我进而测试了较为极限情况下的大量快速发包的效果对比。可以发现选择重传在这种情况下比较占优。得益于其乱序 ACK 的设计\n\n- 快速大量包 `参数: 1000 0 0 0.1`\n\n> altBit: 11117.566406ms\ngoBackN: 8406.244140499999ms\nselectiveRepeat: 7456.902832000002ms\n\n\n\n\n\n## 4. 总结\n\n​\t本次实验中，通过代码模拟实现了可靠数据传输的基础版本 RDT3.0 以及其进阶GBN和SR协议的实现，更加深入的理解了可靠数据传输的工作原理。\n\n\n\n## 附录\n\n除了固定随机参数以外，测试代码中还提供了多次实验取均值的接口，以进一步测试。\n\n```python\ndef multi_test(N):\n    time_list = []\n    for protocol in protocol_list:\n        for i in range(N):\n            time = test_time(protocol, args)\n            time_list.append(float(time))\n        avg_time = np.mean(time_list)\n        print(f'[{protocol}]: {avg_time}ms')\n```\n\n- **部分实验截图**\n\n![](https://tva1.sinaimg.cn/large/008i3skNly1gwoc6uggs1j30e00g7gno.jpg)\n","slug":"Network/rdt","published":1,"updated":"2026-02-03T05:42:14.439Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvk003t7uitbzrr3jao","content":"<h1 id=\"计网传输层-可靠传输协议实验\"><a href=\"#计网传输层-可靠传输协议实验\" class=\"headerlink\" title=\"计网传输层 - 可靠传输协议实验\"></a>计网传输层 - 可靠传输协议实验</h1><p><em>代码连接： <a href=\"https://github.com/ZiYang-xie/RDT_protocol\">ZiYang-xie/RDT_protocol (github.com)</a></em></p>\n<h2 id=\"1-实验简介\"><a href=\"#1-实验简介\" class=\"headerlink\" title=\"1. 实验简介\"></a>1. 实验简介</h2><p>​    本次实验要求完成 rdt3.0 基础停等协议的模拟，以及进阶的GBN和SR协议的实现。我们知道网络层的IP协议是不保证报文段按顺序正确交付，其只是“尽力而为”，因此在传输层中TCP需要实现可靠的传输协议为上层应用层提供可靠的传输支持。RDT3.0是最基础的可靠传输协议，其可以保证报文按序正确交付。而GBN和SR则在RDT3.0基础上添加了流水线架构，并且支持顺序or乱序ACK，从而进一步提升协议的速度。</p>\n<h2 id=\"2-实验内容\"><a href=\"#2-实验内容\" class=\"headerlink\" title=\"2. 实验内容\"></a>2. 实验内容</h2><p>​    实验的代码结构如下图所示，我们需要完成 A_output(), A_input(), A_timerinterrupt(), A_init(), B_input(), B_init()等函数的补充。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gwo9yfv0m8j30oc0dgjsk.jpg\" style=\"zoom:50%;\"></p>\n<h3 id=\"2-1-RDT3-0-Alternating-Bit\"><a href=\"#2-1-RDT3-0-Alternating-Bit\" class=\"headerlink\" title=\"2.1 RDT3.0 (Alternating Bit)\"></a>2.1 RDT3.0 (Alternating Bit)</h3><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gwoa2hbtkaj31i40fyact.jpg\" alt=\"image-20211122220544951\"></p>\n<p>​     其基本逻辑如上图所示，在实现代码的时候需要注意的是，通过一个标识位来标记当前状态来实现状态机。如果在ACK的等待状态接受到了上层的调用，则需要把报文先缓存下来，再到接受到ACK的时候检查缓存，按顺序发送。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-keyword\">if</span> (STATE == WAIT)&#123;\n  \tinform(__FUNCTION__, <span class=\"hljs-string\">&quot;Not yet acked, Buffer the Msg: %.20s&quot;</span>, message.data);\n  \tcache_msg(&amp;message);\n  \t<span class=\"hljs-keyword\">return</span>;\n&#125;</code></pre>\n<p>​    当 <code>checksum</code> 失败和收到重复的 <code>ACK</code> 的时候，需要重传上一次的分组。</p>\n<p>​    报文的缓存使用循环队列模式，基础实现则是通过一个固定大小（足够大）的数组，加上循环的index实现。</p>\n<h3 id=\"2-2-Go-Back-N\"><a href=\"#2-2-Go-Back-N\" class=\"headerlink\" title=\"2.2 Go Back N\"></a>2.2 Go Back N</h3><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gwoaepdhylj31800aamyj.jpg\" style=\"zoom:50%;\"></p>\n<p>​    Go Back N 需要注意<strong>累计确认</strong>， 即 ACK(n): ACKs 所有n之前(包含n)的分组，同时定时器对应最老的那个没被ACK的分组。如果仅 ACK 窗口最左边的分组，会出现如下情况。</p>\n<p>​    </p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gwoahl3tgfj30zy0qkdi5.jpg\" style=\"zoom:30%;\"></p>\n<p>​    在传送分组的时候丢失了两个ACK，但因为没有 ACK0 整个系统就会陷入无限循环的卡死状态。GBN需要注意累计确认，将窗口滑到对应的位置，接收端的ACK发送正常接收的最后一个分组。</p>\n<h3 id=\"2-3-选择重传-Selective-Repeat\"><a href=\"#2-3-选择重传-Selective-Repeat\" class=\"headerlink\" title=\"2.3 选择重传 (Selective Repeat)\"></a>2.3 选择重传 (Selective Repeat)</h3><p>​    </p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gwoakrl3tnj31760owwhx.jpg\" style=\"zoom:50%;\"></p>\n<p>​    选择重传因为可以直接ACK乱序的分组，但是同时要保证交付到上层应用层的顺序，因此其在接收端也同样需要一个缓冲区，这个大小就为窗口大小，来暂存收到的报文段。当前面的报文全部被接受的时候就统一移动窗口，同样的对于发送端，当前面的报文全部被ACK之后可以移动窗口。</p>\n<p>​    因此需要对缓冲区的内容进行标记，在实现中我是选用通过对传输报文的第一个字节标记 <code>\\0</code> 来实现的。对于发送方，在缓冲区中如果被标记 <code>\\0</code> 则说明该位置可写，即尚未存放分组或已经是离开窗口区域。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">clean_pkt</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">char</span> (*buffer)[<span class=\"hljs-number\">20</span>], <span class=\"hljs-keyword\">uint32_t</span> loc)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    buffer[loc][<span class=\"hljs-number\">0</span>] = <span class=\"hljs-string\">&#x27;\\0&#x27;</span>;\n&#125;</code></pre>\n<h2 id=\"3-性能测试\"><a href=\"#3-性能测试\" class=\"headerlink\" title=\"3. 性能测试\"></a>3. 性能测试</h2><h3 id=\"3-0-参数设置\"><a href=\"#3-0-参数设置\" class=\"headerlink\" title=\"3.0 参数设置\"></a>3.0 参数设置</h3><pre><code class=\"hljs yaml\"><span class=\"hljs-comment\">#define TIMEOUT 20</span>\n<span class=\"hljs-comment\">#define BUF_SZ 10000</span>\n<span class=\"hljs-comment\">#define WINDOW_SZ 10</span></code></pre>\n<h3 id=\"3-1-基础情况-无丢包和损坏\"><a href=\"#3-1-基础情况-无丢包和损坏\" class=\"headerlink\" title=\"3.1 基础情况 (无丢包和损坏)\"></a>3.1 基础情况 (无丢包和损坏)</h3><ul>\n<li><code>参数: 10 0 0 10</code> </li>\n</ul>\n<blockquote>\n<p>altBit: 139.041168ms<br>goBackN: 124.61444100000003ms<br>selectiveRepeat: 119.80553200000004ms</p>\n</blockquote>\n<ul>\n<li><code>参数: 100 0 0 10</code></li>\n</ul>\n<blockquote>\n<p>altBit: 1172.531616ms<br>goBackN: 1058.7275695000003ms<br>selectiveRepeat: 1020.7928873333335ms</p>\n</blockquote>\n<p>​    可以看到，在无丢包损坏的情况下，选择重传因为可以乱序ACK而占有优势，GBN因为流水线结构而速度较快，AltBit因为停等是速度最慢的。</p>\n<h3 id=\"3-2-丢包差错情况\"><a href=\"#3-2-丢包差错情况\" class=\"headerlink\" title=\"3.2 丢包差错情况\"></a>3.2 丢包差错情况</h3><ul>\n<li>少量丢包和差错 <code>参数: 10 0.1 0.1 10</code> </li>\n</ul>\n<blockquote>\n<p>altBit: 247.166718ms<br>goBackN: 219.95912200000004ms<br>selectiveRepeat: 227.78014633333336m</p>\n</blockquote>\n<ul>\n<li>大量丢包和差错 <code>参数：10 0.5 0.5 10</code></li>\n</ul>\n<blockquote>\n<p>altBit: 3346.8271479999994ms<br>goBackN: 2001.064117ms<br>selectiveRepeat: 2813.4893593333336ms</p>\n</blockquote>\n<p>​    在丢包和损坏情况下，可以看到 GBN 和 SR 都起到了非常不错的作用，和 AltBit 拉开了差距。但我们同时可以看到 GBN 比 SR 的效果更好，这是因为在丢包的情况下，GBN可以直接重传全部，而性能损失较小。但SR因为要在接收端维护缓冲区，所以有一定的性能损失。</p>\n<h3 id=\"3-3-快速大量发包情况\"><a href=\"#3-3-快速大量发包情况\" class=\"headerlink\" title=\"3.3 快速大量发包情况\"></a>3.3 快速大量发包情况</h3><p>我进而测试了较为极限情况下的大量快速发包的效果对比。可以发现选择重传在这种情况下比较占优。得益于其乱序 ACK 的设计</p>\n<ul>\n<li>快速大量包 <code>参数: 1000 0 0 0.1</code></li>\n</ul>\n<blockquote>\n<p>altBit: 11117.566406ms<br>goBackN: 8406.244140499999ms<br>selectiveRepeat: 7456.902832000002ms</p>\n</blockquote>\n<h2 id=\"4-总结\"><a href=\"#4-总结\" class=\"headerlink\" title=\"4. 总结\"></a>4. 总结</h2><p>​    本次实验中，通过代码模拟实现了可靠数据传输的基础版本 RDT3.0 以及其进阶GBN和SR协议的实现，更加深入的理解了可靠数据传输的工作原理。</p>\n<h2 id=\"附录\"><a href=\"#附录\" class=\"headerlink\" title=\"附录\"></a>附录</h2><p>除了固定随机参数以外，测试代码中还提供了多次实验取均值的接口，以进一步测试。</p>\n<pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">multi_test</span>(<span class=\"hljs-params\">N</span>):</span>\n    time_list = []\n    <span class=\"hljs-keyword\">for</span> protocol <span class=\"hljs-keyword\">in</span> protocol_list:\n        <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(N):\n            time = test_time(protocol, args)\n            time_list.append(<span class=\"hljs-built_in\">float</span>(time))\n        avg_time = np.mean(time_list)\n        print(<span class=\"hljs-string\">f&#x27;[<span class=\"hljs-subst\">&#123;protocol&#125;</span>]: <span class=\"hljs-subst\">&#123;avg_time&#125;</span>ms&#x27;</span>)</code></pre>\n<ul>\n<li><strong>部分实验截图</strong></li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gwoc6uggs1j30e00g7gno.jpg\" alt></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"计网传输层-可靠传输协议实验\"><a href=\"#计网传输层-可靠传输协议实验\" class=\"headerlink\" title=\"计网传输层 - 可靠传输协议实验\"></a>计网传输层 - 可靠传输协议实验</h1><p><em>代码连接： <a href=\"https://github.com/ZiYang-xie/RDT_protocol\">ZiYang-xie/RDT_protocol (github.com)</a></em></p>\n<h2 id=\"1-实验简介\"><a href=\"#1-实验简介\" class=\"headerlink\" title=\"1. 实验简介\"></a>1. 实验简介</h2><p>​    本次实验要求完成 rdt3.0 基础停等协议的模拟，以及进阶的GBN和SR协议的实现。我们知道网络层的IP协议是不保证报文段按顺序正确交付，其只是“尽力而为”，因此在传输层中TCP需要实现可靠的传输协议为上层应用层提供可靠的传输支持。RDT3.0是最基础的可靠传输协议，其可以保证报文按序正确交付。而GBN和SR则在RDT3.0基础上添加了流水线架构，并且支持顺序or乱序ACK，从而进一步提升协议的速度。</p>\n<h2 id=\"2-实验内容\"><a href=\"#2-实验内容\" class=\"headerlink\" title=\"2. 实验内容\"></a>2. 实验内容</h2><p>​    实验的代码结构如下图所示，我们需要完成 A_output(), A_input(), A_timerinterrupt(), A_init(), B_input(), B_init()等函数的补充。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gwo9yfv0m8j30oc0dgjsk.jpg\" style=\"zoom:50%;\"></p>\n<h3 id=\"2-1-RDT3-0-Alternating-Bit\"><a href=\"#2-1-RDT3-0-Alternating-Bit\" class=\"headerlink\" title=\"2.1 RDT3.0 (Alternating Bit)\"></a>2.1 RDT3.0 (Alternating Bit)</h3><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gwoa2hbtkaj31i40fyact.jpg\" alt=\"image-20211122220544951\"></p>\n<p>​     其基本逻辑如上图所示，在实现代码的时候需要注意的是，通过一个标识位来标记当前状态来实现状态机。如果在ACK的等待状态接受到了上层的调用，则需要把报文先缓存下来，再到接受到ACK的时候检查缓存，按顺序发送。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-keyword\">if</span> (STATE == WAIT)&#123;\n  \tinform(__FUNCTION__, <span class=\"hljs-string\">&quot;Not yet acked, Buffer the Msg: %.20s&quot;</span>, message.data);\n  \tcache_msg(&amp;message);\n  \t<span class=\"hljs-keyword\">return</span>;\n&#125;</code></pre>\n<p>​    当 <code>checksum</code> 失败和收到重复的 <code>ACK</code> 的时候，需要重传上一次的分组。</p>\n<p>​    报文的缓存使用循环队列模式，基础实现则是通过一个固定大小（足够大）的数组，加上循环的index实现。</p>\n<h3 id=\"2-2-Go-Back-N\"><a href=\"#2-2-Go-Back-N\" class=\"headerlink\" title=\"2.2 Go Back N\"></a>2.2 Go Back N</h3><p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gwoaepdhylj31800aamyj.jpg\" style=\"zoom:50%;\"></p>\n<p>​    Go Back N 需要注意<strong>累计确认</strong>， 即 ACK(n): ACKs 所有n之前(包含n)的分组，同时定时器对应最老的那个没被ACK的分组。如果仅 ACK 窗口最左边的分组，会出现如下情况。</p>\n<p>​    </p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gwoahl3tgfj30zy0qkdi5.jpg\" style=\"zoom:30%;\"></p>\n<p>​    在传送分组的时候丢失了两个ACK，但因为没有 ACK0 整个系统就会陷入无限循环的卡死状态。GBN需要注意累计确认，将窗口滑到对应的位置，接收端的ACK发送正常接收的最后一个分组。</p>\n<h3 id=\"2-3-选择重传-Selective-Repeat\"><a href=\"#2-3-选择重传-Selective-Repeat\" class=\"headerlink\" title=\"2.3 选择重传 (Selective Repeat)\"></a>2.3 选择重传 (Selective Repeat)</h3><p>​    </p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gwoakrl3tnj31760owwhx.jpg\" style=\"zoom:50%;\"></p>\n<p>​    选择重传因为可以直接ACK乱序的分组，但是同时要保证交付到上层应用层的顺序，因此其在接收端也同样需要一个缓冲区，这个大小就为窗口大小，来暂存收到的报文段。当前面的报文全部被接受的时候就统一移动窗口，同样的对于发送端，当前面的报文全部被ACK之后可以移动窗口。</p>\n<p>​    因此需要对缓冲区的内容进行标记，在实现中我是选用通过对传输报文的第一个字节标记 <code>\\0</code> 来实现的。对于发送方，在缓冲区中如果被标记 <code>\\0</code> 则说明该位置可写，即尚未存放分组或已经是离开窗口区域。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">clean_pkt</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">char</span> (*buffer)[<span class=\"hljs-number\">20</span>], <span class=\"hljs-keyword\">uint32_t</span> loc)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    buffer[loc][<span class=\"hljs-number\">0</span>] = <span class=\"hljs-string\">&#x27;\\0&#x27;</span>;\n&#125;</code></pre>\n<h2 id=\"3-性能测试\"><a href=\"#3-性能测试\" class=\"headerlink\" title=\"3. 性能测试\"></a>3. 性能测试</h2><h3 id=\"3-0-参数设置\"><a href=\"#3-0-参数设置\" class=\"headerlink\" title=\"3.0 参数设置\"></a>3.0 参数设置</h3><pre><code class=\"hljs yaml\"><span class=\"hljs-comment\">#define TIMEOUT 20</span>\n<span class=\"hljs-comment\">#define BUF_SZ 10000</span>\n<span class=\"hljs-comment\">#define WINDOW_SZ 10</span></code></pre>\n<h3 id=\"3-1-基础情况-无丢包和损坏\"><a href=\"#3-1-基础情况-无丢包和损坏\" class=\"headerlink\" title=\"3.1 基础情况 (无丢包和损坏)\"></a>3.1 基础情况 (无丢包和损坏)</h3><ul>\n<li><code>参数: 10 0 0 10</code> </li>\n</ul>\n<blockquote>\n<p>altBit: 139.041168ms<br>goBackN: 124.61444100000003ms<br>selectiveRepeat: 119.80553200000004ms</p>\n</blockquote>\n<ul>\n<li><code>参数: 100 0 0 10</code></li>\n</ul>\n<blockquote>\n<p>altBit: 1172.531616ms<br>goBackN: 1058.7275695000003ms<br>selectiveRepeat: 1020.7928873333335ms</p>\n</blockquote>\n<p>​    可以看到，在无丢包损坏的情况下，选择重传因为可以乱序ACK而占有优势，GBN因为流水线结构而速度较快，AltBit因为停等是速度最慢的。</p>\n<h3 id=\"3-2-丢包差错情况\"><a href=\"#3-2-丢包差错情况\" class=\"headerlink\" title=\"3.2 丢包差错情况\"></a>3.2 丢包差错情况</h3><ul>\n<li>少量丢包和差错 <code>参数: 10 0.1 0.1 10</code> </li>\n</ul>\n<blockquote>\n<p>altBit: 247.166718ms<br>goBackN: 219.95912200000004ms<br>selectiveRepeat: 227.78014633333336m</p>\n</blockquote>\n<ul>\n<li>大量丢包和差错 <code>参数：10 0.5 0.5 10</code></li>\n</ul>\n<blockquote>\n<p>altBit: 3346.8271479999994ms<br>goBackN: 2001.064117ms<br>selectiveRepeat: 2813.4893593333336ms</p>\n</blockquote>\n<p>​    在丢包和损坏情况下，可以看到 GBN 和 SR 都起到了非常不错的作用，和 AltBit 拉开了差距。但我们同时可以看到 GBN 比 SR 的效果更好，这是因为在丢包的情况下，GBN可以直接重传全部，而性能损失较小。但SR因为要在接收端维护缓冲区，所以有一定的性能损失。</p>\n<h3 id=\"3-3-快速大量发包情况\"><a href=\"#3-3-快速大量发包情况\" class=\"headerlink\" title=\"3.3 快速大量发包情况\"></a>3.3 快速大量发包情况</h3><p>我进而测试了较为极限情况下的大量快速发包的效果对比。可以发现选择重传在这种情况下比较占优。得益于其乱序 ACK 的设计</p>\n<ul>\n<li>快速大量包 <code>参数: 1000 0 0 0.1</code></li>\n</ul>\n<blockquote>\n<p>altBit: 11117.566406ms<br>goBackN: 8406.244140499999ms<br>selectiveRepeat: 7456.902832000002ms</p>\n</blockquote>\n<h2 id=\"4-总结\"><a href=\"#4-总结\" class=\"headerlink\" title=\"4. 总结\"></a>4. 总结</h2><p>​    本次实验中，通过代码模拟实现了可靠数据传输的基础版本 RDT3.0 以及其进阶GBN和SR协议的实现，更加深入的理解了可靠数据传输的工作原理。</p>\n<h2 id=\"附录\"><a href=\"#附录\" class=\"headerlink\" title=\"附录\"></a>附录</h2><p>除了固定随机参数以外，测试代码中还提供了多次实验取均值的接口，以进一步测试。</p>\n<pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">multi_test</span>(<span class=\"hljs-params\">N</span>):</span>\n    time_list = []\n    <span class=\"hljs-keyword\">for</span> protocol <span class=\"hljs-keyword\">in</span> protocol_list:\n        <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(N):\n            time = test_time(protocol, args)\n            time_list.append(<span class=\"hljs-built_in\">float</span>(time))\n        avg_time = np.mean(time_list)\n        print(<span class=\"hljs-string\">f&#x27;[<span class=\"hljs-subst\">&#123;protocol&#125;</span>]: <span class=\"hljs-subst\">&#123;avg_time&#125;</span>ms&#x27;</span>)</code></pre>\n<ul>\n<li><strong>部分实验截图</strong></li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/008i3skNly1gwoc6uggs1j30e00g7gno.jpg\" alt></p>\n"},{"title":"PointCNN论文阅读","date":"2020-12-09T04:00:23.000Z","index_img":"/img/Pic/cnn_img.jpeg","banner_img":"/img/Pic/PointCloud.jpg","math":true,"_content":"\n# PointCNN\n\n回顾之前读过的 PointNet++ 是受到 CNN 启发，通过局部的特征提取器和hierarchy 结构解决了 PointNet 在 local 上的劣势。但同时这种基于 PointNet 的顺序不依赖性使用的 symmetry function 最终总会导致一部分的信息丢失，PointCNN 直接使用 CNN 架构和一种自定义的 $\\chi -Conv$ 操作，使常规的卷积也能处理点云。\n\n---\n\n## 关键问题 - PointCloud 上的卷积\n\n我们都知道普通的 2d 卷积的实现方式，因为在图片上像素都是紧密相连的，很好实现，但对于 3d 的 Points 点的空间位置，距离，顺序都会对卷积造成挑战和影响，下图就展示了普通的 2d卷积 和 3d PointCloud 卷积的区别。\n\n![](https://s3.ax1x.com/2020/12/08/r9iVTU.png)\n\n\n显然 PointCloud 上的卷积和形状(即点的相对位置) 和输入顺序有关。如果直接在上面做卷积就会发生灾难。\n\n![](https://s3.ax1x.com/2020/12/08/r9infJ.png)\n\n上图我们看出，直接做卷积的话 $f_{ii}$ 和 $f_{iii}$ 不同的形状信息被丢失了（这正是我们希望保留的），而 $f_{iii}$ 与 $f_{iv}$ 之间仅因为顺序不同而造成了结果不同，即顺序有关，这是我们不希望看到的。\n\n对于这个的解决方式，PointCNN 的作者使用了一个 $\\chi$ - transformer 矩阵，先对 sample point 作用 $\\chi$ 变换矩阵，再进行 Convolution 从而做到顺序无关的同时，不像 symmetry function 会丢失信息。\n\n![有点懒得翻译了，直接放原文](https://s3.ax1x.com/2020/12/08/r9ilOx.png)\n\n可以看出这个 $\\chi$ - transformation 是通过训练一个多层感知机获得的。同时产生输入点集的权重和排序，进而直接作用一个经典的卷积。\n\n![](https://s3.ax1x.com/2020/12/08/r9imY4.png)\n\n简单来说就是我们希望对于 $\\chi_{iii}$ 、 $\\chi_{iv}$ 对于 $f_{iii}$ 、 $f_{iv}$ 的作用能够得到相同的feature，一种简单的实现方式就是找到一个变换矩阵 $\\Pi$ 使得 $f_{iii}^{T} = \\Pi \\times f_{iv}^T$ 这样  $\\chi_{iii} = \\chi_{iv} \\times \\Pi$ 就可以达到目标。\n\n值得注意的是，多层感知机得出的 $\\Pi$ 并非一定是理想化的0101矩阵，而是有如0.1，0.9这样接近01的值，也可以将其理解为 feature 的权重这样得到的结果并不是完美的 即 $f_{iii}^{T} ≈ \\Pi \\times f_{iv}^T$\n\n---\n\n## 点云的平移不变性\n\n对于平移不变性的处理 PointCNN 很简单的使用了局部坐标系的转换，对于分割问题，采用最远点采样方式，然后对于采样点取 k - nearnest neighbours 将坐标系转换到采样点为中心的局部坐标系(即减去采样点坐标)\n\n![](https://s3.ax1x.com/2020/12/08/r9iekF.png)\n\n对于卷积层，具体算法如下\n\n![](https://s3.ax1x.com/2020/12/08/r9i3m6.png)\n\n- 先做feature的选点和聚合，先转换到采样点局部坐标系\n- 利用MLP将每个点变换到高维空间$C_{\\delta}$ （这里用的是一维卷积）\n- Concat 其他特征信息\n- **对每个局部区域中的点使用MLP，得到变换矩阵X**\n- 将得到的 $\\chi$ 作用在 $F_*$ 上生成顺序不依赖的 $F_{\\chi}$\n- 对顺序不依赖的 $F_{\\chi}$ 做 Convolution (这里也是一维卷积)\n\n## 可视化\n\n![](https://s3.ax1x.com/2020/12/08/r9i80K.png)\n\n对于 $\\chi$ - transformer 的效果有上图的 visualization 可以看到 $F_*$ 中不同的 class 还是有overlap的因为对于 $F_*$ 其仅将特征提取到了高维，但其结果还是依赖于输入的顺序，所以不能够很好的划分featrue，而经过了 $\\chi$ - transformer 不同的feature 被划分开来且更为密集，结果较好。\n\n## 模型效果\n\n![](https://s3.ax1x.com/2020/12/08/r9iMlR.png)\n\n可以看到准确率保持在一个比较高的水平。\n\n![](https://s3.ax1x.com/2020/12/08/r9iQ61.png)\n\n同时 PointCNN 具有更少的参数 (0.6M) 以及极快的速度 (0.012s)\nPointCNN 极具前景可以将 CNN 现有的工作进行应用。后续会看 PointCNN++ 等论文。\n\n## 总结\n\nPointCNN 直接将点云和CNN结合将点云的工作引入到了一个开阔的领域，但近来也有一些工作在质疑 CNN 的必要性，google 的论文 Attention is all you need 就指出在 NLP 领域 transformer attention based 方法巨大的前景，也为 3D instance segmentation 提供了新思路。\n关于 PointCNN 这篇经典读的还不是很透，关于 sample 选点的顺序问题和一些训练细节还没有弄的很懂，之后找时间细看。","source":"_posts/Research/PointCNN.md","raw":"---\ntitle: PointCNN论文阅读\ndate: 2020-12-08 20:00:23\nindex_img: /img/Pic/cnn_img.jpeg\nbanner_img: /img/Pic/PointCloud.jpg\ncategory: [Research]\ntags: PointCNN\nmath: true\n---\n\n# PointCNN\n\n回顾之前读过的 PointNet++ 是受到 CNN 启发，通过局部的特征提取器和hierarchy 结构解决了 PointNet 在 local 上的劣势。但同时这种基于 PointNet 的顺序不依赖性使用的 symmetry function 最终总会导致一部分的信息丢失，PointCNN 直接使用 CNN 架构和一种自定义的 $\\chi -Conv$ 操作，使常规的卷积也能处理点云。\n\n---\n\n## 关键问题 - PointCloud 上的卷积\n\n我们都知道普通的 2d 卷积的实现方式，因为在图片上像素都是紧密相连的，很好实现，但对于 3d 的 Points 点的空间位置，距离，顺序都会对卷积造成挑战和影响，下图就展示了普通的 2d卷积 和 3d PointCloud 卷积的区别。\n\n![](https://s3.ax1x.com/2020/12/08/r9iVTU.png)\n\n\n显然 PointCloud 上的卷积和形状(即点的相对位置) 和输入顺序有关。如果直接在上面做卷积就会发生灾难。\n\n![](https://s3.ax1x.com/2020/12/08/r9infJ.png)\n\n上图我们看出，直接做卷积的话 $f_{ii}$ 和 $f_{iii}$ 不同的形状信息被丢失了（这正是我们希望保留的），而 $f_{iii}$ 与 $f_{iv}$ 之间仅因为顺序不同而造成了结果不同，即顺序有关，这是我们不希望看到的。\n\n对于这个的解决方式，PointCNN 的作者使用了一个 $\\chi$ - transformer 矩阵，先对 sample point 作用 $\\chi$ 变换矩阵，再进行 Convolution 从而做到顺序无关的同时，不像 symmetry function 会丢失信息。\n\n![有点懒得翻译了，直接放原文](https://s3.ax1x.com/2020/12/08/r9ilOx.png)\n\n可以看出这个 $\\chi$ - transformation 是通过训练一个多层感知机获得的。同时产生输入点集的权重和排序，进而直接作用一个经典的卷积。\n\n![](https://s3.ax1x.com/2020/12/08/r9imY4.png)\n\n简单来说就是我们希望对于 $\\chi_{iii}$ 、 $\\chi_{iv}$ 对于 $f_{iii}$ 、 $f_{iv}$ 的作用能够得到相同的feature，一种简单的实现方式就是找到一个变换矩阵 $\\Pi$ 使得 $f_{iii}^{T} = \\Pi \\times f_{iv}^T$ 这样  $\\chi_{iii} = \\chi_{iv} \\times \\Pi$ 就可以达到目标。\n\n值得注意的是，多层感知机得出的 $\\Pi$ 并非一定是理想化的0101矩阵，而是有如0.1，0.9这样接近01的值，也可以将其理解为 feature 的权重这样得到的结果并不是完美的 即 $f_{iii}^{T} ≈ \\Pi \\times f_{iv}^T$\n\n---\n\n## 点云的平移不变性\n\n对于平移不变性的处理 PointCNN 很简单的使用了局部坐标系的转换，对于分割问题，采用最远点采样方式，然后对于采样点取 k - nearnest neighbours 将坐标系转换到采样点为中心的局部坐标系(即减去采样点坐标)\n\n![](https://s3.ax1x.com/2020/12/08/r9iekF.png)\n\n对于卷积层，具体算法如下\n\n![](https://s3.ax1x.com/2020/12/08/r9i3m6.png)\n\n- 先做feature的选点和聚合，先转换到采样点局部坐标系\n- 利用MLP将每个点变换到高维空间$C_{\\delta}$ （这里用的是一维卷积）\n- Concat 其他特征信息\n- **对每个局部区域中的点使用MLP，得到变换矩阵X**\n- 将得到的 $\\chi$ 作用在 $F_*$ 上生成顺序不依赖的 $F_{\\chi}$\n- 对顺序不依赖的 $F_{\\chi}$ 做 Convolution (这里也是一维卷积)\n\n## 可视化\n\n![](https://s3.ax1x.com/2020/12/08/r9i80K.png)\n\n对于 $\\chi$ - transformer 的效果有上图的 visualization 可以看到 $F_*$ 中不同的 class 还是有overlap的因为对于 $F_*$ 其仅将特征提取到了高维，但其结果还是依赖于输入的顺序，所以不能够很好的划分featrue，而经过了 $\\chi$ - transformer 不同的feature 被划分开来且更为密集，结果较好。\n\n## 模型效果\n\n![](https://s3.ax1x.com/2020/12/08/r9iMlR.png)\n\n可以看到准确率保持在一个比较高的水平。\n\n![](https://s3.ax1x.com/2020/12/08/r9iQ61.png)\n\n同时 PointCNN 具有更少的参数 (0.6M) 以及极快的速度 (0.012s)\nPointCNN 极具前景可以将 CNN 现有的工作进行应用。后续会看 PointCNN++ 等论文。\n\n## 总结\n\nPointCNN 直接将点云和CNN结合将点云的工作引入到了一个开阔的领域，但近来也有一些工作在质疑 CNN 的必要性，google 的论文 Attention is all you need 就指出在 NLP 领域 transformer attention based 方法巨大的前景，也为 3D instance segmentation 提供了新思路。\n关于 PointCNN 这篇经典读的还不是很透，关于 sample 选点的顺序问题和一些训练细节还没有弄的很懂，之后找时间细看。","slug":"Research/PointCNN","published":1,"updated":"2026-02-03T05:42:14.451Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvk003y7uithhgh2qtc","content":"<h1 id=\"PointCNN\"><a href=\"#PointCNN\" class=\"headerlink\" title=\"PointCNN\"></a>PointCNN</h1><p>回顾之前读过的 PointNet++ 是受到 CNN 启发，通过局部的特征提取器和hierarchy 结构解决了 PointNet 在 local 上的劣势。但同时这种基于 PointNet 的顺序不依赖性使用的 symmetry function 最终总会导致一部分的信息丢失，PointCNN 直接使用 CNN 架构和一种自定义的 $\\chi -Conv$ 操作，使常规的卷积也能处理点云。</p>\n<hr>\n<h2 id=\"关键问题-PointCloud-上的卷积\"><a href=\"#关键问题-PointCloud-上的卷积\" class=\"headerlink\" title=\"关键问题 - PointCloud 上的卷积\"></a>关键问题 - PointCloud 上的卷积</h2><p>我们都知道普通的 2d 卷积的实现方式，因为在图片上像素都是紧密相连的，很好实现，但对于 3d 的 Points 点的空间位置，距离，顺序都会对卷积造成挑战和影响，下图就展示了普通的 2d卷积 和 3d PointCloud 卷积的区别。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9iVTU.png\" alt></p>\n<p>显然 PointCloud 上的卷积和形状(即点的相对位置) 和输入顺序有关。如果直接在上面做卷积就会发生灾难。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9infJ.png\" alt></p>\n<p>上图我们看出，直接做卷积的话 $f<em>{ii}$ 和 $f</em>{iii}$ 不同的形状信息被丢失了（这正是我们希望保留的），而 $f<em>{iii}$ 与 $f</em>{iv}$ 之间仅因为顺序不同而造成了结果不同，即顺序有关，这是我们不希望看到的。</p>\n<p>对于这个的解决方式，PointCNN 的作者使用了一个 $\\chi$ - transformer 矩阵，先对 sample point 作用 $\\chi$ 变换矩阵，再进行 Convolution 从而做到顺序无关的同时，不像 symmetry function 会丢失信息。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9ilOx.png\" alt=\"有点懒得翻译了，直接放原文\"></p>\n<p>可以看出这个 $\\chi$ - transformation 是通过训练一个多层感知机获得的。同时产生输入点集的权重和排序，进而直接作用一个经典的卷积。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9imY4.png\" alt></p>\n<p>简单来说就是我们希望对于 $\\chi<em>{iii}$ 、 $\\chi</em>{iv}$ 对于 $f<em>{iii}$ 、 $f</em>{iv}$ 的作用能够得到相同的feature，一种简单的实现方式就是找到一个变换矩阵 $\\Pi$ 使得 $f<em>{iii}^{T} = \\Pi \\times f</em>{iv}^T$ 这样  $\\chi<em>{iii} = \\chi</em>{iv} \\times \\Pi$ 就可以达到目标。</p>\n<p>值得注意的是，多层感知机得出的 $\\Pi$ 并非一定是理想化的0101矩阵，而是有如0.1，0.9这样接近01的值，也可以将其理解为 feature 的权重这样得到的结果并不是完美的 即 $f<em>{iii}^{T} ≈ \\Pi \\times f</em>{iv}^T$</p>\n<hr>\n<h2 id=\"点云的平移不变性\"><a href=\"#点云的平移不变性\" class=\"headerlink\" title=\"点云的平移不变性\"></a>点云的平移不变性</h2><p>对于平移不变性的处理 PointCNN 很简单的使用了局部坐标系的转换，对于分割问题，采用最远点采样方式，然后对于采样点取 k - nearnest neighbours 将坐标系转换到采样点为中心的局部坐标系(即减去采样点坐标)</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9iekF.png\" alt></p>\n<p>对于卷积层，具体算法如下</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9i3m6.png\" alt></p>\n<ul>\n<li>先做feature的选点和聚合，先转换到采样点局部坐标系</li>\n<li>利用MLP将每个点变换到高维空间$C_{\\delta}$ （这里用的是一维卷积）</li>\n<li>Concat 其他特征信息</li>\n<li><strong>对每个局部区域中的点使用MLP，得到变换矩阵X</strong></li>\n<li>将得到的 $\\chi$ 作用在 $F<em>*$ 上生成顺序不依赖的 $F</em>{\\chi}$</li>\n<li>对顺序不依赖的 $F_{\\chi}$ 做 Convolution (这里也是一维卷积)</li>\n</ul>\n<h2 id=\"可视化\"><a href=\"#可视化\" class=\"headerlink\" title=\"可视化\"></a>可视化</h2><p><img src=\"https://s3.ax1x.com/2020/12/08/r9i80K.png\" alt></p>\n<p>对于 $\\chi$ - transformer 的效果有上图的 visualization 可以看到 $F<em>*$ 中不同的 class 还是有overlap的因为对于 $F</em>*$ 其仅将特征提取到了高维，但其结果还是依赖于输入的顺序，所以不能够很好的划分featrue，而经过了 $\\chi$ - transformer 不同的feature 被划分开来且更为密集，结果较好。</p>\n<h2 id=\"模型效果\"><a href=\"#模型效果\" class=\"headerlink\" title=\"模型效果\"></a>模型效果</h2><p><img src=\"https://s3.ax1x.com/2020/12/08/r9iMlR.png\" alt></p>\n<p>可以看到准确率保持在一个比较高的水平。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9iQ61.png\" alt></p>\n<p>同时 PointCNN 具有更少的参数 (0.6M) 以及极快的速度 (0.012s)<br>PointCNN 极具前景可以将 CNN 现有的工作进行应用。后续会看 PointCNN++ 等论文。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>PointCNN 直接将点云和CNN结合将点云的工作引入到了一个开阔的领域，但近来也有一些工作在质疑 CNN 的必要性，google 的论文 Attention is all you need 就指出在 NLP 领域 transformer attention based 方法巨大的前景，也为 3D instance segmentation 提供了新思路。<br>关于 PointCNN 这篇经典读的还不是很透，关于 sample 选点的顺序问题和一些训练细节还没有弄的很懂，之后找时间细看。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"PointCNN\"><a href=\"#PointCNN\" class=\"headerlink\" title=\"PointCNN\"></a>PointCNN</h1><p>回顾之前读过的 PointNet++ 是受到 CNN 启发，通过局部的特征提取器和hierarchy 结构解决了 PointNet 在 local 上的劣势。但同时这种基于 PointNet 的顺序不依赖性使用的 symmetry function 最终总会导致一部分的信息丢失，PointCNN 直接使用 CNN 架构和一种自定义的 $\\chi -Conv$ 操作，使常规的卷积也能处理点云。</p>\n<hr>\n<h2 id=\"关键问题-PointCloud-上的卷积\"><a href=\"#关键问题-PointCloud-上的卷积\" class=\"headerlink\" title=\"关键问题 - PointCloud 上的卷积\"></a>关键问题 - PointCloud 上的卷积</h2><p>我们都知道普通的 2d 卷积的实现方式，因为在图片上像素都是紧密相连的，很好实现，但对于 3d 的 Points 点的空间位置，距离，顺序都会对卷积造成挑战和影响，下图就展示了普通的 2d卷积 和 3d PointCloud 卷积的区别。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9iVTU.png\" alt></p>\n<p>显然 PointCloud 上的卷积和形状(即点的相对位置) 和输入顺序有关。如果直接在上面做卷积就会发生灾难。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9infJ.png\" alt></p>\n<p>上图我们看出，直接做卷积的话 $f<em>{ii}$ 和 $f</em>{iii}$ 不同的形状信息被丢失了（这正是我们希望保留的），而 $f<em>{iii}$ 与 $f</em>{iv}$ 之间仅因为顺序不同而造成了结果不同，即顺序有关，这是我们不希望看到的。</p>\n<p>对于这个的解决方式，PointCNN 的作者使用了一个 $\\chi$ - transformer 矩阵，先对 sample point 作用 $\\chi$ 变换矩阵，再进行 Convolution 从而做到顺序无关的同时，不像 symmetry function 会丢失信息。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9ilOx.png\" alt=\"有点懒得翻译了，直接放原文\"></p>\n<p>可以看出这个 $\\chi$ - transformation 是通过训练一个多层感知机获得的。同时产生输入点集的权重和排序，进而直接作用一个经典的卷积。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9imY4.png\" alt></p>\n<p>简单来说就是我们希望对于 $\\chi<em>{iii}$ 、 $\\chi</em>{iv}$ 对于 $f<em>{iii}$ 、 $f</em>{iv}$ 的作用能够得到相同的feature，一种简单的实现方式就是找到一个变换矩阵 $\\Pi$ 使得 $f<em>{iii}^{T} = \\Pi \\times f</em>{iv}^T$ 这样  $\\chi<em>{iii} = \\chi</em>{iv} \\times \\Pi$ 就可以达到目标。</p>\n<p>值得注意的是，多层感知机得出的 $\\Pi$ 并非一定是理想化的0101矩阵，而是有如0.1，0.9这样接近01的值，也可以将其理解为 feature 的权重这样得到的结果并不是完美的 即 $f<em>{iii}^{T} ≈ \\Pi \\times f</em>{iv}^T$</p>\n<hr>\n<h2 id=\"点云的平移不变性\"><a href=\"#点云的平移不变性\" class=\"headerlink\" title=\"点云的平移不变性\"></a>点云的平移不变性</h2><p>对于平移不变性的处理 PointCNN 很简单的使用了局部坐标系的转换，对于分割问题，采用最远点采样方式，然后对于采样点取 k - nearnest neighbours 将坐标系转换到采样点为中心的局部坐标系(即减去采样点坐标)</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9iekF.png\" alt></p>\n<p>对于卷积层，具体算法如下</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9i3m6.png\" alt></p>\n<ul>\n<li>先做feature的选点和聚合，先转换到采样点局部坐标系</li>\n<li>利用MLP将每个点变换到高维空间$C_{\\delta}$ （这里用的是一维卷积）</li>\n<li>Concat 其他特征信息</li>\n<li><strong>对每个局部区域中的点使用MLP，得到变换矩阵X</strong></li>\n<li>将得到的 $\\chi$ 作用在 $F<em>*$ 上生成顺序不依赖的 $F</em>{\\chi}$</li>\n<li>对顺序不依赖的 $F_{\\chi}$ 做 Convolution (这里也是一维卷积)</li>\n</ul>\n<h2 id=\"可视化\"><a href=\"#可视化\" class=\"headerlink\" title=\"可视化\"></a>可视化</h2><p><img src=\"https://s3.ax1x.com/2020/12/08/r9i80K.png\" alt></p>\n<p>对于 $\\chi$ - transformer 的效果有上图的 visualization 可以看到 $F<em>*$ 中不同的 class 还是有overlap的因为对于 $F</em>*$ 其仅将特征提取到了高维，但其结果还是依赖于输入的顺序，所以不能够很好的划分featrue，而经过了 $\\chi$ - transformer 不同的feature 被划分开来且更为密集，结果较好。</p>\n<h2 id=\"模型效果\"><a href=\"#模型效果\" class=\"headerlink\" title=\"模型效果\"></a>模型效果</h2><p><img src=\"https://s3.ax1x.com/2020/12/08/r9iMlR.png\" alt></p>\n<p>可以看到准确率保持在一个比较高的水平。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9iQ61.png\" alt></p>\n<p>同时 PointCNN 具有更少的参数 (0.6M) 以及极快的速度 (0.012s)<br>PointCNN 极具前景可以将 CNN 现有的工作进行应用。后续会看 PointCNN++ 等论文。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>PointCNN 直接将点云和CNN结合将点云的工作引入到了一个开阔的领域，但近来也有一些工作在质疑 CNN 的必要性，google 的论文 Attention is all you need 就指出在 NLP 领域 transformer attention based 方法巨大的前景，也为 3D instance segmentation 提供了新思路。<br>关于 PointCNN 这篇经典读的还不是很透，关于 sample 选点的顺序问题和一些训练细节还没有弄的很懂，之后找时间细看。</p>\n"},{"title":"PointNet论文阅读","date":"2020-12-06T22:46:14.000Z","index_img":"/img/Pic/cnn_img.jpeg","banner_img":"/img/Pic/PointCloud.jpg","math":true,"_content":"\n### PointCloud\n\n何谓点云，点云数据和普通的照片又有什么不同？实际上点云并非什么高深的东西，下图就是一张点云的可视化数据。\n![点云街道](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1607249767189&di=e4964b8b875326b97e5ab06da6196601&imgtype=0&src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fq_70%2Cc_zoom%2Cw_640%2Fimages%2F20180118%2F537a4b5eab09459881f9bc6ca18834f9.jpeg)\n\n- **位置信息**\n不同于原先2D的图像，每个像素点仅有RGB信息，点云自带了欧式空间中的位置信息，即坐标(x,y,z) 之后会附带一些RGB灰度值之类的普通图像像素就具有的东西。\n\n了解了点云之后我们来解析一下PointNet这篇论文[1]\n\n---\n\n### 简介\n不同于当时许多处理3D点云任务时，直接将3D点云转化成体素矩阵(Voxel grid)的方式，但由于3D空间不同于2D大量的空间里都是空的(zero grid)，将他们全部体素化会造成不必要的浪费。PointNet可以**直接输入点云**信息，来解决这一问题，同时避免一些转换中造成的其他问题。\n\n### 点云数据的特点\n\n**1. 无序性 （Unordered）**\n我们都知道在欧式空间的度量中点和点之间是不存在像一维二维空间中的序关系的。(可能不严谨，数学不太好，暂时就这样理解)\n对于点云数据信息，每个点**喂入的顺序不应当影响到结果**\n\n**2. 局部相关性 (Interaction among points)**\n我们知道在**空间中的点和其周边点之间的位置关系信息是有意义的**，它代表了物体的形状特征。这正是我们在2D CNN工作中卷积层所提取的东西，因而我们要保留这个特征信息。\n\n**3. 不变性 （Invariance under transformation）**\n对于点云数据应该满足一些**空间变换的不变性**，例如平移和旋转，这些都不会影响最终的结果\n\nPointNet的工作就是尝试解决这三个问题。\n\n---\n\n### 网络结构\n\n![](https://pic1.zhimg.com/80/v2-8dc76710bd09c25d5c8196d6aff56fec_1440w.jpg)\n\n我们看一下 PointNet 的网络架构，首先喂入原始的 PointNet，是一个 $N\\times 3$ 的矩阵(n个点,xyz)先通过一个 $T-Net$ 层进行对齐，然后用感知机 mlp 进行特征提取，装换到 $N\\times 1024$ 1024维空间上再进行 Max Pooling 提取出 Global feature，然后就干自己该干的事去了，对分类任务，将全局特征通过mlp来预测最后的分类分数；对分割任务，将全局特征和之前学习到的各点云的局部特征进行串联，再通过mlp得到每个数据点的分类结果。\n下文会展开更详细的讲解\n\n### 解决无序性 (symmetry function)\n\n对于无序性 PointCloud 数据的处理当时一般有三种方法，\n- 1）对数据进行排序成 canonical order. \n\n对于这种方法，其实不存在一种高维空间的排序。由于CNN中数据抽象纬度很高，要保证高维中的点向一维的稳定映射无关数据顺序是十分困难的，所以其效果有限。\n\n- 2) 用大量打乱数据序列训练一个 RNN，寄希望于这种方式能消除顺序依赖\n\n这种方法看上去可行，然而其仍然无法做到完全顺序无关，在[2]中有详细证明。实验表示，这种方法对于小型数据具有一定鲁棒性，但对于大量point的场景仍然表现疲软。\n\n**3) 通过一个简单的对称函数来处理每个点，获得每个点的 Global signature**\n\n这是本文所使用的方法，很简单却很有效，我们知道一个symmetry function 的输出是无关顺序的, 例如我们熟悉的加法和乘法，这里选用了CNN中常用的 max 函数作为 symmetry function，通过 max pooling 消除数据顺序的影响。\n\n![](https://s3.ax1x.com/2020/12/08/rpks4e.png)\n\n$f$ 这个函数输出一个数据不依赖的值作为该组数据的 *Global signature* 每一个输入值 $x_{1\\to n}$ 是PointCloud中的点，带有 (x,y,z)位置信息以及一些rgb信息，组成共 $NxN$ 的矩阵，$h$ 是一个变换方程，将 $1\\times N$的向量转换为 $1\\times K$，然后 $g$ 就是我们的 symmetry function 将 $N\\times K$ 的矩阵映射到一个值 $R$ 就能够代表这组数据，因为 symmetry function 的顺序无关性，我们能够保证这个值对于相同数据的不同排列是相同的。\n\n---\n\n### 局部和全局数据聚合 (Local and Global Information Aggregation)\n\n这边先讲一下我自己的想法，我很怀疑它到底有没有做局部信息的处理，既解决第二个问题，据PointNet这篇文章自己写的这一章，他说他做了。然后后面PointNet++ 说他没做。我这段看的也比较迷惑，但我个人倾向于原作者尝试去做但做的比较弱。\n\n### 理论证明可行性 (Theory Analysis)\n![拟合可行性](https://pic3.zhimg.com/80/v2-1bee125c29ac11faba0e0a095207a396_1440w.jpg)\n\n这个定理说我们通过之前讲的 $h$ 和 Max pooling 操作能够拟合任意的连续集合函数 $f$\n最坏的拟合就是将其转换成空间中的体素，但通常来说我们的神经网络在调校的过程中都会得到更好的 $h$ 来完成这一过程。\n\nTODO: 详细证明过程在附录中我还没看\n\n![扰动下的鲁棒性](https://pic1.zhimg.com/80/v2-43d9f406855cf5e4681cb3de08382b80_1440w.jpg)\n\n定理二告诉了我们该模型在扰动之下具有鲁棒性，只要不影响关键点集 $C_S$，或者超出最密上限点集 $N_s$ 该模型所得出的 Global signature 都是相同的，(2) 指出关键点集的上限在于我们的转换函数 $h$ 转换的维数 $K$\n\n对于定理二原论文中有直观的图解帮助大家构造 intuition\n![](https://pic2.zhimg.com/80/v2-c1fc6e865ab685dcaefd18e8c063bef1_1440w.jpg)\n\n最后的结果在当时看来是非常不错的。\n![](https://s3.ax1x.com/2020/12/08/rpk2jI.png)\n\n## 总结\n\nPointNet 开创了3D点云的新纪元，日后的PointNet++，PointCNN等网络都是在其基础上发展起来的，作为点云的奠基其用十分简单的方式解决了3D点云数据的顺序 (symmetry function) 和空间不变性 (high demension). 但它没有很好的解决 Local 数据的关系，这一问题会在PointNet++中得到解决。\n\n最后说点自己的话，感觉现在读论文并不是很静得下心来，读的也很笼统不深入，被太多乱七八糟的事情困扰心烦意乱。但事情总得做下去，状态是在做事的过程中一点点找回来的，干等等不来。注重积累一点点来，相信自己在不久的将来能够做出一点自己的东西。\n\n### Reference\n[1] PointNet论文链接：https://arxiv.org/abs/1612.00593\n[2] O. Vinyals, S. Bengio, and M. Kudlur. Order mat\u0002ters: Sequence to sequence for sets. arXiv preprint arXiv:1511.06391, 2015.\n\n","source":"_posts/Research/PointNet.md","raw":"---\ntitle: PointNet论文阅读\ndate: 2020-12-06 14:46:14\nindex_img: /img/Pic/cnn_img.jpeg\nbanner_img: /img/Pic/PointCloud.jpg\ncategory: [Research]\ntags: PointNet\nmath: true\n---\n\n### PointCloud\n\n何谓点云，点云数据和普通的照片又有什么不同？实际上点云并非什么高深的东西，下图就是一张点云的可视化数据。\n![点云街道](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1607249767189&di=e4964b8b875326b97e5ab06da6196601&imgtype=0&src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fq_70%2Cc_zoom%2Cw_640%2Fimages%2F20180118%2F537a4b5eab09459881f9bc6ca18834f9.jpeg)\n\n- **位置信息**\n不同于原先2D的图像，每个像素点仅有RGB信息，点云自带了欧式空间中的位置信息，即坐标(x,y,z) 之后会附带一些RGB灰度值之类的普通图像像素就具有的东西。\n\n了解了点云之后我们来解析一下PointNet这篇论文[1]\n\n---\n\n### 简介\n不同于当时许多处理3D点云任务时，直接将3D点云转化成体素矩阵(Voxel grid)的方式，但由于3D空间不同于2D大量的空间里都是空的(zero grid)，将他们全部体素化会造成不必要的浪费。PointNet可以**直接输入点云**信息，来解决这一问题，同时避免一些转换中造成的其他问题。\n\n### 点云数据的特点\n\n**1. 无序性 （Unordered）**\n我们都知道在欧式空间的度量中点和点之间是不存在像一维二维空间中的序关系的。(可能不严谨，数学不太好，暂时就这样理解)\n对于点云数据信息，每个点**喂入的顺序不应当影响到结果**\n\n**2. 局部相关性 (Interaction among points)**\n我们知道在**空间中的点和其周边点之间的位置关系信息是有意义的**，它代表了物体的形状特征。这正是我们在2D CNN工作中卷积层所提取的东西，因而我们要保留这个特征信息。\n\n**3. 不变性 （Invariance under transformation）**\n对于点云数据应该满足一些**空间变换的不变性**，例如平移和旋转，这些都不会影响最终的结果\n\nPointNet的工作就是尝试解决这三个问题。\n\n---\n\n### 网络结构\n\n![](https://pic1.zhimg.com/80/v2-8dc76710bd09c25d5c8196d6aff56fec_1440w.jpg)\n\n我们看一下 PointNet 的网络架构，首先喂入原始的 PointNet，是一个 $N\\times 3$ 的矩阵(n个点,xyz)先通过一个 $T-Net$ 层进行对齐，然后用感知机 mlp 进行特征提取，装换到 $N\\times 1024$ 1024维空间上再进行 Max Pooling 提取出 Global feature，然后就干自己该干的事去了，对分类任务，将全局特征通过mlp来预测最后的分类分数；对分割任务，将全局特征和之前学习到的各点云的局部特征进行串联，再通过mlp得到每个数据点的分类结果。\n下文会展开更详细的讲解\n\n### 解决无序性 (symmetry function)\n\n对于无序性 PointCloud 数据的处理当时一般有三种方法，\n- 1）对数据进行排序成 canonical order. \n\n对于这种方法，其实不存在一种高维空间的排序。由于CNN中数据抽象纬度很高，要保证高维中的点向一维的稳定映射无关数据顺序是十分困难的，所以其效果有限。\n\n- 2) 用大量打乱数据序列训练一个 RNN，寄希望于这种方式能消除顺序依赖\n\n这种方法看上去可行，然而其仍然无法做到完全顺序无关，在[2]中有详细证明。实验表示，这种方法对于小型数据具有一定鲁棒性，但对于大量point的场景仍然表现疲软。\n\n**3) 通过一个简单的对称函数来处理每个点，获得每个点的 Global signature**\n\n这是本文所使用的方法，很简单却很有效，我们知道一个symmetry function 的输出是无关顺序的, 例如我们熟悉的加法和乘法，这里选用了CNN中常用的 max 函数作为 symmetry function，通过 max pooling 消除数据顺序的影响。\n\n![](https://s3.ax1x.com/2020/12/08/rpks4e.png)\n\n$f$ 这个函数输出一个数据不依赖的值作为该组数据的 *Global signature* 每一个输入值 $x_{1\\to n}$ 是PointCloud中的点，带有 (x,y,z)位置信息以及一些rgb信息，组成共 $NxN$ 的矩阵，$h$ 是一个变换方程，将 $1\\times N$的向量转换为 $1\\times K$，然后 $g$ 就是我们的 symmetry function 将 $N\\times K$ 的矩阵映射到一个值 $R$ 就能够代表这组数据，因为 symmetry function 的顺序无关性，我们能够保证这个值对于相同数据的不同排列是相同的。\n\n---\n\n### 局部和全局数据聚合 (Local and Global Information Aggregation)\n\n这边先讲一下我自己的想法，我很怀疑它到底有没有做局部信息的处理，既解决第二个问题，据PointNet这篇文章自己写的这一章，他说他做了。然后后面PointNet++ 说他没做。我这段看的也比较迷惑，但我个人倾向于原作者尝试去做但做的比较弱。\n\n### 理论证明可行性 (Theory Analysis)\n![拟合可行性](https://pic3.zhimg.com/80/v2-1bee125c29ac11faba0e0a095207a396_1440w.jpg)\n\n这个定理说我们通过之前讲的 $h$ 和 Max pooling 操作能够拟合任意的连续集合函数 $f$\n最坏的拟合就是将其转换成空间中的体素，但通常来说我们的神经网络在调校的过程中都会得到更好的 $h$ 来完成这一过程。\n\nTODO: 详细证明过程在附录中我还没看\n\n![扰动下的鲁棒性](https://pic1.zhimg.com/80/v2-43d9f406855cf5e4681cb3de08382b80_1440w.jpg)\n\n定理二告诉了我们该模型在扰动之下具有鲁棒性，只要不影响关键点集 $C_S$，或者超出最密上限点集 $N_s$ 该模型所得出的 Global signature 都是相同的，(2) 指出关键点集的上限在于我们的转换函数 $h$ 转换的维数 $K$\n\n对于定理二原论文中有直观的图解帮助大家构造 intuition\n![](https://pic2.zhimg.com/80/v2-c1fc6e865ab685dcaefd18e8c063bef1_1440w.jpg)\n\n最后的结果在当时看来是非常不错的。\n![](https://s3.ax1x.com/2020/12/08/rpk2jI.png)\n\n## 总结\n\nPointNet 开创了3D点云的新纪元，日后的PointNet++，PointCNN等网络都是在其基础上发展起来的，作为点云的奠基其用十分简单的方式解决了3D点云数据的顺序 (symmetry function) 和空间不变性 (high demension). 但它没有很好的解决 Local 数据的关系，这一问题会在PointNet++中得到解决。\n\n最后说点自己的话，感觉现在读论文并不是很静得下心来，读的也很笼统不深入，被太多乱七八糟的事情困扰心烦意乱。但事情总得做下去，状态是在做事的过程中一点点找回来的，干等等不来。注重积累一点点来，相信自己在不久的将来能够做出一点自己的东西。\n\n### Reference\n[1] PointNet论文链接：https://arxiv.org/abs/1612.00593\n[2] O. Vinyals, S. Bengio, and M. Kudlur. Order mat\u0002ters: Sequence to sequence for sets. arXiv preprint arXiv:1511.06391, 2015.\n\n","slug":"Research/PointNet","published":1,"updated":"2026-02-03T05:42:14.452Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvl00407uit6v4i011n","content":"<h3 id=\"PointCloud\"><a href=\"#PointCloud\" class=\"headerlink\" title=\"PointCloud\"></a>PointCloud</h3><p>何谓点云，点云数据和普通的照片又有什么不同？实际上点云并非什么高深的东西，下图就是一张点云的可视化数据。<br><img src=\"https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1607249767189&amp;di=e4964b8b875326b97e5ab06da6196601&amp;imgtype=0&amp;src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fq_70%2Cc_zoom%2Cw_640%2Fimages%2F20180118%2F537a4b5eab09459881f9bc6ca18834f9.jpeg\" alt=\"点云街道\"></p>\n<ul>\n<li><strong>位置信息</strong><br>不同于原先2D的图像，每个像素点仅有RGB信息，点云自带了欧式空间中的位置信息，即坐标(x,y,z) 之后会附带一些RGB灰度值之类的普通图像像素就具有的东西。</li>\n</ul>\n<p>了解了点云之后我们来解析一下PointNet这篇论文[1]</p>\n<hr>\n<h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p>不同于当时许多处理3D点云任务时，直接将3D点云转化成体素矩阵(Voxel grid)的方式，但由于3D空间不同于2D大量的空间里都是空的(zero grid)，将他们全部体素化会造成不必要的浪费。PointNet可以<strong>直接输入点云</strong>信息，来解决这一问题，同时避免一些转换中造成的其他问题。</p>\n<h3 id=\"点云数据的特点\"><a href=\"#点云数据的特点\" class=\"headerlink\" title=\"点云数据的特点\"></a>点云数据的特点</h3><p><strong>1. 无序性 （Unordered）</strong><br>我们都知道在欧式空间的度量中点和点之间是不存在像一维二维空间中的序关系的。(可能不严谨，数学不太好，暂时就这样理解)<br>对于点云数据信息，每个点<strong>喂入的顺序不应当影响到结果</strong></p>\n<p><strong>2. 局部相关性 (Interaction among points)</strong><br>我们知道在<strong>空间中的点和其周边点之间的位置关系信息是有意义的</strong>，它代表了物体的形状特征。这正是我们在2D CNN工作中卷积层所提取的东西，因而我们要保留这个特征信息。</p>\n<p><strong>3. 不变性 （Invariance under transformation）</strong><br>对于点云数据应该满足一些<strong>空间变换的不变性</strong>，例如平移和旋转，这些都不会影响最终的结果</p>\n<p>PointNet的工作就是尝试解决这三个问题。</p>\n<hr>\n<h3 id=\"网络结构\"><a href=\"#网络结构\" class=\"headerlink\" title=\"网络结构\"></a>网络结构</h3><p><img src=\"https://pic1.zhimg.com/80/v2-8dc76710bd09c25d5c8196d6aff56fec_1440w.jpg\" alt></p>\n<p>我们看一下 PointNet 的网络架构，首先喂入原始的 PointNet，是一个 $N\\times 3$ 的矩阵(n个点,xyz)先通过一个 $T-Net$ 层进行对齐，然后用感知机 mlp 进行特征提取，装换到 $N\\times 1024$ 1024维空间上再进行 Max Pooling 提取出 Global feature，然后就干自己该干的事去了，对分类任务，将全局特征通过mlp来预测最后的分类分数；对分割任务，将全局特征和之前学习到的各点云的局部特征进行串联，再通过mlp得到每个数据点的分类结果。<br>下文会展开更详细的讲解</p>\n<h3 id=\"解决无序性-symmetry-function\"><a href=\"#解决无序性-symmetry-function\" class=\"headerlink\" title=\"解决无序性 (symmetry function)\"></a>解决无序性 (symmetry function)</h3><p>对于无序性 PointCloud 数据的处理当时一般有三种方法，</p>\n<ul>\n<li>1）对数据进行排序成 canonical order. </li>\n</ul>\n<p>对于这种方法，其实不存在一种高维空间的排序。由于CNN中数据抽象纬度很高，要保证高维中的点向一维的稳定映射无关数据顺序是十分困难的，所以其效果有限。</p>\n<ul>\n<li>2) 用大量打乱数据序列训练一个 RNN，寄希望于这种方式能消除顺序依赖</li>\n</ul>\n<p>这种方法看上去可行，然而其仍然无法做到完全顺序无关，在[2]中有详细证明。实验表示，这种方法对于小型数据具有一定鲁棒性，但对于大量point的场景仍然表现疲软。</p>\n<p><strong>3) 通过一个简单的对称函数来处理每个点，获得每个点的 Global signature</strong></p>\n<p>这是本文所使用的方法，很简单却很有效，我们知道一个symmetry function 的输出是无关顺序的, 例如我们熟悉的加法和乘法，这里选用了CNN中常用的 max 函数作为 symmetry function，通过 max pooling 消除数据顺序的影响。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/rpks4e.png\" alt></p>\n<p>$f$ 这个函数输出一个数据不依赖的值作为该组数据的 <em>Global signature</em> 每一个输入值 $x_{1\\to n}$ 是PointCloud中的点，带有 (x,y,z)位置信息以及一些rgb信息，组成共 $NxN$ 的矩阵，$h$ 是一个变换方程，将 $1\\times N$的向量转换为 $1\\times K$，然后 $g$ 就是我们的 symmetry function 将 $N\\times K$ 的矩阵映射到一个值 $R$ 就能够代表这组数据，因为 symmetry function 的顺序无关性，我们能够保证这个值对于相同数据的不同排列是相同的。</p>\n<hr>\n<h3 id=\"局部和全局数据聚合-Local-and-Global-Information-Aggregation\"><a href=\"#局部和全局数据聚合-Local-and-Global-Information-Aggregation\" class=\"headerlink\" title=\"局部和全局数据聚合 (Local and Global Information Aggregation)\"></a>局部和全局数据聚合 (Local and Global Information Aggregation)</h3><p>这边先讲一下我自己的想法，我很怀疑它到底有没有做局部信息的处理，既解决第二个问题，据PointNet这篇文章自己写的这一章，他说他做了。然后后面PointNet++ 说他没做。我这段看的也比较迷惑，但我个人倾向于原作者尝试去做但做的比较弱。</p>\n<h3 id=\"理论证明可行性-Theory-Analysis\"><a href=\"#理论证明可行性-Theory-Analysis\" class=\"headerlink\" title=\"理论证明可行性 (Theory Analysis)\"></a>理论证明可行性 (Theory Analysis)</h3><p><img src=\"https://pic3.zhimg.com/80/v2-1bee125c29ac11faba0e0a095207a396_1440w.jpg\" alt=\"拟合可行性\"></p>\n<p>这个定理说我们通过之前讲的 $h$ 和 Max pooling 操作能够拟合任意的连续集合函数 $f$<br>最坏的拟合就是将其转换成空间中的体素，但通常来说我们的神经网络在调校的过程中都会得到更好的 $h$ 来完成这一过程。</p>\n<p>TODO: 详细证明过程在附录中我还没看</p>\n<p><img src=\"https://pic1.zhimg.com/80/v2-43d9f406855cf5e4681cb3de08382b80_1440w.jpg\" alt=\"扰动下的鲁棒性\"></p>\n<p>定理二告诉了我们该模型在扰动之下具有鲁棒性，只要不影响关键点集 $C_S$，或者超出最密上限点集 $N_s$ 该模型所得出的 Global signature 都是相同的，(2) 指出关键点集的上限在于我们的转换函数 $h$ 转换的维数 $K$</p>\n<p>对于定理二原论文中有直观的图解帮助大家构造 intuition<br><img src=\"https://pic2.zhimg.com/80/v2-c1fc6e865ab685dcaefd18e8c063bef1_1440w.jpg\" alt></p>\n<p>最后的结果在当时看来是非常不错的。<br><img src=\"https://s3.ax1x.com/2020/12/08/rpk2jI.png\" alt></p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>PointNet 开创了3D点云的新纪元，日后的PointNet++，PointCNN等网络都是在其基础上发展起来的，作为点云的奠基其用十分简单的方式解决了3D点云数据的顺序 (symmetry function) 和空间不变性 (high demension). 但它没有很好的解决 Local 数据的关系，这一问题会在PointNet++中得到解决。</p>\n<p>最后说点自己的话，感觉现在读论文并不是很静得下心来，读的也很笼统不深入，被太多乱七八糟的事情困扰心烦意乱。但事情总得做下去，状态是在做事的过程中一点点找回来的，干等等不来。注重积累一点点来，相信自己在不久的将来能够做出一点自己的东西。</p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><p>[1] PointNet论文链接：<a href=\"https://arxiv.org/abs/1612.00593\">https://arxiv.org/abs/1612.00593</a><br>[2] O. Vinyals, S. Bengio, and M. Kudlur. Order mat\u0002ters: Sequence to sequence for sets. arXiv preprint arXiv:1511.06391, 2015.</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"PointCloud\"><a href=\"#PointCloud\" class=\"headerlink\" title=\"PointCloud\"></a>PointCloud</h3><p>何谓点云，点云数据和普通的照片又有什么不同？实际上点云并非什么高深的东西，下图就是一张点云的可视化数据。<br><img src=\"https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1607249767189&amp;di=e4964b8b875326b97e5ab06da6196601&amp;imgtype=0&amp;src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fq_70%2Cc_zoom%2Cw_640%2Fimages%2F20180118%2F537a4b5eab09459881f9bc6ca18834f9.jpeg\" alt=\"点云街道\"></p>\n<ul>\n<li><strong>位置信息</strong><br>不同于原先2D的图像，每个像素点仅有RGB信息，点云自带了欧式空间中的位置信息，即坐标(x,y,z) 之后会附带一些RGB灰度值之类的普通图像像素就具有的东西。</li>\n</ul>\n<p>了解了点云之后我们来解析一下PointNet这篇论文[1]</p>\n<hr>\n<h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p>不同于当时许多处理3D点云任务时，直接将3D点云转化成体素矩阵(Voxel grid)的方式，但由于3D空间不同于2D大量的空间里都是空的(zero grid)，将他们全部体素化会造成不必要的浪费。PointNet可以<strong>直接输入点云</strong>信息，来解决这一问题，同时避免一些转换中造成的其他问题。</p>\n<h3 id=\"点云数据的特点\"><a href=\"#点云数据的特点\" class=\"headerlink\" title=\"点云数据的特点\"></a>点云数据的特点</h3><p><strong>1. 无序性 （Unordered）</strong><br>我们都知道在欧式空间的度量中点和点之间是不存在像一维二维空间中的序关系的。(可能不严谨，数学不太好，暂时就这样理解)<br>对于点云数据信息，每个点<strong>喂入的顺序不应当影响到结果</strong></p>\n<p><strong>2. 局部相关性 (Interaction among points)</strong><br>我们知道在<strong>空间中的点和其周边点之间的位置关系信息是有意义的</strong>，它代表了物体的形状特征。这正是我们在2D CNN工作中卷积层所提取的东西，因而我们要保留这个特征信息。</p>\n<p><strong>3. 不变性 （Invariance under transformation）</strong><br>对于点云数据应该满足一些<strong>空间变换的不变性</strong>，例如平移和旋转，这些都不会影响最终的结果</p>\n<p>PointNet的工作就是尝试解决这三个问题。</p>\n<hr>\n<h3 id=\"网络结构\"><a href=\"#网络结构\" class=\"headerlink\" title=\"网络结构\"></a>网络结构</h3><p><img src=\"https://pic1.zhimg.com/80/v2-8dc76710bd09c25d5c8196d6aff56fec_1440w.jpg\" alt></p>\n<p>我们看一下 PointNet 的网络架构，首先喂入原始的 PointNet，是一个 $N\\times 3$ 的矩阵(n个点,xyz)先通过一个 $T-Net$ 层进行对齐，然后用感知机 mlp 进行特征提取，装换到 $N\\times 1024$ 1024维空间上再进行 Max Pooling 提取出 Global feature，然后就干自己该干的事去了，对分类任务，将全局特征通过mlp来预测最后的分类分数；对分割任务，将全局特征和之前学习到的各点云的局部特征进行串联，再通过mlp得到每个数据点的分类结果。<br>下文会展开更详细的讲解</p>\n<h3 id=\"解决无序性-symmetry-function\"><a href=\"#解决无序性-symmetry-function\" class=\"headerlink\" title=\"解决无序性 (symmetry function)\"></a>解决无序性 (symmetry function)</h3><p>对于无序性 PointCloud 数据的处理当时一般有三种方法，</p>\n<ul>\n<li>1）对数据进行排序成 canonical order. </li>\n</ul>\n<p>对于这种方法，其实不存在一种高维空间的排序。由于CNN中数据抽象纬度很高，要保证高维中的点向一维的稳定映射无关数据顺序是十分困难的，所以其效果有限。</p>\n<ul>\n<li>2) 用大量打乱数据序列训练一个 RNN，寄希望于这种方式能消除顺序依赖</li>\n</ul>\n<p>这种方法看上去可行，然而其仍然无法做到完全顺序无关，在[2]中有详细证明。实验表示，这种方法对于小型数据具有一定鲁棒性，但对于大量point的场景仍然表现疲软。</p>\n<p><strong>3) 通过一个简单的对称函数来处理每个点，获得每个点的 Global signature</strong></p>\n<p>这是本文所使用的方法，很简单却很有效，我们知道一个symmetry function 的输出是无关顺序的, 例如我们熟悉的加法和乘法，这里选用了CNN中常用的 max 函数作为 symmetry function，通过 max pooling 消除数据顺序的影响。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/rpks4e.png\" alt></p>\n<p>$f$ 这个函数输出一个数据不依赖的值作为该组数据的 <em>Global signature</em> 每一个输入值 $x_{1\\to n}$ 是PointCloud中的点，带有 (x,y,z)位置信息以及一些rgb信息，组成共 $NxN$ 的矩阵，$h$ 是一个变换方程，将 $1\\times N$的向量转换为 $1\\times K$，然后 $g$ 就是我们的 symmetry function 将 $N\\times K$ 的矩阵映射到一个值 $R$ 就能够代表这组数据，因为 symmetry function 的顺序无关性，我们能够保证这个值对于相同数据的不同排列是相同的。</p>\n<hr>\n<h3 id=\"局部和全局数据聚合-Local-and-Global-Information-Aggregation\"><a href=\"#局部和全局数据聚合-Local-and-Global-Information-Aggregation\" class=\"headerlink\" title=\"局部和全局数据聚合 (Local and Global Information Aggregation)\"></a>局部和全局数据聚合 (Local and Global Information Aggregation)</h3><p>这边先讲一下我自己的想法，我很怀疑它到底有没有做局部信息的处理，既解决第二个问题，据PointNet这篇文章自己写的这一章，他说他做了。然后后面PointNet++ 说他没做。我这段看的也比较迷惑，但我个人倾向于原作者尝试去做但做的比较弱。</p>\n<h3 id=\"理论证明可行性-Theory-Analysis\"><a href=\"#理论证明可行性-Theory-Analysis\" class=\"headerlink\" title=\"理论证明可行性 (Theory Analysis)\"></a>理论证明可行性 (Theory Analysis)</h3><p><img src=\"https://pic3.zhimg.com/80/v2-1bee125c29ac11faba0e0a095207a396_1440w.jpg\" alt=\"拟合可行性\"></p>\n<p>这个定理说我们通过之前讲的 $h$ 和 Max pooling 操作能够拟合任意的连续集合函数 $f$<br>最坏的拟合就是将其转换成空间中的体素，但通常来说我们的神经网络在调校的过程中都会得到更好的 $h$ 来完成这一过程。</p>\n<p>TODO: 详细证明过程在附录中我还没看</p>\n<p><img src=\"https://pic1.zhimg.com/80/v2-43d9f406855cf5e4681cb3de08382b80_1440w.jpg\" alt=\"扰动下的鲁棒性\"></p>\n<p>定理二告诉了我们该模型在扰动之下具有鲁棒性，只要不影响关键点集 $C_S$，或者超出最密上限点集 $N_s$ 该模型所得出的 Global signature 都是相同的，(2) 指出关键点集的上限在于我们的转换函数 $h$ 转换的维数 $K$</p>\n<p>对于定理二原论文中有直观的图解帮助大家构造 intuition<br><img src=\"https://pic2.zhimg.com/80/v2-c1fc6e865ab685dcaefd18e8c063bef1_1440w.jpg\" alt></p>\n<p>最后的结果在当时看来是非常不错的。<br><img src=\"https://s3.ax1x.com/2020/12/08/rpk2jI.png\" alt></p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>PointNet 开创了3D点云的新纪元，日后的PointNet++，PointCNN等网络都是在其基础上发展起来的，作为点云的奠基其用十分简单的方式解决了3D点云数据的顺序 (symmetry function) 和空间不变性 (high demension). 但它没有很好的解决 Local 数据的关系，这一问题会在PointNet++中得到解决。</p>\n<p>最后说点自己的话，感觉现在读论文并不是很静得下心来，读的也很笼统不深入，被太多乱七八糟的事情困扰心烦意乱。但事情总得做下去，状态是在做事的过程中一点点找回来的，干等等不来。注重积累一点点来，相信自己在不久的将来能够做出一点自己的东西。</p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><p>[1] PointNet论文链接：<a href=\"https://arxiv.org/abs/1612.00593\">https://arxiv.org/abs/1612.00593</a><br>[2] O. Vinyals, S. Bengio, and M. Kudlur. Order mat\u0002ters: Sequence to sequence for sets. arXiv preprint arXiv:1511.06391, 2015.</p>\n"},{"title":"DETR 论文阅读","date":"2021-01-22T21:47:44.000Z","index_img":"/img/AI.png","math":true,"_content":"\n# End-to-End Object Detection with Transformers\n\n*关键词： 目标检测， Transformer，End-to-End*\n\n\n\n## 简介\n\n​\tDetr 这篇文章抛弃了传统 Fast-RCNN 基于 ROI 的目标检测方式，使用了Transformer以及其提出的 bipartite matching 做到位置无关和生成唯一的目标检测框，以此省去了 Anchor 和 NMS。以非常简单的架构达到媲美甚至超越 Fast-RCNN 的准确率，在能够做目标检测的同时，该模型还有较好的迁移能力，在原论文中通过 Transformer 的 Attention 机制实现了全景分割。\n\n\n\n\n## 结构分析\n\n![网络结构图](https://tva1.sinaimg.cn/large/008eGmZEgy1gmwgc8ubqoj310s07t435.jpg)\n\n​\tDETR 的网络结构很简单，分为三个部分，第一部分是一个传统 CNN 用于提取图片特征到更高维度，第二部分一个Transformer 的 Encoder 和 Decoder 来提取 Bounding Box，最后使用 Bipartite matching loss 来训练网络。\n\n\n\n![结构细节](https://tva1.sinaimg.cn/large/008eGmZEgy1gmwghk322pj30m8069adc.jpg)\n\n​\t\t更加细致的划分可划分为 CNN backbone 部分，Transformer 中的 Encoder 和 Decoder 部分，预测前馈网络 (FFN) 部分。接下来会详细讲解。\n\n\n\n### CNN 部分\n\n​\tDETR 的第一部分用了一个 CNN backbone 将 $x_{img} \\in R^{3 \\times H_0 \\times W_0}$ (3 的 RGB 深度) 转换为 $f \\in R^{C \\times H \\times W}$ 的特征层。论文中用了 $C = 2048, H = \\frac{H_0}{32}, W = \\frac{W_0}{32}$ \n\n\n\n### Transformer 部分\n\n#### Encoder\n\n​\t先用 1x1 的卷积核将纬度从 C 降到 d，获得一个新的特征图 $R^{ d \\times H \\times W}$ 。由于 Encoder 需要一个序列，我们要将特征图拉平成为 $d \\times HW$ 的向量，输入到 encoder 中，每一个 encoder 都是同样的结构，由一个多头注意力模块和一个前馈网络（FFN）组成。不像RNN，transformer 的输入是顺序无关的，于是我们也学 NLP 对每一个注意力层加一个位置编码 （position encodings）。将状态编码和之前拉平的特征图向量相加之后喂入 encoder 中。\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwioerjhbj30ea0ghgq4.jpg\" style=\"zoom:80%;\" />\n\n#### Decoder\n\n​\tdecoder 的输入有两个，一个是 Object Queries 另一个是刚刚 Encoder 的输出，结构和传统 Transformer 差不多。比较有意思的是这个输入的 Object Queries，由于 Transformer 是 fixed size，如果我们需要 N 个 Bounding Box 那么我们就需要 N 个输入，同时这个 Object Queries 顺便充当了 decoder 的 position encodings，是通过学习得来的。\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwi2hocbcj30eh0gb421.jpg\" style=\"zoom:80%;\" />\n\n​\tencoder 的输出直接喂到的是 Encoder-Decoder Attention 层，这 N 个位置嵌入要先通过自注意力层才获得 encoder 的信息。作者将这 N 个 序列最后生成的 Bounding Box 拿出来可视化，结果非常 Amazing 啊。\n\n​\t![](https://tva1.sinaimg.cn/large/008eGmZEgy1gmwinw5iwbj30wn075ale.jpg)\n\n​\t图中的不同颜色的点代表不同大小形态的 Bounding Box，绿色代表较小的 Bounding Box，紫色代较大的 Bounding Box，红色代表大的水平的 boxes，蓝色代表大的竖直的 boxes。 对于每一个输入序列，其都有所侧重，有的侧重与左侧的小 Bounding Box 有的侧重于中间大的Bounding Box。\n\n\n\n### Bipartite matching loss\n\n​\t之前检测器往往通过anchor和groundtruth的IOU来确定正负样本，而DETR使用了bipartite matching loss 来确定正负样本。\n\n​\t![bipartite matching loss](https://tva1.sinaimg.cn/large/008eGmZEgy1gmzoqacu30j307d01waa0.jpg)\n\n​\t其中 $L_{match}$ 是 ground true 和预测 bounding boxes 之间的 pair-wise matching cost （一一配对 penalty）\n\n​\t![bipartite matching](https://tva1.sinaimg.cn/large/008eGmZEgy1gmzoq11i5jj303405hmxa.jpg) \n\n​\t通过一一配对，就不需要再采取传统的 NMS 了，因为一个bounding box 只能和一个 ground true 进行匹配，必然会引入 loss。算法实现采用的是**匈牙利算法**，这个后期我会写在博客上。\n\n\n\n### FFN\n\n​\t最后得出结果的网络，是一个三层的感知机，activation function 用的是 ReLU，以及一个线性映射层。输出的是每一个 bounding box 的中心坐标，以及它的宽高 $(x,y,w,h)$ 以及物体的分类。\n\n\n\n## 实验\n\n​\t原文在 COCO 2017 数据集上做的实验，模型虽然简单但却消耗了大量的训练时间 （Training the baseline model for 300 epochs on 16 V100 GPUs takes 3 days, with 4 images per GPU），最后效果媲美甚至超过了经过良好调教的 Fast-RCNN 类的人工 head + anchor 的模式。\n\n​\t![实验结果](https://tva1.sinaimg.cn/large/008eGmZEgy1gmzpkgtz3xj30gj06n75k.jpg) \n\n\n\n## 总结\n\n​\t这篇文章还是相当惊艳的，一直以来不管是 anchor based 还是 anchor free 的目标检测方法都难以脱离人工定义 anchor 的过程，而本篇文章通过使用 Transformer + positional encoding 达到甚至超越了传统方法的性能，里面特别是 positional encodings 的 object queries 非常耐人寻味，这些 queries 学到的真的只是 positional encoding吗？这个 queries 是否有可能是 tasks 无关的？如果是能不能通过预训练的方式来提高训练速度，这些问题都是后期值得探索的。\n\n\n\n## 参考\n\n[1] Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko: “End-to-End Object Detection with Transformers”, 2020; [arXiv:2005.12872](http://arxiv.org/abs/2005.12872)\n\n[2] 如何评价FAIR的新论文DETR？ https://www.zhihu.com/question/397692959/answer/1258046044 \n\n[3] 如何看待End-to-End Object Detection with Transformers? https://www.zhihu.com/question/397624847/answer/1250143331\n\n[4] 详解Transformer （Attention Is All You Need）https://zhuanlan.zhihu.com/p/48508221\n\n","source":"_posts/Research/DETR.md","raw":"---\ntitle: DETR 论文阅读\ndate: 2021-01-22 13:47:44\nindex_img: /img/AI.png\ncategory: [Research, Object Detection]\ntags: [Transformer]\nmath: true\n---\n\n# End-to-End Object Detection with Transformers\n\n*关键词： 目标检测， Transformer，End-to-End*\n\n\n\n## 简介\n\n​\tDetr 这篇文章抛弃了传统 Fast-RCNN 基于 ROI 的目标检测方式，使用了Transformer以及其提出的 bipartite matching 做到位置无关和生成唯一的目标检测框，以此省去了 Anchor 和 NMS。以非常简单的架构达到媲美甚至超越 Fast-RCNN 的准确率，在能够做目标检测的同时，该模型还有较好的迁移能力，在原论文中通过 Transformer 的 Attention 机制实现了全景分割。\n\n\n\n\n## 结构分析\n\n![网络结构图](https://tva1.sinaimg.cn/large/008eGmZEgy1gmwgc8ubqoj310s07t435.jpg)\n\n​\tDETR 的网络结构很简单，分为三个部分，第一部分是一个传统 CNN 用于提取图片特征到更高维度，第二部分一个Transformer 的 Encoder 和 Decoder 来提取 Bounding Box，最后使用 Bipartite matching loss 来训练网络。\n\n\n\n![结构细节](https://tva1.sinaimg.cn/large/008eGmZEgy1gmwghk322pj30m8069adc.jpg)\n\n​\t\t更加细致的划分可划分为 CNN backbone 部分，Transformer 中的 Encoder 和 Decoder 部分，预测前馈网络 (FFN) 部分。接下来会详细讲解。\n\n\n\n### CNN 部分\n\n​\tDETR 的第一部分用了一个 CNN backbone 将 $x_{img} \\in R^{3 \\times H_0 \\times W_0}$ (3 的 RGB 深度) 转换为 $f \\in R^{C \\times H \\times W}$ 的特征层。论文中用了 $C = 2048, H = \\frac{H_0}{32}, W = \\frac{W_0}{32}$ \n\n\n\n### Transformer 部分\n\n#### Encoder\n\n​\t先用 1x1 的卷积核将纬度从 C 降到 d，获得一个新的特征图 $R^{ d \\times H \\times W}$ 。由于 Encoder 需要一个序列，我们要将特征图拉平成为 $d \\times HW$ 的向量，输入到 encoder 中，每一个 encoder 都是同样的结构，由一个多头注意力模块和一个前馈网络（FFN）组成。不像RNN，transformer 的输入是顺序无关的，于是我们也学 NLP 对每一个注意力层加一个位置编码 （position encodings）。将状态编码和之前拉平的特征图向量相加之后喂入 encoder 中。\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwioerjhbj30ea0ghgq4.jpg\" style=\"zoom:80%;\" />\n\n#### Decoder\n\n​\tdecoder 的输入有两个，一个是 Object Queries 另一个是刚刚 Encoder 的输出，结构和传统 Transformer 差不多。比较有意思的是这个输入的 Object Queries，由于 Transformer 是 fixed size，如果我们需要 N 个 Bounding Box 那么我们就需要 N 个输入，同时这个 Object Queries 顺便充当了 decoder 的 position encodings，是通过学习得来的。\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwi2hocbcj30eh0gb421.jpg\" style=\"zoom:80%;\" />\n\n​\tencoder 的输出直接喂到的是 Encoder-Decoder Attention 层，这 N 个位置嵌入要先通过自注意力层才获得 encoder 的信息。作者将这 N 个 序列最后生成的 Bounding Box 拿出来可视化，结果非常 Amazing 啊。\n\n​\t![](https://tva1.sinaimg.cn/large/008eGmZEgy1gmwinw5iwbj30wn075ale.jpg)\n\n​\t图中的不同颜色的点代表不同大小形态的 Bounding Box，绿色代表较小的 Bounding Box，紫色代较大的 Bounding Box，红色代表大的水平的 boxes，蓝色代表大的竖直的 boxes。 对于每一个输入序列，其都有所侧重，有的侧重与左侧的小 Bounding Box 有的侧重于中间大的Bounding Box。\n\n\n\n### Bipartite matching loss\n\n​\t之前检测器往往通过anchor和groundtruth的IOU来确定正负样本，而DETR使用了bipartite matching loss 来确定正负样本。\n\n​\t![bipartite matching loss](https://tva1.sinaimg.cn/large/008eGmZEgy1gmzoqacu30j307d01waa0.jpg)\n\n​\t其中 $L_{match}$ 是 ground true 和预测 bounding boxes 之间的 pair-wise matching cost （一一配对 penalty）\n\n​\t![bipartite matching](https://tva1.sinaimg.cn/large/008eGmZEgy1gmzoq11i5jj303405hmxa.jpg) \n\n​\t通过一一配对，就不需要再采取传统的 NMS 了，因为一个bounding box 只能和一个 ground true 进行匹配，必然会引入 loss。算法实现采用的是**匈牙利算法**，这个后期我会写在博客上。\n\n\n\n### FFN\n\n​\t最后得出结果的网络，是一个三层的感知机，activation function 用的是 ReLU，以及一个线性映射层。输出的是每一个 bounding box 的中心坐标，以及它的宽高 $(x,y,w,h)$ 以及物体的分类。\n\n\n\n## 实验\n\n​\t原文在 COCO 2017 数据集上做的实验，模型虽然简单但却消耗了大量的训练时间 （Training the baseline model for 300 epochs on 16 V100 GPUs takes 3 days, with 4 images per GPU），最后效果媲美甚至超过了经过良好调教的 Fast-RCNN 类的人工 head + anchor 的模式。\n\n​\t![实验结果](https://tva1.sinaimg.cn/large/008eGmZEgy1gmzpkgtz3xj30gj06n75k.jpg) \n\n\n\n## 总结\n\n​\t这篇文章还是相当惊艳的，一直以来不管是 anchor based 还是 anchor free 的目标检测方法都难以脱离人工定义 anchor 的过程，而本篇文章通过使用 Transformer + positional encoding 达到甚至超越了传统方法的性能，里面特别是 positional encodings 的 object queries 非常耐人寻味，这些 queries 学到的真的只是 positional encoding吗？这个 queries 是否有可能是 tasks 无关的？如果是能不能通过预训练的方式来提高训练速度，这些问题都是后期值得探索的。\n\n\n\n## 参考\n\n[1] Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko: “End-to-End Object Detection with Transformers”, 2020; [arXiv:2005.12872](http://arxiv.org/abs/2005.12872)\n\n[2] 如何评价FAIR的新论文DETR？ https://www.zhihu.com/question/397692959/answer/1258046044 \n\n[3] 如何看待End-to-End Object Detection with Transformers? https://www.zhihu.com/question/397624847/answer/1250143331\n\n[4] 详解Transformer （Attention Is All You Need）https://zhuanlan.zhihu.com/p/48508221\n\n","slug":"Research/DETR","published":1,"updated":"2026-02-03T05:42:14.450Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvl00447uit1hxodpo2","content":"<h1 id=\"End-to-End-Object-Detection-with-Transformers\"><a href=\"#End-to-End-Object-Detection-with-Transformers\" class=\"headerlink\" title=\"End-to-End Object Detection with Transformers\"></a>End-to-End Object Detection with Transformers</h1><p><em>关键词： 目标检测， Transformer，End-to-End</em></p>\n<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>​    Detr 这篇文章抛弃了传统 Fast-RCNN 基于 ROI 的目标检测方式，使用了Transformer以及其提出的 bipartite matching 做到位置无关和生成唯一的目标检测框，以此省去了 Anchor 和 NMS。以非常简单的架构达到媲美甚至超越 Fast-RCNN 的准确率，在能够做目标检测的同时，该模型还有较好的迁移能力，在原论文中通过 Transformer 的 Attention 机制实现了全景分割。</p>\n<h2 id=\"结构分析\"><a href=\"#结构分析\" class=\"headerlink\" title=\"结构分析\"></a>结构分析</h2><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwgc8ubqoj310s07t435.jpg\" alt=\"网络结构图\"></p>\n<p>​    DETR 的网络结构很简单，分为三个部分，第一部分是一个传统 CNN 用于提取图片特征到更高维度，第二部分一个Transformer 的 Encoder 和 Decoder 来提取 Bounding Box，最后使用 Bipartite matching loss 来训练网络。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwghk322pj30m8069adc.jpg\" alt=\"结构细节\"></p>\n<p>​        更加细致的划分可划分为 CNN backbone 部分，Transformer 中的 Encoder 和 Decoder 部分，预测前馈网络 (FFN) 部分。接下来会详细讲解。</p>\n<h3 id=\"CNN-部分\"><a href=\"#CNN-部分\" class=\"headerlink\" title=\"CNN 部分\"></a>CNN 部分</h3><p>​    DETR 的第一部分用了一个 CNN backbone 将 $x_{img} \\in R^{3 \\times H_0 \\times W_0}$ (3 的 RGB 深度) 转换为 $f \\in R^{C \\times H \\times W}$ 的特征层。论文中用了 $C = 2048, H = \\frac{H_0}{32}, W = \\frac{W_0}{32}$ </p>\n<h3 id=\"Transformer-部分\"><a href=\"#Transformer-部分\" class=\"headerlink\" title=\"Transformer 部分\"></a>Transformer 部分</h3><h4 id=\"Encoder\"><a href=\"#Encoder\" class=\"headerlink\" title=\"Encoder\"></a>Encoder</h4><p>​    先用 1x1 的卷积核将纬度从 C 降到 d，获得一个新的特征图 $R^{ d \\times H \\times W}$ 。由于 Encoder 需要一个序列，我们要将特征图拉平成为 $d \\times HW$ 的向量，输入到 encoder 中，每一个 encoder 都是同样的结构，由一个多头注意力模块和一个前馈网络（FFN）组成。不像RNN，transformer 的输入是顺序无关的，于是我们也学 NLP 对每一个注意力层加一个位置编码 （position encodings）。将状态编码和之前拉平的特征图向量相加之后喂入 encoder 中。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwioerjhbj30ea0ghgq4.jpg\" style=\"zoom:80%;\"></p>\n<h4 id=\"Decoder\"><a href=\"#Decoder\" class=\"headerlink\" title=\"Decoder\"></a>Decoder</h4><p>​    decoder 的输入有两个，一个是 Object Queries 另一个是刚刚 Encoder 的输出，结构和传统 Transformer 差不多。比较有意思的是这个输入的 Object Queries，由于 Transformer 是 fixed size，如果我们需要 N 个 Bounding Box 那么我们就需要 N 个输入，同时这个 Object Queries 顺便充当了 decoder 的 position encodings，是通过学习得来的。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwi2hocbcj30eh0gb421.jpg\" style=\"zoom:80%;\"></p>\n<p>​    encoder 的输出直接喂到的是 Encoder-Decoder Attention 层，这 N 个位置嵌入要先通过自注意力层才获得 encoder 的信息。作者将这 N 个 序列最后生成的 Bounding Box 拿出来可视化，结果非常 Amazing 啊。</p>\n<p>​    <img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwinw5iwbj30wn075ale.jpg\" alt></p>\n<p>​    图中的不同颜色的点代表不同大小形态的 Bounding Box，绿色代表较小的 Bounding Box，紫色代较大的 Bounding Box，红色代表大的水平的 boxes，蓝色代表大的竖直的 boxes。 对于每一个输入序列，其都有所侧重，有的侧重与左侧的小 Bounding Box 有的侧重于中间大的Bounding Box。</p>\n<h3 id=\"Bipartite-matching-loss\"><a href=\"#Bipartite-matching-loss\" class=\"headerlink\" title=\"Bipartite matching loss\"></a>Bipartite matching loss</h3><p>​    之前检测器往往通过anchor和groundtruth的IOU来确定正负样本，而DETR使用了bipartite matching loss 来确定正负样本。</p>\n<p>​    <img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmzoqacu30j307d01waa0.jpg\" alt=\"bipartite matching loss\"></p>\n<p>​    其中 $L_{match}$ 是 ground true 和预测 bounding boxes 之间的 pair-wise matching cost （一一配对 penalty）</p>\n<p>​    <img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmzoq11i5jj303405hmxa.jpg\" alt=\"bipartite matching\"> </p>\n<p>​    通过一一配对，就不需要再采取传统的 NMS 了，因为一个bounding box 只能和一个 ground true 进行匹配，必然会引入 loss。算法实现采用的是<strong>匈牙利算法</strong>，这个后期我会写在博客上。</p>\n<h3 id=\"FFN\"><a href=\"#FFN\" class=\"headerlink\" title=\"FFN\"></a>FFN</h3><p>​    最后得出结果的网络，是一个三层的感知机，activation function 用的是 ReLU，以及一个线性映射层。输出的是每一个 bounding box 的中心坐标，以及它的宽高 $(x,y,w,h)$ 以及物体的分类。</p>\n<h2 id=\"实验\"><a href=\"#实验\" class=\"headerlink\" title=\"实验\"></a>实验</h2><p>​    原文在 COCO 2017 数据集上做的实验，模型虽然简单但却消耗了大量的训练时间 （Training the baseline model for 300 epochs on 16 V100 GPUs takes 3 days, with 4 images per GPU），最后效果媲美甚至超过了经过良好调教的 Fast-RCNN 类的人工 head + anchor 的模式。</p>\n<p>​    <img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmzpkgtz3xj30gj06n75k.jpg\" alt=\"实验结果\"> </p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>​    这篇文章还是相当惊艳的，一直以来不管是 anchor based 还是 anchor free 的目标检测方法都难以脱离人工定义 anchor 的过程，而本篇文章通过使用 Transformer + positional encoding 达到甚至超越了传统方法的性能，里面特别是 positional encodings 的 object queries 非常耐人寻味，这些 queries 学到的真的只是 positional encoding吗？这个 queries 是否有可能是 tasks 无关的？如果是能不能通过预训练的方式来提高训练速度，这些问题都是后期值得探索的。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>[1] Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko: “End-to-End Object Detection with Transformers”, 2020; <a href=\"http://arxiv.org/abs/2005.12872\">arXiv:2005.12872</a></p>\n<p>[2] 如何评价FAIR的新论文DETR？ <a href=\"https://www.zhihu.com/question/397692959/answer/1258046044\">https://www.zhihu.com/question/397692959/answer/1258046044</a> </p>\n<p>[3] 如何看待End-to-End Object Detection with Transformers? <a href=\"https://www.zhihu.com/question/397624847/answer/1250143331\">https://www.zhihu.com/question/397624847/answer/1250143331</a></p>\n<p>[4] 详解Transformer （Attention Is All You Need）<a href=\"https://zhuanlan.zhihu.com/p/48508221\">https://zhuanlan.zhihu.com/p/48508221</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"End-to-End-Object-Detection-with-Transformers\"><a href=\"#End-to-End-Object-Detection-with-Transformers\" class=\"headerlink\" title=\"End-to-End Object Detection with Transformers\"></a>End-to-End Object Detection with Transformers</h1><p><em>关键词： 目标检测， Transformer，End-to-End</em></p>\n<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>​    Detr 这篇文章抛弃了传统 Fast-RCNN 基于 ROI 的目标检测方式，使用了Transformer以及其提出的 bipartite matching 做到位置无关和生成唯一的目标检测框，以此省去了 Anchor 和 NMS。以非常简单的架构达到媲美甚至超越 Fast-RCNN 的准确率，在能够做目标检测的同时，该模型还有较好的迁移能力，在原论文中通过 Transformer 的 Attention 机制实现了全景分割。</p>\n<h2 id=\"结构分析\"><a href=\"#结构分析\" class=\"headerlink\" title=\"结构分析\"></a>结构分析</h2><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwgc8ubqoj310s07t435.jpg\" alt=\"网络结构图\"></p>\n<p>​    DETR 的网络结构很简单，分为三个部分，第一部分是一个传统 CNN 用于提取图片特征到更高维度，第二部分一个Transformer 的 Encoder 和 Decoder 来提取 Bounding Box，最后使用 Bipartite matching loss 来训练网络。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwghk322pj30m8069adc.jpg\" alt=\"结构细节\"></p>\n<p>​        更加细致的划分可划分为 CNN backbone 部分，Transformer 中的 Encoder 和 Decoder 部分，预测前馈网络 (FFN) 部分。接下来会详细讲解。</p>\n<h3 id=\"CNN-部分\"><a href=\"#CNN-部分\" class=\"headerlink\" title=\"CNN 部分\"></a>CNN 部分</h3><p>​    DETR 的第一部分用了一个 CNN backbone 将 $x_{img} \\in R^{3 \\times H_0 \\times W_0}$ (3 的 RGB 深度) 转换为 $f \\in R^{C \\times H \\times W}$ 的特征层。论文中用了 $C = 2048, H = \\frac{H_0}{32}, W = \\frac{W_0}{32}$ </p>\n<h3 id=\"Transformer-部分\"><a href=\"#Transformer-部分\" class=\"headerlink\" title=\"Transformer 部分\"></a>Transformer 部分</h3><h4 id=\"Encoder\"><a href=\"#Encoder\" class=\"headerlink\" title=\"Encoder\"></a>Encoder</h4><p>​    先用 1x1 的卷积核将纬度从 C 降到 d，获得一个新的特征图 $R^{ d \\times H \\times W}$ 。由于 Encoder 需要一个序列，我们要将特征图拉平成为 $d \\times HW$ 的向量，输入到 encoder 中，每一个 encoder 都是同样的结构，由一个多头注意力模块和一个前馈网络（FFN）组成。不像RNN，transformer 的输入是顺序无关的，于是我们也学 NLP 对每一个注意力层加一个位置编码 （position encodings）。将状态编码和之前拉平的特征图向量相加之后喂入 encoder 中。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwioerjhbj30ea0ghgq4.jpg\" style=\"zoom:80%;\"></p>\n<h4 id=\"Decoder\"><a href=\"#Decoder\" class=\"headerlink\" title=\"Decoder\"></a>Decoder</h4><p>​    decoder 的输入有两个，一个是 Object Queries 另一个是刚刚 Encoder 的输出，结构和传统 Transformer 差不多。比较有意思的是这个输入的 Object Queries，由于 Transformer 是 fixed size，如果我们需要 N 个 Bounding Box 那么我们就需要 N 个输入，同时这个 Object Queries 顺便充当了 decoder 的 position encodings，是通过学习得来的。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwi2hocbcj30eh0gb421.jpg\" style=\"zoom:80%;\"></p>\n<p>​    encoder 的输出直接喂到的是 Encoder-Decoder Attention 层，这 N 个位置嵌入要先通过自注意力层才获得 encoder 的信息。作者将这 N 个 序列最后生成的 Bounding Box 拿出来可视化，结果非常 Amazing 啊。</p>\n<p>​    <img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwinw5iwbj30wn075ale.jpg\" alt></p>\n<p>​    图中的不同颜色的点代表不同大小形态的 Bounding Box，绿色代表较小的 Bounding Box，紫色代较大的 Bounding Box，红色代表大的水平的 boxes，蓝色代表大的竖直的 boxes。 对于每一个输入序列，其都有所侧重，有的侧重与左侧的小 Bounding Box 有的侧重于中间大的Bounding Box。</p>\n<h3 id=\"Bipartite-matching-loss\"><a href=\"#Bipartite-matching-loss\" class=\"headerlink\" title=\"Bipartite matching loss\"></a>Bipartite matching loss</h3><p>​    之前检测器往往通过anchor和groundtruth的IOU来确定正负样本，而DETR使用了bipartite matching loss 来确定正负样本。</p>\n<p>​    <img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmzoqacu30j307d01waa0.jpg\" alt=\"bipartite matching loss\"></p>\n<p>​    其中 $L_{match}$ 是 ground true 和预测 bounding boxes 之间的 pair-wise matching cost （一一配对 penalty）</p>\n<p>​    <img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmzoq11i5jj303405hmxa.jpg\" alt=\"bipartite matching\"> </p>\n<p>​    通过一一配对，就不需要再采取传统的 NMS 了，因为一个bounding box 只能和一个 ground true 进行匹配，必然会引入 loss。算法实现采用的是<strong>匈牙利算法</strong>，这个后期我会写在博客上。</p>\n<h3 id=\"FFN\"><a href=\"#FFN\" class=\"headerlink\" title=\"FFN\"></a>FFN</h3><p>​    最后得出结果的网络，是一个三层的感知机，activation function 用的是 ReLU，以及一个线性映射层。输出的是每一个 bounding box 的中心坐标，以及它的宽高 $(x,y,w,h)$ 以及物体的分类。</p>\n<h2 id=\"实验\"><a href=\"#实验\" class=\"headerlink\" title=\"实验\"></a>实验</h2><p>​    原文在 COCO 2017 数据集上做的实验，模型虽然简单但却消耗了大量的训练时间 （Training the baseline model for 300 epochs on 16 V100 GPUs takes 3 days, with 4 images per GPU），最后效果媲美甚至超过了经过良好调教的 Fast-RCNN 类的人工 head + anchor 的模式。</p>\n<p>​    <img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmzpkgtz3xj30gj06n75k.jpg\" alt=\"实验结果\"> </p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>​    这篇文章还是相当惊艳的，一直以来不管是 anchor based 还是 anchor free 的目标检测方法都难以脱离人工定义 anchor 的过程，而本篇文章通过使用 Transformer + positional encoding 达到甚至超越了传统方法的性能，里面特别是 positional encodings 的 object queries 非常耐人寻味，这些 queries 学到的真的只是 positional encoding吗？这个 queries 是否有可能是 tasks 无关的？如果是能不能通过预训练的方式来提高训练速度，这些问题都是后期值得探索的。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>[1] Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko: “End-to-End Object Detection with Transformers”, 2020; <a href=\"http://arxiv.org/abs/2005.12872\">arXiv:2005.12872</a></p>\n<p>[2] 如何评价FAIR的新论文DETR？ <a href=\"https://www.zhihu.com/question/397692959/answer/1258046044\">https://www.zhihu.com/question/397692959/answer/1258046044</a> </p>\n<p>[3] 如何看待End-to-End Object Detection with Transformers? <a href=\"https://www.zhihu.com/question/397624847/answer/1250143331\">https://www.zhihu.com/question/397624847/answer/1250143331</a></p>\n<p>[4] 详解Transformer （Attention Is All You Need）<a href=\"https://zhuanlan.zhihu.com/p/48508221\">https://zhuanlan.zhihu.com/p/48508221</a></p>\n"},{"title":"PointNet++论文阅读","date":"2020-12-08T22:36:58.000Z","index_img":"/img/Pic/cnn_img.jpeg","banner_img":"/img/Pic/PointCloud.jpg","math":true,"_content":"# PointNet++\n\n## 综述\n\n回顾一下 PointNet ，我们说PointNet解决了 PointCloud 输入的顺序无关问题，但其有一个缺点就是无法获取局部特征，即没有很好的处理 local information，使其在复杂场景下表现乏力。PointNet++正是针对PointNet这一弱点进行改进。\n\n- 主要改进方式\n\n1. 受到 CNN 神经元感受野不断扩大的启发，利用空间距离，使 PointNet对点集局部区域进行特征迭代提取。\n\n2. 使用最远点提取方式，能够实现较为均匀的点采样\n\n## 关键问题\n\n一、如何做点集划分 (怎么划分空间)\n\n二、如何利用特征提取器提取局部特征信息 (怎么提取特征)\n\n这两个问题是相关的，如果和 CNN 做一个类比，在CNN中卷积核是基本的特征提取器，每个卷积核对应一个 n*n 的像素区域，在PointCloud中同样要找到结构相同的子区域和对应的特征提取器。\n\n那么在 PointNet++ 中作者使用欧式空间中的邻接球作为子区域做点集的 Partition 使用 PointNet 作为特征提取器。\n\n## 网络结构\n![](https://pic1.zhimg.com/80/v2-f3f9a70d0052be1949a18c6e556572b8_1440w.jpg)\n\n主要包括三部分\n### Sample layer\n主要对输入点进行采样，使用最远点采样法，选择$N$个点，能够更均匀的覆盖整个点集。\n![](https://img-blog.csdnimg.cn/20200923132734170.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FUVkxD,size_16,color_FFFFFF,t_70#pic_center)\n\n### Grouping layer\n确定点的局部划分，即确定邻接球的半径和内部的点的数量。\n一种是 ball query 看半径，还有就是用 KNN 看内部点的数量\n\n### PointNet layer\n通过 PointNet 进行特征提取，假设每个 Group 中有 $n$ 个点，那么通过 PointNet 将 $n\\times 3$ 的矩阵转换成 $n\\times K$ 的矩阵。迭代进行操作，感受野逐渐扩大，维数逐渐提升。\n\n## 不均匀点云数据\n\n我们知道点云数据不像图片中的信息是紧密连接的，空间中的点有稀疏和稠密之分。这时候如果平均采样那么会在空间中点稀疏的地方造成浪费，在点密集的地方却不足以提取到足够的信息。为此 PointNet++ 作者提出了两种方式来保证更加优化的特征提取。\n\n![](https://pic1.zhimg.com/80/v2-5389688194b56daf0311e926360f8e6c_1440w.jpg)\n\n### 多尺度组合 (multi-scale grouping, MSG)\n\n对于同一个点多次采用不同的Grouping，过PointNet之后将特征 concat，增加了很多计算量，耗时。\n\n### 多分辨率组合（multi-resolution grouping, MRG）\n\n相当于多层之间采用了不同的分辨率，先用小的grouping通过两层正常提取出的特征，和一次大的grouping提取出的特征进行一个concat，组合了两种分辨率的信息。\n\n---\n\n## 实验效果\n\n![](https://s3.ax1x.com/2020/12/08/rpkt39.png)\n\n从实验效果上我们可以看出其准确率明显好于单一的PointNet，并且在使用了 MSG 和 MRG 后对于大量点集的鲁棒性明显提升了。\n\n","source":"_posts/Research/PointNetpp.md","raw":"---\ntitle: PointNet++论文阅读\ndate: 2020-12-08 14:36:58\nindex_img: /img/Pic/cnn_img.jpeg\nbanner_img: /img/Pic/PointCloud.jpg\ncategory: [Research]\ntags: PointNet\nmath: true\n---\n# PointNet++\n\n## 综述\n\n回顾一下 PointNet ，我们说PointNet解决了 PointCloud 输入的顺序无关问题，但其有一个缺点就是无法获取局部特征，即没有很好的处理 local information，使其在复杂场景下表现乏力。PointNet++正是针对PointNet这一弱点进行改进。\n\n- 主要改进方式\n\n1. 受到 CNN 神经元感受野不断扩大的启发，利用空间距离，使 PointNet对点集局部区域进行特征迭代提取。\n\n2. 使用最远点提取方式，能够实现较为均匀的点采样\n\n## 关键问题\n\n一、如何做点集划分 (怎么划分空间)\n\n二、如何利用特征提取器提取局部特征信息 (怎么提取特征)\n\n这两个问题是相关的，如果和 CNN 做一个类比，在CNN中卷积核是基本的特征提取器，每个卷积核对应一个 n*n 的像素区域，在PointCloud中同样要找到结构相同的子区域和对应的特征提取器。\n\n那么在 PointNet++ 中作者使用欧式空间中的邻接球作为子区域做点集的 Partition 使用 PointNet 作为特征提取器。\n\n## 网络结构\n![](https://pic1.zhimg.com/80/v2-f3f9a70d0052be1949a18c6e556572b8_1440w.jpg)\n\n主要包括三部分\n### Sample layer\n主要对输入点进行采样，使用最远点采样法，选择$N$个点，能够更均匀的覆盖整个点集。\n![](https://img-blog.csdnimg.cn/20200923132734170.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FUVkxD,size_16,color_FFFFFF,t_70#pic_center)\n\n### Grouping layer\n确定点的局部划分，即确定邻接球的半径和内部的点的数量。\n一种是 ball query 看半径，还有就是用 KNN 看内部点的数量\n\n### PointNet layer\n通过 PointNet 进行特征提取，假设每个 Group 中有 $n$ 个点，那么通过 PointNet 将 $n\\times 3$ 的矩阵转换成 $n\\times K$ 的矩阵。迭代进行操作，感受野逐渐扩大，维数逐渐提升。\n\n## 不均匀点云数据\n\n我们知道点云数据不像图片中的信息是紧密连接的，空间中的点有稀疏和稠密之分。这时候如果平均采样那么会在空间中点稀疏的地方造成浪费，在点密集的地方却不足以提取到足够的信息。为此 PointNet++ 作者提出了两种方式来保证更加优化的特征提取。\n\n![](https://pic1.zhimg.com/80/v2-5389688194b56daf0311e926360f8e6c_1440w.jpg)\n\n### 多尺度组合 (multi-scale grouping, MSG)\n\n对于同一个点多次采用不同的Grouping，过PointNet之后将特征 concat，增加了很多计算量，耗时。\n\n### 多分辨率组合（multi-resolution grouping, MRG）\n\n相当于多层之间采用了不同的分辨率，先用小的grouping通过两层正常提取出的特征，和一次大的grouping提取出的特征进行一个concat，组合了两种分辨率的信息。\n\n---\n\n## 实验效果\n\n![](https://s3.ax1x.com/2020/12/08/rpkt39.png)\n\n从实验效果上我们可以看出其准确率明显好于单一的PointNet，并且在使用了 MSG 和 MRG 后对于大量点集的鲁棒性明显提升了。\n\n","slug":"Research/PointNetpp","published":1,"updated":"2026-02-03T05:42:14.452Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cml66bzvl00467uitc5tcaxro","content":"<h1 id=\"PointNet\"><a href=\"#PointNet\" class=\"headerlink\" title=\"PointNet++\"></a>PointNet++</h1><h2 id=\"综述\"><a href=\"#综述\" class=\"headerlink\" title=\"综述\"></a>综述</h2><p>回顾一下 PointNet ，我们说PointNet解决了 PointCloud 输入的顺序无关问题，但其有一个缺点就是无法获取局部特征，即没有很好的处理 local information，使其在复杂场景下表现乏力。PointNet++正是针对PointNet这一弱点进行改进。</p>\n<ul>\n<li>主要改进方式</li>\n</ul>\n<ol>\n<li><p>受到 CNN 神经元感受野不断扩大的启发，利用空间距离，使 PointNet对点集局部区域进行特征迭代提取。</p>\n</li>\n<li><p>使用最远点提取方式，能够实现较为均匀的点采样</p>\n</li>\n</ol>\n<h2 id=\"关键问题\"><a href=\"#关键问题\" class=\"headerlink\" title=\"关键问题\"></a>关键问题</h2><p>一、如何做点集划分 (怎么划分空间)</p>\n<p>二、如何利用特征提取器提取局部特征信息 (怎么提取特征)</p>\n<p>这两个问题是相关的，如果和 CNN 做一个类比，在CNN中卷积核是基本的特征提取器，每个卷积核对应一个 n*n 的像素区域，在PointCloud中同样要找到结构相同的子区域和对应的特征提取器。</p>\n<p>那么在 PointNet++ 中作者使用欧式空间中的邻接球作为子区域做点集的 Partition 使用 PointNet 作为特征提取器。</p>\n<h2 id=\"网络结构\"><a href=\"#网络结构\" class=\"headerlink\" title=\"网络结构\"></a>网络结构</h2><p><img src=\"https://pic1.zhimg.com/80/v2-f3f9a70d0052be1949a18c6e556572b8_1440w.jpg\" alt></p>\n<p>主要包括三部分</p>\n<h3 id=\"Sample-layer\"><a href=\"#Sample-layer\" class=\"headerlink\" title=\"Sample layer\"></a>Sample layer</h3><p>主要对输入点进行采样，使用最远点采样法，选择$N$个点，能够更均匀的覆盖整个点集。<br><img src=\"https://img-blog.csdnimg.cn/20200923132734170.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FUVkxD,size_16,color_FFFFFF,t_70#pic_center\" alt></p>\n<h3 id=\"Grouping-layer\"><a href=\"#Grouping-layer\" class=\"headerlink\" title=\"Grouping layer\"></a>Grouping layer</h3><p>确定点的局部划分，即确定邻接球的半径和内部的点的数量。<br>一种是 ball query 看半径，还有就是用 KNN 看内部点的数量</p>\n<h3 id=\"PointNet-layer\"><a href=\"#PointNet-layer\" class=\"headerlink\" title=\"PointNet layer\"></a>PointNet layer</h3><p>通过 PointNet 进行特征提取，假设每个 Group 中有 $n$ 个点，那么通过 PointNet 将 $n\\times 3$ 的矩阵转换成 $n\\times K$ 的矩阵。迭代进行操作，感受野逐渐扩大，维数逐渐提升。</p>\n<h2 id=\"不均匀点云数据\"><a href=\"#不均匀点云数据\" class=\"headerlink\" title=\"不均匀点云数据\"></a>不均匀点云数据</h2><p>我们知道点云数据不像图片中的信息是紧密连接的，空间中的点有稀疏和稠密之分。这时候如果平均采样那么会在空间中点稀疏的地方造成浪费，在点密集的地方却不足以提取到足够的信息。为此 PointNet++ 作者提出了两种方式来保证更加优化的特征提取。</p>\n<p><img src=\"https://pic1.zhimg.com/80/v2-5389688194b56daf0311e926360f8e6c_1440w.jpg\" alt></p>\n<h3 id=\"多尺度组合-multi-scale-grouping-MSG\"><a href=\"#多尺度组合-multi-scale-grouping-MSG\" class=\"headerlink\" title=\"多尺度组合 (multi-scale grouping, MSG)\"></a>多尺度组合 (multi-scale grouping, MSG)</h3><p>对于同一个点多次采用不同的Grouping，过PointNet之后将特征 concat，增加了很多计算量，耗时。</p>\n<h3 id=\"多分辨率组合（multi-resolution-grouping-MRG）\"><a href=\"#多分辨率组合（multi-resolution-grouping-MRG）\" class=\"headerlink\" title=\"多分辨率组合（multi-resolution grouping, MRG）\"></a>多分辨率组合（multi-resolution grouping, MRG）</h3><p>相当于多层之间采用了不同的分辨率，先用小的grouping通过两层正常提取出的特征，和一次大的grouping提取出的特征进行一个concat，组合了两种分辨率的信息。</p>\n<hr>\n<h2 id=\"实验效果\"><a href=\"#实验效果\" class=\"headerlink\" title=\"实验效果\"></a>实验效果</h2><p><img src=\"https://s3.ax1x.com/2020/12/08/rpkt39.png\" alt></p>\n<p>从实验效果上我们可以看出其准确率明显好于单一的PointNet，并且在使用了 MSG 和 MRG 后对于大量点集的鲁棒性明显提升了。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"PointNet\"><a href=\"#PointNet\" class=\"headerlink\" title=\"PointNet++\"></a>PointNet++</h1><h2 id=\"综述\"><a href=\"#综述\" class=\"headerlink\" title=\"综述\"></a>综述</h2><p>回顾一下 PointNet ，我们说PointNet解决了 PointCloud 输入的顺序无关问题，但其有一个缺点就是无法获取局部特征，即没有很好的处理 local information，使其在复杂场景下表现乏力。PointNet++正是针对PointNet这一弱点进行改进。</p>\n<ul>\n<li>主要改进方式</li>\n</ul>\n<ol>\n<li><p>受到 CNN 神经元感受野不断扩大的启发，利用空间距离，使 PointNet对点集局部区域进行特征迭代提取。</p>\n</li>\n<li><p>使用最远点提取方式，能够实现较为均匀的点采样</p>\n</li>\n</ol>\n<h2 id=\"关键问题\"><a href=\"#关键问题\" class=\"headerlink\" title=\"关键问题\"></a>关键问题</h2><p>一、如何做点集划分 (怎么划分空间)</p>\n<p>二、如何利用特征提取器提取局部特征信息 (怎么提取特征)</p>\n<p>这两个问题是相关的，如果和 CNN 做一个类比，在CNN中卷积核是基本的特征提取器，每个卷积核对应一个 n*n 的像素区域，在PointCloud中同样要找到结构相同的子区域和对应的特征提取器。</p>\n<p>那么在 PointNet++ 中作者使用欧式空间中的邻接球作为子区域做点集的 Partition 使用 PointNet 作为特征提取器。</p>\n<h2 id=\"网络结构\"><a href=\"#网络结构\" class=\"headerlink\" title=\"网络结构\"></a>网络结构</h2><p><img src=\"https://pic1.zhimg.com/80/v2-f3f9a70d0052be1949a18c6e556572b8_1440w.jpg\" alt></p>\n<p>主要包括三部分</p>\n<h3 id=\"Sample-layer\"><a href=\"#Sample-layer\" class=\"headerlink\" title=\"Sample layer\"></a>Sample layer</h3><p>主要对输入点进行采样，使用最远点采样法，选择$N$个点，能够更均匀的覆盖整个点集。<br><img src=\"https://img-blog.csdnimg.cn/20200923132734170.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FUVkxD,size_16,color_FFFFFF,t_70#pic_center\" alt></p>\n<h3 id=\"Grouping-layer\"><a href=\"#Grouping-layer\" class=\"headerlink\" title=\"Grouping layer\"></a>Grouping layer</h3><p>确定点的局部划分，即确定邻接球的半径和内部的点的数量。<br>一种是 ball query 看半径，还有就是用 KNN 看内部点的数量</p>\n<h3 id=\"PointNet-layer\"><a href=\"#PointNet-layer\" class=\"headerlink\" title=\"PointNet layer\"></a>PointNet layer</h3><p>通过 PointNet 进行特征提取，假设每个 Group 中有 $n$ 个点，那么通过 PointNet 将 $n\\times 3$ 的矩阵转换成 $n\\times K$ 的矩阵。迭代进行操作，感受野逐渐扩大，维数逐渐提升。</p>\n<h2 id=\"不均匀点云数据\"><a href=\"#不均匀点云数据\" class=\"headerlink\" title=\"不均匀点云数据\"></a>不均匀点云数据</h2><p>我们知道点云数据不像图片中的信息是紧密连接的，空间中的点有稀疏和稠密之分。这时候如果平均采样那么会在空间中点稀疏的地方造成浪费，在点密集的地方却不足以提取到足够的信息。为此 PointNet++ 作者提出了两种方式来保证更加优化的特征提取。</p>\n<p><img src=\"https://pic1.zhimg.com/80/v2-5389688194b56daf0311e926360f8e6c_1440w.jpg\" alt></p>\n<h3 id=\"多尺度组合-multi-scale-grouping-MSG\"><a href=\"#多尺度组合-multi-scale-grouping-MSG\" class=\"headerlink\" title=\"多尺度组合 (multi-scale grouping, MSG)\"></a>多尺度组合 (multi-scale grouping, MSG)</h3><p>对于同一个点多次采用不同的Grouping，过PointNet之后将特征 concat，增加了很多计算量，耗时。</p>\n<h3 id=\"多分辨率组合（multi-resolution-grouping-MRG）\"><a href=\"#多分辨率组合（multi-resolution-grouping-MRG）\" class=\"headerlink\" title=\"多分辨率组合（multi-resolution grouping, MRG）\"></a>多分辨率组合（multi-resolution grouping, MRG）</h3><p>相当于多层之间采用了不同的分辨率，先用小的grouping通过两层正常提取出的特征，和一次大的grouping提取出的特征进行一个concat，组合了两种分辨率的信息。</p>\n<hr>\n<h2 id=\"实验效果\"><a href=\"#实验效果\" class=\"headerlink\" title=\"实验效果\"></a>实验效果</h2><p><img src=\"https://s3.ax1x.com/2020/12/08/rpkt39.png\" alt></p>\n<p>从实验效果上我们可以看出其准确率明显好于单一的PointNet，并且在使用了 MSG 和 MRG 后对于大量点集的鲁棒性明显提升了。</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cml66bzv500017uit6sca04t2","category_id":"cml66bzv700047uitdnxhgskk","_id":"cml66bzv9000e7uit939o3agj"},{"post_id":"cml66bzv600037uit2k4nawcv","category_id":"cml66bzv800097uit3jav6ejx","_id":"cml66bzva000k7uitcwg1ak4e"},{"post_id":"cml66bzva000h7uit04x2gt25","category_id":"cml66bzv9000f7uit4lt7a9dp","_id":"cml66bzvb000p7uitgv3ah3ep"},{"post_id":"cml66bzv800077uit94dz19kn","category_id":"cml66bzv9000f7uit4lt7a9dp","_id":"cml66bzvb000t7uit54o3a3rg"},{"post_id":"cml66bzva000j7uithr2525yo","category_id":"cml66bzv9000f7uit4lt7a9dp","_id":"cml66bzvc000w7uit62il97zq"},{"post_id":"cml66bzva000n7uitbn439co0","category_id":"cml66bzv9000f7uit4lt7a9dp","_id":"cml66bzvc00107uit0vsc8qu3"},{"post_id":"cml66bzv800087uitdqy407ot","category_id":"cml66bzva000l7uit3uf8b46y","_id":"cml66bzvc00137uitfmej1vfp"},{"post_id":"cml66bzv9000c7uitgr7m7qb2","category_id":"cml66bzv9000f7uit4lt7a9dp","_id":"cml66bzvd00167uit8ka63nk5"},{"post_id":"cml66bzvc000z7uit8vmm8lia","category_id":"cml66bzva000l7uit3uf8b46y","_id":"cml66bzvd00197uit7mkd53qs"},{"post_id":"cml66bzv9000d7uit3xkg1efx","category_id":"cml66bzv9000f7uit4lt7a9dp","_id":"cml66bzvd001b7uitcn8rge2k"},{"post_id":"cml66bzvc00127uit2v5g1f67","category_id":"cml66bzva000l7uit3uf8b46y","_id":"cml66bzvd001f7uit6rmwgll0"},{"post_id":"cml66bzvc00157uit9ve380o3","category_id":"cml66bzva000l7uit3uf8b46y","_id":"cml66bzvd001h7uit95r0dh1u"},{"post_id":"cml66bzvb000o7uit0oma3jpj","category_id":"cml66bzvc00147uit2rsdhpmh","_id":"cml66bzvd001k7uit54pwe87c"},{"post_id":"cml66bzvb000s7uithljbh5v1","category_id":"cml66bzvc00147uit2rsdhpmh","_id":"cml66bzvd001l7uit6djra3wj"},{"post_id":"cml66bzvb000v7uitair9h926","category_id":"cml66bzvd001i7uit2iy7c2l7","_id":"cml66bzve001p7uitgoevcrio"},{"post_id":"cml66bzvd00187uit3y0ta414","category_id":"cml66bzvd001i7uit2iy7c2l7","_id":"cml66bzve001s7uitbffzebc6"},{"post_id":"cml66bzvg002v7uith4qta0c1","category_id":"cml66bzva000l7uit3uf8b46y","_id":"cml66bzvi00307uitbfpi9iz7"},{"post_id":"cml66bzvh002w7uit397285mq","category_id":"cml66bzva000l7uit3uf8b46y","_id":"cml66bzvi00327uit02iodrv7"},{"post_id":"cml66bzvh002y7uit08f05aa8","category_id":"cml66bzva000l7uit3uf8b46y","_id":"cml66bzvi00367uit843638gc"},{"post_id":"cml66bzvh002z7uith8mu3usp","category_id":"cml66bzva000l7uit3uf8b46y","_id":"cml66bzvi00397uithok73unj"},{"post_id":"cml66bzvi00317uitff3qc72p","category_id":"cml66bzva000l7uit3uf8b46y","_id":"cml66bzvj003e7uit2ozs7da1"},{"post_id":"cml66bzvj003g7uit6a8aaq1d","category_id":"cml66bzvi003b7uit8cee60z1","_id":"cml66bzvk003o7uithewp5xe7"},{"post_id":"cml66bzvi00357uitbe5k5e6e","category_id":"cml66bzvi003b7uit8cee60z1","_id":"cml66bzvk003s7uitb7s62vmw"},{"post_id":"cml66bzvj003i7uit9llo8yb2","category_id":"cml66bzvi003b7uit8cee60z1","_id":"cml66bzvk003u7uitgtym6bvr"},{"post_id":"cml66bzvj003l7uit0yzu7zv6","category_id":"cml66bzvi003b7uit8cee60z1","_id":"cml66bzvk003z7uit1kl4dfow"},{"post_id":"cml66bzvi00387uit5f2n2noa","category_id":"cml66bzvj003j7uit5cd15rzs","_id":"cml66bzvl00417uit0g76ds8m"},{"post_id":"cml66bzvk003r7uitb3hzb3ax","category_id":"cml66bzvi003b7uit8cee60z1","_id":"cml66bzvl00457uit9ppef30z"},{"post_id":"cml66bzvj003d7uit28hsb678","category_id":"cml66bzvi003b7uit8cee60z1","_id":"cml66bzvl00477uitg3li7bug"},{"post_id":"cml66bzvk003y7uithhgh2qtc","category_id":"cml66bzvk003w7uit5b3hc53b","_id":"cml66bzvl004a7uit6xowfdcs"},{"post_id":"cml66bzvl00407uit6v4i011n","category_id":"cml66bzvk003w7uit5b3hc53b","_id":"cml66bzvl004c7uit2slgcelw"},{"post_id":"cml66bzvk003t7uitbzrr3jao","category_id":"cml66bzvl00437uit5lpc6myt","_id":"cml66bzvl004f7uite73h878u"},{"post_id":"cml66bzvl00467uitc5tcaxro","category_id":"cml66bzvk003w7uit5b3hc53b","_id":"cml66bzvl004i7uiteaw9gkl5"},{"post_id":"cml66bzvj003n7uit68fc4ywh","category_id":"cml66bzvk003w7uit5b3hc53b","_id":"cml66bzvm004k7uit3hyk3wbj"},{"post_id":"cml66bzvj003n7uit68fc4ywh","category_id":"cml66bzvl00497uitbfa4e6nn","_id":"cml66bzvm004l7uitdevf0fwa"},{"post_id":"cml66bzvl00447uit1hxodpo2","category_id":"cml66bzvk003w7uit5b3hc53b","_id":"cml66bzvm004m7uitfhw4fc3w"},{"post_id":"cml66bzvl00447uit1hxodpo2","category_id":"cml66bzvl00497uitbfa4e6nn","_id":"cml66bzvm004p7uitgi5k6xnl"}],"PostTag":[{"post_id":"cml66bzv500017uit6sca04t2","tag_id":"cml66bzv700057uit6pttgmpy","_id":"cml66bzv8000b7uit2837bqi4"},{"post_id":"cml66bzv600037uit2k4nawcv","tag_id":"cml66bzv8000a7uit5frq7ulz","_id":"cml66bzva000i7uitb27ug1z4"},{"post_id":"cml66bzv700067uithczyfwwo","tag_id":"cml66bzv9000g7uitdvb6478q","_id":"cml66bzvb000u7uitfjiogksr"},{"post_id":"cml66bzv700067uithczyfwwo","tag_id":"cml66bzva000m7uit4h9acdgo","_id":"cml66bzvc000x7uit1iioejbs"},{"post_id":"cml66bzv800077uit94dz19kn","tag_id":"cml66bzvb000r7uit9pwedxqi","_id":"cml66bzvd001a7uit2yni3ohj"},{"post_id":"cml66bzv800077uit94dz19kn","tag_id":"cml66bzvc00117uit2iu0esui","_id":"cml66bzvd001d7uitaaty2x84"},{"post_id":"cml66bzv800087uitdqy407ot","tag_id":"cml66bzvd00177uit522ka9nc","_id":"cml66bzvd001g7uit0ug4615c"},{"post_id":"cml66bzv9000c7uitgr7m7qb2","tag_id":"cml66bzvb000r7uit9pwedxqi","_id":"cml66bzve001o7uitgo5u0fla"},{"post_id":"cml66bzv9000c7uitgr7m7qb2","tag_id":"cml66bzvc00117uit2iu0esui","_id":"cml66bzve001q7uit7g8h7jm3"},{"post_id":"cml66bzv9000d7uit3xkg1efx","tag_id":"cml66bzvb000r7uit9pwedxqi","_id":"cml66bzve001u7uit725s517w"},{"post_id":"cml66bzv9000d7uit3xkg1efx","tag_id":"cml66bzvc00117uit2iu0esui","_id":"cml66bzve001v7uitcr0308ds"},{"post_id":"cml66bzva000h7uit04x2gt25","tag_id":"cml66bzvb000r7uit9pwedxqi","_id":"cml66bzve001y7uith2qpgtuz"},{"post_id":"cml66bzva000h7uit04x2gt25","tag_id":"cml66bzvc00117uit2iu0esui","_id":"cml66bzve001z7uitbuzz5j3c"},{"post_id":"cml66bzva000j7uithr2525yo","tag_id":"cml66bzvb000r7uit9pwedxqi","_id":"cml66bzve00227uit6mqkcadj"},{"post_id":"cml66bzva000j7uithr2525yo","tag_id":"cml66bzvc00117uit2iu0esui","_id":"cml66bzve00237uitaw1d0yj6"},{"post_id":"cml66bzva000n7uitbn439co0","tag_id":"cml66bzvb000r7uit9pwedxqi","_id":"cml66bzve00267uitdhd1c91z"},{"post_id":"cml66bzva000n7uitbn439co0","tag_id":"cml66bzvc00117uit2iu0esui","_id":"cml66bzve00277uitgfmvhi76"},{"post_id":"cml66bzvb000o7uit0oma3jpj","tag_id":"cml66bzve00257uit0b8uasjj","_id":"cml66bzve002a7uit7x783ghb"},{"post_id":"cml66bzvb000o7uit0oma3jpj","tag_id":"cml66bzve00287uitfr958mfa","_id":"cml66bzve002b7uitemqqgk6h"},{"post_id":"cml66bzvb000s7uithljbh5v1","tag_id":"cml66bzve00297uit8sdc96sl","_id":"cml66bzvf002e7uit2bkd54x9"},{"post_id":"cml66bzvb000s7uithljbh5v1","tag_id":"cml66bzve002c7uitcfy7hfnt","_id":"cml66bzvf002f7uitfz6w02g6"},{"post_id":"cml66bzvb000v7uitair9h926","tag_id":"cml66bzve002d7uit29qt7wu3","_id":"cml66bzvf002i7uitfuuua365"},{"post_id":"cml66bzvb000v7uitair9h926","tag_id":"cml66bzvf002g7uitetl0arhb","_id":"cml66bzvf002j7uitajdkaxcr"},{"post_id":"cml66bzvc000z7uit8vmm8lia","tag_id":"cml66bzvf002h7uit2tp68d0v","_id":"cml66bzvf002l7uit2ywk06vp"},{"post_id":"cml66bzvc00127uit2v5g1f67","tag_id":"cml66bzvf002k7uite83489l7","_id":"cml66bzvf002o7uit18434h00"},{"post_id":"cml66bzvc00127uit2v5g1f67","tag_id":"cml66bzvf002m7uit9q263fji","_id":"cml66bzvf002p7uitb1dpc510"},{"post_id":"cml66bzvc00157uit9ve380o3","tag_id":"cml66bzvf002n7uit5osx8bxw","_id":"cml66bzvf002r7uit01gz6vl4"},{"post_id":"cml66bzvd00187uit3y0ta414","tag_id":"cml66bzvf002q7uit4clb22ut","_id":"cml66bzvf002t7uitarfjc8pr"},{"post_id":"cml66bzvd00187uit3y0ta414","tag_id":"cml66bzvf002s7uitad0af1yo","_id":"cml66bzvf002u7uit58ac792y"},{"post_id":"cml66bzvg002v7uith4qta0c1","tag_id":"cml66bzvh002x7uit3ffy2uip","_id":"cml66bzvi00347uit4rdn86cv"},{"post_id":"cml66bzvi00317uitff3qc72p","tag_id":"cml66bzvf002k7uite83489l7","_id":"cml66bzvi00377uitgs9b8c39"},{"post_id":"cml66bzvi00317uitff3qc72p","tag_id":"cml66bzvf002m7uit9q263fji","_id":"cml66bzvi003c7uit5gta77yr"},{"post_id":"cml66bzvh002w7uit397285mq","tag_id":"cml66bzvi00337uitbea18guw","_id":"cml66bzvj003f7uitf4mi1tie"},{"post_id":"cml66bzvh002y7uit08f05aa8","tag_id":"cml66bzvi003a7uitgphr585p","_id":"cml66bzvj003k7uit6mrkd8ia"},{"post_id":"cml66bzvh002z7uith8mu3usp","tag_id":"cml66bzvj003h7uitawwa2xv8","_id":"cml66bzvk003q7uit0o1de1yk"},{"post_id":"cml66bzvi00357uitbe5k5e6e","tag_id":"cml66bzvj003m7uithgbzdyb0","_id":"cml66bzvk003x7uithgx7b2wi"},{"post_id":"cml66bzvi00387uit5f2n2noa","tag_id":"cml66bzvk003v7uithfwt50pe","_id":"cml66bzvl004b7uit6epl5buc"},{"post_id":"cml66bzvi00387uit5f2n2noa","tag_id":"cml66bzvl00427uithyibeigx","_id":"cml66bzvl004d7uit0jly94ie"},{"post_id":"cml66bzvj003d7uit28hsb678","tag_id":"cml66bzvj003m7uithgbzdyb0","_id":"cml66bzvl004h7uitbzog56os"},{"post_id":"cml66bzvj003g7uit6a8aaq1d","tag_id":"cml66bzvl004e7uitftr3avj0","_id":"cml66bzvm004o7uitbg805lcy"},{"post_id":"cml66bzvj003g7uit6a8aaq1d","tag_id":"cml66bzvl004j7uitdvgl20rq","_id":"cml66bzvm004q7uit2vob72ii"},{"post_id":"cml66bzvj003i7uit9llo8yb2","tag_id":"cml66bzvj003m7uithgbzdyb0","_id":"cml66bzvm004s7uit9lu2fx96"},{"post_id":"cml66bzvj003l7uit0yzu7zv6","tag_id":"cml66bzvl004e7uitftr3avj0","_id":"cml66bzvm004u7uit90r0fcie"},{"post_id":"cml66bzvj003n7uit68fc4ywh","tag_id":"cml66bzvm004t7uitbgm14k9r","_id":"cml66bzvm004w7uitfhtm9dhy"},{"post_id":"cml66bzvk003r7uitb3hzb3ax","tag_id":"cml66bzvl004e7uitftr3avj0","_id":"cml66bzvm004z7uitdrbg0pu0"},{"post_id":"cml66bzvk003r7uitb3hzb3ax","tag_id":"cml66bzvm004x7uit06y15j8z","_id":"cml66bzvm00507uitc5twbpgg"},{"post_id":"cml66bzvk003t7uitbzrr3jao","tag_id":"cml66bzvm004y7uit8ioh2b3t","_id":"cml66bzvm00547uitdadhc77o"},{"post_id":"cml66bzvk003t7uitbzrr3jao","tag_id":"cml66bzvm00517uit3d6k0ycm","_id":"cml66bzvm00557uithc0rbbnl"},{"post_id":"cml66bzvk003t7uitbzrr3jao","tag_id":"cml66bzvm00527uitd6j6cayn","_id":"cml66bzvm00577uit5osz7vbd"},{"post_id":"cml66bzvk003y7uithhgh2qtc","tag_id":"cml66bzvm00537uita9kn5g78","_id":"cml66bzvm00587uit9i0o72y1"},{"post_id":"cml66bzvl00407uit6v4i011n","tag_id":"cml66bzvm00567uit3v8cfglk","_id":"cml66bzvm005a7uit7yuh3789"},{"post_id":"cml66bzvl00447uit1hxodpo2","tag_id":"cml66bzvm00597uit1p134yhm","_id":"cml66bzvm005c7uita1zp0wuf"},{"post_id":"cml66bzvl00467uitc5tcaxro","tag_id":"cml66bzvm00567uit3v8cfglk","_id":"cml66bzvm005d7uitchtu8kka"}],"Tag":[{"name":"Summary","_id":"cml66bzv700057uit6pttgmpy"},{"name":"TODO","_id":"cml66bzv8000a7uit5frq7ulz"},{"name":"Hexo","_id":"cml66bzv9000g7uitdvb6478q"},{"name":"Fluid","_id":"cml66bzva000m7uit4h9acdgo"},{"name":"CV","_id":"cml66bzvb000r7uit9pwedxqi"},{"name":"Neural Network","_id":"cml66bzvc00117uit2iu0esui"},{"name":"Link","_id":"cml66bzvd00177uit522ka9nc"},{"name":"LCA","_id":"cml66bzve00257uit0b8uasjj"},{"name":"UFS","_id":"cml66bzve00287uitfr958mfa"},{"name":"Number theory","_id":"cml66bzve00297uit8sdc96sl"},{"name":"Multiplication algorithm","_id":"cml66bzve002c7uitcfy7hfnt"},{"name":"NER","_id":"cml66bzve002d7uit29qt7wu3"},{"name":"BIO","_id":"cml66bzvf002g7uitetl0arhb"},{"name":"Cache","_id":"cml66bzvf002h7uit2tp68d0v"},{"name":"Malloc","_id":"cml66bzvf002k7uite83489l7"},{"name":"VM","_id":"cml66bzvf002m7uit9q263fji"},{"name":"Assembly","_id":"cml66bzvf002n7uit5osx8bxw"},{"name":"SST","_id":"cml66bzvf002q7uit4clb22ut"},{"name":"Sentiment Classification","_id":"cml66bzvf002s7uitad0af1yo"},{"name":"Bits","_id":"cml66bzvh002x7uit3ffy2uip"},{"name":"Linker","_id":"cml66bzvi00337uitbea18guw"},{"name":"Sort","_id":"cml66bzvi003a7uitgphr585p"},{"name":"CPU","_id":"cml66bzvj003h7uitawwa2xv8"},{"name":"OS","_id":"cml66bzvj003m7uithgbzdyb0"},{"name":"P=NP?","_id":"cml66bzvk003v7uithfwt50pe"},{"name":"Computation Complexity","_id":"cml66bzvl00427uithyibeigx"},{"name":"kernel","_id":"cml66bzvl004e7uitftr3avj0"},{"name":"memory addressing","_id":"cml66bzvl004j7uitdvgl20rq"},{"name":"Monocular OD","_id":"cml66bzvm004t7uitbgm14k9r"},{"name":"process","_id":"cml66bzvm004x7uit06y15j8z"},{"name":"RDT","_id":"cml66bzvm004y7uit8ioh2b3t"},{"name":"GBN","_id":"cml66bzvm00517uit3d6k0ycm"},{"name":"SR","_id":"cml66bzvm00527uitd6j6cayn"},{"name":"PointCNN","_id":"cml66bzvm00537uita9kn5g78"},{"name":"PointNet","_id":"cml66bzvm00567uit3v8cfglk"},{"name":"Transformer","_id":"cml66bzvm00597uit1p134yhm"}]}}