{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"themes/fluid/source/css/gitalk.css","path":"css/gitalk.css","modified":1,"renderable":1},{"_id":"themes/fluid/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/avatar.png","path":"img/avatar.png","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg.jpg","path":"img/bg.jpg","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg_in.jpg","path":"img/bg_in.jpg","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/bg2.jpg","path":"img/bg2.jpg","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/default.png","path":"img/default.png","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/favicon.png","path":"img/favicon.png","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/loading.gif","path":"img/loading.gif","modified":1,"renderable":1},{"_id":"themes/fluid/source/img/police_beian.png","path":"img/police_beian.png","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/color-schema.js","path":"js/color-schema.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/boot.js","path":"js/boot.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/debouncer.js","path":"js/debouncer.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/duration.js","path":"js/duration.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/events.js","path":"js/events.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/lazyload.js","path":"js/lazyload.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/leancloud.js","path":"js/leancloud.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/plugins.js","path":"js/plugins.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/local-search.js","path":"js/local-search.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"themes/fluid/source/xml/local-search.xml","path":"xml/local-search.xml","modified":1,"renderable":1},{"_id":"themes/fluid/source/lib/hint/hint.min.css","path":"lib/hint/hint.min.css","modified":1,"renderable":1},{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"source/img/AI.png","path":"img/AI.png","modified":1,"renderable":0},{"_id":"source/img/TODO.png","path":"img/TODO.png","modified":1,"renderable":0},{"_id":"source/img/Cs231n/top.jpg","path":"img/Cs231n/top.jpg","modified":1,"renderable":0},{"_id":"source/img/DS/tree_差分.png","path":"img/DS/tree_差分.png","modified":1,"renderable":0},{"_id":"source/img/DS/tree_差分2.png","path":"img/DS/tree_差分2.png","modified":1,"renderable":0},{"_id":"source/img/ICS_Lab1/bits_btest.JPG","path":"img/ICS_Lab1/bits_btest.JPG","modified":1,"renderable":0},{"_id":"source/img/ICS_Lab1/bits_dlc.png","path":"img/ICS_Lab1/bits_dlc.png","modified":1,"renderable":0},{"_id":"source/img/ICS_Lab1/bits_honor_btest.JPG","path":"img/ICS_Lab1/bits_honor_btest.JPG","modified":1,"renderable":0},{"_id":"source/img/ICS_Lab1/bits_honor_dlc.png","path":"img/ICS_Lab1/bits_honor_dlc.png","modified":1,"renderable":0},{"_id":"source/img/ICS_Lab1/top.jpg","path":"img/ICS_Lab1/top.jpg","modified":1,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_016df1440f7044a54fb4ced529595b58.png","path":"img/ICS_Lab2/upload_016df1440f7044a54fb4ced529595b58.png","modified":1,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_244e1f55d2823d58f65eabab9478d7ce.png","path":"img/ICS_Lab2/upload_244e1f55d2823d58f65eabab9478d7ce.png","modified":1,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_27148224f8cf2be48266eaa52f50b2f8.png","path":"img/ICS_Lab2/upload_27148224f8cf2be48266eaa52f50b2f8.png","modified":1,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_4801c7e177c56f6e7299c273d0120988.png","path":"img/ICS_Lab2/upload_4801c7e177c56f6e7299c273d0120988.png","modified":1,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_64ed470376ec6b72dc43690bf9b4ea0e.png","path":"img/ICS_Lab2/upload_64ed470376ec6b72dc43690bf9b4ea0e.png","modified":1,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_7194e52688ff3d696a3b889e2b17d63f.png","path":"img/ICS_Lab2/upload_7194e52688ff3d696a3b889e2b17d63f.png","modified":1,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_9ea5cd30293a18357af1da93c35e0f59.png","path":"img/ICS_Lab2/upload_9ea5cd30293a18357af1da93c35e0f59.png","modified":1,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_a18a67d1b4dbfa16a7fd8800e3ee304b.png","path":"img/ICS_Lab2/upload_a18a67d1b4dbfa16a7fd8800e3ee304b.png","modified":1,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_ae5e359c30ff5ccb9292a7472c39eb19.png","path":"img/ICS_Lab2/upload_ae5e359c30ff5ccb9292a7472c39eb19.png","modified":1,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_dfddd1801cd10c701dd2753164434977.png","path":"img/ICS_Lab2/upload_dfddd1801cd10c701dd2753164434977.png","modified":1,"renderable":0},{"_id":"source/img/ICS_Lab2/upload_f2ecdd05728cbefbba59b068a29fdfdc.png","path":"img/ICS_Lab2/upload_f2ecdd05728cbefbba59b068a29fdfdc.png","modified":1,"renderable":0},{"_id":"source/img/Pic/Recent.jpeg","path":"img/Pic/Recent.jpeg","modified":1,"renderable":0},{"_id":"source/img/PointCNN/conv.png","path":"img/PointCNN/conv.png","modified":1,"renderable":0},{"_id":"source/img/Pic/PointCloud.jpg","path":"img/Pic/PointCloud.jpg","modified":1,"renderable":0},{"_id":"source/img/Pic/DS.png","path":"img/Pic/DS.png","modified":1,"renderable":0},{"_id":"source/img/PointCNN/conv2.png","path":"img/PointCNN/conv2.png","modified":1,"renderable":0},{"_id":"source/img/PointCNN/conv_a.png","path":"img/PointCNN/conv_a.png","modified":1,"renderable":0},{"_id":"source/img/Pic/cnn_img.jpeg","path":"img/Pic/cnn_img.jpeg","modified":1,"renderable":0},{"_id":"source/img/PointCNN/conv_b.png","path":"img/PointCNN/conv_b.png","modified":1,"renderable":0},{"_id":"source/img/PointCNN/knn.png","path":"img/PointCNN/knn.png","modified":1,"renderable":0},{"_id":"source/img/PointCNN/time2.png","path":"img/PointCNN/time2.png","modified":1,"renderable":0},{"_id":"source/img/PointCNN/time.png","path":"img/PointCNN/time.png","modified":1,"renderable":0},{"_id":"source/img/PointCNN/x_conv.png","path":"img/PointCNN/x_conv.png","modified":1,"renderable":0},{"_id":"source/img/PointNet/symmetry _function.png","path":"img/PointNet/symmetry _function.png","modified":1,"renderable":0},{"_id":"source/img/PointNet++/res.png","path":"img/PointNet++/res.png","modified":1,"renderable":0},{"_id":"source/img/hello_world/top.png","path":"img/hello_world/top.png","modified":1,"renderable":0},{"_id":"source/img/PointCNN/visual.png","path":"img/PointCNN/visual.png","modified":1,"renderable":0},{"_id":"source/img/PointCNN/x_transformer.png","path":"img/PointCNN/x_transformer.png","modified":1,"renderable":0},{"_id":"source/img/PointNet/result.png","path":"img/PointNet/result.png","modified":1,"renderable":0}],"Cache":[{"_id":"source/CNAME","hash":"51544cd37f2188326b08d74bd5b18cde71d558ac","modified":1616219120199},{"_id":"source/.DS_Store","hash":"82f1c02a844379ad7c3f03098b52c90fcb7e03bb","modified":1616499062274},{"_id":"source/_posts/.DS_Store","hash":"c30958085d0c7a3c715e086527ae7f4a02f9a44c","modified":1616495382698},{"_id":"source/_posts/hello-world.md","hash":"74ee16db7816ba9f602499d9f82a00d082f47b43","modified":1607180260957},{"_id":"source/_posts/Readelf.md","hash":"1997bf2128f4ad5764cef93d4cd6aea9a14e9d85","modified":1616392245444},{"_id":"source/about/index.md","hash":"d19ef6b3db3f8159a0b51facf4ffbbcb877bc2ae","modified":1604586167518},{"_id":"source/img/.DS_Store","hash":"6ae2041898048894ac1c7fa7e36f2eae38ebc30e","modified":1614431820888},{"_id":"source/_posts/Recent-Progress (2020-11-15 ~ 2020-11-27).md","hash":"c9ce92251af5542da8d5f7fedd4b3229a4fb54e4","modified":1607409076128},{"_id":"source/_posts/final_todo.md","hash":"e740ed2486df2836ae42bea7b48436baeb8f4ea2","modified":1608189504502},{"_id":"source/_posts/CS231n/CS231n-04-Convolutional-Neural-Networks.md","hash":"63af23d8993f8b340c8f632c4dc8037f619cf215","modified":1607476972529},{"_id":"source/_posts/CS231n/CS231n-03-Introduction-to-Convolutional-neural-network.md","hash":"d4dc274759671030bab92a897b1abe4c1999e003","modified":1607476971272},{"_id":"source/img/TODO.png","hash":"52e3cfd0df7fcc4806f62eb27f717cf045158cb3","modified":1608181578663},{"_id":"source/_posts/CS231n/CS231n_01_Image_Classification.md","hash":"0734667862fbff18dc441e22ebadfa692c197001","modified":1607476968289},{"_id":"source/_posts/CS231n/CS231n-05-Training-Neural-Networks-I.md","hash":"c58e16f3abad2ba20c625d57d2a89689b30efa1d","modified":1607476974187},{"_id":"source/_posts/CS231n/CS231n-06-Training-Neural-Networks-II.md","hash":"77fe84659656f273e9dcb31d1c4d0cd5b33326fa","modified":1607476975792},{"_id":"source/_posts/DS/DataStructureNote1.md","hash":"56d8264c2b99aca82d3871493b2977837f01e963","modified":1607476985341},{"_id":"source/_posts/ICS/ICS_Lab1.md","hash":"6279b2d5cc2a3b74c18eb26f08c8569bc8ba1361","modified":1607477000899},{"_id":"source/_posts/ICS/ICS_Lab3.md","hash":"24d06de4f3c290ee085267b12c8f9a2ba4b50f94","modified":1607476998411},{"_id":"source/_posts/ICS/.DS_Store","hash":"c7d546835eb081a0fc4b4b8bff8fab7976ec68cd","modified":1616384957975},{"_id":"source/_posts/ICS/ICS_Normal.md","hash":"13516bf801e4730b3a743ed529267a5f6cc150b4","modified":1615213898376},{"_id":"source/_posts/DS/DataStructureNote2.md","hash":"0c2fa3dab75219a4232b40fcf2ca28ce1206a26a","modified":1607477007173},{"_id":"source/_posts/CS231n/CS231n_02_Loss-Functions-and-Optimization.md","hash":"44ee119de7e50c0833c5a28c6891ada76e4c1777","modified":1607476969814},{"_id":"source/_posts/ICS/ICS_Lab2.md","hash":"6378cae75f62bc460299993051dcd20b31aaf162","modified":1607476996858},{"_id":"source/_posts/Research/PointCNN.md","hash":"883bdd9339e4a89a47a2699499804f43a9ee4b93","modified":1607476902237},{"_id":"source/_posts/Research/PointNetpp.md","hash":"94b20526f525cfb2b04a8d3cbdaaabf1dcce1299","modified":1607476909367},{"_id":"source/_posts/Research/PointNet.md","hash":"429cf8de9d341948e3e959a64ba38ac285729a57","modified":1607476906797},{"_id":"source/_posts/ICS/ICS_PJ.md","hash":"37b468313891e5ec105b047a447062f79e01f2d4","modified":1609900612512},{"_id":"source/img/ICS_Lab1/.DS_Store","hash":"3644d2a969a48867287119213604eddc91a7af44","modified":1604626120751},{"_id":"source/img/ICS_Lab1/bits_honor_dlc.png","hash":"72b1d169d0c3703bd268e98134eff20a0e0cc31d","modified":1602087878000},{"_id":"source/img/ICS_Lab1/top.jpg","hash":"72a892ba4833d2e1d3c0bdb6a35d3a8d33e8e8cd","modified":1604592245848},{"_id":"source/img/ICS_Lab2/upload_4801c7e177c56f6e7299c273d0120988.png","hash":"e59229dcd7bdc1dc4ddb52601b58d5a5dd8557c6","modified":1604649102324},{"_id":"source/img/ICS_Lab2/upload_f2ecdd05728cbefbba59b068a29fdfdc.png","hash":"fc4024d6fb85e7850ba440cd56a267ed060a959a","modified":1604649401509},{"_id":"source/img/ICS_Lab2/.DS_Store","hash":"ee6df2f45dbbecef218431e70c9d5937af39da22","modified":1604670116108},{"_id":"source/_posts/Research/CaDDN-Paper.md","hash":"39c4d000b53382fce5e8a77f922c1ebff86adfae","modified":1615366970165},{"_id":"source/_posts/Research/.DS_Store","hash":"ff79f494941ca0d8f347300d0451df1ae877b61d","modified":1616392603404},{"_id":"source/_posts/Research/DETR.md","hash":"cc496ea9c81b2fe97e4cf712101ac727532847c3","modified":1611540846702},{"_id":"source/img/Pic/Recent.jpeg","hash":"a894cbfcd2ef37457d03c1eafd83b50842fffdbc","modified":1606471764443},{"_id":"source/img/Pic/DS.png","hash":"de0c67290b8c1fe646ec29df885168c85f405ff8","modified":1607176833559},{"_id":"source/img/PointCNN/conv2.png","hash":"069970fe8dc70a505b2b95330390ff0422d7d01a","modified":1607432145860},{"_id":"source/img/Pic/cnn_img.jpeg","hash":"7ceabac10778f93a977196eb371197062cff2319","modified":1607258113848},{"_id":"source/img/PointCNN/conv_a.png","hash":"a83fca017aa6b6adafe08f172a4299a9d3ae1081","modified":1607432185499},{"_id":"source/img/PointCNN/conv_b.png","hash":"abda8f4a4af23358f2a48a73ed1e8667df5c9f24","modified":1607432782009},{"_id":"source/img/PointCNN/time.png","hash":"e7cdf1994df22ed8b1b5ee22952c5b13f0bfe922","modified":1607442970438},{"_id":"source/img/hello_world/.DS_Store","hash":"3db878c166c09f6b2e7c687494d479908cb0ec43","modified":1604592201178},{"_id":"source/img/PointNet/symmetry _function.png","hash":"5b85bc43d6159b9d0f011e837f5efa77230147c0","modified":1607245241810},{"_id":"source/img/Cs231n/top.jpg","hash":"a9f72513df8d124e1ba28899f90ebb6da8fb55b0","modified":1604758521149},{"_id":"source/img/ICS_Lab1/bits_dlc.png","hash":"e8b818f78cd50dae1edd45dab9267c3069edbc02","modified":1602087872000},{"_id":"source/img/ICS_Lab1/bits_btest.JPG","hash":"647438ec455ecd7a47d6167eb2094f815f800d41","modified":1602068098000},{"_id":"source/img/DS/tree_差分.png","hash":"6a04a5222246a7860b3c6999f4ba2212e22024dc","modified":1607441656715},{"_id":"source/img/ICS_Lab1/bits_honor_btest.JPG","hash":"8e1b2a958402a82be827e9d37272389e9d07b38c","modified":1602068098000},{"_id":"source/img/DS/tree_差分2.png","hash":"732ca9708af1fd33590c2d62f533c562b4b74f41","modified":1607441670297},{"_id":"source/img/ICS_Lab2/upload_7194e52688ff3d696a3b889e2b17d63f.png","hash":"a12aa8b9911ff42e1c7fd341740bb5952026b617","modified":1604649285328},{"_id":"source/img/ICS_Lab2/upload_a18a67d1b4dbfa16a7fd8800e3ee304b.png","hash":"3150fbc95d0db988078ce153187bd333140a3e3d","modified":1604649415745},{"_id":"source/img/ICS_Lab2/upload_ae5e359c30ff5ccb9292a7472c39eb19.png","hash":"6d1014f0788ac311e23beef2c59d068f472f86df","modified":1604649165829},{"_id":"source/img/ICS_Lab2/upload_dfddd1801cd10c701dd2753164434977.png","hash":"18eb25f8c6db5cb7bd810129130c7d6dad71a54c","modified":1604649443778},{"_id":"source/img/PointCNN/conv.png","hash":"73bc365cdf5d5fa0d49a9d6cc31022bf07b4fbb0","modified":1607430907799},{"_id":"source/img/PointCNN/time2.png","hash":"9a95680da0876d027509cb495feb81abcb59c6d0","modified":1607442978985},{"_id":"source/img/PointCNN/knn.png","hash":"74ea4875a0500805ab5213a9672f3a672dcddd45","modified":1607441151318},{"_id":"source/img/PointCNN/x_conv.png","hash":"cbe5888542801d1683deb17ddabbccd3ad9bf9d0","modified":1607441133884},{"_id":"source/img/PointNet/result.png","hash":"2f05d38ce079e66a88ad024ccccfc861d00770c4","modified":1607257346067},{"_id":"source/img/PointCNN/x_transformer.png","hash":"5ceda2ae38097bfe8e24da1295cc513215a0297d","modified":1607432602845},{"_id":"source/img/ICS_Lab2/upload_27148224f8cf2be48266eaa52f50b2f8.png","hash":"f671afdbca16a239e220b637c08410e667950412","modified":1604649141522},{"_id":"source/img/Pic/PointCloud.jpg","hash":"0f07012fcae8097a4377d4a60bcddefb02ca139a","modified":1607222769577},{"_id":"source/img/PointNet++/res.png","hash":"88f91e34a67f37e751ff2e216cf5c086ae4cca7c","modified":1607417652444},{"_id":"source/img/ICS_Lab2/upload_016df1440f7044a54fb4ced529595b58.png","hash":"4ed4e36ce65df848c9e45f7c8b417ec9c1b7db2a","modified":1604649254276},{"_id":"source/img/ICS_Lab2/upload_244e1f55d2823d58f65eabab9478d7ce.png","hash":"8fc4327e7e7b113cd61b14f62890d8debe0179eb","modified":1604649049503},{"_id":"source/img/ICS_Lab2/upload_64ed470376ec6b72dc43690bf9b4ea0e.png","hash":"70d23c7516d816392111cc32620a4ed82b9f6263","modified":1604649440360},{"_id":"source/img/hello_world/top.png","hash":"c61a20a651af82f4a2fd5e6f3724fc36e148fa07","modified":1604592053532},{"_id":"source/img/ICS_Lab2/upload_9ea5cd30293a18357af1da93c35e0f59.png","hash":"7321e52b83920d6f097ef999870bb72d3ece131a","modified":1604649387440},{"_id":"themes/fluid/source/css/_pages/_category/category.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_tag/tag.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1604556361000},{"_id":"themes/fluid/.gitattributes","hash":"a54f902957d49356376b59287b894b1a3d7a003f","modified":1604556361000},{"_id":"themes/fluid/.gitignore","hash":"bd095eee271360a38772ee1a42d4f000fb722e5f","modified":1604556361000},{"_id":"themes/fluid/.DS_Store","hash":"3d4cf6a4f963c16859e8855550200777eafe2924","modified":1616499074164},{"_id":"themes/fluid/README.md","hash":"ea55d234aeae3eb9e232f729f8411810d65c6f49","modified":1604556361000},{"_id":"themes/fluid/README_en.md","hash":"ca8fd19a4948de1f253616a62c0e8a7d81f692f5","modified":1604556361000},{"_id":"themes/fluid/.editorconfig","hash":"33218fbd623feb43edf5f99f15965392cecc44a6","modified":1604556361000},{"_id":"themes/fluid/gulpfile.js","hash":"dc82b6be72c786721a2f5e2acc10a2a94995c540","modified":1604556361000},{"_id":"themes/fluid/.eslintrc","hash":"4bc2b19ce2b8c4d242f97d4ccf2d741e68ab0097","modified":1604556361000},{"_id":"themes/fluid/package.json","hash":"623e6f2dc876daa6ab599fbac4636f54782e6ea3","modified":1604556361000},{"_id":"themes/fluid/LICENSE","hash":"5b919c12e4f5f5cdebb7c17ded4f10f1ebe64811","modified":1604556361000},{"_id":"themes/fluid/languages/de.yml","hash":"13a6a799415fc2f6f69ebd1a399fb44426a5d641","modified":1604556361000},{"_id":"themes/fluid/languages/en.yml","hash":"a85dcc5cc21f9cab50df31e5001b8818ee62d1e2","modified":1604556361000},{"_id":"themes/fluid/languages/ja.yml","hash":"91020031a847c0361a6fd7ab990c7be4bf17529b","modified":1604556361000},{"_id":"themes/fluid/languages/zh-CN.yml","hash":"21307b4137c3d9b04bb58243747e75af0abc5a71","modified":1604556361000},{"_id":"themes/fluid/layout/404.ejs","hash":"689d9f4efd2a7f5edfd9b24561a7ade69d46617c","modified":1604556361000},{"_id":"themes/fluid/layout/about.ejs","hash":"e3e2de8b0dc63ece51c324bb7942f240cdbfc7bf","modified":1604556361000},{"_id":"themes/fluid/layout/categories.ejs","hash":"6c4ab9fcdf5f7b58238bf06276b027075872c424","modified":1604556361000},{"_id":"themes/fluid/layout/archive.ejs","hash":"472d0813ca5b88000a7bc6039f33b7e27b5a3216","modified":1604556361000},{"_id":"themes/fluid/layout/category.ejs","hash":"58291dfec65c36889dfce0ddc603540b67e4c598","modified":1604556361000},{"_id":"themes/fluid/layout/index.ejs","hash":"58e994d28fd72d585d2e4c63d0c0fd3e61dd14b8","modified":1604556361000},{"_id":"themes/fluid/layout/layout.ejs","hash":"d772721214358a658cfacaecb194d9c6db971488","modified":1604556361000},{"_id":"themes/fluid/layout/page.ejs","hash":"8cab50ead4cdb992d35710147a9a5308fb5df290","modified":1604556361000},{"_id":"themes/fluid/layout/links.ejs","hash":"6abd180ff4dd1d5d22e4c70328e3c7f83d174d9c","modified":1604556361000},{"_id":"themes/fluid/layout/tag.ejs","hash":"0ad89eb7c92a822980fa9a85285e6d94ad845d1d","modified":1604556361000},{"_id":"themes/fluid/layout/post.ejs","hash":"f334657509a9b8b4e05d425d3e5f47a1c21b7dd7","modified":1604556361000},{"_id":"themes/fluid/layout/tags.ejs","hash":"1d06af34b6cf1d8a20d2eb565e309326ceba309f","modified":1604556361000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/bug_report_zh.md","hash":"5c5a5565bb13928bc92332d9b99b968673ea7dfb","modified":1604556361000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/bug_report.md","hash":"8f20dca8a03aefd495d0550544f25d8c6e44333e","modified":1604556361000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/feature_request.md","hash":"d3a3204d9bb2b43a69c9cb0be59bada8cb91e412","modified":1604556361000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/feature_request_zh.md","hash":"a413dc14e4737dbcaa8fb797d37f85121ede6551","modified":1604556361000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/question.md","hash":"ab5eab9e3ff889c4ba7fd82846e7f5b7ae15bebc","modified":1604556361000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/question_zh.md","hash":"e24b470f7aa8044499a4f5e39634e5dc43899011","modified":1604556361000},{"_id":"themes/fluid/.github/workflows/limit.yaml","hash":"f8bd2edeb4424ee7a055b31583445d5d5dff91a4","modified":1604556361000},{"_id":"themes/fluid/.github/workflows/lint.yaml","hash":"bccd7961fa146dd5f0d70f77e7ab94e9f58d5bd3","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/archive-list.ejs","hash":"8723aa57f61134a2c1dc84cc7ea88ea366f4fda3","modified":1604556361000},{"_id":"themes/fluid/source/.DS_Store","hash":"a34cc0f73eb1c4ea5e98602b01c881cca5adc940","modified":1616499074164},{"_id":"themes/fluid/layout/_partial/beian.ejs","hash":"bed4ee45bec0f1f1d3ed469e3197bb8f5e0b684e","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/css.ejs","hash":"ea590a8e8e48148335b94aebca2b73c19bd5f789","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/footer.ejs","hash":"382bd3ee27bc6d90776fc9171a487ff208bc4caa","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/head.ejs","hash":"ab70ddfcf7b14c7000130d1a2b54c75dde106d66","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/nav.ejs","hash":"70490c67b7313ae305d39331238232fe62f094f1","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/paginator.ejs","hash":"783eee847562ce14db8f723b4ae742fb69aaf620","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/scripts.ejs","hash":"1d2ea9c4c905bc4b8e1c64c717246f583bd583ee","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/search.ejs","hash":"cdd7919fa01f6ef7ccc09938d662ff3d77f5d999","modified":1604556361000},{"_id":"themes/fluid/scripts/events/index.js","hash":"a6ab2c6d9f9ba58cd1fabb85c2817874246fd525","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/post-meta.ejs","hash":"3e0fa1731b6e54dbcf52ccf8e200e83dc4549bfa","modified":1604556361000},{"_id":"themes/fluid/scripts/filters/locals.js","hash":"58d0fec976f6b1d35e7ea03edc45414088acf05c","modified":1604556361000},{"_id":"themes/fluid/scripts/filters/post-filter.js","hash":"fd567dccd9ea8c158a5dae6847dd99e272c3f43c","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/statistics.ejs","hash":"920bc618d357d48d2b96f8758f6ae8f9488fc4d8","modified":1604556361000},{"_id":"themes/fluid/scripts/generators/pages.js","hash":"d9971f15fbb6b775e3d31a1b9b45011959395010","modified":1604556361000},{"_id":"themes/fluid/scripts/helpers/export-config.js","hash":"2ec0e2c79de89886c67391d5e94b0f18b2a6021e","modified":1604556361000},{"_id":"themes/fluid/scripts/generators/local-search.js","hash":"fc2c50405b771b06b7f6cfc4e9de97b992691555","modified":1604556361000},{"_id":"themes/fluid/scripts/helpers/url.js","hash":"99ab4551dc9c035abcc3bf4da5def2f63449d7ec","modified":1604556361000},{"_id":"themes/fluid/scripts/helpers/page.js","hash":"4607607445233b3029ef20ed5e91de0da0a7f9c5","modified":1604556361000},{"_id":"themes/fluid/scripts/helpers/utils.js","hash":"9045f47c7a71aab39f16cffb3e3847b752c2e0f1","modified":1604556361000},{"_id":"themes/fluid/scripts/helpers/wordcount.js","hash":"e58d422eddb44c1be893f65f79f4c7feecfe6d5f","modified":1604556361000},{"_id":"themes/fluid/scripts/tags/button.js","hash":"3eb43a8cdea0a64576ad6b31b4df6c2bf5698d4c","modified":1604556361000},{"_id":"themes/fluid/scripts/tags/checkbox.js","hash":"63468f7875c09d9557fe8315afc97175745d9087","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/toc.ejs","hash":"3d2fb5552f373e5a0c56bc356702d807bcbcb411","modified":1604556361000},{"_id":"themes/fluid/scripts/tags/group-image.js","hash":"4aeebb797026f1df25646a5d69f7fde79b1bcd26","modified":1604556361000},{"_id":"themes/fluid/scripts/tags/label.js","hash":"f05a6d32cca79535b22907dc03edb9d3fa2d8176","modified":1604556361000},{"_id":"themes/fluid/scripts/tags/note.js","hash":"0886cfe3f8589671a1d289495e359c20a9908080","modified":1604556361000},{"_id":"themes/fluid/scripts/utils/join-path.js","hash":"629e7deb3955f750c1cfa6fc773f412e020fcef4","modified":1604556361000},{"_id":"themes/fluid/scripts/utils/object.js","hash":"61e9555f99edcb23d55361c7154e23af33153ecb","modified":1604556361000},{"_id":"themes/fluid/source/css/main.styl","hash":"d5a8a59c8d1fd17d699a951e59c4ce9ae44c419d","modified":1604556361000},{"_id":"themes/fluid/source/img/.DS_Store","hash":"6eb23ce85b98abe4b326fe1d23ee5a7a9d2c2985","modified":1616499083683},{"_id":"themes/fluid/source/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1604556361000},{"_id":"themes/fluid/source/img/default.png","hash":"7bb2b8ee07db305bcadee2985b81b942027ae940","modified":1604556361000},{"_id":"themes/fluid/source/img/favicon.png","hash":"2defc5fd93898cf749f0ae180f5cf5df12448e6a","modified":1604587528863},{"_id":"themes/fluid/source/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1604556361000},{"_id":"themes/fluid/source/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1604556361000},{"_id":"themes/fluid/source/img/avatar.png","hash":"1253aaa9cbb596c5ce672553d09922f612c89ab1","modified":1605785682743},{"_id":"themes/fluid/source/js/boot.js","hash":"1aea6f229e2298c7c134e9f1cc94576cd3f30611","modified":1604556361000},{"_id":"themes/fluid/source/js/color-schema.js","hash":"7d7444387e549e06a4a378706df92558de62e4e7","modified":1604556361000},{"_id":"themes/fluid/source/js/debouncer.js","hash":"045f324777bdfb99d4c17b1806169f029f897a65","modified":1604556361000},{"_id":"themes/fluid/source/js/events.js","hash":"9b3a3dfdbc64e6b367ae2ebf7700ed611ecd0d47","modified":1604556361000},{"_id":"themes/fluid/source/js/lazyload.js","hash":"0df461660bbd73a79f3125ba4e9bdbc856232e6b","modified":1604556361000},{"_id":"themes/fluid/source/js/leancloud.js","hash":"23e567d77127f5787b0fc7091ddfa085c53b82f4","modified":1604556361000},{"_id":"themes/fluid/source/js/plugins.js","hash":"67d68cd2da25edbc98d433f34cf79039d5cdb082","modified":1604556361000},{"_id":"themes/fluid/source/js/local-search.js","hash":"13d5ef2fe68c49bd6096781034dbb26c190b5176","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/comments/Gitalk.ejs","hash":"3cd99f13535e444fff65c97a1f60e838aeaadba6","modified":1607259912435},{"_id":"themes/fluid/source/js/utils.js","hash":"17ef83ebf76b262ce2cb09c49a15fb1522b82982","modified":1604556361000},{"_id":"themes/fluid/source/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/comments/changyan.ejs","hash":"1b42e725454f3ae8d3bff086afcc294ca2fdeb72","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/comments/disqus.ejs","hash":"335b52bfa1cdd671cec1c4d745216d8404b2df45","modified":1604556361000},{"_id":"themes/fluid/source/js/duration.js","hash":"3c20a17ff6eafdb6792f6dd10f25b855a6a891ca","modified":1604648512579},{"_id":"themes/fluid/layout/_partial/comments/livere.ejs","hash":"593649f7e3f86779649e078b69f6fdc584648d72","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/comments/remark42.ejs","hash":"1e9c4364df5a0971087f779f87f33960e3674124","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/comments/twikoo.ejs","hash":"d7d689156a8d2a6b00b306bd30628fa961449135","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/comments/valine.ejs","hash":"899664e8eea0e77ffcff436a24198ee2da750d11","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/comments/utterances.ejs","hash":"71239ad210d24ad10a01c339590a797062153e8a","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/plugins/local-search.ejs","hash":"1e9ed2dde3050b5a650d0e45b9f712a6279f8f0c","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/plugins/math.ejs","hash":"76c4e0608ae362a265ac5e9c0fc49f75c1bc568e","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/plugins/analytics.ejs","hash":"557077a8825fffc0a2c7fe2b29f319287950244f","modified":1604556361000},{"_id":"themes/fluid/scripts/events/lib/highlight.js","hash":"96d56372cad997b09c26dbd29a19f917140c6ab0","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/plugins/mermaid.ejs","hash":"10ed1f9a611449d37736e17c4e251127b38b3772","modified":1604556361000},{"_id":"themes/fluid/scripts/events/lib/footnote.js","hash":"3b2abc5f5e3b681874637e98e047dc4969eb1983","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/plugins/nprogress.ejs","hash":"19245797dda67bc97d534a5c3f283ff6dfa8a321","modified":1604556361000},{"_id":"themes/fluid/layout/_partial/plugins/typed.ejs","hash":"ab71df2e56b60e8e193ff827e81704e5b358a977","modified":1604556361000},{"_id":"themes/fluid/scripts/events/lib/lazyload.js","hash":"0283128db63cc25b565d0da3c8a2120cc45626d1","modified":1604556361000},{"_id":"themes/fluid/scripts/events/lib/hello.js","hash":"38f6953e430d452d6608dacc4895ca623b4844a5","modified":1604556361000},{"_id":"themes/fluid/scripts/events/lib/merge-configs.js","hash":"2264bec80ba051a19ba80396618f3d0c22948f0b","modified":1604556361000},{"_id":"themes/fluid/scripts/events/lib/preset-configs.js","hash":"202459c9444b1ba967396db3625af261b0b19820","modified":1604556361000},{"_id":"themes/fluid/scripts/events/lib/version.js","hash":"0250fb16c7c798afd1f7fc816163ea0728765568","modified":1604556361000},{"_id":"themes/fluid/source/css/_functions/base.styl","hash":"2e46f3f4e2c9fe34c1ff1c598738fc7349ae8188","modified":1604556361000},{"_id":"themes/fluid/source/css/_mixins/base.styl","hash":"542e306ee9494e8a78e44d6d7d409605d94caeb3","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/pages.styl","hash":"b8e887bc7fb3b765a1f8ec9448eff8603a41984f","modified":1604556361000},{"_id":"themes/fluid/source/css/_variables/base.styl","hash":"fe96204aa2e7ee4f7f404c9e90752a8ff822d779","modified":1604556361000},{"_id":"themes/fluid/source/lib/hint/hint.min.css","hash":"b38df228460ebfb4c0b6085336ee2878fe85aafe","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_about/about.styl","hash":"15d2786d00418e61022475194ad76445d68e27ea","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_archive/archive.styl","hash":"6e6f22b664199772370b59ce1678b0c148b5849f","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_base/base.styl","hash":"aa2528e71c290dc43b69dfbdcf4d8d6c258015a4","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_base/color-schema.styl","hash":"f7004d597163e0af7b9107b0be1df12f4c0a7bc0","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_base/inline.styl","hash":"fab8441a0b8d8f9db6c8370013659c035345ae79","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_base/keyframes.styl","hash":"94065ea50f5bef7566d184f2422f6ac20866ba22","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_category/categories.styl","hash":"1ab7db37c2f7dc7ccdb994dcb41c16a4c8920397","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_base/rewrite.styl","hash":"94a8fb9c160386fce7dcd5ac886dee8cf3a4e750","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_index/index.styl","hash":"4304bab8ad087911cbf5025a41014fbb67f20b5a","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_post/post.styl","hash":"cc991a481214bf02c54cef4535d98ca45f8729f9","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_links/links.styl","hash":"cd4ebb1426abed9fda93b797b02c6d5dd71dc2a1","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_post/tag_plugin.styl","hash":"cbb49a17fcc030029f0c2fbe1e056613109d1ecc","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_tag/tags.styl","hash":"65bfc01c76abc927fa1a23bf2422892b0d566c3f","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/banner.styl","hash":"e3d4acfdf0647e89a7a88f53e754ea543641ae30","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/board.styl","hash":"32d90bcc8bf2fd5d8d78e86a567973d4b69bcfa1","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/copy-btn.styl","hash":"2c9e05a354d4be820646a1c99f814740f299ed37","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/footer.styl","hash":"35539a1ce8476e75515015a06d01ec66e4af6834","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/footnote.styl","hash":"ae9289cc89649af2042907f8a003303b987f3404","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/qrcode.styl","hash":"461d609a802a4f9aa9f492411ed8074813a956b7","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/header.styl","hash":"7c8170d0e2de47570fe8ed523f10ee1c33138a9f","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/scroll-btn.styl","hash":"e4ad804ab26bdbf5b55abbc5548b6db395cfed04","modified":1604556361000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/search.styl","hash":"10f7e91a91e681fb9fe46f9df7707b9ef78707c8","modified":1604556361000},{"_id":"source/img/PointCNN/visual.png","hash":"ae127c6cee0dcd022cb3103ddddbed9faba59b11","modified":1607442761501},{"_id":"themes/fluid/_config.yml","hash":"05927b023a2ef51a3c2d7833600f9ff33abc0716","modified":1616219424043},{"_id":"themes/fluid/source/img/bg_in.jpg","hash":"32c81168dceca41a00e957ca40624fc88eacad49","modified":1604591337292},{"_id":"themes/fluid/source/img/bg.jpg","hash":"b538296f018be0191f38259344c965d36111c06d","modified":1604590815081},{"_id":"themes/fluid/source/img/bg2.jpg","hash":"e5b05a7511ac4e3de7cade9b7004392b2086f10c","modified":1604646379342},{"_id":"source/img/AI.png","hash":"5baef76d6c8f9acab85df7c2003fcfb59e0909df","modified":1611294809951},{"_id":"public/img/avatar.png","hash":"6a7b1a6305d9badcf7e6fa290822d24db66d5a79","modified":1616499106815},{"_id":"public/img/bg.jpg","hash":"2cf1f2e5430c2b62a98cfa02a744ad8abe0ffaca","modified":1616499106815},{"_id":"public/img/bg_in.jpg","hash":"a4faedd145c78afd89a8079192f7cd3e720ff62d","modified":1616499106815},{"_id":"public/img/bg2.jpg","hash":"cdd6b748090207df3d26e72f0e47a0afb9966cc6","modified":1616499106815},{"_id":"public/img/favicon.png","hash":"53e09faacf395db5264b862fbe2c71a53bc5caff","modified":1616499106815},{"_id":"public/img/AI.png","hash":"af71f146a5af8c48fedb443fb3358e7c6476c2b1","modified":1616499106815},{"_id":"public/img/TODO.png","hash":"b2a241f5aeea03ae071663e0f29c7e8ab79406df","modified":1616499106815},{"_id":"public/img/Cs231n/top.jpg","hash":"fbbe6bd223376b9b4828028d41159c69645c349b","modified":1616499106815},{"_id":"public/img/DS/tree_差分.png","hash":"43a2c723da6710036ebf5af47ce2c73e03685e6a","modified":1616499106815},{"_id":"public/img/DS/tree_差分2.png","hash":"31bcbc813e8e7c2de7f0c3d9204f92bcc33327d5","modified":1616499106815},{"_id":"public/img/ICS_Lab1/bits_btest.JPG","hash":"c8fd1bf5a7fc21abe1a4285459a0022554a9065b","modified":1616499106815},{"_id":"public/img/ICS_Lab1/bits_dlc.png","hash":"84de4fd3d56cbbdb1b8776300b8937dedf0dfc55","modified":1616499106815},{"_id":"public/img/ICS_Lab1/bits_honor_btest.JPG","hash":"e6e8a3ee7d62f8a38308f3e4ebd048b8732a59c0","modified":1616499106815},{"_id":"public/img/ICS_Lab1/top.jpg","hash":"0e99aa0f3259a1b7a5138b545ae50b012ba0f129","modified":1616499106815},{"_id":"public/img/ICS_Lab1/bits_honor_dlc.png","hash":"8cce0d1d29aac9d396adacf771f19aff0fc897d6","modified":1616499106815},{"_id":"public/img/ICS_Lab2/upload_016df1440f7044a54fb4ced529595b58.png","hash":"682be76b2091933bfe6a32c335fa4cf12fd906d4","modified":1616499106815},{"_id":"public/img/ICS_Lab2/upload_244e1f55d2823d58f65eabab9478d7ce.png","hash":"1acdcd860d18409efb2b148b203d4dd59429a2d3","modified":1616499106815},{"_id":"public/img/ICS_Lab2/upload_27148224f8cf2be48266eaa52f50b2f8.png","hash":"ce02ba5a9afb01df23a232ca1be2b58b3dc07600","modified":1616499106815},{"_id":"public/img/ICS_Lab2/upload_64ed470376ec6b72dc43690bf9b4ea0e.png","hash":"455e08f18bdb7480fec8f9eec36a07112cd50222","modified":1616499106815},{"_id":"public/img/ICS_Lab2/upload_4801c7e177c56f6e7299c273d0120988.png","hash":"b1453b17cdd6017fa1a4b2f15b4d7c3e3bd04dad","modified":1616499106815},{"_id":"public/img/ICS_Lab2/upload_7194e52688ff3d696a3b889e2b17d63f.png","hash":"7511ff0c9c881dcfe169fa6641cc23b4b73e1cb6","modified":1616499106815},{"_id":"public/img/ICS_Lab2/upload_9ea5cd30293a18357af1da93c35e0f59.png","hash":"9f5c3bd03a64565c69c96c664de6988be31ef2a6","modified":1616499106815},{"_id":"public/img/ICS_Lab2/upload_a18a67d1b4dbfa16a7fd8800e3ee304b.png","hash":"b6ce237e7294ea20a3bcf72c12ad1f80d36512f1","modified":1616499106815},{"_id":"public/img/ICS_Lab2/upload_ae5e359c30ff5ccb9292a7472c39eb19.png","hash":"bc837c737ca5e301791b18d77bedd3cdca4d3911","modified":1616499106815},{"_id":"public/img/ICS_Lab2/upload_dfddd1801cd10c701dd2753164434977.png","hash":"382b338b925b4eed93c765598474ced5c1371be4","modified":1616499106815},{"_id":"public/img/ICS_Lab2/upload_f2ecdd05728cbefbba59b068a29fdfdc.png","hash":"45b3ff0edbbaec32074d13d5113af9cadf42a3cb","modified":1616499106815},{"_id":"public/img/PointCNN/conv.png","hash":"d73e5d349ec34e54be3c424c9c6e6b158c06655f","modified":1616499106815},{"_id":"public/img/Pic/PointCloud.jpg","hash":"158b83c208b3bf07e39a950967af21995a6a3e1d","modified":1616499106815},{"_id":"public/img/Pic/DS.png","hash":"6c8a77a8204d628229366d85850c9637a4288a02","modified":1616499106815},{"_id":"public/img/PointCNN/conv2.png","hash":"7b0c8da55f0d1bfcc5a05318f9d557a35e7679e4","modified":1616499106815},{"_id":"public/img/PointCNN/conv_a.png","hash":"28357c24a4973c99ee73ad52c7941dcbb203b243","modified":1616499106815},{"_id":"public/img/PointCNN/conv_b.png","hash":"cee933de85e54eccb934acda92bb8c2dcfd11d48","modified":1616499106815},{"_id":"public/img/PointCNN/knn.png","hash":"45e811efb4e1b6de265672fcf5646e29d0d17947","modified":1616499106815},{"_id":"public/img/PointCNN/time2.png","hash":"7784db6177b652996cdd6514e125169757d017de","modified":1616499106815},{"_id":"public/img/PointCNN/time.png","hash":"449209e690652baefef37f46862b8595fdc3097b","modified":1616499106815},{"_id":"public/img/PointCNN/x_conv.png","hash":"8b1124241f1953aef83420e6353a6568af9311b5","modified":1616499106815},{"_id":"public/img/PointNet/symmetry _function.png","hash":"f1c056b7d2ae480f81a53ac34e6ca3f9c360c4c4","modified":1616499106815},{"_id":"public/img/PointNet++/res.png","hash":"6aaccc4998c3b2eee654eeda01d71898cd94d5c2","modified":1616499106815},{"_id":"public/img/hello_world/top.png","hash":"4ea85138860cc4c3498a793b922a1e71b503b1e3","modified":1616499106815},{"_id":"public/img/PointCNN/visual.png","hash":"85649f84cf3f6f58a3f573fd0c733a1c25478ba8","modified":1616499106815},{"_id":"public/img/PointCNN/x_transformer.png","hash":"f5253a9da3725d4784f7599e5279178af8f6e101","modified":1616499106815},{"_id":"public/img/PointNet/result.png","hash":"c89d86e87e66b664ee24cc9bc946706523f659bd","modified":1616499106815},{"_id":"public/local-search.xml","hash":"ec155cacdd398beeef8bbdf102f04212cbcba125","modified":1616499106815},{"_id":"public/about/index.html","hash":"90cdb954244670df3c355a3910060b28a3986bef","modified":1616499106815},{"_id":"public/2021/03/08/ICS/ICS_Normal/index.html","hash":"3128de7763c8f9a64dc2b27d888fa4274fcff9de","modified":1616499106815},{"_id":"public/2020/12/08/Research/PointCNN/index.html","hash":"b965e41b3e58deaa2fd35873113e004b1c495b7e","modified":1616499106815},{"_id":"public/2020/12/17/final_todo/index.html","hash":"4fe233467e910d401e97162ec54a8b74a3b54efb","modified":1616499106815},{"_id":"public/2020/12/08/Research/PointNetpp/index.html","hash":"6cb8e5fb7a96c0f6ce2c0333e10485db398fa181","modified":1616499106815},{"_id":"public/2020/12/07/DS/DataStructureNote2/index.html","hash":"13ba8a88d828a455aaf022b03c9029c36e9b3318","modified":1616499106815},{"_id":"public/2020/11/11/CS231n/CS231n-04-Convolutional-Neural-Networks/index.html","hash":"989bf0c68feabcd3294d9c83929727763f070046","modified":1616499106815},{"_id":"public/2020/11/10/CS231n/CS231n-03-Introduction-to-Convolutional-neural-network/index.html","hash":"e303d0db4d2aa44152a6c4574733ab74dde335ee","modified":1616499106815},{"_id":"public/2020/11/05/hello-world/index.html","hash":"915ecf5951187a73910676ac4d8a39c8f39b4eb3","modified":1616499106815},{"_id":"public/archives/index.html","hash":"e9fd3eedf6215d2ad20767b2df05220dd25e6788","modified":1616499106815},{"_id":"public/archives/page/2/index.html","hash":"c2c7d6680b5db296fffbd947f0e0bb51c319ca2c","modified":1616499106815},{"_id":"public/archives/page/3/index.html","hash":"9d7cc44216d4ce233e2ef0457dd7a2d0ab020ec5","modified":1616499106815},{"_id":"public/archives/2020/index.html","hash":"b5052a75c425aa705c384eace12552b23a14519b","modified":1616499106815},{"_id":"public/archives/2020/page/2/index.html","hash":"d57e5c5ec15ee17bd5f5076f7ecac535d036a247","modified":1616499106815},{"_id":"public/archives/2020/11/index.html","hash":"96e1423212558576a8e404cd775b23262e3a4b2a","modified":1616499106815},{"_id":"public/archives/2020/11/page/2/index.html","hash":"0581ad19121d57eba23713f61402e1b2ded96575","modified":1616499106815},{"_id":"public/archives/2020/12/index.html","hash":"26e4d97730c1abbaf642a8fd8171b7fd71fd1b9f","modified":1616499106815},{"_id":"public/archives/2021/index.html","hash":"6def994e5b7b5553f33013de8ad11f13560db843","modified":1616499106815},{"_id":"public/archives/2021/01/index.html","hash":"d93ab3f70185d8617849445b0d6a3c6fc716f062","modified":1616499106815},{"_id":"public/archives/2021/03/index.html","hash":"d1379214587802e2489855a1025ac238da22361a","modified":1616499106815},{"_id":"public/categories/ICS/index.html","hash":"98785709dafbfbbdeea7ac75f969d944dd20ae1d","modified":1616499106815},{"_id":"public/categories/TODO/index.html","hash":"c943615709a21c7131992736fe9f62c104f13ea5","modified":1616499106815},{"_id":"public/categories/Summary/index.html","hash":"9471e781737d3ab03746b0799168d29d173b02f4","modified":1616499106815},{"_id":"public/categories/CS231n/index.html","hash":"47a72f41213a56443a477e28ae3c3bf37b98214d","modified":1616499106815},{"_id":"public/categories/DataStructure/index.html","hash":"7aebe1d89e9555d03949bcbfa9be3a1da94b0b63","modified":1616499106815},{"_id":"public/categories/Research/index.html","hash":"f8d4bb87b41bd7b58ce6aa613834fb3066428d5c","modified":1616499106815},{"_id":"public/categories/Research/Object-Detection/index.html","hash":"3ab0bb58beb40a9e241eb3f52ed0c6e6eb46e91c","modified":1616499106815},{"_id":"public/page/3/index.html","hash":"ec1e5f08553a90a809e94d5d7da4e7e5890abc57","modified":1616499106815},{"_id":"public/tags/Link/index.html","hash":"3d675af90b28df41881a7256eaabbef4e7010ace","modified":1616499106815},{"_id":"public/tags/TODO/index.html","hash":"cae5c177b096d36472cb31589912db517f4705da","modified":1616499106815},{"_id":"public/tags/Summary/index.html","hash":"8bfb7aeb12e4b85ef7a29379ee60d910c1d8ba19","modified":1616499106815},{"_id":"public/tags/Hexo/index.html","hash":"0f87bcd8329c7ad9dfa5c0d2a4edd76ec5dfd7d7","modified":1616499106815},{"_id":"public/tags/Fluid/index.html","hash":"61f40bdc3a404e39a7f4916facd292a58f328ab6","modified":1616499106815},{"_id":"public/tags/CV/index.html","hash":"0d1de9988fd438b15213a4a42533bdfffecdae49","modified":1616499106815},{"_id":"public/tags/Neural-Network/index.html","hash":"00faf3746eb684c70099895386c580909b798270","modified":1616499106815},{"_id":"public/tags/LCA/index.html","hash":"ccd7381faf71b8191882beed5930be9db72a5248","modified":1616499106815},{"_id":"public/tags/UFS/index.html","hash":"ac8b2e72bedace2ce12481f65a7c51632962a036","modified":1616499106815},{"_id":"public/tags/Linker/index.html","hash":"b4031e920952ac489abc7be537679d40f4c37cdc","modified":1616499106815},{"_id":"public/tags/Sort/index.html","hash":"23822de67629334c21526b8197e21c9e29b80a5c","modified":1616499106815},{"_id":"public/tags/CPU/index.html","hash":"ee5542a5e08e6dfaaf4f1148b8c1abfce9e2555e","modified":1616499106815},{"_id":"public/tags/Assembly/index.html","hash":"02c1fb31dfc9ad1b651a9d204c959d2a8c15d21c","modified":1616499106815},{"_id":"public/tags/PointCNN/index.html","hash":"66cd9efd1820936b00498b50912bfd4d4b0038d1","modified":1616499106815},{"_id":"public/tags/Number-theory/index.html","hash":"de6c2174b025824e2a82184ced3e5511c7bad4e5","modified":1616499106815},{"_id":"public/tags/Multiplication-algorithm/index.html","hash":"db767c6670dcc5d18ec96b2e7596cc94c738ed63","modified":1616499106815},{"_id":"public/tags/PointNet/index.html","hash":"23d4e034a8509dcc246ee48a1c83c92a74e47270","modified":1616499106815},{"_id":"public/tags/Monocular-OD/index.html","hash":"c1e06537afae867b7884f01fa3398a3836ddb1e4","modified":1616499106815},{"_id":"public/tags/Transformer/index.html","hash":"85e5a20453745300c2fad4218472cec71f0cef66","modified":1616499106815},{"_id":"public/tags/Bits/index.html","hash":"73909fd1d19c1314322e101bf23a3b2ae5cac5b3","modified":1616499106815},{"_id":"public/404.html","hash":"177d829e9a911916e2c9ae09b6c3dfd1375ad793","modified":1616499106815},{"_id":"public/tags/index.html","hash":"8441fc8c642b434b08c8b1aeb5bd795f1a701e3a","modified":1616499106815},{"_id":"public/categories/index.html","hash":"350a0dd5af70f90ff09bdf884487f05e0198d89e","modified":1616499106815},{"_id":"public/links/index.html","hash":"e1e6c19b8e4f50623ab56540bf1cecbbc7fa616e","modified":1616499106815},{"_id":"public/2021/03/22/Readelf/index.html","hash":"acf2d4f2ae0dfb79589d2b520e89c9e2965f5311","modified":1616499106815},{"_id":"public/2021/03/09/Research/CaDDN-Paper/index.html","hash":"be2c3a374b0b2cd9c1fb65d61451711094cb8987","modified":1616499106815},{"_id":"public/2021/01/22/Research/DETR/index.html","hash":"66781301660e2d499a15ffde0bda578f34f335fc","modified":1616499106815},{"_id":"public/2021/01/06/ICS/ICS_PJ/index.html","hash":"60b6405f1a512e7f246c991367e4405430120f0b","modified":1616499106815},{"_id":"public/2020/12/06/Research/PointNet/index.html","hash":"0a7a8498fed4c76b18bf1d6d603f06d1fe8c50f1","modified":1616499106815},{"_id":"public/2020/12/05/DS/DataStructureNote1/index.html","hash":"d43a8fef5dc47f60b57fc196d3de7f99e51b16af","modified":1616499106815},{"_id":"public/2020/11/27/Recent-Progress (2020-11-15 ~ 2020-11-27)/index.html","hash":"1aeccb3f9a6d12bf349713c83efab45dc60065d9","modified":1616499106815},{"_id":"public/2020/11/15/ICS/ICS_Lab3/index.html","hash":"984f114f927802624858366da0c77bbe6bc2ac9a","modified":1616499106815},{"_id":"public/2020/11/13/CS231n/CS231n-06-Training-Neural-Networks-II/index.html","hash":"2b34a0757d55aee3088414bd7b61c9181fecc8b4","modified":1616499106815},{"_id":"public/2020/11/13/CS231n/CS231n-05-Training-Neural-Networks-I/index.html","hash":"bb45324f957c222d9b61530014d7529ad14f1c64","modified":1616499106815},{"_id":"public/2020/11/08/CS231n/CS231n_02_Loss-Functions-and-Optimization/index.html","hash":"e1b4da9c4c52249a19de1d5e5c8cbb9b3f2d8b0b","modified":1616499106815},{"_id":"public/2020/11/07/CS231n/CS231n_01_Image_Classification/index.html","hash":"7171cafd8d12ea553657bf49a35a55df7d18466a","modified":1616499106815},{"_id":"public/2020/11/06/ICS/ICS_Lab2/index.html","hash":"8c1cc453eff1ffc48f5b3ddb200d5b697745242a","modified":1616499106815},{"_id":"public/2020/11/05/ICS/ICS_Lab1/index.html","hash":"b138848e7062fd7b046604cbc806ae79504b8689","modified":1616499106815},{"_id":"public/index.html","hash":"d632e24bc476f1be7a9c362bd7b1dd3e7339f321","modified":1616499106815},{"_id":"public/page/2/index.html","hash":"60e6d64fa7ce56c664b8a09abae0e37c9f3a99ad","modified":1616499106815},{"_id":"public/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1616499106815},{"_id":"public/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1616499106815},{"_id":"public/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1616499106815},{"_id":"public/CNAME","hash":"51544cd37f2188326b08d74bd5b18cde71d558ac","modified":1616499106815},{"_id":"public/img/Pic/Recent.jpeg","hash":"a894cbfcd2ef37457d03c1eafd83b50842fffdbc","modified":1616499106815},{"_id":"public/img/Pic/cnn_img.jpeg","hash":"7ceabac10778f93a977196eb371197062cff2319","modified":1616499106815},{"_id":"public/img/default.png","hash":"7bb2b8ee07db305bcadee2985b81b942027ae940","modified":1616499106815},{"_id":"public/js/boot.js","hash":"bb6780447ebeaa69a3cc08b6c0b1a8ddb39d5fbd","modified":1616499106815},{"_id":"public/css/gitalk.css","hash":"2234d7496740d11b5b53aaaef9155dcb2c6f3f73","modified":1616499106815},{"_id":"public/js/color-schema.js","hash":"0d15189ddd7b9eadf856c726358ac0ac5b24a2ee","modified":1616499106815},{"_id":"public/js/debouncer.js","hash":"f195b7b767cb7e902290ef1252115b9684ce239b","modified":1616499106815},{"_id":"public/js/events.js","hash":"2b5943b81b257c170658906cc3fa73c80f99c3e4","modified":1616499106815},{"_id":"public/js/lazyload.js","hash":"162f6b8b4e0ac35d67ced30f5ba3bf16fa3c89e8","modified":1616499106815},{"_id":"public/js/leancloud.js","hash":"d16e63e407cd309467934e7d184b33bccfb30853","modified":1616499106815},{"_id":"public/js/duration.js","hash":"3442aaab50477fa24257a87f069fec86281d1d19","modified":1616499106815},{"_id":"public/js/local-search.js","hash":"0746ac1df8338b977823148298b4bba2addf0b91","modified":1616499106815},{"_id":"public/js/plugins.js","hash":"1096ab2d770ac6450cc682fdf987275aaf3f9e69","modified":1616499106815},{"_id":"public/js/utils.js","hash":"7667875eba3e6124b06b291ff47ba9f618e0e520","modified":1616499106815},{"_id":"public/lib/hint/hint.min.css","hash":"b38df228460ebfb4c0b6085336ee2878fe85aafe","modified":1616499106815},{"_id":"public/css/main.css","hash":"27e7b83f06a31af2b6c05e01def2ea87ab147eca","modified":1616499106815}],"Category":[{"name":"ICS","_id":"ckmlxty3l0003s8pd3mtx9oy9"},{"name":"TODO","_id":"ckmlxty3p0008s8pdbe7acy6i"},{"name":"Summary","_id":"ckmlxty3r000es8pd0d9m35ym"},{"name":"CS231n","_id":"ckmlxty3t000ks8pd733l2uzz"},{"name":"DataStructure","_id":"ckmlxty44001fs8pd15czacj1"},{"name":"Research","_id":"ckmlxty47001ms8pd02wp1gpv"},{"name":"Object Detection","parent":"ckmlxty47001ms8pd02wp1gpv","_id":"ckmlxty4b0029s8pdbmf80hqs"}],"Data":[],"Page":[{"title":"about","date":"2020-02-23T11:20:33.000Z","layout":"about","_content":"\n","source":"about/index.md","raw":"---\ntitle: about\ndate: 2020-02-23 19:20:33\nlayout: about\n---\n\n","updated":"2020-11-05T14:22:47.518Z","path":"about/index.html","comments":1,"_id":"ckmlxty3e0000s8pd5ghz1u61","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"ELF头简介","date":"2021-03-22T03:48:36.000Z","index_img":"/img/ICS_Lab1/top.jpg","_content":"\n*项目地址： https://github.com/ZiYang-xie/Readelf* （My Readelf Implement）\n\n---\n\n​\t在linux中我们常用readelf指令来读取ELF (Executable and Linkable Format) 文件中的信息，本文首先介绍ELF头的基本信息，在下篇文章中将会介绍一下个人实现的一个简单的读取ELF头的程序，等效于readelf -h <file>\n\n![ELF文件结构](https://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Elf-layout--en.svg/260px-Elf-layout--en.svg.png)\n\n### ELF头\n\nelf头是位于elf文件的头部，里面存储着一些机器和该ELF文件的基本信息。\n\n```c\ntypedef struct {\n        unsigned char   e_ident[EI_NIDENT];\n        Elf64_Half      e_type;\n        Elf64_Half      e_machine;\n        Elf64_Word      e_version;\n        Elf64_Addr      e_entry;\n        Elf64_Off       e_phoff;\n        Elf64_Off       e_shoff;\n        Elf64_Word      e_flags;\n        Elf64_Half      e_ehsize;\n        Elf64_Half      e_phentsize;\n        Elf64_Half      e_phnum;\n        Elf64_Half      e_shentsize;\n        Elf64_Half      e_shnum;\n        Elf64_Half      e_shstrndx;\n} Elf64_Ehdr;\n```\n\n我们分别介绍其含义\n\n---\n\n#### 1、e_ident\n\n- **长度：16字节**\n- **简介：包含着文件和操作系统信息**\n- <img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosklimwgzj30m00fmq55.jpg\" style=\"zoom:50%;\" />\n\n##### Magic Num - e_ident[0:3]\n\n​\t前四个字节包含着一个 magic number，表示该文件是一个 ELF 文件\n\n##### EI_Class - e_ident[4]\n\n​\t指示文件类型，是ELF32还是ELF64位\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskl3oqhyj30dq05qq3h.jpg\" style=\"zoom:50%;\" />\n\n##### EI_DATA - e_ident[5]\n\n​\t指示文件的编码方式，是大端法还是小端法\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskkp5pdjj30fy05ggm5.jpg\" style=\"zoom:50%;\" />\n\n​\t**ELFDATA2LSB - 小端法**\n\n​\t**ELFDATA2MSB - 大端法**\n\n##### EI_Version - e_ident[6]\n\n​\t标识ELF Version, 该值等于EV_CURRENT，目前为1\n\n##### EI_OSABI - e_ident[7]\n\n​\t表示着该文件运行的操作系统\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskk8xx2wj30oi0jmadb.jpg\" alt=\"操作系统类型对应\" style=\"zoom:50%;\" />\n\n##### EI_ABIVERSION - e_ident[8]\n\n​\t标志着 ABI （应用二进制接口）的版本，ABI相当于硬件层级的API（见下图）\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosknnji29j31400u0qd8.jpg\" alt=\"ABI解释\" style=\"zoom:40%;\" />\n\n##### EI_PAD - e_ident[8:15]\n\n​\t填充位，用零填充用以对齐，可以预留给未来使用\n\n\n\n#### 2、e_type\n\n- **长度：2字节**\n\n- **简介：**指示文件类型\n\n  <img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm36oov3j30he0da40a.jpg\" style=\"zoom:50%;\" />\n\n​\t\n\n#### 3、e_machine\n\n- **长度：2字节**\n\n- **简介：**指示机器类型\n\n  <img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm42l3lxj30u00x2wkc.jpg\" alt=\"部分机器类型\" style=\"zoom:50%;\" />\n\n\n\n#### 4、e_version\n\n​\t**长度：4字节**\n\n​\t**简介：指示文件版本**\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm8c0knij30dk04gglx.jpg\" style=\"zoom:50%;\" />\n\n#### 5、e_entry\n\n​\t**长度：4字节（32位）/8字节（64位）**\n\n​\t**简介：进程开始的虚拟地址**\n\n#### 6、e_phoff\n\n​\t**长度：4字节（32位）/8字节（64位）**\n\n​\t**简介：指向程序头部表的开始**\t\n\n#### 7、e_shoff\n\n​\t**长度：4字节（32位）/8字节（64位）**\n\n​\t**简介：指向节头部表的开始**\t\n\n#### 8、e_flags\n\n​\t**长度：4字节**\n\n​\t**简介：意义取决于目标架构**\t\n\n#### 9、e_ehsize\n\n​\t**长度：2字节**\t\n\n​\t**简介：该文件头部的大小**\n\n#### 10、e_phentsize\n\n​\t**长度：2字节**\t\n\n**简介：程序头部的大小**\t\n\n#### 11、e_phnum\n\n​\t**长度：2字节**\t\n\n​\t**简介：程序头部的条目数**\n\n#### 12、e_shentsize\n\n​\t**长度：2字节**\t\n\n​\t**简介：节头部表的大小**\n\n#### 13、e_shnum\n\n​\t**长度：2字节**\t\n\n​\t**简介：节头部表的条目数**\n\n#### 14、e_shstrndx\n\n​\t**长度：2字节**\t\n\n​\t**简介：节头部表的条目和其位置 (idx) 的对应关系**\n\n---\n\n### Reference\n\n[1] https://en.wikipedia.org/wiki/Executable_and_Linkable_Format\n\n[2] https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html\n\n","source":"_posts/Readelf.md","raw":"---\ntitle: ELF头简介\ndate: 2021-03-22 11:48:36\nindex_img: /img/ICS_Lab1/top.jpg\ncategory: [ICS]\ntags: [Link]\n---\n\n*项目地址： https://github.com/ZiYang-xie/Readelf* （My Readelf Implement）\n\n---\n\n​\t在linux中我们常用readelf指令来读取ELF (Executable and Linkable Format) 文件中的信息，本文首先介绍ELF头的基本信息，在下篇文章中将会介绍一下个人实现的一个简单的读取ELF头的程序，等效于readelf -h <file>\n\n![ELF文件结构](https://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Elf-layout--en.svg/260px-Elf-layout--en.svg.png)\n\n### ELF头\n\nelf头是位于elf文件的头部，里面存储着一些机器和该ELF文件的基本信息。\n\n```c\ntypedef struct {\n        unsigned char   e_ident[EI_NIDENT];\n        Elf64_Half      e_type;\n        Elf64_Half      e_machine;\n        Elf64_Word      e_version;\n        Elf64_Addr      e_entry;\n        Elf64_Off       e_phoff;\n        Elf64_Off       e_shoff;\n        Elf64_Word      e_flags;\n        Elf64_Half      e_ehsize;\n        Elf64_Half      e_phentsize;\n        Elf64_Half      e_phnum;\n        Elf64_Half      e_shentsize;\n        Elf64_Half      e_shnum;\n        Elf64_Half      e_shstrndx;\n} Elf64_Ehdr;\n```\n\n我们分别介绍其含义\n\n---\n\n#### 1、e_ident\n\n- **长度：16字节**\n- **简介：包含着文件和操作系统信息**\n- <img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosklimwgzj30m00fmq55.jpg\" style=\"zoom:50%;\" />\n\n##### Magic Num - e_ident[0:3]\n\n​\t前四个字节包含着一个 magic number，表示该文件是一个 ELF 文件\n\n##### EI_Class - e_ident[4]\n\n​\t指示文件类型，是ELF32还是ELF64位\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskl3oqhyj30dq05qq3h.jpg\" style=\"zoom:50%;\" />\n\n##### EI_DATA - e_ident[5]\n\n​\t指示文件的编码方式，是大端法还是小端法\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskkp5pdjj30fy05ggm5.jpg\" style=\"zoom:50%;\" />\n\n​\t**ELFDATA2LSB - 小端法**\n\n​\t**ELFDATA2MSB - 大端法**\n\n##### EI_Version - e_ident[6]\n\n​\t标识ELF Version, 该值等于EV_CURRENT，目前为1\n\n##### EI_OSABI - e_ident[7]\n\n​\t表示着该文件运行的操作系统\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskk8xx2wj30oi0jmadb.jpg\" alt=\"操作系统类型对应\" style=\"zoom:50%;\" />\n\n##### EI_ABIVERSION - e_ident[8]\n\n​\t标志着 ABI （应用二进制接口）的版本，ABI相当于硬件层级的API（见下图）\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosknnji29j31400u0qd8.jpg\" alt=\"ABI解释\" style=\"zoom:40%;\" />\n\n##### EI_PAD - e_ident[8:15]\n\n​\t填充位，用零填充用以对齐，可以预留给未来使用\n\n\n\n#### 2、e_type\n\n- **长度：2字节**\n\n- **简介：**指示文件类型\n\n  <img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm36oov3j30he0da40a.jpg\" style=\"zoom:50%;\" />\n\n​\t\n\n#### 3、e_machine\n\n- **长度：2字节**\n\n- **简介：**指示机器类型\n\n  <img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm42l3lxj30u00x2wkc.jpg\" alt=\"部分机器类型\" style=\"zoom:50%;\" />\n\n\n\n#### 4、e_version\n\n​\t**长度：4字节**\n\n​\t**简介：指示文件版本**\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm8c0knij30dk04gglx.jpg\" style=\"zoom:50%;\" />\n\n#### 5、e_entry\n\n​\t**长度：4字节（32位）/8字节（64位）**\n\n​\t**简介：进程开始的虚拟地址**\n\n#### 6、e_phoff\n\n​\t**长度：4字节（32位）/8字节（64位）**\n\n​\t**简介：指向程序头部表的开始**\t\n\n#### 7、e_shoff\n\n​\t**长度：4字节（32位）/8字节（64位）**\n\n​\t**简介：指向节头部表的开始**\t\n\n#### 8、e_flags\n\n​\t**长度：4字节**\n\n​\t**简介：意义取决于目标架构**\t\n\n#### 9、e_ehsize\n\n​\t**长度：2字节**\t\n\n​\t**简介：该文件头部的大小**\n\n#### 10、e_phentsize\n\n​\t**长度：2字节**\t\n\n**简介：程序头部的大小**\t\n\n#### 11、e_phnum\n\n​\t**长度：2字节**\t\n\n​\t**简介：程序头部的条目数**\n\n#### 12、e_shentsize\n\n​\t**长度：2字节**\t\n\n​\t**简介：节头部表的大小**\n\n#### 13、e_shnum\n\n​\t**长度：2字节**\t\n\n​\t**简介：节头部表的条目数**\n\n#### 14、e_shstrndx\n\n​\t**长度：2字节**\t\n\n​\t**简介：节头部表的条目和其位置 (idx) 的对应关系**\n\n---\n\n### Reference\n\n[1] https://en.wikipedia.org/wiki/Executable_and_Linkable_Format\n\n[2] https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html\n\n","slug":"Readelf","published":1,"updated":"2021-03-22T05:50:45.444Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty3h0001s8pd3vhk8mmo","content":"<p><em>项目地址： <a href=\"https://github.com/ZiYang-xie/Readelf\">https://github.com/ZiYang-xie/Readelf</a></em> （My Readelf Implement）</p>\n<hr>\n<p>​    在linux中我们常用readelf指令来读取ELF (Executable and Linkable Format) 文件中的信息，本文首先介绍ELF头的基本信息，在下篇文章中将会介绍一下个人实现的一个简单的读取ELF头的程序，等效于readelf -h <file></file></p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Elf-layout--en.svg/260px-Elf-layout--en.svg.png\" alt=\"ELF文件结构\"></p>\n<h3 id=\"ELF头\"><a href=\"#ELF头\" class=\"headerlink\" title=\"ELF头\"></a>ELF头</h3><p>elf头是位于elf文件的头部，里面存储着一些机器和该ELF文件的基本信息。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-keyword\">typedef</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> &#123;</span>\n        <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">char</span>   e_ident[EI_NIDENT];\n        Elf64_Half      e_type;\n        Elf64_Half      e_machine;\n        Elf64_Word      e_version;\n        Elf64_Addr      e_entry;\n        Elf64_Off       e_phoff;\n        Elf64_Off       e_shoff;\n        Elf64_Word      e_flags;\n        Elf64_Half      e_ehsize;\n        Elf64_Half      e_phentsize;\n        Elf64_Half      e_phnum;\n        Elf64_Half      e_shentsize;\n        Elf64_Half      e_shnum;\n        Elf64_Half      e_shstrndx;\n&#125; Elf64_Ehdr;</code></pre>\n<p>我们分别介绍其含义</p>\n<hr>\n<h4 id=\"1、e-ident\"><a href=\"#1、e-ident\" class=\"headerlink\" title=\"1、e_ident\"></a>1、e_ident</h4><ul>\n<li><strong>长度：16字节</strong></li>\n<li><strong>简介：包含着文件和操作系统信息</strong></li>\n<li><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosklimwgzj30m00fmq55.jpg\" style=\"zoom:50%;\"></li>\n</ul>\n<h5 id=\"Magic-Num-e-ident-0-3\"><a href=\"#Magic-Num-e-ident-0-3\" class=\"headerlink\" title=\"Magic Num - e_ident[0:3]\"></a>Magic Num - e_ident[0:3]</h5><p>​    前四个字节包含着一个 magic number，表示该文件是一个 ELF 文件</p>\n<h5 id=\"EI-Class-e-ident-4\"><a href=\"#EI-Class-e-ident-4\" class=\"headerlink\" title=\"EI_Class - e_ident[4]\"></a>EI_Class - e_ident[4]</h5><p>​    指示文件类型，是ELF32还是ELF64位</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskl3oqhyj30dq05qq3h.jpg\" style=\"zoom:50%;\"></p>\n<h5 id=\"EI-DATA-e-ident-5\"><a href=\"#EI-DATA-e-ident-5\" class=\"headerlink\" title=\"EI_DATA - e_ident[5]\"></a>EI_DATA - e_ident[5]</h5><p>​    指示文件的编码方式，是大端法还是小端法</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskkp5pdjj30fy05ggm5.jpg\" style=\"zoom:50%;\"></p>\n<p>​    <strong>ELFDATA2LSB - 小端法</strong></p>\n<p>​    <strong>ELFDATA2MSB - 大端法</strong></p>\n<h5 id=\"EI-Version-e-ident-6\"><a href=\"#EI-Version-e-ident-6\" class=\"headerlink\" title=\"EI_Version - e_ident[6]\"></a>EI_Version - e_ident[6]</h5><p>​    标识ELF Version, 该值等于EV_CURRENT，目前为1</p>\n<h5 id=\"EI-OSABI-e-ident-7\"><a href=\"#EI-OSABI-e-ident-7\" class=\"headerlink\" title=\"EI_OSABI - e_ident[7]\"></a>EI_OSABI - e_ident[7]</h5><p>​    表示着该文件运行的操作系统</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskk8xx2wj30oi0jmadb.jpg\" alt=\"操作系统类型对应\" style=\"zoom:50%;\"></p>\n<h5 id=\"EI-ABIVERSION-e-ident-8\"><a href=\"#EI-ABIVERSION-e-ident-8\" class=\"headerlink\" title=\"EI_ABIVERSION - e_ident[8]\"></a>EI_ABIVERSION - e_ident[8]</h5><p>​    标志着 ABI （应用二进制接口）的版本，ABI相当于硬件层级的API（见下图）</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosknnji29j31400u0qd8.jpg\" alt=\"ABI解释\" style=\"zoom:40%;\"></p>\n<h5 id=\"EI-PAD-e-ident-8-15\"><a href=\"#EI-PAD-e-ident-8-15\" class=\"headerlink\" title=\"EI_PAD - e_ident[8:15]\"></a>EI_PAD - e_ident[8:15]</h5><p>​    填充位，用零填充用以对齐，可以预留给未来使用</p>\n<h4 id=\"2、e-type\"><a href=\"#2、e-type\" class=\"headerlink\" title=\"2、e_type\"></a>2、e_type</h4><ul>\n<li><p><strong>长度：2字节</strong></p>\n</li>\n<li><p><strong>简介：</strong>指示文件类型</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm36oov3j30he0da40a.jpg\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n<p>​    </p>\n<h4 id=\"3、e-machine\"><a href=\"#3、e-machine\" class=\"headerlink\" title=\"3、e_machine\"></a>3、e_machine</h4><ul>\n<li><p><strong>长度：2字节</strong></p>\n</li>\n<li><p><strong>简介：</strong>指示机器类型</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm42l3lxj30u00x2wkc.jpg\" alt=\"部分机器类型\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n<h4 id=\"4、e-version\"><a href=\"#4、e-version\" class=\"headerlink\" title=\"4、e_version\"></a>4、e_version</h4><p>​    <strong>长度：4字节</strong></p>\n<p>​    <strong>简介：指示文件版本</strong></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm8c0knij30dk04gglx.jpg\" style=\"zoom:50%;\"></p>\n<h4 id=\"5、e-entry\"><a href=\"#5、e-entry\" class=\"headerlink\" title=\"5、e_entry\"></a>5、e_entry</h4><p>​    <strong>长度：4字节（32位）/8字节（64位）</strong></p>\n<p>​    <strong>简介：进程开始的虚拟地址</strong></p>\n<h4 id=\"6、e-phoff\"><a href=\"#6、e-phoff\" class=\"headerlink\" title=\"6、e_phoff\"></a>6、e_phoff</h4><p>​    <strong>长度：4字节（32位）/8字节（64位）</strong></p>\n<p>​    <strong>简介：指向程序头部表的开始</strong>    </p>\n<h4 id=\"7、e-shoff\"><a href=\"#7、e-shoff\" class=\"headerlink\" title=\"7、e_shoff\"></a>7、e_shoff</h4><p>​    <strong>长度：4字节（32位）/8字节（64位）</strong></p>\n<p>​    <strong>简介：指向节头部表的开始</strong>    </p>\n<h4 id=\"8、e-flags\"><a href=\"#8、e-flags\" class=\"headerlink\" title=\"8、e_flags\"></a>8、e_flags</h4><p>​    <strong>长度：4字节</strong></p>\n<p>​    <strong>简介：意义取决于目标架构</strong>    </p>\n<h4 id=\"9、e-ehsize\"><a href=\"#9、e-ehsize\" class=\"headerlink\" title=\"9、e_ehsize\"></a>9、e_ehsize</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p>​    <strong>简介：该文件头部的大小</strong></p>\n<h4 id=\"10、e-phentsize\"><a href=\"#10、e-phentsize\" class=\"headerlink\" title=\"10、e_phentsize\"></a>10、e_phentsize</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p><strong>简介：程序头部的大小</strong>    </p>\n<h4 id=\"11、e-phnum\"><a href=\"#11、e-phnum\" class=\"headerlink\" title=\"11、e_phnum\"></a>11、e_phnum</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p>​    <strong>简介：程序头部的条目数</strong></p>\n<h4 id=\"12、e-shentsize\"><a href=\"#12、e-shentsize\" class=\"headerlink\" title=\"12、e_shentsize\"></a>12、e_shentsize</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p>​    <strong>简介：节头部表的大小</strong></p>\n<h4 id=\"13、e-shnum\"><a href=\"#13、e-shnum\" class=\"headerlink\" title=\"13、e_shnum\"></a>13、e_shnum</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p>​    <strong>简介：节头部表的条目数</strong></p>\n<h4 id=\"14、e-shstrndx\"><a href=\"#14、e-shstrndx\" class=\"headerlink\" title=\"14、e_shstrndx\"></a>14、e_shstrndx</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p>​    <strong>简介：节头部表的条目和其位置 (idx) 的对应关系</strong></p>\n<hr>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><p>[1] <a href=\"https://en.wikipedia.org/wiki/Executable_and_Linkable_Format\">https://en.wikipedia.org/wiki/Executable_and_Linkable_Format</a></p>\n<p>[2] <a href=\"https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html\">https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><em>项目地址： <a href=\"https://github.com/ZiYang-xie/Readelf\">https://github.com/ZiYang-xie/Readelf</a></em> （My Readelf Implement）</p>\n<hr>\n<p>​    在linux中我们常用readelf指令来读取ELF (Executable and Linkable Format) 文件中的信息，本文首先介绍ELF头的基本信息，在下篇文章中将会介绍一下个人实现的一个简单的读取ELF头的程序，等效于readelf -h <file></file></p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Elf-layout--en.svg/260px-Elf-layout--en.svg.png\" alt=\"ELF文件结构\"></p>\n<h3 id=\"ELF头\"><a href=\"#ELF头\" class=\"headerlink\" title=\"ELF头\"></a>ELF头</h3><p>elf头是位于elf文件的头部，里面存储着一些机器和该ELF文件的基本信息。</p>\n<pre><code class=\"hljs c\"><span class=\"hljs-keyword\">typedef</span> <span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> &#123;</span>\n        <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">char</span>   e_ident[EI_NIDENT];\n        Elf64_Half      e_type;\n        Elf64_Half      e_machine;\n        Elf64_Word      e_version;\n        Elf64_Addr      e_entry;\n        Elf64_Off       e_phoff;\n        Elf64_Off       e_shoff;\n        Elf64_Word      e_flags;\n        Elf64_Half      e_ehsize;\n        Elf64_Half      e_phentsize;\n        Elf64_Half      e_phnum;\n        Elf64_Half      e_shentsize;\n        Elf64_Half      e_shnum;\n        Elf64_Half      e_shstrndx;\n&#125; Elf64_Ehdr;</code></pre>\n<p>我们分别介绍其含义</p>\n<hr>\n<h4 id=\"1、e-ident\"><a href=\"#1、e-ident\" class=\"headerlink\" title=\"1、e_ident\"></a>1、e_ident</h4><ul>\n<li><strong>长度：16字节</strong></li>\n<li><strong>简介：包含着文件和操作系统信息</strong></li>\n<li><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosklimwgzj30m00fmq55.jpg\" style=\"zoom:50%;\"></li>\n</ul>\n<h5 id=\"Magic-Num-e-ident-0-3\"><a href=\"#Magic-Num-e-ident-0-3\" class=\"headerlink\" title=\"Magic Num - e_ident[0:3]\"></a>Magic Num - e_ident[0:3]</h5><p>​    前四个字节包含着一个 magic number，表示该文件是一个 ELF 文件</p>\n<h5 id=\"EI-Class-e-ident-4\"><a href=\"#EI-Class-e-ident-4\" class=\"headerlink\" title=\"EI_Class - e_ident[4]\"></a>EI_Class - e_ident[4]</h5><p>​    指示文件类型，是ELF32还是ELF64位</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskl3oqhyj30dq05qq3h.jpg\" style=\"zoom:50%;\"></p>\n<h5 id=\"EI-DATA-e-ident-5\"><a href=\"#EI-DATA-e-ident-5\" class=\"headerlink\" title=\"EI_DATA - e_ident[5]\"></a>EI_DATA - e_ident[5]</h5><p>​    指示文件的编码方式，是大端法还是小端法</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskkp5pdjj30fy05ggm5.jpg\" style=\"zoom:50%;\"></p>\n<p>​    <strong>ELFDATA2LSB - 小端法</strong></p>\n<p>​    <strong>ELFDATA2MSB - 大端法</strong></p>\n<h5 id=\"EI-Version-e-ident-6\"><a href=\"#EI-Version-e-ident-6\" class=\"headerlink\" title=\"EI_Version - e_ident[6]\"></a>EI_Version - e_ident[6]</h5><p>​    标识ELF Version, 该值等于EV_CURRENT，目前为1</p>\n<h5 id=\"EI-OSABI-e-ident-7\"><a href=\"#EI-OSABI-e-ident-7\" class=\"headerlink\" title=\"EI_OSABI - e_ident[7]\"></a>EI_OSABI - e_ident[7]</h5><p>​    表示着该文件运行的操作系统</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1goskk8xx2wj30oi0jmadb.jpg\" alt=\"操作系统类型对应\" style=\"zoom:50%;\"></p>\n<h5 id=\"EI-ABIVERSION-e-ident-8\"><a href=\"#EI-ABIVERSION-e-ident-8\" class=\"headerlink\" title=\"EI_ABIVERSION - e_ident[8]\"></a>EI_ABIVERSION - e_ident[8]</h5><p>​    标志着 ABI （应用二进制接口）的版本，ABI相当于硬件层级的API（见下图）</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosknnji29j31400u0qd8.jpg\" alt=\"ABI解释\" style=\"zoom:40%;\"></p>\n<h5 id=\"EI-PAD-e-ident-8-15\"><a href=\"#EI-PAD-e-ident-8-15\" class=\"headerlink\" title=\"EI_PAD - e_ident[8:15]\"></a>EI_PAD - e_ident[8:15]</h5><p>​    填充位，用零填充用以对齐，可以预留给未来使用</p>\n<h4 id=\"2、e-type\"><a href=\"#2、e-type\" class=\"headerlink\" title=\"2、e_type\"></a>2、e_type</h4><ul>\n<li><p><strong>长度：2字节</strong></p>\n</li>\n<li><p><strong>简介：</strong>指示文件类型</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm36oov3j30he0da40a.jpg\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n<p>​    </p>\n<h4 id=\"3、e-machine\"><a href=\"#3、e-machine\" class=\"headerlink\" title=\"3、e_machine\"></a>3、e_machine</h4><ul>\n<li><p><strong>长度：2字节</strong></p>\n</li>\n<li><p><strong>简介：</strong>指示机器类型</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm42l3lxj30u00x2wkc.jpg\" alt=\"部分机器类型\" style=\"zoom:50%;\"></p>\n</li>\n</ul>\n<h4 id=\"4、e-version\"><a href=\"#4、e-version\" class=\"headerlink\" title=\"4、e_version\"></a>4、e_version</h4><p>​    <strong>长度：4字节</strong></p>\n<p>​    <strong>简介：指示文件版本</strong></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEly1gosm8c0knij30dk04gglx.jpg\" style=\"zoom:50%;\"></p>\n<h4 id=\"5、e-entry\"><a href=\"#5、e-entry\" class=\"headerlink\" title=\"5、e_entry\"></a>5、e_entry</h4><p>​    <strong>长度：4字节（32位）/8字节（64位）</strong></p>\n<p>​    <strong>简介：进程开始的虚拟地址</strong></p>\n<h4 id=\"6、e-phoff\"><a href=\"#6、e-phoff\" class=\"headerlink\" title=\"6、e_phoff\"></a>6、e_phoff</h4><p>​    <strong>长度：4字节（32位）/8字节（64位）</strong></p>\n<p>​    <strong>简介：指向程序头部表的开始</strong>    </p>\n<h4 id=\"7、e-shoff\"><a href=\"#7、e-shoff\" class=\"headerlink\" title=\"7、e_shoff\"></a>7、e_shoff</h4><p>​    <strong>长度：4字节（32位）/8字节（64位）</strong></p>\n<p>​    <strong>简介：指向节头部表的开始</strong>    </p>\n<h4 id=\"8、e-flags\"><a href=\"#8、e-flags\" class=\"headerlink\" title=\"8、e_flags\"></a>8、e_flags</h4><p>​    <strong>长度：4字节</strong></p>\n<p>​    <strong>简介：意义取决于目标架构</strong>    </p>\n<h4 id=\"9、e-ehsize\"><a href=\"#9、e-ehsize\" class=\"headerlink\" title=\"9、e_ehsize\"></a>9、e_ehsize</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p>​    <strong>简介：该文件头部的大小</strong></p>\n<h4 id=\"10、e-phentsize\"><a href=\"#10、e-phentsize\" class=\"headerlink\" title=\"10、e_phentsize\"></a>10、e_phentsize</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p><strong>简介：程序头部的大小</strong>    </p>\n<h4 id=\"11、e-phnum\"><a href=\"#11、e-phnum\" class=\"headerlink\" title=\"11、e_phnum\"></a>11、e_phnum</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p>​    <strong>简介：程序头部的条目数</strong></p>\n<h4 id=\"12、e-shentsize\"><a href=\"#12、e-shentsize\" class=\"headerlink\" title=\"12、e_shentsize\"></a>12、e_shentsize</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p>​    <strong>简介：节头部表的大小</strong></p>\n<h4 id=\"13、e-shnum\"><a href=\"#13、e-shnum\" class=\"headerlink\" title=\"13、e_shnum\"></a>13、e_shnum</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p>​    <strong>简介：节头部表的条目数</strong></p>\n<h4 id=\"14、e-shstrndx\"><a href=\"#14、e-shstrndx\" class=\"headerlink\" title=\"14、e_shstrndx\"></a>14、e_shstrndx</h4><p>​    <strong>长度：2字节</strong>    </p>\n<p>​    <strong>简介：节头部表的条目和其位置 (idx) 的对应关系</strong></p>\n<hr>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><p>[1] <a href=\"https://en.wikipedia.org/wiki/Executable_and_Linkable_Format\">https://en.wikipedia.org/wiki/Executable_and_Linkable_Format</a></p>\n<p>[2] <a href=\"https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html\">https://refspecs.linuxfoundation.org/elf/gabi4+/ch4.eheader.html</a></p>\n"},{"title":"期末 DDL + TODOList","date":"2020-12-17T05:04:58.000Z","index_img":"/img/TODO.png","_content":"\n# 期末季DDL\n### 这周的 数据结构/离散/数逻 作业\n#### - 预计需要: 4h+\n\n### 实验室 Reading Group ( *ddl: 12/23 下周三* )\n#### - 预计需要: 2 ~ 3h\n\n### 毛概实践报告 ( *ddl: 12/24 下周四* )\n- 1. 字数5k字\n#### - 预计需要: 2 ~ 3h\n#### - 安排时间：今晚毛概课给它干掉！\n\n### ICSPJ-Stage2 ( *ddl: 12/24 下周四* )\n- 1. 前端优化添加功能 ( 10h )\n- 2. PPT ( 3h )\n#### - 预计需要: 15h+\n\n### 美国文学选读考试 ( *ddl: 12/27 下周日晚上* )\n- 1. 文本复习 ( 5h )\n- 1. 作者复习 ( 5h )\n#### - 预计需要 ( 1day )\n\n### 数据结构上机考 ( *ddl: 12/28 下下周一* )\n- 1. 复习算法 ( 8h )\n- 2. 复习上机题 ( 10h+ )\n#### - 预计需要: 20h+\n\n### 数逻 LAB7 ( *ddl: 12/29 下下周二* )\n#### - 预计需要: 3h+\n\n### 毛概考试 ( *ddl: 12/29 下下周二* )\n- 1. 复习 ( 1h )\n#### - 预计需要: 1h+\n\n### ICS-LAB5 ( *ddl: 12/30 下下周三* )\n#### - 预计需要: 3h\n\n### 近代中国思想与人物期末论文 ( *ddl: 未知* )\n#### - 预计需要: 1day\n\n### 数据结构PJ ( *ddl: 1/3 下下周日* )\n#### - 预计需要: 12h+\n\n### 数据结构考试 ( *ddl: 1/5 下下下周二* )\n- 1. 复习课本 ( 5h )\n#### - 预计需要: 5h+\n\n### 数逻考试 ( *ddl: 1/11 下下下下周一* )\n#### - 预计需要: 1d+\n\n### 离散考试 ( *ddl: 1/12 下下下下周二* )\n#### - 预计需要: 2d+\n","source":"_posts/final_todo.md","raw":"---\ntitle: 期末 DDL + TODOList\ndate: 2020-12-17 13:04:58\nindex_img: /img/TODO.png\ncategory: [TODO]\ntags: TODO\n---\n\n# 期末季DDL\n### 这周的 数据结构/离散/数逻 作业\n#### - 预计需要: 4h+\n\n### 实验室 Reading Group ( *ddl: 12/23 下周三* )\n#### - 预计需要: 2 ~ 3h\n\n### 毛概实践报告 ( *ddl: 12/24 下周四* )\n- 1. 字数5k字\n#### - 预计需要: 2 ~ 3h\n#### - 安排时间：今晚毛概课给它干掉！\n\n### ICSPJ-Stage2 ( *ddl: 12/24 下周四* )\n- 1. 前端优化添加功能 ( 10h )\n- 2. PPT ( 3h )\n#### - 预计需要: 15h+\n\n### 美国文学选读考试 ( *ddl: 12/27 下周日晚上* )\n- 1. 文本复习 ( 5h )\n- 1. 作者复习 ( 5h )\n#### - 预计需要 ( 1day )\n\n### 数据结构上机考 ( *ddl: 12/28 下下周一* )\n- 1. 复习算法 ( 8h )\n- 2. 复习上机题 ( 10h+ )\n#### - 预计需要: 20h+\n\n### 数逻 LAB7 ( *ddl: 12/29 下下周二* )\n#### - 预计需要: 3h+\n\n### 毛概考试 ( *ddl: 12/29 下下周二* )\n- 1. 复习 ( 1h )\n#### - 预计需要: 1h+\n\n### ICS-LAB5 ( *ddl: 12/30 下下周三* )\n#### - 预计需要: 3h\n\n### 近代中国思想与人物期末论文 ( *ddl: 未知* )\n#### - 预计需要: 1day\n\n### 数据结构PJ ( *ddl: 1/3 下下周日* )\n#### - 预计需要: 12h+\n\n### 数据结构考试 ( *ddl: 1/5 下下下周二* )\n- 1. 复习课本 ( 5h )\n#### - 预计需要: 5h+\n\n### 数逻考试 ( *ddl: 1/11 下下下下周一* )\n#### - 预计需要: 1d+\n\n### 离散考试 ( *ddl: 1/12 下下下下周二* )\n#### - 预计需要: 2d+\n","slug":"final_todo","published":1,"updated":"2020-12-17T07:18:24.502Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty3k0002s8pd4l45g0a0","content":"<h1 id=\"期末季DDL\"><a href=\"#期末季DDL\" class=\"headerlink\" title=\"期末季DDL\"></a>期末季DDL</h1><h3 id=\"这周的-数据结构-离散-数逻-作业\"><a href=\"#这周的-数据结构-离散-数逻-作业\" class=\"headerlink\" title=\"这周的 数据结构/离散/数逻 作业\"></a>这周的 数据结构/离散/数逻 作业</h3><h4 id=\"预计需要-4h\"><a href=\"#预计需要-4h\" class=\"headerlink\" title=\"- 预计需要: 4h+\"></a>- 预计需要: 4h+</h4><h3 id=\"实验室-Reading-Group-ddl-12-23-下周三\"><a href=\"#实验室-Reading-Group-ddl-12-23-下周三\" class=\"headerlink\" title=\"实验室 Reading Group ( ddl: 12/23 下周三 )\"></a>实验室 Reading Group ( <em>ddl: 12/23 下周三</em> )</h3><h4 id=\"预计需要-2-3h\"><a href=\"#预计需要-2-3h\" class=\"headerlink\" title=\"- 预计需要: 2 ~ 3h\"></a>- 预计需要: 2 ~ 3h</h4><h3 id=\"毛概实践报告-ddl-12-24-下周四\"><a href=\"#毛概实践报告-ddl-12-24-下周四\" class=\"headerlink\" title=\"毛概实践报告 ( ddl: 12/24 下周四 )\"></a>毛概实践报告 ( <em>ddl: 12/24 下周四</em> )</h3><ul>\n<li><ol>\n<li>字数5k字<h4 id=\"预计需要-2-3h-1\"><a href=\"#预计需要-2-3h-1\" class=\"headerlink\" title=\"- 预计需要: 2 ~ 3h\"></a>- 预计需要: 2 ~ 3h</h4><h4 id=\"安排时间：今晚毛概课给它干掉！\"><a href=\"#安排时间：今晚毛概课给它干掉！\" class=\"headerlink\" title=\"- 安排时间：今晚毛概课给它干掉！\"></a>- 安排时间：今晚毛概课给它干掉！</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"ICSPJ-Stage2-ddl-12-24-下周四\"><a href=\"#ICSPJ-Stage2-ddl-12-24-下周四\" class=\"headerlink\" title=\"ICSPJ-Stage2 ( ddl: 12/24 下周四 )\"></a>ICSPJ-Stage2 ( <em>ddl: 12/24 下周四</em> )</h3><ul>\n<li><ol>\n<li>前端优化添加功能 ( 10h )</li>\n</ol>\n</li>\n<li><ol>\n<li>PPT ( 3h )<h4 id=\"预计需要-15h\"><a href=\"#预计需要-15h\" class=\"headerlink\" title=\"- 预计需要: 15h+\"></a>- 预计需要: 15h+</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"美国文学选读考试-ddl-12-27-下周日晚上\"><a href=\"#美国文学选读考试-ddl-12-27-下周日晚上\" class=\"headerlink\" title=\"美国文学选读考试 ( ddl: 12/27 下周日晚上 )\"></a>美国文学选读考试 ( <em>ddl: 12/27 下周日晚上</em> )</h3><ul>\n<li><ol>\n<li>文本复习 ( 5h )</li>\n</ol>\n</li>\n<li><ol>\n<li>作者复习 ( 5h )<h4 id=\"预计需要-1day\"><a href=\"#预计需要-1day\" class=\"headerlink\" title=\"- 预计需要 ( 1day )\"></a>- 预计需要 ( 1day )</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"数据结构上机考-ddl-12-28-下下周一\"><a href=\"#数据结构上机考-ddl-12-28-下下周一\" class=\"headerlink\" title=\"数据结构上机考 ( ddl: 12/28 下下周一 )\"></a>数据结构上机考 ( <em>ddl: 12/28 下下周一</em> )</h3><ul>\n<li><ol>\n<li>复习算法 ( 8h )</li>\n</ol>\n</li>\n<li><ol>\n<li>复习上机题 ( 10h+ )<h4 id=\"预计需要-20h\"><a href=\"#预计需要-20h\" class=\"headerlink\" title=\"- 预计需要: 20h+\"></a>- 预计需要: 20h+</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"数逻-LAB7-ddl-12-29-下下周二\"><a href=\"#数逻-LAB7-ddl-12-29-下下周二\" class=\"headerlink\" title=\"数逻 LAB7 ( ddl: 12/29 下下周二 )\"></a>数逻 LAB7 ( <em>ddl: 12/29 下下周二</em> )</h3><h4 id=\"预计需要-3h\"><a href=\"#预计需要-3h\" class=\"headerlink\" title=\"- 预计需要: 3h+\"></a>- 预计需要: 3h+</h4><h3 id=\"毛概考试-ddl-12-29-下下周二\"><a href=\"#毛概考试-ddl-12-29-下下周二\" class=\"headerlink\" title=\"毛概考试 ( ddl: 12/29 下下周二 )\"></a>毛概考试 ( <em>ddl: 12/29 下下周二</em> )</h3><ul>\n<li><ol>\n<li>复习 ( 1h )<h4 id=\"预计需要-1h\"><a href=\"#预计需要-1h\" class=\"headerlink\" title=\"- 预计需要: 1h+\"></a>- 预计需要: 1h+</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"ICS-LAB5-ddl-12-30-下下周三\"><a href=\"#ICS-LAB5-ddl-12-30-下下周三\" class=\"headerlink\" title=\"ICS-LAB5 ( ddl: 12/30 下下周三 )\"></a>ICS-LAB5 ( <em>ddl: 12/30 下下周三</em> )</h3><h4 id=\"预计需要-3h-1\"><a href=\"#预计需要-3h-1\" class=\"headerlink\" title=\"- 预计需要: 3h\"></a>- 预计需要: 3h</h4><h3 id=\"近代中国思想与人物期末论文-ddl-未知\"><a href=\"#近代中国思想与人物期末论文-ddl-未知\" class=\"headerlink\" title=\"近代中国思想与人物期末论文 ( ddl: 未知 )\"></a>近代中国思想与人物期末论文 ( <em>ddl: 未知</em> )</h3><h4 id=\"预计需要-1day-1\"><a href=\"#预计需要-1day-1\" class=\"headerlink\" title=\"- 预计需要: 1day\"></a>- 预计需要: 1day</h4><h3 id=\"数据结构PJ-ddl-1-3-下下周日\"><a href=\"#数据结构PJ-ddl-1-3-下下周日\" class=\"headerlink\" title=\"数据结构PJ ( ddl: 1/3 下下周日 )\"></a>数据结构PJ ( <em>ddl: 1/3 下下周日</em> )</h3><h4 id=\"预计需要-12h\"><a href=\"#预计需要-12h\" class=\"headerlink\" title=\"- 预计需要: 12h+\"></a>- 预计需要: 12h+</h4><h3 id=\"数据结构考试-ddl-1-5-下下下周二\"><a href=\"#数据结构考试-ddl-1-5-下下下周二\" class=\"headerlink\" title=\"数据结构考试 ( ddl: 1/5 下下下周二 )\"></a>数据结构考试 ( <em>ddl: 1/5 下下下周二</em> )</h3><ul>\n<li><ol>\n<li>复习课本 ( 5h )<h4 id=\"预计需要-5h\"><a href=\"#预计需要-5h\" class=\"headerlink\" title=\"- 预计需要: 5h+\"></a>- 预计需要: 5h+</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"数逻考试-ddl-1-11-下下下下周一\"><a href=\"#数逻考试-ddl-1-11-下下下下周一\" class=\"headerlink\" title=\"数逻考试 ( ddl: 1/11 下下下下周一 )\"></a>数逻考试 ( <em>ddl: 1/11 下下下下周一</em> )</h3><h4 id=\"预计需要-1d\"><a href=\"#预计需要-1d\" class=\"headerlink\" title=\"- 预计需要: 1d+\"></a>- 预计需要: 1d+</h4><h3 id=\"离散考试-ddl-1-12-下下下下周二\"><a href=\"#离散考试-ddl-1-12-下下下下周二\" class=\"headerlink\" title=\"离散考试 ( ddl: 1/12 下下下下周二 )\"></a>离散考试 ( <em>ddl: 1/12 下下下下周二</em> )</h3><h4 id=\"预计需要-2d\"><a href=\"#预计需要-2d\" class=\"headerlink\" title=\"- 预计需要: 2d+\"></a>- 预计需要: 2d+</h4>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"期末季DDL\"><a href=\"#期末季DDL\" class=\"headerlink\" title=\"期末季DDL\"></a>期末季DDL</h1><h3 id=\"这周的-数据结构-离散-数逻-作业\"><a href=\"#这周的-数据结构-离散-数逻-作业\" class=\"headerlink\" title=\"这周的 数据结构/离散/数逻 作业\"></a>这周的 数据结构/离散/数逻 作业</h3><h4 id=\"预计需要-4h\"><a href=\"#预计需要-4h\" class=\"headerlink\" title=\"- 预计需要: 4h+\"></a>- 预计需要: 4h+</h4><h3 id=\"实验室-Reading-Group-ddl-12-23-下周三\"><a href=\"#实验室-Reading-Group-ddl-12-23-下周三\" class=\"headerlink\" title=\"实验室 Reading Group ( ddl: 12/23 下周三 )\"></a>实验室 Reading Group ( <em>ddl: 12/23 下周三</em> )</h3><h4 id=\"预计需要-2-3h\"><a href=\"#预计需要-2-3h\" class=\"headerlink\" title=\"- 预计需要: 2 ~ 3h\"></a>- 预计需要: 2 ~ 3h</h4><h3 id=\"毛概实践报告-ddl-12-24-下周四\"><a href=\"#毛概实践报告-ddl-12-24-下周四\" class=\"headerlink\" title=\"毛概实践报告 ( ddl: 12/24 下周四 )\"></a>毛概实践报告 ( <em>ddl: 12/24 下周四</em> )</h3><ul>\n<li><ol>\n<li>字数5k字<h4 id=\"预计需要-2-3h-1\"><a href=\"#预计需要-2-3h-1\" class=\"headerlink\" title=\"- 预计需要: 2 ~ 3h\"></a>- 预计需要: 2 ~ 3h</h4><h4 id=\"安排时间：今晚毛概课给它干掉！\"><a href=\"#安排时间：今晚毛概课给它干掉！\" class=\"headerlink\" title=\"- 安排时间：今晚毛概课给它干掉！\"></a>- 安排时间：今晚毛概课给它干掉！</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"ICSPJ-Stage2-ddl-12-24-下周四\"><a href=\"#ICSPJ-Stage2-ddl-12-24-下周四\" class=\"headerlink\" title=\"ICSPJ-Stage2 ( ddl: 12/24 下周四 )\"></a>ICSPJ-Stage2 ( <em>ddl: 12/24 下周四</em> )</h3><ul>\n<li><ol>\n<li>前端优化添加功能 ( 10h )</li>\n</ol>\n</li>\n<li><ol>\n<li>PPT ( 3h )<h4 id=\"预计需要-15h\"><a href=\"#预计需要-15h\" class=\"headerlink\" title=\"- 预计需要: 15h+\"></a>- 预计需要: 15h+</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"美国文学选读考试-ddl-12-27-下周日晚上\"><a href=\"#美国文学选读考试-ddl-12-27-下周日晚上\" class=\"headerlink\" title=\"美国文学选读考试 ( ddl: 12/27 下周日晚上 )\"></a>美国文学选读考试 ( <em>ddl: 12/27 下周日晚上</em> )</h3><ul>\n<li><ol>\n<li>文本复习 ( 5h )</li>\n</ol>\n</li>\n<li><ol>\n<li>作者复习 ( 5h )<h4 id=\"预计需要-1day\"><a href=\"#预计需要-1day\" class=\"headerlink\" title=\"- 预计需要 ( 1day )\"></a>- 预计需要 ( 1day )</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"数据结构上机考-ddl-12-28-下下周一\"><a href=\"#数据结构上机考-ddl-12-28-下下周一\" class=\"headerlink\" title=\"数据结构上机考 ( ddl: 12/28 下下周一 )\"></a>数据结构上机考 ( <em>ddl: 12/28 下下周一</em> )</h3><ul>\n<li><ol>\n<li>复习算法 ( 8h )</li>\n</ol>\n</li>\n<li><ol>\n<li>复习上机题 ( 10h+ )<h4 id=\"预计需要-20h\"><a href=\"#预计需要-20h\" class=\"headerlink\" title=\"- 预计需要: 20h+\"></a>- 预计需要: 20h+</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"数逻-LAB7-ddl-12-29-下下周二\"><a href=\"#数逻-LAB7-ddl-12-29-下下周二\" class=\"headerlink\" title=\"数逻 LAB7 ( ddl: 12/29 下下周二 )\"></a>数逻 LAB7 ( <em>ddl: 12/29 下下周二</em> )</h3><h4 id=\"预计需要-3h\"><a href=\"#预计需要-3h\" class=\"headerlink\" title=\"- 预计需要: 3h+\"></a>- 预计需要: 3h+</h4><h3 id=\"毛概考试-ddl-12-29-下下周二\"><a href=\"#毛概考试-ddl-12-29-下下周二\" class=\"headerlink\" title=\"毛概考试 ( ddl: 12/29 下下周二 )\"></a>毛概考试 ( <em>ddl: 12/29 下下周二</em> )</h3><ul>\n<li><ol>\n<li>复习 ( 1h )<h4 id=\"预计需要-1h\"><a href=\"#预计需要-1h\" class=\"headerlink\" title=\"- 预计需要: 1h+\"></a>- 预计需要: 1h+</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"ICS-LAB5-ddl-12-30-下下周三\"><a href=\"#ICS-LAB5-ddl-12-30-下下周三\" class=\"headerlink\" title=\"ICS-LAB5 ( ddl: 12/30 下下周三 )\"></a>ICS-LAB5 ( <em>ddl: 12/30 下下周三</em> )</h3><h4 id=\"预计需要-3h-1\"><a href=\"#预计需要-3h-1\" class=\"headerlink\" title=\"- 预计需要: 3h\"></a>- 预计需要: 3h</h4><h3 id=\"近代中国思想与人物期末论文-ddl-未知\"><a href=\"#近代中国思想与人物期末论文-ddl-未知\" class=\"headerlink\" title=\"近代中国思想与人物期末论文 ( ddl: 未知 )\"></a>近代中国思想与人物期末论文 ( <em>ddl: 未知</em> )</h3><h4 id=\"预计需要-1day-1\"><a href=\"#预计需要-1day-1\" class=\"headerlink\" title=\"- 预计需要: 1day\"></a>- 预计需要: 1day</h4><h3 id=\"数据结构PJ-ddl-1-3-下下周日\"><a href=\"#数据结构PJ-ddl-1-3-下下周日\" class=\"headerlink\" title=\"数据结构PJ ( ddl: 1/3 下下周日 )\"></a>数据结构PJ ( <em>ddl: 1/3 下下周日</em> )</h3><h4 id=\"预计需要-12h\"><a href=\"#预计需要-12h\" class=\"headerlink\" title=\"- 预计需要: 12h+\"></a>- 预计需要: 12h+</h4><h3 id=\"数据结构考试-ddl-1-5-下下下周二\"><a href=\"#数据结构考试-ddl-1-5-下下下周二\" class=\"headerlink\" title=\"数据结构考试 ( ddl: 1/5 下下下周二 )\"></a>数据结构考试 ( <em>ddl: 1/5 下下下周二</em> )</h3><ul>\n<li><ol>\n<li>复习课本 ( 5h )<h4 id=\"预计需要-5h\"><a href=\"#预计需要-5h\" class=\"headerlink\" title=\"- 预计需要: 5h+\"></a>- 预计需要: 5h+</h4></li>\n</ol>\n</li>\n</ul>\n<h3 id=\"数逻考试-ddl-1-11-下下下下周一\"><a href=\"#数逻考试-ddl-1-11-下下下下周一\" class=\"headerlink\" title=\"数逻考试 ( ddl: 1/11 下下下下周一 )\"></a>数逻考试 ( <em>ddl: 1/11 下下下下周一</em> )</h3><h4 id=\"预计需要-1d\"><a href=\"#预计需要-1d\" class=\"headerlink\" title=\"- 预计需要: 1d+\"></a>- 预计需要: 1d+</h4><h3 id=\"离散考试-ddl-1-12-下下下下周二\"><a href=\"#离散考试-ddl-1-12-下下下下周二\" class=\"headerlink\" title=\"离散考试 ( ddl: 1/12 下下下下周二 )\"></a>离散考试 ( <em>ddl: 1/12 下下下下周二</em> )</h3><h4 id=\"预计需要-2d\"><a href=\"#预计需要-2d\" class=\"headerlink\" title=\"- 预计需要: 2d+\"></a>- 预计需要: 2d+</h4>"},{"title":"近期进展 (2020-11-15 ~ 2020-11-27)","index_img":"/img/Pic/Recent.jpeg","date":"2020-11-27T06:45:21.000Z","_content":"\n# 最近进展\n\n近来比较忙，一直没时间写博客，就暂将这段时间的进展写作一个综述发在博客上\n\n---\n\n## **学业方面**\n### 数据结构 - DataStructure\n数据结构这几周以来都是学的树相关的操作, 对树的相关操作进行了学习和进一步的探究\n\n#### 已经掌握\n\n##### 树的储存\n1. 邻接表形式\n```cpp\nstd::vector<int> Tree[Max]\n```\n\n1. 链式前向星形式\n```cpp\nstruct edge\n{\n    int v;\n    int w;\n    int nex;\n};\n\nedge e[Max];\nint head[Max], cnt = 0; // init -1\n\nvoid add_edge(int u, int v)\n{\n    e[cnt].v = v;\n    e[cnt].w = w;\n    e[cnt].nex = head[u];\n    head[u] = cnt++;\n}\n\n//遍历方式\nfor(int i = head[u]; i != -1; i = e[i].nex)\n```\n> 邻接表相比链式前向星更为动态，但有些阴间题会卡掉邻接表\n\n---\n\n##### 深度优先搜索 (dfs)\n\n基本原则是一种与广度优先搜索对立的，能搜到子节点就往子节点走的搜索方式，既“深度”优先，我们熟知的二叉树的前序和后序遍历都是深度优先搜索的一种。\n\n1. 代码实现 (邻接表形式)\n    ```cpp\n    void dfs(int u, int fa)\n    {\n        for(auto& v : tree[u])\n        {\n            if(v == fa)\n                continue;\n            dfs(v, u)\n        }\n    }\n    ```\n    其中 dfs(v,u) 是 dfs 的精华， 指代如若没搜到叶节点那么则继续向深度搜索，这时候当前节点的子节点作为下一个节点，而当前节点成为其子节点的父节点，因而有从 dfs(u, fa) 到 dfs(v, u) 的向深度搜索\n\n2. 前序遍历 - PreOrder (先出根再出子节点)\n    ```cpp\n    void preOrder(TreeNode* root)\n    {\n        if(!root)\n            return;\n        printf(\"%d\\n\", root->val);\n        for(auto child : root->children)\n            preOrder(root->child)    //递归子树\n    }\n    ```\n\n3. 后序遍历 - PosOrder (先出子节点再出根)\n    ```cpp\n    void posOrder(TreeNode* root)\n    {\n        if(!root)\n            return;\n        for(auto child : root->children)\n            preOrder(root->child)    //递归子树\n        printf(\"%d\\n\", root->val);\n    }\n    ```\n\n 通过两次 dfs 我们可以求树的直径，一次 dfs 到直径的端点，再一次求出直径长度。\n\ndfs 所使用的数据结构是栈，这种数据结构隐含在函数的递归调用中，而对于 bfs 所使用的数据结构是队列，我们就需要\n\n---\n\n##### 广(宽)度优先搜索 (bfs)\nbfs 不同于 dfs 是深度优先的搜索，bfs是将同层的节点全部搜索过后再进入到下一次，既注重 \"广度\" 的搜索模式\n\n1. 代码实现 (邻接表形式)\n```cpp\nbfs(s) \n{\n    q = new queue();\n    q.push(s), visited[s] = true;\n    while (!q.empty()) \n    {\n        u = q.pop();\n        for(auto& v : tree[u])\n        {\n            if (!visited[v]) \n            {\n                q.push(v);\n                visited[v] = true;\n            }\n        }\n    }\n}\n```\n\n1. 层序遍历\n    层序遍历就是一种典型的 bfs，先将同层的打印出来之后再深入一层，代码同上。当然也可以通过 dfs 实现层序这时候就要区分节点的层数\n\n```cpp\n//dfs版本层序\nvector<vector<int> > ans;\nvoid dfs(int u, int fa, int level)\n{\n    if(level > ans.size())\n        ans.emplace_back(vector<int>())\n    ans[level - 1].emplace_back(u);\n    for(auto& v : tree[u])\n    {\n        if(v == fa)\n            continue;\n        dfs(v, u, level + 1)\n    }\n}\n```\n\n---\n\n##### 树形dp\n树形dp，顾名思义是在树上进行的dp，在dfs或bfs的过程中进行动态更新。例如通过树形dp求树的直径\n\n```cpp\nint dfs(int u, int fa)\n{\n    vis[x] = 1;\n    int d1 = 0, d2 = 0;\n    int tmp = 0;\n    for(auto& v : tree[u])\n    {\n        if(v == fa)\n            continue;\n        tmp = dfs(v, u) + 1;\n        if(tmp > d1)\n        {\n            d2 = d1;\n            d1 = tmp;\n        }\n        else if(tmp > d2)\n            d2 = tmp;\n        d = max(d, d1 + d2);\n    }\n    return max;\n}\n```\n\n---\n\n#### **尚未熟练 - TODO**\n  1. LCA问题\n  2. 树状数组\n  3. 线段树\n  4. 树链剖分\n\n---\n\n### 计算机系统 - ICS\n\n最近布置了 y86-64 的 PJ，学习了 CPU 的顺序以及流水线设计模式，开始做PJ。\n\n#### PJ进展:\n##### 设计模式 - C with Class\n在面向过程的 Fetch -> Decode -> Execute -> Memory -> WriteBack 基础上套instr的类壳\n\n##### 后端进度\n1. 完成了Prototype设计\n    - 目前 CC 的 OF 有一点 BUG\n2. 完成了 UniTest 的 Generater\n    - 准备用宏改为 gtest 移植到cpp上\n- TODO:\n    1. 完成 python 到 cpp 的移植\n    2. 尝试添加寄存器\n    3. 实现硬件栈\n  \n##### 前端进度\nTODO中，思考如何设计\n- 可选方案:\n  1. Python 作为中间件用 jinja 模板替换\n  2. C++ 作为后端 js 前端接口（学习中）\n  3. CGI\n\n---\n\n## 科研进度 - CNN\n\n### 目前方向\n3D Instance Segmentation\n\n### 论文收集\n 1. (RDCNet)mini ResNet in 2d Instance Seg\n 2. Attention Based 3d instance segmentation\n 3. Learning Gaussian Instance Segmentation in Point Clouds\n 4. 3D Sementic & Instance Segmentation via Salient Point Clustering Optimization\n\n### TODO\n1. 实现 ResNet Backbone\n2. 复现 Fast R-CNN & Mask R-CNN\n","source":"_posts/Recent-Progress (2020-11-15 ~ 2020-11-27).md","raw":"---\ntitle: 近期进展 (2020-11-15 ~ 2020-11-27)\nindex_img: /img/Pic/Recent.jpeg\ndate: 2020-11-27 14:45:21\ncategory: [Summary]\ntags: Summary\n---\n\n# 最近进展\n\n近来比较忙，一直没时间写博客，就暂将这段时间的进展写作一个综述发在博客上\n\n---\n\n## **学业方面**\n### 数据结构 - DataStructure\n数据结构这几周以来都是学的树相关的操作, 对树的相关操作进行了学习和进一步的探究\n\n#### 已经掌握\n\n##### 树的储存\n1. 邻接表形式\n```cpp\nstd::vector<int> Tree[Max]\n```\n\n1. 链式前向星形式\n```cpp\nstruct edge\n{\n    int v;\n    int w;\n    int nex;\n};\n\nedge e[Max];\nint head[Max], cnt = 0; // init -1\n\nvoid add_edge(int u, int v)\n{\n    e[cnt].v = v;\n    e[cnt].w = w;\n    e[cnt].nex = head[u];\n    head[u] = cnt++;\n}\n\n//遍历方式\nfor(int i = head[u]; i != -1; i = e[i].nex)\n```\n> 邻接表相比链式前向星更为动态，但有些阴间题会卡掉邻接表\n\n---\n\n##### 深度优先搜索 (dfs)\n\n基本原则是一种与广度优先搜索对立的，能搜到子节点就往子节点走的搜索方式，既“深度”优先，我们熟知的二叉树的前序和后序遍历都是深度优先搜索的一种。\n\n1. 代码实现 (邻接表形式)\n    ```cpp\n    void dfs(int u, int fa)\n    {\n        for(auto& v : tree[u])\n        {\n            if(v == fa)\n                continue;\n            dfs(v, u)\n        }\n    }\n    ```\n    其中 dfs(v,u) 是 dfs 的精华， 指代如若没搜到叶节点那么则继续向深度搜索，这时候当前节点的子节点作为下一个节点，而当前节点成为其子节点的父节点，因而有从 dfs(u, fa) 到 dfs(v, u) 的向深度搜索\n\n2. 前序遍历 - PreOrder (先出根再出子节点)\n    ```cpp\n    void preOrder(TreeNode* root)\n    {\n        if(!root)\n            return;\n        printf(\"%d\\n\", root->val);\n        for(auto child : root->children)\n            preOrder(root->child)    //递归子树\n    }\n    ```\n\n3. 后序遍历 - PosOrder (先出子节点再出根)\n    ```cpp\n    void posOrder(TreeNode* root)\n    {\n        if(!root)\n            return;\n        for(auto child : root->children)\n            preOrder(root->child)    //递归子树\n        printf(\"%d\\n\", root->val);\n    }\n    ```\n\n 通过两次 dfs 我们可以求树的直径，一次 dfs 到直径的端点，再一次求出直径长度。\n\ndfs 所使用的数据结构是栈，这种数据结构隐含在函数的递归调用中，而对于 bfs 所使用的数据结构是队列，我们就需要\n\n---\n\n##### 广(宽)度优先搜索 (bfs)\nbfs 不同于 dfs 是深度优先的搜索，bfs是将同层的节点全部搜索过后再进入到下一次，既注重 \"广度\" 的搜索模式\n\n1. 代码实现 (邻接表形式)\n```cpp\nbfs(s) \n{\n    q = new queue();\n    q.push(s), visited[s] = true;\n    while (!q.empty()) \n    {\n        u = q.pop();\n        for(auto& v : tree[u])\n        {\n            if (!visited[v]) \n            {\n                q.push(v);\n                visited[v] = true;\n            }\n        }\n    }\n}\n```\n\n1. 层序遍历\n    层序遍历就是一种典型的 bfs，先将同层的打印出来之后再深入一层，代码同上。当然也可以通过 dfs 实现层序这时候就要区分节点的层数\n\n```cpp\n//dfs版本层序\nvector<vector<int> > ans;\nvoid dfs(int u, int fa, int level)\n{\n    if(level > ans.size())\n        ans.emplace_back(vector<int>())\n    ans[level - 1].emplace_back(u);\n    for(auto& v : tree[u])\n    {\n        if(v == fa)\n            continue;\n        dfs(v, u, level + 1)\n    }\n}\n```\n\n---\n\n##### 树形dp\n树形dp，顾名思义是在树上进行的dp，在dfs或bfs的过程中进行动态更新。例如通过树形dp求树的直径\n\n```cpp\nint dfs(int u, int fa)\n{\n    vis[x] = 1;\n    int d1 = 0, d2 = 0;\n    int tmp = 0;\n    for(auto& v : tree[u])\n    {\n        if(v == fa)\n            continue;\n        tmp = dfs(v, u) + 1;\n        if(tmp > d1)\n        {\n            d2 = d1;\n            d1 = tmp;\n        }\n        else if(tmp > d2)\n            d2 = tmp;\n        d = max(d, d1 + d2);\n    }\n    return max;\n}\n```\n\n---\n\n#### **尚未熟练 - TODO**\n  1. LCA问题\n  2. 树状数组\n  3. 线段树\n  4. 树链剖分\n\n---\n\n### 计算机系统 - ICS\n\n最近布置了 y86-64 的 PJ，学习了 CPU 的顺序以及流水线设计模式，开始做PJ。\n\n#### PJ进展:\n##### 设计模式 - C with Class\n在面向过程的 Fetch -> Decode -> Execute -> Memory -> WriteBack 基础上套instr的类壳\n\n##### 后端进度\n1. 完成了Prototype设计\n    - 目前 CC 的 OF 有一点 BUG\n2. 完成了 UniTest 的 Generater\n    - 准备用宏改为 gtest 移植到cpp上\n- TODO:\n    1. 完成 python 到 cpp 的移植\n    2. 尝试添加寄存器\n    3. 实现硬件栈\n  \n##### 前端进度\nTODO中，思考如何设计\n- 可选方案:\n  1. Python 作为中间件用 jinja 模板替换\n  2. C++ 作为后端 js 前端接口（学习中）\n  3. CGI\n\n---\n\n## 科研进度 - CNN\n\n### 目前方向\n3D Instance Segmentation\n\n### 论文收集\n 1. (RDCNet)mini ResNet in 2d Instance Seg\n 2. Attention Based 3d instance segmentation\n 3. Learning Gaussian Instance Segmentation in Point Clouds\n 4. 3D Sementic & Instance Segmentation via Salient Point Clustering Optimization\n\n### TODO\n1. 实现 ResNet Backbone\n2. 复现 Fast R-CNN & Mask R-CNN\n","slug":"Recent-Progress (2020-11-15 ~ 2020-11-27)","published":1,"updated":"2020-12-08T06:31:16.128Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty3m0005s8pd48u1d6qi","content":"<h1 id=\"最近进展\"><a href=\"#最近进展\" class=\"headerlink\" title=\"最近进展\"></a>最近进展</h1><p>近来比较忙，一直没时间写博客，就暂将这段时间的进展写作一个综述发在博客上</p>\n<hr>\n<h2 id=\"学业方面\"><a href=\"#学业方面\" class=\"headerlink\" title=\"学业方面\"></a><strong>学业方面</strong></h2><h3 id=\"数据结构-DataStructure\"><a href=\"#数据结构-DataStructure\" class=\"headerlink\" title=\"数据结构 - DataStructure\"></a>数据结构 - DataStructure</h3><p>数据结构这几周以来都是学的树相关的操作, 对树的相关操作进行了学习和进一步的探究</p>\n<h4 id=\"已经掌握\"><a href=\"#已经掌握\" class=\"headerlink\" title=\"已经掌握\"></a>已经掌握</h4><h5 id=\"树的储存\"><a href=\"#树的储存\" class=\"headerlink\" title=\"树的储存\"></a>树的储存</h5><ol>\n<li><p>邻接表形式</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-built_in\">std</span>::<span class=\"hljs-built_in\">vector</span>&lt;<span class=\"hljs-keyword\">int</span>&gt; Tree[Max]</code></pre>\n</li>\n<li><p>链式前向星形式</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">edge</span></span>\n<span class=\"hljs-class\">&#123;</span>\n    <span class=\"hljs-keyword\">int</span> v;\n    <span class=\"hljs-keyword\">int</span> w;\n    <span class=\"hljs-keyword\">int</span> nex;\n&#125;;\n\nedge e[Max];\n<span class=\"hljs-keyword\">int</span> head[Max], cnt = <span class=\"hljs-number\">0</span>; <span class=\"hljs-comment\">// init -1</span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">add_edge</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> v)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    e[cnt].v = v;\n    e[cnt].w = w;\n    e[cnt].nex = head[u];\n    head[u] = cnt++;\n&#125;\n\n<span class=\"hljs-comment\">//遍历方式</span>\n<span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = head[u]; i != <span class=\"hljs-number\">-1</span>; i = e[i].nex)</code></pre>\n<blockquote>\n<p>邻接表相比链式前向星更为动态，但有些阴间题会卡掉邻接表</p>\n</blockquote>\n</li>\n</ol>\n<hr>\n<h5 id=\"深度优先搜索-dfs\"><a href=\"#深度优先搜索-dfs\" class=\"headerlink\" title=\"深度优先搜索 (dfs)\"></a>深度优先搜索 (dfs)</h5><p>基本原则是一种与广度优先搜索对立的，能搜到子节点就往子节点走的搜索方式，既“深度”优先，我们熟知的二叉树的前序和后序遍历都是深度优先搜索的一种。</p>\n<ol>\n<li><p>代码实现 (邻接表形式)</p>\n <pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">dfs</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span>&amp; v : tree[u])\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(v == fa)\n            <span class=\"hljs-keyword\">continue</span>;\n        dfs(v, u)\n    &#125;\n&#125;</code></pre>\n<p> 其中 dfs(v,u) 是 dfs 的精华， 指代如若没搜到叶节点那么则继续向深度搜索，这时候当前节点的子节点作为下一个节点，而当前节点成为其子节点的父节点，因而有从 dfs(u, fa) 到 dfs(v, u) 的向深度搜索</p>\n</li>\n<li><p>前序遍历 - PreOrder (先出根再出子节点)</p>\n <pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">preOrder</span><span class=\"hljs-params\">(TreeNode* root)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">if</span>(!root)\n        <span class=\"hljs-keyword\">return</span>;\n    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%d\\n&quot;</span>, root-&gt;val);\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span> child : root-&gt;children)\n        preOrder(root-&gt;child)    <span class=\"hljs-comment\">//递归子树</span>\n&#125;</code></pre>\n</li>\n<li><p>后序遍历 - PosOrder (先出子节点再出根)</p>\n <pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">posOrder</span><span class=\"hljs-params\">(TreeNode* root)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">if</span>(!root)\n        <span class=\"hljs-keyword\">return</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span> child : root-&gt;children)\n        preOrder(root-&gt;child)    <span class=\"hljs-comment\">//递归子树</span>\n    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%d\\n&quot;</span>, root-&gt;val);\n&#125;</code></pre>\n<p>通过两次 dfs 我们可以求树的直径，一次 dfs 到直径的端点，再一次求出直径长度。</p>\n</li>\n</ol>\n<p>dfs 所使用的数据结构是栈，这种数据结构隐含在函数的递归调用中，而对于 bfs 所使用的数据结构是队列，我们就需要</p>\n<hr>\n<h5 id=\"广-宽-度优先搜索-bfs\"><a href=\"#广-宽-度优先搜索-bfs\" class=\"headerlink\" title=\"广(宽)度优先搜索 (bfs)\"></a>广(宽)度优先搜索 (bfs)</h5><p>bfs 不同于 dfs 是深度优先的搜索，bfs是将同层的节点全部搜索过后再进入到下一次，既注重 “广度” 的搜索模式</p>\n<ol>\n<li><p>代码实现 (邻接表形式)</p>\n<pre><code class=\"hljs cpp\">bfs(s) \n&#123;\n    q = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">queue</span>();\n    q.push(s), visited[s] = <span class=\"hljs-literal\">true</span>;\n    <span class=\"hljs-keyword\">while</span> (!q.empty()) \n    &#123;\n        u = q.pop();\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span>&amp; v : tree[u])\n        &#123;\n            <span class=\"hljs-keyword\">if</span> (!visited[v]) \n            &#123;\n                q.push(v);\n                visited[v] = <span class=\"hljs-literal\">true</span>;\n            &#125;\n        &#125;\n    &#125;\n&#125;</code></pre>\n</li>\n<li><p>层序遍历<br> 层序遍历就是一种典型的 bfs，先将同层的打印出来之后再深入一层，代码同上。当然也可以通过 dfs 实现层序这时候就要区分节点的层数</p>\n</li>\n</ol>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">//dfs版本层序</span>\n<span class=\"hljs-built_in\">vector</span>&lt;<span class=\"hljs-built_in\">vector</span>&lt;<span class=\"hljs-keyword\">int</span>&gt; &gt; ans;\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">dfs</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa, <span class=\"hljs-keyword\">int</span> level)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">if</span>(level &gt; ans.size())\n        ans.emplace_back(<span class=\"hljs-built_in\">vector</span>&lt;<span class=\"hljs-keyword\">int</span>&gt;())\n    ans[level - <span class=\"hljs-number\">1</span>].emplace_back(u);\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span>&amp; v : tree[u])\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(v == fa)\n            <span class=\"hljs-keyword\">continue</span>;\n        dfs(v, u, level + <span class=\"hljs-number\">1</span>)\n    &#125;\n&#125;</code></pre>\n<hr>\n<h5 id=\"树形dp\"><a href=\"#树形dp\" class=\"headerlink\" title=\"树形dp\"></a>树形dp</h5><p>树形dp，顾名思义是在树上进行的dp，在dfs或bfs的过程中进行动态更新。例如通过树形dp求树的直径</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">dfs</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    vis[x] = <span class=\"hljs-number\">1</span>;\n    <span class=\"hljs-keyword\">int</span> d1 = <span class=\"hljs-number\">0</span>, d2 = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">int</span> tmp = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span>&amp; v : tree[u])\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(v == fa)\n            <span class=\"hljs-keyword\">continue</span>;\n        tmp = dfs(v, u) + <span class=\"hljs-number\">1</span>;\n        <span class=\"hljs-keyword\">if</span>(tmp &gt; d1)\n        &#123;\n            d2 = d1;\n            d1 = tmp;\n        &#125;\n        <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(tmp &gt; d2)\n            d2 = tmp;\n        d = max(d, d1 + d2);\n    &#125;\n    <span class=\"hljs-keyword\">return</span> max;\n&#125;</code></pre>\n<hr>\n<h4 id=\"尚未熟练-TODO\"><a href=\"#尚未熟练-TODO\" class=\"headerlink\" title=\"尚未熟练 - TODO\"></a><strong>尚未熟练 - TODO</strong></h4><ol>\n<li>LCA问题</li>\n<li>树状数组</li>\n<li>线段树</li>\n<li>树链剖分</li>\n</ol>\n<hr>\n<h3 id=\"计算机系统-ICS\"><a href=\"#计算机系统-ICS\" class=\"headerlink\" title=\"计算机系统 - ICS\"></a>计算机系统 - ICS</h3><p>最近布置了 y86-64 的 PJ，学习了 CPU 的顺序以及流水线设计模式，开始做PJ。</p>\n<h4 id=\"PJ进展\"><a href=\"#PJ进展\" class=\"headerlink\" title=\"PJ进展:\"></a>PJ进展:</h4><h5 id=\"设计模式-C-with-Class\"><a href=\"#设计模式-C-with-Class\" class=\"headerlink\" title=\"设计模式 - C with Class\"></a>设计模式 - C with Class</h5><p>在面向过程的 Fetch -&gt; Decode -&gt; Execute -&gt; Memory -&gt; WriteBack 基础上套instr的类壳</p>\n<h5 id=\"后端进度\"><a href=\"#后端进度\" class=\"headerlink\" title=\"后端进度\"></a>后端进度</h5><ol>\n<li>完成了Prototype设计<ul>\n<li>目前 CC 的 OF 有一点 BUG</li>\n</ul>\n</li>\n<li>完成了 UniTest 的 Generater<ul>\n<li>准备用宏改为 gtest 移植到cpp上</li>\n</ul>\n</li>\n</ol>\n<ul>\n<li>TODO:<ol>\n<li>完成 python 到 cpp 的移植</li>\n<li>尝试添加寄存器</li>\n<li>实现硬件栈</li>\n</ol>\n</li>\n</ul>\n<h5 id=\"前端进度\"><a href=\"#前端进度\" class=\"headerlink\" title=\"前端进度\"></a>前端进度</h5><p>TODO中，思考如何设计</p>\n<ul>\n<li>可选方案:<ol>\n<li>Python 作为中间件用 jinja 模板替换</li>\n<li>C++ 作为后端 js 前端接口（学习中）</li>\n<li>CGI</li>\n</ol>\n</li>\n</ul>\n<hr>\n<h2 id=\"科研进度-CNN\"><a href=\"#科研进度-CNN\" class=\"headerlink\" title=\"科研进度 - CNN\"></a>科研进度 - CNN</h2><h3 id=\"目前方向\"><a href=\"#目前方向\" class=\"headerlink\" title=\"目前方向\"></a>目前方向</h3><p>3D Instance Segmentation</p>\n<h3 id=\"论文收集\"><a href=\"#论文收集\" class=\"headerlink\" title=\"论文收集\"></a>论文收集</h3><ol>\n<li>(RDCNet)mini ResNet in 2d Instance Seg</li>\n<li>Attention Based 3d instance segmentation</li>\n<li>Learning Gaussian Instance Segmentation in Point Clouds</li>\n<li>3D Sementic &amp; Instance Segmentation via Salient Point Clustering Optimization</li>\n</ol>\n<h3 id=\"TODO\"><a href=\"#TODO\" class=\"headerlink\" title=\"TODO\"></a>TODO</h3><ol>\n<li>实现 ResNet Backbone</li>\n<li>复现 Fast R-CNN &amp; Mask R-CNN</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"最近进展\"><a href=\"#最近进展\" class=\"headerlink\" title=\"最近进展\"></a>最近进展</h1><p>近来比较忙，一直没时间写博客，就暂将这段时间的进展写作一个综述发在博客上</p>\n<hr>\n<h2 id=\"学业方面\"><a href=\"#学业方面\" class=\"headerlink\" title=\"学业方面\"></a><strong>学业方面</strong></h2><h3 id=\"数据结构-DataStructure\"><a href=\"#数据结构-DataStructure\" class=\"headerlink\" title=\"数据结构 - DataStructure\"></a>数据结构 - DataStructure</h3><p>数据结构这几周以来都是学的树相关的操作, 对树的相关操作进行了学习和进一步的探究</p>\n<h4 id=\"已经掌握\"><a href=\"#已经掌握\" class=\"headerlink\" title=\"已经掌握\"></a>已经掌握</h4><h5 id=\"树的储存\"><a href=\"#树的储存\" class=\"headerlink\" title=\"树的储存\"></a>树的储存</h5><ol>\n<li><p>邻接表形式</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-built_in\">std</span>::<span class=\"hljs-built_in\">vector</span>&lt;<span class=\"hljs-keyword\">int</span>&gt; Tree[Max]</code></pre>\n</li>\n<li><p>链式前向星形式</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">edge</span></span>\n<span class=\"hljs-class\">&#123;</span>\n    <span class=\"hljs-keyword\">int</span> v;\n    <span class=\"hljs-keyword\">int</span> w;\n    <span class=\"hljs-keyword\">int</span> nex;\n&#125;;\n\nedge e[Max];\n<span class=\"hljs-keyword\">int</span> head[Max], cnt = <span class=\"hljs-number\">0</span>; <span class=\"hljs-comment\">// init -1</span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">add_edge</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> v)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    e[cnt].v = v;\n    e[cnt].w = w;\n    e[cnt].nex = head[u];\n    head[u] = cnt++;\n&#125;\n\n<span class=\"hljs-comment\">//遍历方式</span>\n<span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = head[u]; i != <span class=\"hljs-number\">-1</span>; i = e[i].nex)</code></pre>\n<blockquote>\n<p>邻接表相比链式前向星更为动态，但有些阴间题会卡掉邻接表</p>\n</blockquote>\n</li>\n</ol>\n<hr>\n<h5 id=\"深度优先搜索-dfs\"><a href=\"#深度优先搜索-dfs\" class=\"headerlink\" title=\"深度优先搜索 (dfs)\"></a>深度优先搜索 (dfs)</h5><p>基本原则是一种与广度优先搜索对立的，能搜到子节点就往子节点走的搜索方式，既“深度”优先，我们熟知的二叉树的前序和后序遍历都是深度优先搜索的一种。</p>\n<ol>\n<li><p>代码实现 (邻接表形式)</p>\n <pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">dfs</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span>&amp; v : tree[u])\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(v == fa)\n            <span class=\"hljs-keyword\">continue</span>;\n        dfs(v, u)\n    &#125;\n&#125;</code></pre>\n<p> 其中 dfs(v,u) 是 dfs 的精华， 指代如若没搜到叶节点那么则继续向深度搜索，这时候当前节点的子节点作为下一个节点，而当前节点成为其子节点的父节点，因而有从 dfs(u, fa) 到 dfs(v, u) 的向深度搜索</p>\n</li>\n<li><p>前序遍历 - PreOrder (先出根再出子节点)</p>\n <pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">preOrder</span><span class=\"hljs-params\">(TreeNode* root)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">if</span>(!root)\n        <span class=\"hljs-keyword\">return</span>;\n    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%d\\n&quot;</span>, root-&gt;val);\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span> child : root-&gt;children)\n        preOrder(root-&gt;child)    <span class=\"hljs-comment\">//递归子树</span>\n&#125;</code></pre>\n</li>\n<li><p>后序遍历 - PosOrder (先出子节点再出根)</p>\n <pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">posOrder</span><span class=\"hljs-params\">(TreeNode* root)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">if</span>(!root)\n        <span class=\"hljs-keyword\">return</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span> child : root-&gt;children)\n        preOrder(root-&gt;child)    <span class=\"hljs-comment\">//递归子树</span>\n    <span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;%d\\n&quot;</span>, root-&gt;val);\n&#125;</code></pre>\n<p>通过两次 dfs 我们可以求树的直径，一次 dfs 到直径的端点，再一次求出直径长度。</p>\n</li>\n</ol>\n<p>dfs 所使用的数据结构是栈，这种数据结构隐含在函数的递归调用中，而对于 bfs 所使用的数据结构是队列，我们就需要</p>\n<hr>\n<h5 id=\"广-宽-度优先搜索-bfs\"><a href=\"#广-宽-度优先搜索-bfs\" class=\"headerlink\" title=\"广(宽)度优先搜索 (bfs)\"></a>广(宽)度优先搜索 (bfs)</h5><p>bfs 不同于 dfs 是深度优先的搜索，bfs是将同层的节点全部搜索过后再进入到下一次，既注重 “广度” 的搜索模式</p>\n<ol>\n<li><p>代码实现 (邻接表形式)</p>\n<pre><code class=\"hljs cpp\">bfs(s) \n&#123;\n    q = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-built_in\">queue</span>();\n    q.push(s), visited[s] = <span class=\"hljs-literal\">true</span>;\n    <span class=\"hljs-keyword\">while</span> (!q.empty()) \n    &#123;\n        u = q.pop();\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span>&amp; v : tree[u])\n        &#123;\n            <span class=\"hljs-keyword\">if</span> (!visited[v]) \n            &#123;\n                q.push(v);\n                visited[v] = <span class=\"hljs-literal\">true</span>;\n            &#125;\n        &#125;\n    &#125;\n&#125;</code></pre>\n</li>\n<li><p>层序遍历<br> 层序遍历就是一种典型的 bfs，先将同层的打印出来之后再深入一层，代码同上。当然也可以通过 dfs 实现层序这时候就要区分节点的层数</p>\n</li>\n</ol>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">//dfs版本层序</span>\n<span class=\"hljs-built_in\">vector</span>&lt;<span class=\"hljs-built_in\">vector</span>&lt;<span class=\"hljs-keyword\">int</span>&gt; &gt; ans;\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">dfs</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa, <span class=\"hljs-keyword\">int</span> level)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">if</span>(level &gt; ans.size())\n        ans.emplace_back(<span class=\"hljs-built_in\">vector</span>&lt;<span class=\"hljs-keyword\">int</span>&gt;())\n    ans[level - <span class=\"hljs-number\">1</span>].emplace_back(u);\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span>&amp; v : tree[u])\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(v == fa)\n            <span class=\"hljs-keyword\">continue</span>;\n        dfs(v, u, level + <span class=\"hljs-number\">1</span>)\n    &#125;\n&#125;</code></pre>\n<hr>\n<h5 id=\"树形dp\"><a href=\"#树形dp\" class=\"headerlink\" title=\"树形dp\"></a>树形dp</h5><p>树形dp，顾名思义是在树上进行的dp，在dfs或bfs的过程中进行动态更新。例如通过树形dp求树的直径</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">dfs</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    vis[x] = <span class=\"hljs-number\">1</span>;\n    <span class=\"hljs-keyword\">int</span> d1 = <span class=\"hljs-number\">0</span>, d2 = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">int</span> tmp = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span>&amp; v : tree[u])\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(v == fa)\n            <span class=\"hljs-keyword\">continue</span>;\n        tmp = dfs(v, u) + <span class=\"hljs-number\">1</span>;\n        <span class=\"hljs-keyword\">if</span>(tmp &gt; d1)\n        &#123;\n            d2 = d1;\n            d1 = tmp;\n        &#125;\n        <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(tmp &gt; d2)\n            d2 = tmp;\n        d = max(d, d1 + d2);\n    &#125;\n    <span class=\"hljs-keyword\">return</span> max;\n&#125;</code></pre>\n<hr>\n<h4 id=\"尚未熟练-TODO\"><a href=\"#尚未熟练-TODO\" class=\"headerlink\" title=\"尚未熟练 - TODO\"></a><strong>尚未熟练 - TODO</strong></h4><ol>\n<li>LCA问题</li>\n<li>树状数组</li>\n<li>线段树</li>\n<li>树链剖分</li>\n</ol>\n<hr>\n<h3 id=\"计算机系统-ICS\"><a href=\"#计算机系统-ICS\" class=\"headerlink\" title=\"计算机系统 - ICS\"></a>计算机系统 - ICS</h3><p>最近布置了 y86-64 的 PJ，学习了 CPU 的顺序以及流水线设计模式，开始做PJ。</p>\n<h4 id=\"PJ进展\"><a href=\"#PJ进展\" class=\"headerlink\" title=\"PJ进展:\"></a>PJ进展:</h4><h5 id=\"设计模式-C-with-Class\"><a href=\"#设计模式-C-with-Class\" class=\"headerlink\" title=\"设计模式 - C with Class\"></a>设计模式 - C with Class</h5><p>在面向过程的 Fetch -&gt; Decode -&gt; Execute -&gt; Memory -&gt; WriteBack 基础上套instr的类壳</p>\n<h5 id=\"后端进度\"><a href=\"#后端进度\" class=\"headerlink\" title=\"后端进度\"></a>后端进度</h5><ol>\n<li>完成了Prototype设计<ul>\n<li>目前 CC 的 OF 有一点 BUG</li>\n</ul>\n</li>\n<li>完成了 UniTest 的 Generater<ul>\n<li>准备用宏改为 gtest 移植到cpp上</li>\n</ul>\n</li>\n</ol>\n<ul>\n<li>TODO:<ol>\n<li>完成 python 到 cpp 的移植</li>\n<li>尝试添加寄存器</li>\n<li>实现硬件栈</li>\n</ol>\n</li>\n</ul>\n<h5 id=\"前端进度\"><a href=\"#前端进度\" class=\"headerlink\" title=\"前端进度\"></a>前端进度</h5><p>TODO中，思考如何设计</p>\n<ul>\n<li>可选方案:<ol>\n<li>Python 作为中间件用 jinja 模板替换</li>\n<li>C++ 作为后端 js 前端接口（学习中）</li>\n<li>CGI</li>\n</ol>\n</li>\n</ul>\n<hr>\n<h2 id=\"科研进度-CNN\"><a href=\"#科研进度-CNN\" class=\"headerlink\" title=\"科研进度 - CNN\"></a>科研进度 - CNN</h2><h3 id=\"目前方向\"><a href=\"#目前方向\" class=\"headerlink\" title=\"目前方向\"></a>目前方向</h3><p>3D Instance Segmentation</p>\n<h3 id=\"论文收集\"><a href=\"#论文收集\" class=\"headerlink\" title=\"论文收集\"></a>论文收集</h3><ol>\n<li>(RDCNet)mini ResNet in 2d Instance Seg</li>\n<li>Attention Based 3d instance segmentation</li>\n<li>Learning Gaussian Instance Segmentation in Point Clouds</li>\n<li>3D Sementic &amp; Instance Segmentation via Salient Point Clustering Optimization</li>\n</ol>\n<h3 id=\"TODO\"><a href=\"#TODO\" class=\"headerlink\" title=\"TODO\"></a>TODO</h3><ol>\n<li>实现 ResNet Backbone</li>\n<li>复现 Fast R-CNN &amp; Mask R-CNN</li>\n</ol>\n"},{"title":"Hello World","index_img":"/img/hello_world/top.png","date":"2020-11-05T02:00:00.000Z","math":true,"_content":"\n## 第一篇博客用以测试\n\n### 一、 下面是一段C++代码\n```cpp\n#include <iostream>\nusing namespace std;\n\nint main()\n{\n    cout << \"Hello World!\" << endl;\n}\n```\n\n### 二、 下面是一段表格\n\n| 0 | 1 | 2 | 3 | 4 | \n| :---: | :---: | :---: | :---: | :---: |\n| x | x | x | x | x |\n\n### 三、 下面是一段 Latex\n\n\n$$E= mc^2$$\n\n\n### 四、下面是一张图片\n\n![](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRP-ciAYVH8UlH3ZaZC3NkN3ow9CrG36O5crg&usqp=CAU)","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\ntags: [Hexo, Fluid]\nindex_img: /img/hello_world/top.png\ndate: 2020-11-5 10:00:00\nmath: true\n---\n\n## 第一篇博客用以测试\n\n### 一、 下面是一段C++代码\n```cpp\n#include <iostream>\nusing namespace std;\n\nint main()\n{\n    cout << \"Hello World!\" << endl;\n}\n```\n\n### 二、 下面是一段表格\n\n| 0 | 1 | 2 | 3 | 4 | \n| :---: | :---: | :---: | :---: | :---: |\n| x | x | x | x | x |\n\n### 三、 下面是一段 Latex\n\n\n$$E= mc^2$$\n\n\n### 四、下面是一张图片\n\n![](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRP-ciAYVH8UlH3ZaZC3NkN3ow9CrG36O5crg&usqp=CAU)","slug":"hello-world","published":1,"updated":"2020-12-05T14:57:40.957Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty3n0006s8pd3akv7l1s","content":"<h2 id=\"第一篇博客用以测试\"><a href=\"#第一篇博客用以测试\" class=\"headerlink\" title=\"第一篇博客用以测试\"></a>第一篇博客用以测试</h2><h3 id=\"一、-下面是一段C-代码\"><a href=\"#一、-下面是一段C-代码\" class=\"headerlink\" title=\"一、 下面是一段C++代码\"></a>一、 下面是一段C++代码</h3><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;iostream&gt;</span></span>\n<span class=\"hljs-keyword\">using</span> <span class=\"hljs-keyword\">namespace</span> <span class=\"hljs-built_in\">std</span>;\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-built_in\">cout</span> &lt;&lt; <span class=\"hljs-string\">&quot;Hello World!&quot;</span> &lt;&lt; <span class=\"hljs-built_in\">endl</span>;\n&#125;</code></pre>\n<h3 id=\"二、-下面是一段表格\"><a href=\"#二、-下面是一段表格\" class=\"headerlink\" title=\"二、 下面是一段表格\"></a>二、 下面是一段表格</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">0</th>\n<th style=\"text-align:center\">1</th>\n<th style=\"text-align:center\">2</th>\n<th style=\"text-align:center\">3</th>\n<th style=\"text-align:center\">4</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">x</td>\n<td style=\"text-align:center\">x</td>\n<td style=\"text-align:center\">x</td>\n<td style=\"text-align:center\">x</td>\n<td style=\"text-align:center\">x</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"三、-下面是一段-Latex\"><a href=\"#三、-下面是一段-Latex\" class=\"headerlink\" title=\"三、 下面是一段 Latex\"></a>三、 下面是一段 Latex</h3><script type=\"math/tex; mode=display\">E= mc^2</script><h3 id=\"四、下面是一张图片\"><a href=\"#四、下面是一张图片\" class=\"headerlink\" title=\"四、下面是一张图片\"></a>四、下面是一张图片</h3><p><img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRP-ciAYVH8UlH3ZaZC3NkN3ow9CrG36O5crg&amp;usqp=CAU\" alt></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"第一篇博客用以测试\"><a href=\"#第一篇博客用以测试\" class=\"headerlink\" title=\"第一篇博客用以测试\"></a>第一篇博客用以测试</h2><h3 id=\"一、-下面是一段C-代码\"><a href=\"#一、-下面是一段C-代码\" class=\"headerlink\" title=\"一、 下面是一段C++代码\"></a>一、 下面是一段C++代码</h3><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;iostream&gt;</span></span>\n<span class=\"hljs-keyword\">using</span> <span class=\"hljs-keyword\">namespace</span> <span class=\"hljs-built_in\">std</span>;\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-built_in\">cout</span> &lt;&lt; <span class=\"hljs-string\">&quot;Hello World!&quot;</span> &lt;&lt; <span class=\"hljs-built_in\">endl</span>;\n&#125;</code></pre>\n<h3 id=\"二、-下面是一段表格\"><a href=\"#二、-下面是一段表格\" class=\"headerlink\" title=\"二、 下面是一段表格\"></a>二、 下面是一段表格</h3><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">0</th>\n<th style=\"text-align:center\">1</th>\n<th style=\"text-align:center\">2</th>\n<th style=\"text-align:center\">3</th>\n<th style=\"text-align:center\">4</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">x</td>\n<td style=\"text-align:center\">x</td>\n<td style=\"text-align:center\">x</td>\n<td style=\"text-align:center\">x</td>\n<td style=\"text-align:center\">x</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"三、-下面是一段-Latex\"><a href=\"#三、-下面是一段-Latex\" class=\"headerlink\" title=\"三、 下面是一段 Latex\"></a>三、 下面是一段 Latex</h3><script type=\"math/tex; mode=display\">E= mc^2</script><h3 id=\"四、下面是一张图片\"><a href=\"#四、下面是一张图片\" class=\"headerlink\" title=\"四、下面是一张图片\"></a>四、下面是一张图片</h3><p><img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRP-ciAYVH8UlH3ZaZC3NkN3ow9CrG36O5crg&amp;usqp=CAU\" alt></p>\n"},{"title":"CS231n Convolutional_Neural_Networks 04","date":"2020-11-10T16:57:54.000Z","index_img":"/img/Cs231n/top.jpg","math":true,"_content":"\n### A bit of CNN History\n\n![](https://s1.ax1x.com/2020/11/11/BOGJ5n.png)\n\n![](https://s1.ax1x.com/2020/11/11/BOGGUs.png)\n\n#### Fully Connected Layer\n\n![](https://s1.ax1x.com/2020/11/11/BOGlDg.png)\n\n#### Convolution Layer\n\n![](https://s1.ax1x.com/2020/11/11/BOG1bQ.png)\n\n> We just let the 5x5x3 filter $w$ to take a dot product between itself and a small 5x5z3 chunck of the image\n\n$$W^Tx+b$$\n**The $W$ and $x$ is streched into 1 dimention vec**\n\n- Then the Outcome:\n\n![](https://s1.ax1x.com/2020/11/11/BOG8Ej.png)\n\n> We can use different layers on the top of it and get more activation maps stack them together to get a new image, just as the following pic depicted.\n\n![](https://s1.ax1x.com/2020/11/11/BOGtCq.png)\n\n> Then we can recursively do that work, make the front layer's output be the next layer's input\n\n![](https://s1.ax1x.com/2020/11/11/BOGU2V.png)\n\n**The Layers may look like..**\n*Simple -> Complex*\n \n![](https://s1.ax1x.com/2020/11/11/BOGN80.png)\n\n![](https://s1.ax1x.com/2020/11/11/BOGrVJ.png)\n\n- The Convolution of two signals:\n\n$$f[x,y]*g[x,y] = \\sum\\limits_{n_1 = -\\infin}^{\\infin}\\sum\\limits_{n_2 = -\\infin}^{\\infin}f[n_1,n_2]·g[x-n_1,y-n_2]$$\n\n- A little bit preview\n\n![](https://s1.ax1x.com/2020/11/11/BOG0rF.png)\n\n---\n\n- Convolution Box\n\n![](https://s1.ax1x.com/2020/11/11/BOGwKU.png)\n\n> We can tell that the activation maps are becomming smaller after the filter, so we commonly use zero pad to deal with it.\n\n![](https://s1.ax1x.com/2020/11/11/BOGBb4.png)\n\n![](https://s1.ax1x.com/2020/11/11/BOGsa9.png)\n\n> The Matrix shrinks from 32 —> 28 -> 24 (lose info)\n\n---\n\n### Summary\n1. Accepts a volume of size $W_1 * H_1 * D_1$\n2. Four Hyperparas\n    - Number of filters $K$\n    - spatial extent $F$\n    - stride $S$\n    - zero padding amount $P$\n3. Produces a volume of size $W_2 * H_2 * D_2$\n    - $W_2 = (W_1 - F + 2P)/S + 1$\n    - $H_2 = (H_1 - F + 2P)/S + 1$\n    - $D_2 = K$ *Depth keeps the same*\n\n#### Common Settings\n\nK = (powers of 2)\n- F = 3, S = 1, P =1\n- F = 5, S = 1, P =2\n- F = 1, S = 1, P = 0 \n\n---\n\n### Conv details\n\n- One by One CONV\n\n![](https://s1.ax1x.com/2020/11/11/BOGy5R.png)\n\n- EXAMPLE: CONV in pyTorch\n\n![](https://s1.ax1x.com/2020/11/11/BOGRxK.png)\n\n- The Brain/Neuron View of CONV\n\n![](https://s1.ax1x.com/2020/11/11/BOG226.png)\n\n- Pooling layer\n\n![](https://s1.ax1x.com/2020/11/11/BOGg8x.png)\n\n> Just spacially down sample the image to make it smaller.\nCommon Practice is Max Pooling\n\n![](https://s1.ax1x.com/2020/11/11/BOGcP1.png)\n\n> We may can just use stride to replace pooling?\n\n\n","source":"_posts/CS231n/CS231n-04-Convolutional-Neural-Networks.md","raw":"---\ntitle: CS231n Convolutional_Neural_Networks 04\ndate: 2020-11-11 00:57:54\ntags: [CV,Neural Network]\ncategory: [CS231n]\nindex_img: /img/Cs231n/top.jpg\nmath: true\n---\n\n### A bit of CNN History\n\n![](https://s1.ax1x.com/2020/11/11/BOGJ5n.png)\n\n![](https://s1.ax1x.com/2020/11/11/BOGGUs.png)\n\n#### Fully Connected Layer\n\n![](https://s1.ax1x.com/2020/11/11/BOGlDg.png)\n\n#### Convolution Layer\n\n![](https://s1.ax1x.com/2020/11/11/BOG1bQ.png)\n\n> We just let the 5x5x3 filter $w$ to take a dot product between itself and a small 5x5z3 chunck of the image\n\n$$W^Tx+b$$\n**The $W$ and $x$ is streched into 1 dimention vec**\n\n- Then the Outcome:\n\n![](https://s1.ax1x.com/2020/11/11/BOG8Ej.png)\n\n> We can use different layers on the top of it and get more activation maps stack them together to get a new image, just as the following pic depicted.\n\n![](https://s1.ax1x.com/2020/11/11/BOGtCq.png)\n\n> Then we can recursively do that work, make the front layer's output be the next layer's input\n\n![](https://s1.ax1x.com/2020/11/11/BOGU2V.png)\n\n**The Layers may look like..**\n*Simple -> Complex*\n \n![](https://s1.ax1x.com/2020/11/11/BOGN80.png)\n\n![](https://s1.ax1x.com/2020/11/11/BOGrVJ.png)\n\n- The Convolution of two signals:\n\n$$f[x,y]*g[x,y] = \\sum\\limits_{n_1 = -\\infin}^{\\infin}\\sum\\limits_{n_2 = -\\infin}^{\\infin}f[n_1,n_2]·g[x-n_1,y-n_2]$$\n\n- A little bit preview\n\n![](https://s1.ax1x.com/2020/11/11/BOG0rF.png)\n\n---\n\n- Convolution Box\n\n![](https://s1.ax1x.com/2020/11/11/BOGwKU.png)\n\n> We can tell that the activation maps are becomming smaller after the filter, so we commonly use zero pad to deal with it.\n\n![](https://s1.ax1x.com/2020/11/11/BOGBb4.png)\n\n![](https://s1.ax1x.com/2020/11/11/BOGsa9.png)\n\n> The Matrix shrinks from 32 —> 28 -> 24 (lose info)\n\n---\n\n### Summary\n1. Accepts a volume of size $W_1 * H_1 * D_1$\n2. Four Hyperparas\n    - Number of filters $K$\n    - spatial extent $F$\n    - stride $S$\n    - zero padding amount $P$\n3. Produces a volume of size $W_2 * H_2 * D_2$\n    - $W_2 = (W_1 - F + 2P)/S + 1$\n    - $H_2 = (H_1 - F + 2P)/S + 1$\n    - $D_2 = K$ *Depth keeps the same*\n\n#### Common Settings\n\nK = (powers of 2)\n- F = 3, S = 1, P =1\n- F = 5, S = 1, P =2\n- F = 1, S = 1, P = 0 \n\n---\n\n### Conv details\n\n- One by One CONV\n\n![](https://s1.ax1x.com/2020/11/11/BOGy5R.png)\n\n- EXAMPLE: CONV in pyTorch\n\n![](https://s1.ax1x.com/2020/11/11/BOGRxK.png)\n\n- The Brain/Neuron View of CONV\n\n![](https://s1.ax1x.com/2020/11/11/BOG226.png)\n\n- Pooling layer\n\n![](https://s1.ax1x.com/2020/11/11/BOGg8x.png)\n\n> Just spacially down sample the image to make it smaller.\nCommon Practice is Max Pooling\n\n![](https://s1.ax1x.com/2020/11/11/BOGcP1.png)\n\n> We may can just use stride to replace pooling?\n\n\n","slug":"CS231n/CS231n-04-Convolutional-Neural-Networks","published":1,"updated":"2020-12-09T01:22:52.529Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty3o0007s8pdgn6h1v07","content":"<h3 id=\"A-bit-of-CNN-History\"><a href=\"#A-bit-of-CNN-History\" class=\"headerlink\" title=\"A bit of CNN History\"></a>A bit of CNN History</h3><p><img src=\"https://s1.ax1x.com/2020/11/11/BOGJ5n.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGGUs.png\" alt></p>\n<h4 id=\"Fully-Connected-Layer\"><a href=\"#Fully-Connected-Layer\" class=\"headerlink\" title=\"Fully Connected Layer\"></a>Fully Connected Layer</h4><p><img src=\"https://s1.ax1x.com/2020/11/11/BOGlDg.png\" alt></p>\n<h4 id=\"Convolution-Layer\"><a href=\"#Convolution-Layer\" class=\"headerlink\" title=\"Convolution Layer\"></a>Convolution Layer</h4><p><img src=\"https://s1.ax1x.com/2020/11/11/BOG1bQ.png\" alt></p>\n<blockquote>\n<p>We just let the 5x5x3 filter $w$ to take a dot product between itself and a small 5x5z3 chunck of the image</p>\n</blockquote>\n<script type=\"math/tex; mode=display\">W^Tx+b</script><p><strong>The $W$ and $x$ is streched into 1 dimention vec</strong></p>\n<ul>\n<li>Then the Outcome:</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOG8Ej.png\" alt></p>\n<blockquote>\n<p>We can use different layers on the top of it and get more activation maps stack them together to get a new image, just as the following pic depicted.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGtCq.png\" alt></p>\n<blockquote>\n<p>Then we can recursively do that work, make the front layer’s output be the next layer’s input</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGU2V.png\" alt></p>\n<p><strong>The Layers may look like..</strong><br><em>Simple -&gt; Complex</em></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGN80.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGrVJ.png\" alt></p>\n<ul>\n<li>The Convolution of two signals:</li>\n</ul>\n<script type=\"math/tex; mode=display\">f[x,y]*g[x,y] = \\sum\\limits_{n_1 = -\\infin}^{\\infin}\\sum\\limits_{n_2 = -\\infin}^{\\infin}f[n_1,n_2]·g[x-n_1,y-n_2]</script><ul>\n<li>A little bit preview</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOG0rF.png\" alt></p>\n<hr>\n<ul>\n<li>Convolution Box</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGwKU.png\" alt></p>\n<blockquote>\n<p>We can tell that the activation maps are becomming smaller after the filter, so we commonly use zero pad to deal with it.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGBb4.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGsa9.png\" alt></p>\n<blockquote>\n<p>The Matrix shrinks from 32 —&gt; 28 -&gt; 24 (lose info)</p>\n</blockquote>\n<hr>\n<h3 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h3><ol>\n<li>Accepts a volume of size $W_1 <em> H_1 </em> D_1$</li>\n<li>Four Hyperparas<ul>\n<li>Number of filters $K$</li>\n<li>spatial extent $F$</li>\n<li>stride $S$</li>\n<li>zero padding amount $P$</li>\n</ul>\n</li>\n<li>Produces a volume of size $W_2 <em> H_2 </em> D_2$<ul>\n<li>$W_2 = (W_1 - F + 2P)/S + 1$</li>\n<li>$H_2 = (H_1 - F + 2P)/S + 1$</li>\n<li>$D_2 = K$ <em>Depth keeps the same</em></li>\n</ul>\n</li>\n</ol>\n<h4 id=\"Common-Settings\"><a href=\"#Common-Settings\" class=\"headerlink\" title=\"Common Settings\"></a>Common Settings</h4><p>K = (powers of 2)</p>\n<ul>\n<li>F = 3, S = 1, P =1</li>\n<li>F = 5, S = 1, P =2</li>\n<li>F = 1, S = 1, P = 0 </li>\n</ul>\n<hr>\n<h3 id=\"Conv-details\"><a href=\"#Conv-details\" class=\"headerlink\" title=\"Conv details\"></a>Conv details</h3><ul>\n<li>One by One CONV</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGy5R.png\" alt></p>\n<ul>\n<li>EXAMPLE: CONV in pyTorch</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGRxK.png\" alt></p>\n<ul>\n<li>The Brain/Neuron View of CONV</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOG226.png\" alt></p>\n<ul>\n<li>Pooling layer</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGg8x.png\" alt></p>\n<blockquote>\n<p>Just spacially down sample the image to make it smaller.<br>Common Practice is Max Pooling</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGcP1.png\" alt></p>\n<blockquote>\n<p>We may can just use stride to replace pooling?</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"A-bit-of-CNN-History\"><a href=\"#A-bit-of-CNN-History\" class=\"headerlink\" title=\"A bit of CNN History\"></a>A bit of CNN History</h3><p><img src=\"https://s1.ax1x.com/2020/11/11/BOGJ5n.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGGUs.png\" alt></p>\n<h4 id=\"Fully-Connected-Layer\"><a href=\"#Fully-Connected-Layer\" class=\"headerlink\" title=\"Fully Connected Layer\"></a>Fully Connected Layer</h4><p><img src=\"https://s1.ax1x.com/2020/11/11/BOGlDg.png\" alt></p>\n<h4 id=\"Convolution-Layer\"><a href=\"#Convolution-Layer\" class=\"headerlink\" title=\"Convolution Layer\"></a>Convolution Layer</h4><p><img src=\"https://s1.ax1x.com/2020/11/11/BOG1bQ.png\" alt></p>\n<blockquote>\n<p>We just let the 5x5x3 filter $w$ to take a dot product between itself and a small 5x5z3 chunck of the image</p>\n</blockquote>\n<script type=\"math/tex; mode=display\">W^Tx+b</script><p><strong>The $W$ and $x$ is streched into 1 dimention vec</strong></p>\n<ul>\n<li>Then the Outcome:</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOG8Ej.png\" alt></p>\n<blockquote>\n<p>We can use different layers on the top of it and get more activation maps stack them together to get a new image, just as the following pic depicted.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGtCq.png\" alt></p>\n<blockquote>\n<p>Then we can recursively do that work, make the front layer’s output be the next layer’s input</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGU2V.png\" alt></p>\n<p><strong>The Layers may look like..</strong><br><em>Simple -&gt; Complex</em></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGN80.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGrVJ.png\" alt></p>\n<ul>\n<li>The Convolution of two signals:</li>\n</ul>\n<script type=\"math/tex; mode=display\">f[x,y]*g[x,y] = \\sum\\limits_{n_1 = -\\infin}^{\\infin}\\sum\\limits_{n_2 = -\\infin}^{\\infin}f[n_1,n_2]·g[x-n_1,y-n_2]</script><ul>\n<li>A little bit preview</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOG0rF.png\" alt></p>\n<hr>\n<ul>\n<li>Convolution Box</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGwKU.png\" alt></p>\n<blockquote>\n<p>We can tell that the activation maps are becomming smaller after the filter, so we commonly use zero pad to deal with it.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGBb4.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGsa9.png\" alt></p>\n<blockquote>\n<p>The Matrix shrinks from 32 —&gt; 28 -&gt; 24 (lose info)</p>\n</blockquote>\n<hr>\n<h3 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h3><ol>\n<li>Accepts a volume of size $W_1 <em> H_1 </em> D_1$</li>\n<li>Four Hyperparas<ul>\n<li>Number of filters $K$</li>\n<li>spatial extent $F$</li>\n<li>stride $S$</li>\n<li>zero padding amount $P$</li>\n</ul>\n</li>\n<li>Produces a volume of size $W_2 <em> H_2 </em> D_2$<ul>\n<li>$W_2 = (W_1 - F + 2P)/S + 1$</li>\n<li>$H_2 = (H_1 - F + 2P)/S + 1$</li>\n<li>$D_2 = K$ <em>Depth keeps the same</em></li>\n</ul>\n</li>\n</ol>\n<h4 id=\"Common-Settings\"><a href=\"#Common-Settings\" class=\"headerlink\" title=\"Common Settings\"></a>Common Settings</h4><p>K = (powers of 2)</p>\n<ul>\n<li>F = 3, S = 1, P =1</li>\n<li>F = 5, S = 1, P =2</li>\n<li>F = 1, S = 1, P = 0 </li>\n</ul>\n<hr>\n<h3 id=\"Conv-details\"><a href=\"#Conv-details\" class=\"headerlink\" title=\"Conv details\"></a>Conv details</h3><ul>\n<li>One by One CONV</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGy5R.png\" alt></p>\n<ul>\n<li>EXAMPLE: CONV in pyTorch</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGRxK.png\" alt></p>\n<ul>\n<li>The Brain/Neuron View of CONV</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOG226.png\" alt></p>\n<ul>\n<li>Pooling layer</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGg8x.png\" alt></p>\n<blockquote>\n<p>Just spacially down sample the image to make it smaller.<br>Common Practice is Max Pooling</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/11/BOGcP1.png\" alt></p>\n<blockquote>\n<p>We may can just use stride to replace pooling?</p>\n</blockquote>\n"},{"title":"CS231n Introduction to Convolutional neural network 03","date":"2020-11-09T16:57:26.000Z","index_img":"/img/Cs231n/top.jpg","math":true,"_content":"\n### Computational graphs\n\n![](https://s1.ax1x.com/2020/11/10/BbDAaD.png)\n\n### BackPropagation - A method to compute the gradients of abitrarily complex function\n\n- A recursive application of Chain rule\n\n![](https://s1.ax1x.com/2020/11/10/BbDCKx.png)\n\n> We get the gradient backprop from the front and comupte with the local gradient to prop to the back.\n\n![](https://s1.ax1x.com/2020/11/10/BbDPr6.png)\n\n> In some cases, some part of the graph can be represented by some func that we already know to simplify the computations. (trade off the math)\n\n![](https://s1.ax1x.com/2020/11/10/BbDiqK.png)\n\n- Patterns in backward flow\n\n1. **add gate:** gradient distributor (local = 1)\n2. **max gate:** gradient distributor (local = 1 & 0)\n3. **mul gate:** gradient switcher (local = y & x )\n\n*Gradients add at branches n->1*\n\n- Then We Got the gradients in the form of Jacobian Matrix\n\n![](https://s1.ax1x.com/2020/11/10/BbDkVO.png)\n\n![](https://s1.ax1x.com/2020/11/10/BbDZPH.png)\n\n*This place include some linear algebra*\n\n### Modularized implementation: Forward / Backward API\n\n```python\nclass ComputationalGraph(object):\n    def forward(inputs):\n        # 1. pass inputs to input gates\n        # 2. forward the computational graph\n        for gate in self.graph.nodes_topologically_sorted():\n            gate.forward()\n        return loss\n    def backward():\n        for gate in reversed(self.graph.nodes_topologically_sorted())\n            gate.backward() # compute the gradients\n        return inputs_gradients\n```\n\n#### EXAMPLE: MulGate\n\n```python\nclass MultiplyGate(object):\n    def forward(x, y):\n        z = x*y\n        self.x = x\n        self.y = y\n    def backward(dz):\n        dx = self.y * z\n        dy = self.x * z\n        return [dx, dy]\n```\n\n> This practice is common.\n\n![](https://s1.ax1x.com/2020/11/10/BbDeGd.png)\n\n### Summary so Far\n\n![](https://s1.ax1x.com/2020/11/10/BbDmRA.png)\n\n### Neural networks\n\n(Before) Linear score function: $f = Wx$\n(Now) 2-layers Neural Network $f = W_2max(0, W_1x)$\n....or more layers\n\n![](https://s1.ax1x.com/2020/11/10/BbDEIe.png)\n\n> The h is the scores W1 output, and we put one more linear layer W2 on the top of it to weighting the scores given by h \n","source":"_posts/CS231n/CS231n-03-Introduction-to-Convolutional-neural-network.md","raw":"---\ntitle: CS231n Introduction to Convolutional neural network 03\ndate: 2020-11-10 00:57:26\ntags: [CV,Neural Network]\ncategory: [CS231n]\nindex_img: /img/Cs231n/top.jpg\nmath: true\n---\n\n### Computational graphs\n\n![](https://s1.ax1x.com/2020/11/10/BbDAaD.png)\n\n### BackPropagation - A method to compute the gradients of abitrarily complex function\n\n- A recursive application of Chain rule\n\n![](https://s1.ax1x.com/2020/11/10/BbDCKx.png)\n\n> We get the gradient backprop from the front and comupte with the local gradient to prop to the back.\n\n![](https://s1.ax1x.com/2020/11/10/BbDPr6.png)\n\n> In some cases, some part of the graph can be represented by some func that we already know to simplify the computations. (trade off the math)\n\n![](https://s1.ax1x.com/2020/11/10/BbDiqK.png)\n\n- Patterns in backward flow\n\n1. **add gate:** gradient distributor (local = 1)\n2. **max gate:** gradient distributor (local = 1 & 0)\n3. **mul gate:** gradient switcher (local = y & x )\n\n*Gradients add at branches n->1*\n\n- Then We Got the gradients in the form of Jacobian Matrix\n\n![](https://s1.ax1x.com/2020/11/10/BbDkVO.png)\n\n![](https://s1.ax1x.com/2020/11/10/BbDZPH.png)\n\n*This place include some linear algebra*\n\n### Modularized implementation: Forward / Backward API\n\n```python\nclass ComputationalGraph(object):\n    def forward(inputs):\n        # 1. pass inputs to input gates\n        # 2. forward the computational graph\n        for gate in self.graph.nodes_topologically_sorted():\n            gate.forward()\n        return loss\n    def backward():\n        for gate in reversed(self.graph.nodes_topologically_sorted())\n            gate.backward() # compute the gradients\n        return inputs_gradients\n```\n\n#### EXAMPLE: MulGate\n\n```python\nclass MultiplyGate(object):\n    def forward(x, y):\n        z = x*y\n        self.x = x\n        self.y = y\n    def backward(dz):\n        dx = self.y * z\n        dy = self.x * z\n        return [dx, dy]\n```\n\n> This practice is common.\n\n![](https://s1.ax1x.com/2020/11/10/BbDeGd.png)\n\n### Summary so Far\n\n![](https://s1.ax1x.com/2020/11/10/BbDmRA.png)\n\n### Neural networks\n\n(Before) Linear score function: $f = Wx$\n(Now) 2-layers Neural Network $f = W_2max(0, W_1x)$\n....or more layers\n\n![](https://s1.ax1x.com/2020/11/10/BbDEIe.png)\n\n> The h is the scores W1 output, and we put one more linear layer W2 on the top of it to weighting the scores given by h \n","slug":"CS231n/CS231n-03-Introduction-to-Convolutional-neural-network","published":1,"updated":"2020-12-09T01:22:51.272Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty3p000bs8pd636perai","content":"<h3 id=\"Computational-graphs\"><a href=\"#Computational-graphs\" class=\"headerlink\" title=\"Computational graphs\"></a>Computational graphs</h3><p><img src=\"https://s1.ax1x.com/2020/11/10/BbDAaD.png\" alt></p>\n<h3 id=\"BackPropagation-A-method-to-compute-the-gradients-of-abitrarily-complex-function\"><a href=\"#BackPropagation-A-method-to-compute-the-gradients-of-abitrarily-complex-function\" class=\"headerlink\" title=\"BackPropagation - A method to compute the gradients of abitrarily complex function\"></a>BackPropagation - A method to compute the gradients of abitrarily complex function</h3><ul>\n<li>A recursive application of Chain rule</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDCKx.png\" alt></p>\n<blockquote>\n<p>We get the gradient backprop from the front and comupte with the local gradient to prop to the back.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDPr6.png\" alt></p>\n<blockquote>\n<p>In some cases, some part of the graph can be represented by some func that we already know to simplify the computations. (trade off the math)</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDiqK.png\" alt></p>\n<ul>\n<li>Patterns in backward flow</li>\n</ul>\n<ol>\n<li><strong>add gate:</strong> gradient distributor (local = 1)</li>\n<li><strong>max gate:</strong> gradient distributor (local = 1 &amp; 0)</li>\n<li><strong>mul gate:</strong> gradient switcher (local = y &amp; x )</li>\n</ol>\n<p><em>Gradients add at branches n-&gt;1</em></p>\n<ul>\n<li>Then We Got the gradients in the form of Jacobian Matrix</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDkVO.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDZPH.png\" alt></p>\n<p><em>This place include some linear algebra</em></p>\n<h3 id=\"Modularized-implementation-Forward-Backward-API\"><a href=\"#Modularized-implementation-Forward-Backward-API\" class=\"headerlink\" title=\"Modularized implementation: Forward / Backward API\"></a>Modularized implementation: Forward / Backward API</h3><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ComputationalGraph</span>(<span class=\"hljs-params\"><span class=\"hljs-built_in\">object</span></span>):</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">forward</span>(<span class=\"hljs-params\">inputs</span>):</span>\n        <span class=\"hljs-comment\"># 1. pass inputs to input gates</span>\n        <span class=\"hljs-comment\"># 2. forward the computational graph</span>\n        <span class=\"hljs-keyword\">for</span> gate <span class=\"hljs-keyword\">in</span> self.graph.nodes_topologically_sorted():\n            gate.forward()\n        <span class=\"hljs-keyword\">return</span> loss\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">backward</span>():</span>\n        <span class=\"hljs-keyword\">for</span> gate <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">reversed</span>(self.graph.nodes_topologically_sorted())\n            gate.backward() <span class=\"hljs-comment\"># compute the gradients</span>\n        <span class=\"hljs-keyword\">return</span> inputs_gradients</code></pre>\n<h4 id=\"EXAMPLE-MulGate\"><a href=\"#EXAMPLE-MulGate\" class=\"headerlink\" title=\"EXAMPLE: MulGate\"></a>EXAMPLE: MulGate</h4><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">MultiplyGate</span>(<span class=\"hljs-params\"><span class=\"hljs-built_in\">object</span></span>):</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">forward</span>(<span class=\"hljs-params\">x, y</span>):</span>\n        z = x*y\n        self.x = x\n        self.y = y\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">backward</span>(<span class=\"hljs-params\">dz</span>):</span>\n        dx = self.y * z\n        dy = self.x * z\n        <span class=\"hljs-keyword\">return</span> [dx, dy]</code></pre>\n<blockquote>\n<p>This practice is common.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDeGd.png\" alt></p>\n<h3 id=\"Summary-so-Far\"><a href=\"#Summary-so-Far\" class=\"headerlink\" title=\"Summary so Far\"></a>Summary so Far</h3><p><img src=\"https://s1.ax1x.com/2020/11/10/BbDmRA.png\" alt></p>\n<h3 id=\"Neural-networks\"><a href=\"#Neural-networks\" class=\"headerlink\" title=\"Neural networks\"></a>Neural networks</h3><p>(Before) Linear score function: $f = Wx$<br>(Now) 2-layers Neural Network $f = W_2max(0, W_1x)$<br>….or more layers</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDEIe.png\" alt></p>\n<blockquote>\n<p>The h is the scores W1 output, and we put one more linear layer W2 on the top of it to weighting the scores given by h </p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Computational-graphs\"><a href=\"#Computational-graphs\" class=\"headerlink\" title=\"Computational graphs\"></a>Computational graphs</h3><p><img src=\"https://s1.ax1x.com/2020/11/10/BbDAaD.png\" alt></p>\n<h3 id=\"BackPropagation-A-method-to-compute-the-gradients-of-abitrarily-complex-function\"><a href=\"#BackPropagation-A-method-to-compute-the-gradients-of-abitrarily-complex-function\" class=\"headerlink\" title=\"BackPropagation - A method to compute the gradients of abitrarily complex function\"></a>BackPropagation - A method to compute the gradients of abitrarily complex function</h3><ul>\n<li>A recursive application of Chain rule</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDCKx.png\" alt></p>\n<blockquote>\n<p>We get the gradient backprop from the front and comupte with the local gradient to prop to the back.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDPr6.png\" alt></p>\n<blockquote>\n<p>In some cases, some part of the graph can be represented by some func that we already know to simplify the computations. (trade off the math)</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDiqK.png\" alt></p>\n<ul>\n<li>Patterns in backward flow</li>\n</ul>\n<ol>\n<li><strong>add gate:</strong> gradient distributor (local = 1)</li>\n<li><strong>max gate:</strong> gradient distributor (local = 1 &amp; 0)</li>\n<li><strong>mul gate:</strong> gradient switcher (local = y &amp; x )</li>\n</ol>\n<p><em>Gradients add at branches n-&gt;1</em></p>\n<ul>\n<li>Then We Got the gradients in the form of Jacobian Matrix</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDkVO.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDZPH.png\" alt></p>\n<p><em>This place include some linear algebra</em></p>\n<h3 id=\"Modularized-implementation-Forward-Backward-API\"><a href=\"#Modularized-implementation-Forward-Backward-API\" class=\"headerlink\" title=\"Modularized implementation: Forward / Backward API\"></a>Modularized implementation: Forward / Backward API</h3><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ComputationalGraph</span>(<span class=\"hljs-params\"><span class=\"hljs-built_in\">object</span></span>):</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">forward</span>(<span class=\"hljs-params\">inputs</span>):</span>\n        <span class=\"hljs-comment\"># 1. pass inputs to input gates</span>\n        <span class=\"hljs-comment\"># 2. forward the computational graph</span>\n        <span class=\"hljs-keyword\">for</span> gate <span class=\"hljs-keyword\">in</span> self.graph.nodes_topologically_sorted():\n            gate.forward()\n        <span class=\"hljs-keyword\">return</span> loss\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">backward</span>():</span>\n        <span class=\"hljs-keyword\">for</span> gate <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">reversed</span>(self.graph.nodes_topologically_sorted())\n            gate.backward() <span class=\"hljs-comment\"># compute the gradients</span>\n        <span class=\"hljs-keyword\">return</span> inputs_gradients</code></pre>\n<h4 id=\"EXAMPLE-MulGate\"><a href=\"#EXAMPLE-MulGate\" class=\"headerlink\" title=\"EXAMPLE: MulGate\"></a>EXAMPLE: MulGate</h4><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">MultiplyGate</span>(<span class=\"hljs-params\"><span class=\"hljs-built_in\">object</span></span>):</span>\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">forward</span>(<span class=\"hljs-params\">x, y</span>):</span>\n        z = x*y\n        self.x = x\n        self.y = y\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">backward</span>(<span class=\"hljs-params\">dz</span>):</span>\n        dx = self.y * z\n        dy = self.x * z\n        <span class=\"hljs-keyword\">return</span> [dx, dy]</code></pre>\n<blockquote>\n<p>This practice is common.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDeGd.png\" alt></p>\n<h3 id=\"Summary-so-Far\"><a href=\"#Summary-so-Far\" class=\"headerlink\" title=\"Summary so Far\"></a>Summary so Far</h3><p><img src=\"https://s1.ax1x.com/2020/11/10/BbDmRA.png\" alt></p>\n<h3 id=\"Neural-networks\"><a href=\"#Neural-networks\" class=\"headerlink\" title=\"Neural networks\"></a>Neural networks</h3><p>(Before) Linear score function: $f = Wx$<br>(Now) 2-layers Neural Network $f = W_2max(0, W_1x)$<br>….or more layers</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/10/BbDEIe.png\" alt></p>\n<blockquote>\n<p>The h is the scores W1 output, and we put one more linear layer W2 on the top of it to weighting the scores given by h </p>\n</blockquote>\n"},{"title":"CS231n Image Classification 01","date":"2020-11-07T14:11:53.000Z","index_img":"/img/Cs231n/top.jpg","math":true,"_content":"\n**Preface:** This is the note of Stanford course CS231n, paving the way for my lab research.\n\n# Image Classification\n*A core task in Computer Vision*\n\n---\n\n### Computer' Work \nInput an image, and assign one of the label amoung the given labels.\n\n- **The Problem:** \n1. Semantic Gap\n2. Viewpoint variation\n3. illumination \n4. Deformation\n5. Occlusion\n6. Intraclass variation\n\n---\n\n### An image classifier\n> Coding might be difficult \n\n```python\ndef classify_image(image):\n    # Do Some Magic\n    return class_label\n```\n\n- Attmpts\n  \n![](https://s1.ax1x.com/2020/11/07/BIMSmD.png)\n\n---\n\n### Data-Driven Approach\n1. Collect a dataset of images and labels\n2. Use Machine Learning to train a classifier\n3. Evaluate the classifier on new images\n\n- First classifier: Nearest Neighbor\n\n*Just Memorize all data and labels*\n```python\ndef train(images, labels):\n    # Machine Learning!\n    return model\n```\n\n*Predict the label of the most similar training image*\n```python\ndef predict(model, test_images):\n    # Use model to predict labels\n    return test_labels\n```\n\n**Example Dataset:** CIFAR10\n\n![](https://s1.ax1x.com/2020/11/07/BIM9TH.png)\n\n> **Issues:** Although pics may seem visually similar, but still give lots of errors.\n> \n---\n\n- Compare func used in it\n### **K nearest Neighbors Method**\n\n**L1 distance:** $d_1(I_1,I_2) = \\sum\\limits_{p} \\mid I_1^p - I_2^p \\mid$\n\n![](https://s1.ax1x.com/2020/11/07/BIKXSx.png)\n\n*Minimize the sum given the most similar pics*\n\n#### **BackWards**\n\n![](https://s1.ax1x.com/2020/11/07/BIKjl6.png)\n\n#### **What it looks like**\n\n![](https://s1.ax1x.com/2020/11/07/BIMp0e.png)\n\n**Issues**\n\n1. Isolated Yellow Point\n2. Noisy of one single point (green into blue)\n\n**Use K Nearest Neighbors to Optimize it**\n![](https://s1.ax1x.com/2020/11/07/BIMitA.png)\n\n---\n\n*A Better Cmp Func*\n**L2(Euclidean) distance:** $d_1(I_1,I_2) = \\sqrt{\\sum\\limits_{p}{(I_1^p - I_2^p)}^2}$\n\n![](https://s1.ax1x.com/2020/11/07/BIMFfI.png)\n\n> The L1 Distance depends on the coordinate system, whenever there is a rotate, it would change the L1 Distance, while that won't happen in the L2 Distance case (simply because it's a circle)\n\n---\n\n#### **Hyperparameters**\n- What's the best value of **k**\n- What's the best **distance** to use? (L1,L2 or anything else)\n\n*These things are preset rather than learn automatically from learning process*\n\nThis is **Very problem-dependent**, just try!, but How?\n\n![](https://s1.ax1x.com/2020/11/07/BIME1P.png)\n\n**Training & Validation process should not mixed with the test data**\n\n- Cross Validation\n\n![](https://s1.ax1x.com/2020/11/07/BIMApt.png)\n\n- Validation process\n\n![](https://s1.ax1x.com/2020/11/07/BIMV6f.png)\n\n> using the validation data to choose the best hyperparameters.\n\n![](https://s1.ax1x.com/2020/11/07/BIMu7Q.png)\n\n> Cause we sum the offset, though the differences bettween pics and pics are various, they still got the same L2 distance, which is not so good.\n\n\n---\n\n### **Linear Classification**\n\n- **Parametric Model**\n![](https://s1.ax1x.com/2020/11/07/BIMZX8.png)\n\n$$f(x,W) = Wx + b$$\n> We need f(x,W) to be 10x1 and the x is actually 3072x1, so the W we input may be 10x3072, sometimes we add a bias to balance.\n\n![](https://s1.ax1x.com/2020/11/07/BIMn0g.png)\n\n![](https://s1.ax1x.com/2020/11/07/BIMMkj.png)\n\n> It use a single line to separate the object based on its RGB info\n\nBut how can we tell the quality of W ?\n(View the next lecture)\n\n- **Problems**\n![](https://s1.ax1x.com/2020/11/07/BIMQts.png)\n\n> Since it's linear the Problems is obivious.\n","source":"_posts/CS231n/CS231n_01_Image_Classification.md","raw":"---\ntitle: CS231n Image Classification 01\ndate: 2020-11-07 22:11:53\ntags: [CV,Neural Network]\ncategory: [CS231n]\nindex_img: /img/Cs231n/top.jpg\nmath: true\n---\n\n**Preface:** This is the note of Stanford course CS231n, paving the way for my lab research.\n\n# Image Classification\n*A core task in Computer Vision*\n\n---\n\n### Computer' Work \nInput an image, and assign one of the label amoung the given labels.\n\n- **The Problem:** \n1. Semantic Gap\n2. Viewpoint variation\n3. illumination \n4. Deformation\n5. Occlusion\n6. Intraclass variation\n\n---\n\n### An image classifier\n> Coding might be difficult \n\n```python\ndef classify_image(image):\n    # Do Some Magic\n    return class_label\n```\n\n- Attmpts\n  \n![](https://s1.ax1x.com/2020/11/07/BIMSmD.png)\n\n---\n\n### Data-Driven Approach\n1. Collect a dataset of images and labels\n2. Use Machine Learning to train a classifier\n3. Evaluate the classifier on new images\n\n- First classifier: Nearest Neighbor\n\n*Just Memorize all data and labels*\n```python\ndef train(images, labels):\n    # Machine Learning!\n    return model\n```\n\n*Predict the label of the most similar training image*\n```python\ndef predict(model, test_images):\n    # Use model to predict labels\n    return test_labels\n```\n\n**Example Dataset:** CIFAR10\n\n![](https://s1.ax1x.com/2020/11/07/BIM9TH.png)\n\n> **Issues:** Although pics may seem visually similar, but still give lots of errors.\n> \n---\n\n- Compare func used in it\n### **K nearest Neighbors Method**\n\n**L1 distance:** $d_1(I_1,I_2) = \\sum\\limits_{p} \\mid I_1^p - I_2^p \\mid$\n\n![](https://s1.ax1x.com/2020/11/07/BIKXSx.png)\n\n*Minimize the sum given the most similar pics*\n\n#### **BackWards**\n\n![](https://s1.ax1x.com/2020/11/07/BIKjl6.png)\n\n#### **What it looks like**\n\n![](https://s1.ax1x.com/2020/11/07/BIMp0e.png)\n\n**Issues**\n\n1. Isolated Yellow Point\n2. Noisy of one single point (green into blue)\n\n**Use K Nearest Neighbors to Optimize it**\n![](https://s1.ax1x.com/2020/11/07/BIMitA.png)\n\n---\n\n*A Better Cmp Func*\n**L2(Euclidean) distance:** $d_1(I_1,I_2) = \\sqrt{\\sum\\limits_{p}{(I_1^p - I_2^p)}^2}$\n\n![](https://s1.ax1x.com/2020/11/07/BIMFfI.png)\n\n> The L1 Distance depends on the coordinate system, whenever there is a rotate, it would change the L1 Distance, while that won't happen in the L2 Distance case (simply because it's a circle)\n\n---\n\n#### **Hyperparameters**\n- What's the best value of **k**\n- What's the best **distance** to use? (L1,L2 or anything else)\n\n*These things are preset rather than learn automatically from learning process*\n\nThis is **Very problem-dependent**, just try!, but How?\n\n![](https://s1.ax1x.com/2020/11/07/BIME1P.png)\n\n**Training & Validation process should not mixed with the test data**\n\n- Cross Validation\n\n![](https://s1.ax1x.com/2020/11/07/BIMApt.png)\n\n- Validation process\n\n![](https://s1.ax1x.com/2020/11/07/BIMV6f.png)\n\n> using the validation data to choose the best hyperparameters.\n\n![](https://s1.ax1x.com/2020/11/07/BIMu7Q.png)\n\n> Cause we sum the offset, though the differences bettween pics and pics are various, they still got the same L2 distance, which is not so good.\n\n\n---\n\n### **Linear Classification**\n\n- **Parametric Model**\n![](https://s1.ax1x.com/2020/11/07/BIMZX8.png)\n\n$$f(x,W) = Wx + b$$\n> We need f(x,W) to be 10x1 and the x is actually 3072x1, so the W we input may be 10x3072, sometimes we add a bias to balance.\n\n![](https://s1.ax1x.com/2020/11/07/BIMn0g.png)\n\n![](https://s1.ax1x.com/2020/11/07/BIMMkj.png)\n\n> It use a single line to separate the object based on its RGB info\n\nBut how can we tell the quality of W ?\n(View the next lecture)\n\n- **Problems**\n![](https://s1.ax1x.com/2020/11/07/BIMQts.png)\n\n> Since it's linear the Problems is obivious.\n","slug":"CS231n/CS231n_01_Image_Classification","published":1,"updated":"2020-12-09T01:22:48.289Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty3q000cs8pdh2o9h9bc","content":"<p><strong>Preface:</strong> This is the note of Stanford course CS231n, paving the way for my lab research.</p>\n<h1 id=\"Image-Classification\"><a href=\"#Image-Classification\" class=\"headerlink\" title=\"Image Classification\"></a>Image Classification</h1><p><em>A core task in Computer Vision</em></p>\n<hr>\n<h3 id=\"Computer’-Work\"><a href=\"#Computer’-Work\" class=\"headerlink\" title=\"Computer’ Work\"></a>Computer’ Work</h3><p>Input an image, and assign one of the label amoung the given labels.</p>\n<ul>\n<li><strong>The Problem:</strong> </li>\n</ul>\n<ol>\n<li>Semantic Gap</li>\n<li>Viewpoint variation</li>\n<li>illumination </li>\n<li>Deformation</li>\n<li>Occlusion</li>\n<li>Intraclass variation</li>\n</ol>\n<hr>\n<h3 id=\"An-image-classifier\"><a href=\"#An-image-classifier\" class=\"headerlink\" title=\"An image classifier\"></a>An image classifier</h3><blockquote>\n<p>Coding might be difficult </p>\n</blockquote>\n<pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">classify_image</span>(<span class=\"hljs-params\">image</span>):</span>\n    <span class=\"hljs-comment\"># Do Some Magic</span>\n    <span class=\"hljs-keyword\">return</span> class_label</code></pre>\n<ul>\n<li>Attmpts</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMSmD.png\" alt></p>\n<hr>\n<h3 id=\"Data-Driven-Approach\"><a href=\"#Data-Driven-Approach\" class=\"headerlink\" title=\"Data-Driven Approach\"></a>Data-Driven Approach</h3><ol>\n<li>Collect a dataset of images and labels</li>\n<li>Use Machine Learning to train a classifier</li>\n<li>Evaluate the classifier on new images</li>\n</ol>\n<ul>\n<li>First classifier: Nearest Neighbor</li>\n</ul>\n<p><em>Just Memorize all data and labels</em><br><pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">train</span>(<span class=\"hljs-params\">images, labels</span>):</span>\n    <span class=\"hljs-comment\"># Machine Learning!</span>\n    <span class=\"hljs-keyword\">return</span> model</code></pre></p>\n<p><em>Predict the label of the most similar training image</em><br><pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">predict</span>(<span class=\"hljs-params\">model, test_images</span>):</span>\n    <span class=\"hljs-comment\"># Use model to predict labels</span>\n    <span class=\"hljs-keyword\">return</span> test_labels</code></pre></p>\n<p><strong>Example Dataset:</strong> CIFAR10</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIM9TH.png\" alt></p>\n<blockquote>\n<p><strong>Issues:</strong> Although pics may seem visually similar, but still give lots of errors.</p>\n<hr>\n</blockquote>\n<ul>\n<li>Compare func used in it<h3 id=\"K-nearest-Neighbors-Method\"><a href=\"#K-nearest-Neighbors-Method\" class=\"headerlink\" title=\"K nearest Neighbors Method\"></a><strong>K nearest Neighbors Method</strong></h3></li>\n</ul>\n<p><strong>L1 distance:</strong> $d<em>1(I_1,I_2) = \\sum\\limits</em>{p} \\mid I_1^p - I_2^p \\mid$</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIKXSx.png\" alt></p>\n<p><em>Minimize the sum given the most similar pics</em></p>\n<h4 id=\"BackWards\"><a href=\"#BackWards\" class=\"headerlink\" title=\"BackWards\"></a><strong>BackWards</strong></h4><p><img src=\"https://s1.ax1x.com/2020/11/07/BIKjl6.png\" alt></p>\n<h4 id=\"What-it-looks-like\"><a href=\"#What-it-looks-like\" class=\"headerlink\" title=\"What it looks like\"></a><strong>What it looks like</strong></h4><p><img src=\"https://s1.ax1x.com/2020/11/07/BIMp0e.png\" alt></p>\n<p><strong>Issues</strong></p>\n<ol>\n<li>Isolated Yellow Point</li>\n<li>Noisy of one single point (green into blue)</li>\n</ol>\n<p><strong>Use K Nearest Neighbors to Optimize it</strong><br><img src=\"https://s1.ax1x.com/2020/11/07/BIMitA.png\" alt></p>\n<hr>\n<p><em>A Better Cmp Func</em><br><strong>L2(Euclidean) distance:</strong> $d<em>1(I_1,I_2) = \\sqrt{\\sum\\limits</em>{p}{(I_1^p - I_2^p)}^2}$</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMFfI.png\" alt></p>\n<blockquote>\n<p>The L1 Distance depends on the coordinate system, whenever there is a rotate, it would change the L1 Distance, while that won’t happen in the L2 Distance case (simply because it’s a circle)</p>\n</blockquote>\n<hr>\n<h4 id=\"Hyperparameters\"><a href=\"#Hyperparameters\" class=\"headerlink\" title=\"Hyperparameters\"></a><strong>Hyperparameters</strong></h4><ul>\n<li>What’s the best value of <strong>k</strong></li>\n<li>What’s the best <strong>distance</strong> to use? (L1,L2 or anything else)</li>\n</ul>\n<p><em>These things are preset rather than learn automatically from learning process</em></p>\n<p>This is <strong>Very problem-dependent</strong>, just try!, but How?</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIME1P.png\" alt></p>\n<p><strong>Training &amp; Validation process should not mixed with the test data</strong></p>\n<ul>\n<li>Cross Validation</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMApt.png\" alt></p>\n<ul>\n<li>Validation process</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMV6f.png\" alt></p>\n<blockquote>\n<p>using the validation data to choose the best hyperparameters.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMu7Q.png\" alt></p>\n<blockquote>\n<p>Cause we sum the offset, though the differences bettween pics and pics are various, they still got the same L2 distance, which is not so good.</p>\n</blockquote>\n<hr>\n<h3 id=\"Linear-Classification\"><a href=\"#Linear-Classification\" class=\"headerlink\" title=\"Linear Classification\"></a><strong>Linear Classification</strong></h3><ul>\n<li><strong>Parametric Model</strong><br><img src=\"https://s1.ax1x.com/2020/11/07/BIMZX8.png\" alt></li>\n</ul>\n<script type=\"math/tex; mode=display\">f(x,W) = Wx + b</script><blockquote>\n<p>We need f(x,W) to be 10x1 and the x is actually 3072x1, so the W we input may be 10x3072, sometimes we add a bias to balance.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMn0g.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMMkj.png\" alt></p>\n<blockquote>\n<p>It use a single line to separate the object based on its RGB info</p>\n</blockquote>\n<p>But how can we tell the quality of W ?<br>(View the next lecture)</p>\n<ul>\n<li><strong>Problems</strong><br><img src=\"https://s1.ax1x.com/2020/11/07/BIMQts.png\" alt></li>\n</ul>\n<blockquote>\n<p>Since it’s linear the Problems is obivious.</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<p><strong>Preface:</strong> This is the note of Stanford course CS231n, paving the way for my lab research.</p>\n<h1 id=\"Image-Classification\"><a href=\"#Image-Classification\" class=\"headerlink\" title=\"Image Classification\"></a>Image Classification</h1><p><em>A core task in Computer Vision</em></p>\n<hr>\n<h3 id=\"Computer’-Work\"><a href=\"#Computer’-Work\" class=\"headerlink\" title=\"Computer’ Work\"></a>Computer’ Work</h3><p>Input an image, and assign one of the label amoung the given labels.</p>\n<ul>\n<li><strong>The Problem:</strong> </li>\n</ul>\n<ol>\n<li>Semantic Gap</li>\n<li>Viewpoint variation</li>\n<li>illumination </li>\n<li>Deformation</li>\n<li>Occlusion</li>\n<li>Intraclass variation</li>\n</ol>\n<hr>\n<h3 id=\"An-image-classifier\"><a href=\"#An-image-classifier\" class=\"headerlink\" title=\"An image classifier\"></a>An image classifier</h3><blockquote>\n<p>Coding might be difficult </p>\n</blockquote>\n<pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">classify_image</span>(<span class=\"hljs-params\">image</span>):</span>\n    <span class=\"hljs-comment\"># Do Some Magic</span>\n    <span class=\"hljs-keyword\">return</span> class_label</code></pre>\n<ul>\n<li>Attmpts</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMSmD.png\" alt></p>\n<hr>\n<h3 id=\"Data-Driven-Approach\"><a href=\"#Data-Driven-Approach\" class=\"headerlink\" title=\"Data-Driven Approach\"></a>Data-Driven Approach</h3><ol>\n<li>Collect a dataset of images and labels</li>\n<li>Use Machine Learning to train a classifier</li>\n<li>Evaluate the classifier on new images</li>\n</ol>\n<ul>\n<li>First classifier: Nearest Neighbor</li>\n</ul>\n<p><em>Just Memorize all data and labels</em><br><pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">train</span>(<span class=\"hljs-params\">images, labels</span>):</span>\n    <span class=\"hljs-comment\"># Machine Learning!</span>\n    <span class=\"hljs-keyword\">return</span> model</code></pre></p>\n<p><em>Predict the label of the most similar training image</em><br><pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">predict</span>(<span class=\"hljs-params\">model, test_images</span>):</span>\n    <span class=\"hljs-comment\"># Use model to predict labels</span>\n    <span class=\"hljs-keyword\">return</span> test_labels</code></pre></p>\n<p><strong>Example Dataset:</strong> CIFAR10</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIM9TH.png\" alt></p>\n<blockquote>\n<p><strong>Issues:</strong> Although pics may seem visually similar, but still give lots of errors.</p>\n<hr>\n</blockquote>\n<ul>\n<li>Compare func used in it<h3 id=\"K-nearest-Neighbors-Method\"><a href=\"#K-nearest-Neighbors-Method\" class=\"headerlink\" title=\"K nearest Neighbors Method\"></a><strong>K nearest Neighbors Method</strong></h3></li>\n</ul>\n<p><strong>L1 distance:</strong> $d<em>1(I_1,I_2) = \\sum\\limits</em>{p} \\mid I_1^p - I_2^p \\mid$</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIKXSx.png\" alt></p>\n<p><em>Minimize the sum given the most similar pics</em></p>\n<h4 id=\"BackWards\"><a href=\"#BackWards\" class=\"headerlink\" title=\"BackWards\"></a><strong>BackWards</strong></h4><p><img src=\"https://s1.ax1x.com/2020/11/07/BIKjl6.png\" alt></p>\n<h4 id=\"What-it-looks-like\"><a href=\"#What-it-looks-like\" class=\"headerlink\" title=\"What it looks like\"></a><strong>What it looks like</strong></h4><p><img src=\"https://s1.ax1x.com/2020/11/07/BIMp0e.png\" alt></p>\n<p><strong>Issues</strong></p>\n<ol>\n<li>Isolated Yellow Point</li>\n<li>Noisy of one single point (green into blue)</li>\n</ol>\n<p><strong>Use K Nearest Neighbors to Optimize it</strong><br><img src=\"https://s1.ax1x.com/2020/11/07/BIMitA.png\" alt></p>\n<hr>\n<p><em>A Better Cmp Func</em><br><strong>L2(Euclidean) distance:</strong> $d<em>1(I_1,I_2) = \\sqrt{\\sum\\limits</em>{p}{(I_1^p - I_2^p)}^2}$</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMFfI.png\" alt></p>\n<blockquote>\n<p>The L1 Distance depends on the coordinate system, whenever there is a rotate, it would change the L1 Distance, while that won’t happen in the L2 Distance case (simply because it’s a circle)</p>\n</blockquote>\n<hr>\n<h4 id=\"Hyperparameters\"><a href=\"#Hyperparameters\" class=\"headerlink\" title=\"Hyperparameters\"></a><strong>Hyperparameters</strong></h4><ul>\n<li>What’s the best value of <strong>k</strong></li>\n<li>What’s the best <strong>distance</strong> to use? (L1,L2 or anything else)</li>\n</ul>\n<p><em>These things are preset rather than learn automatically from learning process</em></p>\n<p>This is <strong>Very problem-dependent</strong>, just try!, but How?</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIME1P.png\" alt></p>\n<p><strong>Training &amp; Validation process should not mixed with the test data</strong></p>\n<ul>\n<li>Cross Validation</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMApt.png\" alt></p>\n<ul>\n<li>Validation process</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMV6f.png\" alt></p>\n<blockquote>\n<p>using the validation data to choose the best hyperparameters.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMu7Q.png\" alt></p>\n<blockquote>\n<p>Cause we sum the offset, though the differences bettween pics and pics are various, they still got the same L2 distance, which is not so good.</p>\n</blockquote>\n<hr>\n<h3 id=\"Linear-Classification\"><a href=\"#Linear-Classification\" class=\"headerlink\" title=\"Linear Classification\"></a><strong>Linear Classification</strong></h3><ul>\n<li><strong>Parametric Model</strong><br><img src=\"https://s1.ax1x.com/2020/11/07/BIMZX8.png\" alt></li>\n</ul>\n<script type=\"math/tex; mode=display\">f(x,W) = Wx + b</script><blockquote>\n<p>We need f(x,W) to be 10x1 and the x is actually 3072x1, so the W we input may be 10x3072, sometimes we add a bias to balance.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMn0g.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/07/BIMMkj.png\" alt></p>\n<blockquote>\n<p>It use a single line to separate the object based on its RGB info</p>\n</blockquote>\n<p>But how can we tell the quality of W ?<br>(View the next lecture)</p>\n<ul>\n<li><strong>Problems</strong><br><img src=\"https://s1.ax1x.com/2020/11/07/BIMQts.png\" alt></li>\n</ul>\n<blockquote>\n<p>Since it’s linear the Problems is obivious.</p>\n</blockquote>\n"},{"title":"CS231n Training Neural Networks II 06","date":"2020-11-13T13:11:23.000Z","index_img":"/img/Cs231n/top.jpg","math":true,"_content":"\n### PreView\n- Fancier optimization\n- Regularization\n- Transfer Learning\n\n---\n\n### Problem with SGD\n\n![](https://s3.ax1x.com/2020/11/13/D9JOns.png)\n\n> The zig-zag path reveal the drawbacks of SGD\n\n![](https://s3.ax1x.com/2020/11/13/D9JbcQ.png)\n\n> Stuck in the local minima.\n\n- Saddle points much more common in high dimension.\n\n**Add an Momentum term may solve these problems**\n\n![](https://s3.ax1x.com/2020/11/13/D9JqXj.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9JXBn.png)\n\n> Owing to the exsistance of momentum we can training more faster and overcome the problems mentioned before.\n\n\n![](https://s3.ax1x.com/2020/11/13/D9JH1g.png)\n\n- **Nesterov Momentum**\n\n$$v_{t+1} = \\rho{v_t}-\\alpha{\\nabla{f(x_t+\\rho{v_t})}}\n\\\\\nx_{t+1} = x_t + v_{t+1}\n$$\n\n![](https://s3.ax1x.com/2020/11/13/D9Jj7q.png)\n\n> some kind error correcting term of present v and the previous v\n\n![](https://s3.ax1x.com/2020/11/13/D9JzNV.png)\n\n---\n\n### AdaGrad\n\n```python\ngrad_squared = 0\nwhile True:\n    dx = compute_gradient(x)\n    grad_squared += dx * dx\n    x -= learning_rate * dx / (np.sqrt(grad_squared) + 1e-7)\n```\n\n> The basic idea about AdaGrad algorithm is that the step of dimention with smaller gradients will be divided by small vals and make it move faster, while greater one slower to avoid zig-zag behavior.\n\n> while the step will become smaller and smaller while you get closer to the minima, but in turn with higher risks to stuck in the local minima.\n\n---\n\n### RMSProp\n\n![](https://s3.ax1x.com/2020/11/13/D9JxA0.png)\n\n> With a decay rate to make a smooth stop the reducing of steps.\n\n![](https://s3.ax1x.com/2020/11/13/D9Y99U.png)\n\n---\n\n### Adam (almost)\n\n```python\nfirst_moment = 0\nsecond_moment = 0\nwhile True:\n    dx = compute_gradient(x)\n    first_moment = beta1 + first_moment + (1 - beta1) * dx\n    # Momentum\n    second_moment = beta2 * second_moment + (1 - beta2) * dx * dx\n    # AdaGrad / RMSProp\n    x -= learning_rate * first_moment / (np.sqrt(second_moment) + 1e-7)\n```\n\n> It combine the two methods, but with a little bug of the first step, which gonna be super large.\n\n### Adam (full form)\n\n```python\nfirst_moment = 0\nsecond_moment = 0\nfor t in range(num_iterations):\n    dx = compute_gradient(x)\n    first_moment = beta1 + first_moment + (1 - beta1) * dx\n    # Momentum\n    second_moment = beta2 * second_moment + (1 - beta2) * dx * dx\n    # AdaGrad / RMSProp\n    first_unbias = first_moment / (1 - beta1 ** t)\n    second_unbias = second_moment / (1 - beta2 ** t)\n    x -= learning_rate * first_unbias / (np.sqrt(second_unbias) + 1e-7)\n```\n\n> Bias correction for the fact that first and second moment estimates start at zero\n\n- Great starting point\n1. beta1 = 0.9\n2. beta2 = 0.999\n3. learning_rate = 1e-3 or 5e-4\n\n---\n\n### Decay the learning rate to make it finer\n\n![](https://s3.ax1x.com/2020/11/13/D9YShT.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9YPc4.png)\n\n---\n\n### little bit Fancier Optimization \n\n![](https://s3.ax1x.com/2020/11/13/D9YC3F.png)\n\n> First derivative optimization\n\n![](https://s3.ax1x.com/2020/11/13/D9YijJ.png)\n\n> Second derivative optimization, direct to the mini\n\n![](https://s3.ax1x.com/2020/11/13/D9Yku9.png)\n\n> Don't need learning rate, but impractical for Hessian has O(N^2) elements and Inverting takes O(N^3)\n\n#### Quasi - Newton methods (BGFS)\n\n![](https://s3.ax1x.com/2020/11/13/D9YABR.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9YEH1.png)\n\n---\n\n### In Practice:\n\n- Using Adam\n- If full batch updates can be afforded, try out **L-BFGS**\n\n---\n\n### Reduce the gap between train and unseen data\n\n#### Model Ensembles\n\n1. Train multiple independent models\n2. At test time average their results\n\n2% improvement maybe\n\n![](https://s3.ax1x.com/2020/11/13/D9YeN6.png)\n\n> Instead of using actual parameter vector, keep a moving average of the para vector and use that at test time\n\n```python\nwhile True:\n    data_batch = dataset.sample_data_batch()\n    loss = network.forward(data_batch)\n    dx = network.backward()\n    x += - learning_rate * dx\n    x_test = 0.995*x_test + 0.005*x\n```\n\n#### Regularization to make single model performs better\n\n- Dropout\n\n![](https://s3.ax1x.com/2020/11/13/D9Ym4K.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9YK3D.png)\n\n> Another interpretation is that you can percive each binary mask as a single model, so it just like dropout is training a large ensemble of models with shared paras.\n\n![](https://s3.ax1x.com/2020/11/13/D9Yu9O.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9YMge.png)\n\n#### Batch Normalization\n\n> Which can achieve the same effect as the Dropout, for it includes some noises.\n#### Data Augmentation\n\n> To introduce noise to make it performs better on unseen data.\n\n![](https://s3.ax1x.com/2020/11/13/D9YQjH.png)\n\n#### Stochastic Depth\n\n> Randomly drop layers during training.\n> Use the full networks during testing.\n\n---\n\n### Transfer Learning\n\n> There is no need for huge amount of data.\n\n![](https://s3.ax1x.com/2020/11/13/D9Y1ud.png)\n","source":"_posts/CS231n/CS231n-06-Training-Neural-Networks-II.md","raw":"---\ntitle: CS231n Training Neural Networks II 06\ndate: 2020-11-13 21:11:23\ntags: [CV,Neural Network]\ncategory: [CS231n]\nindex_img: /img/Cs231n/top.jpg\nmath: true\n---\n\n### PreView\n- Fancier optimization\n- Regularization\n- Transfer Learning\n\n---\n\n### Problem with SGD\n\n![](https://s3.ax1x.com/2020/11/13/D9JOns.png)\n\n> The zig-zag path reveal the drawbacks of SGD\n\n![](https://s3.ax1x.com/2020/11/13/D9JbcQ.png)\n\n> Stuck in the local minima.\n\n- Saddle points much more common in high dimension.\n\n**Add an Momentum term may solve these problems**\n\n![](https://s3.ax1x.com/2020/11/13/D9JqXj.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9JXBn.png)\n\n> Owing to the exsistance of momentum we can training more faster and overcome the problems mentioned before.\n\n\n![](https://s3.ax1x.com/2020/11/13/D9JH1g.png)\n\n- **Nesterov Momentum**\n\n$$v_{t+1} = \\rho{v_t}-\\alpha{\\nabla{f(x_t+\\rho{v_t})}}\n\\\\\nx_{t+1} = x_t + v_{t+1}\n$$\n\n![](https://s3.ax1x.com/2020/11/13/D9Jj7q.png)\n\n> some kind error correcting term of present v and the previous v\n\n![](https://s3.ax1x.com/2020/11/13/D9JzNV.png)\n\n---\n\n### AdaGrad\n\n```python\ngrad_squared = 0\nwhile True:\n    dx = compute_gradient(x)\n    grad_squared += dx * dx\n    x -= learning_rate * dx / (np.sqrt(grad_squared) + 1e-7)\n```\n\n> The basic idea about AdaGrad algorithm is that the step of dimention with smaller gradients will be divided by small vals and make it move faster, while greater one slower to avoid zig-zag behavior.\n\n> while the step will become smaller and smaller while you get closer to the minima, but in turn with higher risks to stuck in the local minima.\n\n---\n\n### RMSProp\n\n![](https://s3.ax1x.com/2020/11/13/D9JxA0.png)\n\n> With a decay rate to make a smooth stop the reducing of steps.\n\n![](https://s3.ax1x.com/2020/11/13/D9Y99U.png)\n\n---\n\n### Adam (almost)\n\n```python\nfirst_moment = 0\nsecond_moment = 0\nwhile True:\n    dx = compute_gradient(x)\n    first_moment = beta1 + first_moment + (1 - beta1) * dx\n    # Momentum\n    second_moment = beta2 * second_moment + (1 - beta2) * dx * dx\n    # AdaGrad / RMSProp\n    x -= learning_rate * first_moment / (np.sqrt(second_moment) + 1e-7)\n```\n\n> It combine the two methods, but with a little bug of the first step, which gonna be super large.\n\n### Adam (full form)\n\n```python\nfirst_moment = 0\nsecond_moment = 0\nfor t in range(num_iterations):\n    dx = compute_gradient(x)\n    first_moment = beta1 + first_moment + (1 - beta1) * dx\n    # Momentum\n    second_moment = beta2 * second_moment + (1 - beta2) * dx * dx\n    # AdaGrad / RMSProp\n    first_unbias = first_moment / (1 - beta1 ** t)\n    second_unbias = second_moment / (1 - beta2 ** t)\n    x -= learning_rate * first_unbias / (np.sqrt(second_unbias) + 1e-7)\n```\n\n> Bias correction for the fact that first and second moment estimates start at zero\n\n- Great starting point\n1. beta1 = 0.9\n2. beta2 = 0.999\n3. learning_rate = 1e-3 or 5e-4\n\n---\n\n### Decay the learning rate to make it finer\n\n![](https://s3.ax1x.com/2020/11/13/D9YShT.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9YPc4.png)\n\n---\n\n### little bit Fancier Optimization \n\n![](https://s3.ax1x.com/2020/11/13/D9YC3F.png)\n\n> First derivative optimization\n\n![](https://s3.ax1x.com/2020/11/13/D9YijJ.png)\n\n> Second derivative optimization, direct to the mini\n\n![](https://s3.ax1x.com/2020/11/13/D9Yku9.png)\n\n> Don't need learning rate, but impractical for Hessian has O(N^2) elements and Inverting takes O(N^3)\n\n#### Quasi - Newton methods (BGFS)\n\n![](https://s3.ax1x.com/2020/11/13/D9YABR.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9YEH1.png)\n\n---\n\n### In Practice:\n\n- Using Adam\n- If full batch updates can be afforded, try out **L-BFGS**\n\n---\n\n### Reduce the gap between train and unseen data\n\n#### Model Ensembles\n\n1. Train multiple independent models\n2. At test time average their results\n\n2% improvement maybe\n\n![](https://s3.ax1x.com/2020/11/13/D9YeN6.png)\n\n> Instead of using actual parameter vector, keep a moving average of the para vector and use that at test time\n\n```python\nwhile True:\n    data_batch = dataset.sample_data_batch()\n    loss = network.forward(data_batch)\n    dx = network.backward()\n    x += - learning_rate * dx\n    x_test = 0.995*x_test + 0.005*x\n```\n\n#### Regularization to make single model performs better\n\n- Dropout\n\n![](https://s3.ax1x.com/2020/11/13/D9Ym4K.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9YK3D.png)\n\n> Another interpretation is that you can percive each binary mask as a single model, so it just like dropout is training a large ensemble of models with shared paras.\n\n![](https://s3.ax1x.com/2020/11/13/D9Yu9O.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9YMge.png)\n\n#### Batch Normalization\n\n> Which can achieve the same effect as the Dropout, for it includes some noises.\n#### Data Augmentation\n\n> To introduce noise to make it performs better on unseen data.\n\n![](https://s3.ax1x.com/2020/11/13/D9YQjH.png)\n\n#### Stochastic Depth\n\n> Randomly drop layers during training.\n> Use the full networks during testing.\n\n---\n\n### Transfer Learning\n\n> There is no need for huge amount of data.\n\n![](https://s3.ax1x.com/2020/11/13/D9Y1ud.png)\n","slug":"CS231n/CS231n-06-Training-Neural-Networks-II","published":1,"updated":"2020-12-09T01:22:55.792Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty3r000gs8pd9zhx04nq","content":"<h3 id=\"PreView\"><a href=\"#PreView\" class=\"headerlink\" title=\"PreView\"></a>PreView</h3><ul>\n<li>Fancier optimization</li>\n<li>Regularization</li>\n<li>Transfer Learning</li>\n</ul>\n<hr>\n<h3 id=\"Problem-with-SGD\"><a href=\"#Problem-with-SGD\" class=\"headerlink\" title=\"Problem with SGD\"></a>Problem with SGD</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9JOns.png\" alt></p>\n<blockquote>\n<p>The zig-zag path reveal the drawbacks of SGD</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9JbcQ.png\" alt></p>\n<blockquote>\n<p>Stuck in the local minima.</p>\n</blockquote>\n<ul>\n<li>Saddle points much more common in high dimension.</li>\n</ul>\n<p><strong>Add an Momentum term may solve these problems</strong></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9JqXj.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9JXBn.png\" alt></p>\n<blockquote>\n<p>Owing to the exsistance of momentum we can training more faster and overcome the problems mentioned before.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9JH1g.png\" alt></p>\n<ul>\n<li><strong>Nesterov Momentum</strong></li>\n</ul>\n<script type=\"math/tex; mode=display\">v_{t+1} = \\rho{v_t}-\\alpha{\\nabla{f(x_t+\\rho{v_t})}}\n\\\\\nx_{t+1} = x_t + v_{t+1}</script><p><img src=\"https://s3.ax1x.com/2020/11/13/D9Jj7q.png\" alt></p>\n<blockquote>\n<p>some kind error correcting term of present v and the previous v</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9JzNV.png\" alt></p>\n<hr>\n<h3 id=\"AdaGrad\"><a href=\"#AdaGrad\" class=\"headerlink\" title=\"AdaGrad\"></a>AdaGrad</h3><pre><code class=\"hljs python\">grad_squared = <span class=\"hljs-number\">0</span>\n<span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n    dx = compute_gradient(x)\n    grad_squared += dx * dx\n    x -= learning_rate * dx / (np.sqrt(grad_squared) + <span class=\"hljs-number\">1e-7</span>)</code></pre>\n<blockquote>\n<p>The basic idea about AdaGrad algorithm is that the step of dimention with smaller gradients will be divided by small vals and make it move faster, while greater one slower to avoid zig-zag behavior.</p>\n<p>while the step will become smaller and smaller while you get closer to the minima, but in turn with higher risks to stuck in the local minima.</p>\n</blockquote>\n<hr>\n<h3 id=\"RMSProp\"><a href=\"#RMSProp\" class=\"headerlink\" title=\"RMSProp\"></a>RMSProp</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9JxA0.png\" alt></p>\n<blockquote>\n<p>With a decay rate to make a smooth stop the reducing of steps.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Y99U.png\" alt></p>\n<hr>\n<h3 id=\"Adam-almost\"><a href=\"#Adam-almost\" class=\"headerlink\" title=\"Adam (almost)\"></a>Adam (almost)</h3><pre><code class=\"hljs python\">first_moment = <span class=\"hljs-number\">0</span>\nsecond_moment = <span class=\"hljs-number\">0</span>\n<span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n    dx = compute_gradient(x)\n    first_moment = beta1 + first_moment + (<span class=\"hljs-number\">1</span> - beta1) * dx\n    <span class=\"hljs-comment\"># Momentum</span>\n    second_moment = beta2 * second_moment + (<span class=\"hljs-number\">1</span> - beta2) * dx * dx\n    <span class=\"hljs-comment\"># AdaGrad / RMSProp</span>\n    x -= learning_rate * first_moment / (np.sqrt(second_moment) + <span class=\"hljs-number\">1e-7</span>)</code></pre>\n<blockquote>\n<p>It combine the two methods, but with a little bug of the first step, which gonna be super large.</p>\n</blockquote>\n<h3 id=\"Adam-full-form\"><a href=\"#Adam-full-form\" class=\"headerlink\" title=\"Adam (full form)\"></a>Adam (full form)</h3><pre><code class=\"hljs python\">first_moment = <span class=\"hljs-number\">0</span>\nsecond_moment = <span class=\"hljs-number\">0</span>\n<span class=\"hljs-keyword\">for</span> t <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(num_iterations):\n    dx = compute_gradient(x)\n    first_moment = beta1 + first_moment + (<span class=\"hljs-number\">1</span> - beta1) * dx\n    <span class=\"hljs-comment\"># Momentum</span>\n    second_moment = beta2 * second_moment + (<span class=\"hljs-number\">1</span> - beta2) * dx * dx\n    <span class=\"hljs-comment\"># AdaGrad / RMSProp</span>\n    first_unbias = first_moment / (<span class=\"hljs-number\">1</span> - beta1 ** t)\n    second_unbias = second_moment / (<span class=\"hljs-number\">1</span> - beta2 ** t)\n    x -= learning_rate * first_unbias / (np.sqrt(second_unbias) + <span class=\"hljs-number\">1e-7</span>)</code></pre>\n<blockquote>\n<p>Bias correction for the fact that first and second moment estimates start at zero</p>\n</blockquote>\n<ul>\n<li>Great starting point</li>\n</ul>\n<ol>\n<li>beta1 = 0.9</li>\n<li>beta2 = 0.999</li>\n<li>learning_rate = 1e-3 or 5e-4</li>\n</ol>\n<hr>\n<h3 id=\"Decay-the-learning-rate-to-make-it-finer\"><a href=\"#Decay-the-learning-rate-to-make-it-finer\" class=\"headerlink\" title=\"Decay the learning rate to make it finer\"></a>Decay the learning rate to make it finer</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9YShT.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YPc4.png\" alt></p>\n<hr>\n<h3 id=\"little-bit-Fancier-Optimization\"><a href=\"#little-bit-Fancier-Optimization\" class=\"headerlink\" title=\"little bit Fancier Optimization\"></a>little bit Fancier Optimization</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9YC3F.png\" alt></p>\n<blockquote>\n<p>First derivative optimization</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YijJ.png\" alt></p>\n<blockquote>\n<p>Second derivative optimization, direct to the mini</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Yku9.png\" alt></p>\n<blockquote>\n<p>Don’t need learning rate, but impractical for Hessian has O(N^2) elements and Inverting takes O(N^3)</p>\n</blockquote>\n<h4 id=\"Quasi-Newton-methods-BGFS\"><a href=\"#Quasi-Newton-methods-BGFS\" class=\"headerlink\" title=\"Quasi - Newton methods (BGFS)\"></a>Quasi - Newton methods (BGFS)</h4><p><img src=\"https://s3.ax1x.com/2020/11/13/D9YABR.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YEH1.png\" alt></p>\n<hr>\n<h3 id=\"In-Practice\"><a href=\"#In-Practice\" class=\"headerlink\" title=\"In Practice:\"></a>In Practice:</h3><ul>\n<li>Using Adam</li>\n<li>If full batch updates can be afforded, try out <strong>L-BFGS</strong></li>\n</ul>\n<hr>\n<h3 id=\"Reduce-the-gap-between-train-and-unseen-data\"><a href=\"#Reduce-the-gap-between-train-and-unseen-data\" class=\"headerlink\" title=\"Reduce the gap between train and unseen data\"></a>Reduce the gap between train and unseen data</h3><h4 id=\"Model-Ensembles\"><a href=\"#Model-Ensembles\" class=\"headerlink\" title=\"Model Ensembles\"></a>Model Ensembles</h4><ol>\n<li>Train multiple independent models</li>\n<li>At test time average their results</li>\n</ol>\n<p>2% improvement maybe</p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YeN6.png\" alt></p>\n<blockquote>\n<p>Instead of using actual parameter vector, keep a moving average of the para vector and use that at test time</p>\n</blockquote>\n<pre><code class=\"hljs python\"><span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n    data_batch = dataset.sample_data_batch()\n    loss = network.forward(data_batch)\n    dx = network.backward()\n    x += - learning_rate * dx\n    x_test = <span class=\"hljs-number\">0.995</span>*x_test + <span class=\"hljs-number\">0.005</span>*x</code></pre>\n<h4 id=\"Regularization-to-make-single-model-performs-better\"><a href=\"#Regularization-to-make-single-model-performs-better\" class=\"headerlink\" title=\"Regularization to make single model performs better\"></a>Regularization to make single model performs better</h4><ul>\n<li>Dropout</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Ym4K.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YK3D.png\" alt></p>\n<blockquote>\n<p>Another interpretation is that you can percive each binary mask as a single model, so it just like dropout is training a large ensemble of models with shared paras.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Yu9O.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YMge.png\" alt></p>\n<h4 id=\"Batch-Normalization\"><a href=\"#Batch-Normalization\" class=\"headerlink\" title=\"Batch Normalization\"></a>Batch Normalization</h4><blockquote>\n<p>Which can achieve the same effect as the Dropout, for it includes some noises.</p>\n<h4 id=\"Data-Augmentation\"><a href=\"#Data-Augmentation\" class=\"headerlink\" title=\"Data Augmentation\"></a>Data Augmentation</h4><p>To introduce noise to make it performs better on unseen data.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YQjH.png\" alt></p>\n<h4 id=\"Stochastic-Depth\"><a href=\"#Stochastic-Depth\" class=\"headerlink\" title=\"Stochastic Depth\"></a>Stochastic Depth</h4><blockquote>\n<p>Randomly drop layers during training.<br>Use the full networks during testing.</p>\n</blockquote>\n<hr>\n<h3 id=\"Transfer-Learning\"><a href=\"#Transfer-Learning\" class=\"headerlink\" title=\"Transfer Learning\"></a>Transfer Learning</h3><blockquote>\n<p>There is no need for huge amount of data.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Y1ud.png\" alt></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"PreView\"><a href=\"#PreView\" class=\"headerlink\" title=\"PreView\"></a>PreView</h3><ul>\n<li>Fancier optimization</li>\n<li>Regularization</li>\n<li>Transfer Learning</li>\n</ul>\n<hr>\n<h3 id=\"Problem-with-SGD\"><a href=\"#Problem-with-SGD\" class=\"headerlink\" title=\"Problem with SGD\"></a>Problem with SGD</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9JOns.png\" alt></p>\n<blockquote>\n<p>The zig-zag path reveal the drawbacks of SGD</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9JbcQ.png\" alt></p>\n<blockquote>\n<p>Stuck in the local minima.</p>\n</blockquote>\n<ul>\n<li>Saddle points much more common in high dimension.</li>\n</ul>\n<p><strong>Add an Momentum term may solve these problems</strong></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9JqXj.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9JXBn.png\" alt></p>\n<blockquote>\n<p>Owing to the exsistance of momentum we can training more faster and overcome the problems mentioned before.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9JH1g.png\" alt></p>\n<ul>\n<li><strong>Nesterov Momentum</strong></li>\n</ul>\n<script type=\"math/tex; mode=display\">v_{t+1} = \\rho{v_t}-\\alpha{\\nabla{f(x_t+\\rho{v_t})}}\n\\\\\nx_{t+1} = x_t + v_{t+1}</script><p><img src=\"https://s3.ax1x.com/2020/11/13/D9Jj7q.png\" alt></p>\n<blockquote>\n<p>some kind error correcting term of present v and the previous v</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9JzNV.png\" alt></p>\n<hr>\n<h3 id=\"AdaGrad\"><a href=\"#AdaGrad\" class=\"headerlink\" title=\"AdaGrad\"></a>AdaGrad</h3><pre><code class=\"hljs python\">grad_squared = <span class=\"hljs-number\">0</span>\n<span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n    dx = compute_gradient(x)\n    grad_squared += dx * dx\n    x -= learning_rate * dx / (np.sqrt(grad_squared) + <span class=\"hljs-number\">1e-7</span>)</code></pre>\n<blockquote>\n<p>The basic idea about AdaGrad algorithm is that the step of dimention with smaller gradients will be divided by small vals and make it move faster, while greater one slower to avoid zig-zag behavior.</p>\n<p>while the step will become smaller and smaller while you get closer to the minima, but in turn with higher risks to stuck in the local minima.</p>\n</blockquote>\n<hr>\n<h3 id=\"RMSProp\"><a href=\"#RMSProp\" class=\"headerlink\" title=\"RMSProp\"></a>RMSProp</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9JxA0.png\" alt></p>\n<blockquote>\n<p>With a decay rate to make a smooth stop the reducing of steps.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Y99U.png\" alt></p>\n<hr>\n<h3 id=\"Adam-almost\"><a href=\"#Adam-almost\" class=\"headerlink\" title=\"Adam (almost)\"></a>Adam (almost)</h3><pre><code class=\"hljs python\">first_moment = <span class=\"hljs-number\">0</span>\nsecond_moment = <span class=\"hljs-number\">0</span>\n<span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n    dx = compute_gradient(x)\n    first_moment = beta1 + first_moment + (<span class=\"hljs-number\">1</span> - beta1) * dx\n    <span class=\"hljs-comment\"># Momentum</span>\n    second_moment = beta2 * second_moment + (<span class=\"hljs-number\">1</span> - beta2) * dx * dx\n    <span class=\"hljs-comment\"># AdaGrad / RMSProp</span>\n    x -= learning_rate * first_moment / (np.sqrt(second_moment) + <span class=\"hljs-number\">1e-7</span>)</code></pre>\n<blockquote>\n<p>It combine the two methods, but with a little bug of the first step, which gonna be super large.</p>\n</blockquote>\n<h3 id=\"Adam-full-form\"><a href=\"#Adam-full-form\" class=\"headerlink\" title=\"Adam (full form)\"></a>Adam (full form)</h3><pre><code class=\"hljs python\">first_moment = <span class=\"hljs-number\">0</span>\nsecond_moment = <span class=\"hljs-number\">0</span>\n<span class=\"hljs-keyword\">for</span> t <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(num_iterations):\n    dx = compute_gradient(x)\n    first_moment = beta1 + first_moment + (<span class=\"hljs-number\">1</span> - beta1) * dx\n    <span class=\"hljs-comment\"># Momentum</span>\n    second_moment = beta2 * second_moment + (<span class=\"hljs-number\">1</span> - beta2) * dx * dx\n    <span class=\"hljs-comment\"># AdaGrad / RMSProp</span>\n    first_unbias = first_moment / (<span class=\"hljs-number\">1</span> - beta1 ** t)\n    second_unbias = second_moment / (<span class=\"hljs-number\">1</span> - beta2 ** t)\n    x -= learning_rate * first_unbias / (np.sqrt(second_unbias) + <span class=\"hljs-number\">1e-7</span>)</code></pre>\n<blockquote>\n<p>Bias correction for the fact that first and second moment estimates start at zero</p>\n</blockquote>\n<ul>\n<li>Great starting point</li>\n</ul>\n<ol>\n<li>beta1 = 0.9</li>\n<li>beta2 = 0.999</li>\n<li>learning_rate = 1e-3 or 5e-4</li>\n</ol>\n<hr>\n<h3 id=\"Decay-the-learning-rate-to-make-it-finer\"><a href=\"#Decay-the-learning-rate-to-make-it-finer\" class=\"headerlink\" title=\"Decay the learning rate to make it finer\"></a>Decay the learning rate to make it finer</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9YShT.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YPc4.png\" alt></p>\n<hr>\n<h3 id=\"little-bit-Fancier-Optimization\"><a href=\"#little-bit-Fancier-Optimization\" class=\"headerlink\" title=\"little bit Fancier Optimization\"></a>little bit Fancier Optimization</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9YC3F.png\" alt></p>\n<blockquote>\n<p>First derivative optimization</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YijJ.png\" alt></p>\n<blockquote>\n<p>Second derivative optimization, direct to the mini</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Yku9.png\" alt></p>\n<blockquote>\n<p>Don’t need learning rate, but impractical for Hessian has O(N^2) elements and Inverting takes O(N^3)</p>\n</blockquote>\n<h4 id=\"Quasi-Newton-methods-BGFS\"><a href=\"#Quasi-Newton-methods-BGFS\" class=\"headerlink\" title=\"Quasi - Newton methods (BGFS)\"></a>Quasi - Newton methods (BGFS)</h4><p><img src=\"https://s3.ax1x.com/2020/11/13/D9YABR.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YEH1.png\" alt></p>\n<hr>\n<h3 id=\"In-Practice\"><a href=\"#In-Practice\" class=\"headerlink\" title=\"In Practice:\"></a>In Practice:</h3><ul>\n<li>Using Adam</li>\n<li>If full batch updates can be afforded, try out <strong>L-BFGS</strong></li>\n</ul>\n<hr>\n<h3 id=\"Reduce-the-gap-between-train-and-unseen-data\"><a href=\"#Reduce-the-gap-between-train-and-unseen-data\" class=\"headerlink\" title=\"Reduce the gap between train and unseen data\"></a>Reduce the gap between train and unseen data</h3><h4 id=\"Model-Ensembles\"><a href=\"#Model-Ensembles\" class=\"headerlink\" title=\"Model Ensembles\"></a>Model Ensembles</h4><ol>\n<li>Train multiple independent models</li>\n<li>At test time average their results</li>\n</ol>\n<p>2% improvement maybe</p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YeN6.png\" alt></p>\n<blockquote>\n<p>Instead of using actual parameter vector, keep a moving average of the para vector and use that at test time</p>\n</blockquote>\n<pre><code class=\"hljs python\"><span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n    data_batch = dataset.sample_data_batch()\n    loss = network.forward(data_batch)\n    dx = network.backward()\n    x += - learning_rate * dx\n    x_test = <span class=\"hljs-number\">0.995</span>*x_test + <span class=\"hljs-number\">0.005</span>*x</code></pre>\n<h4 id=\"Regularization-to-make-single-model-performs-better\"><a href=\"#Regularization-to-make-single-model-performs-better\" class=\"headerlink\" title=\"Regularization to make single model performs better\"></a>Regularization to make single model performs better</h4><ul>\n<li>Dropout</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Ym4K.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YK3D.png\" alt></p>\n<blockquote>\n<p>Another interpretation is that you can percive each binary mask as a single model, so it just like dropout is training a large ensemble of models with shared paras.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Yu9O.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YMge.png\" alt></p>\n<h4 id=\"Batch-Normalization\"><a href=\"#Batch-Normalization\" class=\"headerlink\" title=\"Batch Normalization\"></a>Batch Normalization</h4><blockquote>\n<p>Which can achieve the same effect as the Dropout, for it includes some noises.</p>\n<h4 id=\"Data-Augmentation\"><a href=\"#Data-Augmentation\" class=\"headerlink\" title=\"Data Augmentation\"></a>Data Augmentation</h4><p>To introduce noise to make it performs better on unseen data.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9YQjH.png\" alt></p>\n<h4 id=\"Stochastic-Depth\"><a href=\"#Stochastic-Depth\" class=\"headerlink\" title=\"Stochastic Depth\"></a>Stochastic Depth</h4><blockquote>\n<p>Randomly drop layers during training.<br>Use the full networks during testing.</p>\n</blockquote>\n<hr>\n<h3 id=\"Transfer-Learning\"><a href=\"#Transfer-Learning\" class=\"headerlink\" title=\"Transfer Learning\"></a>Transfer Learning</h3><blockquote>\n<p>There is no need for huge amount of data.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Y1ud.png\" alt></p>\n"},{"title":"CS231n Training Neural Networks I 05","date":"2020-11-13T13:09:24.000Z","index_img":"/img/Cs231n/top.jpg","math":true,"_content":"\n### OverView\n1. One time setup\n2. Training dynamics\n3. Evaluation\n\n### Part 1\n- Activation Functions\n- Data Preprocessing\n- Weight initialization\n- Batch Normalization\n- Babysitting the Learning Process\n- Hyperparameter Optimization\n\n---\n\n### Activation Functions\n\n![](https://s3.ax1x.com/2020/11/13/D9uofs.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9uIYj.png)\n\n#### Sigmoid \n\n$$\\sigma(x) = 1/(1+e^{-x})$$\n\n- Squashes numbers to range [0,1]\n- Historically popular \"firing rate\" of a neuron\n\n![](https://s3.ax1x.com/2020/11/13/D9uhTg.png)\n\n**3 Problems**\n1. Saturated the neural may kill the gradient.\n\n![](https://s3.ax1x.com/2020/11/13/D9u5kQ.png)\n\n> x is a very negative and very positive val, its gradient will be killed to zero\n\n1. Sigmoid outputs are not zero-centered\n\n![](https://s3.ax1x.com/2020/11/13/D9u7pn.png)\n\n> For the sign of x and gradient is always the same, it gonna behaves like is above pic.\n\n> thats why we need zero-mean data, to optimize the w just through the zig zag path.\n\n1. exp() is a bit compute expensive\n\n---\n\n#### Tanh\n\n- Squashes numbers to range [-1, 1]\n- zero centered (nice)\n- still kills gradients when saturated\n\n![](https://s3.ax1x.com/2020/11/13/D9uHlq.png)\n\n---\n\n#### ReLU\n\n$$f(x) = max(0, x)$$\n\n![](https://s3.ax1x.com/2020/11/13/D9ub60.png)\n\n- Does not saturate (in + region)\n- Very computationally efficient\n- Converges much faster than sigmoid/tanh in practice\n- Actually more biologically plausible than sigmoid\n\n**Problems**\n1. Not zero-centered output\n2. An annoyance:\n3. when x <= 0 the gradient is slashed to zero (kill half the gradient)\n\n![](https://s3.ax1x.com/2020/11/13/D9uX0U.png)\n\n- Bad Init\n- Learning rate too high\n\n> people like to initialize ReLU neurons with slightly positive biases (eg 0.01), to increase the possibility that being activated.\n\n---\n\n#### Leaky ReLu\n\n$$f(x) = max(0.01x,x)$$\n\n![](https://s3.ax1x.com/2020/11/13/D9uqXV.png)\n\n- Does not saturated\n- Computationally efficient\n- Converges much faster ...\n- **will not die**\n\nor **Para Rectifier ReLu**\n\n$$f(x) = max(\\alpha{x},x)$$\n\n---\n\n#### Exponential Linear Units (ELU)\n\n![](https://s3.ax1x.com/2020/11/13/D9uOmT.png)\n\n- All benefits of ReLU\n- Closer to zero mean outputs\n- Negative saturation regime adds some robustness to noise\n\n*While it requires exp()*\n\n---\n\n#### Maxout \"Neuron\"\n\n![](https://s3.ax1x.com/2020/11/13/D9uj7F.png)\n\n---\n\n#### In practice\n\n- Use ReLU. (zbe careful with learning rates)\n- Try Leaky *ReLU / Maxout / ELU*\n- Don't use sigmoid\n\n---\n\n### Data Preprocessing\n\n#### Step1: Preprocess the data\n\n![](https://s3.ax1x.com/2020/11/13/D9uxk4.png)\n\n- In CV we usually don't normalize the data.\n\n![](https://s3.ax1x.com/2020/11/13/D9KSh9.png)\n\nPractice above make the data zero-mean, but only the first layer, and that's why we need the activation func tobe zero-mean.\n\n---\n\n### Weight Initialization\n\n#### First idea: Small random numbers\n\n```python\nW = 0.01* np.random.randn(D,H)\n```\n\n> Works Okay for small, but have problems in big one.\n\n![](https://s3.ax1x.com/2020/11/13/D9KC11.png)\n\n#### How about making Weight big?\n\n![](https://s3.ax1x.com/2020/11/13/D9KP6x.png)\n\n> it gonna saturated the regime to be either very possitive or very negative input of tanh, and comes out near zero gradients. The weight will not be updated.\n\n\n#### Xavier initialization\n*Woo my initialzation? haha*\n\n![](https://s3.ax1x.com/2020/11/13/D9KiX6.png)\n\n> ensure we are at the active region of tanh\n\n![](https://s3.ax1x.com/2020/11/13/D9KA0O.png)\n\n> Can be addressed by add an extra /2， to ensure the neural won't die in ReLU\n\n---\n\n### Batch Normalization\n\n![](https://s3.ax1x.com/2020/11/13/D9KknK.png)\n\n> To regulize the input tobe unit gaussian.\n\n*I have no idea about it. What is unit gaussian?*\n\n![](https://s3.ax1x.com/2020/11/13/D9KetH.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9KE7D.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9KZAe.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9Kmhd.png)\n\n---\n\n### Babysitting the Learning Process\n\n- 1. Preprocess data\n- 2. Choose the architecture:\n- 3. Double check that the loss is reasonable\n\n![](https://s3.ax1x.com/2020/11/13/D9KK1I.png)\n\n#### The Learning Rate\n\n- Very small learning rate 1e-6\n> litter help\n\n![](https://s3.ax1x.com/2020/11/13/D9K3B8.png)\n\n- Very great learning rate 1e6\n> go extreme\n\n![](https://s3.ax1x.com/2020/11/13/D9KQjP.png)\n\n- A Rough Range\n\n$$1\\times{10}^{-3} \\to 1\\times{10}^{-5} $$\n\n---\n\n### Hyperparameter Optimization\n\n- Cross-validation strategy\n*coarse -> fine*\n\n- Random Sample\n\n![](https://s3.ax1x.com/2020/11/13/D9Ku9A.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9KMct.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9K1nf.png)\n","source":"_posts/CS231n/CS231n-05-Training-Neural-Networks-I.md","raw":"---\ntitle: CS231n Training Neural Networks I 05\ndate: 2020-11-13 21:09:24\ntags: [CV,Neural Network]\ncategory: [CS231n]\nindex_img: /img/Cs231n/top.jpg\nmath: true\n---\n\n### OverView\n1. One time setup\n2. Training dynamics\n3. Evaluation\n\n### Part 1\n- Activation Functions\n- Data Preprocessing\n- Weight initialization\n- Batch Normalization\n- Babysitting the Learning Process\n- Hyperparameter Optimization\n\n---\n\n### Activation Functions\n\n![](https://s3.ax1x.com/2020/11/13/D9uofs.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9uIYj.png)\n\n#### Sigmoid \n\n$$\\sigma(x) = 1/(1+e^{-x})$$\n\n- Squashes numbers to range [0,1]\n- Historically popular \"firing rate\" of a neuron\n\n![](https://s3.ax1x.com/2020/11/13/D9uhTg.png)\n\n**3 Problems**\n1. Saturated the neural may kill the gradient.\n\n![](https://s3.ax1x.com/2020/11/13/D9u5kQ.png)\n\n> x is a very negative and very positive val, its gradient will be killed to zero\n\n1. Sigmoid outputs are not zero-centered\n\n![](https://s3.ax1x.com/2020/11/13/D9u7pn.png)\n\n> For the sign of x and gradient is always the same, it gonna behaves like is above pic.\n\n> thats why we need zero-mean data, to optimize the w just through the zig zag path.\n\n1. exp() is a bit compute expensive\n\n---\n\n#### Tanh\n\n- Squashes numbers to range [-1, 1]\n- zero centered (nice)\n- still kills gradients when saturated\n\n![](https://s3.ax1x.com/2020/11/13/D9uHlq.png)\n\n---\n\n#### ReLU\n\n$$f(x) = max(0, x)$$\n\n![](https://s3.ax1x.com/2020/11/13/D9ub60.png)\n\n- Does not saturate (in + region)\n- Very computationally efficient\n- Converges much faster than sigmoid/tanh in practice\n- Actually more biologically plausible than sigmoid\n\n**Problems**\n1. Not zero-centered output\n2. An annoyance:\n3. when x <= 0 the gradient is slashed to zero (kill half the gradient)\n\n![](https://s3.ax1x.com/2020/11/13/D9uX0U.png)\n\n- Bad Init\n- Learning rate too high\n\n> people like to initialize ReLU neurons with slightly positive biases (eg 0.01), to increase the possibility that being activated.\n\n---\n\n#### Leaky ReLu\n\n$$f(x) = max(0.01x,x)$$\n\n![](https://s3.ax1x.com/2020/11/13/D9uqXV.png)\n\n- Does not saturated\n- Computationally efficient\n- Converges much faster ...\n- **will not die**\n\nor **Para Rectifier ReLu**\n\n$$f(x) = max(\\alpha{x},x)$$\n\n---\n\n#### Exponential Linear Units (ELU)\n\n![](https://s3.ax1x.com/2020/11/13/D9uOmT.png)\n\n- All benefits of ReLU\n- Closer to zero mean outputs\n- Negative saturation regime adds some robustness to noise\n\n*While it requires exp()*\n\n---\n\n#### Maxout \"Neuron\"\n\n![](https://s3.ax1x.com/2020/11/13/D9uj7F.png)\n\n---\n\n#### In practice\n\n- Use ReLU. (zbe careful with learning rates)\n- Try Leaky *ReLU / Maxout / ELU*\n- Don't use sigmoid\n\n---\n\n### Data Preprocessing\n\n#### Step1: Preprocess the data\n\n![](https://s3.ax1x.com/2020/11/13/D9uxk4.png)\n\n- In CV we usually don't normalize the data.\n\n![](https://s3.ax1x.com/2020/11/13/D9KSh9.png)\n\nPractice above make the data zero-mean, but only the first layer, and that's why we need the activation func tobe zero-mean.\n\n---\n\n### Weight Initialization\n\n#### First idea: Small random numbers\n\n```python\nW = 0.01* np.random.randn(D,H)\n```\n\n> Works Okay for small, but have problems in big one.\n\n![](https://s3.ax1x.com/2020/11/13/D9KC11.png)\n\n#### How about making Weight big?\n\n![](https://s3.ax1x.com/2020/11/13/D9KP6x.png)\n\n> it gonna saturated the regime to be either very possitive or very negative input of tanh, and comes out near zero gradients. The weight will not be updated.\n\n\n#### Xavier initialization\n*Woo my initialzation? haha*\n\n![](https://s3.ax1x.com/2020/11/13/D9KiX6.png)\n\n> ensure we are at the active region of tanh\n\n![](https://s3.ax1x.com/2020/11/13/D9KA0O.png)\n\n> Can be addressed by add an extra /2， to ensure the neural won't die in ReLU\n\n---\n\n### Batch Normalization\n\n![](https://s3.ax1x.com/2020/11/13/D9KknK.png)\n\n> To regulize the input tobe unit gaussian.\n\n*I have no idea about it. What is unit gaussian?*\n\n![](https://s3.ax1x.com/2020/11/13/D9KetH.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9KE7D.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9KZAe.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9Kmhd.png)\n\n---\n\n### Babysitting the Learning Process\n\n- 1. Preprocess data\n- 2. Choose the architecture:\n- 3. Double check that the loss is reasonable\n\n![](https://s3.ax1x.com/2020/11/13/D9KK1I.png)\n\n#### The Learning Rate\n\n- Very small learning rate 1e-6\n> litter help\n\n![](https://s3.ax1x.com/2020/11/13/D9K3B8.png)\n\n- Very great learning rate 1e6\n> go extreme\n\n![](https://s3.ax1x.com/2020/11/13/D9KQjP.png)\n\n- A Rough Range\n\n$$1\\times{10}^{-3} \\to 1\\times{10}^{-5} $$\n\n---\n\n### Hyperparameter Optimization\n\n- Cross-validation strategy\n*coarse -> fine*\n\n- Random Sample\n\n![](https://s3.ax1x.com/2020/11/13/D9Ku9A.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9KMct.png)\n\n![](https://s3.ax1x.com/2020/11/13/D9K1nf.png)\n","slug":"CS231n/CS231n-05-Training-Neural-Networks-I","published":1,"updated":"2020-12-09T01:22:54.187Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty3s000is8pd5wt640m8","content":"<h3 id=\"OverView\"><a href=\"#OverView\" class=\"headerlink\" title=\"OverView\"></a>OverView</h3><ol>\n<li>One time setup</li>\n<li>Training dynamics</li>\n<li>Evaluation</li>\n</ol>\n<h3 id=\"Part-1\"><a href=\"#Part-1\" class=\"headerlink\" title=\"Part 1\"></a>Part 1</h3><ul>\n<li>Activation Functions</li>\n<li>Data Preprocessing</li>\n<li>Weight initialization</li>\n<li>Batch Normalization</li>\n<li>Babysitting the Learning Process</li>\n<li>Hyperparameter Optimization</li>\n</ul>\n<hr>\n<h3 id=\"Activation-Functions\"><a href=\"#Activation-Functions\" class=\"headerlink\" title=\"Activation Functions\"></a>Activation Functions</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9uofs.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9uIYj.png\" alt></p>\n<h4 id=\"Sigmoid\"><a href=\"#Sigmoid\" class=\"headerlink\" title=\"Sigmoid\"></a>Sigmoid</h4><script type=\"math/tex; mode=display\">\\sigma(x) = 1/(1+e^{-x})</script><ul>\n<li>Squashes numbers to range [0,1]</li>\n<li>Historically popular “firing rate” of a neuron</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9uhTg.png\" alt></p>\n<p><strong>3 Problems</strong></p>\n<ol>\n<li>Saturated the neural may kill the gradient.</li>\n</ol>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9u5kQ.png\" alt></p>\n<blockquote>\n<p>x is a very negative and very positive val, its gradient will be killed to zero</p>\n</blockquote>\n<ol>\n<li>Sigmoid outputs are not zero-centered</li>\n</ol>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9u7pn.png\" alt></p>\n<blockquote>\n<p>For the sign of x and gradient is always the same, it gonna behaves like is above pic.</p>\n<p>thats why we need zero-mean data, to optimize the w just through the zig zag path.</p>\n</blockquote>\n<ol>\n<li>exp() is a bit compute expensive</li>\n</ol>\n<hr>\n<h4 id=\"Tanh\"><a href=\"#Tanh\" class=\"headerlink\" title=\"Tanh\"></a>Tanh</h4><ul>\n<li>Squashes numbers to range [-1, 1]</li>\n<li>zero centered (nice)</li>\n<li>still kills gradients when saturated</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9uHlq.png\" alt></p>\n<hr>\n<h4 id=\"ReLU\"><a href=\"#ReLU\" class=\"headerlink\" title=\"ReLU\"></a>ReLU</h4><script type=\"math/tex; mode=display\">f(x) = max(0, x)</script><p><img src=\"https://s3.ax1x.com/2020/11/13/D9ub60.png\" alt></p>\n<ul>\n<li>Does not saturate (in + region)</li>\n<li>Very computationally efficient</li>\n<li>Converges much faster than sigmoid/tanh in practice</li>\n<li>Actually more biologically plausible than sigmoid</li>\n</ul>\n<p><strong>Problems</strong></p>\n<ol>\n<li>Not zero-centered output</li>\n<li>An annoyance:</li>\n<li>when x &lt;= 0 the gradient is slashed to zero (kill half the gradient)</li>\n</ol>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9uX0U.png\" alt></p>\n<ul>\n<li>Bad Init</li>\n<li>Learning rate too high</li>\n</ul>\n<blockquote>\n<p>people like to initialize ReLU neurons with slightly positive biases (eg 0.01), to increase the possibility that being activated.</p>\n</blockquote>\n<hr>\n<h4 id=\"Leaky-ReLu\"><a href=\"#Leaky-ReLu\" class=\"headerlink\" title=\"Leaky ReLu\"></a>Leaky ReLu</h4><script type=\"math/tex; mode=display\">f(x) = max(0.01x,x)</script><p><img src=\"https://s3.ax1x.com/2020/11/13/D9uqXV.png\" alt></p>\n<ul>\n<li>Does not saturated</li>\n<li>Computationally efficient</li>\n<li>Converges much faster …</li>\n<li><strong>will not die</strong></li>\n</ul>\n<p>or <strong>Para Rectifier ReLu</strong></p>\n<script type=\"math/tex; mode=display\">f(x) = max(\\alpha{x},x)</script><hr>\n<h4 id=\"Exponential-Linear-Units-ELU\"><a href=\"#Exponential-Linear-Units-ELU\" class=\"headerlink\" title=\"Exponential Linear Units (ELU)\"></a>Exponential Linear Units (ELU)</h4><p><img src=\"https://s3.ax1x.com/2020/11/13/D9uOmT.png\" alt></p>\n<ul>\n<li>All benefits of ReLU</li>\n<li>Closer to zero mean outputs</li>\n<li>Negative saturation regime adds some robustness to noise</li>\n</ul>\n<p><em>While it requires exp()</em></p>\n<hr>\n<h4 id=\"Maxout-“Neuron”\"><a href=\"#Maxout-“Neuron”\" class=\"headerlink\" title=\"Maxout “Neuron”\"></a>Maxout “Neuron”</h4><p><img src=\"https://s3.ax1x.com/2020/11/13/D9uj7F.png\" alt></p>\n<hr>\n<h4 id=\"In-practice\"><a href=\"#In-practice\" class=\"headerlink\" title=\"In practice\"></a>In practice</h4><ul>\n<li>Use ReLU. (zbe careful with learning rates)</li>\n<li>Try Leaky <em>ReLU / Maxout / ELU</em></li>\n<li>Don’t use sigmoid</li>\n</ul>\n<hr>\n<h3 id=\"Data-Preprocessing\"><a href=\"#Data-Preprocessing\" class=\"headerlink\" title=\"Data Preprocessing\"></a>Data Preprocessing</h3><h4 id=\"Step1-Preprocess-the-data\"><a href=\"#Step1-Preprocess-the-data\" class=\"headerlink\" title=\"Step1: Preprocess the data\"></a>Step1: Preprocess the data</h4><p><img src=\"https://s3.ax1x.com/2020/11/13/D9uxk4.png\" alt></p>\n<ul>\n<li>In CV we usually don’t normalize the data.</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KSh9.png\" alt></p>\n<p>Practice above make the data zero-mean, but only the first layer, and that’s why we need the activation func tobe zero-mean.</p>\n<hr>\n<h3 id=\"Weight-Initialization\"><a href=\"#Weight-Initialization\" class=\"headerlink\" title=\"Weight Initialization\"></a>Weight Initialization</h3><h4 id=\"First-idea-Small-random-numbers\"><a href=\"#First-idea-Small-random-numbers\" class=\"headerlink\" title=\"First idea: Small random numbers\"></a>First idea: Small random numbers</h4><pre><code class=\"hljs python\">W = <span class=\"hljs-number\">0.01</span>* np.random.randn(D,H)</code></pre>\n<blockquote>\n<p>Works Okay for small, but have problems in big one.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KC11.png\" alt></p>\n<h4 id=\"How-about-making-Weight-big\"><a href=\"#How-about-making-Weight-big\" class=\"headerlink\" title=\"How about making Weight big?\"></a>How about making Weight big?</h4><p><img src=\"https://s3.ax1x.com/2020/11/13/D9KP6x.png\" alt></p>\n<blockquote>\n<p>it gonna saturated the regime to be either very possitive or very negative input of tanh, and comes out near zero gradients. The weight will not be updated.</p>\n</blockquote>\n<h4 id=\"Xavier-initialization\"><a href=\"#Xavier-initialization\" class=\"headerlink\" title=\"Xavier initialization\"></a>Xavier initialization</h4><p><em>Woo my initialzation? haha</em></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KiX6.png\" alt></p>\n<blockquote>\n<p>ensure we are at the active region of tanh</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KA0O.png\" alt></p>\n<blockquote>\n<p>Can be addressed by add an extra /2， to ensure the neural won’t die in ReLU</p>\n</blockquote>\n<hr>\n<h3 id=\"Batch-Normalization\"><a href=\"#Batch-Normalization\" class=\"headerlink\" title=\"Batch Normalization\"></a>Batch Normalization</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9KknK.png\" alt></p>\n<blockquote>\n<p>To regulize the input tobe unit gaussian.</p>\n</blockquote>\n<p><em>I have no idea about it. What is unit gaussian?</em></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KetH.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KE7D.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KZAe.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Kmhd.png\" alt></p>\n<hr>\n<h3 id=\"Babysitting-the-Learning-Process\"><a href=\"#Babysitting-the-Learning-Process\" class=\"headerlink\" title=\"Babysitting the Learning Process\"></a>Babysitting the Learning Process</h3><ul>\n<li><ol>\n<li>Preprocess data</li>\n</ol>\n</li>\n<li><ol>\n<li>Choose the architecture:</li>\n</ol>\n</li>\n<li><ol>\n<li>Double check that the loss is reasonable</li>\n</ol>\n</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KK1I.png\" alt></p>\n<h4 id=\"The-Learning-Rate\"><a href=\"#The-Learning-Rate\" class=\"headerlink\" title=\"The Learning Rate\"></a>The Learning Rate</h4><ul>\n<li>Very small learning rate 1e-6<blockquote>\n<p>litter help</p>\n</blockquote>\n</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9K3B8.png\" alt></p>\n<ul>\n<li>Very great learning rate 1e6<blockquote>\n<p>go extreme</p>\n</blockquote>\n</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KQjP.png\" alt></p>\n<ul>\n<li>A Rough Range</li>\n</ul>\n<script type=\"math/tex; mode=display\">1\\times{10}^{-3} \\to 1\\times{10}^{-5}</script><hr>\n<h3 id=\"Hyperparameter-Optimization\"><a href=\"#Hyperparameter-Optimization\" class=\"headerlink\" title=\"Hyperparameter Optimization\"></a>Hyperparameter Optimization</h3><ul>\n<li><p>Cross-validation strategy<br><em>coarse -&gt; fine</em></p>\n</li>\n<li><p>Random Sample</p>\n</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Ku9A.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KMct.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9K1nf.png\" alt></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"OverView\"><a href=\"#OverView\" class=\"headerlink\" title=\"OverView\"></a>OverView</h3><ol>\n<li>One time setup</li>\n<li>Training dynamics</li>\n<li>Evaluation</li>\n</ol>\n<h3 id=\"Part-1\"><a href=\"#Part-1\" class=\"headerlink\" title=\"Part 1\"></a>Part 1</h3><ul>\n<li>Activation Functions</li>\n<li>Data Preprocessing</li>\n<li>Weight initialization</li>\n<li>Batch Normalization</li>\n<li>Babysitting the Learning Process</li>\n<li>Hyperparameter Optimization</li>\n</ul>\n<hr>\n<h3 id=\"Activation-Functions\"><a href=\"#Activation-Functions\" class=\"headerlink\" title=\"Activation Functions\"></a>Activation Functions</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9uofs.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9uIYj.png\" alt></p>\n<h4 id=\"Sigmoid\"><a href=\"#Sigmoid\" class=\"headerlink\" title=\"Sigmoid\"></a>Sigmoid</h4><script type=\"math/tex; mode=display\">\\sigma(x) = 1/(1+e^{-x})</script><ul>\n<li>Squashes numbers to range [0,1]</li>\n<li>Historically popular “firing rate” of a neuron</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9uhTg.png\" alt></p>\n<p><strong>3 Problems</strong></p>\n<ol>\n<li>Saturated the neural may kill the gradient.</li>\n</ol>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9u5kQ.png\" alt></p>\n<blockquote>\n<p>x is a very negative and very positive val, its gradient will be killed to zero</p>\n</blockquote>\n<ol>\n<li>Sigmoid outputs are not zero-centered</li>\n</ol>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9u7pn.png\" alt></p>\n<blockquote>\n<p>For the sign of x and gradient is always the same, it gonna behaves like is above pic.</p>\n<p>thats why we need zero-mean data, to optimize the w just through the zig zag path.</p>\n</blockquote>\n<ol>\n<li>exp() is a bit compute expensive</li>\n</ol>\n<hr>\n<h4 id=\"Tanh\"><a href=\"#Tanh\" class=\"headerlink\" title=\"Tanh\"></a>Tanh</h4><ul>\n<li>Squashes numbers to range [-1, 1]</li>\n<li>zero centered (nice)</li>\n<li>still kills gradients when saturated</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9uHlq.png\" alt></p>\n<hr>\n<h4 id=\"ReLU\"><a href=\"#ReLU\" class=\"headerlink\" title=\"ReLU\"></a>ReLU</h4><script type=\"math/tex; mode=display\">f(x) = max(0, x)</script><p><img src=\"https://s3.ax1x.com/2020/11/13/D9ub60.png\" alt></p>\n<ul>\n<li>Does not saturate (in + region)</li>\n<li>Very computationally efficient</li>\n<li>Converges much faster than sigmoid/tanh in practice</li>\n<li>Actually more biologically plausible than sigmoid</li>\n</ul>\n<p><strong>Problems</strong></p>\n<ol>\n<li>Not zero-centered output</li>\n<li>An annoyance:</li>\n<li>when x &lt;= 0 the gradient is slashed to zero (kill half the gradient)</li>\n</ol>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9uX0U.png\" alt></p>\n<ul>\n<li>Bad Init</li>\n<li>Learning rate too high</li>\n</ul>\n<blockquote>\n<p>people like to initialize ReLU neurons with slightly positive biases (eg 0.01), to increase the possibility that being activated.</p>\n</blockquote>\n<hr>\n<h4 id=\"Leaky-ReLu\"><a href=\"#Leaky-ReLu\" class=\"headerlink\" title=\"Leaky ReLu\"></a>Leaky ReLu</h4><script type=\"math/tex; mode=display\">f(x) = max(0.01x,x)</script><p><img src=\"https://s3.ax1x.com/2020/11/13/D9uqXV.png\" alt></p>\n<ul>\n<li>Does not saturated</li>\n<li>Computationally efficient</li>\n<li>Converges much faster …</li>\n<li><strong>will not die</strong></li>\n</ul>\n<p>or <strong>Para Rectifier ReLu</strong></p>\n<script type=\"math/tex; mode=display\">f(x) = max(\\alpha{x},x)</script><hr>\n<h4 id=\"Exponential-Linear-Units-ELU\"><a href=\"#Exponential-Linear-Units-ELU\" class=\"headerlink\" title=\"Exponential Linear Units (ELU)\"></a>Exponential Linear Units (ELU)</h4><p><img src=\"https://s3.ax1x.com/2020/11/13/D9uOmT.png\" alt></p>\n<ul>\n<li>All benefits of ReLU</li>\n<li>Closer to zero mean outputs</li>\n<li>Negative saturation regime adds some robustness to noise</li>\n</ul>\n<p><em>While it requires exp()</em></p>\n<hr>\n<h4 id=\"Maxout-“Neuron”\"><a href=\"#Maxout-“Neuron”\" class=\"headerlink\" title=\"Maxout “Neuron”\"></a>Maxout “Neuron”</h4><p><img src=\"https://s3.ax1x.com/2020/11/13/D9uj7F.png\" alt></p>\n<hr>\n<h4 id=\"In-practice\"><a href=\"#In-practice\" class=\"headerlink\" title=\"In practice\"></a>In practice</h4><ul>\n<li>Use ReLU. (zbe careful with learning rates)</li>\n<li>Try Leaky <em>ReLU / Maxout / ELU</em></li>\n<li>Don’t use sigmoid</li>\n</ul>\n<hr>\n<h3 id=\"Data-Preprocessing\"><a href=\"#Data-Preprocessing\" class=\"headerlink\" title=\"Data Preprocessing\"></a>Data Preprocessing</h3><h4 id=\"Step1-Preprocess-the-data\"><a href=\"#Step1-Preprocess-the-data\" class=\"headerlink\" title=\"Step1: Preprocess the data\"></a>Step1: Preprocess the data</h4><p><img src=\"https://s3.ax1x.com/2020/11/13/D9uxk4.png\" alt></p>\n<ul>\n<li>In CV we usually don’t normalize the data.</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KSh9.png\" alt></p>\n<p>Practice above make the data zero-mean, but only the first layer, and that’s why we need the activation func tobe zero-mean.</p>\n<hr>\n<h3 id=\"Weight-Initialization\"><a href=\"#Weight-Initialization\" class=\"headerlink\" title=\"Weight Initialization\"></a>Weight Initialization</h3><h4 id=\"First-idea-Small-random-numbers\"><a href=\"#First-idea-Small-random-numbers\" class=\"headerlink\" title=\"First idea: Small random numbers\"></a>First idea: Small random numbers</h4><pre><code class=\"hljs python\">W = <span class=\"hljs-number\">0.01</span>* np.random.randn(D,H)</code></pre>\n<blockquote>\n<p>Works Okay for small, but have problems in big one.</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KC11.png\" alt></p>\n<h4 id=\"How-about-making-Weight-big\"><a href=\"#How-about-making-Weight-big\" class=\"headerlink\" title=\"How about making Weight big?\"></a>How about making Weight big?</h4><p><img src=\"https://s3.ax1x.com/2020/11/13/D9KP6x.png\" alt></p>\n<blockquote>\n<p>it gonna saturated the regime to be either very possitive or very negative input of tanh, and comes out near zero gradients. The weight will not be updated.</p>\n</blockquote>\n<h4 id=\"Xavier-initialization\"><a href=\"#Xavier-initialization\" class=\"headerlink\" title=\"Xavier initialization\"></a>Xavier initialization</h4><p><em>Woo my initialzation? haha</em></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KiX6.png\" alt></p>\n<blockquote>\n<p>ensure we are at the active region of tanh</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KA0O.png\" alt></p>\n<blockquote>\n<p>Can be addressed by add an extra /2， to ensure the neural won’t die in ReLU</p>\n</blockquote>\n<hr>\n<h3 id=\"Batch-Normalization\"><a href=\"#Batch-Normalization\" class=\"headerlink\" title=\"Batch Normalization\"></a>Batch Normalization</h3><p><img src=\"https://s3.ax1x.com/2020/11/13/D9KknK.png\" alt></p>\n<blockquote>\n<p>To regulize the input tobe unit gaussian.</p>\n</blockquote>\n<p><em>I have no idea about it. What is unit gaussian?</em></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KetH.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KE7D.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KZAe.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Kmhd.png\" alt></p>\n<hr>\n<h3 id=\"Babysitting-the-Learning-Process\"><a href=\"#Babysitting-the-Learning-Process\" class=\"headerlink\" title=\"Babysitting the Learning Process\"></a>Babysitting the Learning Process</h3><ul>\n<li><ol>\n<li>Preprocess data</li>\n</ol>\n</li>\n<li><ol>\n<li>Choose the architecture:</li>\n</ol>\n</li>\n<li><ol>\n<li>Double check that the loss is reasonable</li>\n</ol>\n</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KK1I.png\" alt></p>\n<h4 id=\"The-Learning-Rate\"><a href=\"#The-Learning-Rate\" class=\"headerlink\" title=\"The Learning Rate\"></a>The Learning Rate</h4><ul>\n<li>Very small learning rate 1e-6<blockquote>\n<p>litter help</p>\n</blockquote>\n</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9K3B8.png\" alt></p>\n<ul>\n<li>Very great learning rate 1e6<blockquote>\n<p>go extreme</p>\n</blockquote>\n</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KQjP.png\" alt></p>\n<ul>\n<li>A Rough Range</li>\n</ul>\n<script type=\"math/tex; mode=display\">1\\times{10}^{-3} \\to 1\\times{10}^{-5}</script><hr>\n<h3 id=\"Hyperparameter-Optimization\"><a href=\"#Hyperparameter-Optimization\" class=\"headerlink\" title=\"Hyperparameter Optimization\"></a>Hyperparameter Optimization</h3><ul>\n<li><p>Cross-validation strategy<br><em>coarse -&gt; fine</em></p>\n</li>\n<li><p>Random Sample</p>\n</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9Ku9A.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9KMct.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2020/11/13/D9K1nf.png\" alt></p>\n"},{"title":"数据结构笔记 (2020-11-30 ~ 2020-12-05)","index_img":"/img/Pic/DS.png","date":"2020-12-05T02:10:02.000Z","math":true,"_content":"\n# 数据结构 - DataStructure\n\n数据结构这周依然是树上操作，课上学了AVL树，然后讲了之前用过的Hash，然后作业里面主要学会了LCA的倍增和不太熟练的欧拉序RMQ，最后学会了并查集的使用（就可以学最后的Tarjan LCA算法了) ，然后这周作业题主要是并查集，带有一道树上差分算法。\n\n---\n\n## LCA 问题\n\nLCA (Least Common Ancestors) 最近公共祖先问题，顾名思义既要找到两个节点最近的公共祖先，朴素做法是，两个节点中深的那个节点向上跳，直到两个节点深度相同，两个节点再同时向上跳（询问父节点）如果他们跳到最后的父节点是同一个那么这个节点就是他们的最近公共祖先。\n\n这种朴素的算法很好思考，但复杂度也是很高的，单次询问时间复杂度 O(n) 因为最坏要把所有节点都跳一遍。\n\n![](https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=1414039454,330983716&fm=26&gp=0.jpg)\n\n### **LCA - 倍增算法**\n\n倍增算法是LCA的经典算法，如同二分算法的本质一样，都是通过每次尽量把问题规模缩减2的幂次，从而达到 O(lgn) 的时间复杂度。\n\n我们简单讲解一下，倍增算法就是我不再像朴素算法一样一个个往上跳，我直接跳2的幂次，从大到小枚举，如果符合题意就跳，直到 2^0 跳一个节点，这样一次遍历下来，总能覆盖所有情况而满足题意跳到要跳的地方，但复杂度却大大降低减为 O(lgn)\n\n- 代码实现\n```cpp\nvoid dfs(int u, int fa)\n{\n    up[u][0] = fa;  // 预处理父亲\n    dep[u] = dep[fa] + 1;\n    for(auto& v : tree[u])\n    {\n        if(v == fa)\n            continue;\n        dfs(v, u);\n    }\n}\n\nvoid pre()\n{\n    for(int k = 1; (1 << k) <= n; ++k)\n        for(int i = 1; i <= n; ++i)\n            up[i][k] = up[up[i][k - 1]][k - 1]; \n            // 预处理所有的上跳\n            // 状态转移方程 跳 2^k 步，等于先跳2^k-1步再往上跳2^k-1步\n            // 2 ^ k = 2 ^ (k - 1) + 2 ^ (k - 1)\n}   \n\nint lca(int x, int y)\n{\n    if(dep[x] < dep[y])\n        swap(x, y); // 让深度大的为x\n    if(dep[x] != dep[y])\n    {\n        for(int k = 31; k >= 0; --k)\n        {\n            if(dep[up[x][k]] >= dep[y])\n                x = up[x][k];   // 调整为同一深度\n        }\n    }\n\n    if(x == y)\n        return x;   \n        // 如果一个是另外一个的长辈那么这时候两个直接就相等了，直接返回\n\n    for(int k = 31; k >= 0; --k)\n    {\n        if(up[x][k] != up[y][k])    // 同时上跳不过头\n        {\n            x = up[x][k];   \n            y = up[y][k];\n        }\n    }\n\n    return up[x][0];    // 最后 lca 就是里面任意一个的父亲\n}\n```\n\n---\n\n### **LCA - 欧拉序RMQ算法**\n\n这边涉及到RMQ问题，我们就先来讲一讲RMQ问题。\n\n- *RMQ 问题*\nRMQ 是英文 Range Maximum/Minimum Query 的缩写，表示区间最大（最小）值。\n\nRMQ问题一般可以使用单调栈、ST表、线段树来解决\n\n通过欧拉序将LCA问题转为RMQ问题后，我们一般使用ST表来解决RMQ问题。因为ST表在时间复杂度上表现优秀，需要 O(nlgn)的预处理，就能做到O(1)的询问。而写起来又较为简单，不像线段树一样复杂。可以处理大部分不需要在线修改的 RMQ 问题。\n\n另一方面如果我们使用单调栈和线段树在单次询问的时间复杂度仍然是 O(lgn) 级别的本没有做到比倍增算法更优，但在代码方面却比倍增算法更为复杂，因而我们选择ST表进行处理。\n\n\n### **ST表 - Sparse table**\n\n我们说 ST 表可以用来解决可重复贡献问题，因为ST表涉及到区间重叠，我们要保证区间重叠不会影响到我们要求的问题。所以ST表只能解决可重复贡献问题，例如最值和gcd。\n\nST表运用的也是倍增的思想，通过倍增区间覆盖来解决问题。\n\n```cpp\n// ST表\nint f[Max][lgn]\b, Logn[Max], a[Max];\n// f[i][k] 表示区间 i ~ i + 2^k - 1 的最值\n\nvoid pre()\n{\n    Logn[1] = 0;\n    for(int i = 2; i < Max; ++i)\n        Logn[i] = Logn[i / 2] + 1;\n}\n\n// 状态转移：\n    // 前者表示 i ~ i + 2^(k - 1) - 1 的区间最值\n    // 后者表示 i + 2^(k - 1) ~ i + 2^k - 1 的区间最值\n    // 合并即为 i ~ i + 2^k - 1的区间最值\nvoid preSet()\n{\n    for(int i = 1; i <= n; ++i)\n        f[i][0] = a[i]; // 显然 f[i][0] = a[i]\n\n    for(int k = 1; k < lgn; ++k)\n        for(int i = 1; i + (1 << (k - 1)) <= n; ++i)\n            f[i][k] = max(f[i][k - 1], f[i + (1 << (k - 1))][k - 1]);\n}\n\n// 查询操作：\n    // 如果我们要查询 区间 l ~ r 的最值, 我们根据ST表性质知道\n    // f[i][k] 表示 l ~ l + 2^k - 1 的区间最值\n    // r - 2^k + 1 ~ r 的区间最值就可以用 f[r - 1 << k + 1][k] 表示\n    // 那么我们需要这两个区间覆盖整个查询区间且不超过\n    // 则 l + 2^k - 1 >= r - 2^k + 1 且 l + 2^k - 1 <= r 且 r - 2^k + 1 >= l\n    // 则 k >= lg(r - l + 2) - 1 且 k <= floor(lg(r - l + 1));\n    // 我们直接取 k == floor(lg(r - l + 1))\n\nint find(int l, int r)\n{\n    int k = Logn[r - l + 1];\n    return max(f[i][k], f[r - (1 << k) + 1][k]); // O(1) 查询\n}\n\n```\n\n这样一个ST表就写好了，回到正题，我们是通过欧拉序把 LCA问题转换为RMQ问题，我们现在来看这是如何进行的。\n\n在看欧拉序之前我们先看一看基本的 dfs 序是怎么做的（真就递归学习呗）\n\n![dfs序](https://img-blog.csdnimg.cn/20191008210415266.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3djeHlreQ==,size_16,color_FFFFFF,t_70)\n\n正常的dfs序是深度优先不记录回溯的，如上图 dfs 序就是 \n**A->B->D->E->G->C->F->H**\n每个节点在dfs序中出现且仅出现一次\n\n而我们再来看欧拉序\n\n![欧拉序](https://img-blog.csdnimg.cn/20191008210445328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3djeHlreQ==,size_16,color_FFFFFF,t_70)\n\n它不同于dfs序将栈pop的元素也加入队列中，从而就形成了上图“逆时针”的模式\n上图欧拉序就是\n**A->B->D->B->E->G->E->B->A->C->F->H->F->C->A**\n一种intuition就是欧拉序是一种正常人走路遍历所有节点的顺序，只要叶节点大于2个的树就不可能是欧拉图或半欧拉图，那么必然要走回头路，在dfs序的基础上将回头路线画出就是欧拉序。\n\n我们来观察欧拉序可以发现，其首尾必然是根节点，然后除了叶节点仅出现一次，其余点出现2次以上(取决于是几叉树)，如果我们默认是二叉树，那么欧拉序的大小就不会超过 2n - 1 (考虑单链或就两叉到底的最坏情况)\n\n如果我们在欧拉序节点旁配上它的深度再结合图来观察\n**A(0)->B(1)->D(2)->B(1)->E(2)->G(3)->E(2)->B(1)->A(0)->C(1)->F(2)->H(3)->F(2)->C(1)->A(0)**\n我们根据欧拉序的性质不难发现一个节点的左右子树必然夹在其在欧拉序中第二次出现的位置的左右两边，例如 B 的 左右子树 D, E 出现在B第二次出现位置[3]的两边[2]、[4]。\n那么我们想如果我们找，两个节点的 LCA 就直接找两个节点第一次出现的位置，将其作为区间左右，在中间找深度最小的点就行了，这样找到的一定就是他们的LCA (不可能找到更浅的祖先) 。 当然其中包含了左边一个节点的子树，但为了方便我们就统一取第一次出现的位置即可。\n\n这样我们就在线性的时间内将LCA问题转化成了RMQ问题，然后通过之前O(nlgn)的预处理我们可以做到 O(1)的询问，这样LCA问题的总复杂度就是ST表预处理的 O(nlogn) 的复杂度。\n\n似乎总体没有比倍增更优，但单次询问比倍增快了很多，适合需要及时快速反馈的应用场景。\n\n- 代码实现\n\n```cpp\n// get eula array\nvoid dfs(int u, int fa, int level)\n{\n    pos[u] = cnt_2;\n    find_u[cnt_2++] = u;\n    dep[u] = level;\n    \n    for(int i = head[u]; i != -1; i = e[i].nex)\n    {\n        int v = e[i].v;\n        \n        // 欧拉序，回溯也放入\n        pos[v] = cnt_2;\n        find_u[cnt_2++] = v;\n        dep[v] = level + 1;\n        dfs(v, u, level + 1);\n    }\n}\n\nvoid ST()\n{\n    // Preset Log\n    Logn[1] = 0;\n    for(int i = 2; i <= n; ++i)\n        Logn[i] = Logn[i >> 1] + 1;\n    \n    for(int i = 1; i <= n; ++i)\n        f[i][0] = find_u[i];\n\n    for(int j = 1; j <= logn; ++j)\n        for(int i = 1; i <= n; ++i)\n            f[i][j] = dep[f[i][j - 1]] < dep[f[i + (j << 1)][j - 1]] ? f[i][j - 1] : f[i + (j << 1)][j - 1];\n\n}\n\nint lca(int u, int v)\n{\n    int l = pos[u], r = pos[v];\n    int j = Logn[r - l + 1];\n    // 直接找区间最小深度的节点\n    int ans = min(f[l][j], f[r - (1 << j) + 1][j]);\n    return pos[ans];    // 返回节点位置...\n}\n```\n\n---\n\n## 并查集\n\n再来讲讲这周学的并查集\n\n并查集顾名思义支持且仅支持两种操作\n1. 合并两个集合\n2. 查询元素所在的集合\n\n并查集是一种树上的操作，通过根节点直接代表整棵树，初始化的时候根节点父节点为自身。\n\n- 合并操作\n\n合并操作相对比较简单，由于我们通过根节点来代表这个集合，那么合并两个集合只需要将其中一个的根节点作为另一个的子节点连接上即可。但同时我们要注意整棵树的深度会影响我们的时间复杂度，因而我们要尽可能不加深或是少加深树的深度，所以我们采用将深度较小的树连接到深度较大的树上，每次这样操作，树深度每次至多 +1，这种策略称之为**按秩合并（启发式合并）**\n\n![](https://oi-wiki.org/ds/images/dsu1.png)\n\n- 代码\n\n```cpp\nvoid unionSet(int x, int y)\n{\n    int tmp_x = find(x);\n    int tmp_y = find(y);\n    if(tmp_x == tmp_y)  // 本来就在同一集合中\n        return; \n    if(sz[tmp_x] > sz[tmp_y])\n        swap(tmp_x, tmp_y); // 让 tmp_x 是深度小的集合\n    fa[tmp_x] = tmp_y; // 将 tmp_x 连接到 tmp_y 上\n}\n```\n\n- 查询操作\n\n我们来讲并查集关键的查询操作，并查集的查询操作给出一个节点，我们查询其父节点，如若其父节点不是自身就继续向上查询，直到查询到根节点（父节点为自身）返回根节点作为这个集合的代表。\n\n我们不难看出这样的查询操作单次是 $O(n)$ 的，原因是我们每次查询都要走完完整的一条链，但是其实我们并不关心该节点的父节点是谁，我们只想知道其根节点是什么。所以我们可以直接让它的父节点直接是根节点，这样虽然在第一次操作的时候，我们还是要走完一条链，但之后该节点的父节点直接就是根节点。这种操作称为**路径压缩**\n\n![](https://oi-wiki.org/ds/images/dsu2.png)\n\n```cpp\n\nint find(int x)\n{\n    if(fa[x] == x)\n        return x;\n    return fa[x] = find(fa[x]); // 路径压缩\n}\n```\n\n- **复杂度分析**\n\n我们现在来分析一下复杂度，朴素算法毫无疑问单次操作是 $O(mn)$ 的\n如果我们使用了路径压缩，在Tarjan大神的论文[1] 中给出了复杂度的证明，只使用路径压缩不使用按秩合并的最坏时间复杂度是 $O(mlogn)$ 已经满足大部分题的需求，所以一般只需要路径压缩就能过题。\n在姚期智的论文 [2] 中，证明了只路径压缩的平均复杂度为 $O(m\\alpha{(m,n)})$\n*注： $\\alpha$ 是阿克曼函数的反函数，其增长极其缓慢，也就是说其单次操作的平均运行时间可以认为是一个很小的常数。*\n\n如果我们同时使用了路径压缩和按秩合并，那么我们可以做到 $O(m\\alpha{(m,n)})$ 的最坏时间复杂度。相当于单次询问是常数级别复杂度。\n\nAckermann 函数\n$$\nA(m,n) =\\left\\{\n\\begin{array}{l}\n    n + 1, \\; m = 0 \\\\\n    A(m - 1, 1), m > 0 \\;and\\; n = 0 \\\\\n    A(m - 1, A(m, n - 1)),\\;othercases\n\\end{array}\n\\right.\n$$\n\n$A(4, 3)$ 大的惊人，其反函数增长就相对应慢的惊人，直接可看为常数\n\n---\n\n## 树上差分算法\n\n讲一下这周作业题里涉及到的树上差分算法\n树上差分问题可以用树链剖分解决，但我目前还不太会，就写一下现在会一点的树上差分。\n\n树上差分分为两种，边差分和点差分。\n\n- 边差分\n考虑一个经典问题，**给出两点x, y 将其路径上的边权加1，最后给出所有边权。**\n\n![图源:https://www.cnblogs.com/zhwer/p/12800475.html](https://s3.ax1x.com/2020/12/08/r99w60.png)\n\n我们看这张图，数组 c[k] 是差分数组只不过我们是自下而上加的，为不影响其他子树的结果，我们的统计在回溯过程中完成，因而是自下而上的，那么这个边权修改过程就可以看做是 c[x]++, c[y]++, 然后 根节点到lca(x, y)被加了两次，我们都要减去 c[lca(x, y)] -= 2\n\n既然是差分那么对于权值的更新，我们就可以如同前缀和一样计算，这不过这里的\"前缀\"是所有的子树权值，我们将所有子树权值收集起来到父节点上。\n\n- 代码实现\n\n```cpp\n// 已求出差分数组c\nvoid getAns(int u, int fa)\n{  \n    for(int i = head[u]; i != -1; i = e[i].nex)\n    {\n        int v = e[i].v;\n        if(v != fa)\n        {\n            getAns(v, u);\n            c[u] += c[v] // 收集子树权值更新c为原本数组\n            // 更新后的c就代表其和其父节点连接边的边权\n        }\n    }\n}\n```\n\n- 点差分\n点差分和边差分差不多，但这回每个点都代表的是自己了。\n![图源:https://www.cnblogs.com/zhwer/p/12800475.html](https://s3.ax1x.com/2020/12/08/r990XV.png)\n\n和边差分不同的是，这回lca不需要减2了，因为每个点代表的就是自己，在统计的时候 x, y 路径上是有 lca(x, y) 的，因而只需要减去一次重复计算即可。但这边lca在计算\"前缀和\"的时候会 +1，差分数组某一地方值的变动会影响到后面所有的值（这就是差分数组的精髓和意义所在）但lca的父亲并不应该 +1 所以我们要将 c[fa[lca(x,y)]]-- 这个过程之后，我们的差分数组就完成了。\n最后自下而上的收集一下，就能得到所有节点的权值了。\n\n- 思想总结\n\n差分的思想就是将原来本不相干的值联系到了一起，把后面点的部分信息移到了前面的点中，形成了区间的覆盖，这种效果正好能够用于解决区间修改问题，避免了暴力算法对每个点都进行操作，很巧妙的思想。\n\n---\n\n## 最后总结\n\n本周DS主要学习这些内容，AVL树很惭愧虽然上课讲了但还没有深入去看，线段树和树链剖分还不太会，树状数组也快忘记了。最近又重新听到了《蜗牛》这首歌，隔了这么多年，再听还是很感动。“历经的伤都不感觉疼”，“任风吹干流过的泪和汗，总有一天我有属于我的天。” \n每周都在不断吸收新知识，很充实也很疲倦，每天都学到12点之后。就是希望能够在未来有一片自己的天。科研也在不断做，但进度很慢，时间分配越来越不够了，最近越来越感到拔尖班的藏龙卧虎，个个都是人才，让我感到了很大的压力。但就像《蜗牛》中说的即使我很慢，拖着重重的壳，只要我每天一步一步的向上爬，我总能触碰到那片属于我的蓝天。\n\n---\n\n## Reference\n[1]Tarjan, R. E., & Van Leeuwen, J. (1984). Worst-case analysis of set union algorithms.\n[2]Yao, A. C. (1985). On the expected performance of path compression algorithms. SIAM Journal on Computing, 14(1), 129-133.","source":"_posts/DS/DataStructureNote1.md","raw":"---\ntitle: 数据结构笔记 (2020-11-30 ~ 2020-12-05)\nindex_img: /img/Pic/DS.png\ndate: 2020-12-05 10:10:02\ncategory: [DataStructure]\ntags: [LCA,UFS]\nmath: true\n---\n\n# 数据结构 - DataStructure\n\n数据结构这周依然是树上操作，课上学了AVL树，然后讲了之前用过的Hash，然后作业里面主要学会了LCA的倍增和不太熟练的欧拉序RMQ，最后学会了并查集的使用（就可以学最后的Tarjan LCA算法了) ，然后这周作业题主要是并查集，带有一道树上差分算法。\n\n---\n\n## LCA 问题\n\nLCA (Least Common Ancestors) 最近公共祖先问题，顾名思义既要找到两个节点最近的公共祖先，朴素做法是，两个节点中深的那个节点向上跳，直到两个节点深度相同，两个节点再同时向上跳（询问父节点）如果他们跳到最后的父节点是同一个那么这个节点就是他们的最近公共祖先。\n\n这种朴素的算法很好思考，但复杂度也是很高的，单次询问时间复杂度 O(n) 因为最坏要把所有节点都跳一遍。\n\n![](https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=1414039454,330983716&fm=26&gp=0.jpg)\n\n### **LCA - 倍增算法**\n\n倍增算法是LCA的经典算法，如同二分算法的本质一样，都是通过每次尽量把问题规模缩减2的幂次，从而达到 O(lgn) 的时间复杂度。\n\n我们简单讲解一下，倍增算法就是我不再像朴素算法一样一个个往上跳，我直接跳2的幂次，从大到小枚举，如果符合题意就跳，直到 2^0 跳一个节点，这样一次遍历下来，总能覆盖所有情况而满足题意跳到要跳的地方，但复杂度却大大降低减为 O(lgn)\n\n- 代码实现\n```cpp\nvoid dfs(int u, int fa)\n{\n    up[u][0] = fa;  // 预处理父亲\n    dep[u] = dep[fa] + 1;\n    for(auto& v : tree[u])\n    {\n        if(v == fa)\n            continue;\n        dfs(v, u);\n    }\n}\n\nvoid pre()\n{\n    for(int k = 1; (1 << k) <= n; ++k)\n        for(int i = 1; i <= n; ++i)\n            up[i][k] = up[up[i][k - 1]][k - 1]; \n            // 预处理所有的上跳\n            // 状态转移方程 跳 2^k 步，等于先跳2^k-1步再往上跳2^k-1步\n            // 2 ^ k = 2 ^ (k - 1) + 2 ^ (k - 1)\n}   \n\nint lca(int x, int y)\n{\n    if(dep[x] < dep[y])\n        swap(x, y); // 让深度大的为x\n    if(dep[x] != dep[y])\n    {\n        for(int k = 31; k >= 0; --k)\n        {\n            if(dep[up[x][k]] >= dep[y])\n                x = up[x][k];   // 调整为同一深度\n        }\n    }\n\n    if(x == y)\n        return x;   \n        // 如果一个是另外一个的长辈那么这时候两个直接就相等了，直接返回\n\n    for(int k = 31; k >= 0; --k)\n    {\n        if(up[x][k] != up[y][k])    // 同时上跳不过头\n        {\n            x = up[x][k];   \n            y = up[y][k];\n        }\n    }\n\n    return up[x][0];    // 最后 lca 就是里面任意一个的父亲\n}\n```\n\n---\n\n### **LCA - 欧拉序RMQ算法**\n\n这边涉及到RMQ问题，我们就先来讲一讲RMQ问题。\n\n- *RMQ 问题*\nRMQ 是英文 Range Maximum/Minimum Query 的缩写，表示区间最大（最小）值。\n\nRMQ问题一般可以使用单调栈、ST表、线段树来解决\n\n通过欧拉序将LCA问题转为RMQ问题后，我们一般使用ST表来解决RMQ问题。因为ST表在时间复杂度上表现优秀，需要 O(nlgn)的预处理，就能做到O(1)的询问。而写起来又较为简单，不像线段树一样复杂。可以处理大部分不需要在线修改的 RMQ 问题。\n\n另一方面如果我们使用单调栈和线段树在单次询问的时间复杂度仍然是 O(lgn) 级别的本没有做到比倍增算法更优，但在代码方面却比倍增算法更为复杂，因而我们选择ST表进行处理。\n\n\n### **ST表 - Sparse table**\n\n我们说 ST 表可以用来解决可重复贡献问题，因为ST表涉及到区间重叠，我们要保证区间重叠不会影响到我们要求的问题。所以ST表只能解决可重复贡献问题，例如最值和gcd。\n\nST表运用的也是倍增的思想，通过倍增区间覆盖来解决问题。\n\n```cpp\n// ST表\nint f[Max][lgn]\b, Logn[Max], a[Max];\n// f[i][k] 表示区间 i ~ i + 2^k - 1 的最值\n\nvoid pre()\n{\n    Logn[1] = 0;\n    for(int i = 2; i < Max; ++i)\n        Logn[i] = Logn[i / 2] + 1;\n}\n\n// 状态转移：\n    // 前者表示 i ~ i + 2^(k - 1) - 1 的区间最值\n    // 后者表示 i + 2^(k - 1) ~ i + 2^k - 1 的区间最值\n    // 合并即为 i ~ i + 2^k - 1的区间最值\nvoid preSet()\n{\n    for(int i = 1; i <= n; ++i)\n        f[i][0] = a[i]; // 显然 f[i][0] = a[i]\n\n    for(int k = 1; k < lgn; ++k)\n        for(int i = 1; i + (1 << (k - 1)) <= n; ++i)\n            f[i][k] = max(f[i][k - 1], f[i + (1 << (k - 1))][k - 1]);\n}\n\n// 查询操作：\n    // 如果我们要查询 区间 l ~ r 的最值, 我们根据ST表性质知道\n    // f[i][k] 表示 l ~ l + 2^k - 1 的区间最值\n    // r - 2^k + 1 ~ r 的区间最值就可以用 f[r - 1 << k + 1][k] 表示\n    // 那么我们需要这两个区间覆盖整个查询区间且不超过\n    // 则 l + 2^k - 1 >= r - 2^k + 1 且 l + 2^k - 1 <= r 且 r - 2^k + 1 >= l\n    // 则 k >= lg(r - l + 2) - 1 且 k <= floor(lg(r - l + 1));\n    // 我们直接取 k == floor(lg(r - l + 1))\n\nint find(int l, int r)\n{\n    int k = Logn[r - l + 1];\n    return max(f[i][k], f[r - (1 << k) + 1][k]); // O(1) 查询\n}\n\n```\n\n这样一个ST表就写好了，回到正题，我们是通过欧拉序把 LCA问题转换为RMQ问题，我们现在来看这是如何进行的。\n\n在看欧拉序之前我们先看一看基本的 dfs 序是怎么做的（真就递归学习呗）\n\n![dfs序](https://img-blog.csdnimg.cn/20191008210415266.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3djeHlreQ==,size_16,color_FFFFFF,t_70)\n\n正常的dfs序是深度优先不记录回溯的，如上图 dfs 序就是 \n**A->B->D->E->G->C->F->H**\n每个节点在dfs序中出现且仅出现一次\n\n而我们再来看欧拉序\n\n![欧拉序](https://img-blog.csdnimg.cn/20191008210445328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3djeHlreQ==,size_16,color_FFFFFF,t_70)\n\n它不同于dfs序将栈pop的元素也加入队列中，从而就形成了上图“逆时针”的模式\n上图欧拉序就是\n**A->B->D->B->E->G->E->B->A->C->F->H->F->C->A**\n一种intuition就是欧拉序是一种正常人走路遍历所有节点的顺序，只要叶节点大于2个的树就不可能是欧拉图或半欧拉图，那么必然要走回头路，在dfs序的基础上将回头路线画出就是欧拉序。\n\n我们来观察欧拉序可以发现，其首尾必然是根节点，然后除了叶节点仅出现一次，其余点出现2次以上(取决于是几叉树)，如果我们默认是二叉树，那么欧拉序的大小就不会超过 2n - 1 (考虑单链或就两叉到底的最坏情况)\n\n如果我们在欧拉序节点旁配上它的深度再结合图来观察\n**A(0)->B(1)->D(2)->B(1)->E(2)->G(3)->E(2)->B(1)->A(0)->C(1)->F(2)->H(3)->F(2)->C(1)->A(0)**\n我们根据欧拉序的性质不难发现一个节点的左右子树必然夹在其在欧拉序中第二次出现的位置的左右两边，例如 B 的 左右子树 D, E 出现在B第二次出现位置[3]的两边[2]、[4]。\n那么我们想如果我们找，两个节点的 LCA 就直接找两个节点第一次出现的位置，将其作为区间左右，在中间找深度最小的点就行了，这样找到的一定就是他们的LCA (不可能找到更浅的祖先) 。 当然其中包含了左边一个节点的子树，但为了方便我们就统一取第一次出现的位置即可。\n\n这样我们就在线性的时间内将LCA问题转化成了RMQ问题，然后通过之前O(nlgn)的预处理我们可以做到 O(1)的询问，这样LCA问题的总复杂度就是ST表预处理的 O(nlogn) 的复杂度。\n\n似乎总体没有比倍增更优，但单次询问比倍增快了很多，适合需要及时快速反馈的应用场景。\n\n- 代码实现\n\n```cpp\n// get eula array\nvoid dfs(int u, int fa, int level)\n{\n    pos[u] = cnt_2;\n    find_u[cnt_2++] = u;\n    dep[u] = level;\n    \n    for(int i = head[u]; i != -1; i = e[i].nex)\n    {\n        int v = e[i].v;\n        \n        // 欧拉序，回溯也放入\n        pos[v] = cnt_2;\n        find_u[cnt_2++] = v;\n        dep[v] = level + 1;\n        dfs(v, u, level + 1);\n    }\n}\n\nvoid ST()\n{\n    // Preset Log\n    Logn[1] = 0;\n    for(int i = 2; i <= n; ++i)\n        Logn[i] = Logn[i >> 1] + 1;\n    \n    for(int i = 1; i <= n; ++i)\n        f[i][0] = find_u[i];\n\n    for(int j = 1; j <= logn; ++j)\n        for(int i = 1; i <= n; ++i)\n            f[i][j] = dep[f[i][j - 1]] < dep[f[i + (j << 1)][j - 1]] ? f[i][j - 1] : f[i + (j << 1)][j - 1];\n\n}\n\nint lca(int u, int v)\n{\n    int l = pos[u], r = pos[v];\n    int j = Logn[r - l + 1];\n    // 直接找区间最小深度的节点\n    int ans = min(f[l][j], f[r - (1 << j) + 1][j]);\n    return pos[ans];    // 返回节点位置...\n}\n```\n\n---\n\n## 并查集\n\n再来讲讲这周学的并查集\n\n并查集顾名思义支持且仅支持两种操作\n1. 合并两个集合\n2. 查询元素所在的集合\n\n并查集是一种树上的操作，通过根节点直接代表整棵树，初始化的时候根节点父节点为自身。\n\n- 合并操作\n\n合并操作相对比较简单，由于我们通过根节点来代表这个集合，那么合并两个集合只需要将其中一个的根节点作为另一个的子节点连接上即可。但同时我们要注意整棵树的深度会影响我们的时间复杂度，因而我们要尽可能不加深或是少加深树的深度，所以我们采用将深度较小的树连接到深度较大的树上，每次这样操作，树深度每次至多 +1，这种策略称之为**按秩合并（启发式合并）**\n\n![](https://oi-wiki.org/ds/images/dsu1.png)\n\n- 代码\n\n```cpp\nvoid unionSet(int x, int y)\n{\n    int tmp_x = find(x);\n    int tmp_y = find(y);\n    if(tmp_x == tmp_y)  // 本来就在同一集合中\n        return; \n    if(sz[tmp_x] > sz[tmp_y])\n        swap(tmp_x, tmp_y); // 让 tmp_x 是深度小的集合\n    fa[tmp_x] = tmp_y; // 将 tmp_x 连接到 tmp_y 上\n}\n```\n\n- 查询操作\n\n我们来讲并查集关键的查询操作，并查集的查询操作给出一个节点，我们查询其父节点，如若其父节点不是自身就继续向上查询，直到查询到根节点（父节点为自身）返回根节点作为这个集合的代表。\n\n我们不难看出这样的查询操作单次是 $O(n)$ 的，原因是我们每次查询都要走完完整的一条链，但是其实我们并不关心该节点的父节点是谁，我们只想知道其根节点是什么。所以我们可以直接让它的父节点直接是根节点，这样虽然在第一次操作的时候，我们还是要走完一条链，但之后该节点的父节点直接就是根节点。这种操作称为**路径压缩**\n\n![](https://oi-wiki.org/ds/images/dsu2.png)\n\n```cpp\n\nint find(int x)\n{\n    if(fa[x] == x)\n        return x;\n    return fa[x] = find(fa[x]); // 路径压缩\n}\n```\n\n- **复杂度分析**\n\n我们现在来分析一下复杂度，朴素算法毫无疑问单次操作是 $O(mn)$ 的\n如果我们使用了路径压缩，在Tarjan大神的论文[1] 中给出了复杂度的证明，只使用路径压缩不使用按秩合并的最坏时间复杂度是 $O(mlogn)$ 已经满足大部分题的需求，所以一般只需要路径压缩就能过题。\n在姚期智的论文 [2] 中，证明了只路径压缩的平均复杂度为 $O(m\\alpha{(m,n)})$\n*注： $\\alpha$ 是阿克曼函数的反函数，其增长极其缓慢，也就是说其单次操作的平均运行时间可以认为是一个很小的常数。*\n\n如果我们同时使用了路径压缩和按秩合并，那么我们可以做到 $O(m\\alpha{(m,n)})$ 的最坏时间复杂度。相当于单次询问是常数级别复杂度。\n\nAckermann 函数\n$$\nA(m,n) =\\left\\{\n\\begin{array}{l}\n    n + 1, \\; m = 0 \\\\\n    A(m - 1, 1), m > 0 \\;and\\; n = 0 \\\\\n    A(m - 1, A(m, n - 1)),\\;othercases\n\\end{array}\n\\right.\n$$\n\n$A(4, 3)$ 大的惊人，其反函数增长就相对应慢的惊人，直接可看为常数\n\n---\n\n## 树上差分算法\n\n讲一下这周作业题里涉及到的树上差分算法\n树上差分问题可以用树链剖分解决，但我目前还不太会，就写一下现在会一点的树上差分。\n\n树上差分分为两种，边差分和点差分。\n\n- 边差分\n考虑一个经典问题，**给出两点x, y 将其路径上的边权加1，最后给出所有边权。**\n\n![图源:https://www.cnblogs.com/zhwer/p/12800475.html](https://s3.ax1x.com/2020/12/08/r99w60.png)\n\n我们看这张图，数组 c[k] 是差分数组只不过我们是自下而上加的，为不影响其他子树的结果，我们的统计在回溯过程中完成，因而是自下而上的，那么这个边权修改过程就可以看做是 c[x]++, c[y]++, 然后 根节点到lca(x, y)被加了两次，我们都要减去 c[lca(x, y)] -= 2\n\n既然是差分那么对于权值的更新，我们就可以如同前缀和一样计算，这不过这里的\"前缀\"是所有的子树权值，我们将所有子树权值收集起来到父节点上。\n\n- 代码实现\n\n```cpp\n// 已求出差分数组c\nvoid getAns(int u, int fa)\n{  \n    for(int i = head[u]; i != -1; i = e[i].nex)\n    {\n        int v = e[i].v;\n        if(v != fa)\n        {\n            getAns(v, u);\n            c[u] += c[v] // 收集子树权值更新c为原本数组\n            // 更新后的c就代表其和其父节点连接边的边权\n        }\n    }\n}\n```\n\n- 点差分\n点差分和边差分差不多，但这回每个点都代表的是自己了。\n![图源:https://www.cnblogs.com/zhwer/p/12800475.html](https://s3.ax1x.com/2020/12/08/r990XV.png)\n\n和边差分不同的是，这回lca不需要减2了，因为每个点代表的就是自己，在统计的时候 x, y 路径上是有 lca(x, y) 的，因而只需要减去一次重复计算即可。但这边lca在计算\"前缀和\"的时候会 +1，差分数组某一地方值的变动会影响到后面所有的值（这就是差分数组的精髓和意义所在）但lca的父亲并不应该 +1 所以我们要将 c[fa[lca(x,y)]]-- 这个过程之后，我们的差分数组就完成了。\n最后自下而上的收集一下，就能得到所有节点的权值了。\n\n- 思想总结\n\n差分的思想就是将原来本不相干的值联系到了一起，把后面点的部分信息移到了前面的点中，形成了区间的覆盖，这种效果正好能够用于解决区间修改问题，避免了暴力算法对每个点都进行操作，很巧妙的思想。\n\n---\n\n## 最后总结\n\n本周DS主要学习这些内容，AVL树很惭愧虽然上课讲了但还没有深入去看，线段树和树链剖分还不太会，树状数组也快忘记了。最近又重新听到了《蜗牛》这首歌，隔了这么多年，再听还是很感动。“历经的伤都不感觉疼”，“任风吹干流过的泪和汗，总有一天我有属于我的天。” \n每周都在不断吸收新知识，很充实也很疲倦，每天都学到12点之后。就是希望能够在未来有一片自己的天。科研也在不断做，但进度很慢，时间分配越来越不够了，最近越来越感到拔尖班的藏龙卧虎，个个都是人才，让我感到了很大的压力。但就像《蜗牛》中说的即使我很慢，拖着重重的壳，只要我每天一步一步的向上爬，我总能触碰到那片属于我的蓝天。\n\n---\n\n## Reference\n[1]Tarjan, R. E., & Van Leeuwen, J. (1984). Worst-case analysis of set union algorithms.\n[2]Yao, A. C. (1985). On the expected performance of path compression algorithms. SIAM Journal on Computing, 14(1), 129-133.","slug":"DS/DataStructureNote1","published":1,"updated":"2020-12-09T01:23:05.341Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty3u000ms8pd3bm6ayoa","content":"<h1 id=\"数据结构-DataStructure\"><a href=\"#数据结构-DataStructure\" class=\"headerlink\" title=\"数据结构 - DataStructure\"></a>数据结构 - DataStructure</h1><p>数据结构这周依然是树上操作，课上学了AVL树，然后讲了之前用过的Hash，然后作业里面主要学会了LCA的倍增和不太熟练的欧拉序RMQ，最后学会了并查集的使用（就可以学最后的Tarjan LCA算法了) ，然后这周作业题主要是并查集，带有一道树上差分算法。</p>\n<hr>\n<h2 id=\"LCA-问题\"><a href=\"#LCA-问题\" class=\"headerlink\" title=\"LCA 问题\"></a>LCA 问题</h2><p>LCA (Least Common Ancestors) 最近公共祖先问题，顾名思义既要找到两个节点最近的公共祖先，朴素做法是，两个节点中深的那个节点向上跳，直到两个节点深度相同，两个节点再同时向上跳（询问父节点）如果他们跳到最后的父节点是同一个那么这个节点就是他们的最近公共祖先。</p>\n<p>这种朴素的算法很好思考，但复杂度也是很高的，单次询问时间复杂度 O(n) 因为最坏要把所有节点都跳一遍。</p>\n<p><img src=\"https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=1414039454,330983716&amp;fm=26&amp;gp=0.jpg\" alt></p>\n<h3 id=\"LCA-倍增算法\"><a href=\"#LCA-倍增算法\" class=\"headerlink\" title=\"LCA - 倍增算法\"></a><strong>LCA - 倍增算法</strong></h3><p>倍增算法是LCA的经典算法，如同二分算法的本质一样，都是通过每次尽量把问题规模缩减2的幂次，从而达到 O(lgn) 的时间复杂度。</p>\n<p>我们简单讲解一下，倍增算法就是我不再像朴素算法一样一个个往上跳，我直接跳2的幂次，从大到小枚举，如果符合题意就跳，直到 2^0 跳一个节点，这样一次遍历下来，总能覆盖所有情况而满足题意跳到要跳的地方，但复杂度却大大降低减为 O(lgn)</p>\n<ul>\n<li>代码实现<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">dfs</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    up[u][<span class=\"hljs-number\">0</span>] = fa;  <span class=\"hljs-comment\">// 预处理父亲</span>\n    dep[u] = dep[fa] + <span class=\"hljs-number\">1</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span>&amp; v : tree[u])\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(v == fa)\n            <span class=\"hljs-keyword\">continue</span>;\n        dfs(v, u);\n    &#125;\n&#125;\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">pre</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> k = <span class=\"hljs-number\">1</span>; (<span class=\"hljs-number\">1</span> &lt;&lt; k) &lt;= n; ++k)\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">1</span>; i &lt;= n; ++i)\n            up[i][k] = up[up[i][k - <span class=\"hljs-number\">1</span>]][k - <span class=\"hljs-number\">1</span>]; \n            <span class=\"hljs-comment\">// 预处理所有的上跳</span>\n            <span class=\"hljs-comment\">// 状态转移方程 跳 2^k 步，等于先跳2^k-1步再往上跳2^k-1步</span>\n            <span class=\"hljs-comment\">// 2 ^ k = 2 ^ (k - 1) + 2 ^ (k - 1)</span>\n&#125;   \n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">lca</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> y)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">if</span>(dep[x] &lt; dep[y])\n        swap(x, y); <span class=\"hljs-comment\">// 让深度大的为x</span>\n    <span class=\"hljs-keyword\">if</span>(dep[x] != dep[y])\n    &#123;\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> k = <span class=\"hljs-number\">31</span>; k &gt;= <span class=\"hljs-number\">0</span>; --k)\n        &#123;\n            <span class=\"hljs-keyword\">if</span>(dep[up[x][k]] &gt;= dep[y])\n                x = up[x][k];   <span class=\"hljs-comment\">// 调整为同一深度</span>\n        &#125;\n    &#125;\n\n    <span class=\"hljs-keyword\">if</span>(x == y)\n        <span class=\"hljs-keyword\">return</span> x;   \n        <span class=\"hljs-comment\">// 如果一个是另外一个的长辈那么这时候两个直接就相等了，直接返回</span>\n\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> k = <span class=\"hljs-number\">31</span>; k &gt;= <span class=\"hljs-number\">0</span>; --k)\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(up[x][k] != up[y][k])    <span class=\"hljs-comment\">// 同时上跳不过头</span>\n        &#123;\n            x = up[x][k];   \n            y = up[y][k];\n        &#125;\n    &#125;\n\n    <span class=\"hljs-keyword\">return</span> up[x][<span class=\"hljs-number\">0</span>];    <span class=\"hljs-comment\">// 最后 lca 就是里面任意一个的父亲</span>\n&#125;</code></pre>\n</li>\n</ul>\n<hr>\n<h3 id=\"LCA-欧拉序RMQ算法\"><a href=\"#LCA-欧拉序RMQ算法\" class=\"headerlink\" title=\"LCA - 欧拉序RMQ算法\"></a><strong>LCA - 欧拉序RMQ算法</strong></h3><p>这边涉及到RMQ问题，我们就先来讲一讲RMQ问题。</p>\n<ul>\n<li><em>RMQ 问题</em><br>RMQ 是英文 Range Maximum/Minimum Query 的缩写，表示区间最大（最小）值。</li>\n</ul>\n<p>RMQ问题一般可以使用单调栈、ST表、线段树来解决</p>\n<p>通过欧拉序将LCA问题转为RMQ问题后，我们一般使用ST表来解决RMQ问题。因为ST表在时间复杂度上表现优秀，需要 O(nlgn)的预处理，就能做到O(1)的询问。而写起来又较为简单，不像线段树一样复杂。可以处理大部分不需要在线修改的 RMQ 问题。</p>\n<p>另一方面如果我们使用单调栈和线段树在单次询问的时间复杂度仍然是 O(lgn) 级别的本没有做到比倍增算法更优，但在代码方面却比倍增算法更为复杂，因而我们选择ST表进行处理。</p>\n<h3 id=\"ST表-Sparse-table\"><a href=\"#ST表-Sparse-table\" class=\"headerlink\" title=\"ST表 - Sparse table\"></a><strong>ST表 - Sparse table</strong></h3><p>我们说 ST 表可以用来解决可重复贡献问题，因为ST表涉及到区间重叠，我们要保证区间重叠不会影响到我们要求的问题。所以ST表只能解决可重复贡献问题，例如最值和gcd。</p>\n<p>ST表运用的也是倍增的思想，通过倍增区间覆盖来解决问题。</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// ST表</span>\n<span class=\"hljs-keyword\">int</span> f[Max][lgn]\b, Logn[Max], a[Max];\n<span class=\"hljs-comment\">// f[i][k] 表示区间 i ~ i + 2^k - 1 的最值</span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">pre</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    Logn[<span class=\"hljs-number\">1</span>] = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">2</span>; i &lt; Max; ++i)\n        Logn[i] = Logn[i / <span class=\"hljs-number\">2</span>] + <span class=\"hljs-number\">1</span>;\n&#125;\n\n<span class=\"hljs-comment\">// 状态转移：</span>\n    <span class=\"hljs-comment\">// 前者表示 i ~ i + 2^(k - 1) - 1 的区间最值</span>\n    <span class=\"hljs-comment\">// 后者表示 i + 2^(k - 1) ~ i + 2^k - 1 的区间最值</span>\n    <span class=\"hljs-comment\">// 合并即为 i ~ i + 2^k - 1的区间最值</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">preSet</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">1</span>; i &lt;= n; ++i)\n        f[i][<span class=\"hljs-number\">0</span>] = a[i]; <span class=\"hljs-comment\">// 显然 f[i][0] = a[i]</span>\n\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> k = <span class=\"hljs-number\">1</span>; k &lt; lgn; ++k)\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">1</span>; i + (<span class=\"hljs-number\">1</span> &lt;&lt; (k - <span class=\"hljs-number\">1</span>)) &lt;= n; ++i)\n            f[i][k] = max(f[i][k - <span class=\"hljs-number\">1</span>], f[i + (<span class=\"hljs-number\">1</span> &lt;&lt; (k - <span class=\"hljs-number\">1</span>))][k - <span class=\"hljs-number\">1</span>]);\n&#125;\n\n<span class=\"hljs-comment\">// 查询操作：</span>\n    <span class=\"hljs-comment\">// 如果我们要查询 区间 l ~ r 的最值, 我们根据ST表性质知道</span>\n    <span class=\"hljs-comment\">// f[i][k] 表示 l ~ l + 2^k - 1 的区间最值</span>\n    <span class=\"hljs-comment\">// r - 2^k + 1 ~ r 的区间最值就可以用 f[r - 1 &lt;&lt; k + 1][k] 表示</span>\n    <span class=\"hljs-comment\">// 那么我们需要这两个区间覆盖整个查询区间且不超过</span>\n    <span class=\"hljs-comment\">// 则 l + 2^k - 1 &gt;= r - 2^k + 1 且 l + 2^k - 1 &lt;= r 且 r - 2^k + 1 &gt;= l</span>\n    <span class=\"hljs-comment\">// 则 k &gt;= lg(r - l + 2) - 1 且 k &lt;= floor(lg(r - l + 1));</span>\n    <span class=\"hljs-comment\">// 我们直接取 k == floor(lg(r - l + 1))</span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">find</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> l, <span class=\"hljs-keyword\">int</span> r)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> k = Logn[r - l + <span class=\"hljs-number\">1</span>];\n    <span class=\"hljs-keyword\">return</span> max(f[i][k], f[r - (<span class=\"hljs-number\">1</span> &lt;&lt; k) + <span class=\"hljs-number\">1</span>][k]); <span class=\"hljs-comment\">// O(1) 查询</span>\n&#125;\n</code></pre>\n<p>这样一个ST表就写好了，回到正题，我们是通过欧拉序把 LCA问题转换为RMQ问题，我们现在来看这是如何进行的。</p>\n<p>在看欧拉序之前我们先看一看基本的 dfs 序是怎么做的（真就递归学习呗）</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20191008210415266.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3djeHlreQ==,size_16,color_FFFFFF,t_70\" alt=\"dfs序\"></p>\n<p>正常的dfs序是深度优先不记录回溯的，如上图 dfs 序就是<br><strong>A-&gt;B-&gt;D-&gt;E-&gt;G-&gt;C-&gt;F-&gt;H</strong><br>每个节点在dfs序中出现且仅出现一次</p>\n<p>而我们再来看欧拉序</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20191008210445328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3djeHlreQ==,size_16,color_FFFFFF,t_70\" alt=\"欧拉序\"></p>\n<p>它不同于dfs序将栈pop的元素也加入队列中，从而就形成了上图“逆时针”的模式<br>上图欧拉序就是<br><strong>A-&gt;B-&gt;D-&gt;B-&gt;E-&gt;G-&gt;E-&gt;B-&gt;A-&gt;C-&gt;F-&gt;H-&gt;F-&gt;C-&gt;A</strong><br>一种intuition就是欧拉序是一种正常人走路遍历所有节点的顺序，只要叶节点大于2个的树就不可能是欧拉图或半欧拉图，那么必然要走回头路，在dfs序的基础上将回头路线画出就是欧拉序。</p>\n<p>我们来观察欧拉序可以发现，其首尾必然是根节点，然后除了叶节点仅出现一次，其余点出现2次以上(取决于是几叉树)，如果我们默认是二叉树，那么欧拉序的大小就不会超过 2n - 1 (考虑单链或就两叉到底的最坏情况)</p>\n<p>如果我们在欧拉序节点旁配上它的深度再结合图来观察<br><strong>A(0)-&gt;B(1)-&gt;D(2)-&gt;B(1)-&gt;E(2)-&gt;G(3)-&gt;E(2)-&gt;B(1)-&gt;A(0)-&gt;C(1)-&gt;F(2)-&gt;H(3)-&gt;F(2)-&gt;C(1)-&gt;A(0)</strong><br>我们根据欧拉序的性质不难发现一个节点的左右子树必然夹在其在欧拉序中第二次出现的位置的左右两边，例如 B 的 左右子树 D, E 出现在B第二次出现位置[3]的两边[2]、[4]。<br>那么我们想如果我们找，两个节点的 LCA 就直接找两个节点第一次出现的位置，将其作为区间左右，在中间找深度最小的点就行了，这样找到的一定就是他们的LCA (不可能找到更浅的祖先) 。 当然其中包含了左边一个节点的子树，但为了方便我们就统一取第一次出现的位置即可。</p>\n<p>这样我们就在线性的时间内将LCA问题转化成了RMQ问题，然后通过之前O(nlgn)的预处理我们可以做到 O(1)的询问，这样LCA问题的总复杂度就是ST表预处理的 O(nlogn) 的复杂度。</p>\n<p>似乎总体没有比倍增更优，但单次询问比倍增快了很多，适合需要及时快速反馈的应用场景。</p>\n<ul>\n<li>代码实现</li>\n</ul>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// get eula array</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">dfs</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa, <span class=\"hljs-keyword\">int</span> level)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    pos[u] = cnt_2;\n    find_u[cnt_2++] = u;\n    dep[u] = level;\n    \n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = head[u]; i != <span class=\"hljs-number\">-1</span>; i = e[i].nex)\n    &#123;\n        <span class=\"hljs-keyword\">int</span> v = e[i].v;\n        \n        <span class=\"hljs-comment\">// 欧拉序，回溯也放入</span>\n        pos[v] = cnt_2;\n        find_u[cnt_2++] = v;\n        dep[v] = level + <span class=\"hljs-number\">1</span>;\n        dfs(v, u, level + <span class=\"hljs-number\">1</span>);\n    &#125;\n&#125;\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">ST</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-comment\">// Preset Log</span>\n    Logn[<span class=\"hljs-number\">1</span>] = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">2</span>; i &lt;= n; ++i)\n        Logn[i] = Logn[i &gt;&gt; <span class=\"hljs-number\">1</span>] + <span class=\"hljs-number\">1</span>;\n    \n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">1</span>; i &lt;= n; ++i)\n        f[i][<span class=\"hljs-number\">0</span>] = find_u[i];\n\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> j = <span class=\"hljs-number\">1</span>; j &lt;= logn; ++j)\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">1</span>; i &lt;= n; ++i)\n            f[i][j] = dep[f[i][j - <span class=\"hljs-number\">1</span>]] &lt; dep[f[i + (j &lt;&lt; <span class=\"hljs-number\">1</span>)][j - <span class=\"hljs-number\">1</span>]] ? f[i][j - <span class=\"hljs-number\">1</span>] : f[i + (j &lt;&lt; <span class=\"hljs-number\">1</span>)][j - <span class=\"hljs-number\">1</span>];\n\n&#125;\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">lca</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> v)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> l = pos[u], r = pos[v];\n    <span class=\"hljs-keyword\">int</span> j = Logn[r - l + <span class=\"hljs-number\">1</span>];\n    <span class=\"hljs-comment\">// 直接找区间最小深度的节点</span>\n    <span class=\"hljs-keyword\">int</span> ans = min(f[l][j], f[r - (<span class=\"hljs-number\">1</span> &lt;&lt; j) + <span class=\"hljs-number\">1</span>][j]);\n    <span class=\"hljs-keyword\">return</span> pos[ans];    <span class=\"hljs-comment\">// 返回节点位置...</span>\n&#125;</code></pre>\n<hr>\n<h2 id=\"并查集\"><a href=\"#并查集\" class=\"headerlink\" title=\"并查集\"></a>并查集</h2><p>再来讲讲这周学的并查集</p>\n<p>并查集顾名思义支持且仅支持两种操作</p>\n<ol>\n<li>合并两个集合</li>\n<li>查询元素所在的集合</li>\n</ol>\n<p>并查集是一种树上的操作，通过根节点直接代表整棵树，初始化的时候根节点父节点为自身。</p>\n<ul>\n<li>合并操作</li>\n</ul>\n<p>合并操作相对比较简单，由于我们通过根节点来代表这个集合，那么合并两个集合只需要将其中一个的根节点作为另一个的子节点连接上即可。但同时我们要注意整棵树的深度会影响我们的时间复杂度，因而我们要尽可能不加深或是少加深树的深度，所以我们采用将深度较小的树连接到深度较大的树上，每次这样操作，树深度每次至多 +1，这种策略称之为<strong>按秩合并（启发式合并）</strong></p>\n<p><img src=\"https://oi-wiki.org/ds/images/dsu1.png\" alt></p>\n<ul>\n<li>代码</li>\n</ul>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">unionSet</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> y)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> tmp_x = find(x);\n    <span class=\"hljs-keyword\">int</span> tmp_y = find(y);\n    <span class=\"hljs-keyword\">if</span>(tmp_x == tmp_y)  <span class=\"hljs-comment\">// 本来就在同一集合中</span>\n        <span class=\"hljs-keyword\">return</span>; \n    <span class=\"hljs-keyword\">if</span>(sz[tmp_x] &gt; sz[tmp_y])\n        swap(tmp_x, tmp_y); <span class=\"hljs-comment\">// 让 tmp_x 是深度小的集合</span>\n    fa[tmp_x] = tmp_y; <span class=\"hljs-comment\">// 将 tmp_x 连接到 tmp_y 上</span>\n&#125;</code></pre>\n<ul>\n<li>查询操作</li>\n</ul>\n<p>我们来讲并查集关键的查询操作，并查集的查询操作给出一个节点，我们查询其父节点，如若其父节点不是自身就继续向上查询，直到查询到根节点（父节点为自身）返回根节点作为这个集合的代表。</p>\n<p>我们不难看出这样的查询操作单次是 $O(n)$ 的，原因是我们每次查询都要走完完整的一条链，但是其实我们并不关心该节点的父节点是谁，我们只想知道其根节点是什么。所以我们可以直接让它的父节点直接是根节点，这样虽然在第一次操作的时候，我们还是要走完一条链，但之后该节点的父节点直接就是根节点。这种操作称为<strong>路径压缩</strong></p>\n<p><img src=\"https://oi-wiki.org/ds/images/dsu2.png\" alt></p>\n<pre><code class=\"hljs cpp\">\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">find</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">if</span>(fa[x] == x)\n        <span class=\"hljs-keyword\">return</span> x;\n    <span class=\"hljs-keyword\">return</span> fa[x] = find(fa[x]); <span class=\"hljs-comment\">// 路径压缩</span>\n&#125;</code></pre>\n<ul>\n<li><strong>复杂度分析</strong></li>\n</ul>\n<p>我们现在来分析一下复杂度，朴素算法毫无疑问单次操作是 $O(mn)$ 的<br>如果我们使用了路径压缩，在Tarjan大神的论文[1] 中给出了复杂度的证明，只使用路径压缩不使用按秩合并的最坏时间复杂度是 $O(mlogn)$ 已经满足大部分题的需求，所以一般只需要路径压缩就能过题。<br>在姚期智的论文 [2] 中，证明了只路径压缩的平均复杂度为 $O(m\\alpha{(m,n)})$<br><em>注： $\\alpha$ 是阿克曼函数的反函数，其增长极其缓慢，也就是说其单次操作的平均运行时间可以认为是一个很小的常数。</em></p>\n<p>如果我们同时使用了路径压缩和按秩合并，那么我们可以做到 $O(m\\alpha{(m,n)})$ 的最坏时间复杂度。相当于单次询问是常数级别复杂度。</p>\n<p>Ackermann 函数</p>\n<script type=\"math/tex; mode=display\">\nA(m,n) =\\left\\{\n\\begin{array}{l}\n    n + 1, \\; m = 0 \\\\\n    A(m - 1, 1), m > 0 \\;and\\; n = 0 \\\\\n    A(m - 1, A(m, n - 1)),\\;othercases\n\\end{array}\n\\right.</script><p>$A(4, 3)$ 大的惊人，其反函数增长就相对应慢的惊人，直接可看为常数</p>\n<hr>\n<h2 id=\"树上差分算法\"><a href=\"#树上差分算法\" class=\"headerlink\" title=\"树上差分算法\"></a>树上差分算法</h2><p>讲一下这周作业题里涉及到的树上差分算法<br>树上差分问题可以用树链剖分解决，但我目前还不太会，就写一下现在会一点的树上差分。</p>\n<p>树上差分分为两种，边差分和点差分。</p>\n<ul>\n<li>边差分<br>考虑一个经典问题，<strong>给出两点x, y 将其路径上的边权加1，最后给出所有边权。</strong></li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r99w60.png\" alt=\"图源:https://www.cnblogs.com/zhwer/p/12800475.html\"></p>\n<p>我们看这张图，数组 c[k] 是差分数组只不过我们是自下而上加的，为不影响其他子树的结果，我们的统计在回溯过程中完成，因而是自下而上的，那么这个边权修改过程就可以看做是 c[x]++, c[y]++, 然后 根节点到lca(x, y)被加了两次，我们都要减去 c[lca(x, y)] -= 2</p>\n<p>既然是差分那么对于权值的更新，我们就可以如同前缀和一样计算，这不过这里的”前缀”是所有的子树权值，我们将所有子树权值收集起来到父节点上。</p>\n<ul>\n<li>代码实现</li>\n</ul>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// 已求出差分数组c</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">getAns</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa)</span></span>\n<span class=\"hljs-function\"></span>&#123;  \n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = head[u]; i != <span class=\"hljs-number\">-1</span>; i = e[i].nex)\n    &#123;\n        <span class=\"hljs-keyword\">int</span> v = e[i].v;\n        <span class=\"hljs-keyword\">if</span>(v != fa)\n        &#123;\n            getAns(v, u);\n            c[u] += c[v] <span class=\"hljs-comment\">// 收集子树权值更新c为原本数组</span>\n            <span class=\"hljs-comment\">// 更新后的c就代表其和其父节点连接边的边权</span>\n        &#125;\n    &#125;\n&#125;</code></pre>\n<ul>\n<li>点差分<br>点差分和边差分差不多，但这回每个点都代表的是自己了。<br><img src=\"https://s3.ax1x.com/2020/12/08/r990XV.png\" alt=\"图源:https://www.cnblogs.com/zhwer/p/12800475.html\"></li>\n</ul>\n<p>和边差分不同的是，这回lca不需要减2了，因为每个点代表的就是自己，在统计的时候 x, y 路径上是有 lca(x, y) 的，因而只需要减去一次重复计算即可。但这边lca在计算”前缀和”的时候会 +1，差分数组某一地方值的变动会影响到后面所有的值（这就是差分数组的精髓和意义所在）但lca的父亲并不应该 +1 所以我们要将 c[fa[lca(x,y)]]— 这个过程之后，我们的差分数组就完成了。<br>最后自下而上的收集一下，就能得到所有节点的权值了。</p>\n<ul>\n<li>思想总结</li>\n</ul>\n<p>差分的思想就是将原来本不相干的值联系到了一起，把后面点的部分信息移到了前面的点中，形成了区间的覆盖，这种效果正好能够用于解决区间修改问题，避免了暴力算法对每个点都进行操作，很巧妙的思想。</p>\n<hr>\n<h2 id=\"最后总结\"><a href=\"#最后总结\" class=\"headerlink\" title=\"最后总结\"></a>最后总结</h2><p>本周DS主要学习这些内容，AVL树很惭愧虽然上课讲了但还没有深入去看，线段树和树链剖分还不太会，树状数组也快忘记了。最近又重新听到了《蜗牛》这首歌，隔了这么多年，再听还是很感动。“历经的伤都不感觉疼”，“任风吹干流过的泪和汗，总有一天我有属于我的天。”<br>每周都在不断吸收新知识，很充实也很疲倦，每天都学到12点之后。就是希望能够在未来有一片自己的天。科研也在不断做，但进度很慢，时间分配越来越不够了，最近越来越感到拔尖班的藏龙卧虎，个个都是人才，让我感到了很大的压力。但就像《蜗牛》中说的即使我很慢，拖着重重的壳，只要我每天一步一步的向上爬，我总能触碰到那片属于我的蓝天。</p>\n<hr>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>[1]Tarjan, R. E., &amp; Van Leeuwen, J. (1984). Worst-case analysis of set union algorithms.<br>[2]Yao, A. C. (1985). On the expected performance of path compression algorithms. SIAM Journal on Computing, 14(1), 129-133.</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"数据结构-DataStructure\"><a href=\"#数据结构-DataStructure\" class=\"headerlink\" title=\"数据结构 - DataStructure\"></a>数据结构 - DataStructure</h1><p>数据结构这周依然是树上操作，课上学了AVL树，然后讲了之前用过的Hash，然后作业里面主要学会了LCA的倍增和不太熟练的欧拉序RMQ，最后学会了并查集的使用（就可以学最后的Tarjan LCA算法了) ，然后这周作业题主要是并查集，带有一道树上差分算法。</p>\n<hr>\n<h2 id=\"LCA-问题\"><a href=\"#LCA-问题\" class=\"headerlink\" title=\"LCA 问题\"></a>LCA 问题</h2><p>LCA (Least Common Ancestors) 最近公共祖先问题，顾名思义既要找到两个节点最近的公共祖先，朴素做法是，两个节点中深的那个节点向上跳，直到两个节点深度相同，两个节点再同时向上跳（询问父节点）如果他们跳到最后的父节点是同一个那么这个节点就是他们的最近公共祖先。</p>\n<p>这种朴素的算法很好思考，但复杂度也是很高的，单次询问时间复杂度 O(n) 因为最坏要把所有节点都跳一遍。</p>\n<p><img src=\"https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=1414039454,330983716&amp;fm=26&amp;gp=0.jpg\" alt></p>\n<h3 id=\"LCA-倍增算法\"><a href=\"#LCA-倍增算法\" class=\"headerlink\" title=\"LCA - 倍增算法\"></a><strong>LCA - 倍增算法</strong></h3><p>倍增算法是LCA的经典算法，如同二分算法的本质一样，都是通过每次尽量把问题规模缩减2的幂次，从而达到 O(lgn) 的时间复杂度。</p>\n<p>我们简单讲解一下，倍增算法就是我不再像朴素算法一样一个个往上跳，我直接跳2的幂次，从大到小枚举，如果符合题意就跳，直到 2^0 跳一个节点，这样一次遍历下来，总能覆盖所有情况而满足题意跳到要跳的地方，但复杂度却大大降低减为 O(lgn)</p>\n<ul>\n<li>代码实现<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">dfs</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    up[u][<span class=\"hljs-number\">0</span>] = fa;  <span class=\"hljs-comment\">// 预处理父亲</span>\n    dep[u] = dep[fa] + <span class=\"hljs-number\">1</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">auto</span>&amp; v : tree[u])\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(v == fa)\n            <span class=\"hljs-keyword\">continue</span>;\n        dfs(v, u);\n    &#125;\n&#125;\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">pre</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> k = <span class=\"hljs-number\">1</span>; (<span class=\"hljs-number\">1</span> &lt;&lt; k) &lt;= n; ++k)\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">1</span>; i &lt;= n; ++i)\n            up[i][k] = up[up[i][k - <span class=\"hljs-number\">1</span>]][k - <span class=\"hljs-number\">1</span>]; \n            <span class=\"hljs-comment\">// 预处理所有的上跳</span>\n            <span class=\"hljs-comment\">// 状态转移方程 跳 2^k 步，等于先跳2^k-1步再往上跳2^k-1步</span>\n            <span class=\"hljs-comment\">// 2 ^ k = 2 ^ (k - 1) + 2 ^ (k - 1)</span>\n&#125;   \n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">lca</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> y)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">if</span>(dep[x] &lt; dep[y])\n        swap(x, y); <span class=\"hljs-comment\">// 让深度大的为x</span>\n    <span class=\"hljs-keyword\">if</span>(dep[x] != dep[y])\n    &#123;\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> k = <span class=\"hljs-number\">31</span>; k &gt;= <span class=\"hljs-number\">0</span>; --k)\n        &#123;\n            <span class=\"hljs-keyword\">if</span>(dep[up[x][k]] &gt;= dep[y])\n                x = up[x][k];   <span class=\"hljs-comment\">// 调整为同一深度</span>\n        &#125;\n    &#125;\n\n    <span class=\"hljs-keyword\">if</span>(x == y)\n        <span class=\"hljs-keyword\">return</span> x;   \n        <span class=\"hljs-comment\">// 如果一个是另外一个的长辈那么这时候两个直接就相等了，直接返回</span>\n\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> k = <span class=\"hljs-number\">31</span>; k &gt;= <span class=\"hljs-number\">0</span>; --k)\n    &#123;\n        <span class=\"hljs-keyword\">if</span>(up[x][k] != up[y][k])    <span class=\"hljs-comment\">// 同时上跳不过头</span>\n        &#123;\n            x = up[x][k];   \n            y = up[y][k];\n        &#125;\n    &#125;\n\n    <span class=\"hljs-keyword\">return</span> up[x][<span class=\"hljs-number\">0</span>];    <span class=\"hljs-comment\">// 最后 lca 就是里面任意一个的父亲</span>\n&#125;</code></pre>\n</li>\n</ul>\n<hr>\n<h3 id=\"LCA-欧拉序RMQ算法\"><a href=\"#LCA-欧拉序RMQ算法\" class=\"headerlink\" title=\"LCA - 欧拉序RMQ算法\"></a><strong>LCA - 欧拉序RMQ算法</strong></h3><p>这边涉及到RMQ问题，我们就先来讲一讲RMQ问题。</p>\n<ul>\n<li><em>RMQ 问题</em><br>RMQ 是英文 Range Maximum/Minimum Query 的缩写，表示区间最大（最小）值。</li>\n</ul>\n<p>RMQ问题一般可以使用单调栈、ST表、线段树来解决</p>\n<p>通过欧拉序将LCA问题转为RMQ问题后，我们一般使用ST表来解决RMQ问题。因为ST表在时间复杂度上表现优秀，需要 O(nlgn)的预处理，就能做到O(1)的询问。而写起来又较为简单，不像线段树一样复杂。可以处理大部分不需要在线修改的 RMQ 问题。</p>\n<p>另一方面如果我们使用单调栈和线段树在单次询问的时间复杂度仍然是 O(lgn) 级别的本没有做到比倍增算法更优，但在代码方面却比倍增算法更为复杂，因而我们选择ST表进行处理。</p>\n<h3 id=\"ST表-Sparse-table\"><a href=\"#ST表-Sparse-table\" class=\"headerlink\" title=\"ST表 - Sparse table\"></a><strong>ST表 - Sparse table</strong></h3><p>我们说 ST 表可以用来解决可重复贡献问题，因为ST表涉及到区间重叠，我们要保证区间重叠不会影响到我们要求的问题。所以ST表只能解决可重复贡献问题，例如最值和gcd。</p>\n<p>ST表运用的也是倍增的思想，通过倍增区间覆盖来解决问题。</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// ST表</span>\n<span class=\"hljs-keyword\">int</span> f[Max][lgn]\b, Logn[Max], a[Max];\n<span class=\"hljs-comment\">// f[i][k] 表示区间 i ~ i + 2^k - 1 的最值</span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">pre</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    Logn[<span class=\"hljs-number\">1</span>] = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">2</span>; i &lt; Max; ++i)\n        Logn[i] = Logn[i / <span class=\"hljs-number\">2</span>] + <span class=\"hljs-number\">1</span>;\n&#125;\n\n<span class=\"hljs-comment\">// 状态转移：</span>\n    <span class=\"hljs-comment\">// 前者表示 i ~ i + 2^(k - 1) - 1 的区间最值</span>\n    <span class=\"hljs-comment\">// 后者表示 i + 2^(k - 1) ~ i + 2^k - 1 的区间最值</span>\n    <span class=\"hljs-comment\">// 合并即为 i ~ i + 2^k - 1的区间最值</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">preSet</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">1</span>; i &lt;= n; ++i)\n        f[i][<span class=\"hljs-number\">0</span>] = a[i]; <span class=\"hljs-comment\">// 显然 f[i][0] = a[i]</span>\n\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> k = <span class=\"hljs-number\">1</span>; k &lt; lgn; ++k)\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">1</span>; i + (<span class=\"hljs-number\">1</span> &lt;&lt; (k - <span class=\"hljs-number\">1</span>)) &lt;= n; ++i)\n            f[i][k] = max(f[i][k - <span class=\"hljs-number\">1</span>], f[i + (<span class=\"hljs-number\">1</span> &lt;&lt; (k - <span class=\"hljs-number\">1</span>))][k - <span class=\"hljs-number\">1</span>]);\n&#125;\n\n<span class=\"hljs-comment\">// 查询操作：</span>\n    <span class=\"hljs-comment\">// 如果我们要查询 区间 l ~ r 的最值, 我们根据ST表性质知道</span>\n    <span class=\"hljs-comment\">// f[i][k] 表示 l ~ l + 2^k - 1 的区间最值</span>\n    <span class=\"hljs-comment\">// r - 2^k + 1 ~ r 的区间最值就可以用 f[r - 1 &lt;&lt; k + 1][k] 表示</span>\n    <span class=\"hljs-comment\">// 那么我们需要这两个区间覆盖整个查询区间且不超过</span>\n    <span class=\"hljs-comment\">// 则 l + 2^k - 1 &gt;= r - 2^k + 1 且 l + 2^k - 1 &lt;= r 且 r - 2^k + 1 &gt;= l</span>\n    <span class=\"hljs-comment\">// 则 k &gt;= lg(r - l + 2) - 1 且 k &lt;= floor(lg(r - l + 1));</span>\n    <span class=\"hljs-comment\">// 我们直接取 k == floor(lg(r - l + 1))</span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">find</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> l, <span class=\"hljs-keyword\">int</span> r)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> k = Logn[r - l + <span class=\"hljs-number\">1</span>];\n    <span class=\"hljs-keyword\">return</span> max(f[i][k], f[r - (<span class=\"hljs-number\">1</span> &lt;&lt; k) + <span class=\"hljs-number\">1</span>][k]); <span class=\"hljs-comment\">// O(1) 查询</span>\n&#125;\n</code></pre>\n<p>这样一个ST表就写好了，回到正题，我们是通过欧拉序把 LCA问题转换为RMQ问题，我们现在来看这是如何进行的。</p>\n<p>在看欧拉序之前我们先看一看基本的 dfs 序是怎么做的（真就递归学习呗）</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20191008210415266.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3djeHlreQ==,size_16,color_FFFFFF,t_70\" alt=\"dfs序\"></p>\n<p>正常的dfs序是深度优先不记录回溯的，如上图 dfs 序就是<br><strong>A-&gt;B-&gt;D-&gt;E-&gt;G-&gt;C-&gt;F-&gt;H</strong><br>每个节点在dfs序中出现且仅出现一次</p>\n<p>而我们再来看欧拉序</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20191008210445328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3djeHlreQ==,size_16,color_FFFFFF,t_70\" alt=\"欧拉序\"></p>\n<p>它不同于dfs序将栈pop的元素也加入队列中，从而就形成了上图“逆时针”的模式<br>上图欧拉序就是<br><strong>A-&gt;B-&gt;D-&gt;B-&gt;E-&gt;G-&gt;E-&gt;B-&gt;A-&gt;C-&gt;F-&gt;H-&gt;F-&gt;C-&gt;A</strong><br>一种intuition就是欧拉序是一种正常人走路遍历所有节点的顺序，只要叶节点大于2个的树就不可能是欧拉图或半欧拉图，那么必然要走回头路，在dfs序的基础上将回头路线画出就是欧拉序。</p>\n<p>我们来观察欧拉序可以发现，其首尾必然是根节点，然后除了叶节点仅出现一次，其余点出现2次以上(取决于是几叉树)，如果我们默认是二叉树，那么欧拉序的大小就不会超过 2n - 1 (考虑单链或就两叉到底的最坏情况)</p>\n<p>如果我们在欧拉序节点旁配上它的深度再结合图来观察<br><strong>A(0)-&gt;B(1)-&gt;D(2)-&gt;B(1)-&gt;E(2)-&gt;G(3)-&gt;E(2)-&gt;B(1)-&gt;A(0)-&gt;C(1)-&gt;F(2)-&gt;H(3)-&gt;F(2)-&gt;C(1)-&gt;A(0)</strong><br>我们根据欧拉序的性质不难发现一个节点的左右子树必然夹在其在欧拉序中第二次出现的位置的左右两边，例如 B 的 左右子树 D, E 出现在B第二次出现位置[3]的两边[2]、[4]。<br>那么我们想如果我们找，两个节点的 LCA 就直接找两个节点第一次出现的位置，将其作为区间左右，在中间找深度最小的点就行了，这样找到的一定就是他们的LCA (不可能找到更浅的祖先) 。 当然其中包含了左边一个节点的子树，但为了方便我们就统一取第一次出现的位置即可。</p>\n<p>这样我们就在线性的时间内将LCA问题转化成了RMQ问题，然后通过之前O(nlgn)的预处理我们可以做到 O(1)的询问，这样LCA问题的总复杂度就是ST表预处理的 O(nlogn) 的复杂度。</p>\n<p>似乎总体没有比倍增更优，但单次询问比倍增快了很多，适合需要及时快速反馈的应用场景。</p>\n<ul>\n<li>代码实现</li>\n</ul>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// get eula array</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">dfs</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa, <span class=\"hljs-keyword\">int</span> level)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    pos[u] = cnt_2;\n    find_u[cnt_2++] = u;\n    dep[u] = level;\n    \n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = head[u]; i != <span class=\"hljs-number\">-1</span>; i = e[i].nex)\n    &#123;\n        <span class=\"hljs-keyword\">int</span> v = e[i].v;\n        \n        <span class=\"hljs-comment\">// 欧拉序，回溯也放入</span>\n        pos[v] = cnt_2;\n        find_u[cnt_2++] = v;\n        dep[v] = level + <span class=\"hljs-number\">1</span>;\n        dfs(v, u, level + <span class=\"hljs-number\">1</span>);\n    &#125;\n&#125;\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">ST</span><span class=\"hljs-params\">()</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-comment\">// Preset Log</span>\n    Logn[<span class=\"hljs-number\">1</span>] = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">2</span>; i &lt;= n; ++i)\n        Logn[i] = Logn[i &gt;&gt; <span class=\"hljs-number\">1</span>] + <span class=\"hljs-number\">1</span>;\n    \n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">1</span>; i &lt;= n; ++i)\n        f[i][<span class=\"hljs-number\">0</span>] = find_u[i];\n\n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> j = <span class=\"hljs-number\">1</span>; j &lt;= logn; ++j)\n        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">1</span>; i &lt;= n; ++i)\n            f[i][j] = dep[f[i][j - <span class=\"hljs-number\">1</span>]] &lt; dep[f[i + (j &lt;&lt; <span class=\"hljs-number\">1</span>)][j - <span class=\"hljs-number\">1</span>]] ? f[i][j - <span class=\"hljs-number\">1</span>] : f[i + (j &lt;&lt; <span class=\"hljs-number\">1</span>)][j - <span class=\"hljs-number\">1</span>];\n\n&#125;\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">lca</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> v)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> l = pos[u], r = pos[v];\n    <span class=\"hljs-keyword\">int</span> j = Logn[r - l + <span class=\"hljs-number\">1</span>];\n    <span class=\"hljs-comment\">// 直接找区间最小深度的节点</span>\n    <span class=\"hljs-keyword\">int</span> ans = min(f[l][j], f[r - (<span class=\"hljs-number\">1</span> &lt;&lt; j) + <span class=\"hljs-number\">1</span>][j]);\n    <span class=\"hljs-keyword\">return</span> pos[ans];    <span class=\"hljs-comment\">// 返回节点位置...</span>\n&#125;</code></pre>\n<hr>\n<h2 id=\"并查集\"><a href=\"#并查集\" class=\"headerlink\" title=\"并查集\"></a>并查集</h2><p>再来讲讲这周学的并查集</p>\n<p>并查集顾名思义支持且仅支持两种操作</p>\n<ol>\n<li>合并两个集合</li>\n<li>查询元素所在的集合</li>\n</ol>\n<p>并查集是一种树上的操作，通过根节点直接代表整棵树，初始化的时候根节点父节点为自身。</p>\n<ul>\n<li>合并操作</li>\n</ul>\n<p>合并操作相对比较简单，由于我们通过根节点来代表这个集合，那么合并两个集合只需要将其中一个的根节点作为另一个的子节点连接上即可。但同时我们要注意整棵树的深度会影响我们的时间复杂度，因而我们要尽可能不加深或是少加深树的深度，所以我们采用将深度较小的树连接到深度较大的树上，每次这样操作，树深度每次至多 +1，这种策略称之为<strong>按秩合并（启发式合并）</strong></p>\n<p><img src=\"https://oi-wiki.org/ds/images/dsu1.png\" alt></p>\n<ul>\n<li>代码</li>\n</ul>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">unionSet</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> y)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span> tmp_x = find(x);\n    <span class=\"hljs-keyword\">int</span> tmp_y = find(y);\n    <span class=\"hljs-keyword\">if</span>(tmp_x == tmp_y)  <span class=\"hljs-comment\">// 本来就在同一集合中</span>\n        <span class=\"hljs-keyword\">return</span>; \n    <span class=\"hljs-keyword\">if</span>(sz[tmp_x] &gt; sz[tmp_y])\n        swap(tmp_x, tmp_y); <span class=\"hljs-comment\">// 让 tmp_x 是深度小的集合</span>\n    fa[tmp_x] = tmp_y; <span class=\"hljs-comment\">// 将 tmp_x 连接到 tmp_y 上</span>\n&#125;</code></pre>\n<ul>\n<li>查询操作</li>\n</ul>\n<p>我们来讲并查集关键的查询操作，并查集的查询操作给出一个节点，我们查询其父节点，如若其父节点不是自身就继续向上查询，直到查询到根节点（父节点为自身）返回根节点作为这个集合的代表。</p>\n<p>我们不难看出这样的查询操作单次是 $O(n)$ 的，原因是我们每次查询都要走完完整的一条链，但是其实我们并不关心该节点的父节点是谁，我们只想知道其根节点是什么。所以我们可以直接让它的父节点直接是根节点，这样虽然在第一次操作的时候，我们还是要走完一条链，但之后该节点的父节点直接就是根节点。这种操作称为<strong>路径压缩</strong></p>\n<p><img src=\"https://oi-wiki.org/ds/images/dsu2.png\" alt></p>\n<pre><code class=\"hljs cpp\">\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">find</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">if</span>(fa[x] == x)\n        <span class=\"hljs-keyword\">return</span> x;\n    <span class=\"hljs-keyword\">return</span> fa[x] = find(fa[x]); <span class=\"hljs-comment\">// 路径压缩</span>\n&#125;</code></pre>\n<ul>\n<li><strong>复杂度分析</strong></li>\n</ul>\n<p>我们现在来分析一下复杂度，朴素算法毫无疑问单次操作是 $O(mn)$ 的<br>如果我们使用了路径压缩，在Tarjan大神的论文[1] 中给出了复杂度的证明，只使用路径压缩不使用按秩合并的最坏时间复杂度是 $O(mlogn)$ 已经满足大部分题的需求，所以一般只需要路径压缩就能过题。<br>在姚期智的论文 [2] 中，证明了只路径压缩的平均复杂度为 $O(m\\alpha{(m,n)})$<br><em>注： $\\alpha$ 是阿克曼函数的反函数，其增长极其缓慢，也就是说其单次操作的平均运行时间可以认为是一个很小的常数。</em></p>\n<p>如果我们同时使用了路径压缩和按秩合并，那么我们可以做到 $O(m\\alpha{(m,n)})$ 的最坏时间复杂度。相当于单次询问是常数级别复杂度。</p>\n<p>Ackermann 函数</p>\n<script type=\"math/tex; mode=display\">\nA(m,n) =\\left\\{\n\\begin{array}{l}\n    n + 1, \\; m = 0 \\\\\n    A(m - 1, 1), m > 0 \\;and\\; n = 0 \\\\\n    A(m - 1, A(m, n - 1)),\\;othercases\n\\end{array}\n\\right.</script><p>$A(4, 3)$ 大的惊人，其反函数增长就相对应慢的惊人，直接可看为常数</p>\n<hr>\n<h2 id=\"树上差分算法\"><a href=\"#树上差分算法\" class=\"headerlink\" title=\"树上差分算法\"></a>树上差分算法</h2><p>讲一下这周作业题里涉及到的树上差分算法<br>树上差分问题可以用树链剖分解决，但我目前还不太会，就写一下现在会一点的树上差分。</p>\n<p>树上差分分为两种，边差分和点差分。</p>\n<ul>\n<li>边差分<br>考虑一个经典问题，<strong>给出两点x, y 将其路径上的边权加1，最后给出所有边权。</strong></li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r99w60.png\" alt=\"图源:https://www.cnblogs.com/zhwer/p/12800475.html\"></p>\n<p>我们看这张图，数组 c[k] 是差分数组只不过我们是自下而上加的，为不影响其他子树的结果，我们的统计在回溯过程中完成，因而是自下而上的，那么这个边权修改过程就可以看做是 c[x]++, c[y]++, 然后 根节点到lca(x, y)被加了两次，我们都要减去 c[lca(x, y)] -= 2</p>\n<p>既然是差分那么对于权值的更新，我们就可以如同前缀和一样计算，这不过这里的”前缀”是所有的子树权值，我们将所有子树权值收集起来到父节点上。</p>\n<ul>\n<li>代码实现</li>\n</ul>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// 已求出差分数组c</span>\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">getAns</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> u, <span class=\"hljs-keyword\">int</span> fa)</span></span>\n<span class=\"hljs-function\"></span>&#123;  \n    <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i = head[u]; i != <span class=\"hljs-number\">-1</span>; i = e[i].nex)\n    &#123;\n        <span class=\"hljs-keyword\">int</span> v = e[i].v;\n        <span class=\"hljs-keyword\">if</span>(v != fa)\n        &#123;\n            getAns(v, u);\n            c[u] += c[v] <span class=\"hljs-comment\">// 收集子树权值更新c为原本数组</span>\n            <span class=\"hljs-comment\">// 更新后的c就代表其和其父节点连接边的边权</span>\n        &#125;\n    &#125;\n&#125;</code></pre>\n<ul>\n<li>点差分<br>点差分和边差分差不多，但这回每个点都代表的是自己了。<br><img src=\"https://s3.ax1x.com/2020/12/08/r990XV.png\" alt=\"图源:https://www.cnblogs.com/zhwer/p/12800475.html\"></li>\n</ul>\n<p>和边差分不同的是，这回lca不需要减2了，因为每个点代表的就是自己，在统计的时候 x, y 路径上是有 lca(x, y) 的，因而只需要减去一次重复计算即可。但这边lca在计算”前缀和”的时候会 +1，差分数组某一地方值的变动会影响到后面所有的值（这就是差分数组的精髓和意义所在）但lca的父亲并不应该 +1 所以我们要将 c[fa[lca(x,y)]]— 这个过程之后，我们的差分数组就完成了。<br>最后自下而上的收集一下，就能得到所有节点的权值了。</p>\n<ul>\n<li>思想总结</li>\n</ul>\n<p>差分的思想就是将原来本不相干的值联系到了一起，把后面点的部分信息移到了前面的点中，形成了区间的覆盖，这种效果正好能够用于解决区间修改问题，避免了暴力算法对每个点都进行操作，很巧妙的思想。</p>\n<hr>\n<h2 id=\"最后总结\"><a href=\"#最后总结\" class=\"headerlink\" title=\"最后总结\"></a>最后总结</h2><p>本周DS主要学习这些内容，AVL树很惭愧虽然上课讲了但还没有深入去看，线段树和树链剖分还不太会，树状数组也快忘记了。最近又重新听到了《蜗牛》这首歌，隔了这么多年，再听还是很感动。“历经的伤都不感觉疼”，“任风吹干流过的泪和汗，总有一天我有属于我的天。”<br>每周都在不断吸收新知识，很充实也很疲倦，每天都学到12点之后。就是希望能够在未来有一片自己的天。科研也在不断做，但进度很慢，时间分配越来越不够了，最近越来越感到拔尖班的藏龙卧虎，个个都是人才，让我感到了很大的压力。但就像《蜗牛》中说的即使我很慢，拖着重重的壳，只要我每天一步一步的向上爬，我总能触碰到那片属于我的蓝天。</p>\n<hr>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>[1]Tarjan, R. E., &amp; Van Leeuwen, J. (1984). Worst-case analysis of set union algorithms.<br>[2]Yao, A. C. (1985). On the expected performance of path compression algorithms. SIAM Journal on Computing, 14(1), 129-133.</p>\n"},{"title":"ICS-Lab4.2 各种链接姿势","date":"2020-11-15T09:37:43.000Z","index_img":"/img/ICS_Lab1/top.jpg","_content":"\n### Task0 - 简单链接\n\n```cpp\n#include \"some.h\"\n\nint main(){\n    testPrint();\n    testPrint(5);\n    notATest();\n    return 0;\n}\n```\n\n- **错误分析**\n\n> 我们可以看到main函数中调用了三个函数，全是外部的，在链接时，符号表会进行搜索匹配。我们再来看some.h中定义了哪些函数.\n\n```cpp\n#include <cstdio>\n\nvoid testPrint();\nvoid testPrint(int num);\n```\n\n> 发现只有两个test函数,而没有notATest定义的函数，根据这个离谱的名字我们可以断定在cstdio中也没有同名函数。\n所以最后符号表中没有匹配上，会引发链接错误。\n\n- **解决方法**\n\n> 直接将 notATest() 注释掉, 再在 makefile 中使用 \n```\ng++ main.cpp some.cpp -o main \n```\n\n---\n\n### Task1 - 链接与重复包含问题\n\n- **解题过程**\n\n通过阅读代码，我们可以发现改题的代码会根据宏DEBUG是否被定义而有不同的行为，决定是否打印更加详细的内容\n\n```cpp\n#include \"function0.h\"\n\nvoid func0(){\n    # ifdef DEBUG\n    printDebug(); //打印debug信息 (详细操作在shared.cpp中)\n    # else\n    print(); //打印正常信息\n    # endif\n}\n```\n\n> 根据题意，我们需要在 Makefile 中,对于要求的 main1 需要做一个相等的条件判断\n\n```makefile\nmain0:\n    g++ main0.cpp function0.cpp function1.cpp shared.cpp -o main0\ndebug = False\nmain1:\nifeq ($(debug),True) \n\tg++ main1.cpp -DDEBUG function0.cpp function1.cpp shared.cpp -o main1\nelse\n\tg++ main1.cpp function0.cpp function1.cpp shared.cpp -o main1\nendif\n```\n\n*值得注意的是，makefile中 if 语句前不能有 tab 或者空格*\n\n**Include 路径**\n![](https://s3.ax1x.com/2020/11/15/DFeVyt.png)\n\n- **问题**\n\n1. 为什么两个function.h都引⽤了shared.h⽽没有出问题？本来有可能出什么问题。\n\n\n> 因为 shared.h 中仅包含函数声明，而不包含函数的定义，因而不会有重定义问题。如果 #include shared.cpp 则会出现重定义问题。\n\n\n2. 如果把shared.h中注释掉的变量定义取消注释会出什么问题？为什么？\n\n> 会出现变量重定义问题，由于全局变量 string 被两次 include 到func0 和 func1 中，最后被同时引用至 main 中，导致重定义。在符号表中产生冲突，报错。\n\n3. 通常使⽤shared.h中另外被注释掉的宏命令(#开头的那些⾏)来规避重复引⽤的⻛险，原理是什么？取消这些注释之后上⼀题的问题解除了吗？背后的原因是什么？\n\n> 通过宏定义，在第一次 include 的时候定义宏为函数名，之后再次include 的时候由于已经 define 就不再次 include。这种方式的缺点是如果有已有宏名与函数名重复时，将会报错。使用 #pragama once 则是由c++编译器保证 include 一次，不会有宏名重复问题。\n\n> 上题的问题并没有解决，因为FOO是全局变量，其赋了初值，被链接器标记为strong，被重复 include 到了 main 中，两个 strong 标记冲突报错。\n\n---\n\n### Task2 - 静态链接库\n\n在这个 Task 中我们需要编译2个静态链接库，并链接3个静态链接库，完成编译。\n\n**A Makefile**\n```makefile\nlibA:\t\n\tg++ -c A.cpp \n\tar -r libA.a A.o\n```\n\n> 先用g++ -c编译出A.o可重定位目标文件，再通过 ar 命令编译静态链接库。（libC 同理）\n\n**Main Makefile**\n```makefile\nmain : \n\tcd A && make libA\n\tcd C && make libC\n\tg++ main.cpp B/libB.a A/libA.a C/libC.a -o main\n```\n\n> 再 CD 入每个目录进行 make 编译， 最后把静态链接库进行链接。 \n\n- **静态库链接搜索路径顺序：**\n\n1. ld会去找GCC命令中的参数-L\n2. 再找gcc的环境变量LIBRARY_PATH\n3. 再找内定目录 /lib /usr/lib /usr/local/lib \n\n- **问题**\n\n1. 若有多个静态链接库需要链接，写命令时需要考虑静态链接库和源⽂件在命令中的顺序吗？是否需要考虑是由什么决定的？\n> **需要考虑**，链接器在链接过程中按命令中输入的顺序进行符号表匹配，可以将这个匹配过程抽象的看作链接器在维护三个集合 E(待合并文件), U(被引用且尚未匹配), D（已匹配），根据顺序动态更新E, 和U,D, 最后如果 U 为空则正常整合 E 生成可执行文件，不然则报错有符号被引用了但未能匹配。所以如果我们的静态库都是相互独立的，那么顺序是没关系的。但如果互相依赖，那么我们必须保证在对某个符号的引用的库后，必然有一个库中存在对其的定义，不然则会报错。\n\n1. 可以使⽤size main命令来查看可执⾏⽂件所占的空间，输出结果的每⼀项是什么意思？\n\n| text  | data   |  bss  |  dec   | hex | filename |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n|  22721  |  712  |  288 |  23721  | 5ca9 | main |\n\n- **text:** 机器代码字节\n- **data:** 包含静态变量和已经初始化的全局变量的数据段字节数大小\n- **bss:** Block Started by Symbol (better save space) 存放程序中未初始化的全局变量的字节数大小，BBS段属于静态内存分配, 不占真实内存空间（仅占位符）\n- **dec:** = test + data + bss\n- **hex:** 16进制的dec\n- **filename:** 顾名思义，文件名\n\n---\n\n### Task3 - 动态链接库\n\n整体操作和上一个Task很像，只是链接的是动态链接库 .so\n\n**A Makefile**\n```makefile\nlibA:\n\tg++ -fPIC -c A.cpp\n\tg++ -shared -fPIC A.o -o libA.so\n```\n\n> 在 A 中先编译出 A.o 再用 -shared 编译出动态链接库 .so\n\n**Main Makefile**\n```makefile\nmain : \n\tcd A && make libA\n\tcd C && make libC\n\tg++ main.cpp A/libA.so ./libB.so C/libC.so -o main\n```\n\n> 直接 cd 进去 make 出动态链接库后，再进行链接。\n\n- **问题**\n\n1. 动态链接库在运⾏时也需要查找库的位置，在Linux中，运⾏时动态链接库的查找顺序是怎样的？\n> **动态链接时、执行时搜索路径顺序:**\n> 1. 编译目标代码时指定的动态库搜索路径\n> 2. 环境变量LD_LIBRARY_PATH指定的动态库搜索路径\n> 3. 配置文件/etc/ld.so.conf中指定的动态库搜索路径\n> 4. 默认的动态库搜索路径/lib\n> 5. 默认的动态库搜索路径/usr/lib\n\n2. 使⽤size main查看编译出的可执⾏⽂件占据的空间，与使⽤静态链接库相⽐占⽤空间有何变化？哪些部分的哪些代码（也要具体到本task）会导致编译出⽂件的占⽤空间发⽣这种变化？\n\n| text  | data  |  bss  |  dec  | hex | filename |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n|  3089 | 720  | 96 | 3905 | f41  |  main |\n\n> **占用空间变小了**，因为不同于静态链接库将所有的静态库都整合入可执行文件中，动态链接库是在程序开始或正在运行时被链接加载的，所有可执行文件本身的空间占用会大幅缩小。\n\n> main 中调用了 A, B, C 函数，所以其中的函数以及静态全局变量 A_name, B_name 会被被置于动态链接库.so中动态加载\n\n1. 编译动态链接库时-fPIC的作⽤是什么，不加会有什么后果？\n-fPIC 含义是 Generate position-independent code (PIC)，例如在汇编的 jmp 语句中通常使用的是固定的内部地址\n```\n100: COMPARE REG1, REG2\n101: JUMP_IF_EQUAL 111\n...\n111: NOP\n```\n> 而通过 -fPIC 参数 jmp 语句所指向的是相对地址\n使用的是代码段和数据段的OFFSET，从而实现位置无关，可以动态加载到内存中，不同进程可以共享。\n\n```\n100: COMPARE REG1, REG2\n101: JUMP_IF_EQUAL CURRENT+10\n...\n111: NOP\n```\n\n> 如果不加，在某些系统下不会有很大的问题，但一般在 -shared 后面最好加上 -fPIC 来保证动态链接库是位置无关的，不然无法实现动态链接（由于位置相关即分配绝对内存地址，导致多个副本存在于内存中，无法实现动态链接）\n\n**info in gcc manual**\n\n- **-shared:**  Produce a shared object which can then be linked with other objects to forman executable. Not all systems support this option. For predictable results,\nyou must also specify the same set of options used for compilation (‘-fpic’,‘-fPIC’, or model suboptions) when you specify this linker option.*\n\n4. 现在被⼴泛使⽤的公开的动态链接库如何进⾏版本替换或共存（以linux系统为例）？\n\n> 通过动态链接，如果开发者需要维护程序的某一部分（某几个功能的函数），仅需要维护修改所在的动态链接库即可，然后将其发布。用户只需要替换动态链接库，在程序运行的时候自然会动态链接到新的链接库，**在接口保持不变**的情况下完成很自然流畅的版本更新。\n\n---\n\n### Task4 - ld手动链接\n\n- **解题过程**\n这题要求我们用ld链接器，进行手动链接，我们先试一下直接链接会发生什么\n\n```makefile\n#链接代码\nld -o main main.o some.o\n```\n\n```cpp\n//报错信息\nld: warning: cannot find entry symbol _start; defaulting to 00000000004000b0\nsome.o: In function `notATest()':\nsome.cpp:(.text+0xc): undefined reference to `puts'\nsome.o: In function `testPrint()':\nsome.cpp:(.text+0x1f): undefined reference to `puts'\nsome.o: In function `testPrint(int)':\nsome.cpp:(.text+0x52): undefined reference to `printf'\nMakefile:2: recipe for target 'main' failed\nmake: *** [main] Error 1\n```\n\n> 发现主要报错信息是 undefined reference to 'puts', 'printf', 说明标准库中的函数符号没有被成功匹配，我们需要把 stdc 加进去\n\n```makefile\n# 链接代码\nld -o main main.o some.o -lc\n# 通过 -lc 命令直接添加标准库，也可以自行指定libc.so路径\n```\n\n> 可以发现main被成功编译出来，但运行时候发现bash报目录中无此文件\n```bash\nbash: ./main: No such file or directory\n```\n\n> 也就是我们并不能运行这个可执行文件，查找资料之后我们尝试指定使用的动态链接器再进行编译，就可以运行了\n\n```makefile\nld -dynamic-linker /lib64/ld-linux-x86-64.so.2 -o main main.o some.o -lc\n```\n\n> 我查询了ld的手册试图查找原因，但并未发现为什么必须要使用--dynamic-linker指令\n\n<div style=\"page-break-after: always;\"></div>\n\n\n- **--dynamic-linker=file**\n>    Set the name of the dynamic linker.  This is only meaningful when generating dynamically linked ELF executables.  **The default dynamic linker is normally correct; don't use this unless you know what you are doing.**\n\n\n\n> 接下去，我们的程序虽然能够运行起来了，但在 main 函数跑完之后会出现 *Segmentation fault (core dumped)* 提示，这也提示了我们对于 main 函数的初始化和结束可能并未正常执行。\n\n- **GDB查看正常程序**\n\n![](https://s3.ax1x.com/2020/11/15/DFeZOP.png)\n\n> 通过 gdb 查看正常程序我们发现，正常的 main 函数执行栈中需要有两个函数为其保证环境 *__lib_csu_init* 和 *__libc_start_main*\n\n- **__libc_start_main**\n我们需要知道，在linux中，main函数的初始化环境和参数传递以及返回值处理工作是由 __libc_start_main 来保证的。一个正常的程序执行需要包含以下要素。\n\n1. performing any necessary security checks if the effective user ID is not the same as the real user ID.\n2. initialize the threading subsystem.\n3. registering the *rtld_fini* to release resources when this dynamic shared object exits (or is unloaded).\n4. registering the *fini* handler to run at program exit.\n5. calling the initializer function *(*init)()*.\n6. calling *main()* with appropriate arguments.\n7. calling *exit()* with the return value from *main()*.\n\n> 具体的初始化和结束调用路径异常复杂，在此不多赘述，放一张图有待进一步研究。\n\n![](https://s3.ax1x.com/2020/11/15/DFemef.png)\n\n*图片来源: https://luomuxiaoxiao.com/?p=516*\n\n---\n\n然后介绍完了主函数的初始化和返回，我们需要知道保证上述的两个函数在哪个动态链接库中，这就涉及到了 *crt1.o, crti.o, crtbegin.o, crtend.o, crtn.o* 这几个库\n*参考： https://blog.csdn.net/farmwang/article/details/73195951*\n\n> **crt是c runtime 的缩写**,用于执行进入main之前的初始化和退出main之后的扫尾工作。\n\n| 目标文件 | crt1.o| crti.o| crtbegin.o| crtend.o | crtn.o |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 作用 | 启动|初始化|构造|析构|结束 |\n\n> 在标准的linux平台下,link的顺序是\n\n\tld crt1.o crti.o [user_objects] [system_libraries] crtn.o\n\n所以我们按照顺序进行链接有如下命令\n\n```makefile\n# 链接指令\nld -dynamic-linker /lib64/ld-linux-x86-64.so.2 -o main /usr/lib/x86_64-linux-gnu/crt1.o main.o some.o -lc /usr/lib/x86_64-linux-gnu/crti.o /usr/lib/x86_64-linux-gnu/crtn.o\n```\n\n> 成功的手动完成了程序的链接工作。\n\n以上艰苦的工作告诉我们，不要轻易尝试手动链接，除非你知道你在干什么。平时好好用 gcc。\n\n- 动态链接器⼀个操作系统中只需要⼀个吗？为什么？\n> 一般来说只要有一个支持的动态链接器即可，完成程序的动态链接工作。 但linux中可能有两个 ld 的版本\n1. ld.so针对a.out格式的二进制可执行文件\n2. ld-linux.so针对ELF格式的二进制可执行文件\n\na.out是旧版类Unix系统中用于执行档、目的码和后来系统中的函数库的一种文件格式，该版本的链接器仍被保留用以向前支持。\n\n---\n\n### Task5 - 运行时打桩\n\nTask5 是一个典型的运行时打桩的 task，给了我们编译好的login程序，让我们改变其行为，让它能够输出 login_success.\n\n> 阅读源码，我们可以发现，login将我们输入的字符串做了hash，与已有某不明hash值，进行比较，如果相等则登陆成功。根据本 lab 的内容主要是讲 make 和链接的，让我们碰撞这个hash显然不是本意。那另一种方法就是通过运行时打桩，改变标准库的链接方式，让strcmp 链接到我们自己写的 strcmp 版本上去，从而我们可以控制其返回值让其返回0使得登陆成功。\n\n*首先要注意 strcmp 并非只有判断密码时的一次唯一调用，在别处还有调用，所以我们要保证 strcmp 函数的基本功能正确*\n```cpp\n// mystrcmp.c\n#define _GNU_SOURCE\n#include <stdio.h>\n#include <dlfcn.h>\n\nint strcmp(const char *lhs, const char *rhs)\n{\n    int(*strcmpp)(const char *lhs, const char *rhs);\n    strcmpp = dlsym(RTLD_NEXT, \"strcmp\");\n\n    char tmp[] = \"3983709877683599140\";\n    if(strcmpp(tmp, rhs) == 0)\n        return 0;\n    return strcmpp(lhs, rhs);\n}\n```\n\n> 我们直接写一个自己的 strcmp 版本，用 dlsym 可以获取在运行时 strcmp 函数的指针 *（不这样做也可以，可以直接自己重写一遍strcmp程序）*，相当于可以直接使用 **真实的标准库中的 strcmp**，然后我们稍微改写一下，让它和我们的hash值比较的时候直接返回0，能够让我们不管输入什么密码都能够 login_success。\n\n接下来我们先将我们写的strcmp编译成动态链接库\n\n```shell\ngcc -shared -fpic -o mystrcmp.so mystrcmp.c -ldl\n```\n\n> 然后使用 **LD_PRELOAD=\"./mystrcmp.so\"** 指令，从而在 strcmp 动态链接到标准库之前让其优先匹配我们写的动态链接库中的 strcmp 符号。\n\n这里需要注意由于是要直接运行 ./login, 所以我们需要把LD_PRELOAD的效果全局化，也既在前面加上 export 标记。\n\n```shell\nexport LD_PRELOAD=\"./mystrcmp.so\"\n```\n\n最后注意不要忘记卸载全局 preload， 不然之后所有程序都 preload 这个strcmp。\n\n```shell\nexport LD_PRELOAD=NULL\n```","source":"_posts/ICS/ICS_Lab3.md","raw":"---\ntitle: ICS-Lab4.2 各种链接姿势\ndate: 2020-11-15 17:37:43\nindex_img: /img/ICS_Lab1/top.jpg\ncategory: [ICS]\ntags: [Linker]\n---\n\n### Task0 - 简单链接\n\n```cpp\n#include \"some.h\"\n\nint main(){\n    testPrint();\n    testPrint(5);\n    notATest();\n    return 0;\n}\n```\n\n- **错误分析**\n\n> 我们可以看到main函数中调用了三个函数，全是外部的，在链接时，符号表会进行搜索匹配。我们再来看some.h中定义了哪些函数.\n\n```cpp\n#include <cstdio>\n\nvoid testPrint();\nvoid testPrint(int num);\n```\n\n> 发现只有两个test函数,而没有notATest定义的函数，根据这个离谱的名字我们可以断定在cstdio中也没有同名函数。\n所以最后符号表中没有匹配上，会引发链接错误。\n\n- **解决方法**\n\n> 直接将 notATest() 注释掉, 再在 makefile 中使用 \n```\ng++ main.cpp some.cpp -o main \n```\n\n---\n\n### Task1 - 链接与重复包含问题\n\n- **解题过程**\n\n通过阅读代码，我们可以发现改题的代码会根据宏DEBUG是否被定义而有不同的行为，决定是否打印更加详细的内容\n\n```cpp\n#include \"function0.h\"\n\nvoid func0(){\n    # ifdef DEBUG\n    printDebug(); //打印debug信息 (详细操作在shared.cpp中)\n    # else\n    print(); //打印正常信息\n    # endif\n}\n```\n\n> 根据题意，我们需要在 Makefile 中,对于要求的 main1 需要做一个相等的条件判断\n\n```makefile\nmain0:\n    g++ main0.cpp function0.cpp function1.cpp shared.cpp -o main0\ndebug = False\nmain1:\nifeq ($(debug),True) \n\tg++ main1.cpp -DDEBUG function0.cpp function1.cpp shared.cpp -o main1\nelse\n\tg++ main1.cpp function0.cpp function1.cpp shared.cpp -o main1\nendif\n```\n\n*值得注意的是，makefile中 if 语句前不能有 tab 或者空格*\n\n**Include 路径**\n![](https://s3.ax1x.com/2020/11/15/DFeVyt.png)\n\n- **问题**\n\n1. 为什么两个function.h都引⽤了shared.h⽽没有出问题？本来有可能出什么问题。\n\n\n> 因为 shared.h 中仅包含函数声明，而不包含函数的定义，因而不会有重定义问题。如果 #include shared.cpp 则会出现重定义问题。\n\n\n2. 如果把shared.h中注释掉的变量定义取消注释会出什么问题？为什么？\n\n> 会出现变量重定义问题，由于全局变量 string 被两次 include 到func0 和 func1 中，最后被同时引用至 main 中，导致重定义。在符号表中产生冲突，报错。\n\n3. 通常使⽤shared.h中另外被注释掉的宏命令(#开头的那些⾏)来规避重复引⽤的⻛险，原理是什么？取消这些注释之后上⼀题的问题解除了吗？背后的原因是什么？\n\n> 通过宏定义，在第一次 include 的时候定义宏为函数名，之后再次include 的时候由于已经 define 就不再次 include。这种方式的缺点是如果有已有宏名与函数名重复时，将会报错。使用 #pragama once 则是由c++编译器保证 include 一次，不会有宏名重复问题。\n\n> 上题的问题并没有解决，因为FOO是全局变量，其赋了初值，被链接器标记为strong，被重复 include 到了 main 中，两个 strong 标记冲突报错。\n\n---\n\n### Task2 - 静态链接库\n\n在这个 Task 中我们需要编译2个静态链接库，并链接3个静态链接库，完成编译。\n\n**A Makefile**\n```makefile\nlibA:\t\n\tg++ -c A.cpp \n\tar -r libA.a A.o\n```\n\n> 先用g++ -c编译出A.o可重定位目标文件，再通过 ar 命令编译静态链接库。（libC 同理）\n\n**Main Makefile**\n```makefile\nmain : \n\tcd A && make libA\n\tcd C && make libC\n\tg++ main.cpp B/libB.a A/libA.a C/libC.a -o main\n```\n\n> 再 CD 入每个目录进行 make 编译， 最后把静态链接库进行链接。 \n\n- **静态库链接搜索路径顺序：**\n\n1. ld会去找GCC命令中的参数-L\n2. 再找gcc的环境变量LIBRARY_PATH\n3. 再找内定目录 /lib /usr/lib /usr/local/lib \n\n- **问题**\n\n1. 若有多个静态链接库需要链接，写命令时需要考虑静态链接库和源⽂件在命令中的顺序吗？是否需要考虑是由什么决定的？\n> **需要考虑**，链接器在链接过程中按命令中输入的顺序进行符号表匹配，可以将这个匹配过程抽象的看作链接器在维护三个集合 E(待合并文件), U(被引用且尚未匹配), D（已匹配），根据顺序动态更新E, 和U,D, 最后如果 U 为空则正常整合 E 生成可执行文件，不然则报错有符号被引用了但未能匹配。所以如果我们的静态库都是相互独立的，那么顺序是没关系的。但如果互相依赖，那么我们必须保证在对某个符号的引用的库后，必然有一个库中存在对其的定义，不然则会报错。\n\n1. 可以使⽤size main命令来查看可执⾏⽂件所占的空间，输出结果的每⼀项是什么意思？\n\n| text  | data   |  bss  |  dec   | hex | filename |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n|  22721  |  712  |  288 |  23721  | 5ca9 | main |\n\n- **text:** 机器代码字节\n- **data:** 包含静态变量和已经初始化的全局变量的数据段字节数大小\n- **bss:** Block Started by Symbol (better save space) 存放程序中未初始化的全局变量的字节数大小，BBS段属于静态内存分配, 不占真实内存空间（仅占位符）\n- **dec:** = test + data + bss\n- **hex:** 16进制的dec\n- **filename:** 顾名思义，文件名\n\n---\n\n### Task3 - 动态链接库\n\n整体操作和上一个Task很像，只是链接的是动态链接库 .so\n\n**A Makefile**\n```makefile\nlibA:\n\tg++ -fPIC -c A.cpp\n\tg++ -shared -fPIC A.o -o libA.so\n```\n\n> 在 A 中先编译出 A.o 再用 -shared 编译出动态链接库 .so\n\n**Main Makefile**\n```makefile\nmain : \n\tcd A && make libA\n\tcd C && make libC\n\tg++ main.cpp A/libA.so ./libB.so C/libC.so -o main\n```\n\n> 直接 cd 进去 make 出动态链接库后，再进行链接。\n\n- **问题**\n\n1. 动态链接库在运⾏时也需要查找库的位置，在Linux中，运⾏时动态链接库的查找顺序是怎样的？\n> **动态链接时、执行时搜索路径顺序:**\n> 1. 编译目标代码时指定的动态库搜索路径\n> 2. 环境变量LD_LIBRARY_PATH指定的动态库搜索路径\n> 3. 配置文件/etc/ld.so.conf中指定的动态库搜索路径\n> 4. 默认的动态库搜索路径/lib\n> 5. 默认的动态库搜索路径/usr/lib\n\n2. 使⽤size main查看编译出的可执⾏⽂件占据的空间，与使⽤静态链接库相⽐占⽤空间有何变化？哪些部分的哪些代码（也要具体到本task）会导致编译出⽂件的占⽤空间发⽣这种变化？\n\n| text  | data  |  bss  |  dec  | hex | filename |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n|  3089 | 720  | 96 | 3905 | f41  |  main |\n\n> **占用空间变小了**，因为不同于静态链接库将所有的静态库都整合入可执行文件中，动态链接库是在程序开始或正在运行时被链接加载的，所有可执行文件本身的空间占用会大幅缩小。\n\n> main 中调用了 A, B, C 函数，所以其中的函数以及静态全局变量 A_name, B_name 会被被置于动态链接库.so中动态加载\n\n1. 编译动态链接库时-fPIC的作⽤是什么，不加会有什么后果？\n-fPIC 含义是 Generate position-independent code (PIC)，例如在汇编的 jmp 语句中通常使用的是固定的内部地址\n```\n100: COMPARE REG1, REG2\n101: JUMP_IF_EQUAL 111\n...\n111: NOP\n```\n> 而通过 -fPIC 参数 jmp 语句所指向的是相对地址\n使用的是代码段和数据段的OFFSET，从而实现位置无关，可以动态加载到内存中，不同进程可以共享。\n\n```\n100: COMPARE REG1, REG2\n101: JUMP_IF_EQUAL CURRENT+10\n...\n111: NOP\n```\n\n> 如果不加，在某些系统下不会有很大的问题，但一般在 -shared 后面最好加上 -fPIC 来保证动态链接库是位置无关的，不然无法实现动态链接（由于位置相关即分配绝对内存地址，导致多个副本存在于内存中，无法实现动态链接）\n\n**info in gcc manual**\n\n- **-shared:**  Produce a shared object which can then be linked with other objects to forman executable. Not all systems support this option. For predictable results,\nyou must also specify the same set of options used for compilation (‘-fpic’,‘-fPIC’, or model suboptions) when you specify this linker option.*\n\n4. 现在被⼴泛使⽤的公开的动态链接库如何进⾏版本替换或共存（以linux系统为例）？\n\n> 通过动态链接，如果开发者需要维护程序的某一部分（某几个功能的函数），仅需要维护修改所在的动态链接库即可，然后将其发布。用户只需要替换动态链接库，在程序运行的时候自然会动态链接到新的链接库，**在接口保持不变**的情况下完成很自然流畅的版本更新。\n\n---\n\n### Task4 - ld手动链接\n\n- **解题过程**\n这题要求我们用ld链接器，进行手动链接，我们先试一下直接链接会发生什么\n\n```makefile\n#链接代码\nld -o main main.o some.o\n```\n\n```cpp\n//报错信息\nld: warning: cannot find entry symbol _start; defaulting to 00000000004000b0\nsome.o: In function `notATest()':\nsome.cpp:(.text+0xc): undefined reference to `puts'\nsome.o: In function `testPrint()':\nsome.cpp:(.text+0x1f): undefined reference to `puts'\nsome.o: In function `testPrint(int)':\nsome.cpp:(.text+0x52): undefined reference to `printf'\nMakefile:2: recipe for target 'main' failed\nmake: *** [main] Error 1\n```\n\n> 发现主要报错信息是 undefined reference to 'puts', 'printf', 说明标准库中的函数符号没有被成功匹配，我们需要把 stdc 加进去\n\n```makefile\n# 链接代码\nld -o main main.o some.o -lc\n# 通过 -lc 命令直接添加标准库，也可以自行指定libc.so路径\n```\n\n> 可以发现main被成功编译出来，但运行时候发现bash报目录中无此文件\n```bash\nbash: ./main: No such file or directory\n```\n\n> 也就是我们并不能运行这个可执行文件，查找资料之后我们尝试指定使用的动态链接器再进行编译，就可以运行了\n\n```makefile\nld -dynamic-linker /lib64/ld-linux-x86-64.so.2 -o main main.o some.o -lc\n```\n\n> 我查询了ld的手册试图查找原因，但并未发现为什么必须要使用--dynamic-linker指令\n\n<div style=\"page-break-after: always;\"></div>\n\n\n- **--dynamic-linker=file**\n>    Set the name of the dynamic linker.  This is only meaningful when generating dynamically linked ELF executables.  **The default dynamic linker is normally correct; don't use this unless you know what you are doing.**\n\n\n\n> 接下去，我们的程序虽然能够运行起来了，但在 main 函数跑完之后会出现 *Segmentation fault (core dumped)* 提示，这也提示了我们对于 main 函数的初始化和结束可能并未正常执行。\n\n- **GDB查看正常程序**\n\n![](https://s3.ax1x.com/2020/11/15/DFeZOP.png)\n\n> 通过 gdb 查看正常程序我们发现，正常的 main 函数执行栈中需要有两个函数为其保证环境 *__lib_csu_init* 和 *__libc_start_main*\n\n- **__libc_start_main**\n我们需要知道，在linux中，main函数的初始化环境和参数传递以及返回值处理工作是由 __libc_start_main 来保证的。一个正常的程序执行需要包含以下要素。\n\n1. performing any necessary security checks if the effective user ID is not the same as the real user ID.\n2. initialize the threading subsystem.\n3. registering the *rtld_fini* to release resources when this dynamic shared object exits (or is unloaded).\n4. registering the *fini* handler to run at program exit.\n5. calling the initializer function *(*init)()*.\n6. calling *main()* with appropriate arguments.\n7. calling *exit()* with the return value from *main()*.\n\n> 具体的初始化和结束调用路径异常复杂，在此不多赘述，放一张图有待进一步研究。\n\n![](https://s3.ax1x.com/2020/11/15/DFemef.png)\n\n*图片来源: https://luomuxiaoxiao.com/?p=516*\n\n---\n\n然后介绍完了主函数的初始化和返回，我们需要知道保证上述的两个函数在哪个动态链接库中，这就涉及到了 *crt1.o, crti.o, crtbegin.o, crtend.o, crtn.o* 这几个库\n*参考： https://blog.csdn.net/farmwang/article/details/73195951*\n\n> **crt是c runtime 的缩写**,用于执行进入main之前的初始化和退出main之后的扫尾工作。\n\n| 目标文件 | crt1.o| crti.o| crtbegin.o| crtend.o | crtn.o |\n| :---: | :---: | :---: | :---: | :---: | :---: |\n| 作用 | 启动|初始化|构造|析构|结束 |\n\n> 在标准的linux平台下,link的顺序是\n\n\tld crt1.o crti.o [user_objects] [system_libraries] crtn.o\n\n所以我们按照顺序进行链接有如下命令\n\n```makefile\n# 链接指令\nld -dynamic-linker /lib64/ld-linux-x86-64.so.2 -o main /usr/lib/x86_64-linux-gnu/crt1.o main.o some.o -lc /usr/lib/x86_64-linux-gnu/crti.o /usr/lib/x86_64-linux-gnu/crtn.o\n```\n\n> 成功的手动完成了程序的链接工作。\n\n以上艰苦的工作告诉我们，不要轻易尝试手动链接，除非你知道你在干什么。平时好好用 gcc。\n\n- 动态链接器⼀个操作系统中只需要⼀个吗？为什么？\n> 一般来说只要有一个支持的动态链接器即可，完成程序的动态链接工作。 但linux中可能有两个 ld 的版本\n1. ld.so针对a.out格式的二进制可执行文件\n2. ld-linux.so针对ELF格式的二进制可执行文件\n\na.out是旧版类Unix系统中用于执行档、目的码和后来系统中的函数库的一种文件格式，该版本的链接器仍被保留用以向前支持。\n\n---\n\n### Task5 - 运行时打桩\n\nTask5 是一个典型的运行时打桩的 task，给了我们编译好的login程序，让我们改变其行为，让它能够输出 login_success.\n\n> 阅读源码，我们可以发现，login将我们输入的字符串做了hash，与已有某不明hash值，进行比较，如果相等则登陆成功。根据本 lab 的内容主要是讲 make 和链接的，让我们碰撞这个hash显然不是本意。那另一种方法就是通过运行时打桩，改变标准库的链接方式，让strcmp 链接到我们自己写的 strcmp 版本上去，从而我们可以控制其返回值让其返回0使得登陆成功。\n\n*首先要注意 strcmp 并非只有判断密码时的一次唯一调用，在别处还有调用，所以我们要保证 strcmp 函数的基本功能正确*\n```cpp\n// mystrcmp.c\n#define _GNU_SOURCE\n#include <stdio.h>\n#include <dlfcn.h>\n\nint strcmp(const char *lhs, const char *rhs)\n{\n    int(*strcmpp)(const char *lhs, const char *rhs);\n    strcmpp = dlsym(RTLD_NEXT, \"strcmp\");\n\n    char tmp[] = \"3983709877683599140\";\n    if(strcmpp(tmp, rhs) == 0)\n        return 0;\n    return strcmpp(lhs, rhs);\n}\n```\n\n> 我们直接写一个自己的 strcmp 版本，用 dlsym 可以获取在运行时 strcmp 函数的指针 *（不这样做也可以，可以直接自己重写一遍strcmp程序）*，相当于可以直接使用 **真实的标准库中的 strcmp**，然后我们稍微改写一下，让它和我们的hash值比较的时候直接返回0，能够让我们不管输入什么密码都能够 login_success。\n\n接下来我们先将我们写的strcmp编译成动态链接库\n\n```shell\ngcc -shared -fpic -o mystrcmp.so mystrcmp.c -ldl\n```\n\n> 然后使用 **LD_PRELOAD=\"./mystrcmp.so\"** 指令，从而在 strcmp 动态链接到标准库之前让其优先匹配我们写的动态链接库中的 strcmp 符号。\n\n这里需要注意由于是要直接运行 ./login, 所以我们需要把LD_PRELOAD的效果全局化，也既在前面加上 export 标记。\n\n```shell\nexport LD_PRELOAD=\"./mystrcmp.so\"\n```\n\n最后注意不要忘记卸载全局 preload， 不然之后所有程序都 preload 这个strcmp。\n\n```shell\nexport LD_PRELOAD=NULL\n```","slug":"ICS/ICS_Lab3","published":1,"updated":"2020-12-09T01:23:18.411Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty3u000os8pda6xe1npm","content":"<h3 id=\"Task0-简单链接\"><a href=\"#Task0-简单链接\" class=\"headerlink\" title=\"Task0 - 简单链接\"></a>Task0 - 简单链接</h3><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&quot;some.h&quot;</span></span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;\n    testPrint();\n    testPrint(<span class=\"hljs-number\">5</span>);\n    notATest();\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n&#125;</code></pre>\n<ul>\n<li><strong>错误分析</strong></li>\n</ul>\n<blockquote>\n<p>我们可以看到main函数中调用了三个函数，全是外部的，在链接时，符号表会进行搜索匹配。我们再来看some.h中定义了哪些函数.</p>\n</blockquote>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;cstdio&gt;</span></span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">testPrint</span><span class=\"hljs-params\">()</span></span>;\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">testPrint</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> num)</span></span>;</code></pre>\n<blockquote>\n<p>发现只有两个test函数,而没有notATest定义的函数，根据这个离谱的名字我们可以断定在cstdio中也没有同名函数。<br>所以最后符号表中没有匹配上，会引发链接错误。</p>\n</blockquote>\n<ul>\n<li><strong>解决方法</strong></li>\n</ul>\n<blockquote>\n<p>直接将 notATest() 注释掉, 再在 makefile 中使用<br><pre><code class=\"hljs css\"><span class=\"hljs-selector-tag\">g</span>++ <span class=\"hljs-selector-tag\">main</span><span class=\"hljs-selector-class\">.cpp</span> <span class=\"hljs-selector-tag\">some</span><span class=\"hljs-selector-class\">.cpp</span> <span class=\"hljs-selector-tag\">-o</span> <span class=\"hljs-selector-tag\">main</span></code></pre></p>\n</blockquote>\n<hr>\n<h3 id=\"Task1-链接与重复包含问题\"><a href=\"#Task1-链接与重复包含问题\" class=\"headerlink\" title=\"Task1 - 链接与重复包含问题\"></a>Task1 - 链接与重复包含问题</h3><ul>\n<li><strong>解题过程</strong></li>\n</ul>\n<p>通过阅读代码，我们可以发现改题的代码会根据宏DEBUG是否被定义而有不同的行为，决定是否打印更加详细的内容</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&quot;function0.h&quot;</span></span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">func0</span><span class=\"hljs-params\">()</span></span>&#123;\n    <span class=\"hljs-meta\"># <span class=\"hljs-meta-keyword\">ifdef</span> DEBUG</span>\n    printDebug(); <span class=\"hljs-comment\">//打印debug信息 (详细操作在shared.cpp中)</span>\n    <span class=\"hljs-meta\"># <span class=\"hljs-meta-keyword\">else</span></span>\n    print(); <span class=\"hljs-comment\">//打印正常信息</span>\n    <span class=\"hljs-meta\"># <span class=\"hljs-meta-keyword\">endif</span></span>\n&#125;</code></pre>\n<blockquote>\n<p>根据题意，我们需要在 Makefile 中,对于要求的 main1 需要做一个相等的条件判断</p>\n</blockquote>\n<pre><code class=\"hljs makefile\"><span class=\"hljs-section\">main0:</span>\n    g++ main0.cpp function0.cpp function1.cpp shared.cpp -o main0\ndebug = False\n<span class=\"hljs-section\">main1:</span>\n<span class=\"hljs-keyword\">ifeq</span> (<span class=\"hljs-variable\">$(debug)</span>,True) \n\tg++ main1.cpp -DDEBUG function0.cpp function1.cpp shared.cpp -o main1\n<span class=\"hljs-keyword\">else</span>\n\tg++ main1.cpp function0.cpp function1.cpp shared.cpp -o main1\n<span class=\"hljs-keyword\">endif</span></code></pre>\n<p><em>值得注意的是，makefile中 if 语句前不能有 tab 或者空格</em></p>\n<p><strong>Include 路径</strong><br><img src=\"https://s3.ax1x.com/2020/11/15/DFeVyt.png\" alt></p>\n<ul>\n<li><strong>问题</strong></li>\n</ul>\n<ol>\n<li>为什么两个function.h都引⽤了shared.h⽽没有出问题？本来有可能出什么问题。</li>\n</ol>\n<blockquote>\n<p>因为 shared.h 中仅包含函数声明，而不包含函数的定义，因而不会有重定义问题。如果 #include shared.cpp 则会出现重定义问题。</p>\n</blockquote>\n<ol>\n<li>如果把shared.h中注释掉的变量定义取消注释会出什么问题？为什么？</li>\n</ol>\n<blockquote>\n<p>会出现变量重定义问题，由于全局变量 string 被两次 include 到func0 和 func1 中，最后被同时引用至 main 中，导致重定义。在符号表中产生冲突，报错。</p>\n</blockquote>\n<ol>\n<li>通常使⽤shared.h中另外被注释掉的宏命令(#开头的那些⾏)来规避重复引⽤的⻛险，原理是什么？取消这些注释之后上⼀题的问题解除了吗？背后的原因是什么？</li>\n</ol>\n<blockquote>\n<p>通过宏定义，在第一次 include 的时候定义宏为函数名，之后再次include 的时候由于已经 define 就不再次 include。这种方式的缺点是如果有已有宏名与函数名重复时，将会报错。使用 #pragama once 则是由c++编译器保证 include 一次，不会有宏名重复问题。</p>\n<p>上题的问题并没有解决，因为FOO是全局变量，其赋了初值，被链接器标记为strong，被重复 include 到了 main 中，两个 strong 标记冲突报错。</p>\n</blockquote>\n<hr>\n<h3 id=\"Task2-静态链接库\"><a href=\"#Task2-静态链接库\" class=\"headerlink\" title=\"Task2 - 静态链接库\"></a>Task2 - 静态链接库</h3><p>在这个 Task 中我们需要编译2个静态链接库，并链接3个静态链接库，完成编译。</p>\n<p><strong>A Makefile</strong><br><pre><code class=\"hljs makefile\"><span class=\"hljs-section\">libA:\t</span>\n\tg++ -c A.cpp \n\tar -r libA.a A.o</code></pre></p>\n<blockquote>\n<p>先用g++ -c编译出A.o可重定位目标文件，再通过 ar 命令编译静态链接库。（libC 同理）</p>\n</blockquote>\n<p><strong>Main Makefile</strong><br><pre><code class=\"hljs makefile\">main : \n\tcd A &amp;&amp; make libA\n\tcd C &amp;&amp; make libC\n\tg++ main.cpp B/libB.a A/libA.a C/libC.a -o main</code></pre></p>\n<blockquote>\n<p>再 CD 入每个目录进行 make 编译， 最后把静态链接库进行链接。 </p>\n</blockquote>\n<ul>\n<li><strong>静态库链接搜索路径顺序：</strong></li>\n</ul>\n<ol>\n<li>ld会去找GCC命令中的参数-L</li>\n<li>再找gcc的环境变量LIBRARY_PATH</li>\n<li>再找内定目录 /lib /usr/lib /usr/local/lib </li>\n</ol>\n<ul>\n<li><strong>问题</strong></li>\n</ul>\n<ol>\n<li><p>若有多个静态链接库需要链接，写命令时需要考虑静态链接库和源⽂件在命令中的顺序吗？是否需要考虑是由什么决定的？</p>\n<blockquote>\n<p><strong>需要考虑</strong>，链接器在链接过程中按命令中输入的顺序进行符号表匹配，可以将这个匹配过程抽象的看作链接器在维护三个集合 E(待合并文件), U(被引用且尚未匹配), D（已匹配），根据顺序动态更新E, 和U,D, 最后如果 U 为空则正常整合 E 生成可执行文件，不然则报错有符号被引用了但未能匹配。所以如果我们的静态库都是相互独立的，那么顺序是没关系的。但如果互相依赖，那么我们必须保证在对某个符号的引用的库后，必然有一个库中存在对其的定义，不然则会报错。</p>\n</blockquote>\n</li>\n<li><p>可以使⽤size main命令来查看可执⾏⽂件所占的空间，输出结果的每⼀项是什么意思？</p>\n</li>\n</ol>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">text</th>\n<th style=\"text-align:center\">data</th>\n<th style=\"text-align:center\">bss</th>\n<th style=\"text-align:center\">dec</th>\n<th style=\"text-align:center\">hex</th>\n<th style=\"text-align:center\">filename</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">22721</td>\n<td style=\"text-align:center\">712</td>\n<td style=\"text-align:center\">288</td>\n<td style=\"text-align:center\">23721</td>\n<td style=\"text-align:center\">5ca9</td>\n<td style=\"text-align:center\">main</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><strong>text:</strong> 机器代码字节</li>\n<li><strong>data:</strong> 包含静态变量和已经初始化的全局变量的数据段字节数大小</li>\n<li><strong>bss:</strong> Block Started by Symbol (better save space) 存放程序中未初始化的全局变量的字节数大小，BBS段属于静态内存分配, 不占真实内存空间（仅占位符）</li>\n<li><strong>dec:</strong> = test + data + bss</li>\n<li><strong>hex:</strong> 16进制的dec</li>\n<li><strong>filename:</strong> 顾名思义，文件名</li>\n</ul>\n<hr>\n<h3 id=\"Task3-动态链接库\"><a href=\"#Task3-动态链接库\" class=\"headerlink\" title=\"Task3 - 动态链接库\"></a>Task3 - 动态链接库</h3><p>整体操作和上一个Task很像，只是链接的是动态链接库 .so</p>\n<p><strong>A Makefile</strong><br><pre><code class=\"hljs makefile\"><span class=\"hljs-section\">libA:</span>\n\tg++ -fPIC -c A.cpp\n\tg++ -shared -fPIC A.o -o libA.so</code></pre></p>\n<blockquote>\n<p>在 A 中先编译出 A.o 再用 -shared 编译出动态链接库 .so</p>\n</blockquote>\n<p><strong>Main Makefile</strong><br><pre><code class=\"hljs makefile\">main : \n\tcd A &amp;&amp; make libA\n\tcd C &amp;&amp; make libC\n\tg++ main.cpp A/libA.so ./libB.so C/libC.so -o main</code></pre></p>\n<blockquote>\n<p>直接 cd 进去 make 出动态链接库后，再进行链接。</p>\n</blockquote>\n<ul>\n<li><strong>问题</strong></li>\n</ul>\n<ol>\n<li><p>动态链接库在运⾏时也需要查找库的位置，在Linux中，运⾏时动态链接库的查找顺序是怎样的？</p>\n<blockquote>\n<p><strong>动态链接时、执行时搜索路径顺序:</strong></p>\n<ol>\n<li>编译目标代码时指定的动态库搜索路径</li>\n<li>环境变量LD_LIBRARY_PATH指定的动态库搜索路径</li>\n<li>配置文件/etc/ld.so.conf中指定的动态库搜索路径</li>\n<li>默认的动态库搜索路径/lib</li>\n<li>默认的动态库搜索路径/usr/lib</li>\n</ol>\n</blockquote>\n</li>\n<li><p>使⽤size main查看编译出的可执⾏⽂件占据的空间，与使⽤静态链接库相⽐占⽤空间有何变化？哪些部分的哪些代码（也要具体到本task）会导致编译出⽂件的占⽤空间发⽣这种变化？</p>\n</li>\n</ol>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">text</th>\n<th style=\"text-align:center\">data</th>\n<th style=\"text-align:center\">bss</th>\n<th style=\"text-align:center\">dec</th>\n<th style=\"text-align:center\">hex</th>\n<th style=\"text-align:center\">filename</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">3089</td>\n<td style=\"text-align:center\">720</td>\n<td style=\"text-align:center\">96</td>\n<td style=\"text-align:center\">3905</td>\n<td style=\"text-align:center\">f41</td>\n<td style=\"text-align:center\">main</td>\n</tr>\n</tbody>\n</table>\n</div>\n<blockquote>\n<p><strong>占用空间变小了</strong>，因为不同于静态链接库将所有的静态库都整合入可执行文件中，动态链接库是在程序开始或正在运行时被链接加载的，所有可执行文件本身的空间占用会大幅缩小。</p>\n<p>main 中调用了 A, B, C 函数，所以其中的函数以及静态全局变量 A_name, B_name 会被被置于动态链接库.so中动态加载</p>\n</blockquote>\n<ol>\n<li>编译动态链接库时-fPIC的作⽤是什么，不加会有什么后果？<br>-fPIC 含义是 Generate position-independent code (PIC)，例如在汇编的 jmp 语句中通常使用的是固定的内部地址<pre><code class=\"hljs angelscript\"><span class=\"hljs-number\">100</span>: COMPARE REG1, REG2\n<span class=\"hljs-number\">101</span>: JUMP_IF_EQUAL <span class=\"hljs-number\">111</span>\n...\n<span class=\"hljs-number\">111</span>: NOP</code></pre>\n<blockquote>\n<p>而通过 -fPIC 参数 jmp 语句所指向的是相对地址<br>使用的是代码段和数据段的OFFSET，从而实现位置无关，可以动态加载到内存中，不同进程可以共享。</p>\n</blockquote>\n</li>\n</ol>\n<pre><code class=\"hljs angelscript\"><span class=\"hljs-number\">100</span>: COMPARE REG1, REG2\n<span class=\"hljs-number\">101</span>: JUMP_IF_EQUAL CURRENT+<span class=\"hljs-number\">10</span>\n...\n<span class=\"hljs-number\">111</span>: NOP</code></pre>\n<blockquote>\n<p>如果不加，在某些系统下不会有很大的问题，但一般在 -shared 后面最好加上 -fPIC 来保证动态链接库是位置无关的，不然无法实现动态链接（由于位置相关即分配绝对内存地址，导致多个副本存在于内存中，无法实现动态链接）</p>\n</blockquote>\n<p><strong>info in gcc manual</strong></p>\n<ul>\n<li><strong>-shared:</strong>  Produce a shared object which can then be linked with other objects to forman executable. Not all systems support this option. For predictable results,<br>you must also specify the same set of options used for compilation (‘-fpic’,‘-fPIC’, or model suboptions) when you specify this linker option.*</li>\n</ul>\n<ol>\n<li>现在被⼴泛使⽤的公开的动态链接库如何进⾏版本替换或共存（以linux系统为例）？</li>\n</ol>\n<blockquote>\n<p>通过动态链接，如果开发者需要维护程序的某一部分（某几个功能的函数），仅需要维护修改所在的动态链接库即可，然后将其发布。用户只需要替换动态链接库，在程序运行的时候自然会动态链接到新的链接库，<strong>在接口保持不变</strong>的情况下完成很自然流畅的版本更新。</p>\n</blockquote>\n<hr>\n<h3 id=\"Task4-ld手动链接\"><a href=\"#Task4-ld手动链接\" class=\"headerlink\" title=\"Task4 - ld手动链接\"></a>Task4 - ld手动链接</h3><ul>\n<li><strong>解题过程</strong><br>这题要求我们用ld链接器，进行手动链接，我们先试一下直接链接会发生什么</li>\n</ul>\n<pre><code class=\"hljs makefile\"><span class=\"hljs-comment\">#链接代码</span>\nld -o main main.o some.o</code></pre>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">//报错信息</span>\nld: warning: cannot find entry symbol _start; defaulting to <span class=\"hljs-number\">00000000004000b</span>0\nsome.o: In function `notATest()<span class=\"hljs-string\">&#x27;:</span>\nsome.cpp:(.text+0xc): undefined reference to `puts&#x27;\nsome.o: In function `testPrint()<span class=\"hljs-string\">&#x27;:</span>\nsome.cpp:(.text+0x1f): undefined reference to `puts&#x27;\nsome.o: In function `testPrint(<span class=\"hljs-keyword\">int</span>)<span class=\"hljs-string\">&#x27;:</span>\nsome.cpp:(.text+0x52): undefined reference to `printf&#x27;\nMakefile:2: recipe for target &#x27;main&#x27; failed\nmake: *** [main] Error <span class=\"hljs-number\">1</span></code></pre>\n<blockquote>\n<p>发现主要报错信息是 undefined reference to ‘puts’, ‘printf’, 说明标准库中的函数符号没有被成功匹配，我们需要把 stdc 加进去</p>\n</blockquote>\n<pre><code class=\"hljs makefile\"><span class=\"hljs-comment\"># 链接代码</span>\nld -o main main.o some.o -lc\n<span class=\"hljs-comment\"># 通过 -lc 命令直接添加标准库，也可以自行指定libc.so路径</span></code></pre>\n<blockquote>\n<p>可以发现main被成功编译出来，但运行时候发现bash报目录中无此文件<br><pre><code class=\"hljs bash\">bash: ./main: No such file or directory</code></pre></p>\n<p>也就是我们并不能运行这个可执行文件，查找资料之后我们尝试指定使用的动态链接器再进行编译，就可以运行了</p>\n</blockquote>\n<pre><code class=\"hljs makefile\">ld -dynamic-linker /lib64/ld-linux-x86-64.so.2 -o main main.o some.o -lc</code></pre>\n<blockquote>\n<p>我查询了ld的手册试图查找原因，但并未发现为什么必须要使用—dynamic-linker指令</p>\n</blockquote>\n<div style=\"page-break-after: always;\"></div>\n\n\n<ul>\n<li><strong>—dynamic-linker=file</strong><blockquote>\n<p>   Set the name of the dynamic linker.  This is only meaningful when generating dynamically linked ELF executables.  <strong>The default dynamic linker is normally correct; don’t use this unless you know what you are doing.</strong></p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>接下去，我们的程序虽然能够运行起来了，但在 main 函数跑完之后会出现 <em>Segmentation fault (core dumped)</em> 提示，这也提示了我们对于 main 函数的初始化和结束可能并未正常执行。</p>\n</blockquote>\n<ul>\n<li><strong>GDB查看正常程序</strong></li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/15/DFeZOP.png\" alt></p>\n<blockquote>\n<p>通过 gdb 查看正常程序我们发现，正常的 main 函数执行栈中需要有两个函数为其保证环境 <em>__lib_csu_init</em> 和 <em>__libc_start_main</em></p>\n</blockquote>\n<ul>\n<li><strong>__libc_start_main</strong><br>我们需要知道，在linux中，main函数的初始化环境和参数传递以及返回值处理工作是由 __libc_start_main 来保证的。一个正常的程序执行需要包含以下要素。</li>\n</ul>\n<ol>\n<li>performing any necessary security checks if the effective user ID is not the same as the real user ID.</li>\n<li>initialize the threading subsystem.</li>\n<li>registering the <em>rtld_fini</em> to release resources when this dynamic shared object exits (or is unloaded).</li>\n<li>registering the <em>fini</em> handler to run at program exit.</li>\n<li>calling the initializer function <em>(</em>init)()*.</li>\n<li>calling <em>main()</em> with appropriate arguments.</li>\n<li>calling <em>exit()</em> with the return value from <em>main()</em>.</li>\n</ol>\n<blockquote>\n<p>具体的初始化和结束调用路径异常复杂，在此不多赘述，放一张图有待进一步研究。</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/15/DFemef.png\" alt></p>\n<p><em>图片来源: <a href=\"https://luomuxiaoxiao.com/?p=516\">https://luomuxiaoxiao.com/?p=516</a></em></p>\n<hr>\n<p>然后介绍完了主函数的初始化和返回，我们需要知道保证上述的两个函数在哪个动态链接库中，这就涉及到了 <em>crt1.o, crti.o, crtbegin.o, crtend.o, crtn.o</em> 这几个库<br><em>参考： <a href=\"https://blog.csdn.net/farmwang/article/details/73195951\">https://blog.csdn.net/farmwang/article/details/73195951</a></em></p>\n<blockquote>\n<p><strong>crt是c runtime 的缩写</strong>,用于执行进入main之前的初始化和退出main之后的扫尾工作。</p>\n</blockquote>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">目标文件</th>\n<th style=\"text-align:center\">crt1.o</th>\n<th style=\"text-align:center\">crti.o</th>\n<th style=\"text-align:center\">crtbegin.o</th>\n<th style=\"text-align:center\">crtend.o</th>\n<th style=\"text-align:center\">crtn.o</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">作用</td>\n<td style=\"text-align:center\">启动</td>\n<td style=\"text-align:center\">初始化</td>\n<td style=\"text-align:center\">构造</td>\n<td style=\"text-align:center\">析构</td>\n<td style=\"text-align:center\">结束</td>\n</tr>\n</tbody>\n</table>\n</div>\n<blockquote>\n<p>在标准的linux平台下,link的顺序是</p>\n</blockquote>\n<pre><code>ld crt1.o crti.o [user_objects] [system_libraries] crtn.o\n</code></pre><p>所以我们按照顺序进行链接有如下命令</p>\n<pre><code class=\"hljs makefile\"><span class=\"hljs-comment\"># 链接指令</span>\nld -dynamic-linker /lib64/ld-linux-x86-64.so.2 -o main /usr/lib/x86_64-linux-gnu/crt1.o main.o some.o -lc /usr/lib/x86_64-linux-gnu/crti.o /usr/lib/x86_64-linux-gnu/crtn.o</code></pre>\n<blockquote>\n<p>成功的手动完成了程序的链接工作。</p>\n</blockquote>\n<p>以上艰苦的工作告诉我们，不要轻易尝试手动链接，除非你知道你在干什么。平时好好用 gcc。</p>\n<ul>\n<li>动态链接器⼀个操作系统中只需要⼀个吗？为什么？<blockquote>\n<p>一般来说只要有一个支持的动态链接器即可，完成程序的动态链接工作。 但linux中可能有两个 ld 的版本</p>\n</blockquote>\n</li>\n</ul>\n<ol>\n<li>ld.so针对a.out格式的二进制可执行文件</li>\n<li>ld-linux.so针对ELF格式的二进制可执行文件</li>\n</ol>\n<p>a.out是旧版类Unix系统中用于执行档、目的码和后来系统中的函数库的一种文件格式，该版本的链接器仍被保留用以向前支持。</p>\n<hr>\n<h3 id=\"Task5-运行时打桩\"><a href=\"#Task5-运行时打桩\" class=\"headerlink\" title=\"Task5 - 运行时打桩\"></a>Task5 - 运行时打桩</h3><p>Task5 是一个典型的运行时打桩的 task，给了我们编译好的login程序，让我们改变其行为，让它能够输出 login_success.</p>\n<blockquote>\n<p>阅读源码，我们可以发现，login将我们输入的字符串做了hash，与已有某不明hash值，进行比较，如果相等则登陆成功。根据本 lab 的内容主要是讲 make 和链接的，让我们碰撞这个hash显然不是本意。那另一种方法就是通过运行时打桩，改变标准库的链接方式，让strcmp 链接到我们自己写的 strcmp 版本上去，从而我们可以控制其返回值让其返回0使得登陆成功。</p>\n</blockquote>\n<p><em>首先要注意 strcmp 并非只有判断密码时的一次唯一调用，在别处还有调用，所以我们要保证 strcmp 函数的基本功能正确</em><br><pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// mystrcmp.c</span>\n<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">define</span> _GNU_SOURCE</span>\n<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span>\n<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;dlfcn.h&gt;</span></span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">strcmp</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">char</span> *lhs, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">char</span> *rhs)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span>(*strcmpp)(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">char</span> *lhs, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">char</span> *rhs);\n    strcmpp = dlsym(RTLD_NEXT, <span class=\"hljs-string\">&quot;strcmp&quot;</span>);\n\n    <span class=\"hljs-keyword\">char</span> tmp[] = <span class=\"hljs-string\">&quot;3983709877683599140&quot;</span>;\n    <span class=\"hljs-keyword\">if</span>(strcmpp(tmp, rhs) == <span class=\"hljs-number\">0</span>)\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">return</span> strcmpp(lhs, rhs);\n&#125;</code></pre></p>\n<blockquote>\n<p>我们直接写一个自己的 strcmp 版本，用 dlsym 可以获取在运行时 strcmp 函数的指针 <em>（不这样做也可以，可以直接自己重写一遍strcmp程序）</em>，相当于可以直接使用 <strong>真实的标准库中的 strcmp</strong>，然后我们稍微改写一下，让它和我们的hash值比较的时候直接返回0，能够让我们不管输入什么密码都能够 login_success。</p>\n</blockquote>\n<p>接下来我们先将我们写的strcmp编译成动态链接库</p>\n<pre><code class=\"hljs shell\">gcc -shared -fpic -o mystrcmp.so mystrcmp.c -ldl</code></pre>\n<blockquote>\n<p>然后使用 <strong>LD_PRELOAD=”./mystrcmp.so”</strong> 指令，从而在 strcmp 动态链接到标准库之前让其优先匹配我们写的动态链接库中的 strcmp 符号。</p>\n</blockquote>\n<p>这里需要注意由于是要直接运行 ./login, 所以我们需要把LD_PRELOAD的效果全局化，也既在前面加上 export 标记。</p>\n<pre><code class=\"hljs shell\">export LD_PRELOAD=&quot;./mystrcmp.so&quot;</code></pre>\n<p>最后注意不要忘记卸载全局 preload， 不然之后所有程序都 preload 这个strcmp。</p>\n<pre><code class=\"hljs shell\">export LD_PRELOAD=NULL</code></pre>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Task0-简单链接\"><a href=\"#Task0-简单链接\" class=\"headerlink\" title=\"Task0 - 简单链接\"></a>Task0 - 简单链接</h3><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&quot;some.h&quot;</span></span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span>&#123;\n    testPrint();\n    testPrint(<span class=\"hljs-number\">5</span>);\n    notATest();\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n&#125;</code></pre>\n<ul>\n<li><strong>错误分析</strong></li>\n</ul>\n<blockquote>\n<p>我们可以看到main函数中调用了三个函数，全是外部的，在链接时，符号表会进行搜索匹配。我们再来看some.h中定义了哪些函数.</p>\n</blockquote>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;cstdio&gt;</span></span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">testPrint</span><span class=\"hljs-params\">()</span></span>;\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">testPrint</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> num)</span></span>;</code></pre>\n<blockquote>\n<p>发现只有两个test函数,而没有notATest定义的函数，根据这个离谱的名字我们可以断定在cstdio中也没有同名函数。<br>所以最后符号表中没有匹配上，会引发链接错误。</p>\n</blockquote>\n<ul>\n<li><strong>解决方法</strong></li>\n</ul>\n<blockquote>\n<p>直接将 notATest() 注释掉, 再在 makefile 中使用<br><pre><code class=\"hljs css\"><span class=\"hljs-selector-tag\">g</span>++ <span class=\"hljs-selector-tag\">main</span><span class=\"hljs-selector-class\">.cpp</span> <span class=\"hljs-selector-tag\">some</span><span class=\"hljs-selector-class\">.cpp</span> <span class=\"hljs-selector-tag\">-o</span> <span class=\"hljs-selector-tag\">main</span></code></pre></p>\n</blockquote>\n<hr>\n<h3 id=\"Task1-链接与重复包含问题\"><a href=\"#Task1-链接与重复包含问题\" class=\"headerlink\" title=\"Task1 - 链接与重复包含问题\"></a>Task1 - 链接与重复包含问题</h3><ul>\n<li><strong>解题过程</strong></li>\n</ul>\n<p>通过阅读代码，我们可以发现改题的代码会根据宏DEBUG是否被定义而有不同的行为，决定是否打印更加详细的内容</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&quot;function0.h&quot;</span></span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">func0</span><span class=\"hljs-params\">()</span></span>&#123;\n    <span class=\"hljs-meta\"># <span class=\"hljs-meta-keyword\">ifdef</span> DEBUG</span>\n    printDebug(); <span class=\"hljs-comment\">//打印debug信息 (详细操作在shared.cpp中)</span>\n    <span class=\"hljs-meta\"># <span class=\"hljs-meta-keyword\">else</span></span>\n    print(); <span class=\"hljs-comment\">//打印正常信息</span>\n    <span class=\"hljs-meta\"># <span class=\"hljs-meta-keyword\">endif</span></span>\n&#125;</code></pre>\n<blockquote>\n<p>根据题意，我们需要在 Makefile 中,对于要求的 main1 需要做一个相等的条件判断</p>\n</blockquote>\n<pre><code class=\"hljs makefile\"><span class=\"hljs-section\">main0:</span>\n    g++ main0.cpp function0.cpp function1.cpp shared.cpp -o main0\ndebug = False\n<span class=\"hljs-section\">main1:</span>\n<span class=\"hljs-keyword\">ifeq</span> (<span class=\"hljs-variable\">$(debug)</span>,True) \n\tg++ main1.cpp -DDEBUG function0.cpp function1.cpp shared.cpp -o main1\n<span class=\"hljs-keyword\">else</span>\n\tg++ main1.cpp function0.cpp function1.cpp shared.cpp -o main1\n<span class=\"hljs-keyword\">endif</span></code></pre>\n<p><em>值得注意的是，makefile中 if 语句前不能有 tab 或者空格</em></p>\n<p><strong>Include 路径</strong><br><img src=\"https://s3.ax1x.com/2020/11/15/DFeVyt.png\" alt></p>\n<ul>\n<li><strong>问题</strong></li>\n</ul>\n<ol>\n<li>为什么两个function.h都引⽤了shared.h⽽没有出问题？本来有可能出什么问题。</li>\n</ol>\n<blockquote>\n<p>因为 shared.h 中仅包含函数声明，而不包含函数的定义，因而不会有重定义问题。如果 #include shared.cpp 则会出现重定义问题。</p>\n</blockquote>\n<ol>\n<li>如果把shared.h中注释掉的变量定义取消注释会出什么问题？为什么？</li>\n</ol>\n<blockquote>\n<p>会出现变量重定义问题，由于全局变量 string 被两次 include 到func0 和 func1 中，最后被同时引用至 main 中，导致重定义。在符号表中产生冲突，报错。</p>\n</blockquote>\n<ol>\n<li>通常使⽤shared.h中另外被注释掉的宏命令(#开头的那些⾏)来规避重复引⽤的⻛险，原理是什么？取消这些注释之后上⼀题的问题解除了吗？背后的原因是什么？</li>\n</ol>\n<blockquote>\n<p>通过宏定义，在第一次 include 的时候定义宏为函数名，之后再次include 的时候由于已经 define 就不再次 include。这种方式的缺点是如果有已有宏名与函数名重复时，将会报错。使用 #pragama once 则是由c++编译器保证 include 一次，不会有宏名重复问题。</p>\n<p>上题的问题并没有解决，因为FOO是全局变量，其赋了初值，被链接器标记为strong，被重复 include 到了 main 中，两个 strong 标记冲突报错。</p>\n</blockquote>\n<hr>\n<h3 id=\"Task2-静态链接库\"><a href=\"#Task2-静态链接库\" class=\"headerlink\" title=\"Task2 - 静态链接库\"></a>Task2 - 静态链接库</h3><p>在这个 Task 中我们需要编译2个静态链接库，并链接3个静态链接库，完成编译。</p>\n<p><strong>A Makefile</strong><br><pre><code class=\"hljs makefile\"><span class=\"hljs-section\">libA:\t</span>\n\tg++ -c A.cpp \n\tar -r libA.a A.o</code></pre></p>\n<blockquote>\n<p>先用g++ -c编译出A.o可重定位目标文件，再通过 ar 命令编译静态链接库。（libC 同理）</p>\n</blockquote>\n<p><strong>Main Makefile</strong><br><pre><code class=\"hljs makefile\">main : \n\tcd A &amp;&amp; make libA\n\tcd C &amp;&amp; make libC\n\tg++ main.cpp B/libB.a A/libA.a C/libC.a -o main</code></pre></p>\n<blockquote>\n<p>再 CD 入每个目录进行 make 编译， 最后把静态链接库进行链接。 </p>\n</blockquote>\n<ul>\n<li><strong>静态库链接搜索路径顺序：</strong></li>\n</ul>\n<ol>\n<li>ld会去找GCC命令中的参数-L</li>\n<li>再找gcc的环境变量LIBRARY_PATH</li>\n<li>再找内定目录 /lib /usr/lib /usr/local/lib </li>\n</ol>\n<ul>\n<li><strong>问题</strong></li>\n</ul>\n<ol>\n<li><p>若有多个静态链接库需要链接，写命令时需要考虑静态链接库和源⽂件在命令中的顺序吗？是否需要考虑是由什么决定的？</p>\n<blockquote>\n<p><strong>需要考虑</strong>，链接器在链接过程中按命令中输入的顺序进行符号表匹配，可以将这个匹配过程抽象的看作链接器在维护三个集合 E(待合并文件), U(被引用且尚未匹配), D（已匹配），根据顺序动态更新E, 和U,D, 最后如果 U 为空则正常整合 E 生成可执行文件，不然则报错有符号被引用了但未能匹配。所以如果我们的静态库都是相互独立的，那么顺序是没关系的。但如果互相依赖，那么我们必须保证在对某个符号的引用的库后，必然有一个库中存在对其的定义，不然则会报错。</p>\n</blockquote>\n</li>\n<li><p>可以使⽤size main命令来查看可执⾏⽂件所占的空间，输出结果的每⼀项是什么意思？</p>\n</li>\n</ol>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">text</th>\n<th style=\"text-align:center\">data</th>\n<th style=\"text-align:center\">bss</th>\n<th style=\"text-align:center\">dec</th>\n<th style=\"text-align:center\">hex</th>\n<th style=\"text-align:center\">filename</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">22721</td>\n<td style=\"text-align:center\">712</td>\n<td style=\"text-align:center\">288</td>\n<td style=\"text-align:center\">23721</td>\n<td style=\"text-align:center\">5ca9</td>\n<td style=\"text-align:center\">main</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><strong>text:</strong> 机器代码字节</li>\n<li><strong>data:</strong> 包含静态变量和已经初始化的全局变量的数据段字节数大小</li>\n<li><strong>bss:</strong> Block Started by Symbol (better save space) 存放程序中未初始化的全局变量的字节数大小，BBS段属于静态内存分配, 不占真实内存空间（仅占位符）</li>\n<li><strong>dec:</strong> = test + data + bss</li>\n<li><strong>hex:</strong> 16进制的dec</li>\n<li><strong>filename:</strong> 顾名思义，文件名</li>\n</ul>\n<hr>\n<h3 id=\"Task3-动态链接库\"><a href=\"#Task3-动态链接库\" class=\"headerlink\" title=\"Task3 - 动态链接库\"></a>Task3 - 动态链接库</h3><p>整体操作和上一个Task很像，只是链接的是动态链接库 .so</p>\n<p><strong>A Makefile</strong><br><pre><code class=\"hljs makefile\"><span class=\"hljs-section\">libA:</span>\n\tg++ -fPIC -c A.cpp\n\tg++ -shared -fPIC A.o -o libA.so</code></pre></p>\n<blockquote>\n<p>在 A 中先编译出 A.o 再用 -shared 编译出动态链接库 .so</p>\n</blockquote>\n<p><strong>Main Makefile</strong><br><pre><code class=\"hljs makefile\">main : \n\tcd A &amp;&amp; make libA\n\tcd C &amp;&amp; make libC\n\tg++ main.cpp A/libA.so ./libB.so C/libC.so -o main</code></pre></p>\n<blockquote>\n<p>直接 cd 进去 make 出动态链接库后，再进行链接。</p>\n</blockquote>\n<ul>\n<li><strong>问题</strong></li>\n</ul>\n<ol>\n<li><p>动态链接库在运⾏时也需要查找库的位置，在Linux中，运⾏时动态链接库的查找顺序是怎样的？</p>\n<blockquote>\n<p><strong>动态链接时、执行时搜索路径顺序:</strong></p>\n<ol>\n<li>编译目标代码时指定的动态库搜索路径</li>\n<li>环境变量LD_LIBRARY_PATH指定的动态库搜索路径</li>\n<li>配置文件/etc/ld.so.conf中指定的动态库搜索路径</li>\n<li>默认的动态库搜索路径/lib</li>\n<li>默认的动态库搜索路径/usr/lib</li>\n</ol>\n</blockquote>\n</li>\n<li><p>使⽤size main查看编译出的可执⾏⽂件占据的空间，与使⽤静态链接库相⽐占⽤空间有何变化？哪些部分的哪些代码（也要具体到本task）会导致编译出⽂件的占⽤空间发⽣这种变化？</p>\n</li>\n</ol>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">text</th>\n<th style=\"text-align:center\">data</th>\n<th style=\"text-align:center\">bss</th>\n<th style=\"text-align:center\">dec</th>\n<th style=\"text-align:center\">hex</th>\n<th style=\"text-align:center\">filename</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">3089</td>\n<td style=\"text-align:center\">720</td>\n<td style=\"text-align:center\">96</td>\n<td style=\"text-align:center\">3905</td>\n<td style=\"text-align:center\">f41</td>\n<td style=\"text-align:center\">main</td>\n</tr>\n</tbody>\n</table>\n</div>\n<blockquote>\n<p><strong>占用空间变小了</strong>，因为不同于静态链接库将所有的静态库都整合入可执行文件中，动态链接库是在程序开始或正在运行时被链接加载的，所有可执行文件本身的空间占用会大幅缩小。</p>\n<p>main 中调用了 A, B, C 函数，所以其中的函数以及静态全局变量 A_name, B_name 会被被置于动态链接库.so中动态加载</p>\n</blockquote>\n<ol>\n<li>编译动态链接库时-fPIC的作⽤是什么，不加会有什么后果？<br>-fPIC 含义是 Generate position-independent code (PIC)，例如在汇编的 jmp 语句中通常使用的是固定的内部地址<pre><code class=\"hljs angelscript\"><span class=\"hljs-number\">100</span>: COMPARE REG1, REG2\n<span class=\"hljs-number\">101</span>: JUMP_IF_EQUAL <span class=\"hljs-number\">111</span>\n...\n<span class=\"hljs-number\">111</span>: NOP</code></pre>\n<blockquote>\n<p>而通过 -fPIC 参数 jmp 语句所指向的是相对地址<br>使用的是代码段和数据段的OFFSET，从而实现位置无关，可以动态加载到内存中，不同进程可以共享。</p>\n</blockquote>\n</li>\n</ol>\n<pre><code class=\"hljs angelscript\"><span class=\"hljs-number\">100</span>: COMPARE REG1, REG2\n<span class=\"hljs-number\">101</span>: JUMP_IF_EQUAL CURRENT+<span class=\"hljs-number\">10</span>\n...\n<span class=\"hljs-number\">111</span>: NOP</code></pre>\n<blockquote>\n<p>如果不加，在某些系统下不会有很大的问题，但一般在 -shared 后面最好加上 -fPIC 来保证动态链接库是位置无关的，不然无法实现动态链接（由于位置相关即分配绝对内存地址，导致多个副本存在于内存中，无法实现动态链接）</p>\n</blockquote>\n<p><strong>info in gcc manual</strong></p>\n<ul>\n<li><strong>-shared:</strong>  Produce a shared object which can then be linked with other objects to forman executable. Not all systems support this option. For predictable results,<br>you must also specify the same set of options used for compilation (‘-fpic’,‘-fPIC’, or model suboptions) when you specify this linker option.*</li>\n</ul>\n<ol>\n<li>现在被⼴泛使⽤的公开的动态链接库如何进⾏版本替换或共存（以linux系统为例）？</li>\n</ol>\n<blockquote>\n<p>通过动态链接，如果开发者需要维护程序的某一部分（某几个功能的函数），仅需要维护修改所在的动态链接库即可，然后将其发布。用户只需要替换动态链接库，在程序运行的时候自然会动态链接到新的链接库，<strong>在接口保持不变</strong>的情况下完成很自然流畅的版本更新。</p>\n</blockquote>\n<hr>\n<h3 id=\"Task4-ld手动链接\"><a href=\"#Task4-ld手动链接\" class=\"headerlink\" title=\"Task4 - ld手动链接\"></a>Task4 - ld手动链接</h3><ul>\n<li><strong>解题过程</strong><br>这题要求我们用ld链接器，进行手动链接，我们先试一下直接链接会发生什么</li>\n</ul>\n<pre><code class=\"hljs makefile\"><span class=\"hljs-comment\">#链接代码</span>\nld -o main main.o some.o</code></pre>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">//报错信息</span>\nld: warning: cannot find entry symbol _start; defaulting to <span class=\"hljs-number\">00000000004000b</span>0\nsome.o: In function `notATest()<span class=\"hljs-string\">&#x27;:</span>\nsome.cpp:(.text+0xc): undefined reference to `puts&#x27;\nsome.o: In function `testPrint()<span class=\"hljs-string\">&#x27;:</span>\nsome.cpp:(.text+0x1f): undefined reference to `puts&#x27;\nsome.o: In function `testPrint(<span class=\"hljs-keyword\">int</span>)<span class=\"hljs-string\">&#x27;:</span>\nsome.cpp:(.text+0x52): undefined reference to `printf&#x27;\nMakefile:2: recipe for target &#x27;main&#x27; failed\nmake: *** [main] Error <span class=\"hljs-number\">1</span></code></pre>\n<blockquote>\n<p>发现主要报错信息是 undefined reference to ‘puts’, ‘printf’, 说明标准库中的函数符号没有被成功匹配，我们需要把 stdc 加进去</p>\n</blockquote>\n<pre><code class=\"hljs makefile\"><span class=\"hljs-comment\"># 链接代码</span>\nld -o main main.o some.o -lc\n<span class=\"hljs-comment\"># 通过 -lc 命令直接添加标准库，也可以自行指定libc.so路径</span></code></pre>\n<blockquote>\n<p>可以发现main被成功编译出来，但运行时候发现bash报目录中无此文件<br><pre><code class=\"hljs bash\">bash: ./main: No such file or directory</code></pre></p>\n<p>也就是我们并不能运行这个可执行文件，查找资料之后我们尝试指定使用的动态链接器再进行编译，就可以运行了</p>\n</blockquote>\n<pre><code class=\"hljs makefile\">ld -dynamic-linker /lib64/ld-linux-x86-64.so.2 -o main main.o some.o -lc</code></pre>\n<blockquote>\n<p>我查询了ld的手册试图查找原因，但并未发现为什么必须要使用—dynamic-linker指令</p>\n</blockquote>\n<div style=\"page-break-after: always;\"></div>\n\n\n<ul>\n<li><strong>—dynamic-linker=file</strong><blockquote>\n<p>   Set the name of the dynamic linker.  This is only meaningful when generating dynamically linked ELF executables.  <strong>The default dynamic linker is normally correct; don’t use this unless you know what you are doing.</strong></p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>接下去，我们的程序虽然能够运行起来了，但在 main 函数跑完之后会出现 <em>Segmentation fault (core dumped)</em> 提示，这也提示了我们对于 main 函数的初始化和结束可能并未正常执行。</p>\n</blockquote>\n<ul>\n<li><strong>GDB查看正常程序</strong></li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2020/11/15/DFeZOP.png\" alt></p>\n<blockquote>\n<p>通过 gdb 查看正常程序我们发现，正常的 main 函数执行栈中需要有两个函数为其保证环境 <em>__lib_csu_init</em> 和 <em>__libc_start_main</em></p>\n</blockquote>\n<ul>\n<li><strong>__libc_start_main</strong><br>我们需要知道，在linux中，main函数的初始化环境和参数传递以及返回值处理工作是由 __libc_start_main 来保证的。一个正常的程序执行需要包含以下要素。</li>\n</ul>\n<ol>\n<li>performing any necessary security checks if the effective user ID is not the same as the real user ID.</li>\n<li>initialize the threading subsystem.</li>\n<li>registering the <em>rtld_fini</em> to release resources when this dynamic shared object exits (or is unloaded).</li>\n<li>registering the <em>fini</em> handler to run at program exit.</li>\n<li>calling the initializer function <em>(</em>init)()*.</li>\n<li>calling <em>main()</em> with appropriate arguments.</li>\n<li>calling <em>exit()</em> with the return value from <em>main()</em>.</li>\n</ol>\n<blockquote>\n<p>具体的初始化和结束调用路径异常复杂，在此不多赘述，放一张图有待进一步研究。</p>\n</blockquote>\n<p><img src=\"https://s3.ax1x.com/2020/11/15/DFemef.png\" alt></p>\n<p><em>图片来源: <a href=\"https://luomuxiaoxiao.com/?p=516\">https://luomuxiaoxiao.com/?p=516</a></em></p>\n<hr>\n<p>然后介绍完了主函数的初始化和返回，我们需要知道保证上述的两个函数在哪个动态链接库中，这就涉及到了 <em>crt1.o, crti.o, crtbegin.o, crtend.o, crtn.o</em> 这几个库<br><em>参考： <a href=\"https://blog.csdn.net/farmwang/article/details/73195951\">https://blog.csdn.net/farmwang/article/details/73195951</a></em></p>\n<blockquote>\n<p><strong>crt是c runtime 的缩写</strong>,用于执行进入main之前的初始化和退出main之后的扫尾工作。</p>\n</blockquote>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">目标文件</th>\n<th style=\"text-align:center\">crt1.o</th>\n<th style=\"text-align:center\">crti.o</th>\n<th style=\"text-align:center\">crtbegin.o</th>\n<th style=\"text-align:center\">crtend.o</th>\n<th style=\"text-align:center\">crtn.o</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">作用</td>\n<td style=\"text-align:center\">启动</td>\n<td style=\"text-align:center\">初始化</td>\n<td style=\"text-align:center\">构造</td>\n<td style=\"text-align:center\">析构</td>\n<td style=\"text-align:center\">结束</td>\n</tr>\n</tbody>\n</table>\n</div>\n<blockquote>\n<p>在标准的linux平台下,link的顺序是</p>\n</blockquote>\n<pre><code>ld crt1.o crti.o [user_objects] [system_libraries] crtn.o\n</code></pre><p>所以我们按照顺序进行链接有如下命令</p>\n<pre><code class=\"hljs makefile\"><span class=\"hljs-comment\"># 链接指令</span>\nld -dynamic-linker /lib64/ld-linux-x86-64.so.2 -o main /usr/lib/x86_64-linux-gnu/crt1.o main.o some.o -lc /usr/lib/x86_64-linux-gnu/crti.o /usr/lib/x86_64-linux-gnu/crtn.o</code></pre>\n<blockquote>\n<p>成功的手动完成了程序的链接工作。</p>\n</blockquote>\n<p>以上艰苦的工作告诉我们，不要轻易尝试手动链接，除非你知道你在干什么。平时好好用 gcc。</p>\n<ul>\n<li>动态链接器⼀个操作系统中只需要⼀个吗？为什么？<blockquote>\n<p>一般来说只要有一个支持的动态链接器即可，完成程序的动态链接工作。 但linux中可能有两个 ld 的版本</p>\n</blockquote>\n</li>\n</ul>\n<ol>\n<li>ld.so针对a.out格式的二进制可执行文件</li>\n<li>ld-linux.so针对ELF格式的二进制可执行文件</li>\n</ol>\n<p>a.out是旧版类Unix系统中用于执行档、目的码和后来系统中的函数库的一种文件格式，该版本的链接器仍被保留用以向前支持。</p>\n<hr>\n<h3 id=\"Task5-运行时打桩\"><a href=\"#Task5-运行时打桩\" class=\"headerlink\" title=\"Task5 - 运行时打桩\"></a>Task5 - 运行时打桩</h3><p>Task5 是一个典型的运行时打桩的 task，给了我们编译好的login程序，让我们改变其行为，让它能够输出 login_success.</p>\n<blockquote>\n<p>阅读源码，我们可以发现，login将我们输入的字符串做了hash，与已有某不明hash值，进行比较，如果相等则登陆成功。根据本 lab 的内容主要是讲 make 和链接的，让我们碰撞这个hash显然不是本意。那另一种方法就是通过运行时打桩，改变标准库的链接方式，让strcmp 链接到我们自己写的 strcmp 版本上去，从而我们可以控制其返回值让其返回0使得登陆成功。</p>\n</blockquote>\n<p><em>首先要注意 strcmp 并非只有判断密码时的一次唯一调用，在别处还有调用，所以我们要保证 strcmp 函数的基本功能正确</em><br><pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// mystrcmp.c</span>\n<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">define</span> _GNU_SOURCE</span>\n<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span>\n<span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span> <span class=\"hljs-meta-string\">&lt;dlfcn.h&gt;</span></span>\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">strcmp</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">char</span> *lhs, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">char</span> *rhs)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n    <span class=\"hljs-keyword\">int</span>(*strcmpp)(<span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">char</span> *lhs, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">char</span> *rhs);\n    strcmpp = dlsym(RTLD_NEXT, <span class=\"hljs-string\">&quot;strcmp&quot;</span>);\n\n    <span class=\"hljs-keyword\">char</span> tmp[] = <span class=\"hljs-string\">&quot;3983709877683599140&quot;</span>;\n    <span class=\"hljs-keyword\">if</span>(strcmpp(tmp, rhs) == <span class=\"hljs-number\">0</span>)\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">return</span> strcmpp(lhs, rhs);\n&#125;</code></pre></p>\n<blockquote>\n<p>我们直接写一个自己的 strcmp 版本，用 dlsym 可以获取在运行时 strcmp 函数的指针 <em>（不这样做也可以，可以直接自己重写一遍strcmp程序）</em>，相当于可以直接使用 <strong>真实的标准库中的 strcmp</strong>，然后我们稍微改写一下，让它和我们的hash值比较的时候直接返回0，能够让我们不管输入什么密码都能够 login_success。</p>\n</blockquote>\n<p>接下来我们先将我们写的strcmp编译成动态链接库</p>\n<pre><code class=\"hljs shell\">gcc -shared -fpic -o mystrcmp.so mystrcmp.c -ldl</code></pre>\n<blockquote>\n<p>然后使用 <strong>LD_PRELOAD=”./mystrcmp.so”</strong> 指令，从而在 strcmp 动态链接到标准库之前让其优先匹配我们写的动态链接库中的 strcmp 符号。</p>\n</blockquote>\n<p>这里需要注意由于是要直接运行 ./login, 所以我们需要把LD_PRELOAD的效果全局化，也既在前面加上 export 标记。</p>\n<pre><code class=\"hljs shell\">export LD_PRELOAD=&quot;./mystrcmp.so&quot;</code></pre>\n<p>最后注意不要忘记卸载全局 preload， 不然之后所有程序都 preload 这个strcmp。</p>\n<pre><code class=\"hljs shell\">export LD_PRELOAD=NULL</code></pre>"},{"title":"排序算法及编译器优化效果对比","date":"2021-03-08T14:11:52.000Z","index_img":"/img/ICS_Lab1/top.jpg","_content":"\n\n\n## *ICS (Normal) 第一周作业*\n\n\n\n### 冒泡与快排用时对比\n\n\n\n![冒泡排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocut0coevj31do0sggpl.jpg)\n\n\n\n### 相同算法在 GCC 编译优化下用时对比\n\n\n\n![冒泡排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocvbzmuy0j31cy0s842c.jpg)\n\n\n\n![快速排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocut5qwjwj31a80smjvj.jpg)\n\n\n\n![优化快速排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutaoylej31b40sqtcm.jpg)\n\n\n\n\n\n### 不同排序算法在不同GCC优化下的变化\n\n\n\n![冒泡排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutf9rb3j31cs0s8dih.jpg)\n\n\n\n![快速排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocuthxygzj31b20t4jtt.jpg)\n\n\n\n![优化快速排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutkvifhj31b20swdi8.jpg)\n\n\n\n---\n\n\n\n### 改进快速排序\n\n\n\n对于快速排序的改进策略一般有两种\n\n\n\n- ***Pivot 三值取中***\n\n快速排序最坏情况是枢纽元为最大或者最小数字，那么所有数都划分到一个序列去了时间复杂度为O(n^2)，为了保证最坏情况不出现，尽量使pivot能够二分序列，我们采用三值取中法，既开头、中间、结尾三个元素选取大小中等的元素与首元交换成为Pivot，避免最坏情况出现。\n\n\n\n**效果：**在应用三值取中后可以发现优化快排的排序速度变得较为稳定，不像普通版本一样依赖于序列的形态。\n\n\n\n- ***小规模插入排序***\n\n即当快速排序所划分的子序列的长度小于某个定值k时，该子序列基本有序，可以采用插入排序的办法对子序列进行排序，从而使整体算法的时间复杂度的期望下降为 $O(nk+nlg(\\frac{n}{k}))$\n\n\n\n### 实验效果\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocuto6qwgj317w0t076c.jpg)\n\n\n\n可以看到在同等数据量下，对于快速排序具有一定优化效果\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutsrs9ij31au0sctcp.jpg)\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutvjlj6j31bg0rkwig.jpg)\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutym2uij31bm0sotct.jpg)\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocuu1tn5uj31b20swdk0.jpg)\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocuu4kk90j31b20s4n1a.jpg)\n\n\n\n可以看到，随着优化等级的增加，优化的快排几乎成线性，更加稳定，而普通快排有所波动。","source":"_posts/ICS/ICS_Normal.md","raw":"---\ntitle: 排序算法及编译器优化效果对比\ndate: 2021-03-08 22:11:52\nindex_img: /img/ICS_Lab1/top.jpg\ncategory: [ICS]\ntags: [Sort]\n---\n\n\n\n## *ICS (Normal) 第一周作业*\n\n\n\n### 冒泡与快排用时对比\n\n\n\n![冒泡排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocut0coevj31do0sggpl.jpg)\n\n\n\n### 相同算法在 GCC 编译优化下用时对比\n\n\n\n![冒泡排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocvbzmuy0j31cy0s842c.jpg)\n\n\n\n![快速排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocut5qwjwj31a80smjvj.jpg)\n\n\n\n![优化快速排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutaoylej31b40sqtcm.jpg)\n\n\n\n\n\n### 不同排序算法在不同GCC优化下的变化\n\n\n\n![冒泡排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutf9rb3j31cs0s8dih.jpg)\n\n\n\n![快速排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocuthxygzj31b20t4jtt.jpg)\n\n\n\n![优化快速排序](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutkvifhj31b20swdi8.jpg)\n\n\n\n---\n\n\n\n### 改进快速排序\n\n\n\n对于快速排序的改进策略一般有两种\n\n\n\n- ***Pivot 三值取中***\n\n快速排序最坏情况是枢纽元为最大或者最小数字，那么所有数都划分到一个序列去了时间复杂度为O(n^2)，为了保证最坏情况不出现，尽量使pivot能够二分序列，我们采用三值取中法，既开头、中间、结尾三个元素选取大小中等的元素与首元交换成为Pivot，避免最坏情况出现。\n\n\n\n**效果：**在应用三值取中后可以发现优化快排的排序速度变得较为稳定，不像普通版本一样依赖于序列的形态。\n\n\n\n- ***小规模插入排序***\n\n即当快速排序所划分的子序列的长度小于某个定值k时，该子序列基本有序，可以采用插入排序的办法对子序列进行排序，从而使整体算法的时间复杂度的期望下降为 $O(nk+nlg(\\frac{n}{k}))$\n\n\n\n### 实验效果\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocuto6qwgj317w0t076c.jpg)\n\n\n\n可以看到在同等数据量下，对于快速排序具有一定优化效果\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutsrs9ij31au0sctcp.jpg)\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutvjlj6j31bg0rkwig.jpg)\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocutym2uij31bm0sotct.jpg)\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocuu1tn5uj31b20swdk0.jpg)\n\n\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1gocuu4kk90j31b20s4n1a.jpg)\n\n\n\n可以看到，随着优化等级的增加，优化的快排几乎成线性，更加稳定，而普通快排有所波动。","slug":"ICS/ICS_Normal","published":1,"updated":"2021-03-08T14:31:38.376Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty3v000ss8pdhko4h6ju","content":"<h2 id=\"ICS-Normal-第一周作业\"><a href=\"#ICS-Normal-第一周作业\" class=\"headerlink\" title=\"ICS (Normal) 第一周作业\"></a><em>ICS (Normal) 第一周作业</em></h2><h3 id=\"冒泡与快排用时对比\"><a href=\"#冒泡与快排用时对比\" class=\"headerlink\" title=\"冒泡与快排用时对比\"></a>冒泡与快排用时对比</h3><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocut0coevj31do0sggpl.jpg\" alt=\"冒泡排序\"></p>\n<h3 id=\"相同算法在-GCC-编译优化下用时对比\"><a href=\"#相同算法在-GCC-编译优化下用时对比\" class=\"headerlink\" title=\"相同算法在 GCC 编译优化下用时对比\"></a>相同算法在 GCC 编译优化下用时对比</h3><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocvbzmuy0j31cy0s842c.jpg\" alt=\"冒泡排序\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocut5qwjwj31a80smjvj.jpg\" alt=\"快速排序\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutaoylej31b40sqtcm.jpg\" alt=\"优化快速排序\"></p>\n<h3 id=\"不同排序算法在不同GCC优化下的变化\"><a href=\"#不同排序算法在不同GCC优化下的变化\" class=\"headerlink\" title=\"不同排序算法在不同GCC优化下的变化\"></a>不同排序算法在不同GCC优化下的变化</h3><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutf9rb3j31cs0s8dih.jpg\" alt=\"冒泡排序\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocuthxygzj31b20t4jtt.jpg\" alt=\"快速排序\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutkvifhj31b20swdi8.jpg\" alt=\"优化快速排序\"></p>\n<hr>\n<h3 id=\"改进快速排序\"><a href=\"#改进快速排序\" class=\"headerlink\" title=\"改进快速排序\"></a>改进快速排序</h3><p>对于快速排序的改进策略一般有两种</p>\n<ul>\n<li><strong><em>Pivot 三值取中</em></strong></li>\n</ul>\n<p>快速排序最坏情况是枢纽元为最大或者最小数字，那么所有数都划分到一个序列去了时间复杂度为O(n^2)，为了保证最坏情况不出现，尽量使pivot能够二分序列，我们采用三值取中法，既开头、中间、结尾三个元素选取大小中等的元素与首元交换成为Pivot，避免最坏情况出现。</p>\n<p><strong>效果：</strong>在应用三值取中后可以发现优化快排的排序速度变得较为稳定，不像普通版本一样依赖于序列的形态。</p>\n<ul>\n<li><strong><em>小规模插入排序</em></strong></li>\n</ul>\n<p>即当快速排序所划分的子序列的长度小于某个定值k时，该子序列基本有序，可以采用插入排序的办法对子序列进行排序，从而使整体算法的时间复杂度的期望下降为 $O(nk+nlg(\\frac{n}{k}))$</p>\n<h3 id=\"实验效果\"><a href=\"#实验效果\" class=\"headerlink\" title=\"实验效果\"></a>实验效果</h3><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocuto6qwgj317w0t076c.jpg\" alt></p>\n<p>可以看到在同等数据量下，对于快速排序具有一定优化效果</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutsrs9ij31au0sctcp.jpg\" alt></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutvjlj6j31bg0rkwig.jpg\" alt></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutym2uij31bm0sotct.jpg\" alt></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocuu1tn5uj31b20swdk0.jpg\" alt></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocuu4kk90j31b20s4n1a.jpg\" alt></p>\n<p>可以看到，随着优化等级的增加，优化的快排几乎成线性，更加稳定，而普通快排有所波动。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"ICS-Normal-第一周作业\"><a href=\"#ICS-Normal-第一周作业\" class=\"headerlink\" title=\"ICS (Normal) 第一周作业\"></a><em>ICS (Normal) 第一周作业</em></h2><h3 id=\"冒泡与快排用时对比\"><a href=\"#冒泡与快排用时对比\" class=\"headerlink\" title=\"冒泡与快排用时对比\"></a>冒泡与快排用时对比</h3><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocut0coevj31do0sggpl.jpg\" alt=\"冒泡排序\"></p>\n<h3 id=\"相同算法在-GCC-编译优化下用时对比\"><a href=\"#相同算法在-GCC-编译优化下用时对比\" class=\"headerlink\" title=\"相同算法在 GCC 编译优化下用时对比\"></a>相同算法在 GCC 编译优化下用时对比</h3><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocvbzmuy0j31cy0s842c.jpg\" alt=\"冒泡排序\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocut5qwjwj31a80smjvj.jpg\" alt=\"快速排序\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutaoylej31b40sqtcm.jpg\" alt=\"优化快速排序\"></p>\n<h3 id=\"不同排序算法在不同GCC优化下的变化\"><a href=\"#不同排序算法在不同GCC优化下的变化\" class=\"headerlink\" title=\"不同排序算法在不同GCC优化下的变化\"></a>不同排序算法在不同GCC优化下的变化</h3><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutf9rb3j31cs0s8dih.jpg\" alt=\"冒泡排序\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocuthxygzj31b20t4jtt.jpg\" alt=\"快速排序\"></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutkvifhj31b20swdi8.jpg\" alt=\"优化快速排序\"></p>\n<hr>\n<h3 id=\"改进快速排序\"><a href=\"#改进快速排序\" class=\"headerlink\" title=\"改进快速排序\"></a>改进快速排序</h3><p>对于快速排序的改进策略一般有两种</p>\n<ul>\n<li><strong><em>Pivot 三值取中</em></strong></li>\n</ul>\n<p>快速排序最坏情况是枢纽元为最大或者最小数字，那么所有数都划分到一个序列去了时间复杂度为O(n^2)，为了保证最坏情况不出现，尽量使pivot能够二分序列，我们采用三值取中法，既开头、中间、结尾三个元素选取大小中等的元素与首元交换成为Pivot，避免最坏情况出现。</p>\n<p><strong>效果：</strong>在应用三值取中后可以发现优化快排的排序速度变得较为稳定，不像普通版本一样依赖于序列的形态。</p>\n<ul>\n<li><strong><em>小规模插入排序</em></strong></li>\n</ul>\n<p>即当快速排序所划分的子序列的长度小于某个定值k时，该子序列基本有序，可以采用插入排序的办法对子序列进行排序，从而使整体算法的时间复杂度的期望下降为 $O(nk+nlg(\\frac{n}{k}))$</p>\n<h3 id=\"实验效果\"><a href=\"#实验效果\" class=\"headerlink\" title=\"实验效果\"></a>实验效果</h3><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocuto6qwgj317w0t076c.jpg\" alt></p>\n<p>可以看到在同等数据量下，对于快速排序具有一定优化效果</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutsrs9ij31au0sctcp.jpg\" alt></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutvjlj6j31bg0rkwig.jpg\" alt></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocutym2uij31bm0sotct.jpg\" alt></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocuu1tn5uj31b20swdk0.jpg\" alt></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gocuu4kk90j31b20s4n1a.jpg\" alt></p>\n<p>可以看到，随着优化等级的增加，优化的快排几乎成线性，更加稳定，而普通快排有所波动。</p>\n"},{"title":"ICS_PJ Y86 Extended CPU","date":"2021-01-06T02:23:45.000Z","index_img":"/img/ICS_Lab1/top.jpg","_content":"\n*项目地址： https://github.com/fdu2019xzy/ICS_Y86*\n\n---\n\n## 一、项目基本信息\n\n### 1. 项目简介\n\nY86-Extended 是由谢子飏和王少文组队合作完成的项目，作为复旦大学 ICS (上) 的期末PJ，\n本项目在实现了本项目在基础流水线处理器架构之上添加了**更高级的分支预测**、**硬件栈**、 **y86 指令集扩展**，并编写了一个**汇编器** yyas (支持宏定义)，以及其他特殊功能。结合精美的前端，根据上传文件性质不同 (yo/ys) 可以在普通模式和编译模式下运行程序, 具有较高的鲁棒性, 能够直观的看到基本信息、所有的寄存器信息 (包括流水线寄存器)、运行进度、当前指令和其他信息。\n\n支持任意**前进回溯**、**设置断点**、**终端输出** (包含**彩色矩阵**)等扩展功能\n\n### 2. 项目分工\n\n王少文：后端 CPU 主体设计及汇编器\n谢子飏： (中) 前端及测试\n\n### 3. 项目架构及设计思路\n\n我们的项目使用**前后端分离**开发策略，考虑到运行速度后端由 C++ 编写，中前端使用 Python, Vue.js, Js 开发。\n\n- 项目架构图\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvtMV.png\" style=\"width:500px\"/>\n\n- 交互逻辑和运行过程\n\n整个交互逻辑和运行过程分为，前端上传 ys/yo 文件 post 到中端的 lauch.py 的flask服务器，flask驱动编译器编译并将编译好的yo文件传到 CPU 中。CPU 按设计跑完输出 data.json 文件，前端 fetch 后端 CPU 生成的 data.json 在前端按操作逻辑进行展示。\n\n由于后端 C++ 跑的非常快，我们前端在上传后几乎能够即时获得 data, 而这样前后端分离的好处在于，我们前端可以非常自由的展现数据，所有的前进回溯甚至跳跃，都可以在 O(1) 内实现，不会出现很大的限制。\n\n---\n\n## 二、使用方式及功能详解\n\n### 1. 具体使用方法\n(见项目目录下 README.md)\n\n### 2. 功能详解\n\n- 主体功能介绍图\n\n![](https://s3.ax1x.com/2021/01/06/sAv8Gn.png)\n\n![](https://s3.ax1x.com/2021/01/06/sAv3Ps.png)\n\n- 当前指令模块\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvV2t.png\" style=\"width:250px\"/>\n\n当前指令显示我们当前运行到的指令 (PC 所指)，并包含前后文2条指令的信息。\n\n**隐藏断点设置**\n\n为了前端的布局美观和统一性，断点设置被隐藏进了当前指令卡片中，点击当前指令卡片即可设置断点。\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvE8I.png\" style=\"width:400px\"/>\n\n可以任意设置增删断点\n\n- **终端字符及彩色矩阵输出**\n\n根据后端的内存映射，我们可以让终端输出字符以及彩色矩阵。\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvJx0.png\" style=\"width:300px\"/>\n\n\n- 附带我们编写的 YYAS 汇编器，能够实现 ys 到 yo 的编译\n\n\n---\n\n\n## 三、代码详解\n\n### 1. 前端代码架构分析\n\n- 前端代码架构图\n\n![](https://s3.ax1x.com/2021/01/06/sAvl5j.png)\n\n前端设计采用 Vue.js 和前端框架 iView 设计，由于 Vue 的**响应式渲染**性质，非常适合我们本次的前端要求，同时为了保持多平台使用的可能性，Vue并没有使用脚手架，所有的 Vue.js、jQuery 都采用了 **CDN 引入**模式。\n\n其中 Index 是主页面入口，Index.js 包括 Vue app 的创建和 Vue 页面路由， Index.html 包含主页面的 DOM 树\n\nPages 里面包含了主要的界面，主页面是 main.js 包含 cpu 的主要功能。\n所有的 Pages 作为 export 模块被引入到 Index.js 中进行路由。\nmain.js 里面包含了 main 页面所有**逻辑函数**，**声明周期钩子**，以及 main 页面的 DOM 树， 其他页面也是同样架构。\n\n（由于是 CDN 引入 main 页面要插入路由的话， DOM 树应当是字符串形式传入 template 中）\n\nCSS 里面包含了所有主要的样式表，对功能和作用区域的不同做了简单的分类。\n\nStatic 里面包含了需要读取的 Json data 信息，以及当前处理编译文件放置在 Source 中。\n\n- **中台前后端链接代码**\n\n前后端连接使用的是 python flask 服务器，通过接前端上传表单的 post，将获得的文件传入编译器编译之后喂入 CPU 中，获得 data.json 前端再 getData。\n\n### 2. 后端代码架构分析\n\n- 后端代码架构图\n\n![](https://s3.ax1x.com/2021/01/06/sAvQaQ.png)\n\n- 汇编器部分\n  - 汇编器的可执行文件为yyas.py，这是包含了所有代码（不需要import）的最终文件，试试./yyas -v 和 ./yyas -h，有惊喜\n  - instr.py为Y86所有指令的信息（不含Y86 Extended的扩展部分）\n  - striper.py为Stage1时，将yo文件转化为yoraw的脚本，目前已经被弃用，仅作为存档提交。现在实现相同功能请使用./yyas -r -np\n- CPU部分\n  - Controller.cpp 为CPU的控制器，主要包含了流水线的控制逻辑\n  - Device.cpp 为CPU流水线的核心，包含了FDEMW五个阶段的运行逻辑\n  - Output.cpp 有一些用于输出的函数，用于Stage1输出至命令行或Stage2输出至json文件\n  - Util.cpp包含了一些辅助的函数，例如In函数和Format函数（这里用了很多modern cpp的魔法）\n\n\n---\n\n<div style=\"page-break-after: always;\"></div>\n\n## 四、 实现细节\n\n#### 前端细节\n\n前端搭建了 anywhere 服务器 (用于解决跨域问题, 踩坑经历可以看第五节)，主要函数在 main.js 文件中， 通过各类声明周期函数和写的 handle 来处理上传，运行，停止，重置，以及断点设置等功能，此处不展开细讲，主要是后端。\n\n（前端使用了 anywhere 服务器 + 中端 flask 服务器的双服务器架构，其主要是因为我们前端在 import 模块时不开本地服务器会产生跨域问题。对于跨域问题我们最开始遇到是在获取 data.json 的时候，踩坑过程中我们曾尝试通过jsonp 解决跨域问题，并且成功了，但在 import 模块时再次遇到了跨域问题，为了一劳永逸，我们直接使用了 anywhere 直接开了一个本地服。）\n\n#### 后端细节\n\n1. **关于流水线**：为了尽可能的靠近实际的硬件架构，我们的CPU核心实现分成了**wire**和**reg**两种struct，用来模拟verilog硬件语言中的wire和reg，reg是实际存在的寄存器，而wire只是用于逻辑中转。为了模拟CPU的并行化，我们采用了如下的逻辑\n\n   1. 利用Reg中的数据计算F D E M W，写入wire变量（实际不存在）\n   2. 利用现在的wire上的值，更新流水线及其他状态\n   3. 将wire的值写入下一个Reg，例如f_wire写入D_Reg，当流水线状态为NORMAL时回到a\n\n2. 每个阶段的具体实现逻辑， 与CSAPP上的电路实现差别不大，此处不再赘述\n\n3. **关于扩展指令集**：我们的指令集扩展见**ISA.md**，具体到流水线上只需少许修改各个阶段的逻辑，与官方设计思路差不太多，依次修改FDEMW就行。\n\n4. **关于分支预测策略**：我们的分支预测采用的是**2比特溢出预测器**，该预测器采用的逻辑如下图\n\n   ![预测器](https://s3.ax1x.com/2021/01/06/sAvG2q.png)\n\n   1. 当JXX的信号不是Jmp时，更新上述的状态机\n   2. 若状态机信号为3或者2，则进行跳转\n   3. 若状态机信号为1或者0，则不进行跳转\n\n   除此之外，我们也需要相应的改变分支错判的逻辑，需要加一个IfJump信号，当E阶段输出的信号与IfJump信号不同，说明分支预测错误，需要清空流水线。\n\n   这样的分支预测器，据统计可以达到90%的正确率（https://en.wikipedia.org/wiki/Branch_predictor），在我们的测试中，一般情况下可以提升10%-30%的性能\n\n5. **关于复杂指令**：在我们增加的指令中，有一些指令如mulq、divq和remq都是很耗时的指令，如果强行让他们在一个周期内完成，我们的CPU时钟频率就会非常低。因此我们假定这部分指令所需要的时间为其他指令最长耗时的10倍，在E阶段设置一个counter，建立一个递减的状态机，使用下面的控制逻辑\n\n   1. 如果指令属于上述复杂指令，将状态机置于10\n   2. 如果状态机不为0，则使F D阶段进入STALL阶段，E阶段继续计算，但阻断E到M的输入，状态机减1\n   3. 如果状态机为0，则流水线继续执行\n\n   这样就可以实现维持较高CPU频率的同时，实现复杂指令。（即不会因为加了这个指令使其他指令的执行变慢）\n\n6. **关于硬件栈**：为了避免每次调用ret指令时两个时钟周期的浪费，我们采用了CSAPP上的硬件栈。在硬件上，硬件栈可以由多路选择器和多个寄存器构成，在这里我们简单的使用Stack实现（大小为0x20）。采用如下的控制逻辑：\n\n   1. 如果调用call指令，在栈没有满时，将地址载入硬件栈\n   2. 如果调用ret指令，在栈非空时，弹栈，将值读出\n   3. 在M阶段执行后，判断硬件栈的预测是否正确\n      1. 若正确，则继续执行\n      2. 若不正确，则清空 F D E的流水线\n\n   使用硬件栈后，最差的情况即是与无硬件栈情况相同，最好情况在我们的测试中，可以增加30%+的性能。\n\n7. 关于指令不可写和非指令不可读保护：我们的汇编器会计算yo文件中，最后一个是指令的位置，在CPU运行时，会进行动态的判断\n\n   1. 在Fetch阶段读取不可读的位置，会产生INS错误\n   2. 在其他阶段写入不可写的位置，会产生ADR错误\n\n8. 关于宏定义：为了CPU的扩展性和兼容性，我们使用了宏定义来动态的开关某些特性，例如 ```OUTPUT_JSON``` 宏定义后即可输出 data_json 供前端使用。\n\n#### 汇编器细节\n\n我们的汇编器采用了依次处理的方式，如下(Code Explains itself)\n\n```python\n    lines = gen_list(lines) #解析关键词\n    lines = remove_single_line_annot(lines) #去除单行注释\n    lines = remove_multi_line_annot(lines) #去除多行注释\n    lines = detach_label(lines) #找到对应的label\n    lines_ref = copy.deepcopy(lines) #复制一份用于输出\n    mem = get_memaddr(lines) #找到内存对应的地址\n    labels = get_def_label(lines) #处理.define\n    lines = replace_label(lines, mem, labels) #处理label\n    byte_code = gen_byte_code(lines) #产生yo代码\n```\n\n\n\n#### 测试细节\n\n我们采用Google Test 和 Python Unitest来辅助我们进行我们的程序测试。其在我们项目文件的 test 文件夹下，我们通过 shell 脚本和 python 脚本将模拟器的输出进行处理，转换成 gtest 代码以便于我们进行测试。\n\n基本语句即为 ```EXPECT_EQ(x, y)```\n\n- 测试代码结构\n\n![](asset/测试代码架构.png)\n\n使用 Google Test 我们能够清晰的看到测试点信息。\n\n- 普通 yo_test\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvZxP.png\" style=\"width:300px\"/>\n\n- Hornor 测试\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvmKf.png\" style=\"width:300px\"/>\n\n- 附加测试\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvMVg.png\" style=\"width:400px\"/>\n\n---\n\n<div style=\"page-break-after: always;\"></div>\n\n\n### 五、特点和创新\n\n1. **汇编器创新**：我们兼容现有的所有ys文件的基础上，还添加了一些伪指令和语法\n\n   1. 不需要写逗号了：现在所有的ys指令操作数之间可以使用空格隔开\n   2. mrmovq和rmmovq：现在不需要强制写括号，可以直接mov至常数地址（此时寄存器为RNONE，我们的CPU也做了相应的修改）如rmmovq %rax $800\n   3. 伪指令\n      1. .define 类似C语言的宏定义\n      2. .string \"mystring\" 将后面的mystring转化为对应的ASCII码写入\n      3. .byte .hword .word支持\n   4. 能够生成yo文件和yoraw文件，生成的yo文件比官方的yo文件漂亮不少，完全对齐\n   5. 有完整的命令行参数\n\n   ```\n   usage: yyas [-h] [-o OUTFILE] [-r] [-np] [-v] sourcefile\n   \n   yyas: Assemble .ys file to .yo file or/and .yo file to raw byte file\n   \n   positional arguments:\n     sourcefile            The source file to be assembled\n   \n   optional arguments:\n     -h, --help            show this help message and exit\n     -o OUTFILE, --output OUTFILE\n                           Assign the output file\n     -r, --raw             Generate raw byte file\n     -np, --noprefix       Do not generate prefix in raw output\n     -v, --version         show version\n   ```\n\n2. **处理器创新**（见具体实现）\n\n   1. 更好的分支预测器\n   2. 硬件栈\n   3. 几乎三倍的指令集支持（及其扩展含义）\n   4. 复杂指令集的多周期支持\n\n---\n\n### 六、总结与回顾\n\n#### PJ 心得总结及致谢\n\n本次 PJ 让我们更加深入的理解了现代流水线处理器的原理，各种硬件栈，扩展指令集的设计也拓展了我们的技术边缘，非常不错的体验。最后非常感谢助教和金老师一学期的辛苦工作。在很多方面帮助了我们，助教的 Lab 非常精彩有趣，金老师的课十分幽默风趣，非常感谢各位的付出。","source":"_posts/ICS/ICS_PJ.md","raw":"---\ntitle: ICS_PJ Y86 Extended CPU\ndate: 2021-01-06 10:23:45\nindex_img: /img/ICS_Lab1/top.jpg\ncategory: [ICS]\ntags: [CPU]\n---\n\n*项目地址： https://github.com/fdu2019xzy/ICS_Y86*\n\n---\n\n## 一、项目基本信息\n\n### 1. 项目简介\n\nY86-Extended 是由谢子飏和王少文组队合作完成的项目，作为复旦大学 ICS (上) 的期末PJ，\n本项目在实现了本项目在基础流水线处理器架构之上添加了**更高级的分支预测**、**硬件栈**、 **y86 指令集扩展**，并编写了一个**汇编器** yyas (支持宏定义)，以及其他特殊功能。结合精美的前端，根据上传文件性质不同 (yo/ys) 可以在普通模式和编译模式下运行程序, 具有较高的鲁棒性, 能够直观的看到基本信息、所有的寄存器信息 (包括流水线寄存器)、运行进度、当前指令和其他信息。\n\n支持任意**前进回溯**、**设置断点**、**终端输出** (包含**彩色矩阵**)等扩展功能\n\n### 2. 项目分工\n\n王少文：后端 CPU 主体设计及汇编器\n谢子飏： (中) 前端及测试\n\n### 3. 项目架构及设计思路\n\n我们的项目使用**前后端分离**开发策略，考虑到运行速度后端由 C++ 编写，中前端使用 Python, Vue.js, Js 开发。\n\n- 项目架构图\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvtMV.png\" style=\"width:500px\"/>\n\n- 交互逻辑和运行过程\n\n整个交互逻辑和运行过程分为，前端上传 ys/yo 文件 post 到中端的 lauch.py 的flask服务器，flask驱动编译器编译并将编译好的yo文件传到 CPU 中。CPU 按设计跑完输出 data.json 文件，前端 fetch 后端 CPU 生成的 data.json 在前端按操作逻辑进行展示。\n\n由于后端 C++ 跑的非常快，我们前端在上传后几乎能够即时获得 data, 而这样前后端分离的好处在于，我们前端可以非常自由的展现数据，所有的前进回溯甚至跳跃，都可以在 O(1) 内实现，不会出现很大的限制。\n\n---\n\n## 二、使用方式及功能详解\n\n### 1. 具体使用方法\n(见项目目录下 README.md)\n\n### 2. 功能详解\n\n- 主体功能介绍图\n\n![](https://s3.ax1x.com/2021/01/06/sAv8Gn.png)\n\n![](https://s3.ax1x.com/2021/01/06/sAv3Ps.png)\n\n- 当前指令模块\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvV2t.png\" style=\"width:250px\"/>\n\n当前指令显示我们当前运行到的指令 (PC 所指)，并包含前后文2条指令的信息。\n\n**隐藏断点设置**\n\n为了前端的布局美观和统一性，断点设置被隐藏进了当前指令卡片中，点击当前指令卡片即可设置断点。\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvE8I.png\" style=\"width:400px\"/>\n\n可以任意设置增删断点\n\n- **终端字符及彩色矩阵输出**\n\n根据后端的内存映射，我们可以让终端输出字符以及彩色矩阵。\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvJx0.png\" style=\"width:300px\"/>\n\n\n- 附带我们编写的 YYAS 汇编器，能够实现 ys 到 yo 的编译\n\n\n---\n\n\n## 三、代码详解\n\n### 1. 前端代码架构分析\n\n- 前端代码架构图\n\n![](https://s3.ax1x.com/2021/01/06/sAvl5j.png)\n\n前端设计采用 Vue.js 和前端框架 iView 设计，由于 Vue 的**响应式渲染**性质，非常适合我们本次的前端要求，同时为了保持多平台使用的可能性，Vue并没有使用脚手架，所有的 Vue.js、jQuery 都采用了 **CDN 引入**模式。\n\n其中 Index 是主页面入口，Index.js 包括 Vue app 的创建和 Vue 页面路由， Index.html 包含主页面的 DOM 树\n\nPages 里面包含了主要的界面，主页面是 main.js 包含 cpu 的主要功能。\n所有的 Pages 作为 export 模块被引入到 Index.js 中进行路由。\nmain.js 里面包含了 main 页面所有**逻辑函数**，**声明周期钩子**，以及 main 页面的 DOM 树， 其他页面也是同样架构。\n\n（由于是 CDN 引入 main 页面要插入路由的话， DOM 树应当是字符串形式传入 template 中）\n\nCSS 里面包含了所有主要的样式表，对功能和作用区域的不同做了简单的分类。\n\nStatic 里面包含了需要读取的 Json data 信息，以及当前处理编译文件放置在 Source 中。\n\n- **中台前后端链接代码**\n\n前后端连接使用的是 python flask 服务器，通过接前端上传表单的 post，将获得的文件传入编译器编译之后喂入 CPU 中，获得 data.json 前端再 getData。\n\n### 2. 后端代码架构分析\n\n- 后端代码架构图\n\n![](https://s3.ax1x.com/2021/01/06/sAvQaQ.png)\n\n- 汇编器部分\n  - 汇编器的可执行文件为yyas.py，这是包含了所有代码（不需要import）的最终文件，试试./yyas -v 和 ./yyas -h，有惊喜\n  - instr.py为Y86所有指令的信息（不含Y86 Extended的扩展部分）\n  - striper.py为Stage1时，将yo文件转化为yoraw的脚本，目前已经被弃用，仅作为存档提交。现在实现相同功能请使用./yyas -r -np\n- CPU部分\n  - Controller.cpp 为CPU的控制器，主要包含了流水线的控制逻辑\n  - Device.cpp 为CPU流水线的核心，包含了FDEMW五个阶段的运行逻辑\n  - Output.cpp 有一些用于输出的函数，用于Stage1输出至命令行或Stage2输出至json文件\n  - Util.cpp包含了一些辅助的函数，例如In函数和Format函数（这里用了很多modern cpp的魔法）\n\n\n---\n\n<div style=\"page-break-after: always;\"></div>\n\n## 四、 实现细节\n\n#### 前端细节\n\n前端搭建了 anywhere 服务器 (用于解决跨域问题, 踩坑经历可以看第五节)，主要函数在 main.js 文件中， 通过各类声明周期函数和写的 handle 来处理上传，运行，停止，重置，以及断点设置等功能，此处不展开细讲，主要是后端。\n\n（前端使用了 anywhere 服务器 + 中端 flask 服务器的双服务器架构，其主要是因为我们前端在 import 模块时不开本地服务器会产生跨域问题。对于跨域问题我们最开始遇到是在获取 data.json 的时候，踩坑过程中我们曾尝试通过jsonp 解决跨域问题，并且成功了，但在 import 模块时再次遇到了跨域问题，为了一劳永逸，我们直接使用了 anywhere 直接开了一个本地服。）\n\n#### 后端细节\n\n1. **关于流水线**：为了尽可能的靠近实际的硬件架构，我们的CPU核心实现分成了**wire**和**reg**两种struct，用来模拟verilog硬件语言中的wire和reg，reg是实际存在的寄存器，而wire只是用于逻辑中转。为了模拟CPU的并行化，我们采用了如下的逻辑\n\n   1. 利用Reg中的数据计算F D E M W，写入wire变量（实际不存在）\n   2. 利用现在的wire上的值，更新流水线及其他状态\n   3. 将wire的值写入下一个Reg，例如f_wire写入D_Reg，当流水线状态为NORMAL时回到a\n\n2. 每个阶段的具体实现逻辑， 与CSAPP上的电路实现差别不大，此处不再赘述\n\n3. **关于扩展指令集**：我们的指令集扩展见**ISA.md**，具体到流水线上只需少许修改各个阶段的逻辑，与官方设计思路差不太多，依次修改FDEMW就行。\n\n4. **关于分支预测策略**：我们的分支预测采用的是**2比特溢出预测器**，该预测器采用的逻辑如下图\n\n   ![预测器](https://s3.ax1x.com/2021/01/06/sAvG2q.png)\n\n   1. 当JXX的信号不是Jmp时，更新上述的状态机\n   2. 若状态机信号为3或者2，则进行跳转\n   3. 若状态机信号为1或者0，则不进行跳转\n\n   除此之外，我们也需要相应的改变分支错判的逻辑，需要加一个IfJump信号，当E阶段输出的信号与IfJump信号不同，说明分支预测错误，需要清空流水线。\n\n   这样的分支预测器，据统计可以达到90%的正确率（https://en.wikipedia.org/wiki/Branch_predictor），在我们的测试中，一般情况下可以提升10%-30%的性能\n\n5. **关于复杂指令**：在我们增加的指令中，有一些指令如mulq、divq和remq都是很耗时的指令，如果强行让他们在一个周期内完成，我们的CPU时钟频率就会非常低。因此我们假定这部分指令所需要的时间为其他指令最长耗时的10倍，在E阶段设置一个counter，建立一个递减的状态机，使用下面的控制逻辑\n\n   1. 如果指令属于上述复杂指令，将状态机置于10\n   2. 如果状态机不为0，则使F D阶段进入STALL阶段，E阶段继续计算，但阻断E到M的输入，状态机减1\n   3. 如果状态机为0，则流水线继续执行\n\n   这样就可以实现维持较高CPU频率的同时，实现复杂指令。（即不会因为加了这个指令使其他指令的执行变慢）\n\n6. **关于硬件栈**：为了避免每次调用ret指令时两个时钟周期的浪费，我们采用了CSAPP上的硬件栈。在硬件上，硬件栈可以由多路选择器和多个寄存器构成，在这里我们简单的使用Stack实现（大小为0x20）。采用如下的控制逻辑：\n\n   1. 如果调用call指令，在栈没有满时，将地址载入硬件栈\n   2. 如果调用ret指令，在栈非空时，弹栈，将值读出\n   3. 在M阶段执行后，判断硬件栈的预测是否正确\n      1. 若正确，则继续执行\n      2. 若不正确，则清空 F D E的流水线\n\n   使用硬件栈后，最差的情况即是与无硬件栈情况相同，最好情况在我们的测试中，可以增加30%+的性能。\n\n7. 关于指令不可写和非指令不可读保护：我们的汇编器会计算yo文件中，最后一个是指令的位置，在CPU运行时，会进行动态的判断\n\n   1. 在Fetch阶段读取不可读的位置，会产生INS错误\n   2. 在其他阶段写入不可写的位置，会产生ADR错误\n\n8. 关于宏定义：为了CPU的扩展性和兼容性，我们使用了宏定义来动态的开关某些特性，例如 ```OUTPUT_JSON``` 宏定义后即可输出 data_json 供前端使用。\n\n#### 汇编器细节\n\n我们的汇编器采用了依次处理的方式，如下(Code Explains itself)\n\n```python\n    lines = gen_list(lines) #解析关键词\n    lines = remove_single_line_annot(lines) #去除单行注释\n    lines = remove_multi_line_annot(lines) #去除多行注释\n    lines = detach_label(lines) #找到对应的label\n    lines_ref = copy.deepcopy(lines) #复制一份用于输出\n    mem = get_memaddr(lines) #找到内存对应的地址\n    labels = get_def_label(lines) #处理.define\n    lines = replace_label(lines, mem, labels) #处理label\n    byte_code = gen_byte_code(lines) #产生yo代码\n```\n\n\n\n#### 测试细节\n\n我们采用Google Test 和 Python Unitest来辅助我们进行我们的程序测试。其在我们项目文件的 test 文件夹下，我们通过 shell 脚本和 python 脚本将模拟器的输出进行处理，转换成 gtest 代码以便于我们进行测试。\n\n基本语句即为 ```EXPECT_EQ(x, y)```\n\n- 测试代码结构\n\n![](asset/测试代码架构.png)\n\n使用 Google Test 我们能够清晰的看到测试点信息。\n\n- 普通 yo_test\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvZxP.png\" style=\"width:300px\"/>\n\n- Hornor 测试\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvmKf.png\" style=\"width:300px\"/>\n\n- 附加测试\n\n<img src=\"https://s3.ax1x.com/2021/01/06/sAvMVg.png\" style=\"width:400px\"/>\n\n---\n\n<div style=\"page-break-after: always;\"></div>\n\n\n### 五、特点和创新\n\n1. **汇编器创新**：我们兼容现有的所有ys文件的基础上，还添加了一些伪指令和语法\n\n   1. 不需要写逗号了：现在所有的ys指令操作数之间可以使用空格隔开\n   2. mrmovq和rmmovq：现在不需要强制写括号，可以直接mov至常数地址（此时寄存器为RNONE，我们的CPU也做了相应的修改）如rmmovq %rax $800\n   3. 伪指令\n      1. .define 类似C语言的宏定义\n      2. .string \"mystring\" 将后面的mystring转化为对应的ASCII码写入\n      3. .byte .hword .word支持\n   4. 能够生成yo文件和yoraw文件，生成的yo文件比官方的yo文件漂亮不少，完全对齐\n   5. 有完整的命令行参数\n\n   ```\n   usage: yyas [-h] [-o OUTFILE] [-r] [-np] [-v] sourcefile\n   \n   yyas: Assemble .ys file to .yo file or/and .yo file to raw byte file\n   \n   positional arguments:\n     sourcefile            The source file to be assembled\n   \n   optional arguments:\n     -h, --help            show this help message and exit\n     -o OUTFILE, --output OUTFILE\n                           Assign the output file\n     -r, --raw             Generate raw byte file\n     -np, --noprefix       Do not generate prefix in raw output\n     -v, --version         show version\n   ```\n\n2. **处理器创新**（见具体实现）\n\n   1. 更好的分支预测器\n   2. 硬件栈\n   3. 几乎三倍的指令集支持（及其扩展含义）\n   4. 复杂指令集的多周期支持\n\n---\n\n### 六、总结与回顾\n\n#### PJ 心得总结及致谢\n\n本次 PJ 让我们更加深入的理解了现代流水线处理器的原理，各种硬件栈，扩展指令集的设计也拓展了我们的技术边缘，非常不错的体验。最后非常感谢助教和金老师一学期的辛苦工作。在很多方面帮助了我们，助教的 Lab 非常精彩有趣，金老师的课十分幽默风趣，非常感谢各位的付出。","slug":"ICS/ICS_PJ","published":1,"updated":"2021-01-06T02:36:52.512Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty3x000ts8pd2h0seurj","content":"<p><em>项目地址： <a href=\"https://github.com/fdu2019xzy/ICS_Y86\">https://github.com/fdu2019xzy/ICS_Y86</a></em></p>\n<hr>\n<h2 id=\"一、项目基本信息\"><a href=\"#一、项目基本信息\" class=\"headerlink\" title=\"一、项目基本信息\"></a>一、项目基本信息</h2><h3 id=\"1-项目简介\"><a href=\"#1-项目简介\" class=\"headerlink\" title=\"1. 项目简介\"></a>1. 项目简介</h3><p>Y86-Extended 是由谢子飏和王少文组队合作完成的项目，作为复旦大学 ICS (上) 的期末PJ，<br>本项目在实现了本项目在基础流水线处理器架构之上添加了<strong>更高级的分支预测</strong>、<strong>硬件栈</strong>、 <strong>y86 指令集扩展</strong>，并编写了一个<strong>汇编器</strong> yyas (支持宏定义)，以及其他特殊功能。结合精美的前端，根据上传文件性质不同 (yo/ys) 可以在普通模式和编译模式下运行程序, 具有较高的鲁棒性, 能够直观的看到基本信息、所有的寄存器信息 (包括流水线寄存器)、运行进度、当前指令和其他信息。</p>\n<p>支持任意<strong>前进回溯</strong>、<strong>设置断点</strong>、<strong>终端输出</strong> (包含<strong>彩色矩阵</strong>)等扩展功能</p>\n<h3 id=\"2-项目分工\"><a href=\"#2-项目分工\" class=\"headerlink\" title=\"2. 项目分工\"></a>2. 项目分工</h3><p>王少文：后端 CPU 主体设计及汇编器<br>谢子飏： (中) 前端及测试</p>\n<h3 id=\"3-项目架构及设计思路\"><a href=\"#3-项目架构及设计思路\" class=\"headerlink\" title=\"3. 项目架构及设计思路\"></a>3. 项目架构及设计思路</h3><p>我们的项目使用<strong>前后端分离</strong>开发策略，考虑到运行速度后端由 C++ 编写，中前端使用 Python, Vue.js, Js 开发。</p>\n<ul>\n<li>项目架构图</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvtMV.png\" style=\"width:500px\"></p>\n<ul>\n<li>交互逻辑和运行过程</li>\n</ul>\n<p>整个交互逻辑和运行过程分为，前端上传 ys/yo 文件 post 到中端的 lauch.py 的flask服务器，flask驱动编译器编译并将编译好的yo文件传到 CPU 中。CPU 按设计跑完输出 data.json 文件，前端 fetch 后端 CPU 生成的 data.json 在前端按操作逻辑进行展示。</p>\n<p>由于后端 C++ 跑的非常快，我们前端在上传后几乎能够即时获得 data, 而这样前后端分离的好处在于，我们前端可以非常自由的展现数据，所有的前进回溯甚至跳跃，都可以在 O(1) 内实现，不会出现很大的限制。</p>\n<hr>\n<h2 id=\"二、使用方式及功能详解\"><a href=\"#二、使用方式及功能详解\" class=\"headerlink\" title=\"二、使用方式及功能详解\"></a>二、使用方式及功能详解</h2><h3 id=\"1-具体使用方法\"><a href=\"#1-具体使用方法\" class=\"headerlink\" title=\"1. 具体使用方法\"></a>1. 具体使用方法</h3><p>(见项目目录下 README.md)</p>\n<h3 id=\"2-功能详解\"><a href=\"#2-功能详解\" class=\"headerlink\" title=\"2. 功能详解\"></a>2. 功能详解</h3><ul>\n<li>主体功能介绍图</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAv8Gn.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAv3Ps.png\" alt></p>\n<ul>\n<li>当前指令模块</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvV2t.png\" style=\"width:250px\"></p>\n<p>当前指令显示我们当前运行到的指令 (PC 所指)，并包含前后文2条指令的信息。</p>\n<p><strong>隐藏断点设置</strong></p>\n<p>为了前端的布局美观和统一性，断点设置被隐藏进了当前指令卡片中，点击当前指令卡片即可设置断点。</p>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvE8I.png\" style=\"width:400px\"></p>\n<p>可以任意设置增删断点</p>\n<ul>\n<li><strong>终端字符及彩色矩阵输出</strong></li>\n</ul>\n<p>根据后端的内存映射，我们可以让终端输出字符以及彩色矩阵。</p>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvJx0.png\" style=\"width:300px\"></p>\n<ul>\n<li>附带我们编写的 YYAS 汇编器，能够实现 ys 到 yo 的编译</li>\n</ul>\n<hr>\n<h2 id=\"三、代码详解\"><a href=\"#三、代码详解\" class=\"headerlink\" title=\"三、代码详解\"></a>三、代码详解</h2><h3 id=\"1-前端代码架构分析\"><a href=\"#1-前端代码架构分析\" class=\"headerlink\" title=\"1. 前端代码架构分析\"></a>1. 前端代码架构分析</h3><ul>\n<li>前端代码架构图</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvl5j.png\" alt></p>\n<p>前端设计采用 Vue.js 和前端框架 iView 设计，由于 Vue 的<strong>响应式渲染</strong>性质，非常适合我们本次的前端要求，同时为了保持多平台使用的可能性，Vue并没有使用脚手架，所有的 Vue.js、jQuery 都采用了 <strong>CDN 引入</strong>模式。</p>\n<p>其中 Index 是主页面入口，Index.js 包括 Vue app 的创建和 Vue 页面路由， Index.html 包含主页面的 DOM 树</p>\n<p>Pages 里面包含了主要的界面，主页面是 main.js 包含 cpu 的主要功能。<br>所有的 Pages 作为 export 模块被引入到 Index.js 中进行路由。<br>main.js 里面包含了 main 页面所有<strong>逻辑函数</strong>，<strong>声明周期钩子</strong>，以及 main 页面的 DOM 树， 其他页面也是同样架构。</p>\n<p>（由于是 CDN 引入 main 页面要插入路由的话， DOM 树应当是字符串形式传入 template 中）</p>\n<p>CSS 里面包含了所有主要的样式表，对功能和作用区域的不同做了简单的分类。</p>\n<p>Static 里面包含了需要读取的 Json data 信息，以及当前处理编译文件放置在 Source 中。</p>\n<ul>\n<li><strong>中台前后端链接代码</strong></li>\n</ul>\n<p>前后端连接使用的是 python flask 服务器，通过接前端上传表单的 post，将获得的文件传入编译器编译之后喂入 CPU 中，获得 data.json 前端再 getData。</p>\n<h3 id=\"2-后端代码架构分析\"><a href=\"#2-后端代码架构分析\" class=\"headerlink\" title=\"2. 后端代码架构分析\"></a>2. 后端代码架构分析</h3><ul>\n<li>后端代码架构图</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvQaQ.png\" alt></p>\n<ul>\n<li>汇编器部分<ul>\n<li>汇编器的可执行文件为yyas.py，这是包含了所有代码（不需要import）的最终文件，试试./yyas -v 和 ./yyas -h，有惊喜</li>\n<li>instr.py为Y86所有指令的信息（不含Y86 Extended的扩展部分）</li>\n<li>striper.py为Stage1时，将yo文件转化为yoraw的脚本，目前已经被弃用，仅作为存档提交。现在实现相同功能请使用./yyas -r -np</li>\n</ul>\n</li>\n<li>CPU部分<ul>\n<li>Controller.cpp 为CPU的控制器，主要包含了流水线的控制逻辑</li>\n<li>Device.cpp 为CPU流水线的核心，包含了FDEMW五个阶段的运行逻辑</li>\n<li>Output.cpp 有一些用于输出的函数，用于Stage1输出至命令行或Stage2输出至json文件</li>\n<li>Util.cpp包含了一些辅助的函数，例如In函数和Format函数（这里用了很多modern cpp的魔法）</li>\n</ul>\n</li>\n</ul>\n<hr>\n<div style=\"page-break-after: always;\"></div>\n\n<h2 id=\"四、-实现细节\"><a href=\"#四、-实现细节\" class=\"headerlink\" title=\"四、 实现细节\"></a>四、 实现细节</h2><h4 id=\"前端细节\"><a href=\"#前端细节\" class=\"headerlink\" title=\"前端细节\"></a>前端细节</h4><p>前端搭建了 anywhere 服务器 (用于解决跨域问题, 踩坑经历可以看第五节)，主要函数在 main.js 文件中， 通过各类声明周期函数和写的 handle 来处理上传，运行，停止，重置，以及断点设置等功能，此处不展开细讲，主要是后端。</p>\n<p>（前端使用了 anywhere 服务器 + 中端 flask 服务器的双服务器架构，其主要是因为我们前端在 import 模块时不开本地服务器会产生跨域问题。对于跨域问题我们最开始遇到是在获取 data.json 的时候，踩坑过程中我们曾尝试通过jsonp 解决跨域问题，并且成功了，但在 import 模块时再次遇到了跨域问题，为了一劳永逸，我们直接使用了 anywhere 直接开了一个本地服。）</p>\n<h4 id=\"后端细节\"><a href=\"#后端细节\" class=\"headerlink\" title=\"后端细节\"></a>后端细节</h4><ol>\n<li><p><strong>关于流水线</strong>：为了尽可能的靠近实际的硬件架构，我们的CPU核心实现分成了<strong>wire</strong>和<strong>reg</strong>两种struct，用来模拟verilog硬件语言中的wire和reg，reg是实际存在的寄存器，而wire只是用于逻辑中转。为了模拟CPU的并行化，我们采用了如下的逻辑</p>\n<ol>\n<li>利用Reg中的数据计算F D E M W，写入wire变量（实际不存在）</li>\n<li>利用现在的wire上的值，更新流水线及其他状态</li>\n<li>将wire的值写入下一个Reg，例如f_wire写入D_Reg，当流水线状态为NORMAL时回到a</li>\n</ol>\n</li>\n<li><p>每个阶段的具体实现逻辑， 与CSAPP上的电路实现差别不大，此处不再赘述</p>\n</li>\n<li><p><strong>关于扩展指令集</strong>：我们的指令集扩展见<strong>ISA.md</strong>，具体到流水线上只需少许修改各个阶段的逻辑，与官方设计思路差不太多，依次修改FDEMW就行。</p>\n</li>\n<li><p><strong>关于分支预测策略</strong>：我们的分支预测采用的是<strong>2比特溢出预测器</strong>，该预测器采用的逻辑如下图</p>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvG2q.png\" alt=\"预测器\"></p>\n<ol>\n<li>当JXX的信号不是Jmp时，更新上述的状态机</li>\n<li>若状态机信号为3或者2，则进行跳转</li>\n<li>若状态机信号为1或者0，则不进行跳转</li>\n</ol>\n<p>除此之外，我们也需要相应的改变分支错判的逻辑，需要加一个IfJump信号，当E阶段输出的信号与IfJump信号不同，说明分支预测错误，需要清空流水线。</p>\n<p>这样的分支预测器，据统计可以达到90%的正确率（<a href=\"https://en.wikipedia.org/wiki/Branch_predictor），在我们的测试中，一般情况下可以提升10%-30%的性能\">https://en.wikipedia.org/wiki/Branch_predictor），在我们的测试中，一般情况下可以提升10%-30%的性能</a></p>\n</li>\n<li><p><strong>关于复杂指令</strong>：在我们增加的指令中，有一些指令如mulq、divq和remq都是很耗时的指令，如果强行让他们在一个周期内完成，我们的CPU时钟频率就会非常低。因此我们假定这部分指令所需要的时间为其他指令最长耗时的10倍，在E阶段设置一个counter，建立一个递减的状态机，使用下面的控制逻辑</p>\n<ol>\n<li>如果指令属于上述复杂指令，将状态机置于10</li>\n<li>如果状态机不为0，则使F D阶段进入STALL阶段，E阶段继续计算，但阻断E到M的输入，状态机减1</li>\n<li>如果状态机为0，则流水线继续执行</li>\n</ol>\n<p>这样就可以实现维持较高CPU频率的同时，实现复杂指令。（即不会因为加了这个指令使其他指令的执行变慢）</p>\n</li>\n<li><p><strong>关于硬件栈</strong>：为了避免每次调用ret指令时两个时钟周期的浪费，我们采用了CSAPP上的硬件栈。在硬件上，硬件栈可以由多路选择器和多个寄存器构成，在这里我们简单的使用Stack实现（大小为0x20）。采用如下的控制逻辑：</p>\n<ol>\n<li>如果调用call指令，在栈没有满时，将地址载入硬件栈</li>\n<li>如果调用ret指令，在栈非空时，弹栈，将值读出</li>\n<li>在M阶段执行后，判断硬件栈的预测是否正确<ol>\n<li>若正确，则继续执行</li>\n<li>若不正确，则清空 F D E的流水线</li>\n</ol>\n</li>\n</ol>\n<p>使用硬件栈后，最差的情况即是与无硬件栈情况相同，最好情况在我们的测试中，可以增加30%+的性能。</p>\n</li>\n<li><p>关于指令不可写和非指令不可读保护：我们的汇编器会计算yo文件中，最后一个是指令的位置，在CPU运行时，会进行动态的判断</p>\n<ol>\n<li>在Fetch阶段读取不可读的位置，会产生INS错误</li>\n<li>在其他阶段写入不可写的位置，会产生ADR错误</li>\n</ol>\n</li>\n<li><p>关于宏定义：为了CPU的扩展性和兼容性，我们使用了宏定义来动态的开关某些特性，例如 <code>OUTPUT_JSON</code> 宏定义后即可输出 data_json 供前端使用。</p>\n</li>\n</ol>\n<h4 id=\"汇编器细节\"><a href=\"#汇编器细节\" class=\"headerlink\" title=\"汇编器细节\"></a>汇编器细节</h4><p>我们的汇编器采用了依次处理的方式，如下(Code Explains itself)</p>\n<pre><code class=\"hljs python\">lines = gen_list(lines) <span class=\"hljs-comment\">#解析关键词</span>\nlines = remove_single_line_annot(lines) <span class=\"hljs-comment\">#去除单行注释</span>\nlines = remove_multi_line_annot(lines) <span class=\"hljs-comment\">#去除多行注释</span>\nlines = detach_label(lines) <span class=\"hljs-comment\">#找到对应的label</span>\nlines_ref = copy.deepcopy(lines) <span class=\"hljs-comment\">#复制一份用于输出</span>\nmem = get_memaddr(lines) <span class=\"hljs-comment\">#找到内存对应的地址</span>\nlabels = get_def_label(lines) <span class=\"hljs-comment\">#处理.define</span>\nlines = replace_label(lines, mem, labels) <span class=\"hljs-comment\">#处理label</span>\nbyte_code = gen_byte_code(lines) <span class=\"hljs-comment\">#产生yo代码</span></code></pre>\n<h4 id=\"测试细节\"><a href=\"#测试细节\" class=\"headerlink\" title=\"测试细节\"></a>测试细节</h4><p>我们采用Google Test 和 Python Unitest来辅助我们进行我们的程序测试。其在我们项目文件的 test 文件夹下，我们通过 shell 脚本和 python 脚本将模拟器的输出进行处理，转换成 gtest 代码以便于我们进行测试。</p>\n<p>基本语句即为 <code>EXPECT_EQ(x, y)</code></p>\n<ul>\n<li>测试代码结构</li>\n</ul>\n<p><img src=\"/2021/01/06/ICS/ICS_PJ/测试代码架构.png\" alt></p>\n<p>使用 Google Test 我们能够清晰的看到测试点信息。</p>\n<ul>\n<li>普通 yo_test</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvZxP.png\" style=\"width:300px\"></p>\n<ul>\n<li>Hornor 测试</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvmKf.png\" style=\"width:300px\"></p>\n<ul>\n<li>附加测试</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvMVg.png\" style=\"width:400px\"></p>\n<hr>\n<div style=\"page-break-after: always;\"></div>\n\n\n<h3 id=\"五、特点和创新\"><a href=\"#五、特点和创新\" class=\"headerlink\" title=\"五、特点和创新\"></a>五、特点和创新</h3><ol>\n<li><p><strong>汇编器创新</strong>：我们兼容现有的所有ys文件的基础上，还添加了一些伪指令和语法</p>\n<ol>\n<li>不需要写逗号了：现在所有的ys指令操作数之间可以使用空格隔开</li>\n<li>mrmovq和rmmovq：现在不需要强制写括号，可以直接mov至常数地址（此时寄存器为RNONE，我们的CPU也做了相应的修改）如rmmovq %rax $800</li>\n<li>伪指令<ol>\n<li>.define 类似C语言的宏定义</li>\n<li>.string “mystring” 将后面的mystring转化为对应的ASCII码写入</li>\n<li>.byte .hword .word支持</li>\n</ol>\n</li>\n<li>能够生成yo文件和yoraw文件，生成的yo文件比官方的yo文件漂亮不少，完全对齐</li>\n<li>有完整的命令行参数</li>\n</ol>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">usage</span>: yyas [-h] [-o OUTFILE] [-r] [-np] [-v] sourcefile\n\n<span class=\"hljs-attribute\">yyas</span>: Assemble .ys file to .yo file or/and .yo file to raw byte file\n\npositional arguments:\n  sourcefile            The source file to be assembled\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -o OUTFILE, --output OUTFILE\n                        Assign the output file\n  -r, --raw             Generate raw byte file\n  -np, --noprefix       Do not generate prefix in raw output\n  -v, --version         show version</code></pre>\n</li>\n<li><p><strong>处理器创新</strong>（见具体实现）</p>\n<ol>\n<li>更好的分支预测器</li>\n<li>硬件栈</li>\n<li>几乎三倍的指令集支持（及其扩展含义）</li>\n<li>复杂指令集的多周期支持</li>\n</ol>\n</li>\n</ol>\n<hr>\n<h3 id=\"六、总结与回顾\"><a href=\"#六、总结与回顾\" class=\"headerlink\" title=\"六、总结与回顾\"></a>六、总结与回顾</h3><h4 id=\"PJ-心得总结及致谢\"><a href=\"#PJ-心得总结及致谢\" class=\"headerlink\" title=\"PJ 心得总结及致谢\"></a>PJ 心得总结及致谢</h4><p>本次 PJ 让我们更加深入的理解了现代流水线处理器的原理，各种硬件栈，扩展指令集的设计也拓展了我们的技术边缘，非常不错的体验。最后非常感谢助教和金老师一学期的辛苦工作。在很多方面帮助了我们，助教的 Lab 非常精彩有趣，金老师的课十分幽默风趣，非常感谢各位的付出。</p>\n","site":{"data":{}},"excerpt":"","more":"<p><em>项目地址： <a href=\"https://github.com/fdu2019xzy/ICS_Y86\">https://github.com/fdu2019xzy/ICS_Y86</a></em></p>\n<hr>\n<h2 id=\"一、项目基本信息\"><a href=\"#一、项目基本信息\" class=\"headerlink\" title=\"一、项目基本信息\"></a>一、项目基本信息</h2><h3 id=\"1-项目简介\"><a href=\"#1-项目简介\" class=\"headerlink\" title=\"1. 项目简介\"></a>1. 项目简介</h3><p>Y86-Extended 是由谢子飏和王少文组队合作完成的项目，作为复旦大学 ICS (上) 的期末PJ，<br>本项目在实现了本项目在基础流水线处理器架构之上添加了<strong>更高级的分支预测</strong>、<strong>硬件栈</strong>、 <strong>y86 指令集扩展</strong>，并编写了一个<strong>汇编器</strong> yyas (支持宏定义)，以及其他特殊功能。结合精美的前端，根据上传文件性质不同 (yo/ys) 可以在普通模式和编译模式下运行程序, 具有较高的鲁棒性, 能够直观的看到基本信息、所有的寄存器信息 (包括流水线寄存器)、运行进度、当前指令和其他信息。</p>\n<p>支持任意<strong>前进回溯</strong>、<strong>设置断点</strong>、<strong>终端输出</strong> (包含<strong>彩色矩阵</strong>)等扩展功能</p>\n<h3 id=\"2-项目分工\"><a href=\"#2-项目分工\" class=\"headerlink\" title=\"2. 项目分工\"></a>2. 项目分工</h3><p>王少文：后端 CPU 主体设计及汇编器<br>谢子飏： (中) 前端及测试</p>\n<h3 id=\"3-项目架构及设计思路\"><a href=\"#3-项目架构及设计思路\" class=\"headerlink\" title=\"3. 项目架构及设计思路\"></a>3. 项目架构及设计思路</h3><p>我们的项目使用<strong>前后端分离</strong>开发策略，考虑到运行速度后端由 C++ 编写，中前端使用 Python, Vue.js, Js 开发。</p>\n<ul>\n<li>项目架构图</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvtMV.png\" style=\"width:500px\"></p>\n<ul>\n<li>交互逻辑和运行过程</li>\n</ul>\n<p>整个交互逻辑和运行过程分为，前端上传 ys/yo 文件 post 到中端的 lauch.py 的flask服务器，flask驱动编译器编译并将编译好的yo文件传到 CPU 中。CPU 按设计跑完输出 data.json 文件，前端 fetch 后端 CPU 生成的 data.json 在前端按操作逻辑进行展示。</p>\n<p>由于后端 C++ 跑的非常快，我们前端在上传后几乎能够即时获得 data, 而这样前后端分离的好处在于，我们前端可以非常自由的展现数据，所有的前进回溯甚至跳跃，都可以在 O(1) 内实现，不会出现很大的限制。</p>\n<hr>\n<h2 id=\"二、使用方式及功能详解\"><a href=\"#二、使用方式及功能详解\" class=\"headerlink\" title=\"二、使用方式及功能详解\"></a>二、使用方式及功能详解</h2><h3 id=\"1-具体使用方法\"><a href=\"#1-具体使用方法\" class=\"headerlink\" title=\"1. 具体使用方法\"></a>1. 具体使用方法</h3><p>(见项目目录下 README.md)</p>\n<h3 id=\"2-功能详解\"><a href=\"#2-功能详解\" class=\"headerlink\" title=\"2. 功能详解\"></a>2. 功能详解</h3><ul>\n<li>主体功能介绍图</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAv8Gn.png\" alt></p>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAv3Ps.png\" alt></p>\n<ul>\n<li>当前指令模块</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvV2t.png\" style=\"width:250px\"></p>\n<p>当前指令显示我们当前运行到的指令 (PC 所指)，并包含前后文2条指令的信息。</p>\n<p><strong>隐藏断点设置</strong></p>\n<p>为了前端的布局美观和统一性，断点设置被隐藏进了当前指令卡片中，点击当前指令卡片即可设置断点。</p>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvE8I.png\" style=\"width:400px\"></p>\n<p>可以任意设置增删断点</p>\n<ul>\n<li><strong>终端字符及彩色矩阵输出</strong></li>\n</ul>\n<p>根据后端的内存映射，我们可以让终端输出字符以及彩色矩阵。</p>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvJx0.png\" style=\"width:300px\"></p>\n<ul>\n<li>附带我们编写的 YYAS 汇编器，能够实现 ys 到 yo 的编译</li>\n</ul>\n<hr>\n<h2 id=\"三、代码详解\"><a href=\"#三、代码详解\" class=\"headerlink\" title=\"三、代码详解\"></a>三、代码详解</h2><h3 id=\"1-前端代码架构分析\"><a href=\"#1-前端代码架构分析\" class=\"headerlink\" title=\"1. 前端代码架构分析\"></a>1. 前端代码架构分析</h3><ul>\n<li>前端代码架构图</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvl5j.png\" alt></p>\n<p>前端设计采用 Vue.js 和前端框架 iView 设计，由于 Vue 的<strong>响应式渲染</strong>性质，非常适合我们本次的前端要求，同时为了保持多平台使用的可能性，Vue并没有使用脚手架，所有的 Vue.js、jQuery 都采用了 <strong>CDN 引入</strong>模式。</p>\n<p>其中 Index 是主页面入口，Index.js 包括 Vue app 的创建和 Vue 页面路由， Index.html 包含主页面的 DOM 树</p>\n<p>Pages 里面包含了主要的界面，主页面是 main.js 包含 cpu 的主要功能。<br>所有的 Pages 作为 export 模块被引入到 Index.js 中进行路由。<br>main.js 里面包含了 main 页面所有<strong>逻辑函数</strong>，<strong>声明周期钩子</strong>，以及 main 页面的 DOM 树， 其他页面也是同样架构。</p>\n<p>（由于是 CDN 引入 main 页面要插入路由的话， DOM 树应当是字符串形式传入 template 中）</p>\n<p>CSS 里面包含了所有主要的样式表，对功能和作用区域的不同做了简单的分类。</p>\n<p>Static 里面包含了需要读取的 Json data 信息，以及当前处理编译文件放置在 Source 中。</p>\n<ul>\n<li><strong>中台前后端链接代码</strong></li>\n</ul>\n<p>前后端连接使用的是 python flask 服务器，通过接前端上传表单的 post，将获得的文件传入编译器编译之后喂入 CPU 中，获得 data.json 前端再 getData。</p>\n<h3 id=\"2-后端代码架构分析\"><a href=\"#2-后端代码架构分析\" class=\"headerlink\" title=\"2. 后端代码架构分析\"></a>2. 后端代码架构分析</h3><ul>\n<li>后端代码架构图</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvQaQ.png\" alt></p>\n<ul>\n<li>汇编器部分<ul>\n<li>汇编器的可执行文件为yyas.py，这是包含了所有代码（不需要import）的最终文件，试试./yyas -v 和 ./yyas -h，有惊喜</li>\n<li>instr.py为Y86所有指令的信息（不含Y86 Extended的扩展部分）</li>\n<li>striper.py为Stage1时，将yo文件转化为yoraw的脚本，目前已经被弃用，仅作为存档提交。现在实现相同功能请使用./yyas -r -np</li>\n</ul>\n</li>\n<li>CPU部分<ul>\n<li>Controller.cpp 为CPU的控制器，主要包含了流水线的控制逻辑</li>\n<li>Device.cpp 为CPU流水线的核心，包含了FDEMW五个阶段的运行逻辑</li>\n<li>Output.cpp 有一些用于输出的函数，用于Stage1输出至命令行或Stage2输出至json文件</li>\n<li>Util.cpp包含了一些辅助的函数，例如In函数和Format函数（这里用了很多modern cpp的魔法）</li>\n</ul>\n</li>\n</ul>\n<hr>\n<div style=\"page-break-after: always;\"></div>\n\n<h2 id=\"四、-实现细节\"><a href=\"#四、-实现细节\" class=\"headerlink\" title=\"四、 实现细节\"></a>四、 实现细节</h2><h4 id=\"前端细节\"><a href=\"#前端细节\" class=\"headerlink\" title=\"前端细节\"></a>前端细节</h4><p>前端搭建了 anywhere 服务器 (用于解决跨域问题, 踩坑经历可以看第五节)，主要函数在 main.js 文件中， 通过各类声明周期函数和写的 handle 来处理上传，运行，停止，重置，以及断点设置等功能，此处不展开细讲，主要是后端。</p>\n<p>（前端使用了 anywhere 服务器 + 中端 flask 服务器的双服务器架构，其主要是因为我们前端在 import 模块时不开本地服务器会产生跨域问题。对于跨域问题我们最开始遇到是在获取 data.json 的时候，踩坑过程中我们曾尝试通过jsonp 解决跨域问题，并且成功了，但在 import 模块时再次遇到了跨域问题，为了一劳永逸，我们直接使用了 anywhere 直接开了一个本地服。）</p>\n<h4 id=\"后端细节\"><a href=\"#后端细节\" class=\"headerlink\" title=\"后端细节\"></a>后端细节</h4><ol>\n<li><p><strong>关于流水线</strong>：为了尽可能的靠近实际的硬件架构，我们的CPU核心实现分成了<strong>wire</strong>和<strong>reg</strong>两种struct，用来模拟verilog硬件语言中的wire和reg，reg是实际存在的寄存器，而wire只是用于逻辑中转。为了模拟CPU的并行化，我们采用了如下的逻辑</p>\n<ol>\n<li>利用Reg中的数据计算F D E M W，写入wire变量（实际不存在）</li>\n<li>利用现在的wire上的值，更新流水线及其他状态</li>\n<li>将wire的值写入下一个Reg，例如f_wire写入D_Reg，当流水线状态为NORMAL时回到a</li>\n</ol>\n</li>\n<li><p>每个阶段的具体实现逻辑， 与CSAPP上的电路实现差别不大，此处不再赘述</p>\n</li>\n<li><p><strong>关于扩展指令集</strong>：我们的指令集扩展见<strong>ISA.md</strong>，具体到流水线上只需少许修改各个阶段的逻辑，与官方设计思路差不太多，依次修改FDEMW就行。</p>\n</li>\n<li><p><strong>关于分支预测策略</strong>：我们的分支预测采用的是<strong>2比特溢出预测器</strong>，该预测器采用的逻辑如下图</p>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvG2q.png\" alt=\"预测器\"></p>\n<ol>\n<li>当JXX的信号不是Jmp时，更新上述的状态机</li>\n<li>若状态机信号为3或者2，则进行跳转</li>\n<li>若状态机信号为1或者0，则不进行跳转</li>\n</ol>\n<p>除此之外，我们也需要相应的改变分支错判的逻辑，需要加一个IfJump信号，当E阶段输出的信号与IfJump信号不同，说明分支预测错误，需要清空流水线。</p>\n<p>这样的分支预测器，据统计可以达到90%的正确率（<a href=\"https://en.wikipedia.org/wiki/Branch_predictor），在我们的测试中，一般情况下可以提升10%-30%的性能\">https://en.wikipedia.org/wiki/Branch_predictor），在我们的测试中，一般情况下可以提升10%-30%的性能</a></p>\n</li>\n<li><p><strong>关于复杂指令</strong>：在我们增加的指令中，有一些指令如mulq、divq和remq都是很耗时的指令，如果强行让他们在一个周期内完成，我们的CPU时钟频率就会非常低。因此我们假定这部分指令所需要的时间为其他指令最长耗时的10倍，在E阶段设置一个counter，建立一个递减的状态机，使用下面的控制逻辑</p>\n<ol>\n<li>如果指令属于上述复杂指令，将状态机置于10</li>\n<li>如果状态机不为0，则使F D阶段进入STALL阶段，E阶段继续计算，但阻断E到M的输入，状态机减1</li>\n<li>如果状态机为0，则流水线继续执行</li>\n</ol>\n<p>这样就可以实现维持较高CPU频率的同时，实现复杂指令。（即不会因为加了这个指令使其他指令的执行变慢）</p>\n</li>\n<li><p><strong>关于硬件栈</strong>：为了避免每次调用ret指令时两个时钟周期的浪费，我们采用了CSAPP上的硬件栈。在硬件上，硬件栈可以由多路选择器和多个寄存器构成，在这里我们简单的使用Stack实现（大小为0x20）。采用如下的控制逻辑：</p>\n<ol>\n<li>如果调用call指令，在栈没有满时，将地址载入硬件栈</li>\n<li>如果调用ret指令，在栈非空时，弹栈，将值读出</li>\n<li>在M阶段执行后，判断硬件栈的预测是否正确<ol>\n<li>若正确，则继续执行</li>\n<li>若不正确，则清空 F D E的流水线</li>\n</ol>\n</li>\n</ol>\n<p>使用硬件栈后，最差的情况即是与无硬件栈情况相同，最好情况在我们的测试中，可以增加30%+的性能。</p>\n</li>\n<li><p>关于指令不可写和非指令不可读保护：我们的汇编器会计算yo文件中，最后一个是指令的位置，在CPU运行时，会进行动态的判断</p>\n<ol>\n<li>在Fetch阶段读取不可读的位置，会产生INS错误</li>\n<li>在其他阶段写入不可写的位置，会产生ADR错误</li>\n</ol>\n</li>\n<li><p>关于宏定义：为了CPU的扩展性和兼容性，我们使用了宏定义来动态的开关某些特性，例如 <code>OUTPUT_JSON</code> 宏定义后即可输出 data_json 供前端使用。</p>\n</li>\n</ol>\n<h4 id=\"汇编器细节\"><a href=\"#汇编器细节\" class=\"headerlink\" title=\"汇编器细节\"></a>汇编器细节</h4><p>我们的汇编器采用了依次处理的方式，如下(Code Explains itself)</p>\n<pre><code class=\"hljs python\">lines = gen_list(lines) <span class=\"hljs-comment\">#解析关键词</span>\nlines = remove_single_line_annot(lines) <span class=\"hljs-comment\">#去除单行注释</span>\nlines = remove_multi_line_annot(lines) <span class=\"hljs-comment\">#去除多行注释</span>\nlines = detach_label(lines) <span class=\"hljs-comment\">#找到对应的label</span>\nlines_ref = copy.deepcopy(lines) <span class=\"hljs-comment\">#复制一份用于输出</span>\nmem = get_memaddr(lines) <span class=\"hljs-comment\">#找到内存对应的地址</span>\nlabels = get_def_label(lines) <span class=\"hljs-comment\">#处理.define</span>\nlines = replace_label(lines, mem, labels) <span class=\"hljs-comment\">#处理label</span>\nbyte_code = gen_byte_code(lines) <span class=\"hljs-comment\">#产生yo代码</span></code></pre>\n<h4 id=\"测试细节\"><a href=\"#测试细节\" class=\"headerlink\" title=\"测试细节\"></a>测试细节</h4><p>我们采用Google Test 和 Python Unitest来辅助我们进行我们的程序测试。其在我们项目文件的 test 文件夹下，我们通过 shell 脚本和 python 脚本将模拟器的输出进行处理，转换成 gtest 代码以便于我们进行测试。</p>\n<p>基本语句即为 <code>EXPECT_EQ(x, y)</code></p>\n<ul>\n<li>测试代码结构</li>\n</ul>\n<p><img src=\"/2021/01/06/ICS/ICS_PJ/测试代码架构.png\" alt></p>\n<p>使用 Google Test 我们能够清晰的看到测试点信息。</p>\n<ul>\n<li>普通 yo_test</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvZxP.png\" style=\"width:300px\"></p>\n<ul>\n<li>Hornor 测试</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvmKf.png\" style=\"width:300px\"></p>\n<ul>\n<li>附加测试</li>\n</ul>\n<p><img src=\"https://s3.ax1x.com/2021/01/06/sAvMVg.png\" style=\"width:400px\"></p>\n<hr>\n<div style=\"page-break-after: always;\"></div>\n\n\n<h3 id=\"五、特点和创新\"><a href=\"#五、特点和创新\" class=\"headerlink\" title=\"五、特点和创新\"></a>五、特点和创新</h3><ol>\n<li><p><strong>汇编器创新</strong>：我们兼容现有的所有ys文件的基础上，还添加了一些伪指令和语法</p>\n<ol>\n<li>不需要写逗号了：现在所有的ys指令操作数之间可以使用空格隔开</li>\n<li>mrmovq和rmmovq：现在不需要强制写括号，可以直接mov至常数地址（此时寄存器为RNONE，我们的CPU也做了相应的修改）如rmmovq %rax $800</li>\n<li>伪指令<ol>\n<li>.define 类似C语言的宏定义</li>\n<li>.string “mystring” 将后面的mystring转化为对应的ASCII码写入</li>\n<li>.byte .hword .word支持</li>\n</ol>\n</li>\n<li>能够生成yo文件和yoraw文件，生成的yo文件比官方的yo文件漂亮不少，完全对齐</li>\n<li>有完整的命令行参数</li>\n</ol>\n<pre><code class=\"hljs\"><span class=\"hljs-attribute\">usage</span>: yyas [-h] [-o OUTFILE] [-r] [-np] [-v] sourcefile\n\n<span class=\"hljs-attribute\">yyas</span>: Assemble .ys file to .yo file or/and .yo file to raw byte file\n\npositional arguments:\n  sourcefile            The source file to be assembled\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -o OUTFILE, --output OUTFILE\n                        Assign the output file\n  -r, --raw             Generate raw byte file\n  -np, --noprefix       Do not generate prefix in raw output\n  -v, --version         show version</code></pre>\n</li>\n<li><p><strong>处理器创新</strong>（见具体实现）</p>\n<ol>\n<li>更好的分支预测器</li>\n<li>硬件栈</li>\n<li>几乎三倍的指令集支持（及其扩展含义）</li>\n<li>复杂指令集的多周期支持</li>\n</ol>\n</li>\n</ol>\n<hr>\n<h3 id=\"六、总结与回顾\"><a href=\"#六、总结与回顾\" class=\"headerlink\" title=\"六、总结与回顾\"></a>六、总结与回顾</h3><h4 id=\"PJ-心得总结及致谢\"><a href=\"#PJ-心得总结及致谢\" class=\"headerlink\" title=\"PJ 心得总结及致谢\"></a>PJ 心得总结及致谢</h4><p>本次 PJ 让我们更加深入的理解了现代流水线处理器的原理，各种硬件栈，扩展指令集的设计也拓展了我们的技术边缘，非常不错的体验。最后非常感谢助教和金老师一学期的辛苦工作。在很多方面帮助了我们，助教的 Lab 非常精彩有趣，金老师的课十分幽默风趣，非常感谢各位的付出。</p>\n"},{"title":"ICS-Lab2 二进制炸弹","index_img":"/img/ICS_Lab1/top.jpg","date":"2020-11-06T07:44:39.000Z","_content":"\n# ICS-Lab2-Bomb\n\n> 这个是CS:APP的第二个lab，主要着重于汇编代码的阅读\n\n***\n\n## 完成截图\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_244e1f55d2823d58f65eabab9478d7ce.png></img>\n\n***\n\n## Phase 1 - 入门\n### 一、分析\n\n> 练手入门题，用esi寄存器储存答案地址 (一个立即数)\n```\nmov    $0x402400,%esi\n```\n> 之后调用了一个 string_not_equal 函数比较输入和答案是否一致，一致就通过了。\n```\ncallq  401338 <strings_not_equal>\n```\n\n### 二、gdb调试\n> 看一下内存地址里面存了什么，获得flag\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_4801c7e177c56f6e7299c273d0120988.png></img>\n\n\n- **答案**: Border relations with Canada have never been better.\n\n***\n\n## Phase 2 - 循环\n### 分析\n\n> 本题是一个do while Loop, 难度不大, 耐心读就行了\n\n**关键位置**\n- 信息1 ： 看到 read_six_number 知道输入6个数，再往下看\n\n```\ncmpl   $0x1,(%rsp) # 比较栈顶地址所存变量大小是否为1\nje     400f30 <phase_2+0x34> # 如果为1 跳转至地址 400f30\ncallq  40143a <explode_bomb> # 如果不为1，直接炸了\njmp    400f30 <phase_2+0x34> # 跳转至地址 400f30\n```\n\n- 信息2 : 第一个数为1\n\n下面进入Loop Body\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_27148224f8cf2be48266eaa52f50b2f8.png></img>\n\n- 信息3 : \n可以看到这个循环把前一个数乘了2，跟后一个数比较, 如果相等就能够继续，不然就炸了。\n\n> 综上也就是说这是一个首项为1，公比为2的等比数列，共6项。\n\n所以答案就是 1 2 4 8 16 32\n\n***\n\n## Phase 3 - 分支\n### 分析\n\n> 第三题关键点在于用gdb查看一下jumptable\n\n 我们先看一下输入，在输入了两个变量后，esi里放了内存中的一个可疑的东西，我们用gdb看一眼。\n```\nmov    $0x4025cf,%esi\n```\n\n```shell=\n(gdb) p(char *) 0x4025cf\n\"%d %d\"\n```\n\n 发现原来是输入两个整型，再往下看\n\n```\ncmpl   $0x7,0x8(%rsp) # 将 M(rsp + 8) 看作32位无符号数跟7比较\nja     400fad <phase_3+0x6a> # 如果大于就跳转至 0x400fad (炸弹炸了)\n```\n\n 发现如果输入的第一个数大于7就爆炸了，看来switch最多只有7个case\n\n```\njmpq   *0x402470(,%rax,8) \n# 跳转至 (eax * 8 + 0x402470)处所存的地址 （jumptable）\n```\n\n> 最关键的是这一句，构造了一个 switch 的 jumptable，我们知道地址是 0x402470，按照 case * 8 + 0x402470 跳转到该地址里面的地址，所以我们用gdb看一下。\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_ae5e359c30ff5ccb9292a7472c39eb19.png></img>\n\n- 我通关选了case 1（它比较特殊，处理它其他内存地址跳转都是按case从小到大顺序的，只有case 1 在最后一个，当然其他也都能过。）\n\n- case 1 跳转到了 0x400fb9 地址\n\n```\nmov    $0x137,%eax \n# eax = 0x137 (311) (不用跳转了，下面就是 0x400fbe)\n```\n\n其将eax置为了0x137，要小心是16进制，所以对应十进制311\n\n```\ncmp    0xc(%rsp),%eax # 比较 M(rsp + 12) 和 eax\nje     400fc9 <phase_3+0x86> # 如果相等就跳转至 0x400fc9 (过关了！)\n```\n\n最后是一个比较，如果eax和第二个输入值相同就过了。\n\n- 本题答案（不唯一)\n\n| case | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 |\n| :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: |\n| ans | 207 | 311 | 707 | 256 | 389 | 206 | 682 | 327 |\n\n\n***\n\n## Phase 4 - 递归\n### 分析\n- 这题是个递归，不过不用很深，很快就能看出答案。\n\n先正常读两个数，放在rdx，rcx中，检查输入。\n\n```\ncmpl   $0xe,0x8(%rsp) \n# 比较 M(rsp + 8) (既 rdx) 与 0xe\njbe    40103a <phase_4+0x2e> \n# 如果 rdx <= 0xe (14) 跳转至 0x40103a, 不然就炸了 (作为无符号数)\n```\n\n> 这两行汇编告诉我们，rdx一定要小于 0xe (14) 且大于等于0, 不然炸了, 大幅度缩小了范围。\n\n> 接下来就进入了函数递归调用，先做点预处理，把edx里面存一个立即数14，然后edi为第一个输入值，esi = 0 进入fun4\n\n```\nmov    $0xe,%edx # edx = 0xe (14)\nmov    $0x0,%esi # esi = 0\nmov    0x8(%rsp),%edi # edi = (第一个输入值)\ncallq  400fce <func4> # 调用func4\n```\n> 先不着急看fun4，先看看最后要怎么过关\n```\ntest   %eax,%eax # eax & eax\njne    401058 <phase_4+0x4c> \n# 如果ZF == 0 就跳转（既eax != 0)，跳转至 0x401058 炸了\ncmpl   $0x0,0xc(%rsp) # 比较 M(rsp + 12) 和 0\nje     40105d <phase_4+0x51> # 如果相等就跳转到 0x40105d, 不然就炸了\n```\n- test 实际上就是一个与操作，所以我们知道需要 eax == 0 且 M(rsp + 12) == 0，到这我们发现，第二个条件只要我们一开始输入的第二个参数为0，就能够保证，那么下面我们就要看进入fun4之后如何让返回值 eax == 0\n\n> 再回来看fun4，其分为两部分，一个是递归的主体，一个是判断是否继续递归。一开始先对eax 和 ecx 进行一些操作。\n- 我们发现 eax 和 ecx 的值在第一层递归都被置为14，(esi 为 0)按其操作得到 eax 除2, ecx 逻辑右移 31 位为0, 接着其实就是比较 edi 和 rax, **相当于就是比较第一个参数和常数 7**\n\n```\njle    400ff2 <func4+0x24> # 若ecx <= 就跳转至 0x400ff2\n```\n```\nmov    $0x0,%eax # eax = 0;\ncmp    %edi,%ecx # 比较 ecx 和 edi \njge    401007 <func4+0x39> \n# 若 edi >= ecx 跳转至 0x401007 返回\n```\n\n- 接着是一个跳转, 如果满足我们就跳转至 0x400ff2, 我们发现这里已经满足了我们需要的 eax == 0，而想要结束就得使 edi >= ecx (7), 所以我们发现，对于上下两个跳转条件，只要 edi == ecx == 7 就能一直成立，从而直接达成条件，不用进入递归。\n\n进而我们得到了本题答案：7 0\n\n***\n\n## Phase 5 - 指针\n### 分析\n- 这题我觉得是最好玩的一题，先直接分析如何通关。\n\n```\nmov    $0x40245e,%esi # esi = 0x40245e \n# 待比较的 string (flyers) 从 0x40245e 移动至 esi\n```\n\n- 我们在接近返回时看到了一个非常可疑的内存地址，直接给它打出来。\n\n```\n(gdb) p(char*) 0x40245e\n$4 = 0x40245e \"flyers\"\n```\n\n> 发现是一个可疑字符串 flyers，阅读上下文汇编代码可知，最后是比较字符串是否和指定字符串 \"flyers\" 一致。\n\n- 我们再往上看看要怎么输入\n\n```\ncallq  40131b <string_length> # 比较字符长度是否为6\ncmp    $0x6,%eax # 比较 eax 和 6\n```\n\n发现输入一定要是六个字符 *(于是试了试 flyers 果然不对)*\n\n- 往下看，发现了一个 Loop 循环了6次\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_016df1440f7044a54fb4ced529595b58.png></img>\n\n> 经过仔细阅读后，发现这个居然是遍历六个输入字符，将其 ascii 码低4位取出来作为偏移量 (offset),在一个基地址 （0x4024b0）后面取字符出来组成 flyers.\n\n- 立刻开启 gdb 查看基地址附近的内存\n\n**发现分别对应的偏移量是 9, 15, 14, 5, 6, 7**\n> 直接查 ascii 码，发现对应 ionefg 、IONEFG 或者有一些不是字母的字符也行，只要低四位是正确的就可以。 \n\n**本题答案:**  ionefg (答案不唯一)\n\n***\n\n## Phase 6 - Node结构体\n### 分析\n这题还是比较麻烦的，代码比较长也比较复杂，要耐心读。\n\n- 这题的代码可以大致分为输入检测与处理和一个对结构体的顺序检测.\n> 最开始上来先输入六个数之后有个双循环，外部保证输入的六个数要大于等于1，且小于等于6，内部保证互异。所以总体看来就是输入的六个数就是123456, 现在问题是输入的顺序。\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_7194e52688ff3d696a3b889e2b17d63f.png></img>\n\n这段代码遍历了所有输入并用7减去了输入的每个数，所以最后做出答案要记得反一下。\n\n- 接下来代码比较复杂，外面大循环循环了六次，内部有两个平行的小循环。作用是构造结构体，并在栈帧中将其存放位置按照输入的数的大小计算得出\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_9ea5cd30293a18357af1da93c35e0f59.png></img>\n\n\n> 分析代码，我们先发现一种特殊情况就是当前计算的数为1时（输入为6）edx直接就是给定的地址 0x6032d0, 其余的都按照其大小，在第一个小循环中循环相应次数，给 rdx 在原地址上相应偏移16位。\n\n> 接着下来将其存入栈帧中 rsp + 32 到 rsp + 80 的位置\n\n- 使用 gdb 查看 node\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_f2ecdd05728cbefbba59b068a29fdfdc.png></img>\n\n\n最后我们看如何通关\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_a18a67d1b4dbfa16a7fd8800e3ee304b.png></img>\n\n> 发现通关条件是要求定序，前面node大于后面的节点，根据gdb node节点的值和要求我们得到了 3 4 5 6 1 2 的结果，最后不要忘记这是被7减过之后的结果，原来的输入要还原。所以答案就是 4 3 2 1 6 5\n\n**本题答案:** 4 3 2 1 6 5\n\n***\n\n## Secret Phase- 递归\n### 一、进入方法\n- 输入上面六种答案之后，发现 secret phase 并没有出现，于是开始着手寻找入口。\n\n> 根据最后结果出现的字符顺藤摸瓜找到了 phase_defuse 函数，一看发现其中有一个可疑的 <string_not_equal> 函数以及几个可疑的内存地址,统统用 gdb 打印。\n\n```\n(gdb) p(char*) 0x402619\n$2 = 0x402619 \"%d %d %s\"\n```\n\n```\n(gdb) p(char*) 0x402622\n$3 = 0x402622 \"DrEvil\"\n```\n\n> 发现之前调用过的__isoc99_sscanf@plt 还有隐藏用法，在输入两个数后再输入一个字符串 \"DrEvil\" 就能成功开启secret phase.\n\n- 所以我们在最后一次调用__isoc99_sscanf@plt的 phase 4 输入 7 0 DrEvil, 果然在 phase 6 之后进入了 secret phase。\n\n### 分析\n- 虽然说是隐藏关，但是复杂度和难度比 phase 6 低了不少，和 phase 4 一样是一个递归，但不同的是这次真的需要递归几次，但也不深。只要确定好路线还是比较容易的。\n\n```\ncallq  40149e <read_line> # 读一行\n...\ncallq  400bd0 <strtol@plt> # 调用 strtol@plt\n```\n\n> secret phase上来读了一整行然后调用了一个 strtol，经过阅读strtol的源码，发现它是以10为base将字符串转为一个整型，实际上就是剔除了最后答案中除了数字以外的字符。(所以写上答案数字然后乱输字母也能过 bushi)\n\n```\nlea    -0x1(%rax),%eax \n# eax = (rax) - 1\ncmp    $0x3e8,%eax \n# eax == 0x3e8 ? (即判断返回值与0x3e9)\n```\n\n- 这段代码告诉我们输入的数要小于 1000\n\n```\nmov    $0x6030f0,%edi # edi = 0x6030f0 (36)\ncallq  401204 <fun7> # 调用fun7\n```\n- 将edi置为 0x6030f0 (里面存的是36) 接着开始调用fun7\n\n> 我们先不着急看fun7, 老样子先看过关要求。\n\n```\ncmp    $0x2,%eax # 比较一下 eax 返回是否为2\n```\n\n发现非常简单，只要eax返回值为2就行\n\n- 再来看fun7\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_64ed470376ec6b72dc43690bf9b4ea0e.png></img>\n\n> 一看这个递归是逃不过了，但我们要让eax == 2, 路线其实非常明确，第一次先走 way3 将 eax 弄成1，再走 way1 让eax*2， 最后一层我们让eax == 0 最后返回我们得到的 eax 就等于2\n*（eax = 0 -> 1 -> 2）*\n\n> 关键是一个 edx 和 esi 的比较，edx == rdi, 然后每次改变rdi使其中储存地址中所储存的变量逐步接近 esi 完成递归操作。\n\n根据所存地址(注意/d打出的是10进制)，可以很容易找出递归路径\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_dfddd1801cd10c701dd2753164434977.png style=\"width:65%\"></img>\n\n- 输入22可以正好满足需求\n> **22 <= 36 因而 rdi = (rdi + 8) (存8)，22 > 8 因而 rdi = = (rdi + 16) (存22), 22==22 所以 eax 返回 0 ，返回 1， 返回2，最终过关**\n\n**本题答案:** 22 (可以带非数字字符)\n\n\n\n\n","source":"_posts/ICS/ICS_Lab2.md","raw":"---\ntitle: ICS-Lab2 二进制炸弹\nindex_img: /img/ICS_Lab1/top.jpg\ndate: 2020-11-06 15:44:39\ncategory: [ICS]\ntags: [Assembly]\n---\n\n# ICS-Lab2-Bomb\n\n> 这个是CS:APP的第二个lab，主要着重于汇编代码的阅读\n\n***\n\n## 完成截图\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_244e1f55d2823d58f65eabab9478d7ce.png></img>\n\n***\n\n## Phase 1 - 入门\n### 一、分析\n\n> 练手入门题，用esi寄存器储存答案地址 (一个立即数)\n```\nmov    $0x402400,%esi\n```\n> 之后调用了一个 string_not_equal 函数比较输入和答案是否一致，一致就通过了。\n```\ncallq  401338 <strings_not_equal>\n```\n\n### 二、gdb调试\n> 看一下内存地址里面存了什么，获得flag\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_4801c7e177c56f6e7299c273d0120988.png></img>\n\n\n- **答案**: Border relations with Canada have never been better.\n\n***\n\n## Phase 2 - 循环\n### 分析\n\n> 本题是一个do while Loop, 难度不大, 耐心读就行了\n\n**关键位置**\n- 信息1 ： 看到 read_six_number 知道输入6个数，再往下看\n\n```\ncmpl   $0x1,(%rsp) # 比较栈顶地址所存变量大小是否为1\nje     400f30 <phase_2+0x34> # 如果为1 跳转至地址 400f30\ncallq  40143a <explode_bomb> # 如果不为1，直接炸了\njmp    400f30 <phase_2+0x34> # 跳转至地址 400f30\n```\n\n- 信息2 : 第一个数为1\n\n下面进入Loop Body\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_27148224f8cf2be48266eaa52f50b2f8.png></img>\n\n- 信息3 : \n可以看到这个循环把前一个数乘了2，跟后一个数比较, 如果相等就能够继续，不然就炸了。\n\n> 综上也就是说这是一个首项为1，公比为2的等比数列，共6项。\n\n所以答案就是 1 2 4 8 16 32\n\n***\n\n## Phase 3 - 分支\n### 分析\n\n> 第三题关键点在于用gdb查看一下jumptable\n\n 我们先看一下输入，在输入了两个变量后，esi里放了内存中的一个可疑的东西，我们用gdb看一眼。\n```\nmov    $0x4025cf,%esi\n```\n\n```shell=\n(gdb) p(char *) 0x4025cf\n\"%d %d\"\n```\n\n 发现原来是输入两个整型，再往下看\n\n```\ncmpl   $0x7,0x8(%rsp) # 将 M(rsp + 8) 看作32位无符号数跟7比较\nja     400fad <phase_3+0x6a> # 如果大于就跳转至 0x400fad (炸弹炸了)\n```\n\n 发现如果输入的第一个数大于7就爆炸了，看来switch最多只有7个case\n\n```\njmpq   *0x402470(,%rax,8) \n# 跳转至 (eax * 8 + 0x402470)处所存的地址 （jumptable）\n```\n\n> 最关键的是这一句，构造了一个 switch 的 jumptable，我们知道地址是 0x402470，按照 case * 8 + 0x402470 跳转到该地址里面的地址，所以我们用gdb看一下。\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_ae5e359c30ff5ccb9292a7472c39eb19.png></img>\n\n- 我通关选了case 1（它比较特殊，处理它其他内存地址跳转都是按case从小到大顺序的，只有case 1 在最后一个，当然其他也都能过。）\n\n- case 1 跳转到了 0x400fb9 地址\n\n```\nmov    $0x137,%eax \n# eax = 0x137 (311) (不用跳转了，下面就是 0x400fbe)\n```\n\n其将eax置为了0x137，要小心是16进制，所以对应十进制311\n\n```\ncmp    0xc(%rsp),%eax # 比较 M(rsp + 12) 和 eax\nje     400fc9 <phase_3+0x86> # 如果相等就跳转至 0x400fc9 (过关了！)\n```\n\n最后是一个比较，如果eax和第二个输入值相同就过了。\n\n- 本题答案（不唯一)\n\n| case | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 |\n| :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: |\n| ans | 207 | 311 | 707 | 256 | 389 | 206 | 682 | 327 |\n\n\n***\n\n## Phase 4 - 递归\n### 分析\n- 这题是个递归，不过不用很深，很快就能看出答案。\n\n先正常读两个数，放在rdx，rcx中，检查输入。\n\n```\ncmpl   $0xe,0x8(%rsp) \n# 比较 M(rsp + 8) (既 rdx) 与 0xe\njbe    40103a <phase_4+0x2e> \n# 如果 rdx <= 0xe (14) 跳转至 0x40103a, 不然就炸了 (作为无符号数)\n```\n\n> 这两行汇编告诉我们，rdx一定要小于 0xe (14) 且大于等于0, 不然炸了, 大幅度缩小了范围。\n\n> 接下来就进入了函数递归调用，先做点预处理，把edx里面存一个立即数14，然后edi为第一个输入值，esi = 0 进入fun4\n\n```\nmov    $0xe,%edx # edx = 0xe (14)\nmov    $0x0,%esi # esi = 0\nmov    0x8(%rsp),%edi # edi = (第一个输入值)\ncallq  400fce <func4> # 调用func4\n```\n> 先不着急看fun4，先看看最后要怎么过关\n```\ntest   %eax,%eax # eax & eax\njne    401058 <phase_4+0x4c> \n# 如果ZF == 0 就跳转（既eax != 0)，跳转至 0x401058 炸了\ncmpl   $0x0,0xc(%rsp) # 比较 M(rsp + 12) 和 0\nje     40105d <phase_4+0x51> # 如果相等就跳转到 0x40105d, 不然就炸了\n```\n- test 实际上就是一个与操作，所以我们知道需要 eax == 0 且 M(rsp + 12) == 0，到这我们发现，第二个条件只要我们一开始输入的第二个参数为0，就能够保证，那么下面我们就要看进入fun4之后如何让返回值 eax == 0\n\n> 再回来看fun4，其分为两部分，一个是递归的主体，一个是判断是否继续递归。一开始先对eax 和 ecx 进行一些操作。\n- 我们发现 eax 和 ecx 的值在第一层递归都被置为14，(esi 为 0)按其操作得到 eax 除2, ecx 逻辑右移 31 位为0, 接着其实就是比较 edi 和 rax, **相当于就是比较第一个参数和常数 7**\n\n```\njle    400ff2 <func4+0x24> # 若ecx <= 就跳转至 0x400ff2\n```\n```\nmov    $0x0,%eax # eax = 0;\ncmp    %edi,%ecx # 比较 ecx 和 edi \njge    401007 <func4+0x39> \n# 若 edi >= ecx 跳转至 0x401007 返回\n```\n\n- 接着是一个跳转, 如果满足我们就跳转至 0x400ff2, 我们发现这里已经满足了我们需要的 eax == 0，而想要结束就得使 edi >= ecx (7), 所以我们发现，对于上下两个跳转条件，只要 edi == ecx == 7 就能一直成立，从而直接达成条件，不用进入递归。\n\n进而我们得到了本题答案：7 0\n\n***\n\n## Phase 5 - 指针\n### 分析\n- 这题我觉得是最好玩的一题，先直接分析如何通关。\n\n```\nmov    $0x40245e,%esi # esi = 0x40245e \n# 待比较的 string (flyers) 从 0x40245e 移动至 esi\n```\n\n- 我们在接近返回时看到了一个非常可疑的内存地址，直接给它打出来。\n\n```\n(gdb) p(char*) 0x40245e\n$4 = 0x40245e \"flyers\"\n```\n\n> 发现是一个可疑字符串 flyers，阅读上下文汇编代码可知，最后是比较字符串是否和指定字符串 \"flyers\" 一致。\n\n- 我们再往上看看要怎么输入\n\n```\ncallq  40131b <string_length> # 比较字符长度是否为6\ncmp    $0x6,%eax # 比较 eax 和 6\n```\n\n发现输入一定要是六个字符 *(于是试了试 flyers 果然不对)*\n\n- 往下看，发现了一个 Loop 循环了6次\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_016df1440f7044a54fb4ced529595b58.png></img>\n\n> 经过仔细阅读后，发现这个居然是遍历六个输入字符，将其 ascii 码低4位取出来作为偏移量 (offset),在一个基地址 （0x4024b0）后面取字符出来组成 flyers.\n\n- 立刻开启 gdb 查看基地址附近的内存\n\n**发现分别对应的偏移量是 9, 15, 14, 5, 6, 7**\n> 直接查 ascii 码，发现对应 ionefg 、IONEFG 或者有一些不是字母的字符也行，只要低四位是正确的就可以。 \n\n**本题答案:**  ionefg (答案不唯一)\n\n***\n\n## Phase 6 - Node结构体\n### 分析\n这题还是比较麻烦的，代码比较长也比较复杂，要耐心读。\n\n- 这题的代码可以大致分为输入检测与处理和一个对结构体的顺序检测.\n> 最开始上来先输入六个数之后有个双循环，外部保证输入的六个数要大于等于1，且小于等于6，内部保证互异。所以总体看来就是输入的六个数就是123456, 现在问题是输入的顺序。\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_7194e52688ff3d696a3b889e2b17d63f.png></img>\n\n这段代码遍历了所有输入并用7减去了输入的每个数，所以最后做出答案要记得反一下。\n\n- 接下来代码比较复杂，外面大循环循环了六次，内部有两个平行的小循环。作用是构造结构体，并在栈帧中将其存放位置按照输入的数的大小计算得出\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_9ea5cd30293a18357af1da93c35e0f59.png></img>\n\n\n> 分析代码，我们先发现一种特殊情况就是当前计算的数为1时（输入为6）edx直接就是给定的地址 0x6032d0, 其余的都按照其大小，在第一个小循环中循环相应次数，给 rdx 在原地址上相应偏移16位。\n\n> 接着下来将其存入栈帧中 rsp + 32 到 rsp + 80 的位置\n\n- 使用 gdb 查看 node\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_f2ecdd05728cbefbba59b068a29fdfdc.png></img>\n\n\n最后我们看如何通关\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_a18a67d1b4dbfa16a7fd8800e3ee304b.png></img>\n\n> 发现通关条件是要求定序，前面node大于后面的节点，根据gdb node节点的值和要求我们得到了 3 4 5 6 1 2 的结果，最后不要忘记这是被7减过之后的结果，原来的输入要还原。所以答案就是 4 3 2 1 6 5\n\n**本题答案:** 4 3 2 1 6 5\n\n***\n\n## Secret Phase- 递归\n### 一、进入方法\n- 输入上面六种答案之后，发现 secret phase 并没有出现，于是开始着手寻找入口。\n\n> 根据最后结果出现的字符顺藤摸瓜找到了 phase_defuse 函数，一看发现其中有一个可疑的 <string_not_equal> 函数以及几个可疑的内存地址,统统用 gdb 打印。\n\n```\n(gdb) p(char*) 0x402619\n$2 = 0x402619 \"%d %d %s\"\n```\n\n```\n(gdb) p(char*) 0x402622\n$3 = 0x402622 \"DrEvil\"\n```\n\n> 发现之前调用过的__isoc99_sscanf@plt 还有隐藏用法，在输入两个数后再输入一个字符串 \"DrEvil\" 就能成功开启secret phase.\n\n- 所以我们在最后一次调用__isoc99_sscanf@plt的 phase 4 输入 7 0 DrEvil, 果然在 phase 6 之后进入了 secret phase。\n\n### 分析\n- 虽然说是隐藏关，但是复杂度和难度比 phase 6 低了不少，和 phase 4 一样是一个递归，但不同的是这次真的需要递归几次，但也不深。只要确定好路线还是比较容易的。\n\n```\ncallq  40149e <read_line> # 读一行\n...\ncallq  400bd0 <strtol@plt> # 调用 strtol@plt\n```\n\n> secret phase上来读了一整行然后调用了一个 strtol，经过阅读strtol的源码，发现它是以10为base将字符串转为一个整型，实际上就是剔除了最后答案中除了数字以外的字符。(所以写上答案数字然后乱输字母也能过 bushi)\n\n```\nlea    -0x1(%rax),%eax \n# eax = (rax) - 1\ncmp    $0x3e8,%eax \n# eax == 0x3e8 ? (即判断返回值与0x3e9)\n```\n\n- 这段代码告诉我们输入的数要小于 1000\n\n```\nmov    $0x6030f0,%edi # edi = 0x6030f0 (36)\ncallq  401204 <fun7> # 调用fun7\n```\n- 将edi置为 0x6030f0 (里面存的是36) 接着开始调用fun7\n\n> 我们先不着急看fun7, 老样子先看过关要求。\n\n```\ncmp    $0x2,%eax # 比较一下 eax 返回是否为2\n```\n\n发现非常简单，只要eax返回值为2就行\n\n- 再来看fun7\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_64ed470376ec6b72dc43690bf9b4ea0e.png></img>\n\n> 一看这个递归是逃不过了，但我们要让eax == 2, 路线其实非常明确，第一次先走 way3 将 eax 弄成1，再走 way1 让eax*2， 最后一层我们让eax == 0 最后返回我们得到的 eax 就等于2\n*（eax = 0 -> 1 -> 2）*\n\n> 关键是一个 edx 和 esi 的比较，edx == rdi, 然后每次改变rdi使其中储存地址中所储存的变量逐步接近 esi 完成递归操作。\n\n根据所存地址(注意/d打出的是10进制)，可以很容易找出递归路径\n\n<img src=https://codimd.s3.shivering-isles.com/demo/uploads/upload_dfddd1801cd10c701dd2753164434977.png style=\"width:65%\"></img>\n\n- 输入22可以正好满足需求\n> **22 <= 36 因而 rdi = (rdi + 8) (存8)，22 > 8 因而 rdi = = (rdi + 16) (存22), 22==22 所以 eax 返回 0 ，返回 1， 返回2，最终过关**\n\n**本题答案:** 22 (可以带非数字字符)\n\n\n\n\n","slug":"ICS/ICS_Lab2","published":1,"updated":"2020-12-09T01:23:16.858Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty3y000ws8pd6qk954ab","content":"<h1 id=\"ICS-Lab2-Bomb\"><a href=\"#ICS-Lab2-Bomb\" class=\"headerlink\" title=\"ICS-Lab2-Bomb\"></a>ICS-Lab2-Bomb</h1><blockquote>\n<p>这个是CS:APP的第二个lab，主要着重于汇编代码的阅读</p>\n</blockquote>\n<hr>\n<h2 id=\"完成截图\"><a href=\"#完成截图\" class=\"headerlink\" title=\"完成截图\"></a>完成截图</h2><p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_244e1f55d2823d58f65eabab9478d7ce.png\"></p>\n<hr>\n<h2 id=\"Phase-1-入门\"><a href=\"#Phase-1-入门\" class=\"headerlink\" title=\"Phase 1 - 入门\"></a>Phase 1 - 入门</h2><h3 id=\"一、分析\"><a href=\"#一、分析\" class=\"headerlink\" title=\"一、分析\"></a>一、分析</h3><blockquote>\n<p>练手入门题，用esi寄存器储存答案地址 (一个立即数)<br><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">402400</span>,%esi</code></pre><br>之后调用了一个 string_not_equal 函数比较输入和答案是否一致，一致就通过了。<br><pre><code class=\"hljs angelscript\">callq  <span class=\"hljs-number\">401338</span> &lt;<span class=\"hljs-built_in\">string</span>s_not_equal&gt;</code></pre></p>\n</blockquote>\n<h3 id=\"二、gdb调试\"><a href=\"#二、gdb调试\" class=\"headerlink\" title=\"二、gdb调试\"></a>二、gdb调试</h3><blockquote>\n<p>看一下内存地址里面存了什么，获得flag</p>\n</blockquote>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_4801c7e177c56f6e7299c273d0120988.png\"></p>\n<ul>\n<li><strong>答案</strong>: Border relations with Canada have never been better.</li>\n</ul>\n<hr>\n<h2 id=\"Phase-2-循环\"><a href=\"#Phase-2-循环\" class=\"headerlink\" title=\"Phase 2 - 循环\"></a>Phase 2 - 循环</h2><h3 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h3><blockquote>\n<p>本题是一个do while Loop, 难度不大, 耐心读就行了</p>\n</blockquote>\n<p><strong>关键位置</strong></p>\n<ul>\n<li>信息1 ： 看到 read_six_number 知道输入6个数，再往下看</li>\n</ul>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">cmpl</span>   $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">1</span>,(%rsp) # 比较栈顶地址所存变量大小是否为<span class=\"hljs-number\">1</span>\n<span class=\"hljs-attribute\">je</span>     <span class=\"hljs-number\">400</span>f<span class=\"hljs-number\">30</span> &lt;phase_<span class=\"hljs-number\">2</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">34</span>&gt; # 如果为<span class=\"hljs-number\">1</span> 跳转至地址 <span class=\"hljs-number\">400</span>f<span class=\"hljs-number\">30</span>\n<span class=\"hljs-attribute\">callq</span>  <span class=\"hljs-number\">40143</span>a &lt;explode_bomb&gt; # 如果不为<span class=\"hljs-number\">1</span>，直接炸了\n<span class=\"hljs-attribute\">jmp</span>    <span class=\"hljs-number\">400</span>f<span class=\"hljs-number\">30</span> &lt;phase_<span class=\"hljs-number\">2</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">34</span>&gt; # 跳转至地址 <span class=\"hljs-number\">400</span>f<span class=\"hljs-number\">30</span></code></pre>\n<ul>\n<li>信息2 : 第一个数为1</li>\n</ul>\n<p>下面进入Loop Body</p>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_27148224f8cf2be48266eaa52f50b2f8.png\"></p>\n<ul>\n<li>信息3 :<br>可以看到这个循环把前一个数乘了2，跟后一个数比较, 如果相等就能够继续，不然就炸了。</li>\n</ul>\n<blockquote>\n<p>综上也就是说这是一个首项为1，公比为2的等比数列，共6项。</p>\n</blockquote>\n<p>所以答案就是 1 2 4 8 16 32</p>\n<hr>\n<h2 id=\"Phase-3-分支\"><a href=\"#Phase-3-分支\" class=\"headerlink\" title=\"Phase 3 - 分支\"></a>Phase 3 - 分支</h2><h3 id=\"分析-1\"><a href=\"#分析-1\" class=\"headerlink\" title=\"分析\"></a>分析</h3><blockquote>\n<p>第三题关键点在于用gdb查看一下jumptable</p>\n</blockquote>\n<p> 我们先看一下输入，在输入了两个变量后，esi里放了内存中的一个可疑的东西，我们用gdb看一眼。<br><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">4025</span>cf,%esi</code></pre></p>\n<pre><code class=\"hljs shell\">(gdb) p(char *) 0x4025cf\n&quot;%d %d&quot;</code></pre>\n<p> 发现原来是输入两个整型，再往下看</p>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">cmpl</span>   $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">7</span>,<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">8</span>(%rsp) # 将 M(rsp + <span class=\"hljs-number\">8</span>) 看作<span class=\"hljs-number\">32</span>位无符号数跟<span class=\"hljs-number\">7</span>比较\n<span class=\"hljs-attribute\">ja</span>     <span class=\"hljs-number\">400</span>fad &lt;phase_<span class=\"hljs-number\">3</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">6</span>a&gt; # 如果大于就跳转至 <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">400</span>fad (炸弹炸了)</code></pre>\n<p> 发现如果输入的第一个数大于7就爆炸了，看来switch最多只有7个case</p>\n<pre><code class=\"hljs angelscript\">jmpq   *<span class=\"hljs-number\">0x402470</span>(,%rax,<span class=\"hljs-number\">8</span>) \n# 跳转至 (eax * <span class=\"hljs-number\">8</span> + <span class=\"hljs-number\">0x402470</span>)处所存的地址 （jumptable）</code></pre>\n<blockquote>\n<p>最关键的是这一句，构造了一个 switch 的 jumptable，我们知道地址是 0x402470，按照 case * 8 + 0x402470 跳转到该地址里面的地址，所以我们用gdb看一下。</p>\n</blockquote>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_ae5e359c30ff5ccb9292a7472c39eb19.png\"></p>\n<ul>\n<li><p>我通关选了case 1（它比较特殊，处理它其他内存地址跳转都是按case从小到大顺序的，只有case 1 在最后一个，当然其他也都能过。）</p>\n</li>\n<li><p>case 1 跳转到了 0x400fb9 地址</p>\n</li>\n</ul>\n<pre><code class=\"hljs angelscript\">mov    $<span class=\"hljs-number\">0x137</span>,%eax \n# eax = <span class=\"hljs-number\">0x137</span> (<span class=\"hljs-number\">311</span>) (不用跳转了，下面就是 <span class=\"hljs-number\">0x400fbe</span>)</code></pre>\n<p>其将eax置为了0x137，要小心是16进制，所以对应十进制311</p>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">cmp</span>    <span class=\"hljs-number\">0</span>xc(%rsp),%eax # 比较 M(rsp + <span class=\"hljs-number\">12</span>) 和 eax\n<span class=\"hljs-attribute\">je</span>     <span class=\"hljs-number\">400</span>fc<span class=\"hljs-number\">9</span> &lt;phase_<span class=\"hljs-number\">3</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">86</span>&gt; # 如果相等就跳转至 <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">400</span>fc<span class=\"hljs-number\">9</span> (过关了！)</code></pre>\n<p>最后是一个比较，如果eax和第二个输入值相同就过了。</p>\n<ul>\n<li>本题答案（不唯一)</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">case</th>\n<th style=\"text-align:center\">0</th>\n<th style=\"text-align:center\">1</th>\n<th style=\"text-align:center\">2</th>\n<th style=\"text-align:center\">3</th>\n<th style=\"text-align:center\">4</th>\n<th style=\"text-align:center\">5</th>\n<th style=\"text-align:center\">6</th>\n<th style=\"text-align:center\">7</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">ans</td>\n<td style=\"text-align:center\">207</td>\n<td style=\"text-align:center\">311</td>\n<td style=\"text-align:center\">707</td>\n<td style=\"text-align:center\">256</td>\n<td style=\"text-align:center\">389</td>\n<td style=\"text-align:center\">206</td>\n<td style=\"text-align:center\">682</td>\n<td style=\"text-align:center\">327</td>\n</tr>\n</tbody>\n</table>\n</div>\n<hr>\n<h2 id=\"Phase-4-递归\"><a href=\"#Phase-4-递归\" class=\"headerlink\" title=\"Phase 4 - 递归\"></a>Phase 4 - 递归</h2><h3 id=\"分析-2\"><a href=\"#分析-2\" class=\"headerlink\" title=\"分析\"></a>分析</h3><ul>\n<li>这题是个递归，不过不用很深，很快就能看出答案。</li>\n</ul>\n<p>先正常读两个数，放在rdx，rcx中，检查输入。</p>\n<pre><code class=\"hljs angelscript\">cmpl   $<span class=\"hljs-number\">0xe</span>,<span class=\"hljs-number\">0x8</span>(%rsp) \n# 比较 M(rsp + <span class=\"hljs-number\">8</span>) (既 rdx) 与 <span class=\"hljs-number\">0xe</span>\njbe    <span class=\"hljs-number\">40103</span>a &lt;phase_4+<span class=\"hljs-number\">0x2e</span>&gt; \n# 如果 rdx &lt;= <span class=\"hljs-number\">0xe</span> (<span class=\"hljs-number\">14</span>) 跳转至 <span class=\"hljs-number\">0x40103a</span>, 不然就炸了 (作为无符号数)</code></pre>\n<blockquote>\n<p>这两行汇编告诉我们，rdx一定要小于 0xe (14) 且大于等于0, 不然炸了, 大幅度缩小了范围。</p>\n<p>接下来就进入了函数递归调用，先做点预处理，把edx里面存一个立即数14，然后edi为第一个输入值，esi = 0 进入fun4</p>\n</blockquote>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>xe,%edx # edx = <span class=\"hljs-number\">0</span>xe (<span class=\"hljs-number\">14</span>)\n<span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">0</span>,%esi # esi = <span class=\"hljs-number\">0</span>\n<span class=\"hljs-attribute\">mov</span>    <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">8</span>(%rsp),%edi # edi = (第一个输入值)\n<span class=\"hljs-attribute\">callq</span>  <span class=\"hljs-number\">400</span>fce &lt;func<span class=\"hljs-number\">4</span>&gt; # 调用func<span class=\"hljs-number\">4</span></code></pre>\n<blockquote>\n<p>先不着急看fun4，先看看最后要怎么过关<br><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">test</span>   %eax,%eax # eax &amp; eax\n<span class=\"hljs-attribute\">jne</span>    <span class=\"hljs-number\">401058</span> &lt;phase_<span class=\"hljs-number\">4</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">4</span>c&gt; \n<span class=\"hljs-comment\"># 如果ZF == 0 就跳转（既eax != 0)，跳转至 0x401058 炸了</span>\n<span class=\"hljs-attribute\">cmpl</span>   $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>xc(%rsp) # 比较 M(rsp + <span class=\"hljs-number\">12</span>) 和 <span class=\"hljs-number\">0</span>\n<span class=\"hljs-attribute\">je</span>     <span class=\"hljs-number\">40105</span>d &lt;phase_<span class=\"hljs-number\">4</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">51</span>&gt; # 如果相等就跳转到 <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">40105</span>d, 不然就炸了</code></pre></p>\n<ul>\n<li>test 实际上就是一个与操作，所以我们知道需要 eax == 0 且 M(rsp + 12) == 0，到这我们发现，第二个条件只要我们一开始输入的第二个参数为0，就能够保证，那么下面我们就要看进入fun4之后如何让返回值 eax == 0</li>\n</ul>\n<p>再回来看fun4，其分为两部分，一个是递归的主体，一个是判断是否继续递归。一开始先对eax 和 ecx 进行一些操作。</p>\n<ul>\n<li>我们发现 eax 和 ecx 的值在第一层递归都被置为14，(esi 为 0)按其操作得到 eax 除2, ecx 逻辑右移 31 位为0, 接着其实就是比较 edi 和 rax, <strong>相当于就是比较第一个参数和常数 7</strong></li>\n</ul>\n</blockquote>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">jle</span>    <span class=\"hljs-number\">400</span>ff<span class=\"hljs-number\">2</span> &lt;func<span class=\"hljs-number\">4</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">24</span>&gt; # 若ecx &lt;= 就跳转至 <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">400</span>ff<span class=\"hljs-number\">2</span></code></pre>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">0</span>,%eax # eax = <span class=\"hljs-number\">0</span>;\n<span class=\"hljs-attribute\">cmp</span>    %edi,%ecx # 比较 ecx 和 edi \n<span class=\"hljs-attribute\">jge</span>    <span class=\"hljs-number\">401007</span> &lt;func<span class=\"hljs-number\">4</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">39</span>&gt; \n<span class=\"hljs-comment\"># 若 edi &gt;= ecx 跳转至 0x401007 返回</span></code></pre>\n<ul>\n<li>接着是一个跳转, 如果满足我们就跳转至 0x400ff2, 我们发现这里已经满足了我们需要的 eax == 0，而想要结束就得使 edi &gt;= ecx (7), 所以我们发现，对于上下两个跳转条件，只要 edi == ecx == 7 就能一直成立，从而直接达成条件，不用进入递归。</li>\n</ul>\n<p>进而我们得到了本题答案：7 0</p>\n<hr>\n<h2 id=\"Phase-5-指针\"><a href=\"#Phase-5-指针\" class=\"headerlink\" title=\"Phase 5 - 指针\"></a>Phase 5 - 指针</h2><h3 id=\"分析-3\"><a href=\"#分析-3\" class=\"headerlink\" title=\"分析\"></a>分析</h3><ul>\n<li>这题我觉得是最好玩的一题，先直接分析如何通关。</li>\n</ul>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">40245</span>e,%esi # esi = <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">40245</span>e \n<span class=\"hljs-comment\"># 待比较的 string (flyers) 从 0x40245e 移动至 esi</span></code></pre>\n<ul>\n<li>我们在接近返回时看到了一个非常可疑的内存地址，直接给它打出来。</li>\n</ul>\n<pre><code class=\"hljs lsl\">(gdb) p(char*) <span class=\"hljs-number\">0x40245e</span>\n$<span class=\"hljs-number\">4</span> = <span class=\"hljs-number\">0x40245e</span> <span class=\"hljs-string\">&quot;flyers&quot;</span></code></pre>\n<blockquote>\n<p>发现是一个可疑字符串 flyers，阅读上下文汇编代码可知，最后是比较字符串是否和指定字符串 “flyers” 一致。</p>\n</blockquote>\n<ul>\n<li>我们再往上看看要怎么输入</li>\n</ul>\n<pre><code class=\"hljs angelscript\">callq  <span class=\"hljs-number\">40131</span>b &lt;<span class=\"hljs-built_in\">string</span>_length&gt; # 比较字符长度是否为<span class=\"hljs-number\">6</span>\ncmp    $<span class=\"hljs-number\">0x6</span>,%eax # 比较 eax 和 <span class=\"hljs-number\">6</span></code></pre>\n<p>发现输入一定要是六个字符 <em>(于是试了试 flyers 果然不对)</em></p>\n<ul>\n<li>往下看，发现了一个 Loop 循环了6次</li>\n</ul>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_016df1440f7044a54fb4ced529595b58.png\"></p>\n<blockquote>\n<p>经过仔细阅读后，发现这个居然是遍历六个输入字符，将其 ascii 码低4位取出来作为偏移量 (offset),在一个基地址 （0x4024b0）后面取字符出来组成 flyers.</p>\n</blockquote>\n<ul>\n<li>立刻开启 gdb 查看基地址附近的内存</li>\n</ul>\n<p><strong>发现分别对应的偏移量是 9, 15, 14, 5, 6, 7</strong></p>\n<blockquote>\n<p>直接查 ascii 码，发现对应 ionefg 、IONEFG 或者有一些不是字母的字符也行，只要低四位是正确的就可以。 </p>\n</blockquote>\n<p><strong>本题答案:</strong>  ionefg (答案不唯一)</p>\n<hr>\n<h2 id=\"Phase-6-Node结构体\"><a href=\"#Phase-6-Node结构体\" class=\"headerlink\" title=\"Phase 6 - Node结构体\"></a>Phase 6 - Node结构体</h2><h3 id=\"分析-4\"><a href=\"#分析-4\" class=\"headerlink\" title=\"分析\"></a>分析</h3><p>这题还是比较麻烦的，代码比较长也比较复杂，要耐心读。</p>\n<ul>\n<li>这题的代码可以大致分为输入检测与处理和一个对结构体的顺序检测.<blockquote>\n<p>最开始上来先输入六个数之后有个双循环，外部保证输入的六个数要大于等于1，且小于等于6，内部保证互异。所以总体看来就是输入的六个数就是123456, 现在问题是输入的顺序。</p>\n</blockquote>\n</li>\n</ul>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_7194e52688ff3d696a3b889e2b17d63f.png\"></p>\n<p>这段代码遍历了所有输入并用7减去了输入的每个数，所以最后做出答案要记得反一下。</p>\n<ul>\n<li>接下来代码比较复杂，外面大循环循环了六次，内部有两个平行的小循环。作用是构造结构体，并在栈帧中将其存放位置按照输入的数的大小计算得出</li>\n</ul>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_9ea5cd30293a18357af1da93c35e0f59.png\"></p>\n<blockquote>\n<p>分析代码，我们先发现一种特殊情况就是当前计算的数为1时（输入为6）edx直接就是给定的地址 0x6032d0, 其余的都按照其大小，在第一个小循环中循环相应次数，给 rdx 在原地址上相应偏移16位。</p>\n<p>接着下来将其存入栈帧中 rsp + 32 到 rsp + 80 的位置</p>\n</blockquote>\n<ul>\n<li>使用 gdb 查看 node</li>\n</ul>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_f2ecdd05728cbefbba59b068a29fdfdc.png\"></p>\n<p>最后我们看如何通关</p>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_a18a67d1b4dbfa16a7fd8800e3ee304b.png\"></p>\n<blockquote>\n<p>发现通关条件是要求定序，前面node大于后面的节点，根据gdb node节点的值和要求我们得到了 3 4 5 6 1 2 的结果，最后不要忘记这是被7减过之后的结果，原来的输入要还原。所以答案就是 4 3 2 1 6 5</p>\n</blockquote>\n<p><strong>本题答案:</strong> 4 3 2 1 6 5</p>\n<hr>\n<h2 id=\"Secret-Phase-递归\"><a href=\"#Secret-Phase-递归\" class=\"headerlink\" title=\"Secret Phase- 递归\"></a>Secret Phase- 递归</h2><h3 id=\"一、进入方法\"><a href=\"#一、进入方法\" class=\"headerlink\" title=\"一、进入方法\"></a>一、进入方法</h3><ul>\n<li>输入上面六种答案之后，发现 secret phase 并没有出现，于是开始着手寻找入口。</li>\n</ul>\n<blockquote>\n<p>根据最后结果出现的字符顺藤摸瓜找到了 phase_defuse 函数，一看发现其中有一个可疑的 <string_not_equal> 函数以及几个可疑的内存地址,统统用 gdb 打印。</string_not_equal></p>\n</blockquote>\n<pre><code class=\"hljs perl\">(gdb) p(char*) <span class=\"hljs-number\">0x402619</span>\n$2 = <span class=\"hljs-number\">0x402619</span> <span class=\"hljs-string\">&quot;%d %d %s&quot;</span></code></pre>\n<pre><code class=\"hljs lsl\">(gdb) p(char*) <span class=\"hljs-number\">0x402622</span>\n$<span class=\"hljs-number\">3</span> = <span class=\"hljs-number\">0x402622</span> <span class=\"hljs-string\">&quot;DrEvil&quot;</span></code></pre>\n<blockquote>\n<p>发现之前调用过的__isoc99_sscanf@plt 还有隐藏用法，在输入两个数后再输入一个字符串 “DrEvil” 就能成功开启secret phase.</p>\n</blockquote>\n<ul>\n<li>所以我们在最后一次调用__isoc99_sscanf@plt的 phase 4 输入 7 0 DrEvil, 果然在 phase 6 之后进入了 secret phase。</li>\n</ul>\n<h3 id=\"分析-5\"><a href=\"#分析-5\" class=\"headerlink\" title=\"分析\"></a>分析</h3><ul>\n<li>虽然说是隐藏关，但是复杂度和难度比 phase 6 低了不少，和 phase 4 一样是一个递归，但不同的是这次真的需要递归几次，但也不深。只要确定好路线还是比较容易的。</li>\n</ul>\n<pre><code class=\"hljs angelscript\">callq  <span class=\"hljs-number\">40149</span>e &lt;read_line&gt; # 读一行\n...\ncallq  <span class=\"hljs-number\">400</span>bd0 &lt;<span class=\"hljs-symbol\">strtol@</span>plt&gt; # 调用 <span class=\"hljs-symbol\">strtol@</span>plt</code></pre>\n<blockquote>\n<p>secret phase上来读了一整行然后调用了一个 strtol，经过阅读strtol的源码，发现它是以10为base将字符串转为一个整型，实际上就是剔除了最后答案中除了数字以外的字符。(所以写上答案数字然后乱输字母也能过 bushi)</p>\n</blockquote>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">lea</span>    -<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">1</span>(%rax),%eax \n<span class=\"hljs-comment\"># eax = (rax) - 1</span>\n<span class=\"hljs-attribute\">cmp</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">3</span>e<span class=\"hljs-number\">8</span>,%eax \n<span class=\"hljs-comment\"># eax == 0x3e8 ? (即判断返回值与0x3e9)</span></code></pre>\n<ul>\n<li>这段代码告诉我们输入的数要小于 1000</li>\n</ul>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">6030</span>f<span class=\"hljs-number\">0</span>,%edi # edi = <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">6030</span>f<span class=\"hljs-number\">0</span> (<span class=\"hljs-number\">36</span>)\n<span class=\"hljs-attribute\">callq</span>  <span class=\"hljs-number\">401204</span> &lt;fun<span class=\"hljs-number\">7</span>&gt; # 调用fun<span class=\"hljs-number\">7</span></code></pre>\n<ul>\n<li>将edi置为 0x6030f0 (里面存的是36) 接着开始调用fun7</li>\n</ul>\n<blockquote>\n<p>我们先不着急看fun7, 老样子先看过关要求。</p>\n</blockquote>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">cmp</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">2</span>,%eax # 比较一下 eax 返回是否为<span class=\"hljs-number\">2</span></code></pre>\n<p>发现非常简单，只要eax返回值为2就行</p>\n<ul>\n<li>再来看fun7</li>\n</ul>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_64ed470376ec6b72dc43690bf9b4ea0e.png\"></p>\n<blockquote>\n<p>一看这个递归是逃不过了，但我们要让eax == 2, 路线其实非常明确，第一次先走 way3 将 eax 弄成1，再走 way1 让eax<em>2， 最后一层我们让eax == 0 最后返回我们得到的 eax 就等于2\n</em>（eax = 0 -&gt; 1 -&gt; 2）*</p>\n<p>关键是一个 edx 和 esi 的比较，edx == rdi, 然后每次改变rdi使其中储存地址中所储存的变量逐步接近 esi 完成递归操作。</p>\n</blockquote>\n<p>根据所存地址(注意/d打出的是10进制)，可以很容易找出递归路径</p>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_dfddd1801cd10c701dd2753164434977.png\" style=\"width:65%\"></p>\n<ul>\n<li>输入22可以正好满足需求<blockquote>\n<p><strong>22 &lt;= 36 因而 rdi = (rdi + 8) (存8)，22 &gt; 8 因而 rdi = = (rdi + 16) (存22), 22==22 所以 eax 返回 0 ，返回 1， 返回2，最终过关</strong></p>\n</blockquote>\n</li>\n</ul>\n<p><strong>本题答案:</strong> 22 (可以带非数字字符)</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"ICS-Lab2-Bomb\"><a href=\"#ICS-Lab2-Bomb\" class=\"headerlink\" title=\"ICS-Lab2-Bomb\"></a>ICS-Lab2-Bomb</h1><blockquote>\n<p>这个是CS:APP的第二个lab，主要着重于汇编代码的阅读</p>\n</blockquote>\n<hr>\n<h2 id=\"完成截图\"><a href=\"#完成截图\" class=\"headerlink\" title=\"完成截图\"></a>完成截图</h2><p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_244e1f55d2823d58f65eabab9478d7ce.png\"></p>\n<hr>\n<h2 id=\"Phase-1-入门\"><a href=\"#Phase-1-入门\" class=\"headerlink\" title=\"Phase 1 - 入门\"></a>Phase 1 - 入门</h2><h3 id=\"一、分析\"><a href=\"#一、分析\" class=\"headerlink\" title=\"一、分析\"></a>一、分析</h3><blockquote>\n<p>练手入门题，用esi寄存器储存答案地址 (一个立即数)<br><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">402400</span>,%esi</code></pre><br>之后调用了一个 string_not_equal 函数比较输入和答案是否一致，一致就通过了。<br><pre><code class=\"hljs angelscript\">callq  <span class=\"hljs-number\">401338</span> &lt;<span class=\"hljs-built_in\">string</span>s_not_equal&gt;</code></pre></p>\n</blockquote>\n<h3 id=\"二、gdb调试\"><a href=\"#二、gdb调试\" class=\"headerlink\" title=\"二、gdb调试\"></a>二、gdb调试</h3><blockquote>\n<p>看一下内存地址里面存了什么，获得flag</p>\n</blockquote>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_4801c7e177c56f6e7299c273d0120988.png\"></p>\n<ul>\n<li><strong>答案</strong>: Border relations with Canada have never been better.</li>\n</ul>\n<hr>\n<h2 id=\"Phase-2-循环\"><a href=\"#Phase-2-循环\" class=\"headerlink\" title=\"Phase 2 - 循环\"></a>Phase 2 - 循环</h2><h3 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h3><blockquote>\n<p>本题是一个do while Loop, 难度不大, 耐心读就行了</p>\n</blockquote>\n<p><strong>关键位置</strong></p>\n<ul>\n<li>信息1 ： 看到 read_six_number 知道输入6个数，再往下看</li>\n</ul>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">cmpl</span>   $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">1</span>,(%rsp) # 比较栈顶地址所存变量大小是否为<span class=\"hljs-number\">1</span>\n<span class=\"hljs-attribute\">je</span>     <span class=\"hljs-number\">400</span>f<span class=\"hljs-number\">30</span> &lt;phase_<span class=\"hljs-number\">2</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">34</span>&gt; # 如果为<span class=\"hljs-number\">1</span> 跳转至地址 <span class=\"hljs-number\">400</span>f<span class=\"hljs-number\">30</span>\n<span class=\"hljs-attribute\">callq</span>  <span class=\"hljs-number\">40143</span>a &lt;explode_bomb&gt; # 如果不为<span class=\"hljs-number\">1</span>，直接炸了\n<span class=\"hljs-attribute\">jmp</span>    <span class=\"hljs-number\">400</span>f<span class=\"hljs-number\">30</span> &lt;phase_<span class=\"hljs-number\">2</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">34</span>&gt; # 跳转至地址 <span class=\"hljs-number\">400</span>f<span class=\"hljs-number\">30</span></code></pre>\n<ul>\n<li>信息2 : 第一个数为1</li>\n</ul>\n<p>下面进入Loop Body</p>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_27148224f8cf2be48266eaa52f50b2f8.png\"></p>\n<ul>\n<li>信息3 :<br>可以看到这个循环把前一个数乘了2，跟后一个数比较, 如果相等就能够继续，不然就炸了。</li>\n</ul>\n<blockquote>\n<p>综上也就是说这是一个首项为1，公比为2的等比数列，共6项。</p>\n</blockquote>\n<p>所以答案就是 1 2 4 8 16 32</p>\n<hr>\n<h2 id=\"Phase-3-分支\"><a href=\"#Phase-3-分支\" class=\"headerlink\" title=\"Phase 3 - 分支\"></a>Phase 3 - 分支</h2><h3 id=\"分析-1\"><a href=\"#分析-1\" class=\"headerlink\" title=\"分析\"></a>分析</h3><blockquote>\n<p>第三题关键点在于用gdb查看一下jumptable</p>\n</blockquote>\n<p> 我们先看一下输入，在输入了两个变量后，esi里放了内存中的一个可疑的东西，我们用gdb看一眼。<br><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">4025</span>cf,%esi</code></pre></p>\n<pre><code class=\"hljs shell\">(gdb) p(char *) 0x4025cf\n&quot;%d %d&quot;</code></pre>\n<p> 发现原来是输入两个整型，再往下看</p>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">cmpl</span>   $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">7</span>,<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">8</span>(%rsp) # 将 M(rsp + <span class=\"hljs-number\">8</span>) 看作<span class=\"hljs-number\">32</span>位无符号数跟<span class=\"hljs-number\">7</span>比较\n<span class=\"hljs-attribute\">ja</span>     <span class=\"hljs-number\">400</span>fad &lt;phase_<span class=\"hljs-number\">3</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">6</span>a&gt; # 如果大于就跳转至 <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">400</span>fad (炸弹炸了)</code></pre>\n<p> 发现如果输入的第一个数大于7就爆炸了，看来switch最多只有7个case</p>\n<pre><code class=\"hljs angelscript\">jmpq   *<span class=\"hljs-number\">0x402470</span>(,%rax,<span class=\"hljs-number\">8</span>) \n# 跳转至 (eax * <span class=\"hljs-number\">8</span> + <span class=\"hljs-number\">0x402470</span>)处所存的地址 （jumptable）</code></pre>\n<blockquote>\n<p>最关键的是这一句，构造了一个 switch 的 jumptable，我们知道地址是 0x402470，按照 case * 8 + 0x402470 跳转到该地址里面的地址，所以我们用gdb看一下。</p>\n</blockquote>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_ae5e359c30ff5ccb9292a7472c39eb19.png\"></p>\n<ul>\n<li><p>我通关选了case 1（它比较特殊，处理它其他内存地址跳转都是按case从小到大顺序的，只有case 1 在最后一个，当然其他也都能过。）</p>\n</li>\n<li><p>case 1 跳转到了 0x400fb9 地址</p>\n</li>\n</ul>\n<pre><code class=\"hljs angelscript\">mov    $<span class=\"hljs-number\">0x137</span>,%eax \n# eax = <span class=\"hljs-number\">0x137</span> (<span class=\"hljs-number\">311</span>) (不用跳转了，下面就是 <span class=\"hljs-number\">0x400fbe</span>)</code></pre>\n<p>其将eax置为了0x137，要小心是16进制，所以对应十进制311</p>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">cmp</span>    <span class=\"hljs-number\">0</span>xc(%rsp),%eax # 比较 M(rsp + <span class=\"hljs-number\">12</span>) 和 eax\n<span class=\"hljs-attribute\">je</span>     <span class=\"hljs-number\">400</span>fc<span class=\"hljs-number\">9</span> &lt;phase_<span class=\"hljs-number\">3</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">86</span>&gt; # 如果相等就跳转至 <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">400</span>fc<span class=\"hljs-number\">9</span> (过关了！)</code></pre>\n<p>最后是一个比较，如果eax和第二个输入值相同就过了。</p>\n<ul>\n<li>本题答案（不唯一)</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">case</th>\n<th style=\"text-align:center\">0</th>\n<th style=\"text-align:center\">1</th>\n<th style=\"text-align:center\">2</th>\n<th style=\"text-align:center\">3</th>\n<th style=\"text-align:center\">4</th>\n<th style=\"text-align:center\">5</th>\n<th style=\"text-align:center\">6</th>\n<th style=\"text-align:center\">7</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">ans</td>\n<td style=\"text-align:center\">207</td>\n<td style=\"text-align:center\">311</td>\n<td style=\"text-align:center\">707</td>\n<td style=\"text-align:center\">256</td>\n<td style=\"text-align:center\">389</td>\n<td style=\"text-align:center\">206</td>\n<td style=\"text-align:center\">682</td>\n<td style=\"text-align:center\">327</td>\n</tr>\n</tbody>\n</table>\n</div>\n<hr>\n<h2 id=\"Phase-4-递归\"><a href=\"#Phase-4-递归\" class=\"headerlink\" title=\"Phase 4 - 递归\"></a>Phase 4 - 递归</h2><h3 id=\"分析-2\"><a href=\"#分析-2\" class=\"headerlink\" title=\"分析\"></a>分析</h3><ul>\n<li>这题是个递归，不过不用很深，很快就能看出答案。</li>\n</ul>\n<p>先正常读两个数，放在rdx，rcx中，检查输入。</p>\n<pre><code class=\"hljs angelscript\">cmpl   $<span class=\"hljs-number\">0xe</span>,<span class=\"hljs-number\">0x8</span>(%rsp) \n# 比较 M(rsp + <span class=\"hljs-number\">8</span>) (既 rdx) 与 <span class=\"hljs-number\">0xe</span>\njbe    <span class=\"hljs-number\">40103</span>a &lt;phase_4+<span class=\"hljs-number\">0x2e</span>&gt; \n# 如果 rdx &lt;= <span class=\"hljs-number\">0xe</span> (<span class=\"hljs-number\">14</span>) 跳转至 <span class=\"hljs-number\">0x40103a</span>, 不然就炸了 (作为无符号数)</code></pre>\n<blockquote>\n<p>这两行汇编告诉我们，rdx一定要小于 0xe (14) 且大于等于0, 不然炸了, 大幅度缩小了范围。</p>\n<p>接下来就进入了函数递归调用，先做点预处理，把edx里面存一个立即数14，然后edi为第一个输入值，esi = 0 进入fun4</p>\n</blockquote>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>xe,%edx # edx = <span class=\"hljs-number\">0</span>xe (<span class=\"hljs-number\">14</span>)\n<span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">0</span>,%esi # esi = <span class=\"hljs-number\">0</span>\n<span class=\"hljs-attribute\">mov</span>    <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">8</span>(%rsp),%edi # edi = (第一个输入值)\n<span class=\"hljs-attribute\">callq</span>  <span class=\"hljs-number\">400</span>fce &lt;func<span class=\"hljs-number\">4</span>&gt; # 调用func<span class=\"hljs-number\">4</span></code></pre>\n<blockquote>\n<p>先不着急看fun4，先看看最后要怎么过关<br><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">test</span>   %eax,%eax # eax &amp; eax\n<span class=\"hljs-attribute\">jne</span>    <span class=\"hljs-number\">401058</span> &lt;phase_<span class=\"hljs-number\">4</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">4</span>c&gt; \n<span class=\"hljs-comment\"># 如果ZF == 0 就跳转（既eax != 0)，跳转至 0x401058 炸了</span>\n<span class=\"hljs-attribute\">cmpl</span>   $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>xc(%rsp) # 比较 M(rsp + <span class=\"hljs-number\">12</span>) 和 <span class=\"hljs-number\">0</span>\n<span class=\"hljs-attribute\">je</span>     <span class=\"hljs-number\">40105</span>d &lt;phase_<span class=\"hljs-number\">4</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">51</span>&gt; # 如果相等就跳转到 <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">40105</span>d, 不然就炸了</code></pre></p>\n<ul>\n<li>test 实际上就是一个与操作，所以我们知道需要 eax == 0 且 M(rsp + 12) == 0，到这我们发现，第二个条件只要我们一开始输入的第二个参数为0，就能够保证，那么下面我们就要看进入fun4之后如何让返回值 eax == 0</li>\n</ul>\n<p>再回来看fun4，其分为两部分，一个是递归的主体，一个是判断是否继续递归。一开始先对eax 和 ecx 进行一些操作。</p>\n<ul>\n<li>我们发现 eax 和 ecx 的值在第一层递归都被置为14，(esi 为 0)按其操作得到 eax 除2, ecx 逻辑右移 31 位为0, 接着其实就是比较 edi 和 rax, <strong>相当于就是比较第一个参数和常数 7</strong></li>\n</ul>\n</blockquote>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">jle</span>    <span class=\"hljs-number\">400</span>ff<span class=\"hljs-number\">2</span> &lt;func<span class=\"hljs-number\">4</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">24</span>&gt; # 若ecx &lt;= 就跳转至 <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">400</span>ff<span class=\"hljs-number\">2</span></code></pre>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">0</span>,%eax # eax = <span class=\"hljs-number\">0</span>;\n<span class=\"hljs-attribute\">cmp</span>    %edi,%ecx # 比较 ecx 和 edi \n<span class=\"hljs-attribute\">jge</span>    <span class=\"hljs-number\">401007</span> &lt;func<span class=\"hljs-number\">4</span>+<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">39</span>&gt; \n<span class=\"hljs-comment\"># 若 edi &gt;= ecx 跳转至 0x401007 返回</span></code></pre>\n<ul>\n<li>接着是一个跳转, 如果满足我们就跳转至 0x400ff2, 我们发现这里已经满足了我们需要的 eax == 0，而想要结束就得使 edi &gt;= ecx (7), 所以我们发现，对于上下两个跳转条件，只要 edi == ecx == 7 就能一直成立，从而直接达成条件，不用进入递归。</li>\n</ul>\n<p>进而我们得到了本题答案：7 0</p>\n<hr>\n<h2 id=\"Phase-5-指针\"><a href=\"#Phase-5-指针\" class=\"headerlink\" title=\"Phase 5 - 指针\"></a>Phase 5 - 指针</h2><h3 id=\"分析-3\"><a href=\"#分析-3\" class=\"headerlink\" title=\"分析\"></a>分析</h3><ul>\n<li>这题我觉得是最好玩的一题，先直接分析如何通关。</li>\n</ul>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">40245</span>e,%esi # esi = <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">40245</span>e \n<span class=\"hljs-comment\"># 待比较的 string (flyers) 从 0x40245e 移动至 esi</span></code></pre>\n<ul>\n<li>我们在接近返回时看到了一个非常可疑的内存地址，直接给它打出来。</li>\n</ul>\n<pre><code class=\"hljs lsl\">(gdb) p(char*) <span class=\"hljs-number\">0x40245e</span>\n$<span class=\"hljs-number\">4</span> = <span class=\"hljs-number\">0x40245e</span> <span class=\"hljs-string\">&quot;flyers&quot;</span></code></pre>\n<blockquote>\n<p>发现是一个可疑字符串 flyers，阅读上下文汇编代码可知，最后是比较字符串是否和指定字符串 “flyers” 一致。</p>\n</blockquote>\n<ul>\n<li>我们再往上看看要怎么输入</li>\n</ul>\n<pre><code class=\"hljs angelscript\">callq  <span class=\"hljs-number\">40131</span>b &lt;<span class=\"hljs-built_in\">string</span>_length&gt; # 比较字符长度是否为<span class=\"hljs-number\">6</span>\ncmp    $<span class=\"hljs-number\">0x6</span>,%eax # 比较 eax 和 <span class=\"hljs-number\">6</span></code></pre>\n<p>发现输入一定要是六个字符 <em>(于是试了试 flyers 果然不对)</em></p>\n<ul>\n<li>往下看，发现了一个 Loop 循环了6次</li>\n</ul>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_016df1440f7044a54fb4ced529595b58.png\"></p>\n<blockquote>\n<p>经过仔细阅读后，发现这个居然是遍历六个输入字符，将其 ascii 码低4位取出来作为偏移量 (offset),在一个基地址 （0x4024b0）后面取字符出来组成 flyers.</p>\n</blockquote>\n<ul>\n<li>立刻开启 gdb 查看基地址附近的内存</li>\n</ul>\n<p><strong>发现分别对应的偏移量是 9, 15, 14, 5, 6, 7</strong></p>\n<blockquote>\n<p>直接查 ascii 码，发现对应 ionefg 、IONEFG 或者有一些不是字母的字符也行，只要低四位是正确的就可以。 </p>\n</blockquote>\n<p><strong>本题答案:</strong>  ionefg (答案不唯一)</p>\n<hr>\n<h2 id=\"Phase-6-Node结构体\"><a href=\"#Phase-6-Node结构体\" class=\"headerlink\" title=\"Phase 6 - Node结构体\"></a>Phase 6 - Node结构体</h2><h3 id=\"分析-4\"><a href=\"#分析-4\" class=\"headerlink\" title=\"分析\"></a>分析</h3><p>这题还是比较麻烦的，代码比较长也比较复杂，要耐心读。</p>\n<ul>\n<li>这题的代码可以大致分为输入检测与处理和一个对结构体的顺序检测.<blockquote>\n<p>最开始上来先输入六个数之后有个双循环，外部保证输入的六个数要大于等于1，且小于等于6，内部保证互异。所以总体看来就是输入的六个数就是123456, 现在问题是输入的顺序。</p>\n</blockquote>\n</li>\n</ul>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_7194e52688ff3d696a3b889e2b17d63f.png\"></p>\n<p>这段代码遍历了所有输入并用7减去了输入的每个数，所以最后做出答案要记得反一下。</p>\n<ul>\n<li>接下来代码比较复杂，外面大循环循环了六次，内部有两个平行的小循环。作用是构造结构体，并在栈帧中将其存放位置按照输入的数的大小计算得出</li>\n</ul>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_9ea5cd30293a18357af1da93c35e0f59.png\"></p>\n<blockquote>\n<p>分析代码，我们先发现一种特殊情况就是当前计算的数为1时（输入为6）edx直接就是给定的地址 0x6032d0, 其余的都按照其大小，在第一个小循环中循环相应次数，给 rdx 在原地址上相应偏移16位。</p>\n<p>接着下来将其存入栈帧中 rsp + 32 到 rsp + 80 的位置</p>\n</blockquote>\n<ul>\n<li>使用 gdb 查看 node</li>\n</ul>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_f2ecdd05728cbefbba59b068a29fdfdc.png\"></p>\n<p>最后我们看如何通关</p>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_a18a67d1b4dbfa16a7fd8800e3ee304b.png\"></p>\n<blockquote>\n<p>发现通关条件是要求定序，前面node大于后面的节点，根据gdb node节点的值和要求我们得到了 3 4 5 6 1 2 的结果，最后不要忘记这是被7减过之后的结果，原来的输入要还原。所以答案就是 4 3 2 1 6 5</p>\n</blockquote>\n<p><strong>本题答案:</strong> 4 3 2 1 6 5</p>\n<hr>\n<h2 id=\"Secret-Phase-递归\"><a href=\"#Secret-Phase-递归\" class=\"headerlink\" title=\"Secret Phase- 递归\"></a>Secret Phase- 递归</h2><h3 id=\"一、进入方法\"><a href=\"#一、进入方法\" class=\"headerlink\" title=\"一、进入方法\"></a>一、进入方法</h3><ul>\n<li>输入上面六种答案之后，发现 secret phase 并没有出现，于是开始着手寻找入口。</li>\n</ul>\n<blockquote>\n<p>根据最后结果出现的字符顺藤摸瓜找到了 phase_defuse 函数，一看发现其中有一个可疑的 <string_not_equal> 函数以及几个可疑的内存地址,统统用 gdb 打印。</string_not_equal></p>\n</blockquote>\n<pre><code class=\"hljs perl\">(gdb) p(char*) <span class=\"hljs-number\">0x402619</span>\n$2 = <span class=\"hljs-number\">0x402619</span> <span class=\"hljs-string\">&quot;%d %d %s&quot;</span></code></pre>\n<pre><code class=\"hljs lsl\">(gdb) p(char*) <span class=\"hljs-number\">0x402622</span>\n$<span class=\"hljs-number\">3</span> = <span class=\"hljs-number\">0x402622</span> <span class=\"hljs-string\">&quot;DrEvil&quot;</span></code></pre>\n<blockquote>\n<p>发现之前调用过的__isoc99_sscanf@plt 还有隐藏用法，在输入两个数后再输入一个字符串 “DrEvil” 就能成功开启secret phase.</p>\n</blockquote>\n<ul>\n<li>所以我们在最后一次调用__isoc99_sscanf@plt的 phase 4 输入 7 0 DrEvil, 果然在 phase 6 之后进入了 secret phase。</li>\n</ul>\n<h3 id=\"分析-5\"><a href=\"#分析-5\" class=\"headerlink\" title=\"分析\"></a>分析</h3><ul>\n<li>虽然说是隐藏关，但是复杂度和难度比 phase 6 低了不少，和 phase 4 一样是一个递归，但不同的是这次真的需要递归几次，但也不深。只要确定好路线还是比较容易的。</li>\n</ul>\n<pre><code class=\"hljs angelscript\">callq  <span class=\"hljs-number\">40149</span>e &lt;read_line&gt; # 读一行\n...\ncallq  <span class=\"hljs-number\">400</span>bd0 &lt;<span class=\"hljs-symbol\">strtol@</span>plt&gt; # 调用 <span class=\"hljs-symbol\">strtol@</span>plt</code></pre>\n<blockquote>\n<p>secret phase上来读了一整行然后调用了一个 strtol，经过阅读strtol的源码，发现它是以10为base将字符串转为一个整型，实际上就是剔除了最后答案中除了数字以外的字符。(所以写上答案数字然后乱输字母也能过 bushi)</p>\n</blockquote>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">lea</span>    -<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">1</span>(%rax),%eax \n<span class=\"hljs-comment\"># eax = (rax) - 1</span>\n<span class=\"hljs-attribute\">cmp</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">3</span>e<span class=\"hljs-number\">8</span>,%eax \n<span class=\"hljs-comment\"># eax == 0x3e8 ? (即判断返回值与0x3e9)</span></code></pre>\n<ul>\n<li>这段代码告诉我们输入的数要小于 1000</li>\n</ul>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">mov</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">6030</span>f<span class=\"hljs-number\">0</span>,%edi # edi = <span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">6030</span>f<span class=\"hljs-number\">0</span> (<span class=\"hljs-number\">36</span>)\n<span class=\"hljs-attribute\">callq</span>  <span class=\"hljs-number\">401204</span> &lt;fun<span class=\"hljs-number\">7</span>&gt; # 调用fun<span class=\"hljs-number\">7</span></code></pre>\n<ul>\n<li>将edi置为 0x6030f0 (里面存的是36) 接着开始调用fun7</li>\n</ul>\n<blockquote>\n<p>我们先不着急看fun7, 老样子先看过关要求。</p>\n</blockquote>\n<pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">cmp</span>    $<span class=\"hljs-number\">0</span>x<span class=\"hljs-number\">2</span>,%eax # 比较一下 eax 返回是否为<span class=\"hljs-number\">2</span></code></pre>\n<p>发现非常简单，只要eax返回值为2就行</p>\n<ul>\n<li>再来看fun7</li>\n</ul>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_64ed470376ec6b72dc43690bf9b4ea0e.png\"></p>\n<blockquote>\n<p>一看这个递归是逃不过了，但我们要让eax == 2, 路线其实非常明确，第一次先走 way3 将 eax 弄成1，再走 way1 让eax<em>2， 最后一层我们让eax == 0 最后返回我们得到的 eax 就等于2\n</em>（eax = 0 -&gt; 1 -&gt; 2）*</p>\n<p>关键是一个 edx 和 esi 的比较，edx == rdi, 然后每次改变rdi使其中储存地址中所储存的变量逐步接近 esi 完成递归操作。</p>\n</blockquote>\n<p>根据所存地址(注意/d打出的是10进制)，可以很容易找出递归路径</p>\n<p><img src=\"https://codimd.s3.shivering-isles.com/demo/uploads/upload_dfddd1801cd10c701dd2753164434977.png\" style=\"width:65%\"></p>\n<ul>\n<li>输入22可以正好满足需求<blockquote>\n<p><strong>22 &lt;= 36 因而 rdi = (rdi + 8) (存8)，22 &gt; 8 因而 rdi = = (rdi + 16) (存22), 22==22 所以 eax 返回 0 ，返回 1， 返回2，最终过关</strong></p>\n</blockquote>\n</li>\n</ul>\n<p><strong>本题答案:</strong> 22 (可以带非数字字符)</p>\n"},{"title":"CS231n Loss Functions and Optimization 02","date":"2020-11-08T12:52:06.000Z","index_img":"/img/Cs231n/top.jpg","math":true,"_content":"\n### Preview the Goal in this lecture\n1. Define a loss function\n2. Come up with a way of finding the paras that minimize the (1)\n(optimization)\n\n**The Remain Problem from last lecture**\n\n- How to choose the W para ? \n\n![](https://s1.ax1x.com/2020/11/08/BTZxgK.png)\n\n### Loss function\n\n> A loss function tells how good our current classifier is.\n\n$${(x_i,y_i)}_{i=1}^N$$\n\nThe $X_i$ is image and the $y_i$ is label (int)\n\nThe Total loss is defined as the func follows.\n\n$$L = \\frac{1}{N}\\sum\\limits_iL_i(f(x_i,W),y_i)$$\n*Which is the sum of every single test's loss*\n\n---\n\n#### **Muticlass SVM loss**\n\nGiven an example $(x_i,y_i)$ where $x_i$ is the image and where $y_i$ is the (int) label, using the shorthand for the score vec $s = f(x_i,W)$\n\nThe SVM loss has the form:\n\n![](https://s1.ax1x.com/2020/11/08/BTZ7B4.png)\n\n> if the incorrect score is smaller than the right score (x margin), we set the loss to 0.\nin this case the safe margin is set to one\n**Margin choice depends on our need**\n\n\n- Then we loop the class\n\n![](https://s1.ax1x.com/2020/11/08/BTZqE9.png)\n\n![](https://s1.ax1x.com/2020/11/08/BTZLNR.png)\n\n- What if we use\n\n$$L = \\frac{1}{N}\\sum\\limits_iL_i(f(x_i,W),y_i)^2$$\n> This is not a linear function and totally different, it's may be useful sometimes depends on the way you care about the errors.\n\n#### Example Code\n\n```python\ndef L_i_vectorized(x, y, W):\n    scores = W.dot(x)\n    margins = np.maximun(0, scores - scores[y] + margin)\n    margins[y] = 0\n    loss_i = np.sum(margins)\n    return loss_i\n    # pretty easy\n```\n\n![](https://s1.ax1x.com/2020/11/08/BTZO41.png)\n\n> It just change the gap bettween scores\n\n![](https://s1.ax1x.com/2020/11/08/BTZzjO.png)\n\n![](https://s1.ax1x.com/2020/11/08/BTe9De.png)\n\n> often use L2 regularization just Euclid norm.\n\n![](https://s1.ax1x.com/2020/11/08/BTepuD.png)\n\n> In this case the L1 and L2 reg is equal, but we can tell that L1 prefers the $w_1$ for it contains more zero, while the L2 prefers the $w_2$ for the weight is evenly spreaded through the test case.\n\n> The Multiclass SVM loss just care about the gap bettween the right labels and the wrongs.\n\n#### **Softmax Classifier**\n\n![](https://s1.ax1x.com/2020/11/08/BTeiEd.png)\n\n> We just want to make the true probability closer to 1 (closer the better, eq is the best), so the loss func can be chosed by using the -log on the $P$.\n\n![](https://s1.ax1x.com/2020/11/08/BTeCHH.png)\n\n> If we want to get the zero loss, the score may goes to inf! But Computer don't like that.\n\n- Debugging Way\noutcomes might be $logC$\n\n---\n\n![](https://s1.ax1x.com/2020/11/08/BTek4I.png)\n\n![](https://s1.ax1x.com/2020/11/08/BTeECt.png)\n\n---\n\n### Optimization\n\n#### Random Search - The Naive but Simplest way \n> Really Slow !!!\n\n#### Gradient Descent\n> We just get the Gradient of W and go down to the bottom (maybe local best?)\n\n![](https://s1.ax1x.com/2020/11/08/BTeFUA.png)\n\n**Code**\n\n```python\n# Vanilla Gradient Descent\n\nwhile True:\n    weight_grad = evaluate_gradient(loss_fun, data, weights)\n    weights += -step_size * weight_grad\n```\n\n**Step size is called elearning rate which is important**\n\n![](https://s1.ax1x.com/2020/11/08/BTeV8P.png)\n\n> Since the N might be super large, we sample some sets called minibatch and use it to estimate the true gradient.\n\n![](https://s1.ax1x.com/2020/11/08/BTeZgf.png)\n\n\n---\n\n![](https://s1.ax1x.com/2020/11/08/BTenKS.png)\n\n![](https://s1.ax1x.com/2020/11/08/BTeuDg.png)\n\n**Color Feature**\n![](https://s1.ax1x.com/2020/11/08/BTeQEj.png)\n\n**Gradient** *Extract the edge info*\n![](https://s1.ax1x.com/2020/11/08/BTelUs.png)\n\n**NLP?**\n![](https://s1.ax1x.com/2020/11/08/BTeG80.png)\n\n> clustering different image patches from images\n\n![](https://s1.ax1x.com/2020/11/08/BTe15n.png)\n- Differences\n1. Extract the Feature at first and feed into the linear classificator\n2. Convolutional Neutral Network would learn the feature automatically during the training process.","source":"_posts/CS231n/CS231n_02_Loss-Functions-and-Optimization.md","raw":"---\ntitle: CS231n Loss Functions and Optimization 02\ndate: 2020-11-08 20:52:06\ntags: [CV,Neural Network]\ncategory: [CS231n]\nindex_img: /img/Cs231n/top.jpg\nmath: true\n---\n\n### Preview the Goal in this lecture\n1. Define a loss function\n2. Come up with a way of finding the paras that minimize the (1)\n(optimization)\n\n**The Remain Problem from last lecture**\n\n- How to choose the W para ? \n\n![](https://s1.ax1x.com/2020/11/08/BTZxgK.png)\n\n### Loss function\n\n> A loss function tells how good our current classifier is.\n\n$${(x_i,y_i)}_{i=1}^N$$\n\nThe $X_i$ is image and the $y_i$ is label (int)\n\nThe Total loss is defined as the func follows.\n\n$$L = \\frac{1}{N}\\sum\\limits_iL_i(f(x_i,W),y_i)$$\n*Which is the sum of every single test's loss*\n\n---\n\n#### **Muticlass SVM loss**\n\nGiven an example $(x_i,y_i)$ where $x_i$ is the image and where $y_i$ is the (int) label, using the shorthand for the score vec $s = f(x_i,W)$\n\nThe SVM loss has the form:\n\n![](https://s1.ax1x.com/2020/11/08/BTZ7B4.png)\n\n> if the incorrect score is smaller than the right score (x margin), we set the loss to 0.\nin this case the safe margin is set to one\n**Margin choice depends on our need**\n\n\n- Then we loop the class\n\n![](https://s1.ax1x.com/2020/11/08/BTZqE9.png)\n\n![](https://s1.ax1x.com/2020/11/08/BTZLNR.png)\n\n- What if we use\n\n$$L = \\frac{1}{N}\\sum\\limits_iL_i(f(x_i,W),y_i)^2$$\n> This is not a linear function and totally different, it's may be useful sometimes depends on the way you care about the errors.\n\n#### Example Code\n\n```python\ndef L_i_vectorized(x, y, W):\n    scores = W.dot(x)\n    margins = np.maximun(0, scores - scores[y] + margin)\n    margins[y] = 0\n    loss_i = np.sum(margins)\n    return loss_i\n    # pretty easy\n```\n\n![](https://s1.ax1x.com/2020/11/08/BTZO41.png)\n\n> It just change the gap bettween scores\n\n![](https://s1.ax1x.com/2020/11/08/BTZzjO.png)\n\n![](https://s1.ax1x.com/2020/11/08/BTe9De.png)\n\n> often use L2 regularization just Euclid norm.\n\n![](https://s1.ax1x.com/2020/11/08/BTepuD.png)\n\n> In this case the L1 and L2 reg is equal, but we can tell that L1 prefers the $w_1$ for it contains more zero, while the L2 prefers the $w_2$ for the weight is evenly spreaded through the test case.\n\n> The Multiclass SVM loss just care about the gap bettween the right labels and the wrongs.\n\n#### **Softmax Classifier**\n\n![](https://s1.ax1x.com/2020/11/08/BTeiEd.png)\n\n> We just want to make the true probability closer to 1 (closer the better, eq is the best), so the loss func can be chosed by using the -log on the $P$.\n\n![](https://s1.ax1x.com/2020/11/08/BTeCHH.png)\n\n> If we want to get the zero loss, the score may goes to inf! But Computer don't like that.\n\n- Debugging Way\noutcomes might be $logC$\n\n---\n\n![](https://s1.ax1x.com/2020/11/08/BTek4I.png)\n\n![](https://s1.ax1x.com/2020/11/08/BTeECt.png)\n\n---\n\n### Optimization\n\n#### Random Search - The Naive but Simplest way \n> Really Slow !!!\n\n#### Gradient Descent\n> We just get the Gradient of W and go down to the bottom (maybe local best?)\n\n![](https://s1.ax1x.com/2020/11/08/BTeFUA.png)\n\n**Code**\n\n```python\n# Vanilla Gradient Descent\n\nwhile True:\n    weight_grad = evaluate_gradient(loss_fun, data, weights)\n    weights += -step_size * weight_grad\n```\n\n**Step size is called elearning rate which is important**\n\n![](https://s1.ax1x.com/2020/11/08/BTeV8P.png)\n\n> Since the N might be super large, we sample some sets called minibatch and use it to estimate the true gradient.\n\n![](https://s1.ax1x.com/2020/11/08/BTeZgf.png)\n\n\n---\n\n![](https://s1.ax1x.com/2020/11/08/BTenKS.png)\n\n![](https://s1.ax1x.com/2020/11/08/BTeuDg.png)\n\n**Color Feature**\n![](https://s1.ax1x.com/2020/11/08/BTeQEj.png)\n\n**Gradient** *Extract the edge info*\n![](https://s1.ax1x.com/2020/11/08/BTelUs.png)\n\n**NLP?**\n![](https://s1.ax1x.com/2020/11/08/BTeG80.png)\n\n> clustering different image patches from images\n\n![](https://s1.ax1x.com/2020/11/08/BTe15n.png)\n- Differences\n1. Extract the Feature at first and feed into the linear classificator\n2. Convolutional Neutral Network would learn the feature automatically during the training process.","slug":"CS231n/CS231n_02_Loss-Functions-and-Optimization","published":1,"updated":"2020-12-09T01:22:49.814Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty3z0010s8pd87d906th","content":"<h3 id=\"Preview-the-Goal-in-this-lecture\"><a href=\"#Preview-the-Goal-in-this-lecture\" class=\"headerlink\" title=\"Preview the Goal in this lecture\"></a>Preview the Goal in this lecture</h3><ol>\n<li>Define a loss function</li>\n<li>Come up with a way of finding the paras that minimize the (1)<br>(optimization)</li>\n</ol>\n<p><strong>The Remain Problem from last lecture</strong></p>\n<ul>\n<li>How to choose the W para ? </li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZxgK.png\" alt></p>\n<h3 id=\"Loss-function\"><a href=\"#Loss-function\" class=\"headerlink\" title=\"Loss function\"></a>Loss function</h3><blockquote>\n<p>A loss function tells how good our current classifier is.</p>\n</blockquote>\n<script type=\"math/tex; mode=display\">{(x_i,y_i)}_{i=1}^N</script><p>The $X_i$ is image and the $y_i$ is label (int)</p>\n<p>The Total loss is defined as the func follows.</p>\n<script type=\"math/tex; mode=display\">L = \\frac{1}{N}\\sum\\limits_iL_i(f(x_i,W),y_i)</script><p><em>Which is the sum of every single test’s loss</em></p>\n<hr>\n<h4 id=\"Muticlass-SVM-loss\"><a href=\"#Muticlass-SVM-loss\" class=\"headerlink\" title=\"Muticlass SVM loss\"></a><strong>Muticlass SVM loss</strong></h4><p>Given an example $(x_i,y_i)$ where $x_i$ is the image and where $y_i$ is the (int) label, using the shorthand for the score vec $s = f(x_i,W)$</p>\n<p>The SVM loss has the form:</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZ7B4.png\" alt></p>\n<blockquote>\n<p>if the incorrect score is smaller than the right score (x margin), we set the loss to 0.<br>in this case the safe margin is set to one<br><strong>Margin choice depends on our need</strong></p>\n</blockquote>\n<ul>\n<li>Then we loop the class</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZqE9.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZLNR.png\" alt></p>\n<ul>\n<li>What if we use</li>\n</ul>\n<script type=\"math/tex; mode=display\">L = \\frac{1}{N}\\sum\\limits_iL_i(f(x_i,W),y_i)^2</script><blockquote>\n<p>This is not a linear function and totally different, it’s may be useful sometimes depends on the way you care about the errors.</p>\n</blockquote>\n<h4 id=\"Example-Code\"><a href=\"#Example-Code\" class=\"headerlink\" title=\"Example Code\"></a>Example Code</h4><pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">L_i_vectorized</span>(<span class=\"hljs-params\">x, y, W</span>):</span>\n    scores = W.dot(x)\n    margins = np.maximun(<span class=\"hljs-number\">0</span>, scores - scores[y] + margin)\n    margins[y] = <span class=\"hljs-number\">0</span>\n    loss_i = np.<span class=\"hljs-built_in\">sum</span>(margins)\n    <span class=\"hljs-keyword\">return</span> loss_i\n    <span class=\"hljs-comment\"># pretty easy</span></code></pre>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZO41.png\" alt></p>\n<blockquote>\n<p>It just change the gap bettween scores</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZzjO.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTe9De.png\" alt></p>\n<blockquote>\n<p>often use L2 regularization just Euclid norm.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTepuD.png\" alt></p>\n<blockquote>\n<p>In this case the L1 and L2 reg is equal, but we can tell that L1 prefers the $w_1$ for it contains more zero, while the L2 prefers the $w_2$ for the weight is evenly spreaded through the test case.</p>\n<p>The Multiclass SVM loss just care about the gap bettween the right labels and the wrongs.</p>\n</blockquote>\n<h4 id=\"Softmax-Classifier\"><a href=\"#Softmax-Classifier\" class=\"headerlink\" title=\"Softmax Classifier\"></a><strong>Softmax Classifier</strong></h4><p><img src=\"https://s1.ax1x.com/2020/11/08/BTeiEd.png\" alt></p>\n<blockquote>\n<p>We just want to make the true probability closer to 1 (closer the better, eq is the best), so the loss func can be chosed by using the -log on the $P$.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeCHH.png\" alt></p>\n<blockquote>\n<p>If we want to get the zero loss, the score may goes to inf! But Computer don’t like that.</p>\n</blockquote>\n<ul>\n<li>Debugging Way<br>outcomes might be $logC$</li>\n</ul>\n<hr>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTek4I.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeECt.png\" alt></p>\n<hr>\n<h3 id=\"Optimization\"><a href=\"#Optimization\" class=\"headerlink\" title=\"Optimization\"></a>Optimization</h3><h4 id=\"Random-Search-The-Naive-but-Simplest-way\"><a href=\"#Random-Search-The-Naive-but-Simplest-way\" class=\"headerlink\" title=\"Random Search - The Naive but Simplest way\"></a>Random Search - The Naive but Simplest way</h4><blockquote>\n<p>Really Slow !!!</p>\n</blockquote>\n<h4 id=\"Gradient-Descent\"><a href=\"#Gradient-Descent\" class=\"headerlink\" title=\"Gradient Descent\"></a>Gradient Descent</h4><blockquote>\n<p>We just get the Gradient of W and go down to the bottom (maybe local best?)</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeFUA.png\" alt></p>\n<p><strong>Code</strong></p>\n<pre><code class=\"hljs python\"><span class=\"hljs-comment\"># Vanilla Gradient Descent</span>\n\n<span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n    weight_grad = evaluate_gradient(loss_fun, data, weights)\n    weights += -step_size * weight_grad</code></pre>\n<p><strong>Step size is called elearning rate which is important</strong></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeV8P.png\" alt></p>\n<blockquote>\n<p>Since the N might be super large, we sample some sets called minibatch and use it to estimate the true gradient.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeZgf.png\" alt></p>\n<hr>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTenKS.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeuDg.png\" alt></p>\n<p><strong>Color Feature</strong><br><img src=\"https://s1.ax1x.com/2020/11/08/BTeQEj.png\" alt></p>\n<p><strong>Gradient</strong> <em>Extract the edge info</em><br><img src=\"https://s1.ax1x.com/2020/11/08/BTelUs.png\" alt></p>\n<p><strong>NLP?</strong><br><img src=\"https://s1.ax1x.com/2020/11/08/BTeG80.png\" alt></p>\n<blockquote>\n<p>clustering different image patches from images</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTe15n.png\" alt></p>\n<ul>\n<li>Differences</li>\n</ul>\n<ol>\n<li>Extract the Feature at first and feed into the linear classificator</li>\n<li>Convolutional Neutral Network would learn the feature automatically during the training process.</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Preview-the-Goal-in-this-lecture\"><a href=\"#Preview-the-Goal-in-this-lecture\" class=\"headerlink\" title=\"Preview the Goal in this lecture\"></a>Preview the Goal in this lecture</h3><ol>\n<li>Define a loss function</li>\n<li>Come up with a way of finding the paras that minimize the (1)<br>(optimization)</li>\n</ol>\n<p><strong>The Remain Problem from last lecture</strong></p>\n<ul>\n<li>How to choose the W para ? </li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZxgK.png\" alt></p>\n<h3 id=\"Loss-function\"><a href=\"#Loss-function\" class=\"headerlink\" title=\"Loss function\"></a>Loss function</h3><blockquote>\n<p>A loss function tells how good our current classifier is.</p>\n</blockquote>\n<script type=\"math/tex; mode=display\">{(x_i,y_i)}_{i=1}^N</script><p>The $X_i$ is image and the $y_i$ is label (int)</p>\n<p>The Total loss is defined as the func follows.</p>\n<script type=\"math/tex; mode=display\">L = \\frac{1}{N}\\sum\\limits_iL_i(f(x_i,W),y_i)</script><p><em>Which is the sum of every single test’s loss</em></p>\n<hr>\n<h4 id=\"Muticlass-SVM-loss\"><a href=\"#Muticlass-SVM-loss\" class=\"headerlink\" title=\"Muticlass SVM loss\"></a><strong>Muticlass SVM loss</strong></h4><p>Given an example $(x_i,y_i)$ where $x_i$ is the image and where $y_i$ is the (int) label, using the shorthand for the score vec $s = f(x_i,W)$</p>\n<p>The SVM loss has the form:</p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZ7B4.png\" alt></p>\n<blockquote>\n<p>if the incorrect score is smaller than the right score (x margin), we set the loss to 0.<br>in this case the safe margin is set to one<br><strong>Margin choice depends on our need</strong></p>\n</blockquote>\n<ul>\n<li>Then we loop the class</li>\n</ul>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZqE9.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZLNR.png\" alt></p>\n<ul>\n<li>What if we use</li>\n</ul>\n<script type=\"math/tex; mode=display\">L = \\frac{1}{N}\\sum\\limits_iL_i(f(x_i,W),y_i)^2</script><blockquote>\n<p>This is not a linear function and totally different, it’s may be useful sometimes depends on the way you care about the errors.</p>\n</blockquote>\n<h4 id=\"Example-Code\"><a href=\"#Example-Code\" class=\"headerlink\" title=\"Example Code\"></a>Example Code</h4><pre><code class=\"hljs python\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">L_i_vectorized</span>(<span class=\"hljs-params\">x, y, W</span>):</span>\n    scores = W.dot(x)\n    margins = np.maximun(<span class=\"hljs-number\">0</span>, scores - scores[y] + margin)\n    margins[y] = <span class=\"hljs-number\">0</span>\n    loss_i = np.<span class=\"hljs-built_in\">sum</span>(margins)\n    <span class=\"hljs-keyword\">return</span> loss_i\n    <span class=\"hljs-comment\"># pretty easy</span></code></pre>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZO41.png\" alt></p>\n<blockquote>\n<p>It just change the gap bettween scores</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTZzjO.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTe9De.png\" alt></p>\n<blockquote>\n<p>often use L2 regularization just Euclid norm.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTepuD.png\" alt></p>\n<blockquote>\n<p>In this case the L1 and L2 reg is equal, but we can tell that L1 prefers the $w_1$ for it contains more zero, while the L2 prefers the $w_2$ for the weight is evenly spreaded through the test case.</p>\n<p>The Multiclass SVM loss just care about the gap bettween the right labels and the wrongs.</p>\n</blockquote>\n<h4 id=\"Softmax-Classifier\"><a href=\"#Softmax-Classifier\" class=\"headerlink\" title=\"Softmax Classifier\"></a><strong>Softmax Classifier</strong></h4><p><img src=\"https://s1.ax1x.com/2020/11/08/BTeiEd.png\" alt></p>\n<blockquote>\n<p>We just want to make the true probability closer to 1 (closer the better, eq is the best), so the loss func can be chosed by using the -log on the $P$.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeCHH.png\" alt></p>\n<blockquote>\n<p>If we want to get the zero loss, the score may goes to inf! But Computer don’t like that.</p>\n</blockquote>\n<ul>\n<li>Debugging Way<br>outcomes might be $logC$</li>\n</ul>\n<hr>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTek4I.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeECt.png\" alt></p>\n<hr>\n<h3 id=\"Optimization\"><a href=\"#Optimization\" class=\"headerlink\" title=\"Optimization\"></a>Optimization</h3><h4 id=\"Random-Search-The-Naive-but-Simplest-way\"><a href=\"#Random-Search-The-Naive-but-Simplest-way\" class=\"headerlink\" title=\"Random Search - The Naive but Simplest way\"></a>Random Search - The Naive but Simplest way</h4><blockquote>\n<p>Really Slow !!!</p>\n</blockquote>\n<h4 id=\"Gradient-Descent\"><a href=\"#Gradient-Descent\" class=\"headerlink\" title=\"Gradient Descent\"></a>Gradient Descent</h4><blockquote>\n<p>We just get the Gradient of W and go down to the bottom (maybe local best?)</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeFUA.png\" alt></p>\n<p><strong>Code</strong></p>\n<pre><code class=\"hljs python\"><span class=\"hljs-comment\"># Vanilla Gradient Descent</span>\n\n<span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n    weight_grad = evaluate_gradient(loss_fun, data, weights)\n    weights += -step_size * weight_grad</code></pre>\n<p><strong>Step size is called elearning rate which is important</strong></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeV8P.png\" alt></p>\n<blockquote>\n<p>Since the N might be super large, we sample some sets called minibatch and use it to estimate the true gradient.</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeZgf.png\" alt></p>\n<hr>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTenKS.png\" alt></p>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTeuDg.png\" alt></p>\n<p><strong>Color Feature</strong><br><img src=\"https://s1.ax1x.com/2020/11/08/BTeQEj.png\" alt></p>\n<p><strong>Gradient</strong> <em>Extract the edge info</em><br><img src=\"https://s1.ax1x.com/2020/11/08/BTelUs.png\" alt></p>\n<p><strong>NLP?</strong><br><img src=\"https://s1.ax1x.com/2020/11/08/BTeG80.png\" alt></p>\n<blockquote>\n<p>clustering different image patches from images</p>\n</blockquote>\n<p><img src=\"https://s1.ax1x.com/2020/11/08/BTe15n.png\" alt></p>\n<ul>\n<li>Differences</li>\n</ul>\n<ol>\n<li>Extract the Feature at first and feed into the linear classificator</li>\n<li>Convolutional Neutral Network would learn the feature automatically during the training process.</li>\n</ol>\n"},{"title":"PointCNN论文阅读","date":"2020-12-08T12:00:23.000Z","index_img":"/img/Pic/cnn_img.jpeg","banner_img":"/img/Pic/PointCloud.jpg","math":true,"_content":"\n# PointCNN\n\n回顾之前读过的 PointNet++ 是受到 CNN 启发，通过局部的特征提取器和hierarchy 结构解决了 PointNet 在 local 上的劣势。但同时这种基于 PointNet 的顺序不依赖性使用的 symmetry function 最终总会导致一部分的信息丢失，PointCNN 直接使用 CNN 架构和一种自定义的 $\\chi -Conv$ 操作，使常规的卷积也能处理点云。\n\n---\n\n## 关键问题 - PointCloud 上的卷积\n\n我们都知道普通的 2d 卷积的实现方式，因为在图片上像素都是紧密相连的，很好实现，但对于 3d 的 Points 点的空间位置，距离，顺序都会对卷积造成挑战和影响，下图就展示了普通的 2d卷积 和 3d PointCloud 卷积的区别。\n\n![](https://s3.ax1x.com/2020/12/08/r9iVTU.png)\n\n\n显然 PointCloud 上的卷积和形状(即点的相对位置) 和输入顺序有关。如果直接在上面做卷积就会发生灾难。\n\n![](https://s3.ax1x.com/2020/12/08/r9infJ.png)\n\n上图我们看出，直接做卷积的话 $f_{ii}$ 和 $f_{iii}$ 不同的形状信息被丢失了（这正是我们希望保留的），而 $f_{iii}$ 与 $f_{iv}$ 之间仅因为顺序不同而造成了结果不同，即顺序有关，这是我们不希望看到的。\n\n对于这个的解决方式，PointCNN 的作者使用了一个 $\\chi$ - transformer 矩阵，先对 sample point 作用 $\\chi$ 变换矩阵，再进行 Convolution 从而做到顺序无关的同时，不像 symmetry function 会丢失信息。\n\n![有点懒得翻译了，直接放原文](https://s3.ax1x.com/2020/12/08/r9ilOx.png)\n\n可以看出这个 $\\chi$ - transformation 是通过训练一个多层感知机获得的。同时产生输入点集的权重和排序，进而直接作用一个经典的卷积。\n\n![](https://s3.ax1x.com/2020/12/08/r9imY4.png)\n\n简单来说就是我们希望对于 $\\chi_{iii}$ 、 $\\chi_{iv}$ 对于 $f_{iii}$ 、 $f_{iv}$ 的作用能够得到相同的feature，一种简单的实现方式就是找到一个变换矩阵 $\\Pi$ 使得 $f_{iii}^{T} = \\Pi \\times f_{iv}^T$ 这样  $\\chi_{iii} = \\chi_{iv} \\times \\Pi$ 就可以达到目标。\n\n值得注意的是，多层感知机得出的 $\\Pi$ 并非一定是理想化的0101矩阵，而是有如0.1，0.9这样接近01的值，也可以将其理解为 feature 的权重这样得到的结果并不是完美的 即 $f_{iii}^{T} ≈ \\Pi \\times f_{iv}^T$\n\n---\n\n## 点云的平移不变性\n\n对于平移不变性的处理 PointCNN 很简单的使用了局部坐标系的转换，对于分割问题，采用最远点采样方式，然后对于采样点取 k - nearnest neighbours 将坐标系转换到采样点为中心的局部坐标系(即减去采样点坐标)\n\n![](https://s3.ax1x.com/2020/12/08/r9iekF.png)\n\n对于卷积层，具体算法如下\n\n![](https://s3.ax1x.com/2020/12/08/r9i3m6.png)\n\n- 先做feature的选点和聚合，先转换到采样点局部坐标系\n- 利用MLP将每个点变换到高维空间$C_{\\delta}$ （这里用的是一维卷积）\n- Concat 其他特征信息\n- **对每个局部区域中的点使用MLP，得到变换矩阵X**\n- 将得到的 $\\chi$ 作用在 $F_*$ 上生成顺序不依赖的 $F_{\\chi}$\n- 对顺序不依赖的 $F_{\\chi}$ 做 Convolution (这里也是一维卷积)\n\n## 可视化\n\n![](https://s3.ax1x.com/2020/12/08/r9i80K.png)\n\n对于 $\\chi$ - transformer 的效果有上图的 visualization 可以看到 $F_*$ 中不同的 class 还是有overlap的因为对于 $F_*$ 其仅将特征提取到了高维，但其结果还是依赖于输入的顺序，所以不能够很好的划分featrue，而经过了 $\\chi$ - transformer 不同的feature 被划分开来且更为密集，结果较好。\n\n## 模型效果\n\n![](https://s3.ax1x.com/2020/12/08/r9iMlR.png)\n\n可以看到准确率保持在一个比较高的水平。\n\n![](https://s3.ax1x.com/2020/12/08/r9iQ61.png)\n\n同时 PointCNN 具有更少的参数 (0.6M) 以及极快的速度 (0.012s)\nPointCNN 极具前景可以将 CNN 现有的工作进行应用。后续会看 PointCNN++ 等论文。\n\n## 总结\n\nPointCNN 直接将点云和CNN结合将点云的工作引入到了一个开阔的领域，但近来也有一些工作在质疑 CNN 的必要性，google 的论文 Attention is all you need 就指出在 NLP 领域 transformer attention based 方法巨大的前景，也为 3D instance segmentation 提供了新思路。\n关于 PointCNN 这篇经典读的还不是很透，关于 sample 选点的顺序问题和一些训练细节还没有弄的很懂，之后找时间细看。","source":"_posts/Research/PointCNN.md","raw":"---\ntitle: PointCNN论文阅读\ndate: 2020-12-08 20:00:23\nindex_img: /img/Pic/cnn_img.jpeg\nbanner_img: /img/Pic/PointCloud.jpg\ncategory: [Research]\ntags: PointCNN\nmath: true\n---\n\n# PointCNN\n\n回顾之前读过的 PointNet++ 是受到 CNN 启发，通过局部的特征提取器和hierarchy 结构解决了 PointNet 在 local 上的劣势。但同时这种基于 PointNet 的顺序不依赖性使用的 symmetry function 最终总会导致一部分的信息丢失，PointCNN 直接使用 CNN 架构和一种自定义的 $\\chi -Conv$ 操作，使常规的卷积也能处理点云。\n\n---\n\n## 关键问题 - PointCloud 上的卷积\n\n我们都知道普通的 2d 卷积的实现方式，因为在图片上像素都是紧密相连的，很好实现，但对于 3d 的 Points 点的空间位置，距离，顺序都会对卷积造成挑战和影响，下图就展示了普通的 2d卷积 和 3d PointCloud 卷积的区别。\n\n![](https://s3.ax1x.com/2020/12/08/r9iVTU.png)\n\n\n显然 PointCloud 上的卷积和形状(即点的相对位置) 和输入顺序有关。如果直接在上面做卷积就会发生灾难。\n\n![](https://s3.ax1x.com/2020/12/08/r9infJ.png)\n\n上图我们看出，直接做卷积的话 $f_{ii}$ 和 $f_{iii}$ 不同的形状信息被丢失了（这正是我们希望保留的），而 $f_{iii}$ 与 $f_{iv}$ 之间仅因为顺序不同而造成了结果不同，即顺序有关，这是我们不希望看到的。\n\n对于这个的解决方式，PointCNN 的作者使用了一个 $\\chi$ - transformer 矩阵，先对 sample point 作用 $\\chi$ 变换矩阵，再进行 Convolution 从而做到顺序无关的同时，不像 symmetry function 会丢失信息。\n\n![有点懒得翻译了，直接放原文](https://s3.ax1x.com/2020/12/08/r9ilOx.png)\n\n可以看出这个 $\\chi$ - transformation 是通过训练一个多层感知机获得的。同时产生输入点集的权重和排序，进而直接作用一个经典的卷积。\n\n![](https://s3.ax1x.com/2020/12/08/r9imY4.png)\n\n简单来说就是我们希望对于 $\\chi_{iii}$ 、 $\\chi_{iv}$ 对于 $f_{iii}$ 、 $f_{iv}$ 的作用能够得到相同的feature，一种简单的实现方式就是找到一个变换矩阵 $\\Pi$ 使得 $f_{iii}^{T} = \\Pi \\times f_{iv}^T$ 这样  $\\chi_{iii} = \\chi_{iv} \\times \\Pi$ 就可以达到目标。\n\n值得注意的是，多层感知机得出的 $\\Pi$ 并非一定是理想化的0101矩阵，而是有如0.1，0.9这样接近01的值，也可以将其理解为 feature 的权重这样得到的结果并不是完美的 即 $f_{iii}^{T} ≈ \\Pi \\times f_{iv}^T$\n\n---\n\n## 点云的平移不变性\n\n对于平移不变性的处理 PointCNN 很简单的使用了局部坐标系的转换，对于分割问题，采用最远点采样方式，然后对于采样点取 k - nearnest neighbours 将坐标系转换到采样点为中心的局部坐标系(即减去采样点坐标)\n\n![](https://s3.ax1x.com/2020/12/08/r9iekF.png)\n\n对于卷积层，具体算法如下\n\n![](https://s3.ax1x.com/2020/12/08/r9i3m6.png)\n\n- 先做feature的选点和聚合，先转换到采样点局部坐标系\n- 利用MLP将每个点变换到高维空间$C_{\\delta}$ （这里用的是一维卷积）\n- Concat 其他特征信息\n- **对每个局部区域中的点使用MLP，得到变换矩阵X**\n- 将得到的 $\\chi$ 作用在 $F_*$ 上生成顺序不依赖的 $F_{\\chi}$\n- 对顺序不依赖的 $F_{\\chi}$ 做 Convolution (这里也是一维卷积)\n\n## 可视化\n\n![](https://s3.ax1x.com/2020/12/08/r9i80K.png)\n\n对于 $\\chi$ - transformer 的效果有上图的 visualization 可以看到 $F_*$ 中不同的 class 还是有overlap的因为对于 $F_*$ 其仅将特征提取到了高维，但其结果还是依赖于输入的顺序，所以不能够很好的划分featrue，而经过了 $\\chi$ - transformer 不同的feature 被划分开来且更为密集，结果较好。\n\n## 模型效果\n\n![](https://s3.ax1x.com/2020/12/08/r9iMlR.png)\n\n可以看到准确率保持在一个比较高的水平。\n\n![](https://s3.ax1x.com/2020/12/08/r9iQ61.png)\n\n同时 PointCNN 具有更少的参数 (0.6M) 以及极快的速度 (0.012s)\nPointCNN 极具前景可以将 CNN 现有的工作进行应用。后续会看 PointCNN++ 等论文。\n\n## 总结\n\nPointCNN 直接将点云和CNN结合将点云的工作引入到了一个开阔的领域，但近来也有一些工作在质疑 CNN 的必要性，google 的论文 Attention is all you need 就指出在 NLP 领域 transformer attention based 方法巨大的前景，也为 3D instance segmentation 提供了新思路。\n关于 PointCNN 这篇经典读的还不是很透，关于 sample 选点的顺序问题和一些训练细节还没有弄的很懂，之后找时间细看。","slug":"Research/PointCNN","published":1,"updated":"2020-12-09T01:21:42.237Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty400014s8pdbyq818pn","content":"<h1 id=\"PointCNN\"><a href=\"#PointCNN\" class=\"headerlink\" title=\"PointCNN\"></a>PointCNN</h1><p>回顾之前读过的 PointNet++ 是受到 CNN 启发，通过局部的特征提取器和hierarchy 结构解决了 PointNet 在 local 上的劣势。但同时这种基于 PointNet 的顺序不依赖性使用的 symmetry function 最终总会导致一部分的信息丢失，PointCNN 直接使用 CNN 架构和一种自定义的 $\\chi -Conv$ 操作，使常规的卷积也能处理点云。</p>\n<hr>\n<h2 id=\"关键问题-PointCloud-上的卷积\"><a href=\"#关键问题-PointCloud-上的卷积\" class=\"headerlink\" title=\"关键问题 - PointCloud 上的卷积\"></a>关键问题 - PointCloud 上的卷积</h2><p>我们都知道普通的 2d 卷积的实现方式，因为在图片上像素都是紧密相连的，很好实现，但对于 3d 的 Points 点的空间位置，距离，顺序都会对卷积造成挑战和影响，下图就展示了普通的 2d卷积 和 3d PointCloud 卷积的区别。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9iVTU.png\" alt></p>\n<p>显然 PointCloud 上的卷积和形状(即点的相对位置) 和输入顺序有关。如果直接在上面做卷积就会发生灾难。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9infJ.png\" alt></p>\n<p>上图我们看出，直接做卷积的话 $f<em>{ii}$ 和 $f</em>{iii}$ 不同的形状信息被丢失了（这正是我们希望保留的），而 $f<em>{iii}$ 与 $f</em>{iv}$ 之间仅因为顺序不同而造成了结果不同，即顺序有关，这是我们不希望看到的。</p>\n<p>对于这个的解决方式，PointCNN 的作者使用了一个 $\\chi$ - transformer 矩阵，先对 sample point 作用 $\\chi$ 变换矩阵，再进行 Convolution 从而做到顺序无关的同时，不像 symmetry function 会丢失信息。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9ilOx.png\" alt=\"有点懒得翻译了，直接放原文\"></p>\n<p>可以看出这个 $\\chi$ - transformation 是通过训练一个多层感知机获得的。同时产生输入点集的权重和排序，进而直接作用一个经典的卷积。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9imY4.png\" alt></p>\n<p>简单来说就是我们希望对于 $\\chi<em>{iii}$ 、 $\\chi</em>{iv}$ 对于 $f<em>{iii}$ 、 $f</em>{iv}$ 的作用能够得到相同的feature，一种简单的实现方式就是找到一个变换矩阵 $\\Pi$ 使得 $f<em>{iii}^{T} = \\Pi \\times f</em>{iv}^T$ 这样  $\\chi<em>{iii} = \\chi</em>{iv} \\times \\Pi$ 就可以达到目标。</p>\n<p>值得注意的是，多层感知机得出的 $\\Pi$ 并非一定是理想化的0101矩阵，而是有如0.1，0.9这样接近01的值，也可以将其理解为 feature 的权重这样得到的结果并不是完美的 即 $f<em>{iii}^{T} ≈ \\Pi \\times f</em>{iv}^T$</p>\n<hr>\n<h2 id=\"点云的平移不变性\"><a href=\"#点云的平移不变性\" class=\"headerlink\" title=\"点云的平移不变性\"></a>点云的平移不变性</h2><p>对于平移不变性的处理 PointCNN 很简单的使用了局部坐标系的转换，对于分割问题，采用最远点采样方式，然后对于采样点取 k - nearnest neighbours 将坐标系转换到采样点为中心的局部坐标系(即减去采样点坐标)</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9iekF.png\" alt></p>\n<p>对于卷积层，具体算法如下</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9i3m6.png\" alt></p>\n<ul>\n<li>先做feature的选点和聚合，先转换到采样点局部坐标系</li>\n<li>利用MLP将每个点变换到高维空间$C_{\\delta}$ （这里用的是一维卷积）</li>\n<li>Concat 其他特征信息</li>\n<li><strong>对每个局部区域中的点使用MLP，得到变换矩阵X</strong></li>\n<li>将得到的 $\\chi$ 作用在 $F<em>*$ 上生成顺序不依赖的 $F</em>{\\chi}$</li>\n<li>对顺序不依赖的 $F_{\\chi}$ 做 Convolution (这里也是一维卷积)</li>\n</ul>\n<h2 id=\"可视化\"><a href=\"#可视化\" class=\"headerlink\" title=\"可视化\"></a>可视化</h2><p><img src=\"https://s3.ax1x.com/2020/12/08/r9i80K.png\" alt></p>\n<p>对于 $\\chi$ - transformer 的效果有上图的 visualization 可以看到 $F<em>*$ 中不同的 class 还是有overlap的因为对于 $F</em>*$ 其仅将特征提取到了高维，但其结果还是依赖于输入的顺序，所以不能够很好的划分featrue，而经过了 $\\chi$ - transformer 不同的feature 被划分开来且更为密集，结果较好。</p>\n<h2 id=\"模型效果\"><a href=\"#模型效果\" class=\"headerlink\" title=\"模型效果\"></a>模型效果</h2><p><img src=\"https://s3.ax1x.com/2020/12/08/r9iMlR.png\" alt></p>\n<p>可以看到准确率保持在一个比较高的水平。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9iQ61.png\" alt></p>\n<p>同时 PointCNN 具有更少的参数 (0.6M) 以及极快的速度 (0.012s)<br>PointCNN 极具前景可以将 CNN 现有的工作进行应用。后续会看 PointCNN++ 等论文。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>PointCNN 直接将点云和CNN结合将点云的工作引入到了一个开阔的领域，但近来也有一些工作在质疑 CNN 的必要性，google 的论文 Attention is all you need 就指出在 NLP 领域 transformer attention based 方法巨大的前景，也为 3D instance segmentation 提供了新思路。<br>关于 PointCNN 这篇经典读的还不是很透，关于 sample 选点的顺序问题和一些训练细节还没有弄的很懂，之后找时间细看。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"PointCNN\"><a href=\"#PointCNN\" class=\"headerlink\" title=\"PointCNN\"></a>PointCNN</h1><p>回顾之前读过的 PointNet++ 是受到 CNN 启发，通过局部的特征提取器和hierarchy 结构解决了 PointNet 在 local 上的劣势。但同时这种基于 PointNet 的顺序不依赖性使用的 symmetry function 最终总会导致一部分的信息丢失，PointCNN 直接使用 CNN 架构和一种自定义的 $\\chi -Conv$ 操作，使常规的卷积也能处理点云。</p>\n<hr>\n<h2 id=\"关键问题-PointCloud-上的卷积\"><a href=\"#关键问题-PointCloud-上的卷积\" class=\"headerlink\" title=\"关键问题 - PointCloud 上的卷积\"></a>关键问题 - PointCloud 上的卷积</h2><p>我们都知道普通的 2d 卷积的实现方式，因为在图片上像素都是紧密相连的，很好实现，但对于 3d 的 Points 点的空间位置，距离，顺序都会对卷积造成挑战和影响，下图就展示了普通的 2d卷积 和 3d PointCloud 卷积的区别。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9iVTU.png\" alt></p>\n<p>显然 PointCloud 上的卷积和形状(即点的相对位置) 和输入顺序有关。如果直接在上面做卷积就会发生灾难。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9infJ.png\" alt></p>\n<p>上图我们看出，直接做卷积的话 $f<em>{ii}$ 和 $f</em>{iii}$ 不同的形状信息被丢失了（这正是我们希望保留的），而 $f<em>{iii}$ 与 $f</em>{iv}$ 之间仅因为顺序不同而造成了结果不同，即顺序有关，这是我们不希望看到的。</p>\n<p>对于这个的解决方式，PointCNN 的作者使用了一个 $\\chi$ - transformer 矩阵，先对 sample point 作用 $\\chi$ 变换矩阵，再进行 Convolution 从而做到顺序无关的同时，不像 symmetry function 会丢失信息。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9ilOx.png\" alt=\"有点懒得翻译了，直接放原文\"></p>\n<p>可以看出这个 $\\chi$ - transformation 是通过训练一个多层感知机获得的。同时产生输入点集的权重和排序，进而直接作用一个经典的卷积。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9imY4.png\" alt></p>\n<p>简单来说就是我们希望对于 $\\chi<em>{iii}$ 、 $\\chi</em>{iv}$ 对于 $f<em>{iii}$ 、 $f</em>{iv}$ 的作用能够得到相同的feature，一种简单的实现方式就是找到一个变换矩阵 $\\Pi$ 使得 $f<em>{iii}^{T} = \\Pi \\times f</em>{iv}^T$ 这样  $\\chi<em>{iii} = \\chi</em>{iv} \\times \\Pi$ 就可以达到目标。</p>\n<p>值得注意的是，多层感知机得出的 $\\Pi$ 并非一定是理想化的0101矩阵，而是有如0.1，0.9这样接近01的值，也可以将其理解为 feature 的权重这样得到的结果并不是完美的 即 $f<em>{iii}^{T} ≈ \\Pi \\times f</em>{iv}^T$</p>\n<hr>\n<h2 id=\"点云的平移不变性\"><a href=\"#点云的平移不变性\" class=\"headerlink\" title=\"点云的平移不变性\"></a>点云的平移不变性</h2><p>对于平移不变性的处理 PointCNN 很简单的使用了局部坐标系的转换，对于分割问题，采用最远点采样方式，然后对于采样点取 k - nearnest neighbours 将坐标系转换到采样点为中心的局部坐标系(即减去采样点坐标)</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9iekF.png\" alt></p>\n<p>对于卷积层，具体算法如下</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9i3m6.png\" alt></p>\n<ul>\n<li>先做feature的选点和聚合，先转换到采样点局部坐标系</li>\n<li>利用MLP将每个点变换到高维空间$C_{\\delta}$ （这里用的是一维卷积）</li>\n<li>Concat 其他特征信息</li>\n<li><strong>对每个局部区域中的点使用MLP，得到变换矩阵X</strong></li>\n<li>将得到的 $\\chi$ 作用在 $F<em>*$ 上生成顺序不依赖的 $F</em>{\\chi}$</li>\n<li>对顺序不依赖的 $F_{\\chi}$ 做 Convolution (这里也是一维卷积)</li>\n</ul>\n<h2 id=\"可视化\"><a href=\"#可视化\" class=\"headerlink\" title=\"可视化\"></a>可视化</h2><p><img src=\"https://s3.ax1x.com/2020/12/08/r9i80K.png\" alt></p>\n<p>对于 $\\chi$ - transformer 的效果有上图的 visualization 可以看到 $F<em>*$ 中不同的 class 还是有overlap的因为对于 $F</em>*$ 其仅将特征提取到了高维，但其结果还是依赖于输入的顺序，所以不能够很好的划分featrue，而经过了 $\\chi$ - transformer 不同的feature 被划分开来且更为密集，结果较好。</p>\n<h2 id=\"模型效果\"><a href=\"#模型效果\" class=\"headerlink\" title=\"模型效果\"></a>模型效果</h2><p><img src=\"https://s3.ax1x.com/2020/12/08/r9iMlR.png\" alt></p>\n<p>可以看到准确率保持在一个比较高的水平。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/r9iQ61.png\" alt></p>\n<p>同时 PointCNN 具有更少的参数 (0.6M) 以及极快的速度 (0.012s)<br>PointCNN 极具前景可以将 CNN 现有的工作进行应用。后续会看 PointCNN++ 等论文。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>PointCNN 直接将点云和CNN结合将点云的工作引入到了一个开阔的领域，但近来也有一些工作在质疑 CNN 的必要性，google 的论文 Attention is all you need 就指出在 NLP 领域 transformer attention based 方法巨大的前景，也为 3D instance segmentation 提供了新思路。<br>关于 PointCNN 这篇经典读的还不是很透，关于 sample 选点的顺序问题和一些训练细节还没有弄的很懂，之后找时间细看。</p>\n"},{"title":"素数筛法 (2020-12-7)","index_img":"/img/Pic/DS.png","date":"2020-12-07T15:12:25.000Z","math":true,"_content":"\n# 素数筛法\n\n我们今天来讲讲筛法，今天上机出其不意的考了一手筛法，我居然天真的在写暴力素数判断。所以今天就来复习(重学)一下筛法。\n\n如果我们想要判断一个数是否是素数有什么方法呢？ 暴力判断肯定是最容易想到的方法，按定义素数不能被1和其自身以外的数整除，我们自然会想到从 x - 1到2全判一遍的算法。但显然，我们做了很多重复的工作。\n\n实际上我们可以发现，如果我们判断出了一个素数，那么它的倍数显然就不可能是素数，这样就可以直接将其开除“素籍“，踢出待选区域。这种筛选素数的方法就像一个筛子，每碰到一个素数就筛掉一批非素数，大大降低了复杂度。\n\n![](https://images2015.cnblogs.com/blog/927750/201612/927750-20161229220529101-1487746442.png)\n\n## 埃拉托斯特尼筛法\n\n按上述思想写出代码，就是埃氏筛法。\n\n- 代码实现\n\n```cpp\nint Eratosthenes(int n) {\n    int p = 0;\n    for (int i = 0; i <= n; ++i) \n        is_prime[i] = 1;\n    is_prime[0] = is_prime[1] = 0;\n    for (int i = 2; i <= n; ++i) \n    {\n        if (is_prime[i]) // 直接从2开筛不会放进来一个非素数\n        {\n            prime[p++] = i; \n            if ((long long)i * i <= n)\n                for (int j = i * i; j <= n; j += i)\n                    // 因为从 2 到 i - 1 的倍数我们之前筛过了，这里直接从 i 的 i倍开始，提高了运行速度\n                    is_prime[j] = 0;  // 是i的倍数的均不是素数\n        }\n    }\n    return p;\n}\n```\n\n### 复杂度计算\n\n关于埃氏筛法的复杂度计算，我们来做一个推导，首先我们可以看出每次循环中，若当前素数是p，那么单次循环执行 n/p 次， 所以总的表达式就是 n 乘上所有素数的倒数和 $n\\sum_{p} \\frac{1}{p}$\n\n关于所有素数的倒数和，在欧拉相关的论文中有明确的估计。\n\n$$\\sum_{p\\le x} \\frac{1}{p} = \\ln\\ln(x) + \\gamma + \\sum_{m = 2}^{\\infty}{\\mu (m){\\frac{\\zeta(m)}{m} + \\delta}}$$\n论文链接 [https://arxiv.org/pdf/math/0504289.pdf]\n\n可知埃氏筛法的复杂度为 $O(nloglogn)$\n\n---\n\n## 欧拉筛法 （线性筛）\n\nTODO","source":"_posts/DS/DataStructureNote2.md","raw":"---\ntitle: 素数筛法 (2020-12-7)\nindex_img: /img/Pic/DS.png\ndate: 2020-12-07 23:12:25\ncategory: [DataStructure]\ntags: [Number theory, Multiplication algorithm]\nmath: true\n---\n\n# 素数筛法\n\n我们今天来讲讲筛法，今天上机出其不意的考了一手筛法，我居然天真的在写暴力素数判断。所以今天就来复习(重学)一下筛法。\n\n如果我们想要判断一个数是否是素数有什么方法呢？ 暴力判断肯定是最容易想到的方法，按定义素数不能被1和其自身以外的数整除，我们自然会想到从 x - 1到2全判一遍的算法。但显然，我们做了很多重复的工作。\n\n实际上我们可以发现，如果我们判断出了一个素数，那么它的倍数显然就不可能是素数，这样就可以直接将其开除“素籍“，踢出待选区域。这种筛选素数的方法就像一个筛子，每碰到一个素数就筛掉一批非素数，大大降低了复杂度。\n\n![](https://images2015.cnblogs.com/blog/927750/201612/927750-20161229220529101-1487746442.png)\n\n## 埃拉托斯特尼筛法\n\n按上述思想写出代码，就是埃氏筛法。\n\n- 代码实现\n\n```cpp\nint Eratosthenes(int n) {\n    int p = 0;\n    for (int i = 0; i <= n; ++i) \n        is_prime[i] = 1;\n    is_prime[0] = is_prime[1] = 0;\n    for (int i = 2; i <= n; ++i) \n    {\n        if (is_prime[i]) // 直接从2开筛不会放进来一个非素数\n        {\n            prime[p++] = i; \n            if ((long long)i * i <= n)\n                for (int j = i * i; j <= n; j += i)\n                    // 因为从 2 到 i - 1 的倍数我们之前筛过了，这里直接从 i 的 i倍开始，提高了运行速度\n                    is_prime[j] = 0;  // 是i的倍数的均不是素数\n        }\n    }\n    return p;\n}\n```\n\n### 复杂度计算\n\n关于埃氏筛法的复杂度计算，我们来做一个推导，首先我们可以看出每次循环中，若当前素数是p，那么单次循环执行 n/p 次， 所以总的表达式就是 n 乘上所有素数的倒数和 $n\\sum_{p} \\frac{1}{p}$\n\n关于所有素数的倒数和，在欧拉相关的论文中有明确的估计。\n\n$$\\sum_{p\\le x} \\frac{1}{p} = \\ln\\ln(x) + \\gamma + \\sum_{m = 2}^{\\infty}{\\mu (m){\\frac{\\zeta(m)}{m} + \\delta}}$$\n论文链接 [https://arxiv.org/pdf/math/0504289.pdf]\n\n可知埃氏筛法的复杂度为 $O(nloglogn)$\n\n---\n\n## 欧拉筛法 （线性筛）\n\nTODO","slug":"DS/DataStructureNote2","published":1,"updated":"2020-12-09T01:23:27.173Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty410017s8pd5wk6cdeg","content":"<h1 id=\"素数筛法\"><a href=\"#素数筛法\" class=\"headerlink\" title=\"素数筛法\"></a>素数筛法</h1><p>我们今天来讲讲筛法，今天上机出其不意的考了一手筛法，我居然天真的在写暴力素数判断。所以今天就来复习(重学)一下筛法。</p>\n<p>如果我们想要判断一个数是否是素数有什么方法呢？ 暴力判断肯定是最容易想到的方法，按定义素数不能被1和其自身以外的数整除，我们自然会想到从 x - 1到2全判一遍的算法。但显然，我们做了很多重复的工作。</p>\n<p>实际上我们可以发现，如果我们判断出了一个素数，那么它的倍数显然就不可能是素数，这样就可以直接将其开除“素籍“，踢出待选区域。这种筛选素数的方法就像一个筛子，每碰到一个素数就筛掉一批非素数，大大降低了复杂度。</p>\n<p><img src=\"https://images2015.cnblogs.com/blog/927750/201612/927750-20161229220529101-1487746442.png\" alt></p>\n<h2 id=\"埃拉托斯特尼筛法\"><a href=\"#埃拉托斯特尼筛法\" class=\"headerlink\" title=\"埃拉托斯特尼筛法\"></a>埃拉托斯特尼筛法</h2><p>按上述思想写出代码，就是埃氏筛法。</p>\n<ul>\n<li>代码实现</li>\n</ul>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">Eratosthenes</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;\n    <span class=\"hljs-keyword\">int</span> p = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt;= n; ++i) \n        is_prime[i] = <span class=\"hljs-number\">1</span>;\n    is_prime[<span class=\"hljs-number\">0</span>] = is_prime[<span class=\"hljs-number\">1</span>] = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">2</span>; i &lt;= n; ++i) \n    &#123;\n        <span class=\"hljs-keyword\">if</span> (is_prime[i]) <span class=\"hljs-comment\">// 直接从2开筛不会放进来一个非素数</span>\n        &#123;\n            prime[p++] = i; \n            <span class=\"hljs-keyword\">if</span> ((<span class=\"hljs-keyword\">long</span> <span class=\"hljs-keyword\">long</span>)i * i &lt;= n)\n                <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> j = i * i; j &lt;= n; j += i)\n                    <span class=\"hljs-comment\">// 因为从 2 到 i - 1 的倍数我们之前筛过了，这里直接从 i 的 i倍开始，提高了运行速度</span>\n                    is_prime[j] = <span class=\"hljs-number\">0</span>;  <span class=\"hljs-comment\">// 是i的倍数的均不是素数</span>\n        &#125;\n    &#125;\n    <span class=\"hljs-keyword\">return</span> p;\n&#125;</code></pre>\n<h3 id=\"复杂度计算\"><a href=\"#复杂度计算\" class=\"headerlink\" title=\"复杂度计算\"></a>复杂度计算</h3><p>关于埃氏筛法的复杂度计算，我们来做一个推导，首先我们可以看出每次循环中，若当前素数是p，那么单次循环执行 n/p 次， 所以总的表达式就是 n 乘上所有素数的倒数和 $n\\sum_{p} \\frac{1}{p}$</p>\n<p>关于所有素数的倒数和，在欧拉相关的论文中有明确的估计。</p>\n<script type=\"math/tex; mode=display\">\\sum_{p\\le x} \\frac{1}{p} = \\ln\\ln(x) + \\gamma + \\sum_{m = 2}^{\\infty}{\\mu (m){\\frac{\\zeta(m)}{m} + \\delta}}</script><p>论文链接 [<a href=\"https://arxiv.org/pdf/math/0504289.pdf\">https://arxiv.org/pdf/math/0504289.pdf</a>]</p>\n<p>可知埃氏筛法的复杂度为 $O(nloglogn)$</p>\n<hr>\n<h2 id=\"欧拉筛法-（线性筛）\"><a href=\"#欧拉筛法-（线性筛）\" class=\"headerlink\" title=\"欧拉筛法 （线性筛）\"></a>欧拉筛法 （线性筛）</h2><p>TODO</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"素数筛法\"><a href=\"#素数筛法\" class=\"headerlink\" title=\"素数筛法\"></a>素数筛法</h1><p>我们今天来讲讲筛法，今天上机出其不意的考了一手筛法，我居然天真的在写暴力素数判断。所以今天就来复习(重学)一下筛法。</p>\n<p>如果我们想要判断一个数是否是素数有什么方法呢？ 暴力判断肯定是最容易想到的方法，按定义素数不能被1和其自身以外的数整除，我们自然会想到从 x - 1到2全判一遍的算法。但显然，我们做了很多重复的工作。</p>\n<p>实际上我们可以发现，如果我们判断出了一个素数，那么它的倍数显然就不可能是素数，这样就可以直接将其开除“素籍“，踢出待选区域。这种筛选素数的方法就像一个筛子，每碰到一个素数就筛掉一批非素数，大大降低了复杂度。</p>\n<p><img src=\"https://images2015.cnblogs.com/blog/927750/201612/927750-20161229220529101-1487746442.png\" alt></p>\n<h2 id=\"埃拉托斯特尼筛法\"><a href=\"#埃拉托斯特尼筛法\" class=\"headerlink\" title=\"埃拉托斯特尼筛法\"></a>埃拉托斯特尼筛法</h2><p>按上述思想写出代码，就是埃氏筛法。</p>\n<ul>\n<li>代码实现</li>\n</ul>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">Eratosthenes</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;\n    <span class=\"hljs-keyword\">int</span> p = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt;= n; ++i) \n        is_prime[i] = <span class=\"hljs-number\">1</span>;\n    is_prime[<span class=\"hljs-number\">0</span>] = is_prime[<span class=\"hljs-number\">1</span>] = <span class=\"hljs-number\">0</span>;\n    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">2</span>; i &lt;= n; ++i) \n    &#123;\n        <span class=\"hljs-keyword\">if</span> (is_prime[i]) <span class=\"hljs-comment\">// 直接从2开筛不会放进来一个非素数</span>\n        &#123;\n            prime[p++] = i; \n            <span class=\"hljs-keyword\">if</span> ((<span class=\"hljs-keyword\">long</span> <span class=\"hljs-keyword\">long</span>)i * i &lt;= n)\n                <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-keyword\">int</span> j = i * i; j &lt;= n; j += i)\n                    <span class=\"hljs-comment\">// 因为从 2 到 i - 1 的倍数我们之前筛过了，这里直接从 i 的 i倍开始，提高了运行速度</span>\n                    is_prime[j] = <span class=\"hljs-number\">0</span>;  <span class=\"hljs-comment\">// 是i的倍数的均不是素数</span>\n        &#125;\n    &#125;\n    <span class=\"hljs-keyword\">return</span> p;\n&#125;</code></pre>\n<h3 id=\"复杂度计算\"><a href=\"#复杂度计算\" class=\"headerlink\" title=\"复杂度计算\"></a>复杂度计算</h3><p>关于埃氏筛法的复杂度计算，我们来做一个推导，首先我们可以看出每次循环中，若当前素数是p，那么单次循环执行 n/p 次， 所以总的表达式就是 n 乘上所有素数的倒数和 $n\\sum_{p} \\frac{1}{p}$</p>\n<p>关于所有素数的倒数和，在欧拉相关的论文中有明确的估计。</p>\n<script type=\"math/tex; mode=display\">\\sum_{p\\le x} \\frac{1}{p} = \\ln\\ln(x) + \\gamma + \\sum_{m = 2}^{\\infty}{\\mu (m){\\frac{\\zeta(m)}{m} + \\delta}}</script><p>论文链接 [<a href=\"https://arxiv.org/pdf/math/0504289.pdf\">https://arxiv.org/pdf/math/0504289.pdf</a>]</p>\n<p>可知埃氏筛法的复杂度为 $O(nloglogn)$</p>\n<hr>\n<h2 id=\"欧拉筛法-（线性筛）\"><a href=\"#欧拉筛法-（线性筛）\" class=\"headerlink\" title=\"欧拉筛法 （线性筛）\"></a>欧拉筛法 （线性筛）</h2><p>TODO</p>\n"},{"title":"PointNet论文阅读","date":"2020-12-06T06:46:14.000Z","index_img":"/img/Pic/cnn_img.jpeg","banner_img":"/img/Pic/PointCloud.jpg","math":true,"_content":"\n### PointCloud\n\n何谓点云，点云数据和普通的照片又有什么不同？实际上点云并非什么高深的东西，下图就是一张点云的可视化数据。\n![点云街道](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1607249767189&di=e4964b8b875326b97e5ab06da6196601&imgtype=0&src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fq_70%2Cc_zoom%2Cw_640%2Fimages%2F20180118%2F537a4b5eab09459881f9bc6ca18834f9.jpeg)\n\n- **位置信息**\n不同于原先2D的图像，每个像素点仅有RGB信息，点云自带了欧式空间中的位置信息，即坐标(x,y,z) 之后会附带一些RGB灰度值之类的普通图像像素就具有的东西。\n\n了解了点云之后我们来解析一下PointNet这篇论文[1]\n\n---\n\n### 简介\n不同于当时许多处理3D点云任务时，直接将3D点云转化成体素矩阵(Voxel grid)的方式，但由于3D空间不同于2D大量的空间里都是空的(zero grid)，将他们全部体素化会造成不必要的浪费。PointNet可以**直接输入点云**信息，来解决这一问题，同时避免一些转换中造成的其他问题。\n\n### 点云数据的特点\n\n**1. 无序性 （Unordered）**\n我们都知道在欧式空间的度量中点和点之间是不存在像一维二维空间中的序关系的。(可能不严谨，数学不太好，暂时就这样理解)\n对于点云数据信息，每个点**喂入的顺序不应当影响到结果**\n\n**2. 局部相关性 (Interaction among points)**\n我们知道在**空间中的点和其周边点之间的位置关系信息是有意义的**，它代表了物体的形状特征。这正是我们在2D CNN工作中卷积层所提取的东西，因而我们要保留这个特征信息。\n\n**3. 不变性 （Invariance under transformation）**\n对于点云数据应该满足一些**空间变换的不变性**，例如平移和旋转，这些都不会影响最终的结果\n\nPointNet的工作就是尝试解决这三个问题。\n\n---\n\n### 网络结构\n\n![](https://pic1.zhimg.com/80/v2-8dc76710bd09c25d5c8196d6aff56fec_1440w.jpg)\n\n我们看一下 PointNet 的网络架构，首先喂入原始的 PointNet，是一个 $N\\times 3$ 的矩阵(n个点,xyz)先通过一个 $T-Net$ 层进行对齐，然后用感知机 mlp 进行特征提取，装换到 $N\\times 1024$ 1024维空间上再进行 Max Pooling 提取出 Global feature，然后就干自己该干的事去了，对分类任务，将全局特征通过mlp来预测最后的分类分数；对分割任务，将全局特征和之前学习到的各点云的局部特征进行串联，再通过mlp得到每个数据点的分类结果。\n下文会展开更详细的讲解\n\n### 解决无序性 (symmetry function)\n\n对于无序性 PointCloud 数据的处理当时一般有三种方法，\n- 1）对数据进行排序成 canonical order. \n\n对于这种方法，其实不存在一种高维空间的排序。由于CNN中数据抽象纬度很高，要保证高维中的点向一维的稳定映射无关数据顺序是十分困难的，所以其效果有限。\n\n- 2) 用大量打乱数据序列训练一个 RNN，寄希望于这种方式能消除顺序依赖\n\n这种方法看上去可行，然而其仍然无法做到完全顺序无关，在[2]中有详细证明。实验表示，这种方法对于小型数据具有一定鲁棒性，但对于大量point的场景仍然表现疲软。\n\n**3) 通过一个简单的对称函数来处理每个点，获得每个点的 Global signature**\n\n这是本文所使用的方法，很简单却很有效，我们知道一个symmetry function 的输出是无关顺序的, 例如我们熟悉的加法和乘法，这里选用了CNN中常用的 max 函数作为 symmetry function，通过 max pooling 消除数据顺序的影响。\n\n![](https://s3.ax1x.com/2020/12/08/rpks4e.png)\n\n$f$ 这个函数输出一个数据不依赖的值作为该组数据的 *Global signature* 每一个输入值 $x_{1\\to n}$ 是PointCloud中的点，带有 (x,y,z)位置信息以及一些rgb信息，组成共 $NxN$ 的矩阵，$h$ 是一个变换方程，将 $1\\times N$的向量转换为 $1\\times K$，然后 $g$ 就是我们的 symmetry function 将 $N\\times K$ 的矩阵映射到一个值 $R$ 就能够代表这组数据，因为 symmetry function 的顺序无关性，我们能够保证这个值对于相同数据的不同排列是相同的。\n\n---\n\n### 局部和全局数据聚合 (Local and Global Information Aggregation)\n\n这边先讲一下我自己的想法，我很怀疑它到底有没有做局部信息的处理，既解决第二个问题，据PointNet这篇文章自己写的这一章，他说他做了。然后后面PointNet++ 说他没做。我这段看的也比较迷惑，但我个人倾向于原作者尝试去做但做的比较弱。\n\n### 理论证明可行性 (Theory Analysis)\n![拟合可行性](https://pic3.zhimg.com/80/v2-1bee125c29ac11faba0e0a095207a396_1440w.jpg)\n\n这个定理说我们通过之前讲的 $h$ 和 Max pooling 操作能够拟合任意的连续集合函数 $f$\n最坏的拟合就是将其转换成空间中的体素，但通常来说我们的神经网络在调校的过程中都会得到更好的 $h$ 来完成这一过程。\n\nTODO: 详细证明过程在附录中我还没看\n\n![扰动下的鲁棒性](https://pic1.zhimg.com/80/v2-43d9f406855cf5e4681cb3de08382b80_1440w.jpg)\n\n定理二告诉了我们该模型在扰动之下具有鲁棒性，只要不影响关键点集 $C_S$，或者超出最密上限点集 $N_s$ 该模型所得出的 Global signature 都是相同的，(2) 指出关键点集的上限在于我们的转换函数 $h$ 转换的维数 $K$\n\n对于定理二原论文中有直观的图解帮助大家构造 intuition\n![](https://pic2.zhimg.com/80/v2-c1fc6e865ab685dcaefd18e8c063bef1_1440w.jpg)\n\n最后的结果在当时看来是非常不错的。\n![](https://s3.ax1x.com/2020/12/08/rpk2jI.png)\n\n## 总结\n\nPointNet 开创了3D点云的新纪元，日后的PointNet++，PointCNN等网络都是在其基础上发展起来的，作为点云的奠基其用十分简单的方式解决了3D点云数据的顺序 (symmetry function) 和空间不变性 (high demension). 但它没有很好的解决 Local 数据的关系，这一问题会在PointNet++中得到解决。\n\n最后说点自己的话，感觉现在读论文并不是很静得下心来，读的也很笼统不深入，被太多乱七八糟的事情困扰心烦意乱。但事情总得做下去，状态是在做事的过程中一点点找回来的，干等等不来。注重积累一点点来，相信自己在不久的将来能够做出一点自己的东西。\n\n### Reference\n[1] PointNet论文链接：https://arxiv.org/abs/1612.00593\n[2] O. Vinyals, S. Bengio, and M. Kudlur. Order mat\u0002ters: Sequence to sequence for sets. arXiv preprint arXiv:1511.06391, 2015.\n\n","source":"_posts/Research/PointNet.md","raw":"---\ntitle: PointNet论文阅读\ndate: 2020-12-06 14:46:14\nindex_img: /img/Pic/cnn_img.jpeg\nbanner_img: /img/Pic/PointCloud.jpg\ncategory: [Research]\ntags: PointNet\nmath: true\n---\n\n### PointCloud\n\n何谓点云，点云数据和普通的照片又有什么不同？实际上点云并非什么高深的东西，下图就是一张点云的可视化数据。\n![点云街道](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1607249767189&di=e4964b8b875326b97e5ab06da6196601&imgtype=0&src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fq_70%2Cc_zoom%2Cw_640%2Fimages%2F20180118%2F537a4b5eab09459881f9bc6ca18834f9.jpeg)\n\n- **位置信息**\n不同于原先2D的图像，每个像素点仅有RGB信息，点云自带了欧式空间中的位置信息，即坐标(x,y,z) 之后会附带一些RGB灰度值之类的普通图像像素就具有的东西。\n\n了解了点云之后我们来解析一下PointNet这篇论文[1]\n\n---\n\n### 简介\n不同于当时许多处理3D点云任务时，直接将3D点云转化成体素矩阵(Voxel grid)的方式，但由于3D空间不同于2D大量的空间里都是空的(zero grid)，将他们全部体素化会造成不必要的浪费。PointNet可以**直接输入点云**信息，来解决这一问题，同时避免一些转换中造成的其他问题。\n\n### 点云数据的特点\n\n**1. 无序性 （Unordered）**\n我们都知道在欧式空间的度量中点和点之间是不存在像一维二维空间中的序关系的。(可能不严谨，数学不太好，暂时就这样理解)\n对于点云数据信息，每个点**喂入的顺序不应当影响到结果**\n\n**2. 局部相关性 (Interaction among points)**\n我们知道在**空间中的点和其周边点之间的位置关系信息是有意义的**，它代表了物体的形状特征。这正是我们在2D CNN工作中卷积层所提取的东西，因而我们要保留这个特征信息。\n\n**3. 不变性 （Invariance under transformation）**\n对于点云数据应该满足一些**空间变换的不变性**，例如平移和旋转，这些都不会影响最终的结果\n\nPointNet的工作就是尝试解决这三个问题。\n\n---\n\n### 网络结构\n\n![](https://pic1.zhimg.com/80/v2-8dc76710bd09c25d5c8196d6aff56fec_1440w.jpg)\n\n我们看一下 PointNet 的网络架构，首先喂入原始的 PointNet，是一个 $N\\times 3$ 的矩阵(n个点,xyz)先通过一个 $T-Net$ 层进行对齐，然后用感知机 mlp 进行特征提取，装换到 $N\\times 1024$ 1024维空间上再进行 Max Pooling 提取出 Global feature，然后就干自己该干的事去了，对分类任务，将全局特征通过mlp来预测最后的分类分数；对分割任务，将全局特征和之前学习到的各点云的局部特征进行串联，再通过mlp得到每个数据点的分类结果。\n下文会展开更详细的讲解\n\n### 解决无序性 (symmetry function)\n\n对于无序性 PointCloud 数据的处理当时一般有三种方法，\n- 1）对数据进行排序成 canonical order. \n\n对于这种方法，其实不存在一种高维空间的排序。由于CNN中数据抽象纬度很高，要保证高维中的点向一维的稳定映射无关数据顺序是十分困难的，所以其效果有限。\n\n- 2) 用大量打乱数据序列训练一个 RNN，寄希望于这种方式能消除顺序依赖\n\n这种方法看上去可行，然而其仍然无法做到完全顺序无关，在[2]中有详细证明。实验表示，这种方法对于小型数据具有一定鲁棒性，但对于大量point的场景仍然表现疲软。\n\n**3) 通过一个简单的对称函数来处理每个点，获得每个点的 Global signature**\n\n这是本文所使用的方法，很简单却很有效，我们知道一个symmetry function 的输出是无关顺序的, 例如我们熟悉的加法和乘法，这里选用了CNN中常用的 max 函数作为 symmetry function，通过 max pooling 消除数据顺序的影响。\n\n![](https://s3.ax1x.com/2020/12/08/rpks4e.png)\n\n$f$ 这个函数输出一个数据不依赖的值作为该组数据的 *Global signature* 每一个输入值 $x_{1\\to n}$ 是PointCloud中的点，带有 (x,y,z)位置信息以及一些rgb信息，组成共 $NxN$ 的矩阵，$h$ 是一个变换方程，将 $1\\times N$的向量转换为 $1\\times K$，然后 $g$ 就是我们的 symmetry function 将 $N\\times K$ 的矩阵映射到一个值 $R$ 就能够代表这组数据，因为 symmetry function 的顺序无关性，我们能够保证这个值对于相同数据的不同排列是相同的。\n\n---\n\n### 局部和全局数据聚合 (Local and Global Information Aggregation)\n\n这边先讲一下我自己的想法，我很怀疑它到底有没有做局部信息的处理，既解决第二个问题，据PointNet这篇文章自己写的这一章，他说他做了。然后后面PointNet++ 说他没做。我这段看的也比较迷惑，但我个人倾向于原作者尝试去做但做的比较弱。\n\n### 理论证明可行性 (Theory Analysis)\n![拟合可行性](https://pic3.zhimg.com/80/v2-1bee125c29ac11faba0e0a095207a396_1440w.jpg)\n\n这个定理说我们通过之前讲的 $h$ 和 Max pooling 操作能够拟合任意的连续集合函数 $f$\n最坏的拟合就是将其转换成空间中的体素，但通常来说我们的神经网络在调校的过程中都会得到更好的 $h$ 来完成这一过程。\n\nTODO: 详细证明过程在附录中我还没看\n\n![扰动下的鲁棒性](https://pic1.zhimg.com/80/v2-43d9f406855cf5e4681cb3de08382b80_1440w.jpg)\n\n定理二告诉了我们该模型在扰动之下具有鲁棒性，只要不影响关键点集 $C_S$，或者超出最密上限点集 $N_s$ 该模型所得出的 Global signature 都是相同的，(2) 指出关键点集的上限在于我们的转换函数 $h$ 转换的维数 $K$\n\n对于定理二原论文中有直观的图解帮助大家构造 intuition\n![](https://pic2.zhimg.com/80/v2-c1fc6e865ab685dcaefd18e8c063bef1_1440w.jpg)\n\n最后的结果在当时看来是非常不错的。\n![](https://s3.ax1x.com/2020/12/08/rpk2jI.png)\n\n## 总结\n\nPointNet 开创了3D点云的新纪元，日后的PointNet++，PointCNN等网络都是在其基础上发展起来的，作为点云的奠基其用十分简单的方式解决了3D点云数据的顺序 (symmetry function) 和空间不变性 (high demension). 但它没有很好的解决 Local 数据的关系，这一问题会在PointNet++中得到解决。\n\n最后说点自己的话，感觉现在读论文并不是很静得下心来，读的也很笼统不深入，被太多乱七八糟的事情困扰心烦意乱。但事情总得做下去，状态是在做事的过程中一点点找回来的，干等等不来。注重积累一点点来，相信自己在不久的将来能够做出一点自己的东西。\n\n### Reference\n[1] PointNet论文链接：https://arxiv.org/abs/1612.00593\n[2] O. Vinyals, S. Bengio, and M. Kudlur. Order mat\u0002ters: Sequence to sequence for sets. arXiv preprint arXiv:1511.06391, 2015.\n\n","slug":"Research/PointNet","published":1,"updated":"2020-12-09T01:21:46.797Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty42001as8pdf47va6bd","content":"<h3 id=\"PointCloud\"><a href=\"#PointCloud\" class=\"headerlink\" title=\"PointCloud\"></a>PointCloud</h3><p>何谓点云，点云数据和普通的照片又有什么不同？实际上点云并非什么高深的东西，下图就是一张点云的可视化数据。<br><img src=\"https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1607249767189&amp;di=e4964b8b875326b97e5ab06da6196601&amp;imgtype=0&amp;src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fq_70%2Cc_zoom%2Cw_640%2Fimages%2F20180118%2F537a4b5eab09459881f9bc6ca18834f9.jpeg\" alt=\"点云街道\"></p>\n<ul>\n<li><strong>位置信息</strong><br>不同于原先2D的图像，每个像素点仅有RGB信息，点云自带了欧式空间中的位置信息，即坐标(x,y,z) 之后会附带一些RGB灰度值之类的普通图像像素就具有的东西。</li>\n</ul>\n<p>了解了点云之后我们来解析一下PointNet这篇论文[1]</p>\n<hr>\n<h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p>不同于当时许多处理3D点云任务时，直接将3D点云转化成体素矩阵(Voxel grid)的方式，但由于3D空间不同于2D大量的空间里都是空的(zero grid)，将他们全部体素化会造成不必要的浪费。PointNet可以<strong>直接输入点云</strong>信息，来解决这一问题，同时避免一些转换中造成的其他问题。</p>\n<h3 id=\"点云数据的特点\"><a href=\"#点云数据的特点\" class=\"headerlink\" title=\"点云数据的特点\"></a>点云数据的特点</h3><p><strong>1. 无序性 （Unordered）</strong><br>我们都知道在欧式空间的度量中点和点之间是不存在像一维二维空间中的序关系的。(可能不严谨，数学不太好，暂时就这样理解)<br>对于点云数据信息，每个点<strong>喂入的顺序不应当影响到结果</strong></p>\n<p><strong>2. 局部相关性 (Interaction among points)</strong><br>我们知道在<strong>空间中的点和其周边点之间的位置关系信息是有意义的</strong>，它代表了物体的形状特征。这正是我们在2D CNN工作中卷积层所提取的东西，因而我们要保留这个特征信息。</p>\n<p><strong>3. 不变性 （Invariance under transformation）</strong><br>对于点云数据应该满足一些<strong>空间变换的不变性</strong>，例如平移和旋转，这些都不会影响最终的结果</p>\n<p>PointNet的工作就是尝试解决这三个问题。</p>\n<hr>\n<h3 id=\"网络结构\"><a href=\"#网络结构\" class=\"headerlink\" title=\"网络结构\"></a>网络结构</h3><p><img src=\"https://pic1.zhimg.com/80/v2-8dc76710bd09c25d5c8196d6aff56fec_1440w.jpg\" alt></p>\n<p>我们看一下 PointNet 的网络架构，首先喂入原始的 PointNet，是一个 $N\\times 3$ 的矩阵(n个点,xyz)先通过一个 $T-Net$ 层进行对齐，然后用感知机 mlp 进行特征提取，装换到 $N\\times 1024$ 1024维空间上再进行 Max Pooling 提取出 Global feature，然后就干自己该干的事去了，对分类任务，将全局特征通过mlp来预测最后的分类分数；对分割任务，将全局特征和之前学习到的各点云的局部特征进行串联，再通过mlp得到每个数据点的分类结果。<br>下文会展开更详细的讲解</p>\n<h3 id=\"解决无序性-symmetry-function\"><a href=\"#解决无序性-symmetry-function\" class=\"headerlink\" title=\"解决无序性 (symmetry function)\"></a>解决无序性 (symmetry function)</h3><p>对于无序性 PointCloud 数据的处理当时一般有三种方法，</p>\n<ul>\n<li>1）对数据进行排序成 canonical order. </li>\n</ul>\n<p>对于这种方法，其实不存在一种高维空间的排序。由于CNN中数据抽象纬度很高，要保证高维中的点向一维的稳定映射无关数据顺序是十分困难的，所以其效果有限。</p>\n<ul>\n<li>2) 用大量打乱数据序列训练一个 RNN，寄希望于这种方式能消除顺序依赖</li>\n</ul>\n<p>这种方法看上去可行，然而其仍然无法做到完全顺序无关，在[2]中有详细证明。实验表示，这种方法对于小型数据具有一定鲁棒性，但对于大量point的场景仍然表现疲软。</p>\n<p><strong>3) 通过一个简单的对称函数来处理每个点，获得每个点的 Global signature</strong></p>\n<p>这是本文所使用的方法，很简单却很有效，我们知道一个symmetry function 的输出是无关顺序的, 例如我们熟悉的加法和乘法，这里选用了CNN中常用的 max 函数作为 symmetry function，通过 max pooling 消除数据顺序的影响。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/rpks4e.png\" alt></p>\n<p>$f$ 这个函数输出一个数据不依赖的值作为该组数据的 <em>Global signature</em> 每一个输入值 $x_{1\\to n}$ 是PointCloud中的点，带有 (x,y,z)位置信息以及一些rgb信息，组成共 $NxN$ 的矩阵，$h$ 是一个变换方程，将 $1\\times N$的向量转换为 $1\\times K$，然后 $g$ 就是我们的 symmetry function 将 $N\\times K$ 的矩阵映射到一个值 $R$ 就能够代表这组数据，因为 symmetry function 的顺序无关性，我们能够保证这个值对于相同数据的不同排列是相同的。</p>\n<hr>\n<h3 id=\"局部和全局数据聚合-Local-and-Global-Information-Aggregation\"><a href=\"#局部和全局数据聚合-Local-and-Global-Information-Aggregation\" class=\"headerlink\" title=\"局部和全局数据聚合 (Local and Global Information Aggregation)\"></a>局部和全局数据聚合 (Local and Global Information Aggregation)</h3><p>这边先讲一下我自己的想法，我很怀疑它到底有没有做局部信息的处理，既解决第二个问题，据PointNet这篇文章自己写的这一章，他说他做了。然后后面PointNet++ 说他没做。我这段看的也比较迷惑，但我个人倾向于原作者尝试去做但做的比较弱。</p>\n<h3 id=\"理论证明可行性-Theory-Analysis\"><a href=\"#理论证明可行性-Theory-Analysis\" class=\"headerlink\" title=\"理论证明可行性 (Theory Analysis)\"></a>理论证明可行性 (Theory Analysis)</h3><p><img src=\"https://pic3.zhimg.com/80/v2-1bee125c29ac11faba0e0a095207a396_1440w.jpg\" alt=\"拟合可行性\"></p>\n<p>这个定理说我们通过之前讲的 $h$ 和 Max pooling 操作能够拟合任意的连续集合函数 $f$<br>最坏的拟合就是将其转换成空间中的体素，但通常来说我们的神经网络在调校的过程中都会得到更好的 $h$ 来完成这一过程。</p>\n<p>TODO: 详细证明过程在附录中我还没看</p>\n<p><img src=\"https://pic1.zhimg.com/80/v2-43d9f406855cf5e4681cb3de08382b80_1440w.jpg\" alt=\"扰动下的鲁棒性\"></p>\n<p>定理二告诉了我们该模型在扰动之下具有鲁棒性，只要不影响关键点集 $C_S$，或者超出最密上限点集 $N_s$ 该模型所得出的 Global signature 都是相同的，(2) 指出关键点集的上限在于我们的转换函数 $h$ 转换的维数 $K$</p>\n<p>对于定理二原论文中有直观的图解帮助大家构造 intuition<br><img src=\"https://pic2.zhimg.com/80/v2-c1fc6e865ab685dcaefd18e8c063bef1_1440w.jpg\" alt></p>\n<p>最后的结果在当时看来是非常不错的。<br><img src=\"https://s3.ax1x.com/2020/12/08/rpk2jI.png\" alt></p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>PointNet 开创了3D点云的新纪元，日后的PointNet++，PointCNN等网络都是在其基础上发展起来的，作为点云的奠基其用十分简单的方式解决了3D点云数据的顺序 (symmetry function) 和空间不变性 (high demension). 但它没有很好的解决 Local 数据的关系，这一问题会在PointNet++中得到解决。</p>\n<p>最后说点自己的话，感觉现在读论文并不是很静得下心来，读的也很笼统不深入，被太多乱七八糟的事情困扰心烦意乱。但事情总得做下去，状态是在做事的过程中一点点找回来的，干等等不来。注重积累一点点来，相信自己在不久的将来能够做出一点自己的东西。</p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><p>[1] PointNet论文链接：<a href=\"https://arxiv.org/abs/1612.00593\">https://arxiv.org/abs/1612.00593</a><br>[2] O. Vinyals, S. Bengio, and M. Kudlur. Order mat\u0002ters: Sequence to sequence for sets. arXiv preprint arXiv:1511.06391, 2015.</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"PointCloud\"><a href=\"#PointCloud\" class=\"headerlink\" title=\"PointCloud\"></a>PointCloud</h3><p>何谓点云，点云数据和普通的照片又有什么不同？实际上点云并非什么高深的东西，下图就是一张点云的可视化数据。<br><img src=\"https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1607249767189&amp;di=e4964b8b875326b97e5ab06da6196601&amp;imgtype=0&amp;src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fq_70%2Cc_zoom%2Cw_640%2Fimages%2F20180118%2F537a4b5eab09459881f9bc6ca18834f9.jpeg\" alt=\"点云街道\"></p>\n<ul>\n<li><strong>位置信息</strong><br>不同于原先2D的图像，每个像素点仅有RGB信息，点云自带了欧式空间中的位置信息，即坐标(x,y,z) 之后会附带一些RGB灰度值之类的普通图像像素就具有的东西。</li>\n</ul>\n<p>了解了点云之后我们来解析一下PointNet这篇论文[1]</p>\n<hr>\n<h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p>不同于当时许多处理3D点云任务时，直接将3D点云转化成体素矩阵(Voxel grid)的方式，但由于3D空间不同于2D大量的空间里都是空的(zero grid)，将他们全部体素化会造成不必要的浪费。PointNet可以<strong>直接输入点云</strong>信息，来解决这一问题，同时避免一些转换中造成的其他问题。</p>\n<h3 id=\"点云数据的特点\"><a href=\"#点云数据的特点\" class=\"headerlink\" title=\"点云数据的特点\"></a>点云数据的特点</h3><p><strong>1. 无序性 （Unordered）</strong><br>我们都知道在欧式空间的度量中点和点之间是不存在像一维二维空间中的序关系的。(可能不严谨，数学不太好，暂时就这样理解)<br>对于点云数据信息，每个点<strong>喂入的顺序不应当影响到结果</strong></p>\n<p><strong>2. 局部相关性 (Interaction among points)</strong><br>我们知道在<strong>空间中的点和其周边点之间的位置关系信息是有意义的</strong>，它代表了物体的形状特征。这正是我们在2D CNN工作中卷积层所提取的东西，因而我们要保留这个特征信息。</p>\n<p><strong>3. 不变性 （Invariance under transformation）</strong><br>对于点云数据应该满足一些<strong>空间变换的不变性</strong>，例如平移和旋转，这些都不会影响最终的结果</p>\n<p>PointNet的工作就是尝试解决这三个问题。</p>\n<hr>\n<h3 id=\"网络结构\"><a href=\"#网络结构\" class=\"headerlink\" title=\"网络结构\"></a>网络结构</h3><p><img src=\"https://pic1.zhimg.com/80/v2-8dc76710bd09c25d5c8196d6aff56fec_1440w.jpg\" alt></p>\n<p>我们看一下 PointNet 的网络架构，首先喂入原始的 PointNet，是一个 $N\\times 3$ 的矩阵(n个点,xyz)先通过一个 $T-Net$ 层进行对齐，然后用感知机 mlp 进行特征提取，装换到 $N\\times 1024$ 1024维空间上再进行 Max Pooling 提取出 Global feature，然后就干自己该干的事去了，对分类任务，将全局特征通过mlp来预测最后的分类分数；对分割任务，将全局特征和之前学习到的各点云的局部特征进行串联，再通过mlp得到每个数据点的分类结果。<br>下文会展开更详细的讲解</p>\n<h3 id=\"解决无序性-symmetry-function\"><a href=\"#解决无序性-symmetry-function\" class=\"headerlink\" title=\"解决无序性 (symmetry function)\"></a>解决无序性 (symmetry function)</h3><p>对于无序性 PointCloud 数据的处理当时一般有三种方法，</p>\n<ul>\n<li>1）对数据进行排序成 canonical order. </li>\n</ul>\n<p>对于这种方法，其实不存在一种高维空间的排序。由于CNN中数据抽象纬度很高，要保证高维中的点向一维的稳定映射无关数据顺序是十分困难的，所以其效果有限。</p>\n<ul>\n<li>2) 用大量打乱数据序列训练一个 RNN，寄希望于这种方式能消除顺序依赖</li>\n</ul>\n<p>这种方法看上去可行，然而其仍然无法做到完全顺序无关，在[2]中有详细证明。实验表示，这种方法对于小型数据具有一定鲁棒性，但对于大量point的场景仍然表现疲软。</p>\n<p><strong>3) 通过一个简单的对称函数来处理每个点，获得每个点的 Global signature</strong></p>\n<p>这是本文所使用的方法，很简单却很有效，我们知道一个symmetry function 的输出是无关顺序的, 例如我们熟悉的加法和乘法，这里选用了CNN中常用的 max 函数作为 symmetry function，通过 max pooling 消除数据顺序的影响。</p>\n<p><img src=\"https://s3.ax1x.com/2020/12/08/rpks4e.png\" alt></p>\n<p>$f$ 这个函数输出一个数据不依赖的值作为该组数据的 <em>Global signature</em> 每一个输入值 $x_{1\\to n}$ 是PointCloud中的点，带有 (x,y,z)位置信息以及一些rgb信息，组成共 $NxN$ 的矩阵，$h$ 是一个变换方程，将 $1\\times N$的向量转换为 $1\\times K$，然后 $g$ 就是我们的 symmetry function 将 $N\\times K$ 的矩阵映射到一个值 $R$ 就能够代表这组数据，因为 symmetry function 的顺序无关性，我们能够保证这个值对于相同数据的不同排列是相同的。</p>\n<hr>\n<h3 id=\"局部和全局数据聚合-Local-and-Global-Information-Aggregation\"><a href=\"#局部和全局数据聚合-Local-and-Global-Information-Aggregation\" class=\"headerlink\" title=\"局部和全局数据聚合 (Local and Global Information Aggregation)\"></a>局部和全局数据聚合 (Local and Global Information Aggregation)</h3><p>这边先讲一下我自己的想法，我很怀疑它到底有没有做局部信息的处理，既解决第二个问题，据PointNet这篇文章自己写的这一章，他说他做了。然后后面PointNet++ 说他没做。我这段看的也比较迷惑，但我个人倾向于原作者尝试去做但做的比较弱。</p>\n<h3 id=\"理论证明可行性-Theory-Analysis\"><a href=\"#理论证明可行性-Theory-Analysis\" class=\"headerlink\" title=\"理论证明可行性 (Theory Analysis)\"></a>理论证明可行性 (Theory Analysis)</h3><p><img src=\"https://pic3.zhimg.com/80/v2-1bee125c29ac11faba0e0a095207a396_1440w.jpg\" alt=\"拟合可行性\"></p>\n<p>这个定理说我们通过之前讲的 $h$ 和 Max pooling 操作能够拟合任意的连续集合函数 $f$<br>最坏的拟合就是将其转换成空间中的体素，但通常来说我们的神经网络在调校的过程中都会得到更好的 $h$ 来完成这一过程。</p>\n<p>TODO: 详细证明过程在附录中我还没看</p>\n<p><img src=\"https://pic1.zhimg.com/80/v2-43d9f406855cf5e4681cb3de08382b80_1440w.jpg\" alt=\"扰动下的鲁棒性\"></p>\n<p>定理二告诉了我们该模型在扰动之下具有鲁棒性，只要不影响关键点集 $C_S$，或者超出最密上限点集 $N_s$ 该模型所得出的 Global signature 都是相同的，(2) 指出关键点集的上限在于我们的转换函数 $h$ 转换的维数 $K$</p>\n<p>对于定理二原论文中有直观的图解帮助大家构造 intuition<br><img src=\"https://pic2.zhimg.com/80/v2-c1fc6e865ab685dcaefd18e8c063bef1_1440w.jpg\" alt></p>\n<p>最后的结果在当时看来是非常不错的。<br><img src=\"https://s3.ax1x.com/2020/12/08/rpk2jI.png\" alt></p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>PointNet 开创了3D点云的新纪元，日后的PointNet++，PointCNN等网络都是在其基础上发展起来的，作为点云的奠基其用十分简单的方式解决了3D点云数据的顺序 (symmetry function) 和空间不变性 (high demension). 但它没有很好的解决 Local 数据的关系，这一问题会在PointNet++中得到解决。</p>\n<p>最后说点自己的话，感觉现在读论文并不是很静得下心来，读的也很笼统不深入，被太多乱七八糟的事情困扰心烦意乱。但事情总得做下去，状态是在做事的过程中一点点找回来的，干等等不来。注重积累一点点来，相信自己在不久的将来能够做出一点自己的东西。</p>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><p>[1] PointNet论文链接：<a href=\"https://arxiv.org/abs/1612.00593\">https://arxiv.org/abs/1612.00593</a><br>[2] O. Vinyals, S. Bengio, and M. Kudlur. Order mat\u0002ters: Sequence to sequence for sets. arXiv preprint arXiv:1511.06391, 2015.</p>\n"},{"title":"PointNet++论文阅读","date":"2020-12-08T06:36:58.000Z","index_img":"/img/Pic/cnn_img.jpeg","banner_img":"/img/Pic/PointCloud.jpg","math":true,"_content":"# PointNet++\n\n## 综述\n\n回顾一下 PointNet ，我们说PointNet解决了 PointCloud 输入的顺序无关问题，但其有一个缺点就是无法获取局部特征，即没有很好的处理 local information，使其在复杂场景下表现乏力。PointNet++正是针对PointNet这一弱点进行改进。\n\n- 主要改进方式\n\n1. 受到 CNN 神经元感受野不断扩大的启发，利用空间距离，使 PointNet对点集局部区域进行特征迭代提取。\n\n2. 使用最远点提取方式，能够实现较为均匀的点采样\n\n## 关键问题\n\n一、如何做点集划分 (怎么划分空间)\n\n二、如何利用特征提取器提取局部特征信息 (怎么提取特征)\n\n这两个问题是相关的，如果和 CNN 做一个类比，在CNN中卷积核是基本的特征提取器，每个卷积核对应一个 n*n 的像素区域，在PointCloud中同样要找到结构相同的子区域和对应的特征提取器。\n\n那么在 PointNet++ 中作者使用欧式空间中的邻接球作为子区域做点集的 Partition 使用 PointNet 作为特征提取器。\n\n## 网络结构\n![](https://pic1.zhimg.com/80/v2-f3f9a70d0052be1949a18c6e556572b8_1440w.jpg)\n\n主要包括三部分\n### Sample layer\n主要对输入点进行采样，使用最远点采样法，选择$N$个点，能够更均匀的覆盖整个点集。\n![](https://img-blog.csdnimg.cn/20200923132734170.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FUVkxD,size_16,color_FFFFFF,t_70#pic_center)\n\n### Grouping layer\n确定点的局部划分，即确定邻接球的半径和内部的点的数量。\n一种是 ball query 看半径，还有就是用 KNN 看内部点的数量\n\n### PointNet layer\n通过 PointNet 进行特征提取，假设每个 Group 中有 $n$ 个点，那么通过 PointNet 将 $n\\times 3$ 的矩阵转换成 $n\\times K$ 的矩阵。迭代进行操作，感受野逐渐扩大，维数逐渐提升。\n\n## 不均匀点云数据\n\n我们知道点云数据不像图片中的信息是紧密连接的，空间中的点有稀疏和稠密之分。这时候如果平均采样那么会在空间中点稀疏的地方造成浪费，在点密集的地方却不足以提取到足够的信息。为此 PointNet++ 作者提出了两种方式来保证更加优化的特征提取。\n\n![](https://pic1.zhimg.com/80/v2-5389688194b56daf0311e926360f8e6c_1440w.jpg)\n\n### 多尺度组合 (multi-scale grouping, MSG)\n\n对于同一个点多次采用不同的Grouping，过PointNet之后将特征 concat，增加了很多计算量，耗时。\n\n### 多分辨率组合（multi-resolution grouping, MRG）\n\n相当于多层之间采用了不同的分辨率，先用小的grouping通过两层正常提取出的特征，和一次大的grouping提取出的特征进行一个concat，组合了两种分辨率的信息。\n\n---\n\n## 实验效果\n\n![](https://s3.ax1x.com/2020/12/08/rpkt39.png)\n\n从实验效果上我们可以看出其准确率明显好于单一的PointNet，并且在使用了 MSG 和 MRG 后对于大量点集的鲁棒性明显提升了。\n\n","source":"_posts/Research/PointNetpp.md","raw":"---\ntitle: PointNet++论文阅读\ndate: 2020-12-08 14:36:58\nindex_img: /img/Pic/cnn_img.jpeg\nbanner_img: /img/Pic/PointCloud.jpg\ncategory: [Research]\ntags: PointNet\nmath: true\n---\n# PointNet++\n\n## 综述\n\n回顾一下 PointNet ，我们说PointNet解决了 PointCloud 输入的顺序无关问题，但其有一个缺点就是无法获取局部特征，即没有很好的处理 local information，使其在复杂场景下表现乏力。PointNet++正是针对PointNet这一弱点进行改进。\n\n- 主要改进方式\n\n1. 受到 CNN 神经元感受野不断扩大的启发，利用空间距离，使 PointNet对点集局部区域进行特征迭代提取。\n\n2. 使用最远点提取方式，能够实现较为均匀的点采样\n\n## 关键问题\n\n一、如何做点集划分 (怎么划分空间)\n\n二、如何利用特征提取器提取局部特征信息 (怎么提取特征)\n\n这两个问题是相关的，如果和 CNN 做一个类比，在CNN中卷积核是基本的特征提取器，每个卷积核对应一个 n*n 的像素区域，在PointCloud中同样要找到结构相同的子区域和对应的特征提取器。\n\n那么在 PointNet++ 中作者使用欧式空间中的邻接球作为子区域做点集的 Partition 使用 PointNet 作为特征提取器。\n\n## 网络结构\n![](https://pic1.zhimg.com/80/v2-f3f9a70d0052be1949a18c6e556572b8_1440w.jpg)\n\n主要包括三部分\n### Sample layer\n主要对输入点进行采样，使用最远点采样法，选择$N$个点，能够更均匀的覆盖整个点集。\n![](https://img-blog.csdnimg.cn/20200923132734170.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FUVkxD,size_16,color_FFFFFF,t_70#pic_center)\n\n### Grouping layer\n确定点的局部划分，即确定邻接球的半径和内部的点的数量。\n一种是 ball query 看半径，还有就是用 KNN 看内部点的数量\n\n### PointNet layer\n通过 PointNet 进行特征提取，假设每个 Group 中有 $n$ 个点，那么通过 PointNet 将 $n\\times 3$ 的矩阵转换成 $n\\times K$ 的矩阵。迭代进行操作，感受野逐渐扩大，维数逐渐提升。\n\n## 不均匀点云数据\n\n我们知道点云数据不像图片中的信息是紧密连接的，空间中的点有稀疏和稠密之分。这时候如果平均采样那么会在空间中点稀疏的地方造成浪费，在点密集的地方却不足以提取到足够的信息。为此 PointNet++ 作者提出了两种方式来保证更加优化的特征提取。\n\n![](https://pic1.zhimg.com/80/v2-5389688194b56daf0311e926360f8e6c_1440w.jpg)\n\n### 多尺度组合 (multi-scale grouping, MSG)\n\n对于同一个点多次采用不同的Grouping，过PointNet之后将特征 concat，增加了很多计算量，耗时。\n\n### 多分辨率组合（multi-resolution grouping, MRG）\n\n相当于多层之间采用了不同的分辨率，先用小的grouping通过两层正常提取出的特征，和一次大的grouping提取出的特征进行一个concat，组合了两种分辨率的信息。\n\n---\n\n## 实验效果\n\n![](https://s3.ax1x.com/2020/12/08/rpkt39.png)\n\n从实验效果上我们可以看出其准确率明显好于单一的PointNet，并且在使用了 MSG 和 MRG 后对于大量点集的鲁棒性明显提升了。\n\n","slug":"Research/PointNetpp","published":1,"updated":"2020-12-09T01:21:49.367Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty43001ds8pde3ykgu2z","content":"<h1 id=\"PointNet\"><a href=\"#PointNet\" class=\"headerlink\" title=\"PointNet++\"></a>PointNet++</h1><h2 id=\"综述\"><a href=\"#综述\" class=\"headerlink\" title=\"综述\"></a>综述</h2><p>回顾一下 PointNet ，我们说PointNet解决了 PointCloud 输入的顺序无关问题，但其有一个缺点就是无法获取局部特征，即没有很好的处理 local information，使其在复杂场景下表现乏力。PointNet++正是针对PointNet这一弱点进行改进。</p>\n<ul>\n<li>主要改进方式</li>\n</ul>\n<ol>\n<li><p>受到 CNN 神经元感受野不断扩大的启发，利用空间距离，使 PointNet对点集局部区域进行特征迭代提取。</p>\n</li>\n<li><p>使用最远点提取方式，能够实现较为均匀的点采样</p>\n</li>\n</ol>\n<h2 id=\"关键问题\"><a href=\"#关键问题\" class=\"headerlink\" title=\"关键问题\"></a>关键问题</h2><p>一、如何做点集划分 (怎么划分空间)</p>\n<p>二、如何利用特征提取器提取局部特征信息 (怎么提取特征)</p>\n<p>这两个问题是相关的，如果和 CNN 做一个类比，在CNN中卷积核是基本的特征提取器，每个卷积核对应一个 n*n 的像素区域，在PointCloud中同样要找到结构相同的子区域和对应的特征提取器。</p>\n<p>那么在 PointNet++ 中作者使用欧式空间中的邻接球作为子区域做点集的 Partition 使用 PointNet 作为特征提取器。</p>\n<h2 id=\"网络结构\"><a href=\"#网络结构\" class=\"headerlink\" title=\"网络结构\"></a>网络结构</h2><p><img src=\"https://pic1.zhimg.com/80/v2-f3f9a70d0052be1949a18c6e556572b8_1440w.jpg\" alt></p>\n<p>主要包括三部分</p>\n<h3 id=\"Sample-layer\"><a href=\"#Sample-layer\" class=\"headerlink\" title=\"Sample layer\"></a>Sample layer</h3><p>主要对输入点进行采样，使用最远点采样法，选择$N$个点，能够更均匀的覆盖整个点集。<br><img src=\"https://img-blog.csdnimg.cn/20200923132734170.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FUVkxD,size_16,color_FFFFFF,t_70#pic_center\" alt></p>\n<h3 id=\"Grouping-layer\"><a href=\"#Grouping-layer\" class=\"headerlink\" title=\"Grouping layer\"></a>Grouping layer</h3><p>确定点的局部划分，即确定邻接球的半径和内部的点的数量。<br>一种是 ball query 看半径，还有就是用 KNN 看内部点的数量</p>\n<h3 id=\"PointNet-layer\"><a href=\"#PointNet-layer\" class=\"headerlink\" title=\"PointNet layer\"></a>PointNet layer</h3><p>通过 PointNet 进行特征提取，假设每个 Group 中有 $n$ 个点，那么通过 PointNet 将 $n\\times 3$ 的矩阵转换成 $n\\times K$ 的矩阵。迭代进行操作，感受野逐渐扩大，维数逐渐提升。</p>\n<h2 id=\"不均匀点云数据\"><a href=\"#不均匀点云数据\" class=\"headerlink\" title=\"不均匀点云数据\"></a>不均匀点云数据</h2><p>我们知道点云数据不像图片中的信息是紧密连接的，空间中的点有稀疏和稠密之分。这时候如果平均采样那么会在空间中点稀疏的地方造成浪费，在点密集的地方却不足以提取到足够的信息。为此 PointNet++ 作者提出了两种方式来保证更加优化的特征提取。</p>\n<p><img src=\"https://pic1.zhimg.com/80/v2-5389688194b56daf0311e926360f8e6c_1440w.jpg\" alt></p>\n<h3 id=\"多尺度组合-multi-scale-grouping-MSG\"><a href=\"#多尺度组合-multi-scale-grouping-MSG\" class=\"headerlink\" title=\"多尺度组合 (multi-scale grouping, MSG)\"></a>多尺度组合 (multi-scale grouping, MSG)</h3><p>对于同一个点多次采用不同的Grouping，过PointNet之后将特征 concat，增加了很多计算量，耗时。</p>\n<h3 id=\"多分辨率组合（multi-resolution-grouping-MRG）\"><a href=\"#多分辨率组合（multi-resolution-grouping-MRG）\" class=\"headerlink\" title=\"多分辨率组合（multi-resolution grouping, MRG）\"></a>多分辨率组合（multi-resolution grouping, MRG）</h3><p>相当于多层之间采用了不同的分辨率，先用小的grouping通过两层正常提取出的特征，和一次大的grouping提取出的特征进行一个concat，组合了两种分辨率的信息。</p>\n<hr>\n<h2 id=\"实验效果\"><a href=\"#实验效果\" class=\"headerlink\" title=\"实验效果\"></a>实验效果</h2><p><img src=\"https://s3.ax1x.com/2020/12/08/rpkt39.png\" alt></p>\n<p>从实验效果上我们可以看出其准确率明显好于单一的PointNet，并且在使用了 MSG 和 MRG 后对于大量点集的鲁棒性明显提升了。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"PointNet\"><a href=\"#PointNet\" class=\"headerlink\" title=\"PointNet++\"></a>PointNet++</h1><h2 id=\"综述\"><a href=\"#综述\" class=\"headerlink\" title=\"综述\"></a>综述</h2><p>回顾一下 PointNet ，我们说PointNet解决了 PointCloud 输入的顺序无关问题，但其有一个缺点就是无法获取局部特征，即没有很好的处理 local information，使其在复杂场景下表现乏力。PointNet++正是针对PointNet这一弱点进行改进。</p>\n<ul>\n<li>主要改进方式</li>\n</ul>\n<ol>\n<li><p>受到 CNN 神经元感受野不断扩大的启发，利用空间距离，使 PointNet对点集局部区域进行特征迭代提取。</p>\n</li>\n<li><p>使用最远点提取方式，能够实现较为均匀的点采样</p>\n</li>\n</ol>\n<h2 id=\"关键问题\"><a href=\"#关键问题\" class=\"headerlink\" title=\"关键问题\"></a>关键问题</h2><p>一、如何做点集划分 (怎么划分空间)</p>\n<p>二、如何利用特征提取器提取局部特征信息 (怎么提取特征)</p>\n<p>这两个问题是相关的，如果和 CNN 做一个类比，在CNN中卷积核是基本的特征提取器，每个卷积核对应一个 n*n 的像素区域，在PointCloud中同样要找到结构相同的子区域和对应的特征提取器。</p>\n<p>那么在 PointNet++ 中作者使用欧式空间中的邻接球作为子区域做点集的 Partition 使用 PointNet 作为特征提取器。</p>\n<h2 id=\"网络结构\"><a href=\"#网络结构\" class=\"headerlink\" title=\"网络结构\"></a>网络结构</h2><p><img src=\"https://pic1.zhimg.com/80/v2-f3f9a70d0052be1949a18c6e556572b8_1440w.jpg\" alt></p>\n<p>主要包括三部分</p>\n<h3 id=\"Sample-layer\"><a href=\"#Sample-layer\" class=\"headerlink\" title=\"Sample layer\"></a>Sample layer</h3><p>主要对输入点进行采样，使用最远点采样法，选择$N$个点，能够更均匀的覆盖整个点集。<br><img src=\"https://img-blog.csdnimg.cn/20200923132734170.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1FUVkxD,size_16,color_FFFFFF,t_70#pic_center\" alt></p>\n<h3 id=\"Grouping-layer\"><a href=\"#Grouping-layer\" class=\"headerlink\" title=\"Grouping layer\"></a>Grouping layer</h3><p>确定点的局部划分，即确定邻接球的半径和内部的点的数量。<br>一种是 ball query 看半径，还有就是用 KNN 看内部点的数量</p>\n<h3 id=\"PointNet-layer\"><a href=\"#PointNet-layer\" class=\"headerlink\" title=\"PointNet layer\"></a>PointNet layer</h3><p>通过 PointNet 进行特征提取，假设每个 Group 中有 $n$ 个点，那么通过 PointNet 将 $n\\times 3$ 的矩阵转换成 $n\\times K$ 的矩阵。迭代进行操作，感受野逐渐扩大，维数逐渐提升。</p>\n<h2 id=\"不均匀点云数据\"><a href=\"#不均匀点云数据\" class=\"headerlink\" title=\"不均匀点云数据\"></a>不均匀点云数据</h2><p>我们知道点云数据不像图片中的信息是紧密连接的，空间中的点有稀疏和稠密之分。这时候如果平均采样那么会在空间中点稀疏的地方造成浪费，在点密集的地方却不足以提取到足够的信息。为此 PointNet++ 作者提出了两种方式来保证更加优化的特征提取。</p>\n<p><img src=\"https://pic1.zhimg.com/80/v2-5389688194b56daf0311e926360f8e6c_1440w.jpg\" alt></p>\n<h3 id=\"多尺度组合-multi-scale-grouping-MSG\"><a href=\"#多尺度组合-multi-scale-grouping-MSG\" class=\"headerlink\" title=\"多尺度组合 (multi-scale grouping, MSG)\"></a>多尺度组合 (multi-scale grouping, MSG)</h3><p>对于同一个点多次采用不同的Grouping，过PointNet之后将特征 concat，增加了很多计算量，耗时。</p>\n<h3 id=\"多分辨率组合（multi-resolution-grouping-MRG）\"><a href=\"#多分辨率组合（multi-resolution-grouping-MRG）\" class=\"headerlink\" title=\"多分辨率组合（multi-resolution grouping, MRG）\"></a>多分辨率组合（multi-resolution grouping, MRG）</h3><p>相当于多层之间采用了不同的分辨率，先用小的grouping通过两层正常提取出的特征，和一次大的grouping提取出的特征进行一个concat，组合了两种分辨率的信息。</p>\n<hr>\n<h2 id=\"实验效果\"><a href=\"#实验效果\" class=\"headerlink\" title=\"实验效果\"></a>实验效果</h2><p><img src=\"https://s3.ax1x.com/2020/12/08/rpkt39.png\" alt></p>\n<p>从实验效果上我们可以看出其准确率明显好于单一的PointNet，并且在使用了 MSG 和 MRG 后对于大量点集的鲁棒性明显提升了。</p>\n"},{"title":"CaDDN论文阅读","date":"2021-03-09T12:20:50.000Z","index_img":"/img/AI.png","math":true,"_content":"\n# **Categorical Depth Distribution Network for Monocular 3D Object Detection**\n\n**关键词： 单目3d检测、绝对深度分配网络**\n\n**论文链接：**https://arxiv.org/pdf/2103.01100.pdf\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1godx97xntnj30bl08p0wn.jpg)\n\n## 前言\n\n​\t单目3D检测的难点一直在于对深度的预测，实例从3D空间被映射到2D平面的图像上丢失了深度信息，对深度的处理一直是单目3D目标检测研究的重点方向，目前主流的方法主要分为三类。\n\n**1、直接检测  (Direct Methods)**\n\n​\t直接检测方法没有显式的对深度进行学习，比较有代表性的是关键点检测方法，通过关键点结合几何特征来帮助3D-Bbox的检测，好处是简单直接且高效，但这类方法由于没有显式的学习深度信息，往往导致深度预测的结果不尽理想。\n\n**2、基于深度  (Depth-Based Methods)**\n\n​\t基于深度的方法通常先会通过一个单目深度预测分支来得到一张深度图作为网络的输入从而辅助对深度的检测，由于有了深度信息其可被转换成点云来处理（可以用上3d检测的方法)。但由于其深度和目标检测分离训练的结构，导致其可能会丢失一些隐含的信息。\n\n**3、基于网格  (Grid-Based Methods)**\n\n​\t基于网格的方法避免了对深度的直接预测，而是通过预测一个 BEV grid 的表达来作为3D检测网络的输入，OFT[1]提出了一种体素网格，通过把体素投影到图像平面上进而采样图像特征将其转换成BEV的形式。但这也会导致大量体素和特征的重叠从而降低检测的准确性。\n\n\n\n​\t**CaDDN** 网络对上面三种情况的优点进行结合，整体网络结构是同时训练了深度预测和3D检测（jointly）以期待其能够解决方法2中的问题，同时利用也将图像平面转换成了BEV的形式来提高检测的准确性。\n\n![网络结构](https://tva1.sinaimg.cn/large/008eGmZEgy1godxz73f1jj30nm0dntcy.jpg)\n\n\n\n## 网络结构\n\n### Frustum Feature Network\n\n- **Depth Distribution Network**\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1godzoe00t7j30b908dabe.jpg)\n\n对于特征提取网络，其输出形似一个截角锥形，因而作者称其为Frustum feature Network，其输入是原始图像 $I \\in R^{W_1\\times H_1\\times 3}$ 输出 $G \\in R^{W_F\\times H_F\\times D \\times C}$ 其中 W和H是特征的宽高，D 是深度桶，用以深度预测，C 是特征的维度。图像特征被用以在每个像素上预测绝对的深度分布 $D \\in R^{W_F\\times H_F\\times D}$ 网络对每个像素预测其落入某一深度桶（深度离散化）的概率，总共D个。\n\n（这一网络其是从 DeepLabV3[2] 上魔改过来的。）\n\n- Image Channel Reduce\n\n同时在分配深度桶的同时，网络另一分支用1x1卷积 + BN + ReLU 把特征的维数从256降到了64。\n\n\n\n​\t经过这两个分支后，将预测出来的深度桶和特征像素做外积得到了带有深度信息的特征图（$G(u,v) = D(u,v) \\otimes F(u,v)$）且由于特征桶的结构，具有较高的容错性。称 G 为 frustum features\n\n\n\n### Frustum to Voxel Trans\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1godzokeng2j30b907ujsr.jpg)\n\n\n\n​\tG 之后将被转换成体素的形式，这里的问题是在第分辨率的frustum features进行高分辨率的体素采样会导致过采样，导致出现大量相同的体素特征，浪费算力不说还降低预测准确性。所以这边作者直接把降采样前的特征层拉了过来，来保证不会出现上述问题。\n\n\n\n ### Voxel Collapse to BEV -> Detection\n\n​\t由于BEV在保证同等检测效果的情况下能够节省计算资源，作者将体素的 Z 轴和 channels 直接连接起来，继续用1x1卷积 + BN + ReLU 将体素块压缩成 BEV的形式。然后接着在 BEV 特征块上连接检测头进行 3D目标检测。\n\n\n\n## 深度离散化\n\n​\t本文的主要亮点就是其对于深度的处理，其对每个像素位置分配了离散化的深度桶，预测其属于某一深度的概率。这里的深度离散化作者使用的是 LID (Linear-increasing discretization)[3] 因为其对不同深度之间提供了最为平衡的预测概率。对于检测任务的深度我们最需要的是检测目标的深度信息，而更少去在意背景点的深度。\n\n​\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t$$d_c = d_min + \\frac{d_{max}-d_{min}}{D(D+1)}\\cdot{d_i}{(d_1+1)}$$\n\n​\t*（其中 $d_c$ 是连续深度值，[$d_{min},d_{max}$]是离散化的上下界，D是深度桶的数量，$d_i$ 是下标）*\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1goe03wlr9sj30dn0bd0tp.jpg)\n\n\n\n## 实验效果\n\n![KITTI实验效果](https://tva1.sinaimg.cn/large/008eGmZEgy1goe0ckxhf6j30r10fgn17.jpg)\n\n​\t可以看到其在车辆和新人检测上都打破了目前最好的检测方法，对骑行者的检测不如 MonoPSR 但也大大超过了其余检测模型。\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1goe0gh8vyhj30dw07jdgw.jpg)\n\n这张表可以看出其将深度预测和特征融合所得到的 frustum features 确实有助于提升检测效果。\n\n\n\n## 结语\n\n​\t个人觉得这篇paper的主要成功点在于其对于单目深度预测的创新解决方法，不同于传统的深度预测模型，提出了离散化深度将每个像素的深度概率离散化分配在不同的深度桶中，避免了网络过度依赖于深度的准确检测。但同时其也没有从根本上解决深度预测的问题，同时其中间对于特征图进行体素化投影再转为 BEV 的过程较为复杂，虽然其把降采样前的特征层拿来转成体素形式但是仍然还是无法避免会有损失。\n\n​\t个人觉得可以借鉴该模型的深度预测方法，应用在现有的模型上或者对该模型的网络结构进行简化，可能会带来更好的效果。\n\n\n\n---\n\n### Reference\n\n[1]  Thomas Roddick, Alex Kendall, and Roberto Cipolla. Ortho\u0002 graphic feature transform for monocular 3D object detection.*BMVC*, 2018\n\n[2] Liang-Chieh Chen, George Papandreou, Florian Schroff, andHartwig Adam. Rethinking atrous convolution for semantic image segmentation. *arXiv preprint*, 2017\n\n[3] Yunlei Tang, Sebastian Dorn, and Chiragkumar Savani. Cen\u0002ter3d: Center-based monocular 3d object detection with joint depth understanding. *arXiv preprint*, 2020","source":"_posts/Research/CaDDN-Paper.md","raw":"---\ntitle: CaDDN论文阅读\ndate: 2021-03-09 20:20:50\nindex_img: /img/AI.png\ncategory: [Research, Object Detection]\ntags: [Monocular OD]\nmath: true\n---\n\n# **Categorical Depth Distribution Network for Monocular 3D Object Detection**\n\n**关键词： 单目3d检测、绝对深度分配网络**\n\n**论文链接：**https://arxiv.org/pdf/2103.01100.pdf\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1godx97xntnj30bl08p0wn.jpg)\n\n## 前言\n\n​\t单目3D检测的难点一直在于对深度的预测，实例从3D空间被映射到2D平面的图像上丢失了深度信息，对深度的处理一直是单目3D目标检测研究的重点方向，目前主流的方法主要分为三类。\n\n**1、直接检测  (Direct Methods)**\n\n​\t直接检测方法没有显式的对深度进行学习，比较有代表性的是关键点检测方法，通过关键点结合几何特征来帮助3D-Bbox的检测，好处是简单直接且高效，但这类方法由于没有显式的学习深度信息，往往导致深度预测的结果不尽理想。\n\n**2、基于深度  (Depth-Based Methods)**\n\n​\t基于深度的方法通常先会通过一个单目深度预测分支来得到一张深度图作为网络的输入从而辅助对深度的检测，由于有了深度信息其可被转换成点云来处理（可以用上3d检测的方法)。但由于其深度和目标检测分离训练的结构，导致其可能会丢失一些隐含的信息。\n\n**3、基于网格  (Grid-Based Methods)**\n\n​\t基于网格的方法避免了对深度的直接预测，而是通过预测一个 BEV grid 的表达来作为3D检测网络的输入，OFT[1]提出了一种体素网格，通过把体素投影到图像平面上进而采样图像特征将其转换成BEV的形式。但这也会导致大量体素和特征的重叠从而降低检测的准确性。\n\n\n\n​\t**CaDDN** 网络对上面三种情况的优点进行结合，整体网络结构是同时训练了深度预测和3D检测（jointly）以期待其能够解决方法2中的问题，同时利用也将图像平面转换成了BEV的形式来提高检测的准确性。\n\n![网络结构](https://tva1.sinaimg.cn/large/008eGmZEgy1godxz73f1jj30nm0dntcy.jpg)\n\n\n\n## 网络结构\n\n### Frustum Feature Network\n\n- **Depth Distribution Network**\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1godzoe00t7j30b908dabe.jpg)\n\n对于特征提取网络，其输出形似一个截角锥形，因而作者称其为Frustum feature Network，其输入是原始图像 $I \\in R^{W_1\\times H_1\\times 3}$ 输出 $G \\in R^{W_F\\times H_F\\times D \\times C}$ 其中 W和H是特征的宽高，D 是深度桶，用以深度预测，C 是特征的维度。图像特征被用以在每个像素上预测绝对的深度分布 $D \\in R^{W_F\\times H_F\\times D}$ 网络对每个像素预测其落入某一深度桶（深度离散化）的概率，总共D个。\n\n（这一网络其是从 DeepLabV3[2] 上魔改过来的。）\n\n- Image Channel Reduce\n\n同时在分配深度桶的同时，网络另一分支用1x1卷积 + BN + ReLU 把特征的维数从256降到了64。\n\n\n\n​\t经过这两个分支后，将预测出来的深度桶和特征像素做外积得到了带有深度信息的特征图（$G(u,v) = D(u,v) \\otimes F(u,v)$）且由于特征桶的结构，具有较高的容错性。称 G 为 frustum features\n\n\n\n### Frustum to Voxel Trans\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1godzokeng2j30b907ujsr.jpg)\n\n\n\n​\tG 之后将被转换成体素的形式，这里的问题是在第分辨率的frustum features进行高分辨率的体素采样会导致过采样，导致出现大量相同的体素特征，浪费算力不说还降低预测准确性。所以这边作者直接把降采样前的特征层拉了过来，来保证不会出现上述问题。\n\n\n\n ### Voxel Collapse to BEV -> Detection\n\n​\t由于BEV在保证同等检测效果的情况下能够节省计算资源，作者将体素的 Z 轴和 channels 直接连接起来，继续用1x1卷积 + BN + ReLU 将体素块压缩成 BEV的形式。然后接着在 BEV 特征块上连接检测头进行 3D目标检测。\n\n\n\n## 深度离散化\n\n​\t本文的主要亮点就是其对于深度的处理，其对每个像素位置分配了离散化的深度桶，预测其属于某一深度的概率。这里的深度离散化作者使用的是 LID (Linear-increasing discretization)[3] 因为其对不同深度之间提供了最为平衡的预测概率。对于检测任务的深度我们最需要的是检测目标的深度信息，而更少去在意背景点的深度。\n\n​\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t$$d_c = d_min + \\frac{d_{max}-d_{min}}{D(D+1)}\\cdot{d_i}{(d_1+1)}$$\n\n​\t*（其中 $d_c$ 是连续深度值，[$d_{min},d_{max}$]是离散化的上下界，D是深度桶的数量，$d_i$ 是下标）*\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1goe03wlr9sj30dn0bd0tp.jpg)\n\n\n\n## 实验效果\n\n![KITTI实验效果](https://tva1.sinaimg.cn/large/008eGmZEgy1goe0ckxhf6j30r10fgn17.jpg)\n\n​\t可以看到其在车辆和新人检测上都打破了目前最好的检测方法，对骑行者的检测不如 MonoPSR 但也大大超过了其余检测模型。\n\n![](https://tva1.sinaimg.cn/large/008eGmZEgy1goe0gh8vyhj30dw07jdgw.jpg)\n\n这张表可以看出其将深度预测和特征融合所得到的 frustum features 确实有助于提升检测效果。\n\n\n\n## 结语\n\n​\t个人觉得这篇paper的主要成功点在于其对于单目深度预测的创新解决方法，不同于传统的深度预测模型，提出了离散化深度将每个像素的深度概率离散化分配在不同的深度桶中，避免了网络过度依赖于深度的准确检测。但同时其也没有从根本上解决深度预测的问题，同时其中间对于特征图进行体素化投影再转为 BEV 的过程较为复杂，虽然其把降采样前的特征层拿来转成体素形式但是仍然还是无法避免会有损失。\n\n​\t个人觉得可以借鉴该模型的深度预测方法，应用在现有的模型上或者对该模型的网络结构进行简化，可能会带来更好的效果。\n\n\n\n---\n\n### Reference\n\n[1]  Thomas Roddick, Alex Kendall, and Roberto Cipolla. Ortho\u0002 graphic feature transform for monocular 3D object detection.*BMVC*, 2018\n\n[2] Liang-Chieh Chen, George Papandreou, Florian Schroff, andHartwig Adam. Rethinking atrous convolution for semantic image segmentation. *arXiv preprint*, 2017\n\n[3] Yunlei Tang, Sebastian Dorn, and Chiragkumar Savani. Cen\u0002ter3d: Center-based monocular 3d object detection with joint depth understanding. *arXiv preprint*, 2020","slug":"Research/CaDDN-Paper","published":1,"updated":"2021-03-10T09:02:50.165Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty44001hs8pdekw402qc","content":"<h1 id=\"Categorical-Depth-Distribution-Network-for-Monocular-3D-Object-Detection\"><a href=\"#Categorical-Depth-Distribution-Network-for-Monocular-3D-Object-Detection\" class=\"headerlink\" title=\"Categorical Depth Distribution Network for Monocular 3D Object Detection\"></a><strong>Categorical Depth Distribution Network for Monocular 3D Object Detection</strong></h1><p><strong>关键词： 单目3d检测、绝对深度分配网络</strong></p>\n<p><strong>论文链接：</strong><a href=\"https://arxiv.org/pdf/2103.01100.pdf\">https://arxiv.org/pdf/2103.01100.pdf</a></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1godx97xntnj30bl08p0wn.jpg\" alt></p>\n<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>​    单目3D检测的难点一直在于对深度的预测，实例从3D空间被映射到2D平面的图像上丢失了深度信息，对深度的处理一直是单目3D目标检测研究的重点方向，目前主流的方法主要分为三类。</p>\n<p><strong>1、直接检测  (Direct Methods)</strong></p>\n<p>​    直接检测方法没有显式的对深度进行学习，比较有代表性的是关键点检测方法，通过关键点结合几何特征来帮助3D-Bbox的检测，好处是简单直接且高效，但这类方法由于没有显式的学习深度信息，往往导致深度预测的结果不尽理想。</p>\n<p><strong>2、基于深度  (Depth-Based Methods)</strong></p>\n<p>​    基于深度的方法通常先会通过一个单目深度预测分支来得到一张深度图作为网络的输入从而辅助对深度的检测，由于有了深度信息其可被转换成点云来处理（可以用上3d检测的方法)。但由于其深度和目标检测分离训练的结构，导致其可能会丢失一些隐含的信息。</p>\n<p><strong>3、基于网格  (Grid-Based Methods)</strong></p>\n<p>​    基于网格的方法避免了对深度的直接预测，而是通过预测一个 BEV grid 的表达来作为3D检测网络的输入，OFT[1]提出了一种体素网格，通过把体素投影到图像平面上进而采样图像特征将其转换成BEV的形式。但这也会导致大量体素和特征的重叠从而降低检测的准确性。</p>\n<p>​    <strong>CaDDN</strong> 网络对上面三种情况的优点进行结合，整体网络结构是同时训练了深度预测和3D检测（jointly）以期待其能够解决方法2中的问题，同时利用也将图像平面转换成了BEV的形式来提高检测的准确性。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1godxz73f1jj30nm0dntcy.jpg\" alt=\"网络结构\"></p>\n<h2 id=\"网络结构\"><a href=\"#网络结构\" class=\"headerlink\" title=\"网络结构\"></a>网络结构</h2><h3 id=\"Frustum-Feature-Network\"><a href=\"#Frustum-Feature-Network\" class=\"headerlink\" title=\"Frustum Feature Network\"></a>Frustum Feature Network</h3><ul>\n<li><strong>Depth Distribution Network</strong></li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1godzoe00t7j30b908dabe.jpg\" alt></p>\n<p>对于特征提取网络，其输出形似一个截角锥形，因而作者称其为Frustum feature Network，其输入是原始图像 $I \\in R^{W_1\\times H_1\\times 3}$ 输出 $G \\in R^{W_F\\times H_F\\times D \\times C}$ 其中 W和H是特征的宽高，D 是深度桶，用以深度预测，C 是特征的维度。图像特征被用以在每个像素上预测绝对的深度分布 $D \\in R^{W_F\\times H_F\\times D}$ 网络对每个像素预测其落入某一深度桶（深度离散化）的概率，总共D个。</p>\n<p>（这一网络其是从 DeepLabV3[2] 上魔改过来的。）</p>\n<ul>\n<li>Image Channel Reduce</li>\n</ul>\n<p>同时在分配深度桶的同时，网络另一分支用1x1卷积 + BN + ReLU 把特征的维数从256降到了64。</p>\n<p>​    经过这两个分支后，将预测出来的深度桶和特征像素做外积得到了带有深度信息的特征图（$G(u,v) = D(u,v) \\otimes F(u,v)$）且由于特征桶的结构，具有较高的容错性。称 G 为 frustum features</p>\n<h3 id=\"Frustum-to-Voxel-Trans\"><a href=\"#Frustum-to-Voxel-Trans\" class=\"headerlink\" title=\"Frustum to Voxel Trans\"></a>Frustum to Voxel Trans</h3><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1godzokeng2j30b907ujsr.jpg\" alt></p>\n<p>​    G 之后将被转换成体素的形式，这里的问题是在第分辨率的frustum features进行高分辨率的体素采样会导致过采样，导致出现大量相同的体素特征，浪费算力不说还降低预测准确性。所以这边作者直接把降采样前的特征层拉了过来，来保证不会出现上述问题。</p>\n<h3 id=\"Voxel-Collapse-to-BEV-gt-Detection\"><a href=\"#Voxel-Collapse-to-BEV-gt-Detection\" class=\"headerlink\" title=\"Voxel Collapse to BEV -&gt; Detection\"></a>Voxel Collapse to BEV -&gt; Detection</h3><p>​    由于BEV在保证同等检测效果的情况下能够节省计算资源，作者将体素的 Z 轴和 channels 直接连接起来，继续用1x1卷积 + BN + ReLU 将体素块压缩成 BEV的形式。然后接着在 BEV 特征块上连接检测头进行 3D目标检测。</p>\n<h2 id=\"深度离散化\"><a href=\"#深度离散化\" class=\"headerlink\" title=\"深度离散化\"></a>深度离散化</h2><p>​    本文的主要亮点就是其对于深度的处理，其对每个像素位置分配了离散化的深度桶，预测其属于某一深度的概率。这里的深度离散化作者使用的是 LID (Linear-increasing discretization)[3] 因为其对不同深度之间提供了最为平衡的预测概率。对于检测任务的深度我们最需要的是检测目标的深度信息，而更少去在意背景点的深度。</p>\n<p>​                                                            <script type=\"math/tex\">d_c = d_min + \\frac{d_{max}-d_{min}}{D(D+1)}\\cdot{d_i}{(d_1+1)}</script></p>\n<p>​    <em>（其中 $d<em>c$ 是连续深度值，[$d</em>{min},d_{max}$]是离散化的上下界，D是深度桶的数量，$d_i$ 是下标）</em></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1goe03wlr9sj30dn0bd0tp.jpg\" alt></p>\n<h2 id=\"实验效果\"><a href=\"#实验效果\" class=\"headerlink\" title=\"实验效果\"></a>实验效果</h2><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1goe0ckxhf6j30r10fgn17.jpg\" alt=\"KITTI实验效果\"></p>\n<p>​    可以看到其在车辆和新人检测上都打破了目前最好的检测方法，对骑行者的检测不如 MonoPSR 但也大大超过了其余检测模型。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1goe0gh8vyhj30dw07jdgw.jpg\" alt></p>\n<p>这张表可以看出其将深度预测和特征融合所得到的 frustum features 确实有助于提升检测效果。</p>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>​    个人觉得这篇paper的主要成功点在于其对于单目深度预测的创新解决方法，不同于传统的深度预测模型，提出了离散化深度将每个像素的深度概率离散化分配在不同的深度桶中，避免了网络过度依赖于深度的准确检测。但同时其也没有从根本上解决深度预测的问题，同时其中间对于特征图进行体素化投影再转为 BEV 的过程较为复杂，虽然其把降采样前的特征层拿来转成体素形式但是仍然还是无法避免会有损失。</p>\n<p>​    个人觉得可以借鉴该模型的深度预测方法，应用在现有的模型上或者对该模型的网络结构进行简化，可能会带来更好的效果。</p>\n<hr>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><p>[1]  Thomas Roddick, Alex Kendall, and Roberto Cipolla. Ortho\u0002 graphic feature transform for monocular 3D object detection.<em>BMVC</em>, 2018</p>\n<p>[2] Liang-Chieh Chen, George Papandreou, Florian Schroff, andHartwig Adam. Rethinking atrous convolution for semantic image segmentation. <em>arXiv preprint</em>, 2017</p>\n<p>[3] Yunlei Tang, Sebastian Dorn, and Chiragkumar Savani. Cen\u0002ter3d: Center-based monocular 3d object detection with joint depth understanding. <em>arXiv preprint</em>, 2020</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Categorical-Depth-Distribution-Network-for-Monocular-3D-Object-Detection\"><a href=\"#Categorical-Depth-Distribution-Network-for-Monocular-3D-Object-Detection\" class=\"headerlink\" title=\"Categorical Depth Distribution Network for Monocular 3D Object Detection\"></a><strong>Categorical Depth Distribution Network for Monocular 3D Object Detection</strong></h1><p><strong>关键词： 单目3d检测、绝对深度分配网络</strong></p>\n<p><strong>论文链接：</strong><a href=\"https://arxiv.org/pdf/2103.01100.pdf\">https://arxiv.org/pdf/2103.01100.pdf</a></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1godx97xntnj30bl08p0wn.jpg\" alt></p>\n<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>​    单目3D检测的难点一直在于对深度的预测，实例从3D空间被映射到2D平面的图像上丢失了深度信息，对深度的处理一直是单目3D目标检测研究的重点方向，目前主流的方法主要分为三类。</p>\n<p><strong>1、直接检测  (Direct Methods)</strong></p>\n<p>​    直接检测方法没有显式的对深度进行学习，比较有代表性的是关键点检测方法，通过关键点结合几何特征来帮助3D-Bbox的检测，好处是简单直接且高效，但这类方法由于没有显式的学习深度信息，往往导致深度预测的结果不尽理想。</p>\n<p><strong>2、基于深度  (Depth-Based Methods)</strong></p>\n<p>​    基于深度的方法通常先会通过一个单目深度预测分支来得到一张深度图作为网络的输入从而辅助对深度的检测，由于有了深度信息其可被转换成点云来处理（可以用上3d检测的方法)。但由于其深度和目标检测分离训练的结构，导致其可能会丢失一些隐含的信息。</p>\n<p><strong>3、基于网格  (Grid-Based Methods)</strong></p>\n<p>​    基于网格的方法避免了对深度的直接预测，而是通过预测一个 BEV grid 的表达来作为3D检测网络的输入，OFT[1]提出了一种体素网格，通过把体素投影到图像平面上进而采样图像特征将其转换成BEV的形式。但这也会导致大量体素和特征的重叠从而降低检测的准确性。</p>\n<p>​    <strong>CaDDN</strong> 网络对上面三种情况的优点进行结合，整体网络结构是同时训练了深度预测和3D检测（jointly）以期待其能够解决方法2中的问题，同时利用也将图像平面转换成了BEV的形式来提高检测的准确性。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1godxz73f1jj30nm0dntcy.jpg\" alt=\"网络结构\"></p>\n<h2 id=\"网络结构\"><a href=\"#网络结构\" class=\"headerlink\" title=\"网络结构\"></a>网络结构</h2><h3 id=\"Frustum-Feature-Network\"><a href=\"#Frustum-Feature-Network\" class=\"headerlink\" title=\"Frustum Feature Network\"></a>Frustum Feature Network</h3><ul>\n<li><strong>Depth Distribution Network</strong></li>\n</ul>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1godzoe00t7j30b908dabe.jpg\" alt></p>\n<p>对于特征提取网络，其输出形似一个截角锥形，因而作者称其为Frustum feature Network，其输入是原始图像 $I \\in R^{W_1\\times H_1\\times 3}$ 输出 $G \\in R^{W_F\\times H_F\\times D \\times C}$ 其中 W和H是特征的宽高，D 是深度桶，用以深度预测，C 是特征的维度。图像特征被用以在每个像素上预测绝对的深度分布 $D \\in R^{W_F\\times H_F\\times D}$ 网络对每个像素预测其落入某一深度桶（深度离散化）的概率，总共D个。</p>\n<p>（这一网络其是从 DeepLabV3[2] 上魔改过来的。）</p>\n<ul>\n<li>Image Channel Reduce</li>\n</ul>\n<p>同时在分配深度桶的同时，网络另一分支用1x1卷积 + BN + ReLU 把特征的维数从256降到了64。</p>\n<p>​    经过这两个分支后，将预测出来的深度桶和特征像素做外积得到了带有深度信息的特征图（$G(u,v) = D(u,v) \\otimes F(u,v)$）且由于特征桶的结构，具有较高的容错性。称 G 为 frustum features</p>\n<h3 id=\"Frustum-to-Voxel-Trans\"><a href=\"#Frustum-to-Voxel-Trans\" class=\"headerlink\" title=\"Frustum to Voxel Trans\"></a>Frustum to Voxel Trans</h3><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1godzokeng2j30b907ujsr.jpg\" alt></p>\n<p>​    G 之后将被转换成体素的形式，这里的问题是在第分辨率的frustum features进行高分辨率的体素采样会导致过采样，导致出现大量相同的体素特征，浪费算力不说还降低预测准确性。所以这边作者直接把降采样前的特征层拉了过来，来保证不会出现上述问题。</p>\n<h3 id=\"Voxel-Collapse-to-BEV-gt-Detection\"><a href=\"#Voxel-Collapse-to-BEV-gt-Detection\" class=\"headerlink\" title=\"Voxel Collapse to BEV -&gt; Detection\"></a>Voxel Collapse to BEV -&gt; Detection</h3><p>​    由于BEV在保证同等检测效果的情况下能够节省计算资源，作者将体素的 Z 轴和 channels 直接连接起来，继续用1x1卷积 + BN + ReLU 将体素块压缩成 BEV的形式。然后接着在 BEV 特征块上连接检测头进行 3D目标检测。</p>\n<h2 id=\"深度离散化\"><a href=\"#深度离散化\" class=\"headerlink\" title=\"深度离散化\"></a>深度离散化</h2><p>​    本文的主要亮点就是其对于深度的处理，其对每个像素位置分配了离散化的深度桶，预测其属于某一深度的概率。这里的深度离散化作者使用的是 LID (Linear-increasing discretization)[3] 因为其对不同深度之间提供了最为平衡的预测概率。对于检测任务的深度我们最需要的是检测目标的深度信息，而更少去在意背景点的深度。</p>\n<p>​                                                            <script type=\"math/tex\">d_c = d_min + \\frac{d_{max}-d_{min}}{D(D+1)}\\cdot{d_i}{(d_1+1)}</script></p>\n<p>​    <em>（其中 $d<em>c$ 是连续深度值，[$d</em>{min},d_{max}$]是离散化的上下界，D是深度桶的数量，$d_i$ 是下标）</em></p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1goe03wlr9sj30dn0bd0tp.jpg\" alt></p>\n<h2 id=\"实验效果\"><a href=\"#实验效果\" class=\"headerlink\" title=\"实验效果\"></a>实验效果</h2><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1goe0ckxhf6j30r10fgn17.jpg\" alt=\"KITTI实验效果\"></p>\n<p>​    可以看到其在车辆和新人检测上都打破了目前最好的检测方法，对骑行者的检测不如 MonoPSR 但也大大超过了其余检测模型。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1goe0gh8vyhj30dw07jdgw.jpg\" alt></p>\n<p>这张表可以看出其将深度预测和特征融合所得到的 frustum features 确实有助于提升检测效果。</p>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>​    个人觉得这篇paper的主要成功点在于其对于单目深度预测的创新解决方法，不同于传统的深度预测模型，提出了离散化深度将每个像素的深度概率离散化分配在不同的深度桶中，避免了网络过度依赖于深度的准确检测。但同时其也没有从根本上解决深度预测的问题，同时其中间对于特征图进行体素化投影再转为 BEV 的过程较为复杂，虽然其把降采样前的特征层拿来转成体素形式但是仍然还是无法避免会有损失。</p>\n<p>​    个人觉得可以借鉴该模型的深度预测方法，应用在现有的模型上或者对该模型的网络结构进行简化，可能会带来更好的效果。</p>\n<hr>\n<h3 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h3><p>[1]  Thomas Roddick, Alex Kendall, and Roberto Cipolla. Ortho\u0002 graphic feature transform for monocular 3D object detection.<em>BMVC</em>, 2018</p>\n<p>[2] Liang-Chieh Chen, George Papandreou, Florian Schroff, andHartwig Adam. Rethinking atrous convolution for semantic image segmentation. <em>arXiv preprint</em>, 2017</p>\n<p>[3] Yunlei Tang, Sebastian Dorn, and Chiragkumar Savani. Cen\u0002ter3d: Center-based monocular 3d object detection with joint depth understanding. <em>arXiv preprint</em>, 2020</p>\n"},{"title":"DETR 论文阅读","date":"2021-01-22T05:47:44.000Z","index_img":"/img/AI.png","math":true,"_content":"\n# End-to-End Object Detection with Transformers\n\n*关键词： 目标检测， Transformer，End-to-End*\n\n\n\n## 简介\n\n​\tDetr 这篇文章抛弃了传统 Fast-RCNN 基于 ROI 的目标检测方式，使用了Transformer以及其提出的 bipartite matching 做到位置无关和生成唯一的目标检测框，以此省去了 Anchor 和 NMS。以非常简单的架构达到媲美甚至超越 Fast-RCNN 的准确率，在能够做目标检测的同时，该模型还有较好的迁移能力，在原论文中通过 Transformer 的 Attention 机制实现了全景分割。\n\n\n\n\n## 结构分析\n\n![网络结构图](https://tva1.sinaimg.cn/large/008eGmZEgy1gmwgc8ubqoj310s07t435.jpg)\n\n​\tDETR 的网络结构很简单，分为三个部分，第一部分是一个传统 CNN 用于提取图片特征到更高维度，第二部分一个Transformer 的 Encoder 和 Decoder 来提取 Bounding Box，最后使用 Bipartite matching loss 来训练网络。\n\n\n\n![结构细节](https://tva1.sinaimg.cn/large/008eGmZEgy1gmwghk322pj30m8069adc.jpg)\n\n​\t\t更加细致的划分可划分为 CNN backbone 部分，Transformer 中的 Encoder 和 Decoder 部分，预测前馈网络 (FFN) 部分。接下来会详细讲解。\n\n\n\n### CNN 部分\n\n​\tDETR 的第一部分用了一个 CNN backbone 将 $x_{img} \\in R^{3 \\times H_0 \\times W_0}$ (3 的 RGB 深度) 转换为 $f \\in R^{C \\times H \\times W}$ 的特征层。论文中用了 $C = 2048, H = \\frac{H_0}{32}, W = \\frac{W_0}{32}$ \n\n\n\n### Transformer 部分\n\n#### Encoder\n\n​\t先用 1x1 的卷积核将纬度从 C 降到 d，获得一个新的特征图 $R^{ d \\times H \\times W}$ 。由于 Encoder 需要一个序列，我们要将特征图拉平成为 $d \\times HW$ 的向量，输入到 encoder 中，每一个 encoder 都是同样的结构，由一个多头注意力模块和一个前馈网络（FFN）组成。不像RNN，transformer 的输入是顺序无关的，于是我们也学 NLP 对每一个注意力层加一个位置编码 （position encodings）。将状态编码和之前拉平的特征图向量相加之后喂入 encoder 中。\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwioerjhbj30ea0ghgq4.jpg\" style=\"zoom:80%;\" />\n\n#### Decoder\n\n​\tdecoder 的输入有两个，一个是 Object Queries 另一个是刚刚 Encoder 的输出，结构和传统 Transformer 差不多。比较有意思的是这个输入的 Object Queries，由于 Transformer 是 fixed size，如果我们需要 N 个 Bounding Box 那么我们就需要 N 个输入，同时这个 Object Queries 顺便充当了 decoder 的 position encodings，是通过学习得来的。\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwi2hocbcj30eh0gb421.jpg\" style=\"zoom:80%;\" />\n\n​\tencoder 的输出直接喂到的是 Encoder-Decoder Attention 层，这 N 个位置嵌入要先通过自注意力层才获得 encoder 的信息。作者将这 N 个 序列最后生成的 Bounding Box 拿出来可视化，结果非常 Amazing 啊。\n\n​\t![](https://tva1.sinaimg.cn/large/008eGmZEgy1gmwinw5iwbj30wn075ale.jpg)\n\n​\t图中的不同颜色的点代表不同大小形态的 Bounding Box，绿色代表较小的 Bounding Box，紫色代较大的 Bounding Box，红色代表大的水平的 boxes，蓝色代表大的竖直的 boxes。 对于每一个输入序列，其都有所侧重，有的侧重与左侧的小 Bounding Box 有的侧重于中间大的Bounding Box。\n\n\n\n### Bipartite matching loss\n\n​\t之前检测器往往通过anchor和groundtruth的IOU来确定正负样本，而DETR使用了bipartite matching loss 来确定正负样本。\n\n​\t![bipartite matching loss](https://tva1.sinaimg.cn/large/008eGmZEgy1gmzoqacu30j307d01waa0.jpg)\n\n​\t其中 $L_{match}$ 是 ground true 和预测 bounding boxes 之间的 pair-wise matching cost （一一配对 penalty）\n\n​\t![bipartite matching](https://tva1.sinaimg.cn/large/008eGmZEgy1gmzoq11i5jj303405hmxa.jpg) \n\n​\t通过一一配对，就不需要再采取传统的 NMS 了，因为一个bounding box 只能和一个 ground true 进行匹配，必然会引入 loss。算法实现采用的是**匈牙利算法**，这个后期我会写在博客上。\n\n\n\n### FFN\n\n​\t最后得出结果的网络，是一个三层的感知机，activation function 用的是 ReLU，以及一个线性映射层。输出的是每一个 bounding box 的中心坐标，以及它的宽高 $(x,y,w,h)$ 以及物体的分类。\n\n\n\n## 实验\n\n​\t原文在 COCO 2017 数据集上做的实验，模型虽然简单但却消耗了大量的训练时间 （Training the baseline model for 300 epochs on 16 V100 GPUs takes 3 days, with 4 images per GPU），最后效果媲美甚至超过了经过良好调教的 Fast-RCNN 类的人工 head + anchor 的模式。\n\n​\t![实验结果](https://tva1.sinaimg.cn/large/008eGmZEgy1gmzpkgtz3xj30gj06n75k.jpg) \n\n\n\n## 总结\n\n​\t这篇文章还是相当惊艳的，一直以来不管是 anchor based 还是 anchor free 的目标检测方法都难以脱离人工定义 anchor 的过程，而本篇文章通过使用 Transformer + positional encoding 达到甚至超越了传统方法的性能，里面特别是 positional encodings 的 object queries 非常耐人寻味，这些 queries 学到的真的只是 positional encoding吗？这个 queries 是否有可能是 tasks 无关的？如果是能不能通过预训练的方式来提高训练速度，这些问题都是后期值得探索的。\n\n\n\n## 参考\n\n[1] Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko: “End-to-End Object Detection with Transformers”, 2020; [arXiv:2005.12872](http://arxiv.org/abs/2005.12872)\n\n[2] 如何评价FAIR的新论文DETR？ https://www.zhihu.com/question/397692959/answer/1258046044 \n\n[3] 如何看待End-to-End Object Detection with Transformers? https://www.zhihu.com/question/397624847/answer/1250143331\n\n[4] 详解Transformer （Attention Is All You Need）https://zhuanlan.zhihu.com/p/48508221\n\n","source":"_posts/Research/DETR.md","raw":"---\ntitle: DETR 论文阅读\ndate: 2021-01-22 13:47:44\nindex_img: /img/AI.png\ncategory: [Research, Object Detection]\ntags: [Transformer]\nmath: true\n---\n\n# End-to-End Object Detection with Transformers\n\n*关键词： 目标检测， Transformer，End-to-End*\n\n\n\n## 简介\n\n​\tDetr 这篇文章抛弃了传统 Fast-RCNN 基于 ROI 的目标检测方式，使用了Transformer以及其提出的 bipartite matching 做到位置无关和生成唯一的目标检测框，以此省去了 Anchor 和 NMS。以非常简单的架构达到媲美甚至超越 Fast-RCNN 的准确率，在能够做目标检测的同时，该模型还有较好的迁移能力，在原论文中通过 Transformer 的 Attention 机制实现了全景分割。\n\n\n\n\n## 结构分析\n\n![网络结构图](https://tva1.sinaimg.cn/large/008eGmZEgy1gmwgc8ubqoj310s07t435.jpg)\n\n​\tDETR 的网络结构很简单，分为三个部分，第一部分是一个传统 CNN 用于提取图片特征到更高维度，第二部分一个Transformer 的 Encoder 和 Decoder 来提取 Bounding Box，最后使用 Bipartite matching loss 来训练网络。\n\n\n\n![结构细节](https://tva1.sinaimg.cn/large/008eGmZEgy1gmwghk322pj30m8069adc.jpg)\n\n​\t\t更加细致的划分可划分为 CNN backbone 部分，Transformer 中的 Encoder 和 Decoder 部分，预测前馈网络 (FFN) 部分。接下来会详细讲解。\n\n\n\n### CNN 部分\n\n​\tDETR 的第一部分用了一个 CNN backbone 将 $x_{img} \\in R^{3 \\times H_0 \\times W_0}$ (3 的 RGB 深度) 转换为 $f \\in R^{C \\times H \\times W}$ 的特征层。论文中用了 $C = 2048, H = \\frac{H_0}{32}, W = \\frac{W_0}{32}$ \n\n\n\n### Transformer 部分\n\n#### Encoder\n\n​\t先用 1x1 的卷积核将纬度从 C 降到 d，获得一个新的特征图 $R^{ d \\times H \\times W}$ 。由于 Encoder 需要一个序列，我们要将特征图拉平成为 $d \\times HW$ 的向量，输入到 encoder 中，每一个 encoder 都是同样的结构，由一个多头注意力模块和一个前馈网络（FFN）组成。不像RNN，transformer 的输入是顺序无关的，于是我们也学 NLP 对每一个注意力层加一个位置编码 （position encodings）。将状态编码和之前拉平的特征图向量相加之后喂入 encoder 中。\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwioerjhbj30ea0ghgq4.jpg\" style=\"zoom:80%;\" />\n\n#### Decoder\n\n​\tdecoder 的输入有两个，一个是 Object Queries 另一个是刚刚 Encoder 的输出，结构和传统 Transformer 差不多。比较有意思的是这个输入的 Object Queries，由于 Transformer 是 fixed size，如果我们需要 N 个 Bounding Box 那么我们就需要 N 个输入，同时这个 Object Queries 顺便充当了 decoder 的 position encodings，是通过学习得来的。\n\n<img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwi2hocbcj30eh0gb421.jpg\" style=\"zoom:80%;\" />\n\n​\tencoder 的输出直接喂到的是 Encoder-Decoder Attention 层，这 N 个位置嵌入要先通过自注意力层才获得 encoder 的信息。作者将这 N 个 序列最后生成的 Bounding Box 拿出来可视化，结果非常 Amazing 啊。\n\n​\t![](https://tva1.sinaimg.cn/large/008eGmZEgy1gmwinw5iwbj30wn075ale.jpg)\n\n​\t图中的不同颜色的点代表不同大小形态的 Bounding Box，绿色代表较小的 Bounding Box，紫色代较大的 Bounding Box，红色代表大的水平的 boxes，蓝色代表大的竖直的 boxes。 对于每一个输入序列，其都有所侧重，有的侧重与左侧的小 Bounding Box 有的侧重于中间大的Bounding Box。\n\n\n\n### Bipartite matching loss\n\n​\t之前检测器往往通过anchor和groundtruth的IOU来确定正负样本，而DETR使用了bipartite matching loss 来确定正负样本。\n\n​\t![bipartite matching loss](https://tva1.sinaimg.cn/large/008eGmZEgy1gmzoqacu30j307d01waa0.jpg)\n\n​\t其中 $L_{match}$ 是 ground true 和预测 bounding boxes 之间的 pair-wise matching cost （一一配对 penalty）\n\n​\t![bipartite matching](https://tva1.sinaimg.cn/large/008eGmZEgy1gmzoq11i5jj303405hmxa.jpg) \n\n​\t通过一一配对，就不需要再采取传统的 NMS 了，因为一个bounding box 只能和一个 ground true 进行匹配，必然会引入 loss。算法实现采用的是**匈牙利算法**，这个后期我会写在博客上。\n\n\n\n### FFN\n\n​\t最后得出结果的网络，是一个三层的感知机，activation function 用的是 ReLU，以及一个线性映射层。输出的是每一个 bounding box 的中心坐标，以及它的宽高 $(x,y,w,h)$ 以及物体的分类。\n\n\n\n## 实验\n\n​\t原文在 COCO 2017 数据集上做的实验，模型虽然简单但却消耗了大量的训练时间 （Training the baseline model for 300 epochs on 16 V100 GPUs takes 3 days, with 4 images per GPU），最后效果媲美甚至超过了经过良好调教的 Fast-RCNN 类的人工 head + anchor 的模式。\n\n​\t![实验结果](https://tva1.sinaimg.cn/large/008eGmZEgy1gmzpkgtz3xj30gj06n75k.jpg) \n\n\n\n## 总结\n\n​\t这篇文章还是相当惊艳的，一直以来不管是 anchor based 还是 anchor free 的目标检测方法都难以脱离人工定义 anchor 的过程，而本篇文章通过使用 Transformer + positional encoding 达到甚至超越了传统方法的性能，里面特别是 positional encodings 的 object queries 非常耐人寻味，这些 queries 学到的真的只是 positional encoding吗？这个 queries 是否有可能是 tasks 无关的？如果是能不能通过预训练的方式来提高训练速度，这些问题都是后期值得探索的。\n\n\n\n## 参考\n\n[1] Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko: “End-to-End Object Detection with Transformers”, 2020; [arXiv:2005.12872](http://arxiv.org/abs/2005.12872)\n\n[2] 如何评价FAIR的新论文DETR？ https://www.zhihu.com/question/397692959/answer/1258046044 \n\n[3] 如何看待End-to-End Object Detection with Transformers? https://www.zhihu.com/question/397624847/answer/1250143331\n\n[4] 详解Transformer （Attention Is All You Need）https://zhuanlan.zhihu.com/p/48508221\n\n","slug":"Research/DETR","published":1,"updated":"2021-01-25T02:14:06.702Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty4h0035s8pd5lfhafgi","content":"<h1 id=\"End-to-End-Object-Detection-with-Transformers\"><a href=\"#End-to-End-Object-Detection-with-Transformers\" class=\"headerlink\" title=\"End-to-End Object Detection with Transformers\"></a>End-to-End Object Detection with Transformers</h1><p><em>关键词： 目标检测， Transformer，End-to-End</em></p>\n<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>​    Detr 这篇文章抛弃了传统 Fast-RCNN 基于 ROI 的目标检测方式，使用了Transformer以及其提出的 bipartite matching 做到位置无关和生成唯一的目标检测框，以此省去了 Anchor 和 NMS。以非常简单的架构达到媲美甚至超越 Fast-RCNN 的准确率，在能够做目标检测的同时，该模型还有较好的迁移能力，在原论文中通过 Transformer 的 Attention 机制实现了全景分割。</p>\n<h2 id=\"结构分析\"><a href=\"#结构分析\" class=\"headerlink\" title=\"结构分析\"></a>结构分析</h2><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwgc8ubqoj310s07t435.jpg\" alt=\"网络结构图\"></p>\n<p>​    DETR 的网络结构很简单，分为三个部分，第一部分是一个传统 CNN 用于提取图片特征到更高维度，第二部分一个Transformer 的 Encoder 和 Decoder 来提取 Bounding Box，最后使用 Bipartite matching loss 来训练网络。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwghk322pj30m8069adc.jpg\" alt=\"结构细节\"></p>\n<p>​        更加细致的划分可划分为 CNN backbone 部分，Transformer 中的 Encoder 和 Decoder 部分，预测前馈网络 (FFN) 部分。接下来会详细讲解。</p>\n<h3 id=\"CNN-部分\"><a href=\"#CNN-部分\" class=\"headerlink\" title=\"CNN 部分\"></a>CNN 部分</h3><p>​    DETR 的第一部分用了一个 CNN backbone 将 $x_{img} \\in R^{3 \\times H_0 \\times W_0}$ (3 的 RGB 深度) 转换为 $f \\in R^{C \\times H \\times W}$ 的特征层。论文中用了 $C = 2048, H = \\frac{H_0}{32}, W = \\frac{W_0}{32}$ </p>\n<h3 id=\"Transformer-部分\"><a href=\"#Transformer-部分\" class=\"headerlink\" title=\"Transformer 部分\"></a>Transformer 部分</h3><h4 id=\"Encoder\"><a href=\"#Encoder\" class=\"headerlink\" title=\"Encoder\"></a>Encoder</h4><p>​    先用 1x1 的卷积核将纬度从 C 降到 d，获得一个新的特征图 $R^{ d \\times H \\times W}$ 。由于 Encoder 需要一个序列，我们要将特征图拉平成为 $d \\times HW$ 的向量，输入到 encoder 中，每一个 encoder 都是同样的结构，由一个多头注意力模块和一个前馈网络（FFN）组成。不像RNN，transformer 的输入是顺序无关的，于是我们也学 NLP 对每一个注意力层加一个位置编码 （position encodings）。将状态编码和之前拉平的特征图向量相加之后喂入 encoder 中。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwioerjhbj30ea0ghgq4.jpg\" style=\"zoom:80%;\"></p>\n<h4 id=\"Decoder\"><a href=\"#Decoder\" class=\"headerlink\" title=\"Decoder\"></a>Decoder</h4><p>​    decoder 的输入有两个，一个是 Object Queries 另一个是刚刚 Encoder 的输出，结构和传统 Transformer 差不多。比较有意思的是这个输入的 Object Queries，由于 Transformer 是 fixed size，如果我们需要 N 个 Bounding Box 那么我们就需要 N 个输入，同时这个 Object Queries 顺便充当了 decoder 的 position encodings，是通过学习得来的。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwi2hocbcj30eh0gb421.jpg\" style=\"zoom:80%;\"></p>\n<p>​    encoder 的输出直接喂到的是 Encoder-Decoder Attention 层，这 N 个位置嵌入要先通过自注意力层才获得 encoder 的信息。作者将这 N 个 序列最后生成的 Bounding Box 拿出来可视化，结果非常 Amazing 啊。</p>\n<p>​    <img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwinw5iwbj30wn075ale.jpg\" alt></p>\n<p>​    图中的不同颜色的点代表不同大小形态的 Bounding Box，绿色代表较小的 Bounding Box，紫色代较大的 Bounding Box，红色代表大的水平的 boxes，蓝色代表大的竖直的 boxes。 对于每一个输入序列，其都有所侧重，有的侧重与左侧的小 Bounding Box 有的侧重于中间大的Bounding Box。</p>\n<h3 id=\"Bipartite-matching-loss\"><a href=\"#Bipartite-matching-loss\" class=\"headerlink\" title=\"Bipartite matching loss\"></a>Bipartite matching loss</h3><p>​    之前检测器往往通过anchor和groundtruth的IOU来确定正负样本，而DETR使用了bipartite matching loss 来确定正负样本。</p>\n<p>​    <img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmzoqacu30j307d01waa0.jpg\" alt=\"bipartite matching loss\"></p>\n<p>​    其中 $L_{match}$ 是 ground true 和预测 bounding boxes 之间的 pair-wise matching cost （一一配对 penalty）</p>\n<p>​    <img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmzoq11i5jj303405hmxa.jpg\" alt=\"bipartite matching\"> </p>\n<p>​    通过一一配对，就不需要再采取传统的 NMS 了，因为一个bounding box 只能和一个 ground true 进行匹配，必然会引入 loss。算法实现采用的是<strong>匈牙利算法</strong>，这个后期我会写在博客上。</p>\n<h3 id=\"FFN\"><a href=\"#FFN\" class=\"headerlink\" title=\"FFN\"></a>FFN</h3><p>​    最后得出结果的网络，是一个三层的感知机，activation function 用的是 ReLU，以及一个线性映射层。输出的是每一个 bounding box 的中心坐标，以及它的宽高 $(x,y,w,h)$ 以及物体的分类。</p>\n<h2 id=\"实验\"><a href=\"#实验\" class=\"headerlink\" title=\"实验\"></a>实验</h2><p>​    原文在 COCO 2017 数据集上做的实验，模型虽然简单但却消耗了大量的训练时间 （Training the baseline model for 300 epochs on 16 V100 GPUs takes 3 days, with 4 images per GPU），最后效果媲美甚至超过了经过良好调教的 Fast-RCNN 类的人工 head + anchor 的模式。</p>\n<p>​    <img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmzpkgtz3xj30gj06n75k.jpg\" alt=\"实验结果\"> </p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>​    这篇文章还是相当惊艳的，一直以来不管是 anchor based 还是 anchor free 的目标检测方法都难以脱离人工定义 anchor 的过程，而本篇文章通过使用 Transformer + positional encoding 达到甚至超越了传统方法的性能，里面特别是 positional encodings 的 object queries 非常耐人寻味，这些 queries 学到的真的只是 positional encoding吗？这个 queries 是否有可能是 tasks 无关的？如果是能不能通过预训练的方式来提高训练速度，这些问题都是后期值得探索的。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>[1] Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko: “End-to-End Object Detection with Transformers”, 2020; <a href=\"http://arxiv.org/abs/2005.12872\">arXiv:2005.12872</a></p>\n<p>[2] 如何评价FAIR的新论文DETR？ <a href=\"https://www.zhihu.com/question/397692959/answer/1258046044\">https://www.zhihu.com/question/397692959/answer/1258046044</a> </p>\n<p>[3] 如何看待End-to-End Object Detection with Transformers? <a href=\"https://www.zhihu.com/question/397624847/answer/1250143331\">https://www.zhihu.com/question/397624847/answer/1250143331</a></p>\n<p>[4] 详解Transformer （Attention Is All You Need）<a href=\"https://zhuanlan.zhihu.com/p/48508221\">https://zhuanlan.zhihu.com/p/48508221</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"End-to-End-Object-Detection-with-Transformers\"><a href=\"#End-to-End-Object-Detection-with-Transformers\" class=\"headerlink\" title=\"End-to-End Object Detection with Transformers\"></a>End-to-End Object Detection with Transformers</h1><p><em>关键词： 目标检测， Transformer，End-to-End</em></p>\n<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>​    Detr 这篇文章抛弃了传统 Fast-RCNN 基于 ROI 的目标检测方式，使用了Transformer以及其提出的 bipartite matching 做到位置无关和生成唯一的目标检测框，以此省去了 Anchor 和 NMS。以非常简单的架构达到媲美甚至超越 Fast-RCNN 的准确率，在能够做目标检测的同时，该模型还有较好的迁移能力，在原论文中通过 Transformer 的 Attention 机制实现了全景分割。</p>\n<h2 id=\"结构分析\"><a href=\"#结构分析\" class=\"headerlink\" title=\"结构分析\"></a>结构分析</h2><p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwgc8ubqoj310s07t435.jpg\" alt=\"网络结构图\"></p>\n<p>​    DETR 的网络结构很简单，分为三个部分，第一部分是一个传统 CNN 用于提取图片特征到更高维度，第二部分一个Transformer 的 Encoder 和 Decoder 来提取 Bounding Box，最后使用 Bipartite matching loss 来训练网络。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwghk322pj30m8069adc.jpg\" alt=\"结构细节\"></p>\n<p>​        更加细致的划分可划分为 CNN backbone 部分，Transformer 中的 Encoder 和 Decoder 部分，预测前馈网络 (FFN) 部分。接下来会详细讲解。</p>\n<h3 id=\"CNN-部分\"><a href=\"#CNN-部分\" class=\"headerlink\" title=\"CNN 部分\"></a>CNN 部分</h3><p>​    DETR 的第一部分用了一个 CNN backbone 将 $x_{img} \\in R^{3 \\times H_0 \\times W_0}$ (3 的 RGB 深度) 转换为 $f \\in R^{C \\times H \\times W}$ 的特征层。论文中用了 $C = 2048, H = \\frac{H_0}{32}, W = \\frac{W_0}{32}$ </p>\n<h3 id=\"Transformer-部分\"><a href=\"#Transformer-部分\" class=\"headerlink\" title=\"Transformer 部分\"></a>Transformer 部分</h3><h4 id=\"Encoder\"><a href=\"#Encoder\" class=\"headerlink\" title=\"Encoder\"></a>Encoder</h4><p>​    先用 1x1 的卷积核将纬度从 C 降到 d，获得一个新的特征图 $R^{ d \\times H \\times W}$ 。由于 Encoder 需要一个序列，我们要将特征图拉平成为 $d \\times HW$ 的向量，输入到 encoder 中，每一个 encoder 都是同样的结构，由一个多头注意力模块和一个前馈网络（FFN）组成。不像RNN，transformer 的输入是顺序无关的，于是我们也学 NLP 对每一个注意力层加一个位置编码 （position encodings）。将状态编码和之前拉平的特征图向量相加之后喂入 encoder 中。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwioerjhbj30ea0ghgq4.jpg\" style=\"zoom:80%;\"></p>\n<h4 id=\"Decoder\"><a href=\"#Decoder\" class=\"headerlink\" title=\"Decoder\"></a>Decoder</h4><p>​    decoder 的输入有两个，一个是 Object Queries 另一个是刚刚 Encoder 的输出，结构和传统 Transformer 差不多。比较有意思的是这个输入的 Object Queries，由于 Transformer 是 fixed size，如果我们需要 N 个 Bounding Box 那么我们就需要 N 个输入，同时这个 Object Queries 顺便充当了 decoder 的 position encodings，是通过学习得来的。</p>\n<p><img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwi2hocbcj30eh0gb421.jpg\" style=\"zoom:80%;\"></p>\n<p>​    encoder 的输出直接喂到的是 Encoder-Decoder Attention 层，这 N 个位置嵌入要先通过自注意力层才获得 encoder 的信息。作者将这 N 个 序列最后生成的 Bounding Box 拿出来可视化，结果非常 Amazing 啊。</p>\n<p>​    <img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmwinw5iwbj30wn075ale.jpg\" alt></p>\n<p>​    图中的不同颜色的点代表不同大小形态的 Bounding Box，绿色代表较小的 Bounding Box，紫色代较大的 Bounding Box，红色代表大的水平的 boxes，蓝色代表大的竖直的 boxes。 对于每一个输入序列，其都有所侧重，有的侧重与左侧的小 Bounding Box 有的侧重于中间大的Bounding Box。</p>\n<h3 id=\"Bipartite-matching-loss\"><a href=\"#Bipartite-matching-loss\" class=\"headerlink\" title=\"Bipartite matching loss\"></a>Bipartite matching loss</h3><p>​    之前检测器往往通过anchor和groundtruth的IOU来确定正负样本，而DETR使用了bipartite matching loss 来确定正负样本。</p>\n<p>​    <img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmzoqacu30j307d01waa0.jpg\" alt=\"bipartite matching loss\"></p>\n<p>​    其中 $L_{match}$ 是 ground true 和预测 bounding boxes 之间的 pair-wise matching cost （一一配对 penalty）</p>\n<p>​    <img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmzoq11i5jj303405hmxa.jpg\" alt=\"bipartite matching\"> </p>\n<p>​    通过一一配对，就不需要再采取传统的 NMS 了，因为一个bounding box 只能和一个 ground true 进行匹配，必然会引入 loss。算法实现采用的是<strong>匈牙利算法</strong>，这个后期我会写在博客上。</p>\n<h3 id=\"FFN\"><a href=\"#FFN\" class=\"headerlink\" title=\"FFN\"></a>FFN</h3><p>​    最后得出结果的网络，是一个三层的感知机，activation function 用的是 ReLU，以及一个线性映射层。输出的是每一个 bounding box 的中心坐标，以及它的宽高 $(x,y,w,h)$ 以及物体的分类。</p>\n<h2 id=\"实验\"><a href=\"#实验\" class=\"headerlink\" title=\"实验\"></a>实验</h2><p>​    原文在 COCO 2017 数据集上做的实验，模型虽然简单但却消耗了大量的训练时间 （Training the baseline model for 300 epochs on 16 V100 GPUs takes 3 days, with 4 images per GPU），最后效果媲美甚至超过了经过良好调教的 Fast-RCNN 类的人工 head + anchor 的模式。</p>\n<p>​    <img src=\"https://tva1.sinaimg.cn/large/008eGmZEgy1gmzpkgtz3xj30gj06n75k.jpg\" alt=\"实验结果\"> </p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>​    这篇文章还是相当惊艳的，一直以来不管是 anchor based 还是 anchor free 的目标检测方法都难以脱离人工定义 anchor 的过程，而本篇文章通过使用 Transformer + positional encoding 达到甚至超越了传统方法的性能，里面特别是 positional encodings 的 object queries 非常耐人寻味，这些 queries 学到的真的只是 positional encoding吗？这个 queries 是否有可能是 tasks 无关的？如果是能不能通过预训练的方式来提高训练速度，这些问题都是后期值得探索的。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p>[1] Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko: “End-to-End Object Detection with Transformers”, 2020; <a href=\"http://arxiv.org/abs/2005.12872\">arXiv:2005.12872</a></p>\n<p>[2] 如何评价FAIR的新论文DETR？ <a href=\"https://www.zhihu.com/question/397692959/answer/1258046044\">https://www.zhihu.com/question/397692959/answer/1258046044</a> </p>\n<p>[3] 如何看待End-to-End Object Detection with Transformers? <a href=\"https://www.zhihu.com/question/397624847/answer/1250143331\">https://www.zhihu.com/question/397624847/answer/1250143331</a></p>\n<p>[4] 详解Transformer （Attention Is All You Need）<a href=\"https://zhuanlan.zhihu.com/p/48508221\">https://zhuanlan.zhihu.com/p/48508221</a></p>\n"},{"title":"ICS-Lab1 位运算","index_img":"/img/ICS_Lab1/top.jpg","date":"2020-11-05T15:58:42.000Z","_content":"\n# ICS_Lab1-位运算\n\n> 这个是CS:APP的第一个lab，也是我ICS课上的第一个lab，主要注重于使用受限制的位运算来完成操作\n\n***\n\n## **Bits.c**\n### **1. bitAnd--与**\n**题目：**\n\n    只用~和|实现&\n\n**样例：**\n\n    bitAnd(6, 5) = 4\n\n**可使用操作：** ~ |\n    \n**最大操作数限制：** 8\n\n**使用操作数：** 4\n\n```cpp\nint bitAnd(int x, int y) {\n  return ~(~x | ~y); //De Morgan's laws\n}\n```\n\n> 应用摩根律 ~(x | y) = ~x & ~y, 可得 x & y = ~(~x | ~y)\n\n***\n\n### **2. getByte--获取字节**\n**题目：**\n\n    从x中提取字节n, n编号从0至3\n\n**样例：**\n\n    getByte(0x12345678,1) = 0x56\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 6\n\n**使用操作数：** 3\n\n**代码：**\n```cpp\nint getByte(int x, int n) {\n  return (x >> (n << 3)) & 0xff;\n}\n```\n\n**分析：**\n\n*由于 1Byte = 8bits = 2^3bits， 所以 n Bytes = 2^3 * n bits*\n> 因而将n左移3位，即 n * 2^3, 再将x右移 n * 2^3 即可将所求字节放在低8位，将其与上0xff，即可取出字节。\n\n***\n\n### **3. logicalShift--逻辑右移**\n**题目：**\n\n    将x逻辑右移n位\n\n**样例：**\n\n    logicalShift(0x87654321,4) = 0x08765432\n\n**可使用操作：**  ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 20\n\n**使用操作数：** 10\n\n**代码：**\n```cpp\nint logicalShift(int x, int n) {\n  //flag equals to: if n == 0 return 0; else return 1;\n  int flag = !!n;\n  int mask = ~(flag << (32 + (~n + 1)));\n  return (x >> n) & mask;\n}\n```\n\n**分析：**\n\n* 算数右移\n> 算数右移即在右移后用原符号位数将高位补齐，保持右移后二进制数的符号保持不变。\n\n* 逻辑右移\n> 逻辑右移即在右移后用 0 将高位补齐，是“逻辑上”的右移。\n\n> 在正常右移运算中使用的是算数右移，因而要解决的问题即对于负数如何将最高位补上0，而非符号位1。\n> 我采取掩码的方式，先将x正常右移n位与上其高位的掩码，使其右移产生的高位变为0\n\n* 掩码构造\n> 掩码不能草率的构造为 ~(-1 << (32 - n)), 这种构造方式当n为0时会因-1被左移32位而导致异常，构造出来的mask仍为0\n\n> 由于不能使用if，为判断n是否为0，我才用了一个flag = !n + ~0, 其有很好的性质。当n为0时，flag也为0，而当n不为零时，flag统一为-1，这样使用flag代替原先的-1, 从而避免上述情况。\n\n> 这样我们可以使用 mask = ~(flag << (32 + (~n + 1)))，来构造掩码，当n为0时，flag为0，从而mask = -1，避免上述错误。\n\n***\n\n### **4. bitCount--比特计数**\n**题目：**\n\n    返回二进制数中1的个数\n\n**样例：**\n\n    bitCount(5) = 2, bitCount(7) = 3\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 40\n\n**使用操作数：** 36\n\n**代码：**\n```cpp\nint bitCount(int x) {\n  int tmp, l1, l2, l4, l8, l16; //tmp is used to save ops\n  tmp = (0x55 << 8) + 0x55;\n  l1 = (tmp << 16) + tmp; //0x55555555\n  tmp = (0x33 << 8) + 0x33;\n  l2 = (tmp << 16) + tmp; //0x33333333\n  tmp = (0x0f << 8) + 0x0f;\n  l4 = (tmp << 16) + tmp; //0x0f0f0f0f\n  l8 = (0xff << 16) + 0xff; //0x00ff00ff\n  l16 = (0xff << 8) + 0xff; //0x0000ffff\n\n  x = (x & l1) + ((x >> 1) & l1);\n  x = (x & l2) + ((x >> 2) & l2);\n  x = (x & l4) + ((x >> 4) & l4);\n  x = (x & l8) + ((x >> 8) & l8);\n  x = (x & l16) + ((x >> 16) & l16);\n  return x;\n}\n```\n\n**分析：**\n\n* 分治思想\n> 本题使用了一个简单的分治思想，对于一个二进制数，要对其中为1的位做计数， 对于1位二进制数来说，1的个数无非就是其本身所表示的1或0。利用这个特性，我们可以先将一个二进制数每一位独立分开为相间隔的两部分, 其每位表示的就是自身的二进制个数，再将两串二进制数对其相加，所得到的每两位分隔的二进制数就是表达这个位置的位为1的个数。\n\n> 进一步相加为4位，8位其所代表的含义不变，最后合并至32位二进制数，其所表示的就是原二进制数中所含1的个数。\n\n```cpp\n//以八位二进制数 10101110 为例//\n按 1|0|1|0|1|1|1|0 分割， 为两串1|1|1|1和0|0|1|0，再将其合并，成为 01 | 01 | 10 | 01, 再将两串 01 | 10 和01 | 01合并得 0010 | 0011（这个很容易看出表示左四位有2个1，右四位有3个1），再次合并得 00000101, 得到总共有5个1。\n\n//对于32位二进制数亦按此继续操作即可//\n```\n\n> 于是为完成分割取位的操作，我们需要采用掩码\n\n* 0x55555555 \\ 0x33333333 \\ 0x0f0f0f0f \\ 0x0000ffff\n\n> 利用位运算分别构造，使用tmp可以节约ops, 之后按照分治思想进行操作即可。\n\n***\n\n### **5. bang--逻辑非**\n\n**题目：**\n\n    计算 !x 而不使用逻辑非!\n\n**样例：**\n\n    bang(3) = 0, bang(0) = 1\n\n**可使用操作：** ~ & ^ | + << >>\n    \n**最大操作数限制：** 12\n\n**使用操作数：** 6\n\n**代码：**\n```cpp\nint bang(int x) {\n  return ((x >> 31) | ((~x + 1) >> 31)) + 1;\n}\n```\n\n**分析：**\n\n* 逻辑非\n> 对于逻辑非运算，应该都很熟悉，!x 当且仅当x为0时其为1，其余时候都为0，可以用来区分零和非零数。\n\n> 该问题的关键就是在于如何区分零和非零数，我们知道零的二补码仍然是零，而对于其余非零数，其符号位会有相应改变，利用这一性质，我们可以对零和非零数做出区分。\n\n> 使用 ```((x >> 31) | ((~x + 1) >> 31))```，将二进制数x的符号位与其补码左移31位相与，如若是非零数，其中符号位至少有一个为1，所以经过31位的算数右移后，其中一项必为-1，一项为0，相与之后得到-1,。而对于0来说，结果始终为0。\n\n> 最后只要将结果+1，就能得到逻辑非的效果。\n\n***\n\n### **6. tmin--最小数**\n\n**题目：**\n\n    返回二补码中最小的数\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 4\n\n**使用操作数：** 1\n\n**代码：**\n```cpp\nint tmin(void) {\n  return 1 << 31;\n}\n```\n\n**分析：**\n\n> 此题非常简单，我们知道计算机中负数是用其补码表示的，int所能表示的最小数为0x80000000(-2^31), 即符号位为1，其余皆为0，所以只要将1左移31位即可。\n\n***\n\n### **7. fitsBits--填充比特**\n\n**题目：**\n\n    返回1如果x可以表示为n位二补码，反之返回0 (1 <= n <= 32)\n\n**样例：**\n\n    fitsBits(5,3) = 0, fitsBits(-4,3) = 1\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 15\n\n**使用操作数：** 7\n\n**代码：**\n```cpp\nint fitsBits(int x, int n) {\n  int k = x >> (n + ~0); // if can k = 0 or -1\n  return !k | !(k + 1);\n}\n```\n\n**分析：**\n\n> 我们知道如若一个数能够被n位二进制数表示，则其第n位即最高位是符号位，那么将其右移n-1位后，根据算术右移，其得到的结果不是0，就是1。否则表示，其还有高于n位的位数， 即不能用n位表示。\n\n> 所以用 k = x >> (n + ~0) 表示将其右移n-1位，再用 !k | !(k + 1) 判断k是否为0或-1\n\n***\n\n### **8. divpwr2--除以2的n次方**\n\n**题目：**\n\n    计算 x/(2^n), (0 <= n <= 30)\n\n**样例：**\n\n    divpwr2(15,1) = 7, divpwr2(-33,4) = -2\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 15\n\n**使用操作数：** 7\n\n**代码：**\n```cpp\nint divpwr2(int x, int n) {\n    int sign = x >> 31;\n    int bias = (1 << n) + ~0;\n    x = x + (bias & sign);\n    return x >> n;\n}\n```\n\n**分析：**\n\n> 本题的难点在于Round toward zero, 我们知道除以2的n次方即为将x右移n位。对于正数，尾数截断，因而自然向0舍入。而对于负数则不是如此，经试验在gcc上对于负数，其是向偶数舍入的，因而我们要对负数进行操作。\n\n> 同时由于其向偶数舍入，我们不能简单地对负数进行+1操作，例如原本正确的 -7/4 = -1.25 = -1，但是经过+1操作后变为-6/4 = -1.5 Round toward even则变为了2。所以我们不应简单加一，而是加一个偏差值，其为2^n - 1，对于-7/4来说，就是3，加上bias之后得到(-7 + 3)/4即为-1。\n\n> 所以我们构造bias = (1 << n) + ~0 (由于不能用减号，-1用+~0表示)，然后我们要记得将sign取出，在x进行加操作时先检查一下x是否是负数，再进行操作。最后只要方向的将x右移n位即可。\n\n\n***\n\n### **9. negate--取负**\n\n**题目：**\n\n    返回-x\n\n**样例：**\n\n    negate(1) = -1.\n\n**可使用操作：**  ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 5\n\n**使用操作数：** 2\n\n**代码：**\n```cpp\nint negate(int x) {\n  return ~x + 1;\n}\n```\n\n**分析：**\n\n> 很简单，对于有符号二进制数取负就是取其补码，而补码等于其取反加一，返回取反加一即可。\n\n***\n\n### **10. isPositive--是正数**\n\n**题目：**\n\n    返回1如果x大于0，反之返回0\n\n**样例：**\n\n    isPositive(-1) = 0.\n\n**可使用操作：**  ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 8\n\n**使用操作数：** 5\n\n**代码：**\n```cpp\nint isPositive(int x) {\n  return !(x >> 31) & !!x;\n}\n```\n\n**分析：**\n> 这题关键在于把0剔除了，区分正负数就是区分其符号位，将x右移31位，负数得-1，正数为0，用一个逻辑非使正数为1，负数为0，然后再和!!x与一下就能剔除0\n\n* !!x 当 x == 0 时返回 0，不为 0 时返回 1\n\n***\n\n### **11. isLessOrEqual--小于等于**\n\n**题目：**\n\n    如果x小于等于y返回1，反之返回0\n\n**样例：**\n\n    isLessOrEqual(4,5) = 1.\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 24\n\n**使用操作数：** 14\n\n**代码：**\n```cpp\nint isLessOrEqual(int x, int y) {\n  int res = y + (~x + 1); // y - x\n  int xSign = x >> 31;\n  int ySign = y >> 31;\n  int dif = ~xSign + ySign;\n  return (~(dif + 1 >> 31) & !(res >> 31)) | !dif;\n}\n```\n\n**分析：**\n> 我在这里采取了作差的方法 res = y + (~x + 1)，即计算一下y-x，判断其是否非负，同时也要考虑溢出问题，即 x 为负数，y为正数，y-x后溢出为负。\n\n> 我将x,y右移31位代表其符号，若负则为-1，若正为0。我同时构造了一个 dif 以表示x,y符号之间的关系。\n\n> **dif = ~xSign + ySign**\n1.  当 x < 0 && y < 0 时，dif = -1 \n2.  当 x < 0 && y > 0 时，dif = 0 \n3.  当 x > 0 && y < 0 时，dif = -2 \n4.  当 x > 0 && y < 0 时，dif = -1\n\n> 将 x,y 符号之间的关系表达出来，把 dif 加一我们可以观察到当 x,y 同号时，dif为0，所以将其取反和 !(res >> 31) 相与，就可以表示同号不溢出的情况，而当 x < 0, y > 0 的情况发生时，我们注意到 dif 就是 0 ，所以我们直接或上 !dif 即可表达这种情况。\n\n***\n\n### **12. ilog2--以2为底的对数**\n\n**题目：**\n\n    返回x取以2为底的对数并向下取整，输入的 x > 0\n\n**样例：**\n\n    ilog2(16) = 4\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 90\n\n**使用操作数：** 48\n\n**代码：**\n\n```cpp\nint ilog2(int x) {\n  int tmp, l1, l2, l4, l8, l16;\n  x |= x >> 1;\n  x |= x >> 2;\n  x |= x >> 4;\n  x |= x >> 8;\n  x |= x >> 16;\n  \n  tmp = (0x55 << 8) + 0x55;\n  l1 = (tmp << 16) + tmp;\n  tmp = (0x33 << 8) + 0x33;\n  l2 = (tmp << 16) + tmp;\n  tmp = (0x0f << 8) + 0x0f;\n  l4 = (tmp << 16) + tmp;\n  l8 = (0xff << 16) + 0xff;\n  l16 = (0xff << 8) + 0xff;\n\n  x = (x & l1) + ((x >> 1) & l1);\n  x = (x & l2) + ((x >> 2) & l2);\n  x = (x & l4) + ((x >> 4) & l4);\n  x = (x & l8) + ((x >> 8) & l8);\n  x = (x & l16) + ((x >> 16) & l16);\n  return x + ~0;\n```\n\n**分析：**\n\n> 我们知道二进制数每位有其位权，所以对 x 取以2为底的对数就是指其为1的最高位的位权。为了获得最高位的位置，其实我们可以将其最高位往下全部变为1，再类似bitsCount数其中1的个数就行了。\n\n> 我把 x 移位相与，保证最高位往下所有数字为1，再使用bitsCount就得到答案。\n\n> 最后不要忘记减一\n\n\n***\n\n### **13. float_neg--浮点数的负数**\n\n**题目：**\n\n    返回-f，当NaN时，返回参数f\n\n**可使用操作：** 所有的整型操作，包括 ||, &&. 以及 if, while\n    \n**最大操作数限制：** 10\n\n**使用操作数：** 5\n\n**代码：**\n```cpp\nunsigned float_neg(unsigned uf) {\n  unsigned exp = uf & 0x7f800000;\n  unsigned frac = uf & 0x007fffff;\n  if(exp == 0x7f800000 && frac)\n    return uf;\n  return uf ^= 0x80000000;\n}\n```\n\n**分析：**\n* IEEE-float\n> 我们知道IEEE单精度浮点数，最高位为符号位，其后8位为阶码exp，后23位为尾数frac。其牺牲了精度来扩大了表达范围。\n\n> 而当 exp 全 1 时，如若frac非全零，则表示NaN。若全零，则表示无穷大/小。\n\n> 这里我们只要将原数和符号位0x80000000异或一下，即可取负。不要忘记排除NaN的情况。\n\n***\n\n### **14. float_i2f--int转float**\n\n**题目：**\n\n    把int类型的数转换为float表示(比特形式)\n\n**可使用操作：** 所有的整型操作，包括 ||, &&. 以及 if, while\n    \n**最大操作数限制：** 30\n\n**使用操作数：** 30\n\n**代码：**\n\n```cpp\nunsigned float_i2f(int x) {\n  unsigned frac, mask1, mask2, mask3, mask4, d;\n  int high = 0x80000000;\n  unsigned sign = x & 0x80000000;\n  unsigned exp = 127;\n  int count = 32, i;\n  if(sign)\n    x = ~x + 1;\n  else if(!x)\n    return x;\n  \n  frac = x;\n\n  for(;high; high >>= 1)\n  {\n    --count;\n    if(high & x)\n      break;\n  }\n  i = count - 23;\n  mask1 = ~(1 << count); // the highest 1\n  mask2 = 1 << i; //the lowest of remain frac;\n  mask3 = mask2 >> 1; // the highest of deserted bits \n  mask4 = mask2 - 1; // the deserted bits\n  exp += count;\n\n  frac &= mask1;\n  \n  if(i > 0)\n  {\n    d = frac & mask4; // deserted bits\n    if(d > mask3 | (d == mask3 && frac & mask2))\n    {\n      frac += mask2;\n      if(frac > 0x3fffffff)\n      {\n        frac = 0;\n        exp++;\n      }\n    }\n    frac >>= i;\n  }\n  else\n    frac <<= -i;\n\n  return sign | exp << 23 | frac;\n}\n```\n\n**分析：**\n\n> 我认为这题比较难，我做了很久很久....它难在浮点数向偶数舍入以及其操作数的限制。\n\n> 我们知道由于浮点数表示范围比整型大，我们可以将整型转换为浮点数，但是相应的会有一些精度的丢失，因为尾数frac只有23位，而int有31位可用。\n\n> 所以其关键在于int的位数，一开始先把该取出来的都用掩码取出来，把负数和零处理一下。之后我利用了一个循环先找出int的最高位在哪，利用count计数。\n\n> 后面我采取了四个掩码，分别代表最高位的1，留下的尾数中的最低位，要舍去的位数的最高位，以及舍弃的位数的掩码。利用这四个掩码我们可以达到存frac时，将其向**偶数舍入**。\n\n> 具体操作是，先取出丢弃的尾数，将其存放在d中，看其有没有超过0.5 (即 d 是否大于 mask3) 如果大于，直接frac++就行。而如果等于的话，还要看frac是否是奇数 (即frac & mask2是否为1) 如果是，则要向偶数舍入,frac++。\n\n> 加完frac之后还要注意**溢出问题**，如果溢出了，要将frac置0，然后把阶码 exp++，再按照之前输出来的尾数移动，将尾数对齐即可 （位数最高默认为1不存，因而把最高位隐去）。\n\n> 最后把符号位，阶码位和尾数位拼接，得到最后的结果。\n\n***\n\n### 15. float_twice--float * 2\n\n**题目：**\n\n    返回float * 2, 当参数是NaN时，返回参数\n\n**可使用操作：** 所有的整型操作，包括 ||, &&. 以及 if, while\n    \n**最大操作数限制：** 30\n\n**使用操作数：** 20\n\n**代码：**\n```cpp\nunsigned float_twice(unsigned uf) {\n  unsigned sign = uf & 0x80000000;\n  unsigned exp = uf & 0x7f800000;\n  unsigned frac = uf & 0x007fffff;\n  if(exp == 0x7f800000) //NaN & inf\n    return uf;\n  if(!exp && !frac) // 0\n    return uf;\n  if(!exp && frac <= 0x3fffff)  // low\n    frac *= 2;\n  else if(!exp && frac > 0x3fffff) // high\n  {\n    exp += 0x00800000;\n    frac = (frac * 2) & 0x7fffff;\n  }\n  else // normal\n    exp += 0x00800000;\n  return sign + exp + frac;\n}\n```\n\n**分析：**\n> 主要要分析的地方，在于当阶码exp为0时，是否在乘2之后进位。所以要考虑尾数是否大于0x3fffff，如果小于等于之，则直接尾数乘2就行，不会溢出，否则则exp要进位，同时尾数乘2之后要与上0x7fffff保证不溢出。\n\n> 其他正常情况直接exp++就行，注意一下特殊情况;\n\n*本题中测试集中有一个inf，也要直接返回参数uf*\n\n***\n\n## **Bits_honor.c**\n### **1. bitReverse--比特翻转**\n\n**题目：**\n\n    把32比特int的比特位翻转\n\n**样例：**\n\n    bitReverse(0x80000004) = 0x20000001\n    bitReverse(0x7FFFFFFF) = 0xFFFFFFFE\n    \n**最大操作数限制：** 40\n\n**使用操作数：** 40\n\n**代码：**\n```cpp\nint bitReverse(int x)\n{\n   int tmp,l1, l2, l4, l8, l16;\n\n   tmp = (0x55 << 8) + 0x55;\n   l1 = (tmp << 16) + tmp;\n   tmp = (0x33 << 8) + 0x33;\n   l2 = (tmp << 16) + tmp;\n   tmp = (0x0f << 8) + 0x0f;\n   l4 = (tmp << 16) + tmp;\n   l8 = (0xff << 16) + 0xff;\n   l16 = (0xff << 8) + 0xff;\n\n   x = ((x >> 16) & l16) | (x << 16);\n   x = ((x >> 8) & l8) | ((x & l8) << 8);\n   x = ((x >> 4) & l4) | ((x & l4) << 4);\n   x = ((x >> 2) & l2) | ((x & l2) << 2);\n   x = ((x >> 1) & l1) | ((x & l1) << 1);\n   return x;\n}\n```\n\n**分析：**\n\n> 这题和 bitsCount 有异曲同工之妙，也是一个分治法，将32位二进制数一分为二，交换，再将内部各自再一分为二，交换，直至最底层2位二进制数互换位置，最后完成了将所有位数翻转的工作。\n\n> 但值得注意的是，给出的是有符号的int，所以在右移交换位置时，会发生因为负数算术右移导致高位全是1的情况，致使在与的过程中高位全部变为1。这边只要将其移动后在和掩码相与就能解决这一问题。而对于低位，先与掩码相与再移动，可以省去取反得到高位掩码的操作数。再用tmp省一下操作数。\n\n> 最后操作数正好卡在40\n\n***\n\n### **2. mod3--取模3**\n\n**题目：**\n\n    计算 x 取模 3，而不用%\n\n**样例：**\n\n    mod3(100) = 1\n    mod3(-100) = -1\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 90\n\n**使用操作数：** 24\n\n**代码：**\n```cpp\nint mod3(int x)\n{\n   int mask = (0xff << 8) + 0xff;\n\n   x = (x >> 16) + (x & mask); // sum base 4^8 digits (a <= 0x1FFFE)\n   x = (x >> 8) + (x & 0xff); // sum base 4^4 digits (a <= 0x2FD)\n   x = (x >> 4) + (x & 0xf); // sum base 4^2 digits (a <= 0x3C)\n   x = (x >> 2) + (x & 0x3); // sum base 4^1 digits (a <= 0x1D)\n   x = (x >> 2) + (x & 0x3); // sum base 4^1 digits (a <= 0x9)\n   x = (x >> 2) + (x & 0x3); // sum base 4^1 digits (a <= 0x4)\n\n   x = (((x + 1) >> 2) + x) & 0x3;\n   return x;\n}\n```\n\n**分析：**\n\n> 这题难度算是比较大的，我参考了一些资料最后才写出这个代码。其实这题也与bitsCount有着一定的联系。\n\n> 对于解这题有一个根本的公式即 \n    \n    a % m = ((b % m)(a/b) + (a % b)) % m\n    其中b是进制数\n\n> 我们知道，如果想要知道一个十进制的数能否被三整除，只要看它所有数位之和是否能被三整除就行了。其实这就是上述公式的特殊情况，由于10 mod 3 == 1 所以其就退化为\n\n    a mod m = (a/b + a % b) % m\n    递归下来就是所有数位之和\n\n> 而对于二进制的情况，我们可以将进制位b选为4，这样正好是两位二进制数，同时4 % 3 == 1，这样一来，对于二进制数中我们只需要统计所有两两数位(四进制)的和能否被三整除就行了。\n\n> 而考虑到我们每做一次 a/b + a % b 统计数位和都减小了数的规模，这样只要做有限次就能够将数控制在<=3的范围内。\n\n> 对于a % 4，这是一个经典的trivial情况，我们只需要做 a & 3，就能够轻松得到a % 4的值。而对于a/4，只需要做a >> 2即可。\n\n> 对于二进制数我们不仅可以按两位两位的四进制数位和来数，也可以直接数其倍数(4^i)，从最大4^8开始统计，一步步减小x的值，最后将x做到<= 3的范围\n\n> 最后要判断x是否为3，如果为3的话则要置为0，我利用3数位全为1的特点，将其+1进位后，右移2位。如果为3，则得到的是1。将其再加上x，如若x是1或2，则还是不变，但如果是3，它又会进位到4，那么我们只要再与上0x3，则会得到0，即为想要的结果。\n\n\n***\n\n### **3. float_f2i--float转int**\n\n**题目：**\n\n    输入一个按二进制位储存的float（以unsigned表示），将其转为int输出。(NaN,inf，溢出直接返回参数)\n\n**可使用操作：** 所有的整型操作，包括 ||, &&. 以及 if, while\n    \n**最大操作数限制：** 30\n\n**使用操作数：** 17\n\n**代码：**\n```cpp\nint float_f2i(unsigned uf)\n{\n   int sign, exp, frac, res;\n   unsigned int tmp;\n\n   if(!uf)\n      return 0;\n   sign = uf & 0x80000000;\n   exp = uf & 0x7f800000;\n   frac = (uf & 0x007fffff) | 0x00800000;\n\n   if(exp == 0x7f800000) //NaN and inf\n      return 0x80000000u;\n\n   exp >>= 23;\n\n   if(exp < 127)\n      return 0;\n   else if(exp > 158)\n      return 0x80000000u;\n   else if(exp > 150)\n      tmp = frac << (exp - 150);\n   else\n      tmp = frac >> (150 - exp);\n\n      \n   if(sign)\n      res = ~tmp + 1;\n   else\n      res = tmp;\n   \n   return res | sign;\n}\n```\n\n**分析：**\n\n> 这题特殊情况比较多，把NaN和inf处理一下，然后注意一下溢出情况，即取出来的exp - bias > 31，肯定超过2^31整型储存的最大值，直接返回0x80000000u，然后对于exp小于127的，其指数是负数，直接返回int值为0。对于在exp - bias 在 0 到 31 之间的，由于frac只有23位，所以要将注意一下讨论23的情况。\n\n> 最后把取出来的符号位对一下，如果负数取反加一，正数直接等，最后再或上符号位，返回答案。\n\n---\n\n## **结果截图**\n### **bits.c**\n\n![bits_btest](/img/ICS_Lab1/bits_btest.JPG)\n\n![bits_dlc](/img/ICS_Lab1/bits_dlc.png)\n\n### **bits_honor.c**\n\n![bits_honor_btest](/img/ICS_Lab1/bits_honor_btest.JPG)\n\n![bits_honor_dlc](/img/ICS_Lab1/bits_honor_dlc.png)\n\n\n\n## 参考\n***\n<https://baike.baidu.com/item/%E7%AE%97%E6%9C%AF%E5%8F%B3%E7%A7%BB/3711081?fr=aladdin>\n<https://blog.csdn.net/jiahonghao2002/article/details/108223366>\n<https://leetcode-cn.com/problems/reverse-bits/solution/dian-dao-er-jin-zhi-wei-by-leetcode/>\n<http://homepage.cs.uiowa.edu/~jones/bcd/mod.shtml#exmod3>\n<https://www.zhihu.com/question/38206659/answer/763034261>\n<https://blog.csdn.net/xindaxinda123/article/details/95617758>\n<https://www.runoob.com/w3cnote/32-float-storage.html>","source":"_posts/ICS/ICS_Lab1.md","raw":"---\ntitle: ICS-Lab1 位运算\nindex_img: /img/ICS_Lab1/top.jpg\ndate: 2020-11-05 23:58:42\ncategory: [ICS]\ntags: [Bits]\n---\n\n# ICS_Lab1-位运算\n\n> 这个是CS:APP的第一个lab，也是我ICS课上的第一个lab，主要注重于使用受限制的位运算来完成操作\n\n***\n\n## **Bits.c**\n### **1. bitAnd--与**\n**题目：**\n\n    只用~和|实现&\n\n**样例：**\n\n    bitAnd(6, 5) = 4\n\n**可使用操作：** ~ |\n    \n**最大操作数限制：** 8\n\n**使用操作数：** 4\n\n```cpp\nint bitAnd(int x, int y) {\n  return ~(~x | ~y); //De Morgan's laws\n}\n```\n\n> 应用摩根律 ~(x | y) = ~x & ~y, 可得 x & y = ~(~x | ~y)\n\n***\n\n### **2. getByte--获取字节**\n**题目：**\n\n    从x中提取字节n, n编号从0至3\n\n**样例：**\n\n    getByte(0x12345678,1) = 0x56\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 6\n\n**使用操作数：** 3\n\n**代码：**\n```cpp\nint getByte(int x, int n) {\n  return (x >> (n << 3)) & 0xff;\n}\n```\n\n**分析：**\n\n*由于 1Byte = 8bits = 2^3bits， 所以 n Bytes = 2^3 * n bits*\n> 因而将n左移3位，即 n * 2^3, 再将x右移 n * 2^3 即可将所求字节放在低8位，将其与上0xff，即可取出字节。\n\n***\n\n### **3. logicalShift--逻辑右移**\n**题目：**\n\n    将x逻辑右移n位\n\n**样例：**\n\n    logicalShift(0x87654321,4) = 0x08765432\n\n**可使用操作：**  ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 20\n\n**使用操作数：** 10\n\n**代码：**\n```cpp\nint logicalShift(int x, int n) {\n  //flag equals to: if n == 0 return 0; else return 1;\n  int flag = !!n;\n  int mask = ~(flag << (32 + (~n + 1)));\n  return (x >> n) & mask;\n}\n```\n\n**分析：**\n\n* 算数右移\n> 算数右移即在右移后用原符号位数将高位补齐，保持右移后二进制数的符号保持不变。\n\n* 逻辑右移\n> 逻辑右移即在右移后用 0 将高位补齐，是“逻辑上”的右移。\n\n> 在正常右移运算中使用的是算数右移，因而要解决的问题即对于负数如何将最高位补上0，而非符号位1。\n> 我采取掩码的方式，先将x正常右移n位与上其高位的掩码，使其右移产生的高位变为0\n\n* 掩码构造\n> 掩码不能草率的构造为 ~(-1 << (32 - n)), 这种构造方式当n为0时会因-1被左移32位而导致异常，构造出来的mask仍为0\n\n> 由于不能使用if，为判断n是否为0，我才用了一个flag = !n + ~0, 其有很好的性质。当n为0时，flag也为0，而当n不为零时，flag统一为-1，这样使用flag代替原先的-1, 从而避免上述情况。\n\n> 这样我们可以使用 mask = ~(flag << (32 + (~n + 1)))，来构造掩码，当n为0时，flag为0，从而mask = -1，避免上述错误。\n\n***\n\n### **4. bitCount--比特计数**\n**题目：**\n\n    返回二进制数中1的个数\n\n**样例：**\n\n    bitCount(5) = 2, bitCount(7) = 3\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 40\n\n**使用操作数：** 36\n\n**代码：**\n```cpp\nint bitCount(int x) {\n  int tmp, l1, l2, l4, l8, l16; //tmp is used to save ops\n  tmp = (0x55 << 8) + 0x55;\n  l1 = (tmp << 16) + tmp; //0x55555555\n  tmp = (0x33 << 8) + 0x33;\n  l2 = (tmp << 16) + tmp; //0x33333333\n  tmp = (0x0f << 8) + 0x0f;\n  l4 = (tmp << 16) + tmp; //0x0f0f0f0f\n  l8 = (0xff << 16) + 0xff; //0x00ff00ff\n  l16 = (0xff << 8) + 0xff; //0x0000ffff\n\n  x = (x & l1) + ((x >> 1) & l1);\n  x = (x & l2) + ((x >> 2) & l2);\n  x = (x & l4) + ((x >> 4) & l4);\n  x = (x & l8) + ((x >> 8) & l8);\n  x = (x & l16) + ((x >> 16) & l16);\n  return x;\n}\n```\n\n**分析：**\n\n* 分治思想\n> 本题使用了一个简单的分治思想，对于一个二进制数，要对其中为1的位做计数， 对于1位二进制数来说，1的个数无非就是其本身所表示的1或0。利用这个特性，我们可以先将一个二进制数每一位独立分开为相间隔的两部分, 其每位表示的就是自身的二进制个数，再将两串二进制数对其相加，所得到的每两位分隔的二进制数就是表达这个位置的位为1的个数。\n\n> 进一步相加为4位，8位其所代表的含义不变，最后合并至32位二进制数，其所表示的就是原二进制数中所含1的个数。\n\n```cpp\n//以八位二进制数 10101110 为例//\n按 1|0|1|0|1|1|1|0 分割， 为两串1|1|1|1和0|0|1|0，再将其合并，成为 01 | 01 | 10 | 01, 再将两串 01 | 10 和01 | 01合并得 0010 | 0011（这个很容易看出表示左四位有2个1，右四位有3个1），再次合并得 00000101, 得到总共有5个1。\n\n//对于32位二进制数亦按此继续操作即可//\n```\n\n> 于是为完成分割取位的操作，我们需要采用掩码\n\n* 0x55555555 \\ 0x33333333 \\ 0x0f0f0f0f \\ 0x0000ffff\n\n> 利用位运算分别构造，使用tmp可以节约ops, 之后按照分治思想进行操作即可。\n\n***\n\n### **5. bang--逻辑非**\n\n**题目：**\n\n    计算 !x 而不使用逻辑非!\n\n**样例：**\n\n    bang(3) = 0, bang(0) = 1\n\n**可使用操作：** ~ & ^ | + << >>\n    \n**最大操作数限制：** 12\n\n**使用操作数：** 6\n\n**代码：**\n```cpp\nint bang(int x) {\n  return ((x >> 31) | ((~x + 1) >> 31)) + 1;\n}\n```\n\n**分析：**\n\n* 逻辑非\n> 对于逻辑非运算，应该都很熟悉，!x 当且仅当x为0时其为1，其余时候都为0，可以用来区分零和非零数。\n\n> 该问题的关键就是在于如何区分零和非零数，我们知道零的二补码仍然是零，而对于其余非零数，其符号位会有相应改变，利用这一性质，我们可以对零和非零数做出区分。\n\n> 使用 ```((x >> 31) | ((~x + 1) >> 31))```，将二进制数x的符号位与其补码左移31位相与，如若是非零数，其中符号位至少有一个为1，所以经过31位的算数右移后，其中一项必为-1，一项为0，相与之后得到-1,。而对于0来说，结果始终为0。\n\n> 最后只要将结果+1，就能得到逻辑非的效果。\n\n***\n\n### **6. tmin--最小数**\n\n**题目：**\n\n    返回二补码中最小的数\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 4\n\n**使用操作数：** 1\n\n**代码：**\n```cpp\nint tmin(void) {\n  return 1 << 31;\n}\n```\n\n**分析：**\n\n> 此题非常简单，我们知道计算机中负数是用其补码表示的，int所能表示的最小数为0x80000000(-2^31), 即符号位为1，其余皆为0，所以只要将1左移31位即可。\n\n***\n\n### **7. fitsBits--填充比特**\n\n**题目：**\n\n    返回1如果x可以表示为n位二补码，反之返回0 (1 <= n <= 32)\n\n**样例：**\n\n    fitsBits(5,3) = 0, fitsBits(-4,3) = 1\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 15\n\n**使用操作数：** 7\n\n**代码：**\n```cpp\nint fitsBits(int x, int n) {\n  int k = x >> (n + ~0); // if can k = 0 or -1\n  return !k | !(k + 1);\n}\n```\n\n**分析：**\n\n> 我们知道如若一个数能够被n位二进制数表示，则其第n位即最高位是符号位，那么将其右移n-1位后，根据算术右移，其得到的结果不是0，就是1。否则表示，其还有高于n位的位数， 即不能用n位表示。\n\n> 所以用 k = x >> (n + ~0) 表示将其右移n-1位，再用 !k | !(k + 1) 判断k是否为0或-1\n\n***\n\n### **8. divpwr2--除以2的n次方**\n\n**题目：**\n\n    计算 x/(2^n), (0 <= n <= 30)\n\n**样例：**\n\n    divpwr2(15,1) = 7, divpwr2(-33,4) = -2\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 15\n\n**使用操作数：** 7\n\n**代码：**\n```cpp\nint divpwr2(int x, int n) {\n    int sign = x >> 31;\n    int bias = (1 << n) + ~0;\n    x = x + (bias & sign);\n    return x >> n;\n}\n```\n\n**分析：**\n\n> 本题的难点在于Round toward zero, 我们知道除以2的n次方即为将x右移n位。对于正数，尾数截断，因而自然向0舍入。而对于负数则不是如此，经试验在gcc上对于负数，其是向偶数舍入的，因而我们要对负数进行操作。\n\n> 同时由于其向偶数舍入，我们不能简单地对负数进行+1操作，例如原本正确的 -7/4 = -1.25 = -1，但是经过+1操作后变为-6/4 = -1.5 Round toward even则变为了2。所以我们不应简单加一，而是加一个偏差值，其为2^n - 1，对于-7/4来说，就是3，加上bias之后得到(-7 + 3)/4即为-1。\n\n> 所以我们构造bias = (1 << n) + ~0 (由于不能用减号，-1用+~0表示)，然后我们要记得将sign取出，在x进行加操作时先检查一下x是否是负数，再进行操作。最后只要方向的将x右移n位即可。\n\n\n***\n\n### **9. negate--取负**\n\n**题目：**\n\n    返回-x\n\n**样例：**\n\n    negate(1) = -1.\n\n**可使用操作：**  ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 5\n\n**使用操作数：** 2\n\n**代码：**\n```cpp\nint negate(int x) {\n  return ~x + 1;\n}\n```\n\n**分析：**\n\n> 很简单，对于有符号二进制数取负就是取其补码，而补码等于其取反加一，返回取反加一即可。\n\n***\n\n### **10. isPositive--是正数**\n\n**题目：**\n\n    返回1如果x大于0，反之返回0\n\n**样例：**\n\n    isPositive(-1) = 0.\n\n**可使用操作：**  ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 8\n\n**使用操作数：** 5\n\n**代码：**\n```cpp\nint isPositive(int x) {\n  return !(x >> 31) & !!x;\n}\n```\n\n**分析：**\n> 这题关键在于把0剔除了，区分正负数就是区分其符号位，将x右移31位，负数得-1，正数为0，用一个逻辑非使正数为1，负数为0，然后再和!!x与一下就能剔除0\n\n* !!x 当 x == 0 时返回 0，不为 0 时返回 1\n\n***\n\n### **11. isLessOrEqual--小于等于**\n\n**题目：**\n\n    如果x小于等于y返回1，反之返回0\n\n**样例：**\n\n    isLessOrEqual(4,5) = 1.\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 24\n\n**使用操作数：** 14\n\n**代码：**\n```cpp\nint isLessOrEqual(int x, int y) {\n  int res = y + (~x + 1); // y - x\n  int xSign = x >> 31;\n  int ySign = y >> 31;\n  int dif = ~xSign + ySign;\n  return (~(dif + 1 >> 31) & !(res >> 31)) | !dif;\n}\n```\n\n**分析：**\n> 我在这里采取了作差的方法 res = y + (~x + 1)，即计算一下y-x，判断其是否非负，同时也要考虑溢出问题，即 x 为负数，y为正数，y-x后溢出为负。\n\n> 我将x,y右移31位代表其符号，若负则为-1，若正为0。我同时构造了一个 dif 以表示x,y符号之间的关系。\n\n> **dif = ~xSign + ySign**\n1.  当 x < 0 && y < 0 时，dif = -1 \n2.  当 x < 0 && y > 0 时，dif = 0 \n3.  当 x > 0 && y < 0 时，dif = -2 \n4.  当 x > 0 && y < 0 时，dif = -1\n\n> 将 x,y 符号之间的关系表达出来，把 dif 加一我们可以观察到当 x,y 同号时，dif为0，所以将其取反和 !(res >> 31) 相与，就可以表示同号不溢出的情况，而当 x < 0, y > 0 的情况发生时，我们注意到 dif 就是 0 ，所以我们直接或上 !dif 即可表达这种情况。\n\n***\n\n### **12. ilog2--以2为底的对数**\n\n**题目：**\n\n    返回x取以2为底的对数并向下取整，输入的 x > 0\n\n**样例：**\n\n    ilog2(16) = 4\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 90\n\n**使用操作数：** 48\n\n**代码：**\n\n```cpp\nint ilog2(int x) {\n  int tmp, l1, l2, l4, l8, l16;\n  x |= x >> 1;\n  x |= x >> 2;\n  x |= x >> 4;\n  x |= x >> 8;\n  x |= x >> 16;\n  \n  tmp = (0x55 << 8) + 0x55;\n  l1 = (tmp << 16) + tmp;\n  tmp = (0x33 << 8) + 0x33;\n  l2 = (tmp << 16) + tmp;\n  tmp = (0x0f << 8) + 0x0f;\n  l4 = (tmp << 16) + tmp;\n  l8 = (0xff << 16) + 0xff;\n  l16 = (0xff << 8) + 0xff;\n\n  x = (x & l1) + ((x >> 1) & l1);\n  x = (x & l2) + ((x >> 2) & l2);\n  x = (x & l4) + ((x >> 4) & l4);\n  x = (x & l8) + ((x >> 8) & l8);\n  x = (x & l16) + ((x >> 16) & l16);\n  return x + ~0;\n```\n\n**分析：**\n\n> 我们知道二进制数每位有其位权，所以对 x 取以2为底的对数就是指其为1的最高位的位权。为了获得最高位的位置，其实我们可以将其最高位往下全部变为1，再类似bitsCount数其中1的个数就行了。\n\n> 我把 x 移位相与，保证最高位往下所有数字为1，再使用bitsCount就得到答案。\n\n> 最后不要忘记减一\n\n\n***\n\n### **13. float_neg--浮点数的负数**\n\n**题目：**\n\n    返回-f，当NaN时，返回参数f\n\n**可使用操作：** 所有的整型操作，包括 ||, &&. 以及 if, while\n    \n**最大操作数限制：** 10\n\n**使用操作数：** 5\n\n**代码：**\n```cpp\nunsigned float_neg(unsigned uf) {\n  unsigned exp = uf & 0x7f800000;\n  unsigned frac = uf & 0x007fffff;\n  if(exp == 0x7f800000 && frac)\n    return uf;\n  return uf ^= 0x80000000;\n}\n```\n\n**分析：**\n* IEEE-float\n> 我们知道IEEE单精度浮点数，最高位为符号位，其后8位为阶码exp，后23位为尾数frac。其牺牲了精度来扩大了表达范围。\n\n> 而当 exp 全 1 时，如若frac非全零，则表示NaN。若全零，则表示无穷大/小。\n\n> 这里我们只要将原数和符号位0x80000000异或一下，即可取负。不要忘记排除NaN的情况。\n\n***\n\n### **14. float_i2f--int转float**\n\n**题目：**\n\n    把int类型的数转换为float表示(比特形式)\n\n**可使用操作：** 所有的整型操作，包括 ||, &&. 以及 if, while\n    \n**最大操作数限制：** 30\n\n**使用操作数：** 30\n\n**代码：**\n\n```cpp\nunsigned float_i2f(int x) {\n  unsigned frac, mask1, mask2, mask3, mask4, d;\n  int high = 0x80000000;\n  unsigned sign = x & 0x80000000;\n  unsigned exp = 127;\n  int count = 32, i;\n  if(sign)\n    x = ~x + 1;\n  else if(!x)\n    return x;\n  \n  frac = x;\n\n  for(;high; high >>= 1)\n  {\n    --count;\n    if(high & x)\n      break;\n  }\n  i = count - 23;\n  mask1 = ~(1 << count); // the highest 1\n  mask2 = 1 << i; //the lowest of remain frac;\n  mask3 = mask2 >> 1; // the highest of deserted bits \n  mask4 = mask2 - 1; // the deserted bits\n  exp += count;\n\n  frac &= mask1;\n  \n  if(i > 0)\n  {\n    d = frac & mask4; // deserted bits\n    if(d > mask3 | (d == mask3 && frac & mask2))\n    {\n      frac += mask2;\n      if(frac > 0x3fffffff)\n      {\n        frac = 0;\n        exp++;\n      }\n    }\n    frac >>= i;\n  }\n  else\n    frac <<= -i;\n\n  return sign | exp << 23 | frac;\n}\n```\n\n**分析：**\n\n> 我认为这题比较难，我做了很久很久....它难在浮点数向偶数舍入以及其操作数的限制。\n\n> 我们知道由于浮点数表示范围比整型大，我们可以将整型转换为浮点数，但是相应的会有一些精度的丢失，因为尾数frac只有23位，而int有31位可用。\n\n> 所以其关键在于int的位数，一开始先把该取出来的都用掩码取出来，把负数和零处理一下。之后我利用了一个循环先找出int的最高位在哪，利用count计数。\n\n> 后面我采取了四个掩码，分别代表最高位的1，留下的尾数中的最低位，要舍去的位数的最高位，以及舍弃的位数的掩码。利用这四个掩码我们可以达到存frac时，将其向**偶数舍入**。\n\n> 具体操作是，先取出丢弃的尾数，将其存放在d中，看其有没有超过0.5 (即 d 是否大于 mask3) 如果大于，直接frac++就行。而如果等于的话，还要看frac是否是奇数 (即frac & mask2是否为1) 如果是，则要向偶数舍入,frac++。\n\n> 加完frac之后还要注意**溢出问题**，如果溢出了，要将frac置0，然后把阶码 exp++，再按照之前输出来的尾数移动，将尾数对齐即可 （位数最高默认为1不存，因而把最高位隐去）。\n\n> 最后把符号位，阶码位和尾数位拼接，得到最后的结果。\n\n***\n\n### 15. float_twice--float * 2\n\n**题目：**\n\n    返回float * 2, 当参数是NaN时，返回参数\n\n**可使用操作：** 所有的整型操作，包括 ||, &&. 以及 if, while\n    \n**最大操作数限制：** 30\n\n**使用操作数：** 20\n\n**代码：**\n```cpp\nunsigned float_twice(unsigned uf) {\n  unsigned sign = uf & 0x80000000;\n  unsigned exp = uf & 0x7f800000;\n  unsigned frac = uf & 0x007fffff;\n  if(exp == 0x7f800000) //NaN & inf\n    return uf;\n  if(!exp && !frac) // 0\n    return uf;\n  if(!exp && frac <= 0x3fffff)  // low\n    frac *= 2;\n  else if(!exp && frac > 0x3fffff) // high\n  {\n    exp += 0x00800000;\n    frac = (frac * 2) & 0x7fffff;\n  }\n  else // normal\n    exp += 0x00800000;\n  return sign + exp + frac;\n}\n```\n\n**分析：**\n> 主要要分析的地方，在于当阶码exp为0时，是否在乘2之后进位。所以要考虑尾数是否大于0x3fffff，如果小于等于之，则直接尾数乘2就行，不会溢出，否则则exp要进位，同时尾数乘2之后要与上0x7fffff保证不溢出。\n\n> 其他正常情况直接exp++就行，注意一下特殊情况;\n\n*本题中测试集中有一个inf，也要直接返回参数uf*\n\n***\n\n## **Bits_honor.c**\n### **1. bitReverse--比特翻转**\n\n**题目：**\n\n    把32比特int的比特位翻转\n\n**样例：**\n\n    bitReverse(0x80000004) = 0x20000001\n    bitReverse(0x7FFFFFFF) = 0xFFFFFFFE\n    \n**最大操作数限制：** 40\n\n**使用操作数：** 40\n\n**代码：**\n```cpp\nint bitReverse(int x)\n{\n   int tmp,l1, l2, l4, l8, l16;\n\n   tmp = (0x55 << 8) + 0x55;\n   l1 = (tmp << 16) + tmp;\n   tmp = (0x33 << 8) + 0x33;\n   l2 = (tmp << 16) + tmp;\n   tmp = (0x0f << 8) + 0x0f;\n   l4 = (tmp << 16) + tmp;\n   l8 = (0xff << 16) + 0xff;\n   l16 = (0xff << 8) + 0xff;\n\n   x = ((x >> 16) & l16) | (x << 16);\n   x = ((x >> 8) & l8) | ((x & l8) << 8);\n   x = ((x >> 4) & l4) | ((x & l4) << 4);\n   x = ((x >> 2) & l2) | ((x & l2) << 2);\n   x = ((x >> 1) & l1) | ((x & l1) << 1);\n   return x;\n}\n```\n\n**分析：**\n\n> 这题和 bitsCount 有异曲同工之妙，也是一个分治法，将32位二进制数一分为二，交换，再将内部各自再一分为二，交换，直至最底层2位二进制数互换位置，最后完成了将所有位数翻转的工作。\n\n> 但值得注意的是，给出的是有符号的int，所以在右移交换位置时，会发生因为负数算术右移导致高位全是1的情况，致使在与的过程中高位全部变为1。这边只要将其移动后在和掩码相与就能解决这一问题。而对于低位，先与掩码相与再移动，可以省去取反得到高位掩码的操作数。再用tmp省一下操作数。\n\n> 最后操作数正好卡在40\n\n***\n\n### **2. mod3--取模3**\n\n**题目：**\n\n    计算 x 取模 3，而不用%\n\n**样例：**\n\n    mod3(100) = 1\n    mod3(-100) = -1\n\n**可使用操作：** ! ~ & ^ | + << >>\n    \n**最大操作数限制：** 90\n\n**使用操作数：** 24\n\n**代码：**\n```cpp\nint mod3(int x)\n{\n   int mask = (0xff << 8) + 0xff;\n\n   x = (x >> 16) + (x & mask); // sum base 4^8 digits (a <= 0x1FFFE)\n   x = (x >> 8) + (x & 0xff); // sum base 4^4 digits (a <= 0x2FD)\n   x = (x >> 4) + (x & 0xf); // sum base 4^2 digits (a <= 0x3C)\n   x = (x >> 2) + (x & 0x3); // sum base 4^1 digits (a <= 0x1D)\n   x = (x >> 2) + (x & 0x3); // sum base 4^1 digits (a <= 0x9)\n   x = (x >> 2) + (x & 0x3); // sum base 4^1 digits (a <= 0x4)\n\n   x = (((x + 1) >> 2) + x) & 0x3;\n   return x;\n}\n```\n\n**分析：**\n\n> 这题难度算是比较大的，我参考了一些资料最后才写出这个代码。其实这题也与bitsCount有着一定的联系。\n\n> 对于解这题有一个根本的公式即 \n    \n    a % m = ((b % m)(a/b) + (a % b)) % m\n    其中b是进制数\n\n> 我们知道，如果想要知道一个十进制的数能否被三整除，只要看它所有数位之和是否能被三整除就行了。其实这就是上述公式的特殊情况，由于10 mod 3 == 1 所以其就退化为\n\n    a mod m = (a/b + a % b) % m\n    递归下来就是所有数位之和\n\n> 而对于二进制的情况，我们可以将进制位b选为4，这样正好是两位二进制数，同时4 % 3 == 1，这样一来，对于二进制数中我们只需要统计所有两两数位(四进制)的和能否被三整除就行了。\n\n> 而考虑到我们每做一次 a/b + a % b 统计数位和都减小了数的规模，这样只要做有限次就能够将数控制在<=3的范围内。\n\n> 对于a % 4，这是一个经典的trivial情况，我们只需要做 a & 3，就能够轻松得到a % 4的值。而对于a/4，只需要做a >> 2即可。\n\n> 对于二进制数我们不仅可以按两位两位的四进制数位和来数，也可以直接数其倍数(4^i)，从最大4^8开始统计，一步步减小x的值，最后将x做到<= 3的范围\n\n> 最后要判断x是否为3，如果为3的话则要置为0，我利用3数位全为1的特点，将其+1进位后，右移2位。如果为3，则得到的是1。将其再加上x，如若x是1或2，则还是不变，但如果是3，它又会进位到4，那么我们只要再与上0x3，则会得到0，即为想要的结果。\n\n\n***\n\n### **3. float_f2i--float转int**\n\n**题目：**\n\n    输入一个按二进制位储存的float（以unsigned表示），将其转为int输出。(NaN,inf，溢出直接返回参数)\n\n**可使用操作：** 所有的整型操作，包括 ||, &&. 以及 if, while\n    \n**最大操作数限制：** 30\n\n**使用操作数：** 17\n\n**代码：**\n```cpp\nint float_f2i(unsigned uf)\n{\n   int sign, exp, frac, res;\n   unsigned int tmp;\n\n   if(!uf)\n      return 0;\n   sign = uf & 0x80000000;\n   exp = uf & 0x7f800000;\n   frac = (uf & 0x007fffff) | 0x00800000;\n\n   if(exp == 0x7f800000) //NaN and inf\n      return 0x80000000u;\n\n   exp >>= 23;\n\n   if(exp < 127)\n      return 0;\n   else if(exp > 158)\n      return 0x80000000u;\n   else if(exp > 150)\n      tmp = frac << (exp - 150);\n   else\n      tmp = frac >> (150 - exp);\n\n      \n   if(sign)\n      res = ~tmp + 1;\n   else\n      res = tmp;\n   \n   return res | sign;\n}\n```\n\n**分析：**\n\n> 这题特殊情况比较多，把NaN和inf处理一下，然后注意一下溢出情况，即取出来的exp - bias > 31，肯定超过2^31整型储存的最大值，直接返回0x80000000u，然后对于exp小于127的，其指数是负数，直接返回int值为0。对于在exp - bias 在 0 到 31 之间的，由于frac只有23位，所以要将注意一下讨论23的情况。\n\n> 最后把取出来的符号位对一下，如果负数取反加一，正数直接等，最后再或上符号位，返回答案。\n\n---\n\n## **结果截图**\n### **bits.c**\n\n![bits_btest](/img/ICS_Lab1/bits_btest.JPG)\n\n![bits_dlc](/img/ICS_Lab1/bits_dlc.png)\n\n### **bits_honor.c**\n\n![bits_honor_btest](/img/ICS_Lab1/bits_honor_btest.JPG)\n\n![bits_honor_dlc](/img/ICS_Lab1/bits_honor_dlc.png)\n\n\n\n## 参考\n***\n<https://baike.baidu.com/item/%E7%AE%97%E6%9C%AF%E5%8F%B3%E7%A7%BB/3711081?fr=aladdin>\n<https://blog.csdn.net/jiahonghao2002/article/details/108223366>\n<https://leetcode-cn.com/problems/reverse-bits/solution/dian-dao-er-jin-zhi-wei-by-leetcode/>\n<http://homepage.cs.uiowa.edu/~jones/bcd/mod.shtml#exmod3>\n<https://www.zhihu.com/question/38206659/answer/763034261>\n<https://blog.csdn.net/xindaxinda123/article/details/95617758>\n<https://www.runoob.com/w3cnote/32-float-storage.html>","slug":"ICS/ICS_Lab1","published":1,"updated":"2020-12-09T01:23:20.899Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmlxty4i0036s8pd7qq1368u","content":"<h1 id=\"ICS-Lab1-位运算\"><a href=\"#ICS-Lab1-位运算\" class=\"headerlink\" title=\"ICS_Lab1-位运算\"></a>ICS_Lab1-位运算</h1><blockquote>\n<p>这个是CS:APP的第一个lab，也是我ICS课上的第一个lab，主要注重于使用受限制的位运算来完成操作</p>\n</blockquote>\n<hr>\n<h2 id=\"Bits-c\"><a href=\"#Bits-c\" class=\"headerlink\" title=\"Bits.c\"></a><strong>Bits.c</strong></h2><h3 id=\"1-bitAnd—与\"><a href=\"#1-bitAnd—与\" class=\"headerlink\" title=\"1. bitAnd—与\"></a><strong>1. bitAnd—与</strong></h3><p><strong>题目：</strong></p>\n<pre><code>只用~和|实现&amp;\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>bitAnd(6, 5) = 4\n</code></pre><p><strong>可使用操作：</strong> ~ |</p>\n<p><strong>最大操作数限制：</strong> 8</p>\n<p><strong>使用操作数：</strong> 4</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">bitAnd</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> y)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> ~(~x | ~y); <span class=\"hljs-comment\">//De Morgan&#x27;s laws</span>\n&#125;</code></pre>\n<blockquote>\n<p>应用摩根律 ~(x | y) = ~x &amp; ~y, 可得 x &amp; y = ~(~x | ~y)</p>\n</blockquote>\n<hr>\n<h3 id=\"2-getByte—获取字节\"><a href=\"#2-getByte—获取字节\" class=\"headerlink\" title=\"2. getByte—获取字节\"></a><strong>2. getByte—获取字节</strong></h3><p><strong>题目：</strong></p>\n<pre><code>从x中提取字节n, n编号从0至3\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>getByte(0x12345678,1) = 0x56\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 6</p>\n<p><strong>使用操作数：</strong> 3</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">getByte</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> (x &gt;&gt; (n &lt;&lt; <span class=\"hljs-number\">3</span>)) &amp; <span class=\"hljs-number\">0xff</span>;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<p><em>由于 1Byte = 8bits = 2^3bits， 所以 n Bytes = 2^3 </em> n bits*</p>\n<blockquote>\n<p>因而将n左移3位，即 n <em> 2^3, 再将x右移 n </em> 2^3 即可将所求字节放在低8位，将其与上0xff，即可取出字节。</p>\n</blockquote>\n<hr>\n<h3 id=\"3-logicalShift—逻辑右移\"><a href=\"#3-logicalShift—逻辑右移\" class=\"headerlink\" title=\"3. logicalShift—逻辑右移\"></a><strong>3. logicalShift—逻辑右移</strong></h3><p><strong>题目：</strong></p>\n<pre><code>将x逻辑右移n位\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>logicalShift(0x87654321,4) = 0x08765432\n</code></pre><p><strong>可使用操作：</strong>  ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 20</p>\n<p><strong>使用操作数：</strong> 10</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">logicalShift</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;\n  <span class=\"hljs-comment\">//flag equals to: if n == 0 return 0; else return 1;</span>\n  <span class=\"hljs-keyword\">int</span> flag = !!n;\n  <span class=\"hljs-keyword\">int</span> mask = ~(flag &lt;&lt; (<span class=\"hljs-number\">32</span> + (~n + <span class=\"hljs-number\">1</span>)));\n  <span class=\"hljs-keyword\">return</span> (x &gt;&gt; n) &amp; mask;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<ul>\n<li><p>算数右移</p>\n<blockquote>\n<p>算数右移即在右移后用原符号位数将高位补齐，保持右移后二进制数的符号保持不变。</p>\n</blockquote>\n</li>\n<li><p>逻辑右移</p>\n<blockquote>\n<p>逻辑右移即在右移后用 0 将高位补齐，是“逻辑上”的右移。</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>在正常右移运算中使用的是算数右移，因而要解决的问题即对于负数如何将最高位补上0，而非符号位1。<br>我采取掩码的方式，先将x正常右移n位与上其高位的掩码，使其右移产生的高位变为0</p>\n</blockquote>\n<ul>\n<li>掩码构造<blockquote>\n<p>掩码不能草率的构造为 ~(-1 &lt;&lt; (32 - n)), 这种构造方式当n为0时会因-1被左移32位而导致异常，构造出来的mask仍为0</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>由于不能使用if，为判断n是否为0，我才用了一个flag = !n + ~0, 其有很好的性质。当n为0时，flag也为0，而当n不为零时，flag统一为-1，这样使用flag代替原先的-1, 从而避免上述情况。</p>\n<p>这样我们可以使用 mask = ~(flag &lt;&lt; (32 + (~n + 1)))，来构造掩码，当n为0时，flag为0，从而mask = -1，避免上述错误。</p>\n</blockquote>\n<hr>\n<h3 id=\"4-bitCount—比特计数\"><a href=\"#4-bitCount—比特计数\" class=\"headerlink\" title=\"4. bitCount—比特计数\"></a><strong>4. bitCount—比特计数</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回二进制数中1的个数\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>bitCount(5) = 2, bitCount(7) = 3\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 40</p>\n<p><strong>使用操作数：</strong> 36</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">bitCount</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">int</span> tmp, l1, l2, l4, l8, l16; <span class=\"hljs-comment\">//tmp is used to save ops</span>\n  tmp = (<span class=\"hljs-number\">0x55</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x55</span>;\n  l1 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp; <span class=\"hljs-comment\">//0x55555555</span>\n  tmp = (<span class=\"hljs-number\">0x33</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x33</span>;\n  l2 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp; <span class=\"hljs-comment\">//0x33333333</span>\n  tmp = (<span class=\"hljs-number\">0x0f</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x0f</span>;\n  l4 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp; <span class=\"hljs-comment\">//0x0f0f0f0f</span>\n  l8 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">16</span>) + <span class=\"hljs-number\">0xff</span>; <span class=\"hljs-comment\">//0x00ff00ff</span>\n  l16 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0xff</span>; <span class=\"hljs-comment\">//0x0000ffff</span>\n\n  x = (x &amp; l1) + ((x &gt;&gt; <span class=\"hljs-number\">1</span>) &amp; l1);\n  x = (x &amp; l2) + ((x &gt;&gt; <span class=\"hljs-number\">2</span>) &amp; l2);\n  x = (x &amp; l4) + ((x &gt;&gt; <span class=\"hljs-number\">4</span>) &amp; l4);\n  x = (x &amp; l8) + ((x &gt;&gt; <span class=\"hljs-number\">8</span>) &amp; l8);\n  x = (x &amp; l16) + ((x &gt;&gt; <span class=\"hljs-number\">16</span>) &amp; l16);\n  <span class=\"hljs-keyword\">return</span> x;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<ul>\n<li>分治思想<blockquote>\n<p>本题使用了一个简单的分治思想，对于一个二进制数，要对其中为1的位做计数， 对于1位二进制数来说，1的个数无非就是其本身所表示的1或0。利用这个特性，我们可以先将一个二进制数每一位独立分开为相间隔的两部分, 其每位表示的就是自身的二进制个数，再将两串二进制数对其相加，所得到的每两位分隔的二进制数就是表达这个位置的位为1的个数。</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>进一步相加为4位，8位其所代表的含义不变，最后合并至32位二进制数，其所表示的就是原二进制数中所含1的个数。</p>\n</blockquote>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">//以八位二进制数 10101110 为例//</span>\n按 <span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">0</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">0</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">0</span> 分割， 为两串<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">1</span>和<span class=\"hljs-number\">0</span>|<span class=\"hljs-number\">0</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">0</span>，再将其合并，成为 <span class=\"hljs-number\">01</span> | <span class=\"hljs-number\">01</span> | <span class=\"hljs-number\">10</span> | <span class=\"hljs-number\">01</span>, 再将两串 <span class=\"hljs-number\">01</span> | <span class=\"hljs-number\">10</span> 和<span class=\"hljs-number\">01</span> | <span class=\"hljs-number\">01</span>合并得 <span class=\"hljs-number\">0010</span> | <span class=\"hljs-number\">0011</span>（这个很容易看出表示左四位有<span class=\"hljs-number\">2</span>个<span class=\"hljs-number\">1</span>，右四位有<span class=\"hljs-number\">3</span>个<span class=\"hljs-number\">1</span>），再次合并得 <span class=\"hljs-number\">00000101</span>, 得到总共有<span class=\"hljs-number\">5</span>个<span class=\"hljs-number\">1</span>。\n\n<span class=\"hljs-comment\">//对于32位二进制数亦按此继续操作即可//</span></code></pre>\n<blockquote>\n<p>于是为完成分割取位的操作，我们需要采用掩码</p>\n</blockquote>\n<ul>\n<li>0x55555555 \\ 0x33333333 \\ 0x0f0f0f0f \\ 0x0000ffff</li>\n</ul>\n<blockquote>\n<p>利用位运算分别构造，使用tmp可以节约ops, 之后按照分治思想进行操作即可。</p>\n</blockquote>\n<hr>\n<h3 id=\"5-bang—逻辑非\"><a href=\"#5-bang—逻辑非\" class=\"headerlink\" title=\"5. bang—逻辑非\"></a><strong>5. bang—逻辑非</strong></h3><p><strong>题目：</strong></p>\n<pre><code>计算 !x 而不使用逻辑非!\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>bang(3) = 0, bang(0) = 1\n</code></pre><p><strong>可使用操作：</strong> ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 12</p>\n<p><strong>使用操作数：</strong> 6</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">bang</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> ((x &gt;&gt; <span class=\"hljs-number\">31</span>) | ((~x + <span class=\"hljs-number\">1</span>) &gt;&gt; <span class=\"hljs-number\">31</span>)) + <span class=\"hljs-number\">1</span>;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<ul>\n<li>逻辑非<blockquote>\n<p>对于逻辑非运算，应该都很熟悉，!x 当且仅当x为0时其为1，其余时候都为0，可以用来区分零和非零数。</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>该问题的关键就是在于如何区分零和非零数，我们知道零的二补码仍然是零，而对于其余非零数，其符号位会有相应改变，利用这一性质，我们可以对零和非零数做出区分。</p>\n<p>使用 <code>((x &gt;&gt; 31) | ((~x + 1) &gt;&gt; 31))</code>，将二进制数x的符号位与其补码左移31位相与，如若是非零数，其中符号位至少有一个为1，所以经过31位的算数右移后，其中一项必为-1，一项为0，相与之后得到-1,。而对于0来说，结果始终为0。</p>\n<p>最后只要将结果+1，就能得到逻辑非的效果。</p>\n</blockquote>\n<hr>\n<h3 id=\"6-tmin—最小数\"><a href=\"#6-tmin—最小数\" class=\"headerlink\" title=\"6. tmin—最小数\"></a><strong>6. tmin—最小数</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回二补码中最小的数\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 4</p>\n<p><strong>使用操作数：</strong> 1</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">tmin</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">1</span> &lt;&lt; <span class=\"hljs-number\">31</span>;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>此题非常简单，我们知道计算机中负数是用其补码表示的，int所能表示的最小数为0x80000000(-2^31), 即符号位为1，其余皆为0，所以只要将1左移31位即可。</p>\n</blockquote>\n<hr>\n<h3 id=\"7-fitsBits—填充比特\"><a href=\"#7-fitsBits—填充比特\" class=\"headerlink\" title=\"7. fitsBits—填充比特\"></a><strong>7. fitsBits—填充比特</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回1如果x可以表示为n位二补码，反之返回0 (1 &lt;= n &lt;= 32)\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>fitsBits(5,3) = 0, fitsBits(-4,3) = 1\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 15</p>\n<p><strong>使用操作数：</strong> 7</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">fitsBits</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;\n  <span class=\"hljs-keyword\">int</span> k = x &gt;&gt; (n + ~<span class=\"hljs-number\">0</span>); <span class=\"hljs-comment\">// if can k = 0 or -1</span>\n  <span class=\"hljs-keyword\">return</span> !k | !(k + <span class=\"hljs-number\">1</span>);\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>我们知道如若一个数能够被n位二进制数表示，则其第n位即最高位是符号位，那么将其右移n-1位后，根据算术右移，其得到的结果不是0，就是1。否则表示，其还有高于n位的位数， 即不能用n位表示。</p>\n<p>所以用 k = x &gt;&gt; (n + ~0) 表示将其右移n-1位，再用 !k | !(k + 1) 判断k是否为0或-1</p>\n</blockquote>\n<hr>\n<h3 id=\"8-divpwr2—除以2的n次方\"><a href=\"#8-divpwr2—除以2的n次方\" class=\"headerlink\" title=\"8. divpwr2—除以2的n次方\"></a><strong>8. divpwr2—除以2的n次方</strong></h3><p><strong>题目：</strong></p>\n<pre><code>计算 x/(2^n), (0 &lt;= n &lt;= 30)\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>divpwr2(15,1) = 7, divpwr2(-33,4) = -2\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 15</p>\n<p><strong>使用操作数：</strong> 7</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">divpwr2</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;\n    <span class=\"hljs-keyword\">int</span> sign = x &gt;&gt; <span class=\"hljs-number\">31</span>;\n    <span class=\"hljs-keyword\">int</span> bias = (<span class=\"hljs-number\">1</span> &lt;&lt; n) + ~<span class=\"hljs-number\">0</span>;\n    x = x + (bias &amp; sign);\n    <span class=\"hljs-keyword\">return</span> x &gt;&gt; n;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>本题的难点在于Round toward zero, 我们知道除以2的n次方即为将x右移n位。对于正数，尾数截断，因而自然向0舍入。而对于负数则不是如此，经试验在gcc上对于负数，其是向偶数舍入的，因而我们要对负数进行操作。</p>\n<p>同时由于其向偶数舍入，我们不能简单地对负数进行+1操作，例如原本正确的 -7/4 = -1.25 = -1，但是经过+1操作后变为-6/4 = -1.5 Round toward even则变为了2。所以我们不应简单加一，而是加一个偏差值，其为2^n - 1，对于-7/4来说，就是3，加上bias之后得到(-7 + 3)/4即为-1。</p>\n<p>所以我们构造bias = (1 &lt;&lt; n) + ~0 (由于不能用减号，-1用+~0表示)，然后我们要记得将sign取出，在x进行加操作时先检查一下x是否是负数，再进行操作。最后只要方向的将x右移n位即可。</p>\n</blockquote>\n<hr>\n<h3 id=\"9-negate—取负\"><a href=\"#9-negate—取负\" class=\"headerlink\" title=\"9. negate—取负\"></a><strong>9. negate—取负</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回-x\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>negate(1) = -1.\n</code></pre><p><strong>可使用操作：</strong>  ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 5</p>\n<p><strong>使用操作数：</strong> 2</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">negate</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> ~x + <span class=\"hljs-number\">1</span>;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>很简单，对于有符号二进制数取负就是取其补码，而补码等于其取反加一，返回取反加一即可。</p>\n</blockquote>\n<hr>\n<h3 id=\"10-isPositive—是正数\"><a href=\"#10-isPositive—是正数\" class=\"headerlink\" title=\"10. isPositive—是正数\"></a><strong>10. isPositive—是正数</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回1如果x大于0，反之返回0\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>isPositive(-1) = 0.\n</code></pre><p><strong>可使用操作：</strong>  ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 8</p>\n<p><strong>使用操作数：</strong> 5</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">isPositive</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> !(x &gt;&gt; <span class=\"hljs-number\">31</span>) &amp; !!x;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>这题关键在于把0剔除了，区分正负数就是区分其符号位，将x右移31位，负数得-1，正数为0，用一个逻辑非使正数为1，负数为0，然后再和!!x与一下就能剔除0</p>\n</blockquote>\n<ul>\n<li>!!x 当 x == 0 时返回 0，不为 0 时返回 1</li>\n</ul>\n<hr>\n<h3 id=\"11-isLessOrEqual—小于等于\"><a href=\"#11-isLessOrEqual—小于等于\" class=\"headerlink\" title=\"11. isLessOrEqual—小于等于\"></a><strong>11. isLessOrEqual—小于等于</strong></h3><p><strong>题目：</strong></p>\n<pre><code>如果x小于等于y返回1，反之返回0\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>isLessOrEqual(4,5) = 1.\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 24</p>\n<p><strong>使用操作数：</strong> 14</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">isLessOrEqual</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> y)</span> </span>&#123;\n  <span class=\"hljs-keyword\">int</span> res = y + (~x + <span class=\"hljs-number\">1</span>); <span class=\"hljs-comment\">// y - x</span>\n  <span class=\"hljs-keyword\">int</span> xSign = x &gt;&gt; <span class=\"hljs-number\">31</span>;\n  <span class=\"hljs-keyword\">int</span> ySign = y &gt;&gt; <span class=\"hljs-number\">31</span>;\n  <span class=\"hljs-keyword\">int</span> dif = ~xSign + ySign;\n  <span class=\"hljs-keyword\">return</span> (~(dif + <span class=\"hljs-number\">1</span> &gt;&gt; <span class=\"hljs-number\">31</span>) &amp; !(res &gt;&gt; <span class=\"hljs-number\">31</span>)) | !dif;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>我在这里采取了作差的方法 res = y + (~x + 1)，即计算一下y-x，判断其是否非负，同时也要考虑溢出问题，即 x 为负数，y为正数，y-x后溢出为负。</p>\n<p>我将x,y右移31位代表其符号，若负则为-1，若正为0。我同时构造了一个 dif 以表示x,y符号之间的关系。</p>\n<p><strong>dif = ~xSign + ySign</strong></p>\n<ol>\n<li>当 x &lt; 0 &amp;&amp; y &lt; 0 时，dif = -1 </li>\n<li>当 x &lt; 0 &amp;&amp; y &gt; 0 时，dif = 0 </li>\n<li>当 x &gt; 0 &amp;&amp; y &lt; 0 时，dif = -2 </li>\n<li>当 x &gt; 0 &amp;&amp; y &lt; 0 时，dif = -1</li>\n</ol>\n<p>将 x,y 符号之间的关系表达出来，把 dif 加一我们可以观察到当 x,y 同号时，dif为0，所以将其取反和 !(res &gt;&gt; 31) 相与，就可以表示同号不溢出的情况，而当 x &lt; 0, y &gt; 0 的情况发生时，我们注意到 dif 就是 0 ，所以我们直接或上 !dif 即可表达这种情况。</p>\n</blockquote>\n<hr>\n<h3 id=\"12-ilog2—以2为底的对数\"><a href=\"#12-ilog2—以2为底的对数\" class=\"headerlink\" title=\"12. ilog2—以2为底的对数\"></a><strong>12. ilog2—以2为底的对数</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回x取以2为底的对数并向下取整，输入的 x &gt; 0\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>ilog2(16) = 4\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 90</p>\n<p><strong>使用操作数：</strong> 48</p>\n<p><strong>代码：</strong></p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">ilog2</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">int</span> tmp, l1, l2, l4, l8, l16;\n  x |= x &gt;&gt; <span class=\"hljs-number\">1</span>;\n  x |= x &gt;&gt; <span class=\"hljs-number\">2</span>;\n  x |= x &gt;&gt; <span class=\"hljs-number\">4</span>;\n  x |= x &gt;&gt; <span class=\"hljs-number\">8</span>;\n  x |= x &gt;&gt; <span class=\"hljs-number\">16</span>;\n  \n  tmp = (<span class=\"hljs-number\">0x55</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x55</span>;\n  l1 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n  tmp = (<span class=\"hljs-number\">0x33</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x33</span>;\n  l2 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n  tmp = (<span class=\"hljs-number\">0x0f</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x0f</span>;\n  l4 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n  l8 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">16</span>) + <span class=\"hljs-number\">0xff</span>;\n  l16 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0xff</span>;\n\n  x = (x &amp; l1) + ((x &gt;&gt; <span class=\"hljs-number\">1</span>) &amp; l1);\n  x = (x &amp; l2) + ((x &gt;&gt; <span class=\"hljs-number\">2</span>) &amp; l2);\n  x = (x &amp; l4) + ((x &gt;&gt; <span class=\"hljs-number\">4</span>) &amp; l4);\n  x = (x &amp; l8) + ((x &gt;&gt; <span class=\"hljs-number\">8</span>) &amp; l8);\n  x = (x &amp; l16) + ((x &gt;&gt; <span class=\"hljs-number\">16</span>) &amp; l16);\n  <span class=\"hljs-keyword\">return</span> x + ~<span class=\"hljs-number\">0</span>;</code></pre>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>我们知道二进制数每位有其位权，所以对 x 取以2为底的对数就是指其为1的最高位的位权。为了获得最高位的位置，其实我们可以将其最高位往下全部变为1，再类似bitsCount数其中1的个数就行了。</p>\n<p>我把 x 移位相与，保证最高位往下所有数字为1，再使用bitsCount就得到答案。</p>\n<p>最后不要忘记减一</p>\n</blockquote>\n<hr>\n<h3 id=\"13-float-neg—浮点数的负数\"><a href=\"#13-float-neg—浮点数的负数\" class=\"headerlink\" title=\"13. float_neg—浮点数的负数\"></a><strong>13. float_neg—浮点数的负数</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回-f，当NaN时，返回参数f\n</code></pre><p><strong>可使用操作：</strong> 所有的整型操作，包括 ||, &amp;&amp;. 以及 if, while</p>\n<p><strong>最大操作数限制：</strong> 10</p>\n<p><strong>使用操作数：</strong> 5</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-title\">float_neg</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">unsigned</span> uf)</span> </span>&#123;\n  <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-built_in\">exp</span> = uf &amp; <span class=\"hljs-number\">0x7f800000</span>;\n  <span class=\"hljs-keyword\">unsigned</span> frac = uf &amp; <span class=\"hljs-number\">0x007fffff</span>;\n  <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> == <span class=\"hljs-number\">0x7f800000</span> &amp;&amp; frac)\n    <span class=\"hljs-keyword\">return</span> uf;\n  <span class=\"hljs-keyword\">return</span> uf ^= <span class=\"hljs-number\">0x80000000</span>;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<ul>\n<li>IEEE-float<blockquote>\n<p>我们知道IEEE单精度浮点数，最高位为符号位，其后8位为阶码exp，后23位为尾数frac。其牺牲了精度来扩大了表达范围。</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>而当 exp 全 1 时，如若frac非全零，则表示NaN。若全零，则表示无穷大/小。</p>\n<p>这里我们只要将原数和符号位0x80000000异或一下，即可取负。不要忘记排除NaN的情况。</p>\n</blockquote>\n<hr>\n<h3 id=\"14-float-i2f—int转float\"><a href=\"#14-float-i2f—int转float\" class=\"headerlink\" title=\"14. float_i2f—int转float\"></a><strong>14. float_i2f—int转float</strong></h3><p><strong>题目：</strong></p>\n<pre><code>把int类型的数转换为float表示(比特形式)\n</code></pre><p><strong>可使用操作：</strong> 所有的整型操作，包括 ||, &amp;&amp;. 以及 if, while</p>\n<p><strong>最大操作数限制：</strong> 30</p>\n<p><strong>使用操作数：</strong> 30</p>\n<p><strong>代码：</strong></p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-title\">float_i2f</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">unsigned</span> frac, mask1, mask2, mask3, mask4, d;\n  <span class=\"hljs-keyword\">int</span> high = <span class=\"hljs-number\">0x80000000</span>;\n  <span class=\"hljs-keyword\">unsigned</span> sign = x &amp; <span class=\"hljs-number\">0x80000000</span>;\n  <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-built_in\">exp</span> = <span class=\"hljs-number\">127</span>;\n  <span class=\"hljs-keyword\">int</span> count = <span class=\"hljs-number\">32</span>, i;\n  <span class=\"hljs-keyword\">if</span>(sign)\n    x = ~x + <span class=\"hljs-number\">1</span>;\n  <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(!x)\n    <span class=\"hljs-keyword\">return</span> x;\n  \n  frac = x;\n\n  <span class=\"hljs-keyword\">for</span>(;high; high &gt;&gt;= <span class=\"hljs-number\">1</span>)\n  &#123;\n    --count;\n    <span class=\"hljs-keyword\">if</span>(high &amp; x)\n      <span class=\"hljs-keyword\">break</span>;\n  &#125;\n  i = count - <span class=\"hljs-number\">23</span>;\n  mask1 = ~(<span class=\"hljs-number\">1</span> &lt;&lt; count); <span class=\"hljs-comment\">// the highest 1</span>\n  mask2 = <span class=\"hljs-number\">1</span> &lt;&lt; i; <span class=\"hljs-comment\">//the lowest of remain frac;</span>\n  mask3 = mask2 &gt;&gt; <span class=\"hljs-number\">1</span>; <span class=\"hljs-comment\">// the highest of deserted bits </span>\n  mask4 = mask2 - <span class=\"hljs-number\">1</span>; <span class=\"hljs-comment\">// the deserted bits</span>\n  <span class=\"hljs-built_in\">exp</span> += count;\n\n  frac &amp;= mask1;\n  \n  <span class=\"hljs-keyword\">if</span>(i &gt; <span class=\"hljs-number\">0</span>)\n  &#123;\n    d = frac &amp; mask4; <span class=\"hljs-comment\">// deserted bits</span>\n    <span class=\"hljs-keyword\">if</span>(d &gt; mask3 | (d == mask3 &amp;&amp; frac &amp; mask2))\n    &#123;\n      frac += mask2;\n      <span class=\"hljs-keyword\">if</span>(frac &gt; <span class=\"hljs-number\">0x3fffffff</span>)\n      &#123;\n        frac = <span class=\"hljs-number\">0</span>;\n        <span class=\"hljs-built_in\">exp</span>++;\n      &#125;\n    &#125;\n    frac &gt;&gt;= i;\n  &#125;\n  <span class=\"hljs-keyword\">else</span>\n    frac &lt;&lt;= -i;\n\n  <span class=\"hljs-keyword\">return</span> sign | <span class=\"hljs-built_in\">exp</span> &lt;&lt; <span class=\"hljs-number\">23</span> | frac;\n&#125;</code></pre>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>我认为这题比较难，我做了很久很久….它难在浮点数向偶数舍入以及其操作数的限制。</p>\n<p>我们知道由于浮点数表示范围比整型大，我们可以将整型转换为浮点数，但是相应的会有一些精度的丢失，因为尾数frac只有23位，而int有31位可用。</p>\n<p>所以其关键在于int的位数，一开始先把该取出来的都用掩码取出来，把负数和零处理一下。之后我利用了一个循环先找出int的最高位在哪，利用count计数。</p>\n<p>后面我采取了四个掩码，分别代表最高位的1，留下的尾数中的最低位，要舍去的位数的最高位，以及舍弃的位数的掩码。利用这四个掩码我们可以达到存frac时，将其向<strong>偶数舍入</strong>。</p>\n<p>具体操作是，先取出丢弃的尾数，将其存放在d中，看其有没有超过0.5 (即 d 是否大于 mask3) 如果大于，直接frac++就行。而如果等于的话，还要看frac是否是奇数 (即frac &amp; mask2是否为1) 如果是，则要向偶数舍入,frac++。</p>\n<p>加完frac之后还要注意<strong>溢出问题</strong>，如果溢出了，要将frac置0，然后把阶码 exp++，再按照之前输出来的尾数移动，将尾数对齐即可 （位数最高默认为1不存，因而把最高位隐去）。</p>\n<p>最后把符号位，阶码位和尾数位拼接，得到最后的结果。</p>\n</blockquote>\n<hr>\n<h3 id=\"15-float-twice—float-2\"><a href=\"#15-float-twice—float-2\" class=\"headerlink\" title=\"15. float_twice—float * 2\"></a>15. float_twice—float * 2</h3><p><strong>题目：</strong></p>\n<pre><code>返回float * 2, 当参数是NaN时，返回参数\n</code></pre><p><strong>可使用操作：</strong> 所有的整型操作，包括 ||, &amp;&amp;. 以及 if, while</p>\n<p><strong>最大操作数限制：</strong> 30</p>\n<p><strong>使用操作数：</strong> 20</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-title\">float_twice</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">unsigned</span> uf)</span> </span>&#123;\n  <span class=\"hljs-keyword\">unsigned</span> sign = uf &amp; <span class=\"hljs-number\">0x80000000</span>;\n  <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-built_in\">exp</span> = uf &amp; <span class=\"hljs-number\">0x7f800000</span>;\n  <span class=\"hljs-keyword\">unsigned</span> frac = uf &amp; <span class=\"hljs-number\">0x007fffff</span>;\n  <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> == <span class=\"hljs-number\">0x7f800000</span>) <span class=\"hljs-comment\">//NaN &amp; inf</span>\n    <span class=\"hljs-keyword\">return</span> uf;\n  <span class=\"hljs-keyword\">if</span>(!<span class=\"hljs-built_in\">exp</span> &amp;&amp; !frac) <span class=\"hljs-comment\">// 0</span>\n    <span class=\"hljs-keyword\">return</span> uf;\n  <span class=\"hljs-keyword\">if</span>(!<span class=\"hljs-built_in\">exp</span> &amp;&amp; frac &lt;= <span class=\"hljs-number\">0x3fffff</span>)  <span class=\"hljs-comment\">// low</span>\n    frac *= <span class=\"hljs-number\">2</span>;\n  <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(!<span class=\"hljs-built_in\">exp</span> &amp;&amp; frac &gt; <span class=\"hljs-number\">0x3fffff</span>) <span class=\"hljs-comment\">// high</span>\n  &#123;\n    <span class=\"hljs-built_in\">exp</span> += <span class=\"hljs-number\">0x00800000</span>;\n    frac = (frac * <span class=\"hljs-number\">2</span>) &amp; <span class=\"hljs-number\">0x7fffff</span>;\n  &#125;\n  <span class=\"hljs-keyword\">else</span> <span class=\"hljs-comment\">// normal</span>\n    <span class=\"hljs-built_in\">exp</span> += <span class=\"hljs-number\">0x00800000</span>;\n  <span class=\"hljs-keyword\">return</span> sign + <span class=\"hljs-built_in\">exp</span> + frac;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>主要要分析的地方，在于当阶码exp为0时，是否在乘2之后进位。所以要考虑尾数是否大于0x3fffff，如果小于等于之，则直接尾数乘2就行，不会溢出，否则则exp要进位，同时尾数乘2之后要与上0x7fffff保证不溢出。</p>\n<p>其他正常情况直接exp++就行，注意一下特殊情况;</p>\n</blockquote>\n<p><em>本题中测试集中有一个inf，也要直接返回参数uf</em></p>\n<hr>\n<h2 id=\"Bits-honor-c\"><a href=\"#Bits-honor-c\" class=\"headerlink\" title=\"Bits_honor.c\"></a><strong>Bits_honor.c</strong></h2><h3 id=\"1-bitReverse—比特翻转\"><a href=\"#1-bitReverse—比特翻转\" class=\"headerlink\" title=\"1. bitReverse—比特翻转\"></a><strong>1. bitReverse—比特翻转</strong></h3><p><strong>题目：</strong></p>\n<pre><code>把32比特int的比特位翻转\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>bitReverse(0x80000004) = 0x20000001\nbitReverse(0x7FFFFFFF) = 0xFFFFFFFE\n</code></pre><p><strong>最大操作数限制：</strong> 40</p>\n<p><strong>使用操作数：</strong> 40</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">bitReverse</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n   <span class=\"hljs-keyword\">int</span> tmp,l1, l2, l4, l8, l16;\n\n   tmp = (<span class=\"hljs-number\">0x55</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x55</span>;\n   l1 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n   tmp = (<span class=\"hljs-number\">0x33</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x33</span>;\n   l2 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n   tmp = (<span class=\"hljs-number\">0x0f</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x0f</span>;\n   l4 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n   l8 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">16</span>) + <span class=\"hljs-number\">0xff</span>;\n   l16 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0xff</span>;\n\n   x = ((x &gt;&gt; <span class=\"hljs-number\">16</span>) &amp; l16) | (x &lt;&lt; <span class=\"hljs-number\">16</span>);\n   x = ((x &gt;&gt; <span class=\"hljs-number\">8</span>) &amp; l8) | ((x &amp; l8) &lt;&lt; <span class=\"hljs-number\">8</span>);\n   x = ((x &gt;&gt; <span class=\"hljs-number\">4</span>) &amp; l4) | ((x &amp; l4) &lt;&lt; <span class=\"hljs-number\">4</span>);\n   x = ((x &gt;&gt; <span class=\"hljs-number\">2</span>) &amp; l2) | ((x &amp; l2) &lt;&lt; <span class=\"hljs-number\">2</span>);\n   x = ((x &gt;&gt; <span class=\"hljs-number\">1</span>) &amp; l1) | ((x &amp; l1) &lt;&lt; <span class=\"hljs-number\">1</span>);\n   <span class=\"hljs-keyword\">return</span> x;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>这题和 bitsCount 有异曲同工之妙，也是一个分治法，将32位二进制数一分为二，交换，再将内部各自再一分为二，交换，直至最底层2位二进制数互换位置，最后完成了将所有位数翻转的工作。</p>\n<p>但值得注意的是，给出的是有符号的int，所以在右移交换位置时，会发生因为负数算术右移导致高位全是1的情况，致使在与的过程中高位全部变为1。这边只要将其移动后在和掩码相与就能解决这一问题。而对于低位，先与掩码相与再移动，可以省去取反得到高位掩码的操作数。再用tmp省一下操作数。</p>\n<p>最后操作数正好卡在40</p>\n</blockquote>\n<hr>\n<h3 id=\"2-mod3—取模3\"><a href=\"#2-mod3—取模3\" class=\"headerlink\" title=\"2. mod3—取模3\"></a><strong>2. mod3—取模3</strong></h3><p><strong>题目：</strong></p>\n<pre><code>计算 x 取模 3，而不用%\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>mod3(100) = 1\nmod3(-100) = -1\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 90</p>\n<p><strong>使用操作数：</strong> 24</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">mod3</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n   <span class=\"hljs-keyword\">int</span> mask = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0xff</span>;\n\n   x = (x &gt;&gt; <span class=\"hljs-number\">16</span>) + (x &amp; mask); <span class=\"hljs-comment\">// sum base 4^8 digits (a &lt;= 0x1FFFE)</span>\n   x = (x &gt;&gt; <span class=\"hljs-number\">8</span>) + (x &amp; <span class=\"hljs-number\">0xff</span>); <span class=\"hljs-comment\">// sum base 4^4 digits (a &lt;= 0x2FD)</span>\n   x = (x &gt;&gt; <span class=\"hljs-number\">4</span>) + (x &amp; <span class=\"hljs-number\">0xf</span>); <span class=\"hljs-comment\">// sum base 4^2 digits (a &lt;= 0x3C)</span>\n   x = (x &gt;&gt; <span class=\"hljs-number\">2</span>) + (x &amp; <span class=\"hljs-number\">0x3</span>); <span class=\"hljs-comment\">// sum base 4^1 digits (a &lt;= 0x1D)</span>\n   x = (x &gt;&gt; <span class=\"hljs-number\">2</span>) + (x &amp; <span class=\"hljs-number\">0x3</span>); <span class=\"hljs-comment\">// sum base 4^1 digits (a &lt;= 0x9)</span>\n   x = (x &gt;&gt; <span class=\"hljs-number\">2</span>) + (x &amp; <span class=\"hljs-number\">0x3</span>); <span class=\"hljs-comment\">// sum base 4^1 digits (a &lt;= 0x4)</span>\n\n   x = (((x + <span class=\"hljs-number\">1</span>) &gt;&gt; <span class=\"hljs-number\">2</span>) + x) &amp; <span class=\"hljs-number\">0x3</span>;\n   <span class=\"hljs-keyword\">return</span> x;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>这题难度算是比较大的，我参考了一些资料最后才写出这个代码。其实这题也与bitsCount有着一定的联系。</p>\n<p>对于解这题有一个根本的公式即 </p>\n</blockquote>\n<pre><code>a % m = ((b % m)(a/b) + (a % b)) % m\n其中b是进制数\n</code></pre><blockquote>\n<p>我们知道，如果想要知道一个十进制的数能否被三整除，只要看它所有数位之和是否能被三整除就行了。其实这就是上述公式的特殊情况，由于10 mod 3 == 1 所以其就退化为</p>\n</blockquote>\n<pre><code>a mod m = (a/b + a % b) % m\n递归下来就是所有数位之和\n</code></pre><blockquote>\n<p>而对于二进制的情况，我们可以将进制位b选为4，这样正好是两位二进制数，同时4 % 3 == 1，这样一来，对于二进制数中我们只需要统计所有两两数位(四进制)的和能否被三整除就行了。</p>\n<p>而考虑到我们每做一次 a/b + a % b 统计数位和都减小了数的规模，这样只要做有限次就能够将数控制在&lt;=3的范围内。</p>\n<p>对于a % 4，这是一个经典的trivial情况，我们只需要做 a &amp; 3，就能够轻松得到a % 4的值。而对于a/4，只需要做a &gt;&gt; 2即可。</p>\n<p>对于二进制数我们不仅可以按两位两位的四进制数位和来数，也可以直接数其倍数(4^i)，从最大4^8开始统计，一步步减小x的值，最后将x做到&lt;= 3的范围</p>\n<p>最后要判断x是否为3，如果为3的话则要置为0，我利用3数位全为1的特点，将其+1进位后，右移2位。如果为3，则得到的是1。将其再加上x，如若x是1或2，则还是不变，但如果是3，它又会进位到4，那么我们只要再与上0x3，则会得到0，即为想要的结果。</p>\n</blockquote>\n<hr>\n<h3 id=\"3-float-f2i—float转int\"><a href=\"#3-float-f2i—float转int\" class=\"headerlink\" title=\"3. float_f2i—float转int\"></a><strong>3. float_f2i—float转int</strong></h3><p><strong>题目：</strong></p>\n<pre><code>输入一个按二进制位储存的float（以unsigned表示），将其转为int输出。(NaN,inf，溢出直接返回参数)\n</code></pre><p><strong>可使用操作：</strong> 所有的整型操作，包括 ||, &amp;&amp;. 以及 if, while</p>\n<p><strong>最大操作数限制：</strong> 30</p>\n<p><strong>使用操作数：</strong> 17</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">float_f2i</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">unsigned</span> uf)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n   <span class=\"hljs-keyword\">int</span> sign, <span class=\"hljs-built_in\">exp</span>, frac, res;\n   <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">int</span> tmp;\n\n   <span class=\"hljs-keyword\">if</span>(!uf)\n      <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n   sign = uf &amp; <span class=\"hljs-number\">0x80000000</span>;\n   <span class=\"hljs-built_in\">exp</span> = uf &amp; <span class=\"hljs-number\">0x7f800000</span>;\n   frac = (uf &amp; <span class=\"hljs-number\">0x007fffff</span>) | <span class=\"hljs-number\">0x00800000</span>;\n\n   <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> == <span class=\"hljs-number\">0x7f800000</span>) <span class=\"hljs-comment\">//NaN and inf</span>\n      <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0x80000000</span>u;\n\n   <span class=\"hljs-built_in\">exp</span> &gt;&gt;= <span class=\"hljs-number\">23</span>;\n\n   <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> &lt; <span class=\"hljs-number\">127</span>)\n      <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n   <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> &gt; <span class=\"hljs-number\">158</span>)\n      <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0x80000000</span>u;\n   <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> &gt; <span class=\"hljs-number\">150</span>)\n      tmp = frac &lt;&lt; (<span class=\"hljs-built_in\">exp</span> - <span class=\"hljs-number\">150</span>);\n   <span class=\"hljs-keyword\">else</span>\n      tmp = frac &gt;&gt; (<span class=\"hljs-number\">150</span> - <span class=\"hljs-built_in\">exp</span>);\n\n      \n   <span class=\"hljs-keyword\">if</span>(sign)\n      res = ~tmp + <span class=\"hljs-number\">1</span>;\n   <span class=\"hljs-keyword\">else</span>\n      res = tmp;\n   \n   <span class=\"hljs-keyword\">return</span> res | sign;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>这题特殊情况比较多，把NaN和inf处理一下，然后注意一下溢出情况，即取出来的exp - bias &gt; 31，肯定超过2^31整型储存的最大值，直接返回0x80000000u，然后对于exp小于127的，其指数是负数，直接返回int值为0。对于在exp - bias 在 0 到 31 之间的，由于frac只有23位，所以要将注意一下讨论23的情况。</p>\n<p>最后把取出来的符号位对一下，如果负数取反加一，正数直接等，最后再或上符号位，返回答案。</p>\n</blockquote>\n<hr>\n<h2 id=\"结果截图\"><a href=\"#结果截图\" class=\"headerlink\" title=\"结果截图\"></a><strong>结果截图</strong></h2><h3 id=\"bits-c\"><a href=\"#bits-c\" class=\"headerlink\" title=\"bits.c\"></a><strong>bits.c</strong></h3><p><img src=\"/2020/11/05/ICS/ICS_Lab1/ICS_Lab1/bits_btest.JPG\" alt=\"bits_btest\"></p>\n<p><img src=\"/2020/11/05/ICS/ICS_Lab1/ICS_Lab1/bits_dlc.png\" alt=\"bits_dlc\"></p>\n<h3 id=\"bits-honor-c\"><a href=\"#bits-honor-c\" class=\"headerlink\" title=\"bits_honor.c\"></a><strong>bits_honor.c</strong></h3><p><img src=\"/2020/11/05/ICS/ICS_Lab1/ICS_Lab1/bits_honor_btest.JPG\" alt=\"bits_honor_btest\"></p>\n<p><img src=\"/2020/11/05/ICS/ICS_Lab1/ICS_Lab1/bits_honor_dlc.png\" alt=\"bits_honor_dlc\"></p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><hr>\n<p><a href=\"https://baike.baidu.com/item/%E7%AE%97%E6%9C%AF%E5%8F%B3%E7%A7%BB/3711081?fr=aladdin\">https://baike.baidu.com/item/%E7%AE%97%E6%9C%AF%E5%8F%B3%E7%A7%BB/3711081?fr=aladdin</a><br><a href=\"https://blog.csdn.net/jiahonghao2002/article/details/108223366\">https://blog.csdn.net/jiahonghao2002/article/details/108223366</a><br><a href=\"https://leetcode-cn.com/problems/reverse-bits/solution/dian-dao-er-jin-zhi-wei-by-leetcode/\">https://leetcode-cn.com/problems/reverse-bits/solution/dian-dao-er-jin-zhi-wei-by-leetcode/</a><br><a href=\"http://homepage.cs.uiowa.edu/~jones/bcd/mod.shtml#exmod3\">http://homepage.cs.uiowa.edu/~jones/bcd/mod.shtml#exmod3</a><br><a href=\"https://www.zhihu.com/question/38206659/answer/763034261\">https://www.zhihu.com/question/38206659/answer/763034261</a><br><a href=\"https://blog.csdn.net/xindaxinda123/article/details/95617758\">https://blog.csdn.net/xindaxinda123/article/details/95617758</a><br><a href=\"https://www.runoob.com/w3cnote/32-float-storage.html\">https://www.runoob.com/w3cnote/32-float-storage.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"ICS-Lab1-位运算\"><a href=\"#ICS-Lab1-位运算\" class=\"headerlink\" title=\"ICS_Lab1-位运算\"></a>ICS_Lab1-位运算</h1><blockquote>\n<p>这个是CS:APP的第一个lab，也是我ICS课上的第一个lab，主要注重于使用受限制的位运算来完成操作</p>\n</blockquote>\n<hr>\n<h2 id=\"Bits-c\"><a href=\"#Bits-c\" class=\"headerlink\" title=\"Bits.c\"></a><strong>Bits.c</strong></h2><h3 id=\"1-bitAnd—与\"><a href=\"#1-bitAnd—与\" class=\"headerlink\" title=\"1. bitAnd—与\"></a><strong>1. bitAnd—与</strong></h3><p><strong>题目：</strong></p>\n<pre><code>只用~和|实现&amp;\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>bitAnd(6, 5) = 4\n</code></pre><p><strong>可使用操作：</strong> ~ |</p>\n<p><strong>最大操作数限制：</strong> 8</p>\n<p><strong>使用操作数：</strong> 4</p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">bitAnd</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> y)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> ~(~x | ~y); <span class=\"hljs-comment\">//De Morgan&#x27;s laws</span>\n&#125;</code></pre>\n<blockquote>\n<p>应用摩根律 ~(x | y) = ~x &amp; ~y, 可得 x &amp; y = ~(~x | ~y)</p>\n</blockquote>\n<hr>\n<h3 id=\"2-getByte—获取字节\"><a href=\"#2-getByte—获取字节\" class=\"headerlink\" title=\"2. getByte—获取字节\"></a><strong>2. getByte—获取字节</strong></h3><p><strong>题目：</strong></p>\n<pre><code>从x中提取字节n, n编号从0至3\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>getByte(0x12345678,1) = 0x56\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 6</p>\n<p><strong>使用操作数：</strong> 3</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">getByte</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> (x &gt;&gt; (n &lt;&lt; <span class=\"hljs-number\">3</span>)) &amp; <span class=\"hljs-number\">0xff</span>;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<p><em>由于 1Byte = 8bits = 2^3bits， 所以 n Bytes = 2^3 </em> n bits*</p>\n<blockquote>\n<p>因而将n左移3位，即 n <em> 2^3, 再将x右移 n </em> 2^3 即可将所求字节放在低8位，将其与上0xff，即可取出字节。</p>\n</blockquote>\n<hr>\n<h3 id=\"3-logicalShift—逻辑右移\"><a href=\"#3-logicalShift—逻辑右移\" class=\"headerlink\" title=\"3. logicalShift—逻辑右移\"></a><strong>3. logicalShift—逻辑右移</strong></h3><p><strong>题目：</strong></p>\n<pre><code>将x逻辑右移n位\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>logicalShift(0x87654321,4) = 0x08765432\n</code></pre><p><strong>可使用操作：</strong>  ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 20</p>\n<p><strong>使用操作数：</strong> 10</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">logicalShift</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;\n  <span class=\"hljs-comment\">//flag equals to: if n == 0 return 0; else return 1;</span>\n  <span class=\"hljs-keyword\">int</span> flag = !!n;\n  <span class=\"hljs-keyword\">int</span> mask = ~(flag &lt;&lt; (<span class=\"hljs-number\">32</span> + (~n + <span class=\"hljs-number\">1</span>)));\n  <span class=\"hljs-keyword\">return</span> (x &gt;&gt; n) &amp; mask;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<ul>\n<li><p>算数右移</p>\n<blockquote>\n<p>算数右移即在右移后用原符号位数将高位补齐，保持右移后二进制数的符号保持不变。</p>\n</blockquote>\n</li>\n<li><p>逻辑右移</p>\n<blockquote>\n<p>逻辑右移即在右移后用 0 将高位补齐，是“逻辑上”的右移。</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>在正常右移运算中使用的是算数右移，因而要解决的问题即对于负数如何将最高位补上0，而非符号位1。<br>我采取掩码的方式，先将x正常右移n位与上其高位的掩码，使其右移产生的高位变为0</p>\n</blockquote>\n<ul>\n<li>掩码构造<blockquote>\n<p>掩码不能草率的构造为 ~(-1 &lt;&lt; (32 - n)), 这种构造方式当n为0时会因-1被左移32位而导致异常，构造出来的mask仍为0</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>由于不能使用if，为判断n是否为0，我才用了一个flag = !n + ~0, 其有很好的性质。当n为0时，flag也为0，而当n不为零时，flag统一为-1，这样使用flag代替原先的-1, 从而避免上述情况。</p>\n<p>这样我们可以使用 mask = ~(flag &lt;&lt; (32 + (~n + 1)))，来构造掩码，当n为0时，flag为0，从而mask = -1，避免上述错误。</p>\n</blockquote>\n<hr>\n<h3 id=\"4-bitCount—比特计数\"><a href=\"#4-bitCount—比特计数\" class=\"headerlink\" title=\"4. bitCount—比特计数\"></a><strong>4. bitCount—比特计数</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回二进制数中1的个数\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>bitCount(5) = 2, bitCount(7) = 3\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 40</p>\n<p><strong>使用操作数：</strong> 36</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">bitCount</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">int</span> tmp, l1, l2, l4, l8, l16; <span class=\"hljs-comment\">//tmp is used to save ops</span>\n  tmp = (<span class=\"hljs-number\">0x55</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x55</span>;\n  l1 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp; <span class=\"hljs-comment\">//0x55555555</span>\n  tmp = (<span class=\"hljs-number\">0x33</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x33</span>;\n  l2 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp; <span class=\"hljs-comment\">//0x33333333</span>\n  tmp = (<span class=\"hljs-number\">0x0f</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x0f</span>;\n  l4 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp; <span class=\"hljs-comment\">//0x0f0f0f0f</span>\n  l8 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">16</span>) + <span class=\"hljs-number\">0xff</span>; <span class=\"hljs-comment\">//0x00ff00ff</span>\n  l16 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0xff</span>; <span class=\"hljs-comment\">//0x0000ffff</span>\n\n  x = (x &amp; l1) + ((x &gt;&gt; <span class=\"hljs-number\">1</span>) &amp; l1);\n  x = (x &amp; l2) + ((x &gt;&gt; <span class=\"hljs-number\">2</span>) &amp; l2);\n  x = (x &amp; l4) + ((x &gt;&gt; <span class=\"hljs-number\">4</span>) &amp; l4);\n  x = (x &amp; l8) + ((x &gt;&gt; <span class=\"hljs-number\">8</span>) &amp; l8);\n  x = (x &amp; l16) + ((x &gt;&gt; <span class=\"hljs-number\">16</span>) &amp; l16);\n  <span class=\"hljs-keyword\">return</span> x;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<ul>\n<li>分治思想<blockquote>\n<p>本题使用了一个简单的分治思想，对于一个二进制数，要对其中为1的位做计数， 对于1位二进制数来说，1的个数无非就是其本身所表示的1或0。利用这个特性，我们可以先将一个二进制数每一位独立分开为相间隔的两部分, 其每位表示的就是自身的二进制个数，再将两串二进制数对其相加，所得到的每两位分隔的二进制数就是表达这个位置的位为1的个数。</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>进一步相加为4位，8位其所代表的含义不变，最后合并至32位二进制数，其所表示的就是原二进制数中所含1的个数。</p>\n</blockquote>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">//以八位二进制数 10101110 为例//</span>\n按 <span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">0</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">0</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">0</span> 分割， 为两串<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">1</span>和<span class=\"hljs-number\">0</span>|<span class=\"hljs-number\">0</span>|<span class=\"hljs-number\">1</span>|<span class=\"hljs-number\">0</span>，再将其合并，成为 <span class=\"hljs-number\">01</span> | <span class=\"hljs-number\">01</span> | <span class=\"hljs-number\">10</span> | <span class=\"hljs-number\">01</span>, 再将两串 <span class=\"hljs-number\">01</span> | <span class=\"hljs-number\">10</span> 和<span class=\"hljs-number\">01</span> | <span class=\"hljs-number\">01</span>合并得 <span class=\"hljs-number\">0010</span> | <span class=\"hljs-number\">0011</span>（这个很容易看出表示左四位有<span class=\"hljs-number\">2</span>个<span class=\"hljs-number\">1</span>，右四位有<span class=\"hljs-number\">3</span>个<span class=\"hljs-number\">1</span>），再次合并得 <span class=\"hljs-number\">00000101</span>, 得到总共有<span class=\"hljs-number\">5</span>个<span class=\"hljs-number\">1</span>。\n\n<span class=\"hljs-comment\">//对于32位二进制数亦按此继续操作即可//</span></code></pre>\n<blockquote>\n<p>于是为完成分割取位的操作，我们需要采用掩码</p>\n</blockquote>\n<ul>\n<li>0x55555555 \\ 0x33333333 \\ 0x0f0f0f0f \\ 0x0000ffff</li>\n</ul>\n<blockquote>\n<p>利用位运算分别构造，使用tmp可以节约ops, 之后按照分治思想进行操作即可。</p>\n</blockquote>\n<hr>\n<h3 id=\"5-bang—逻辑非\"><a href=\"#5-bang—逻辑非\" class=\"headerlink\" title=\"5. bang—逻辑非\"></a><strong>5. bang—逻辑非</strong></h3><p><strong>题目：</strong></p>\n<pre><code>计算 !x 而不使用逻辑非!\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>bang(3) = 0, bang(0) = 1\n</code></pre><p><strong>可使用操作：</strong> ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 12</p>\n<p><strong>使用操作数：</strong> 6</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">bang</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> ((x &gt;&gt; <span class=\"hljs-number\">31</span>) | ((~x + <span class=\"hljs-number\">1</span>) &gt;&gt; <span class=\"hljs-number\">31</span>)) + <span class=\"hljs-number\">1</span>;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<ul>\n<li>逻辑非<blockquote>\n<p>对于逻辑非运算，应该都很熟悉，!x 当且仅当x为0时其为1，其余时候都为0，可以用来区分零和非零数。</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>该问题的关键就是在于如何区分零和非零数，我们知道零的二补码仍然是零，而对于其余非零数，其符号位会有相应改变，利用这一性质，我们可以对零和非零数做出区分。</p>\n<p>使用 <code>((x &gt;&gt; 31) | ((~x + 1) &gt;&gt; 31))</code>，将二进制数x的符号位与其补码左移31位相与，如若是非零数，其中符号位至少有一个为1，所以经过31位的算数右移后，其中一项必为-1，一项为0，相与之后得到-1,。而对于0来说，结果始终为0。</p>\n<p>最后只要将结果+1，就能得到逻辑非的效果。</p>\n</blockquote>\n<hr>\n<h3 id=\"6-tmin—最小数\"><a href=\"#6-tmin—最小数\" class=\"headerlink\" title=\"6. tmin—最小数\"></a><strong>6. tmin—最小数</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回二补码中最小的数\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 4</p>\n<p><strong>使用操作数：</strong> 1</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">tmin</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">1</span> &lt;&lt; <span class=\"hljs-number\">31</span>;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>此题非常简单，我们知道计算机中负数是用其补码表示的，int所能表示的最小数为0x80000000(-2^31), 即符号位为1，其余皆为0，所以只要将1左移31位即可。</p>\n</blockquote>\n<hr>\n<h3 id=\"7-fitsBits—填充比特\"><a href=\"#7-fitsBits—填充比特\" class=\"headerlink\" title=\"7. fitsBits—填充比特\"></a><strong>7. fitsBits—填充比特</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回1如果x可以表示为n位二补码，反之返回0 (1 &lt;= n &lt;= 32)\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>fitsBits(5,3) = 0, fitsBits(-4,3) = 1\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 15</p>\n<p><strong>使用操作数：</strong> 7</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">fitsBits</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;\n  <span class=\"hljs-keyword\">int</span> k = x &gt;&gt; (n + ~<span class=\"hljs-number\">0</span>); <span class=\"hljs-comment\">// if can k = 0 or -1</span>\n  <span class=\"hljs-keyword\">return</span> !k | !(k + <span class=\"hljs-number\">1</span>);\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>我们知道如若一个数能够被n位二进制数表示，则其第n位即最高位是符号位，那么将其右移n-1位后，根据算术右移，其得到的结果不是0，就是1。否则表示，其还有高于n位的位数， 即不能用n位表示。</p>\n<p>所以用 k = x &gt;&gt; (n + ~0) 表示将其右移n-1位，再用 !k | !(k + 1) 判断k是否为0或-1</p>\n</blockquote>\n<hr>\n<h3 id=\"8-divpwr2—除以2的n次方\"><a href=\"#8-divpwr2—除以2的n次方\" class=\"headerlink\" title=\"8. divpwr2—除以2的n次方\"></a><strong>8. divpwr2—除以2的n次方</strong></h3><p><strong>题目：</strong></p>\n<pre><code>计算 x/(2^n), (0 &lt;= n &lt;= 30)\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>divpwr2(15,1) = 7, divpwr2(-33,4) = -2\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 15</p>\n<p><strong>使用操作数：</strong> 7</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">divpwr2</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;\n    <span class=\"hljs-keyword\">int</span> sign = x &gt;&gt; <span class=\"hljs-number\">31</span>;\n    <span class=\"hljs-keyword\">int</span> bias = (<span class=\"hljs-number\">1</span> &lt;&lt; n) + ~<span class=\"hljs-number\">0</span>;\n    x = x + (bias &amp; sign);\n    <span class=\"hljs-keyword\">return</span> x &gt;&gt; n;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>本题的难点在于Round toward zero, 我们知道除以2的n次方即为将x右移n位。对于正数，尾数截断，因而自然向0舍入。而对于负数则不是如此，经试验在gcc上对于负数，其是向偶数舍入的，因而我们要对负数进行操作。</p>\n<p>同时由于其向偶数舍入，我们不能简单地对负数进行+1操作，例如原本正确的 -7/4 = -1.25 = -1，但是经过+1操作后变为-6/4 = -1.5 Round toward even则变为了2。所以我们不应简单加一，而是加一个偏差值，其为2^n - 1，对于-7/4来说，就是3，加上bias之后得到(-7 + 3)/4即为-1。</p>\n<p>所以我们构造bias = (1 &lt;&lt; n) + ~0 (由于不能用减号，-1用+~0表示)，然后我们要记得将sign取出，在x进行加操作时先检查一下x是否是负数，再进行操作。最后只要方向的将x右移n位即可。</p>\n</blockquote>\n<hr>\n<h3 id=\"9-negate—取负\"><a href=\"#9-negate—取负\" class=\"headerlink\" title=\"9. negate—取负\"></a><strong>9. negate—取负</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回-x\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>negate(1) = -1.\n</code></pre><p><strong>可使用操作：</strong>  ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 5</p>\n<p><strong>使用操作数：</strong> 2</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">negate</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> ~x + <span class=\"hljs-number\">1</span>;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>很简单，对于有符号二进制数取负就是取其补码，而补码等于其取反加一，返回取反加一即可。</p>\n</blockquote>\n<hr>\n<h3 id=\"10-isPositive—是正数\"><a href=\"#10-isPositive—是正数\" class=\"headerlink\" title=\"10. isPositive—是正数\"></a><strong>10. isPositive—是正数</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回1如果x大于0，反之返回0\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>isPositive(-1) = 0.\n</code></pre><p><strong>可使用操作：</strong>  ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 8</p>\n<p><strong>使用操作数：</strong> 5</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">isPositive</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">return</span> !(x &gt;&gt; <span class=\"hljs-number\">31</span>) &amp; !!x;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>这题关键在于把0剔除了，区分正负数就是区分其符号位，将x右移31位，负数得-1，正数为0，用一个逻辑非使正数为1，负数为0，然后再和!!x与一下就能剔除0</p>\n</blockquote>\n<ul>\n<li>!!x 当 x == 0 时返回 0，不为 0 时返回 1</li>\n</ul>\n<hr>\n<h3 id=\"11-isLessOrEqual—小于等于\"><a href=\"#11-isLessOrEqual—小于等于\" class=\"headerlink\" title=\"11. isLessOrEqual—小于等于\"></a><strong>11. isLessOrEqual—小于等于</strong></h3><p><strong>题目：</strong></p>\n<pre><code>如果x小于等于y返回1，反之返回0\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>isLessOrEqual(4,5) = 1.\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 24</p>\n<p><strong>使用操作数：</strong> 14</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">isLessOrEqual</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x, <span class=\"hljs-keyword\">int</span> y)</span> </span>&#123;\n  <span class=\"hljs-keyword\">int</span> res = y + (~x + <span class=\"hljs-number\">1</span>); <span class=\"hljs-comment\">// y - x</span>\n  <span class=\"hljs-keyword\">int</span> xSign = x &gt;&gt; <span class=\"hljs-number\">31</span>;\n  <span class=\"hljs-keyword\">int</span> ySign = y &gt;&gt; <span class=\"hljs-number\">31</span>;\n  <span class=\"hljs-keyword\">int</span> dif = ~xSign + ySign;\n  <span class=\"hljs-keyword\">return</span> (~(dif + <span class=\"hljs-number\">1</span> &gt;&gt; <span class=\"hljs-number\">31</span>) &amp; !(res &gt;&gt; <span class=\"hljs-number\">31</span>)) | !dif;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>我在这里采取了作差的方法 res = y + (~x + 1)，即计算一下y-x，判断其是否非负，同时也要考虑溢出问题，即 x 为负数，y为正数，y-x后溢出为负。</p>\n<p>我将x,y右移31位代表其符号，若负则为-1，若正为0。我同时构造了一个 dif 以表示x,y符号之间的关系。</p>\n<p><strong>dif = ~xSign + ySign</strong></p>\n<ol>\n<li>当 x &lt; 0 &amp;&amp; y &lt; 0 时，dif = -1 </li>\n<li>当 x &lt; 0 &amp;&amp; y &gt; 0 时，dif = 0 </li>\n<li>当 x &gt; 0 &amp;&amp; y &lt; 0 时，dif = -2 </li>\n<li>当 x &gt; 0 &amp;&amp; y &lt; 0 时，dif = -1</li>\n</ol>\n<p>将 x,y 符号之间的关系表达出来，把 dif 加一我们可以观察到当 x,y 同号时，dif为0，所以将其取反和 !(res &gt;&gt; 31) 相与，就可以表示同号不溢出的情况，而当 x &lt; 0, y &gt; 0 的情况发生时，我们注意到 dif 就是 0 ，所以我们直接或上 !dif 即可表达这种情况。</p>\n</blockquote>\n<hr>\n<h3 id=\"12-ilog2—以2为底的对数\"><a href=\"#12-ilog2—以2为底的对数\" class=\"headerlink\" title=\"12. ilog2—以2为底的对数\"></a><strong>12. ilog2—以2为底的对数</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回x取以2为底的对数并向下取整，输入的 x &gt; 0\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>ilog2(16) = 4\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 90</p>\n<p><strong>使用操作数：</strong> 48</p>\n<p><strong>代码：</strong></p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">ilog2</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">int</span> tmp, l1, l2, l4, l8, l16;\n  x |= x &gt;&gt; <span class=\"hljs-number\">1</span>;\n  x |= x &gt;&gt; <span class=\"hljs-number\">2</span>;\n  x |= x &gt;&gt; <span class=\"hljs-number\">4</span>;\n  x |= x &gt;&gt; <span class=\"hljs-number\">8</span>;\n  x |= x &gt;&gt; <span class=\"hljs-number\">16</span>;\n  \n  tmp = (<span class=\"hljs-number\">0x55</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x55</span>;\n  l1 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n  tmp = (<span class=\"hljs-number\">0x33</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x33</span>;\n  l2 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n  tmp = (<span class=\"hljs-number\">0x0f</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x0f</span>;\n  l4 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n  l8 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">16</span>) + <span class=\"hljs-number\">0xff</span>;\n  l16 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0xff</span>;\n\n  x = (x &amp; l1) + ((x &gt;&gt; <span class=\"hljs-number\">1</span>) &amp; l1);\n  x = (x &amp; l2) + ((x &gt;&gt; <span class=\"hljs-number\">2</span>) &amp; l2);\n  x = (x &amp; l4) + ((x &gt;&gt; <span class=\"hljs-number\">4</span>) &amp; l4);\n  x = (x &amp; l8) + ((x &gt;&gt; <span class=\"hljs-number\">8</span>) &amp; l8);\n  x = (x &amp; l16) + ((x &gt;&gt; <span class=\"hljs-number\">16</span>) &amp; l16);\n  <span class=\"hljs-keyword\">return</span> x + ~<span class=\"hljs-number\">0</span>;</code></pre>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>我们知道二进制数每位有其位权，所以对 x 取以2为底的对数就是指其为1的最高位的位权。为了获得最高位的位置，其实我们可以将其最高位往下全部变为1，再类似bitsCount数其中1的个数就行了。</p>\n<p>我把 x 移位相与，保证最高位往下所有数字为1，再使用bitsCount就得到答案。</p>\n<p>最后不要忘记减一</p>\n</blockquote>\n<hr>\n<h3 id=\"13-float-neg—浮点数的负数\"><a href=\"#13-float-neg—浮点数的负数\" class=\"headerlink\" title=\"13. float_neg—浮点数的负数\"></a><strong>13. float_neg—浮点数的负数</strong></h3><p><strong>题目：</strong></p>\n<pre><code>返回-f，当NaN时，返回参数f\n</code></pre><p><strong>可使用操作：</strong> 所有的整型操作，包括 ||, &amp;&amp;. 以及 if, while</p>\n<p><strong>最大操作数限制：</strong> 10</p>\n<p><strong>使用操作数：</strong> 5</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-title\">float_neg</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">unsigned</span> uf)</span> </span>&#123;\n  <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-built_in\">exp</span> = uf &amp; <span class=\"hljs-number\">0x7f800000</span>;\n  <span class=\"hljs-keyword\">unsigned</span> frac = uf &amp; <span class=\"hljs-number\">0x007fffff</span>;\n  <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> == <span class=\"hljs-number\">0x7f800000</span> &amp;&amp; frac)\n    <span class=\"hljs-keyword\">return</span> uf;\n  <span class=\"hljs-keyword\">return</span> uf ^= <span class=\"hljs-number\">0x80000000</span>;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<ul>\n<li>IEEE-float<blockquote>\n<p>我们知道IEEE单精度浮点数，最高位为符号位，其后8位为阶码exp，后23位为尾数frac。其牺牲了精度来扩大了表达范围。</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>而当 exp 全 1 时，如若frac非全零，则表示NaN。若全零，则表示无穷大/小。</p>\n<p>这里我们只要将原数和符号位0x80000000异或一下，即可取负。不要忘记排除NaN的情况。</p>\n</blockquote>\n<hr>\n<h3 id=\"14-float-i2f—int转float\"><a href=\"#14-float-i2f—int转float\" class=\"headerlink\" title=\"14. float_i2f—int转float\"></a><strong>14. float_i2f—int转float</strong></h3><p><strong>题目：</strong></p>\n<pre><code>把int类型的数转换为float表示(比特形式)\n</code></pre><p><strong>可使用操作：</strong> 所有的整型操作，包括 ||, &amp;&amp;. 以及 if, while</p>\n<p><strong>最大操作数限制：</strong> 30</p>\n<p><strong>使用操作数：</strong> 30</p>\n<p><strong>代码：</strong></p>\n<pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-title\">float_i2f</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span> </span>&#123;\n  <span class=\"hljs-keyword\">unsigned</span> frac, mask1, mask2, mask3, mask4, d;\n  <span class=\"hljs-keyword\">int</span> high = <span class=\"hljs-number\">0x80000000</span>;\n  <span class=\"hljs-keyword\">unsigned</span> sign = x &amp; <span class=\"hljs-number\">0x80000000</span>;\n  <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-built_in\">exp</span> = <span class=\"hljs-number\">127</span>;\n  <span class=\"hljs-keyword\">int</span> count = <span class=\"hljs-number\">32</span>, i;\n  <span class=\"hljs-keyword\">if</span>(sign)\n    x = ~x + <span class=\"hljs-number\">1</span>;\n  <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(!x)\n    <span class=\"hljs-keyword\">return</span> x;\n  \n  frac = x;\n\n  <span class=\"hljs-keyword\">for</span>(;high; high &gt;&gt;= <span class=\"hljs-number\">1</span>)\n  &#123;\n    --count;\n    <span class=\"hljs-keyword\">if</span>(high &amp; x)\n      <span class=\"hljs-keyword\">break</span>;\n  &#125;\n  i = count - <span class=\"hljs-number\">23</span>;\n  mask1 = ~(<span class=\"hljs-number\">1</span> &lt;&lt; count); <span class=\"hljs-comment\">// the highest 1</span>\n  mask2 = <span class=\"hljs-number\">1</span> &lt;&lt; i; <span class=\"hljs-comment\">//the lowest of remain frac;</span>\n  mask3 = mask2 &gt;&gt; <span class=\"hljs-number\">1</span>; <span class=\"hljs-comment\">// the highest of deserted bits </span>\n  mask4 = mask2 - <span class=\"hljs-number\">1</span>; <span class=\"hljs-comment\">// the deserted bits</span>\n  <span class=\"hljs-built_in\">exp</span> += count;\n\n  frac &amp;= mask1;\n  \n  <span class=\"hljs-keyword\">if</span>(i &gt; <span class=\"hljs-number\">0</span>)\n  &#123;\n    d = frac &amp; mask4; <span class=\"hljs-comment\">// deserted bits</span>\n    <span class=\"hljs-keyword\">if</span>(d &gt; mask3 | (d == mask3 &amp;&amp; frac &amp; mask2))\n    &#123;\n      frac += mask2;\n      <span class=\"hljs-keyword\">if</span>(frac &gt; <span class=\"hljs-number\">0x3fffffff</span>)\n      &#123;\n        frac = <span class=\"hljs-number\">0</span>;\n        <span class=\"hljs-built_in\">exp</span>++;\n      &#125;\n    &#125;\n    frac &gt;&gt;= i;\n  &#125;\n  <span class=\"hljs-keyword\">else</span>\n    frac &lt;&lt;= -i;\n\n  <span class=\"hljs-keyword\">return</span> sign | <span class=\"hljs-built_in\">exp</span> &lt;&lt; <span class=\"hljs-number\">23</span> | frac;\n&#125;</code></pre>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>我认为这题比较难，我做了很久很久….它难在浮点数向偶数舍入以及其操作数的限制。</p>\n<p>我们知道由于浮点数表示范围比整型大，我们可以将整型转换为浮点数，但是相应的会有一些精度的丢失，因为尾数frac只有23位，而int有31位可用。</p>\n<p>所以其关键在于int的位数，一开始先把该取出来的都用掩码取出来，把负数和零处理一下。之后我利用了一个循环先找出int的最高位在哪，利用count计数。</p>\n<p>后面我采取了四个掩码，分别代表最高位的1，留下的尾数中的最低位，要舍去的位数的最高位，以及舍弃的位数的掩码。利用这四个掩码我们可以达到存frac时，将其向<strong>偶数舍入</strong>。</p>\n<p>具体操作是，先取出丢弃的尾数，将其存放在d中，看其有没有超过0.5 (即 d 是否大于 mask3) 如果大于，直接frac++就行。而如果等于的话，还要看frac是否是奇数 (即frac &amp; mask2是否为1) 如果是，则要向偶数舍入,frac++。</p>\n<p>加完frac之后还要注意<strong>溢出问题</strong>，如果溢出了，要将frac置0，然后把阶码 exp++，再按照之前输出来的尾数移动，将尾数对齐即可 （位数最高默认为1不存，因而把最高位隐去）。</p>\n<p>最后把符号位，阶码位和尾数位拼接，得到最后的结果。</p>\n</blockquote>\n<hr>\n<h3 id=\"15-float-twice—float-2\"><a href=\"#15-float-twice—float-2\" class=\"headerlink\" title=\"15. float_twice—float * 2\"></a>15. float_twice—float * 2</h3><p><strong>题目：</strong></p>\n<pre><code>返回float * 2, 当参数是NaN时，返回参数\n</code></pre><p><strong>可使用操作：</strong> 所有的整型操作，包括 ||, &amp;&amp;. 以及 if, while</p>\n<p><strong>最大操作数限制：</strong> 30</p>\n<p><strong>使用操作数：</strong> 20</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-title\">float_twice</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">unsigned</span> uf)</span> </span>&#123;\n  <span class=\"hljs-keyword\">unsigned</span> sign = uf &amp; <span class=\"hljs-number\">0x80000000</span>;\n  <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-built_in\">exp</span> = uf &amp; <span class=\"hljs-number\">0x7f800000</span>;\n  <span class=\"hljs-keyword\">unsigned</span> frac = uf &amp; <span class=\"hljs-number\">0x007fffff</span>;\n  <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> == <span class=\"hljs-number\">0x7f800000</span>) <span class=\"hljs-comment\">//NaN &amp; inf</span>\n    <span class=\"hljs-keyword\">return</span> uf;\n  <span class=\"hljs-keyword\">if</span>(!<span class=\"hljs-built_in\">exp</span> &amp;&amp; !frac) <span class=\"hljs-comment\">// 0</span>\n    <span class=\"hljs-keyword\">return</span> uf;\n  <span class=\"hljs-keyword\">if</span>(!<span class=\"hljs-built_in\">exp</span> &amp;&amp; frac &lt;= <span class=\"hljs-number\">0x3fffff</span>)  <span class=\"hljs-comment\">// low</span>\n    frac *= <span class=\"hljs-number\">2</span>;\n  <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(!<span class=\"hljs-built_in\">exp</span> &amp;&amp; frac &gt; <span class=\"hljs-number\">0x3fffff</span>) <span class=\"hljs-comment\">// high</span>\n  &#123;\n    <span class=\"hljs-built_in\">exp</span> += <span class=\"hljs-number\">0x00800000</span>;\n    frac = (frac * <span class=\"hljs-number\">2</span>) &amp; <span class=\"hljs-number\">0x7fffff</span>;\n  &#125;\n  <span class=\"hljs-keyword\">else</span> <span class=\"hljs-comment\">// normal</span>\n    <span class=\"hljs-built_in\">exp</span> += <span class=\"hljs-number\">0x00800000</span>;\n  <span class=\"hljs-keyword\">return</span> sign + <span class=\"hljs-built_in\">exp</span> + frac;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>主要要分析的地方，在于当阶码exp为0时，是否在乘2之后进位。所以要考虑尾数是否大于0x3fffff，如果小于等于之，则直接尾数乘2就行，不会溢出，否则则exp要进位，同时尾数乘2之后要与上0x7fffff保证不溢出。</p>\n<p>其他正常情况直接exp++就行，注意一下特殊情况;</p>\n</blockquote>\n<p><em>本题中测试集中有一个inf，也要直接返回参数uf</em></p>\n<hr>\n<h2 id=\"Bits-honor-c\"><a href=\"#Bits-honor-c\" class=\"headerlink\" title=\"Bits_honor.c\"></a><strong>Bits_honor.c</strong></h2><h3 id=\"1-bitReverse—比特翻转\"><a href=\"#1-bitReverse—比特翻转\" class=\"headerlink\" title=\"1. bitReverse—比特翻转\"></a><strong>1. bitReverse—比特翻转</strong></h3><p><strong>题目：</strong></p>\n<pre><code>把32比特int的比特位翻转\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>bitReverse(0x80000004) = 0x20000001\nbitReverse(0x7FFFFFFF) = 0xFFFFFFFE\n</code></pre><p><strong>最大操作数限制：</strong> 40</p>\n<p><strong>使用操作数：</strong> 40</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">bitReverse</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n   <span class=\"hljs-keyword\">int</span> tmp,l1, l2, l4, l8, l16;\n\n   tmp = (<span class=\"hljs-number\">0x55</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x55</span>;\n   l1 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n   tmp = (<span class=\"hljs-number\">0x33</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x33</span>;\n   l2 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n   tmp = (<span class=\"hljs-number\">0x0f</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0x0f</span>;\n   l4 = (tmp &lt;&lt; <span class=\"hljs-number\">16</span>) + tmp;\n   l8 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">16</span>) + <span class=\"hljs-number\">0xff</span>;\n   l16 = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0xff</span>;\n\n   x = ((x &gt;&gt; <span class=\"hljs-number\">16</span>) &amp; l16) | (x &lt;&lt; <span class=\"hljs-number\">16</span>);\n   x = ((x &gt;&gt; <span class=\"hljs-number\">8</span>) &amp; l8) | ((x &amp; l8) &lt;&lt; <span class=\"hljs-number\">8</span>);\n   x = ((x &gt;&gt; <span class=\"hljs-number\">4</span>) &amp; l4) | ((x &amp; l4) &lt;&lt; <span class=\"hljs-number\">4</span>);\n   x = ((x &gt;&gt; <span class=\"hljs-number\">2</span>) &amp; l2) | ((x &amp; l2) &lt;&lt; <span class=\"hljs-number\">2</span>);\n   x = ((x &gt;&gt; <span class=\"hljs-number\">1</span>) &amp; l1) | ((x &amp; l1) &lt;&lt; <span class=\"hljs-number\">1</span>);\n   <span class=\"hljs-keyword\">return</span> x;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>这题和 bitsCount 有异曲同工之妙，也是一个分治法，将32位二进制数一分为二，交换，再将内部各自再一分为二，交换，直至最底层2位二进制数互换位置，最后完成了将所有位数翻转的工作。</p>\n<p>但值得注意的是，给出的是有符号的int，所以在右移交换位置时，会发生因为负数算术右移导致高位全是1的情况，致使在与的过程中高位全部变为1。这边只要将其移动后在和掩码相与就能解决这一问题。而对于低位，先与掩码相与再移动，可以省去取反得到高位掩码的操作数。再用tmp省一下操作数。</p>\n<p>最后操作数正好卡在40</p>\n</blockquote>\n<hr>\n<h3 id=\"2-mod3—取模3\"><a href=\"#2-mod3—取模3\" class=\"headerlink\" title=\"2. mod3—取模3\"></a><strong>2. mod3—取模3</strong></h3><p><strong>题目：</strong></p>\n<pre><code>计算 x 取模 3，而不用%\n</code></pre><p><strong>样例：</strong></p>\n<pre><code>mod3(100) = 1\nmod3(-100) = -1\n</code></pre><p><strong>可使用操作：</strong> ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</p>\n<p><strong>最大操作数限制：</strong> 90</p>\n<p><strong>使用操作数：</strong> 24</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">mod3</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> x)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n   <span class=\"hljs-keyword\">int</span> mask = (<span class=\"hljs-number\">0xff</span> &lt;&lt; <span class=\"hljs-number\">8</span>) + <span class=\"hljs-number\">0xff</span>;\n\n   x = (x &gt;&gt; <span class=\"hljs-number\">16</span>) + (x &amp; mask); <span class=\"hljs-comment\">// sum base 4^8 digits (a &lt;= 0x1FFFE)</span>\n   x = (x &gt;&gt; <span class=\"hljs-number\">8</span>) + (x &amp; <span class=\"hljs-number\">0xff</span>); <span class=\"hljs-comment\">// sum base 4^4 digits (a &lt;= 0x2FD)</span>\n   x = (x &gt;&gt; <span class=\"hljs-number\">4</span>) + (x &amp; <span class=\"hljs-number\">0xf</span>); <span class=\"hljs-comment\">// sum base 4^2 digits (a &lt;= 0x3C)</span>\n   x = (x &gt;&gt; <span class=\"hljs-number\">2</span>) + (x &amp; <span class=\"hljs-number\">0x3</span>); <span class=\"hljs-comment\">// sum base 4^1 digits (a &lt;= 0x1D)</span>\n   x = (x &gt;&gt; <span class=\"hljs-number\">2</span>) + (x &amp; <span class=\"hljs-number\">0x3</span>); <span class=\"hljs-comment\">// sum base 4^1 digits (a &lt;= 0x9)</span>\n   x = (x &gt;&gt; <span class=\"hljs-number\">2</span>) + (x &amp; <span class=\"hljs-number\">0x3</span>); <span class=\"hljs-comment\">// sum base 4^1 digits (a &lt;= 0x4)</span>\n\n   x = (((x + <span class=\"hljs-number\">1</span>) &gt;&gt; <span class=\"hljs-number\">2</span>) + x) &amp; <span class=\"hljs-number\">0x3</span>;\n   <span class=\"hljs-keyword\">return</span> x;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>这题难度算是比较大的，我参考了一些资料最后才写出这个代码。其实这题也与bitsCount有着一定的联系。</p>\n<p>对于解这题有一个根本的公式即 </p>\n</blockquote>\n<pre><code>a % m = ((b % m)(a/b) + (a % b)) % m\n其中b是进制数\n</code></pre><blockquote>\n<p>我们知道，如果想要知道一个十进制的数能否被三整除，只要看它所有数位之和是否能被三整除就行了。其实这就是上述公式的特殊情况，由于10 mod 3 == 1 所以其就退化为</p>\n</blockquote>\n<pre><code>a mod m = (a/b + a % b) % m\n递归下来就是所有数位之和\n</code></pre><blockquote>\n<p>而对于二进制的情况，我们可以将进制位b选为4，这样正好是两位二进制数，同时4 % 3 == 1，这样一来，对于二进制数中我们只需要统计所有两两数位(四进制)的和能否被三整除就行了。</p>\n<p>而考虑到我们每做一次 a/b + a % b 统计数位和都减小了数的规模，这样只要做有限次就能够将数控制在&lt;=3的范围内。</p>\n<p>对于a % 4，这是一个经典的trivial情况，我们只需要做 a &amp; 3，就能够轻松得到a % 4的值。而对于a/4，只需要做a &gt;&gt; 2即可。</p>\n<p>对于二进制数我们不仅可以按两位两位的四进制数位和来数，也可以直接数其倍数(4^i)，从最大4^8开始统计，一步步减小x的值，最后将x做到&lt;= 3的范围</p>\n<p>最后要判断x是否为3，如果为3的话则要置为0，我利用3数位全为1的特点，将其+1进位后，右移2位。如果为3，则得到的是1。将其再加上x，如若x是1或2，则还是不变，但如果是3，它又会进位到4，那么我们只要再与上0x3，则会得到0，即为想要的结果。</p>\n</blockquote>\n<hr>\n<h3 id=\"3-float-f2i—float转int\"><a href=\"#3-float-f2i—float转int\" class=\"headerlink\" title=\"3. float_f2i—float转int\"></a><strong>3. float_f2i—float转int</strong></h3><p><strong>题目：</strong></p>\n<pre><code>输入一个按二进制位储存的float（以unsigned表示），将其转为int输出。(NaN,inf，溢出直接返回参数)\n</code></pre><p><strong>可使用操作：</strong> 所有的整型操作，包括 ||, &amp;&amp;. 以及 if, while</p>\n<p><strong>最大操作数限制：</strong> 30</p>\n<p><strong>使用操作数：</strong> 17</p>\n<p><strong>代码：</strong><br><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">float_f2i</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">unsigned</span> uf)</span></span>\n<span class=\"hljs-function\"></span>&#123;\n   <span class=\"hljs-keyword\">int</span> sign, <span class=\"hljs-built_in\">exp</span>, frac, res;\n   <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">int</span> tmp;\n\n   <span class=\"hljs-keyword\">if</span>(!uf)\n      <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n   sign = uf &amp; <span class=\"hljs-number\">0x80000000</span>;\n   <span class=\"hljs-built_in\">exp</span> = uf &amp; <span class=\"hljs-number\">0x7f800000</span>;\n   frac = (uf &amp; <span class=\"hljs-number\">0x007fffff</span>) | <span class=\"hljs-number\">0x00800000</span>;\n\n   <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> == <span class=\"hljs-number\">0x7f800000</span>) <span class=\"hljs-comment\">//NaN and inf</span>\n      <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0x80000000</span>u;\n\n   <span class=\"hljs-built_in\">exp</span> &gt;&gt;= <span class=\"hljs-number\">23</span>;\n\n   <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> &lt; <span class=\"hljs-number\">127</span>)\n      <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\n   <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> &gt; <span class=\"hljs-number\">158</span>)\n      <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0x80000000</span>u;\n   <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span>(<span class=\"hljs-built_in\">exp</span> &gt; <span class=\"hljs-number\">150</span>)\n      tmp = frac &lt;&lt; (<span class=\"hljs-built_in\">exp</span> - <span class=\"hljs-number\">150</span>);\n   <span class=\"hljs-keyword\">else</span>\n      tmp = frac &gt;&gt; (<span class=\"hljs-number\">150</span> - <span class=\"hljs-built_in\">exp</span>);\n\n      \n   <span class=\"hljs-keyword\">if</span>(sign)\n      res = ~tmp + <span class=\"hljs-number\">1</span>;\n   <span class=\"hljs-keyword\">else</span>\n      res = tmp;\n   \n   <span class=\"hljs-keyword\">return</span> res | sign;\n&#125;</code></pre></p>\n<p><strong>分析：</strong></p>\n<blockquote>\n<p>这题特殊情况比较多，把NaN和inf处理一下，然后注意一下溢出情况，即取出来的exp - bias &gt; 31，肯定超过2^31整型储存的最大值，直接返回0x80000000u，然后对于exp小于127的，其指数是负数，直接返回int值为0。对于在exp - bias 在 0 到 31 之间的，由于frac只有23位，所以要将注意一下讨论23的情况。</p>\n<p>最后把取出来的符号位对一下，如果负数取反加一，正数直接等，最后再或上符号位，返回答案。</p>\n</blockquote>\n<hr>\n<h2 id=\"结果截图\"><a href=\"#结果截图\" class=\"headerlink\" title=\"结果截图\"></a><strong>结果截图</strong></h2><h3 id=\"bits-c\"><a href=\"#bits-c\" class=\"headerlink\" title=\"bits.c\"></a><strong>bits.c</strong></h3><p><img src=\"/2020/11/05/ICS/ICS_Lab1/ICS_Lab1/bits_btest.JPG\" alt=\"bits_btest\"></p>\n<p><img src=\"/2020/11/05/ICS/ICS_Lab1/ICS_Lab1/bits_dlc.png\" alt=\"bits_dlc\"></p>\n<h3 id=\"bits-honor-c\"><a href=\"#bits-honor-c\" class=\"headerlink\" title=\"bits_honor.c\"></a><strong>bits_honor.c</strong></h3><p><img src=\"/2020/11/05/ICS/ICS_Lab1/ICS_Lab1/bits_honor_btest.JPG\" alt=\"bits_honor_btest\"></p>\n<p><img src=\"/2020/11/05/ICS/ICS_Lab1/ICS_Lab1/bits_honor_dlc.png\" alt=\"bits_honor_dlc\"></p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><hr>\n<p><a href=\"https://baike.baidu.com/item/%E7%AE%97%E6%9C%AF%E5%8F%B3%E7%A7%BB/3711081?fr=aladdin\">https://baike.baidu.com/item/%E7%AE%97%E6%9C%AF%E5%8F%B3%E7%A7%BB/3711081?fr=aladdin</a><br><a href=\"https://blog.csdn.net/jiahonghao2002/article/details/108223366\">https://blog.csdn.net/jiahonghao2002/article/details/108223366</a><br><a href=\"https://leetcode-cn.com/problems/reverse-bits/solution/dian-dao-er-jin-zhi-wei-by-leetcode/\">https://leetcode-cn.com/problems/reverse-bits/solution/dian-dao-er-jin-zhi-wei-by-leetcode/</a><br><a href=\"http://homepage.cs.uiowa.edu/~jones/bcd/mod.shtml#exmod3\">http://homepage.cs.uiowa.edu/~jones/bcd/mod.shtml#exmod3</a><br><a href=\"https://www.zhihu.com/question/38206659/answer/763034261\">https://www.zhihu.com/question/38206659/answer/763034261</a><br><a href=\"https://blog.csdn.net/xindaxinda123/article/details/95617758\">https://blog.csdn.net/xindaxinda123/article/details/95617758</a><br><a href=\"https://www.runoob.com/w3cnote/32-float-storage.html\">https://www.runoob.com/w3cnote/32-float-storage.html</a></p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"ckmlxty3h0001s8pd3vhk8mmo","category_id":"ckmlxty3l0003s8pd3mtx9oy9","_id":"ckmlxty3r000ds8pd7fx91m45"},{"post_id":"ckmlxty3k0002s8pd4l45g0a0","category_id":"ckmlxty3p0008s8pdbe7acy6i","_id":"ckmlxty3t000js8pdfwm44yg0"},{"post_id":"ckmlxty3m0005s8pd48u1d6qi","category_id":"ckmlxty3r000es8pd0d9m35ym","_id":"ckmlxty3v000ps8pd9lrp4a9p"},{"post_id":"ckmlxty3o0007s8pdgn6h1v07","category_id":"ckmlxty3t000ks8pd733l2uzz","_id":"ckmlxty3y000vs8pdc5e03b1c"},{"post_id":"ckmlxty3u000os8pda6xe1npm","category_id":"ckmlxty3l0003s8pd3mtx9oy9","_id":"ckmlxty3z000ys8pdge5o9dlp"},{"post_id":"ckmlxty3v000ss8pdhko4h6ju","category_id":"ckmlxty3l0003s8pd3mtx9oy9","_id":"ckmlxty400012s8pd4ep6diwq"},{"post_id":"ckmlxty3p000bs8pd636perai","category_id":"ckmlxty3t000ks8pd733l2uzz","_id":"ckmlxty410016s8pdf7q9d0eq"},{"post_id":"ckmlxty3x000ts8pd2h0seurj","category_id":"ckmlxty3l0003s8pd3mtx9oy9","_id":"ckmlxty420019s8pdhtt23u30"},{"post_id":"ckmlxty3y000ws8pd6qk954ab","category_id":"ckmlxty3l0003s8pd3mtx9oy9","_id":"ckmlxty43001cs8pdc6kmerld"},{"post_id":"ckmlxty3q000cs8pdh2o9h9bc","category_id":"ckmlxty3t000ks8pd733l2uzz","_id":"ckmlxty44001gs8pd873s7uge"},{"post_id":"ckmlxty3z0010s8pd87d906th","category_id":"ckmlxty3t000ks8pd733l2uzz","_id":"ckmlxty46001ks8pd1p7r7c7q"},{"post_id":"ckmlxty3r000gs8pd9zhx04nq","category_id":"ckmlxty3t000ks8pd733l2uzz","_id":"ckmlxty47001ls8pddc2o2bwo"},{"post_id":"ckmlxty3s000is8pd5wt640m8","category_id":"ckmlxty3t000ks8pd733l2uzz","_id":"ckmlxty47001os8pd8haofcod"},{"post_id":"ckmlxty3u000ms8pd3bm6ayoa","category_id":"ckmlxty44001fs8pd15czacj1","_id":"ckmlxty48001qs8pdh0d6elc8"},{"post_id":"ckmlxty400014s8pdbyq818pn","category_id":"ckmlxty47001ms8pd02wp1gpv","_id":"ckmlxty48001vs8pd0isdfuou"},{"post_id":"ckmlxty410017s8pd5wk6cdeg","category_id":"ckmlxty44001fs8pd15czacj1","_id":"ckmlxty49001zs8pdht4u8d63"},{"post_id":"ckmlxty42001as8pdf47va6bd","category_id":"ckmlxty47001ms8pd02wp1gpv","_id":"ckmlxty4a0023s8pd79qbbwq0"},{"post_id":"ckmlxty43001ds8pde3ykgu2z","category_id":"ckmlxty47001ms8pd02wp1gpv","_id":"ckmlxty4a0026s8pde3hc28sh"},{"post_id":"ckmlxty44001hs8pdekw402qc","category_id":"ckmlxty47001ms8pd02wp1gpv","_id":"ckmlxty4c002es8pdgzztedde"},{"post_id":"ckmlxty44001hs8pdekw402qc","category_id":"ckmlxty4b0029s8pdbmf80hqs","_id":"ckmlxty4c002fs8pd2s4l1wad"},{"post_id":"ckmlxty4h0035s8pd5lfhafgi","category_id":"ckmlxty47001ms8pd02wp1gpv","_id":"ckmlxty4j0038s8pd9289a1k6"},{"post_id":"ckmlxty4h0035s8pd5lfhafgi","category_id":"ckmlxty4b0029s8pdbmf80hqs","_id":"ckmlxty4j003as8pd8667bmms"},{"post_id":"ckmlxty4i0036s8pd7qq1368u","category_id":"ckmlxty3l0003s8pd3mtx9oy9","_id":"ckmlxty4j003cs8pdhyc843p6"}],"PostTag":[{"post_id":"ckmlxty3h0001s8pd3vhk8mmo","tag_id":"ckmlxty3m0004s8pd8n7c3aml","_id":"ckmlxty3p000as8pd22evb5v1"},{"post_id":"ckmlxty3k0002s8pd4l45g0a0","tag_id":"ckmlxty3p0009s8pdf5h7c9eu","_id":"ckmlxty3s000hs8pdamdcbjxb"},{"post_id":"ckmlxty3m0005s8pd48u1d6qi","tag_id":"ckmlxty3r000fs8pd9txzgn3q","_id":"ckmlxty3u000ns8pd023pffhi"},{"post_id":"ckmlxty3n0006s8pd3akv7l1s","tag_id":"ckmlxty3t000ls8pdey8xa64j","_id":"ckmlxty3z000zs8pd3w2r2yqm"},{"post_id":"ckmlxty3n0006s8pd3akv7l1s","tag_id":"ckmlxty3v000rs8pd9rcw2juh","_id":"ckmlxty400013s8pd36i93olv"},{"post_id":"ckmlxty3o0007s8pdgn6h1v07","tag_id":"ckmlxty3z000xs8pdgeq0bmk1","_id":"ckmlxty44001es8pdh8ev7zce"},{"post_id":"ckmlxty3o0007s8pdgn6h1v07","tag_id":"ckmlxty410015s8pd3f801gh3","_id":"ckmlxty46001is8pd66em7no7"},{"post_id":"ckmlxty3p000bs8pd636perai","tag_id":"ckmlxty3z000xs8pdgeq0bmk1","_id":"ckmlxty47001ps8pdch6b0fbe"},{"post_id":"ckmlxty3p000bs8pd636perai","tag_id":"ckmlxty410015s8pd3f801gh3","_id":"ckmlxty48001ss8pd053f01r2"},{"post_id":"ckmlxty3q000cs8pdh2o9h9bc","tag_id":"ckmlxty3z000xs8pdgeq0bmk1","_id":"ckmlxty49001xs8pd7gy4frbj"},{"post_id":"ckmlxty3q000cs8pdh2o9h9bc","tag_id":"ckmlxty410015s8pd3f801gh3","_id":"ckmlxty490020s8pdhq2saeu5"},{"post_id":"ckmlxty3r000gs8pd9zhx04nq","tag_id":"ckmlxty3z000xs8pdgeq0bmk1","_id":"ckmlxty4a0025s8pdgxe8h9zo"},{"post_id":"ckmlxty3r000gs8pd9zhx04nq","tag_id":"ckmlxty410015s8pd3f801gh3","_id":"ckmlxty4a0027s8pdewqofict"},{"post_id":"ckmlxty3s000is8pd5wt640m8","tag_id":"ckmlxty3z000xs8pdgeq0bmk1","_id":"ckmlxty4b002bs8pd2zzy0v2y"},{"post_id":"ckmlxty3s000is8pd5wt640m8","tag_id":"ckmlxty410015s8pd3f801gh3","_id":"ckmlxty4b002cs8pdb6ju7rf5"},{"post_id":"ckmlxty3u000ms8pd3bm6ayoa","tag_id":"ckmlxty4b002as8pd5qtsb64f","_id":"ckmlxty4c002hs8pd592w1d2k"},{"post_id":"ckmlxty3u000ms8pd3bm6ayoa","tag_id":"ckmlxty4b002ds8pd90tn3liz","_id":"ckmlxty4c002is8pd5u5nhxfe"},{"post_id":"ckmlxty3u000os8pda6xe1npm","tag_id":"ckmlxty4c002gs8pdhpvs7nan","_id":"ckmlxty4c002ks8pd8gctaiwr"},{"post_id":"ckmlxty3v000ss8pdhko4h6ju","tag_id":"ckmlxty4c002js8pd8wf76vzv","_id":"ckmlxty4d002ms8pd40z8hhqj"},{"post_id":"ckmlxty3x000ts8pd2h0seurj","tag_id":"ckmlxty4c002ls8pd17dtffb9","_id":"ckmlxty4d002os8pd0u0qcder"},{"post_id":"ckmlxty3y000ws8pd6qk954ab","tag_id":"ckmlxty4d002ns8pd40ra558j","_id":"ckmlxty4d002qs8pddp4xatme"},{"post_id":"ckmlxty3z0010s8pd87d906th","tag_id":"ckmlxty3z000xs8pdgeq0bmk1","_id":"ckmlxty4e002ss8pdal433cgs"},{"post_id":"ckmlxty3z0010s8pd87d906th","tag_id":"ckmlxty410015s8pd3f801gh3","_id":"ckmlxty4e002ts8pd1g2ca2x7"},{"post_id":"ckmlxty400014s8pdbyq818pn","tag_id":"ckmlxty4d002rs8pd9olcc7lv","_id":"ckmlxty4e002vs8pd1zp9exmm"},{"post_id":"ckmlxty410017s8pd5wk6cdeg","tag_id":"ckmlxty4e002us8pd1cdbcczb","_id":"ckmlxty4e002ys8pdha5cfleh"},{"post_id":"ckmlxty410017s8pd5wk6cdeg","tag_id":"ckmlxty4e002ws8pd5zoyd3p9","_id":"ckmlxty4e002zs8pd8obwhjh5"},{"post_id":"ckmlxty42001as8pdf47va6bd","tag_id":"ckmlxty4e002xs8pd7d8c3r8a","_id":"ckmlxty4f0031s8pdebvq6mcp"},{"post_id":"ckmlxty43001ds8pde3ykgu2z","tag_id":"ckmlxty4e002xs8pd7d8c3r8a","_id":"ckmlxty4f0033s8pdhgyj7r67"},{"post_id":"ckmlxty44001hs8pdekw402qc","tag_id":"ckmlxty4f0032s8pdc1dra0wz","_id":"ckmlxty4f0034s8pd2szucqae"},{"post_id":"ckmlxty4h0035s8pd5lfhafgi","tag_id":"ckmlxty4i0037s8pd8pqw6e4f","_id":"ckmlxty4j003bs8pd4ylebahn"},{"post_id":"ckmlxty4i0036s8pd7qq1368u","tag_id":"ckmlxty4j0039s8pd32se4uh1","_id":"ckmlxty4j003ds8pddkux2o9s"}],"Tag":[{"name":"Link","_id":"ckmlxty3m0004s8pd8n7c3aml"},{"name":"TODO","_id":"ckmlxty3p0009s8pdf5h7c9eu"},{"name":"Summary","_id":"ckmlxty3r000fs8pd9txzgn3q"},{"name":"Hexo","_id":"ckmlxty3t000ls8pdey8xa64j"},{"name":"Fluid","_id":"ckmlxty3v000rs8pd9rcw2juh"},{"name":"CV","_id":"ckmlxty3z000xs8pdgeq0bmk1"},{"name":"Neural Network","_id":"ckmlxty410015s8pd3f801gh3"},{"name":"LCA","_id":"ckmlxty4b002as8pd5qtsb64f"},{"name":"UFS","_id":"ckmlxty4b002ds8pd90tn3liz"},{"name":"Linker","_id":"ckmlxty4c002gs8pdhpvs7nan"},{"name":"Sort","_id":"ckmlxty4c002js8pd8wf76vzv"},{"name":"CPU","_id":"ckmlxty4c002ls8pd17dtffb9"},{"name":"Assembly","_id":"ckmlxty4d002ns8pd40ra558j"},{"name":"PointCNN","_id":"ckmlxty4d002rs8pd9olcc7lv"},{"name":"Number theory","_id":"ckmlxty4e002us8pd1cdbcczb"},{"name":"Multiplication algorithm","_id":"ckmlxty4e002ws8pd5zoyd3p9"},{"name":"PointNet","_id":"ckmlxty4e002xs8pd7d8c3r8a"},{"name":"Monocular OD","_id":"ckmlxty4f0032s8pdc1dra0wz"},{"name":"Transformer","_id":"ckmlxty4i0037s8pd8pqw6e4f"},{"name":"Bits","_id":"ckmlxty4j0039s8pd32se4uh1"}]}}